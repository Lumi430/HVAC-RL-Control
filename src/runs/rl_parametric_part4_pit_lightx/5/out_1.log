Traceback (most recent call last):
  File "../../../a3c_eplus_rlParametric_v0.1.py", line 14, in <module>
    from main_args import *
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/main_args.py", line 4, in <module>
    import gym
ImportError: No module named gym
Using TensorFlow backend.
[2019-04-24 09:35:28,815] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v3', activation='linear', agent_num=5, check_args_only=False, clip_norm=1.0, debug_log_prob=0.001, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Light-Pit-Train-Repeat-v2', eval_act_func='part4_v4', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=50000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_add_time_to_state=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_r_term_zero=True, is_warm_start=True, job_mode='Train', learning_rate=1e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=3000000, metric_func='part4_v2', model_dir='Part4-Light-Pit-Train-Repeat-v2-res1/model_data/model.ckpt-3000000', model_param=[13, 1], model_type='nn', num_threads=16, output='./Part4-Light-Pit-Train-Repeat-v2-res2', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v8', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=10.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=11, test_env=['Part4-Light-Pit-Test-Repeat-v3', 'Part4-Light-Pit-Test-Repeat-v4'], test_mode='Multiple', train_act_func='part4_v4', train_freq=25, v_loss_frac=0.5, violation_penalty_scl=5.0, weight_initer='glorot_uniform', window_len=10)
[2019-04-24 09:35:28,815] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-24 09:35:28.867138: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-24 09:35:59,365] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-24 09:35:59,366] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Light-Pit-Train-Repeat-v2', 'Part4-Light-Pit-Test-Repeat-v3', 'Part4-Light-Pit-Test-Repeat-v4'] ...
[2019-04-24 09:35:59,394] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation worker starts!
[2019-04-24 09:35:59,411] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation worker starts!
[2019-04-24 09:35:59,428] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation worker starts!
[2019-04-24 09:35:59,429] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:35:59,429] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-24 09:35:59,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:35:59,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run1
[2019-04-24 09:36:00,439] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:00,439] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-24 09:36:00,543] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:00,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run1
[2019-04-24 09:36:01,440] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:01,452] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-24 09:36:01,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:01,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run1
[2019-04-24 09:36:02,453] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:02,453] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-24 09:36:02,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:02,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run1
[2019-04-24 09:36:03,454] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:03,455] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-24 09:36:03,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:03,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run1
[2019-04-24 09:36:04,456] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:04,457] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2019-04-24 09:36:04,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:04,623] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run1
[2019-04-24 09:36:05,458] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:05,459] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2019-04-24 09:36:05,638] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:05,640] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run1
[2019-04-24 09:36:06,462] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:06,463] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-04-24 09:36:06,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:06,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run1
[2019-04-24 09:36:07,464] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:07,465] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-04-24 09:36:07,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:07,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run1
[2019-04-24 09:36:08,466] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:08,467] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-04-24 09:36:08,636] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:08,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run1
[2019-04-24 09:36:09,468] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:09,478] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-24 09:36:09,851] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:09,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run1
[2019-04-24 09:36:10,478] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:10,479] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-24 09:36:10,665] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-24 09:36:10,665] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:36:10,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:10,669] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:36:10,669] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:10,671] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run1
[2019-04-24 09:36:10,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run1
[2019-04-24 09:36:10,891] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:36:10,892] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:10,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run1
[2019-04-24 09:36:11,359] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:11,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run1
[2019-04-24 09:36:11,489] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:11,490] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-24 09:36:11,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:11,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run1
[2019-04-24 09:36:12,500] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:12,513] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-24 09:36:13,514] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:13,515] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-24 09:36:13,671] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:13,674] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run1
[2019-04-24 09:36:14,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:14,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run1
[2019-04-24 09:36:14,529] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:36:14,530] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-24 09:36:15,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:36:15,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run1
[2019-04-24 09:36:51,960] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.20599602], dtype=float32), 0.29495656]
[2019-04-24 09:36:51,961] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [1.433333333333334, 86.0, 0.0, 0.0, 19.0, 21.04507669706954, -0.5685645692044065, 0.0, 1.0, 55.0, 70.75778089262346]
[2019-04-24 09:36:51,962] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 09:36:51,963] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [5.7507229e-01 2.3677251e-03 6.2170769e-03 7.3940441e-07 9.7041941e-10
 7.4221795e-08 1.2240263e-08 5.5191722e-03 4.1082299e-01 1.2371083e-09
 1.2478574e-10], sampled 0.015342521860748803
[2019-04-24 09:37:04,231] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.20599602], dtype=float32), 0.29495656]
[2019-04-24 09:37:04,232] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [1.005542477333333, 68.98867959333334, 0.0, 0.0, 19.0, 18.67604646787008, -1.194982262120213, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:37:04,232] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 09:37:04,233] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [3.9822432e-01 6.9858325e-03 2.0431779e-02 6.6578773e-06 1.4783596e-08
 5.7979651e-07 1.8682452e-07 9.4927698e-03 5.6485796e-01 2.0354312e-08
 5.1674744e-09], sampled 0.4649786800858966
[2019-04-24 09:37:54,477] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2880.7759 89661.6707 197.9900
[2019-04-24 09:37:54,510] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:37:54,627] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:38:00,784] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2621.3988 100153.9347 -178.8478
[2019-04-24 09:38:00,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:38:00,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:38:07,407] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2543.8439 104616.9392 -255.0066
[2019-04-24 09:38:07,427] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:38:07,531] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:38:08,429] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2621.3988034746462, 100153.93465046567, -178.84783039244178, 2880.7759046046713, 89661.67073976932, 197.98997484664008, 2543.8439105166312, 104616.93917415239, -255.00661837224123]
[2019-04-24 09:38:17,445] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3108984e-01 1.9243798e-03 1.1717133e-02 2.9807435e-07 1.6427643e-10
 2.1629779e-08 2.6735547e-09 6.6199945e-04 4.5460629e-01 1.5322851e-10
 4.2781303e-11], sum to 1.0000
[2019-04-24 09:38:17,446] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7975
[2019-04-24 09:38:17,640] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 19.0, 20.71270189148861, -0.7832037800327515, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 172800.0000, 
sim time next is 174000.0000, 
raw observation next is [-8.566666666666666, 72.0, 0.0, 0.0, 19.0, 20.59759069249273, -0.5901591843500916, 0.0, 1.0, 55.0, 80.96084907312371], 
processed observation next is [1.0, 0.0, 0.22530009233610343, 0.72, 0.0, 0.0, 0.08333333333333333, 0.21646589104106084, 0.3032802718833028, 0.0, 1.0, 0.8, 0.8096084907312371], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12058026], dtype=float32), -0.41686964]. 
=============================================
[2019-04-24 09:38:18,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4552835e-01 3.3147421e-03 4.2358311e-03 1.0251654e-06 1.1332302e-09
 1.6112241e-07 2.1187009e-08 4.6750861e-03 4.4224474e-01 5.0913235e-10
 5.1197391e-10], sum to 1.0000
[2019-04-24 09:38:18,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9423
[2019-04-24 09:38:18,335] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 18.75462817270654, -0.9839870596247874, 0.0, 1.0, 55.0, 90.69897381905116], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 189600.0000, 
sim time next is 190800.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 19.70806858480366, -0.8846839716694005, 0.0, 1.0, 55.0, 57.737232430506175], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.14233904873363823, 0.2051053427768665, 0.0, 1.0, 0.8, 0.5773723243050618], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.93603295], dtype=float32), 0.46327278]. 
=============================================
[2019-04-24 09:38:35,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9027209e-01 1.4017342e-03 4.5090211e-03 1.0553141e-06 5.6885635e-11
 2.6017469e-08 2.6826896e-10 1.4254361e-03 3.0239069e-01 1.5166089e-10
 3.3627403e-11], sum to 1.0000
[2019-04-24 09:38:35,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0308
[2019-04-24 09:38:36,030] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 88.0, 0.0, 0.0, 22.5, 21.79088089184303, -0.6413932166973785, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 498000.0000, 
sim time next is 499200.0000, 
raw observation next is [0.9000000000000001, 92.0, 0.0, 0.0, 22.5, 21.2657485070474, -0.7425716105913168, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.48753462603878117, 0.92, 0.0, 0.0, 0.375, 0.2721457089206168, 0.2524761298028944, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9137138], dtype=float32), 1.216151]. 
=============================================
[2019-04-24 09:38:38,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2950438e-01 3.9228979e-03 5.3704176e-03 3.7983193e-06 5.1936178e-10
 3.3461779e-07 4.2880832e-09 1.5322244e-03 3.5966593e-01 1.0111150e-09
 2.8480995e-10], sum to 1.0000
[2019-04-24 09:38:38,104] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9474
[2019-04-24 09:38:38,366] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 25.0, 125.5, 0.0, 22.5, 21.17093641662386, -0.8240382184610269, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 475200.0000, 
sim time next is 476400.0000, 
raw observation next is [-1.533333333333333, 26.0, 127.8333333333333, 0.0, 22.5, 21.85300394803022, -0.4713517863598253, 1.0, 1.0, 55.0, 106.09577391263807], 
processed observation next is [1.0, 0.5217391304347826, 0.42012927054478305, 0.26, 0.426111111111111, 0.0, 0.375, 0.3210836623358517, 0.34288273788005824, 1.0, 1.0, 0.8, 1.0609577391263807], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.5834756], dtype=float32), 0.14068522]. 
=============================================
[2019-04-24 09:38:48,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7326853e-01 1.7550942e-03 1.3712492e-03 2.7729303e-07 1.0156173e-11
 1.6261117e-08 1.2726364e-10 1.0897482e-03 4.2251509e-01 1.3708971e-11
 2.3783800e-12], sum to 1.0000
[2019-04-24 09:38:48,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2731
[2019-04-24 09:38:48,171] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1333333333333333, 52.33333333333333, 124.0, 503.0, 22.5, 22.9341438534989, -0.1934633353716489, 1.0, 1.0, 55.0, 77.69053919434677], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 736800.0000, 
sim time next is 738000.0000, 
raw observation next is [0.5, 50.0, 110.0, 611.0, 22.5, 23.51282018112968, -0.3097735399318545, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.5, 0.36666666666666664, 0.6751381215469613, 0.375, 0.45940168176080665, 0.39674215335604845, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42149898], dtype=float32), -2.6307783]. 
=============================================
[2019-04-24 09:38:51,364] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.99783087e-01 1.93073531e-03 3.95131856e-03 2.13927919e-07
 1.50325349e-10 3.54241472e-08 1.37221046e-09 1.47874828e-03
 2.92855859e-01 1.01410706e-10 2.02734374e-11], sum to 1.0000
[2019-04-24 09:38:51,365] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7736
[2019-04-24 09:38:51,536] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.066666666666666, 72.33333333333333, 90.83333333333333, 0.0, 22.5, 21.92619490545815, -0.6472931108809178, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 816000.0000, 
sim time next is 817200.0000, 
raw observation next is [-4.5, 71.0, 98.5, 0.0, 22.5, 22.47888426805864, -0.4400005370075462, 1.0, 1.0, 55.0, 98.14918773475505], 
processed observation next is [1.0, 0.4782608695652174, 0.3379501385041552, 0.71, 0.3283333333333333, 0.0, 0.375, 0.3732403556715533, 0.35333315433081797, 1.0, 1.0, 0.8, 0.9814918773475505], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4355887], dtype=float32), -0.07719306]. 
=============================================
[2019-04-24 09:38:53,218] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8231497e-01 7.8743976e-03 8.1098005e-03 2.6250353e-07 5.4862417e-11
 1.3629736e-08 5.7759147e-10 1.8344534e-03 4.9986604e-01 2.6912176e-11
 2.1635846e-11], sum to 1.0000
[2019-04-24 09:38:53,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4420
[2019-04-24 09:38:53,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 81.33333333333334, 44.83333333333333, 0.0, 22.5, 23.15436649538298, -0.3770593119738164, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 897600.0000, 
sim time next is 898800.0000, 
raw observation next is [1.1, 82.66666666666667, 52.83333333333333, 0.0, 22.5, 22.7823169454022, -0.4440216567425051, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8266666666666667, 0.1761111111111111, 0.0, 0.375, 0.3985264121168501, 0.35199278108583165, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19371526], dtype=float32), 0.6765564]. 
=============================================
[2019-04-24 09:38:53,838] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.2061963e-01 1.9998276e-03 6.6619767e-03 2.8124637e-07 4.6072760e-11
 9.1568371e-09 1.1037392e-09 2.9367807e-03 4.6778145e-01 7.6474015e-11
 3.7798001e-11], sum to 1.0000
[2019-04-24 09:38:53,839] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3902
[2019-04-24 09:38:53,968] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 72.0, 0.0, 0.0, 19.0, 21.91741038017675, -0.6218421004573945, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 884400.0000, 
sim time next is 885600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 21.01827502303083, -0.756193888206442, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.25152291858590264, 0.24793537059785267, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13784328], dtype=float32), 1.5064416]. 
=============================================
[2019-04-24 09:38:55,274] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1812161e-01 2.1871710e-04 2.2455114e-03 4.0007031e-08 4.4550522e-12
 1.9581230e-09 1.9919230e-10 3.8925727e-04 5.7902479e-01 7.4179846e-12
 3.9022986e-12], sum to 1.0000
[2019-04-24 09:38:55,276] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8673
[2019-04-24 09:38:55,408] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.633333333333333, 79.33333333333334, 0.0, 0.0, 19.0, 22.49350813272133, -0.4089365529491529, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 861600.0000, 
sim time next is 862800.0000, 
raw observation next is [-2.466666666666667, 79.66666666666666, 0.0, 0.0, 19.0, 22.21042245526053, -0.3031517916496632, 0.0, 1.0, 55.0, 66.16210656537736], 
processed observation next is [1.0, 1.0, 0.39427516158818104, 0.7966666666666665, 0.0, 0.0, 0.08333333333333333, 0.3508685379383776, 0.39894940278344554, 0.0, 1.0, 0.8, 0.6616210656537735], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3384364], dtype=float32), -1.634041]. 
=============================================
[2019-04-24 09:38:55,689] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.9956237e-01 8.0022379e-05 6.1896211e-04 6.5780990e-09 4.6659578e-13
 3.0929864e-10 5.2776138e-12 3.4645727e-04 2.9939219e-01 4.7012356e-13
 8.7566971e-14], sum to 1.0000
[2019-04-24 09:38:55,723] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2553
[2019-04-24 09:38:55,746] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.600000000000001, 92.66666666666667, 24.0, 0.0, 22.5, 24.77213150767027, -0.0798599027433229, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 922800.0000, 
sim time next is 924000.0000, 
raw observation next is [4.8, 92.33333333333333, 15.0, 0.0, 22.5, 23.95210247871698, -0.08685269062274333, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5955678670360112, 0.9233333333333333, 0.05, 0.0, 0.375, 0.49600853989308175, 0.4710491031257522, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.552029], dtype=float32), -2.035366]. 
=============================================
[2019-04-24 09:38:56,898] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.3574066e-01 5.2172918e-04 1.4319926e-03 3.7472752e-08 1.3525705e-12
 5.8461508e-10 4.4502811e-11 3.3868378e-04 2.6196688e-01 2.1714880e-12
 1.5663361e-12], sum to 1.0000
[2019-04-24 09:38:56,898] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7147
[2019-04-24 09:38:57,005] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.8, 93.0, 100.0, 0.0, 22.5, 23.12608769603566, -0.3444427224756224, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 910800.0000, 
sim time next is 912000.0000, 
raw observation next is [3.8, 93.0, 97.33333333333333, 0.0, 22.5, 22.26459990419739, -0.3701370081068121, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5678670360110805, 0.93, 0.3244444444444444, 0.0, 0.375, 0.35538332534978245, 0.3766209972977293, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47288615], dtype=float32), -0.4510465]. 
=============================================
[2019-04-24 09:38:59,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4758329e-01 7.2318369e-05 8.1254193e-04 1.9964834e-09 1.0723177e-13
 1.5587104e-10 3.2815767e-13 2.1353176e-04 1.5131833e-01 1.3882619e-13
 6.3122259e-15], sum to 1.0000
[2019-04-24 09:38:59,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3336
[2019-04-24 09:38:59,933] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.83333333333333, 82.66666666666667, 114.8333333333333, 0.0, 22.5, 24.87842794912419, 0.4605687713233611, 1.0, 1.0, 55.0, 66.08864147334793], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 999600.0000, 
sim time next is 1000800.0000, 
raw observation next is [14.4, 81.0, 106.5, 0.0, 22.5, 25.19608040683756, 0.3292977912534177, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.8614958448753465, 0.81, 0.355, 0.0, 0.375, 0.5996733672364633, 0.6097659304178059, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6335937], dtype=float32), 1.1887889]. 
=============================================
[2019-04-24 09:39:01,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9113456e-01 8.9896307e-04 1.7994279e-03 1.5423957e-07 6.4110807e-11
 1.9243746e-08 1.4843762e-10 3.1833886e-04 1.0584842e-01 2.6185810e-11
 2.5228788e-12], sum to 1.0000
[2019-04-24 09:39:01,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3752
[2019-04-24 09:39:01,147] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 60.0, 0.0, 0.0, 22.5, 24.94649364898702, 0.4537897725756144, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1108800.0000, 
sim time next is 1110000.0000, 
raw observation next is [13.63333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 24.77278402481858, 0.423122013940084, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.840258541089566, 0.6066666666666667, 0.0, 0.0, 0.08333333333333333, 0.5643986687348818, 0.6410406713133613, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3700004], dtype=float32), 0.78141147]. 
=============================================
[2019-04-24 09:39:01,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.465187]
 [57.885647]
 [56.61921 ]
 [55.96871 ]
 [56.260868]
 [56.385548]
 [56.745316]
 [57.19056 ]
 [57.57576 ]
 [56.854427]
 [57.585304]
 [57.75748 ]
 [57.894577]
 [58.07199 ]
 [58.347923]
 [58.732876]
 [58.943146]
 [60.74192 ]
 [62.67098 ]
 [64.58956 ]
 [65.23243 ]
 [67.48388 ]
 [69.172615]
 [70.90931 ]
 [72.66924 ]], R is [[60.0053215 ]
 [60.40526962]
 [60.80121613]
 [61.19320297]
 [61.58127213]
 [61.96546173]
 [62.34580612]
 [62.72234726]
 [63.09512329]
 [62.46417236]
 [62.83953094]
 [63.21113586]
 [63.57902527]
 [63.9432373 ]
 [64.30380249]
 [64.6607666 ]
 [65.01416016]
 [65.3640213 ]
 [65.71038055]
 [66.05327606]
 [65.39274597]
 [65.73882294]
 [66.08143616]
 [66.42062378]
 [66.75641632]].
[2019-04-24 09:39:01,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9943694e-01 2.4080930e-04 2.5330153e-03 8.6118437e-09 2.7782179e-13
 1.6653277e-10 7.5903962e-12 3.9888534e-04 3.9739034e-01 1.1704055e-12
 5.5999832e-14], sum to 1.0000
[2019-04-24 09:39:01,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4313
[2019-04-24 09:39:01,313] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 19.0, 24.79548571256692, 0.2865794877426631, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1029600.0000, 
sim time next is 1030800.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 19.0, 24.49444389561408, 0.201088345013616, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.8614958448753465, 0.75, 0.0, 0.0, 0.08333333333333333, 0.54120365796784, 0.567029448337872, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09506555], dtype=float32), 0.9285091]. 
=============================================
[2019-04-24 09:39:01,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7478814e-01 3.5198552e-03 2.7089741e-03 1.2754251e-08 1.5954387e-12
 2.1192352e-09 1.7490289e-11 3.3260180e-04 2.1865034e-01 1.6435862e-12
 1.4716097e-13], sum to 1.0000
[2019-04-24 09:39:01,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7793
[2019-04-24 09:39:01,476] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [11.8, 69.33333333333333, 0.0, 0.0, 19.0, 24.09011809590285, 0.451803449221604, 0.0, 1.0, 55.0, 74.97078854943442], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1122000.0000, 
sim time next is 1123200.0000, 
raw observation next is [11.6, 71.0, 0.0, 0.0, 19.0, 25.03185927147735, 0.52324016291017, 0.0, 1.0, 25.0, 37.831128678913274], 
processed observation next is [0.0, 0.0, 0.7839335180055402, 0.71, 0.0, 0.0, 0.08333333333333333, 0.5859882726231126, 0.6744133876367234, 0.0, 1.0, 0.2, 0.37831128678913273], 
reward next is 0.4217, 
noisyNet noise sample is [array([-1.3319523], dtype=float32), -1.2260091]. 
=============================================
[2019-04-24 09:39:09,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4961562e-01 2.7683703e-04 2.6864382e-03 1.6820046e-08 4.0599694e-12
 1.7550489e-09 1.6117642e-10 5.1566918e-04 4.4690552e-01 1.3548250e-11
 3.9095596e-13], sum to 1.0000
[2019-04-24 09:39:09,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2523
[2019-04-24 09:39:09,250] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.5, 100.0, 0.0, 0.0, 19.0, 24.66961430728481, 0.5656224486606872, 0.0, 1.0, 55.0, 69.00801953132991], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1287600.0000, 
sim time next is 1288800.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 19.0, 25.0301447153725, 0.4646495915408679, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.6149584487534627, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5858453929477084, 0.6548831971802893, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2700806], dtype=float32), 0.21803905]. 
=============================================
[2019-04-24 09:39:11,785] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.0256356e-01 4.1264028e-04 1.2825690e-03 1.0590335e-08 4.3845735e-13
 5.9003341e-10 3.9583867e-11 1.3662528e-03 3.9437494e-01 1.0372413e-12
 1.9273558e-13], sum to 1.0000
[2019-04-24 09:39:11,805] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5984
[2019-04-24 09:39:12,027] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 92.0, 0.0, 0.0, 19.0, 24.54887293588072, 0.3209304148823162, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1310400.0000, 
sim time next is 1311600.0000, 
raw observation next is [2.0, 92.0, 0.0, 0.0, 19.0, 24.21475324061781, 0.2671957062939961, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.518005540166205, 0.92, 0.0, 0.0, 0.08333333333333333, 0.5178961033848175, 0.589065235431332, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6264903], dtype=float32), 0.3987849]. 
=============================================
[2019-04-24 09:39:12,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0564893e-01 3.6946654e-03 6.5488541e-03 9.5214212e-08 3.9660025e-11
 4.9962430e-09 2.2713897e-10 3.4190083e-03 3.8068843e-01 1.2991032e-10
 3.1642941e-12], sum to 1.0000
[2019-04-24 09:39:12,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0811
[2019-04-24 09:39:12,609] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 96.66666666666667, 0.0, 0.0, 19.0, 21.48697843548527, -0.2111799662273423, 0.0, 1.0, 55.0, 85.85091552811261], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1394400.0000, 
sim time next is 1395600.0000, 
raw observation next is [-0.4, 98.33333333333333, 0.0, 0.0, 19.0, 22.39860900078482, -0.2935521929933214, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.45152354570637127, 0.9833333333333333, 0.0, 0.0, 0.08333333333333333, 0.36655075006540166, 0.4021492690022262, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2571677], dtype=float32), -1.3719572]. 
=============================================
[2019-04-24 09:39:12,897] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8037117e-01 1.2405736e-04 1.4405447e-04 1.1196216e-08 1.1273116e-13
 1.3850596e-10 2.7301115e-12 8.6082866e-05 3.1927457e-01 1.5365381e-13
 2.9584842e-14], sum to 1.0000
[2019-04-24 09:39:12,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5603
[2019-04-24 09:39:13,103] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 93.0, 95.0, 0.0, 22.5, 24.42026982992504, 0.3086967766430231, 1.0, 1.0, 55.0, 59.788024419765485], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1428000.0000, 
sim time next is 1429200.0000, 
raw observation next is [0.5, 92.0, 93.0, 0.0, 22.5, 24.95605847297922, 0.268418071652371, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.92, 0.31, 0.0, 0.375, 0.5796715394149349, 0.5894726905507903, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8844013], dtype=float32), -0.97875863]. 
=============================================
[2019-04-24 09:39:18,950] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.6243867e-01 2.0154335e-03 2.6306445e-03 2.1381265e-08 1.6134745e-12
 1.6841855e-09 1.7814195e-11 1.1110497e-03 4.3180418e-01 2.8821342e-12
 2.3791760e-13], sum to 1.0000
[2019-04-24 09:39:18,962] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5918
[2019-04-24 09:39:19,216] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.833333333333334, 97.33333333333333, 0.0, 0.0, 19.0, 23.32504404555892, -0.04843415241066257, 0.0, 1.0, 55.0, 46.964625348950094], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1491600.0000, 
sim time next is 1492800.0000, 
raw observation next is [1.466666666666667, 98.66666666666666, 0.0, 0.0, 19.0, 23.5322072248085, -0.01188069056760354, 0.0, 1.0, 55.0, 46.24271303820895], 
processed observation next is [1.0, 0.2608695652173913, 0.5032317636195753, 0.9866666666666666, 0.0, 0.0, 0.08333333333333333, 0.46101726873404153, 0.49603976981079884, 0.0, 1.0, 0.8, 0.4624271303820895], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32393432], dtype=float32), -0.1318309]. 
=============================================
[2019-04-24 09:39:24,130] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.8537649e-01 2.3133743e-04 4.8064391e-04 4.7324948e-09 2.2191460e-13
 1.1633633e-09 8.4011799e-12 9.1726467e-04 2.1299420e-01 2.6701514e-13
 2.3404710e-14], sum to 1.0000
[2019-04-24 09:39:24,139] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5607
[2019-04-24 09:39:24,150] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 79.0, 0.0, 0.0, 19.0, 25.05905501318954, 0.5075889244083746, 0.0, 1.0, 55.0, 65.47370276485177], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1562400.0000, 
sim time next is 1563600.0000, 
raw observation next is [4.800000000000001, 81.33333333333334, 0.0, 0.0, 19.0, 25.40868408341097, 0.4110351219190783, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5955678670360112, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.6173903402842477, 0.6370117073063595, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07942148], dtype=float32), -0.47306025]. 
=============================================
[2019-04-24 09:39:28,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3869157e-01 5.2256254e-04 5.5112346e-04 1.0720747e-08 8.3740621e-13
 1.5289416e-09 1.2019206e-11 1.9829171e-03 2.5825182e-01 2.2268945e-12
 3.1776171e-13], sum to 1.0000
[2019-04-24 09:39:28,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7407
[2019-04-24 09:39:28,495] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 19.0, 23.68233679998172, 0.2843082601052559, 0.0, 1.0, 55.0, 76.52370092132946], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1657200.0000, 
sim time next is 1658400.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 19.0, 24.64287141654523, 0.3430624347236164, 0.0, 1.0, 50.0, 37.54246773616842], 
processed observation next is [1.0, 0.17391304347826086, 0.6454293628808865, 0.97, 0.0, 0.0, 0.08333333333333333, 0.5535726180454358, 0.6143541449078721, 0.0, 1.0, 0.7, 0.37542467736168417], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4102258], dtype=float32), -1.4637792]. 
=============================================
[2019-04-24 09:39:31,864] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.65459788e-01 1.17450650e-03 1.11433165e-02 4.64364120e-07
 3.34611672e-10 6.50829222e-08 6.56297594e-09 1.26110623e-03
 4.20960873e-01 3.47984891e-10 1.13152716e-10], sum to 1.0000
[2019-04-24 09:39:31,865] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7533
[2019-04-24 09:39:31,910] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 83.0, 109.0, 0.0, 19.0, 20.91133845609994, -0.6293729287609803, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1778400.0000, 
sim time next is 1779600.0000, 
raw observation next is [-2.8, 84.33333333333334, 102.3333333333333, 0.0, 19.0, 21.01583143689467, -0.4130278140625347, 0.0, 1.0, 55.0, 83.86229227394892], 
processed observation next is [0.0, 0.6086956521739131, 0.38504155124653744, 0.8433333333333334, 0.341111111111111, 0.0, 0.08333333333333333, 0.25131928640788903, 0.36232406197915507, 0.0, 1.0, 0.8, 0.8386229227394892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1968883], dtype=float32), 0.22608948]. 
=============================================
[2019-04-24 09:39:32,224] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.61743104e-01 6.11399999e-04 2.31528305e-03 7.75775618e-07
 1.89477461e-10 4.83785385e-08 2.87081869e-09 2.58373003e-03
 3.32745641e-01 1.29600414e-10 1.35261845e-11], sum to 1.0000
[2019-04-24 09:39:32,226] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0166
[2019-04-24 09:39:32,381] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1333333333333334, 91.0, 0.0, 0.0, 19.0, 22.27762329851221, -0.1323523556232265, 0.0, 1.0, 55.0, 73.87087329609747], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1736400.0000, 
sim time next is 1737600.0000, 
raw observation next is [0.06666666666666668, 91.0, 0.0, 0.0, 19.0, 22.62916529269003, -0.2587363292506754, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.46445060018467227, 0.91, 0.0, 0.0, 0.08333333333333333, 0.38576377439083576, 0.41375455691644153, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9506826], dtype=float32), 0.08120762]. 
=============================================
[2019-04-24 09:39:44,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.4914109e-01 1.6107024e-03 4.7924942e-03 5.1167410e-07 6.7190586e-11
 2.3055030e-08 9.8808373e-10 5.7234173e-04 5.4388279e-01 3.8923809e-11
 1.7674385e-11], sum to 1.0000
[2019-04-24 09:39:44,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5341
[2019-04-24 09:39:44,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.8, 83.0, 0.0, 0.0, 19.0, 20.71008969304694, -0.6350740495269948, 0.0, 1.0, 55.0, 79.03382815863944], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1982400.0000, 
sim time next is 1983600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 21.16270217014963, -0.5886170947898753, 0.0, 1.0, 55.0, 55.70910792669869], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.26355851417913573, 0.30379430173670824, 0.0, 1.0, 0.8, 0.557091079266987], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14300472], dtype=float32), -0.8780341]. 
=============================================
[2019-04-24 09:39:52,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6238457e-01 1.1237889e-03 2.1061820e-03 7.9404650e-08 3.1881314e-12
 5.1924647e-09 4.5754390e-11 6.3353445e-04 3.3375180e-01 5.6640448e-12
 1.9418677e-12], sum to 1.0000
[2019-04-24 09:39:52,084] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0805
[2019-04-24 09:39:52,158] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 79.0, 152.0, 0.0, 22.5, 24.02965629544501, -0.02138599690327543, 1.0, 1.0, 55.0, 63.60638767111411], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2034000.0000, 
sim time next is 2035200.0000, 
raw observation next is [-4.300000000000001, 79.0, 149.3333333333333, 0.0, 22.5, 23.96571931544575, -0.1815086822542729, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.34349030470914127, 0.79, 0.4977777777777776, 0.0, 0.375, 0.4971432762871458, 0.4394971059152424, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1434159], dtype=float32), -0.1206402]. 
=============================================
[2019-04-24 09:39:53,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8922920e-01 3.9155995e-03 1.0668224e-02 5.7038818e-07 9.5136655e-11
 2.6339643e-08 8.7677190e-09 2.2239343e-03 4.9396241e-01 2.4297425e-10
 9.0911716e-11], sum to 1.0000
[2019-04-24 09:39:53,873] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1396
[2019-04-24 09:39:53,904] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 0.0, 0.0, 19.0, 20.79485024646907, -0.6975112150472021, 0.0, 1.0, 55.0, 50.85540707271764], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2185200.0000, 
sim time next is 2186400.0000, 
raw observation next is [-5.6, 75.0, 0.0, 0.0, 22.5, 20.74566939148877, -0.8596448829122804, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.30747922437673136, 0.75, 0.0, 0.0, 0.375, 0.22880578262406429, 0.21345170569590655, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57110476], dtype=float32), -1.1120851]. 
=============================================
[2019-04-24 09:39:58,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4814419e-01 7.6878566e-04 4.5793764e-03 1.9467515e-07 1.8113255e-10
 3.5349128e-08 1.9118216e-09 1.5181813e-03 3.4498921e-01 4.6555282e-10
 3.5942468e-11], sum to 1.0000
[2019-04-24 09:39:58,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5704
[2019-04-24 09:39:58,517] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.333333333333334, 83.0, 0.0, 0.0, 19.0, 21.21178197749738, -0.6153133089631074, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2151600.0000, 
sim time next is 2152800.0000, 
raw observation next is [-6.7, 83.0, 0.0, 0.0, 19.0, 20.59485131647547, -0.7062783371789237, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2770083102493075, 0.83, 0.0, 0.0, 0.08333333333333333, 0.21623760970628916, 0.26457388760702544, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5282723], dtype=float32), 0.7638555]. 
=============================================
[2019-04-24 09:40:02,177] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.5449785e-01 6.5765076e-04 1.7444202e-03 1.4360405e-07 1.4976353e-11
 1.2253031e-08 1.4198956e-10 4.1792839e-04 1.4268208e-01 4.1151346e-11
 9.9970119e-12], sum to 1.0000
[2019-04-24 09:40:02,178] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3984
[2019-04-24 09:40:02,265] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 22.5, 21.71938233428506, -0.5175530712255638, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2224800.0000, 
sim time next is 2226000.0000, 
raw observation next is [-4.533333333333333, 68.66666666666667, 0.0, 0.0, 22.5, 21.54981763628635, -0.562418478497793, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3370267774699908, 0.6866666666666668, 0.0, 0.0, 0.375, 0.2958181363571957, 0.31252717383406897, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9026, 
noisyNet noise sample is [array([-1.0815558], dtype=float32), 0.17953606]. 
=============================================
[2019-04-24 09:40:07,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3851869e-01 8.1032194e-04 1.3037065e-02 8.5888234e-07 3.0228517e-09
 3.0122933e-07 2.3367356e-08 3.7806833e-03 3.4385207e-01 3.2333063e-09
 1.9473742e-10], sum to 1.0000
[2019-04-24 09:40:07,360] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1958
[2019-04-24 09:40:07,428] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 51.66666666666667, 241.8333333333333, 353.3333333333334, 19.0, 21.77165111465407, -0.3709546201685789, 0.0, 1.0, 55.0, 48.76791093222753], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2378400.0000, 
sim time next is 2379600.0000, 
raw observation next is [-0.6, 54.0, 221.5, 212.0, 19.0, 22.04731271222411, -0.4778011395223838, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.44598337950138506, 0.54, 0.7383333333333333, 0.23425414364640884, 0.08333333333333333, 0.33727605935200905, 0.34073295349253874, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4357669], dtype=float32), -0.7337669]. 
=============================================
[2019-04-24 09:40:14,980] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.7992744e-01 1.2495172e-02 3.0470178e-02 6.0346542e-06 3.2638013e-08
 1.4068956e-06 2.8546478e-07 6.7611611e-03 3.7033820e-01 5.9981510e-08
 7.7180236e-09], sum to 1.0000
[2019-04-24 09:40:14,981] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3150
[2019-04-24 09:40:15,110] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.933333333333333, 27.0, 75.33333333333333, 766.6666666666667, 19.0, 21.59948484528172, -0.5944766499794621, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2472000.0000, 
sim time next is 2473200.0000, 
raw observation next is [3.3, 27.0, 70.0, 732.0, 19.0, 21.18284524221813, -0.6837319574558315, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.554016620498615, 0.27, 0.23333333333333334, 0.8088397790055248, 0.08333333333333333, 0.26523710351817736, 0.27208934751472286, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10315021], dtype=float32), -0.16485523]. 
=============================================
[2019-04-24 09:40:16,860] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0165440e-01 2.2886486e-03 2.5367506e-03 5.0537960e-07 3.0975892e-11
 2.8442258e-08 2.2207687e-10 6.2894612e-04 1.9289070e-01 4.0729004e-11
 2.8706872e-11], sum to 1.0000
[2019-04-24 09:40:16,899] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7833
[2019-04-24 09:40:16,964] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.466666666666667, 36.0, 220.3333333333333, 30.16666666666666, 22.5, 23.4463096504435, -0.2489147212440372, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2550000.0000, 
sim time next is 2551200.0000, 
raw observation next is [1.833333333333333, 33.0, 210.1666666666667, 98.66666666666666, 22.5, 23.31135639209756, -0.2631109832594534, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5133887349953832, 0.33, 0.7005555555555557, 0.10902394106813995, 0.375, 0.4426130326747968, 0.4122963389135155, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.48896366], dtype=float32), -0.90547943]. 
=============================================
[2019-04-24 09:40:20,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0654334e-01 3.4053016e-03 3.7477612e-03 5.8752590e-07 7.3157869e-10
 4.0166768e-08 3.7562335e-09 3.5787472e-03 4.8272422e-01 5.7534205e-10
 1.5702417e-10], sum to 1.0000
[2019-04-24 09:40:20,542] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6074
[2019-04-24 09:40:20,696] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 19.0, 19.43227131223474, -0.8386356785970795, 0.0, 1.0, 55.0, 89.6486736288519], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2617200.0000, 
sim time next is 2618400.0000, 
raw observation next is [-7.300000000000001, 79.0, 0.0, 0.0, 22.5, 20.47814548733215, -0.6851779310566356, 1.0, 1.0, 55.0, 73.78441144967869], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.79, 0.0, 0.0, 0.375, 0.2065121239443458, 0.2716073563144548, 1.0, 1.0, 0.8, 0.7378441144967869], 
reward next is 0.9259, 
noisyNet noise sample is [array([1.2853788], dtype=float32), -1.8648623]. 
=============================================
[2019-04-24 09:40:20,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4309249e-01 3.9430754e-03 8.3674118e-03 9.1239633e-07 2.1573804e-10
 4.2139636e-08 1.2602109e-08 2.2185787e-03 4.4237739e-01 5.8199634e-10
 4.3517134e-11], sum to 1.0000
[2019-04-24 09:40:20,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7949
[2019-04-24 09:40:21,678] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.833333333333333, 66.0, 0.0, 0.0, 19.0, 21.03758709523856, -0.4642046601232476, 0.0, 1.0, 55.0, 83.45948907213858], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2594400.0000, 
sim time next is 2595600.0000, 
raw observation next is [-5.0, 68.0, 0.0, 0.0, 19.0, 21.82221699722143, -0.3712739529542702, 0.0, 1.0, 55.0, 53.71791929685719], 
processed observation next is [1.0, 0.043478260869565216, 0.32409972299168976, 0.68, 0.0, 0.0, 0.08333333333333333, 0.318518083101786, 0.37624201568190996, 0.0, 1.0, 0.8, 0.5371791929685719], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06376311], dtype=float32), -0.10923038]. 
=============================================
[2019-04-24 09:40:28,298] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.7039070e-01 5.1037194e-03 6.6023734e-03 1.6111252e-07 2.9811945e-10
 4.2028475e-08 4.1703769e-09 3.0065300e-03 4.1489646e-01 2.8450120e-10
 2.5729309e-11], sum to 1.0000
[2019-04-24 09:40:28,303] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6411
[2019-04-24 09:40:28,393] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 19.0, 22.30311817389314, -0.4808616038995054, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2595600.0000, 
sim time next is 2596800.0000, 
raw observation next is [-5.0, 70.0, 0.0, 0.0, 19.0, 22.0651809579693, -0.3534563274085964, 0.0, 1.0, 55.0, 70.95632341763168], 
processed observation next is [1.0, 0.043478260869565216, 0.32409972299168976, 0.7, 0.0, 0.0, 0.08333333333333333, 0.33876507983077503, 0.3821812241971345, 0.0, 1.0, 0.8, 0.7095632341763168], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7847749], dtype=float32), 0.45874313]. 
=============================================
[2019-04-24 09:40:37,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3602012e-01 4.4608735e-03 1.6630521e-03 2.1891063e-07 1.0791622e-10
 4.3739597e-08 1.4692731e-09 2.5204958e-03 3.5533521e-01 1.1443075e-10
 3.5840390e-11], sum to 1.0000
[2019-04-24 09:40:37,761] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1387
[2019-04-24 09:40:37,922] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.66666666666667, 81.0, 100.3333333333333, 622.3333333333333, 22.5, 21.70479080189103, -0.3915882214559105, 1.0, 1.0, 55.0, 100.1159248433529], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2713200.0000, 
sim time next is 2714400.0000, 
raw observation next is [-12.0, 76.0, 107.0, 643.0, 22.5, 22.81883783390441, -0.3996397152066133, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.13019390581717452, 0.76, 0.3566666666666667, 0.7104972375690608, 0.375, 0.40156981949203424, 0.36678676159779555, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4894783], dtype=float32), -0.53951764]. 
=============================================
[2019-04-24 09:40:45,738] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 38200: loss 25.7521
[2019-04-24 09:40:45,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 38202: learning rate 0.0000
[2019-04-24 09:40:49,600] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 38809: loss 66.5538
[2019-04-24 09:40:49,601] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 38809: learning rate 0.0000
[2019-04-24 09:40:51,113] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39034: loss -5.3939
[2019-04-24 09:40:51,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39034: learning rate 0.0000
[2019-04-24 09:40:55,108] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39694: loss 17.8020
[2019-04-24 09:40:55,179] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39703: loss -10.0427
[2019-04-24 09:40:55,188] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39703: loss -4.9953
[2019-04-24 09:40:55,189] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39703: learning rate 0.0000
[2019-04-24 09:40:55,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39703: learning rate 0.0000
[2019-04-24 09:40:55,250] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39702: learning rate 0.0000
[2019-04-24 09:40:55,331] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39728: loss 1.1062
[2019-04-24 09:40:55,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39728: learning rate 0.0000
[2019-04-24 09:40:56,460] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39937: loss 17.1507
[2019-04-24 09:40:56,463] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39939: learning rate 0.0000
[2019-04-24 09:40:56,885] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 40020: loss -3.8204
[2019-04-24 09:40:56,886] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 40020: learning rate 0.0000
[2019-04-24 09:40:57,235] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 40076: loss -3.5813
[2019-04-24 09:40:57,257] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 2500, global step 40080: learning rate 0.0000
[2019-04-24 09:40:57,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6373159e-01 3.9610891e-03 3.1962588e-02 2.6883179e-06 6.0919274e-09
 3.0513789e-07 4.4846399e-08 2.6937190e-03 4.9764803e-01 1.6437477e-08
 1.0173683e-09], sum to 1.0000
[2019-04-24 09:40:57,451] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0556
[2019-04-24 09:40:57,530] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666667, 50.66666666666667, 61.5, 517.1666666666666, 19.0, 22.70336821463571, -0.2939466289979379, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3082800.0000, 
sim time next is 3084000.0000, 
raw observation next is [0.3333333333333334, 61.33333333333334, 48.66666666666666, 419.6666666666667, 19.0, 22.35322398758442, -0.3896470224531219, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.4718374884579871, 0.6133333333333334, 0.16222222222222218, 0.4637200736648251, 0.08333333333333333, 0.3627686656320351, 0.3701176591822927, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42376384], dtype=float32), 2.0115747]. 
=============================================
[2019-04-24 09:40:58,480] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 40293: loss 10.0426
[2019-04-24 09:40:58,522] A3C_AGENT_WORKER-Thread-8 DEBUG:Local step 2500, global step 40293: learning rate 0.0000
[2019-04-24 09:40:59,445] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40419: loss 41.3137
[2019-04-24 09:40:59,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40423: learning rate 0.0000
[2019-04-24 09:41:00,691] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.05778372e-01 1.83127413e-03 1.36681525e-02 9.06650143e-07
 3.86165411e-09 1.78208836e-07 5.58956970e-08 2.47709360e-03
 4.76244003e-01 2.58869814e-09 2.70521133e-10], sum to 1.0000
[2019-04-24 09:41:00,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5607
[2019-04-24 09:41:00,807] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.666666666666667, 58.33333333333334, 86.0, 681.0, 19.0, 22.34629942421621, -0.380559167058889, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2992800.0000, 
sim time next is 2994000.0000, 
raw observation next is [-1.333333333333333, 56.66666666666667, 78.5, 634.8333333333334, 19.0, 22.09556308696823, -0.2710508754044909, 0.0, 1.0, 55.0, 62.75505181473669], 
processed observation next is [0.0, 0.6521739130434783, 0.42566943674976926, 0.5666666666666668, 0.26166666666666666, 0.7014732965009208, 0.08333333333333333, 0.34129692391401917, 0.40964970819850305, 0.0, 1.0, 0.8, 0.6275505181473668], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06774308], dtype=float32), 0.38902026]. 
=============================================
[2019-04-24 09:41:01,639] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40762: loss -7.8972
[2019-04-24 09:41:01,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40772: learning rate 0.0000
[2019-04-24 09:41:03,012] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40965: loss -9.9241
[2019-04-24 09:41:03,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40965: learning rate 0.0000
[2019-04-24 09:41:04,471] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 41216: loss -16.0023
[2019-04-24 09:41:04,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 41216: learning rate 0.0000
[2019-04-24 09:41:05,270] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 41346: loss 1.8588
[2019-04-24 09:41:05,351] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 41359: learning rate 0.0000
[2019-04-24 09:41:05,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6002381e-01 4.5720491e-04 9.4170100e-04 2.6186923e-08 1.7987660e-12
 9.6377795e-10 1.1523597e-11 1.0074738e-03 3.3756980e-01 1.4148464e-12
 2.7432706e-13], sum to 1.0000
[2019-04-24 09:41:05,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9247
[2019-04-24 09:41:05,470] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 75.66666666666667, 114.6666666666667, 821.0, 22.5, 24.90706075253249, 0.2901981284692734, 1.0, 1.0, 55.0, 72.85948186251329], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3241200.0000, 
sim time next is 3242400.0000, 
raw observation next is [-2.0, 80.33333333333333, 114.3333333333333, 821.1666666666667, 22.5, 25.21657120870336, 0.4923128851351584, 1.0, 1.0, 55.0, 46.57058559859536], 
processed observation next is [1.0, 0.5217391304347826, 0.40720221606648205, 0.8033333333333332, 0.381111111111111, 0.9073664825046042, 0.375, 0.6013809340586134, 0.6641042950450528, 1.0, 1.0, 0.8, 0.4657058559859536], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0245028], dtype=float32), 0.041456405]. 
=============================================
[2019-04-24 09:41:09,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1937726e-01 1.8835907e-03 9.0750810e-03 8.8868553e-08 2.1534562e-11
 1.1199396e-08 5.1836219e-10 2.4556792e-03 3.6720833e-01 3.5640733e-11
 3.7157729e-12], sum to 1.0000
[2019-04-24 09:41:09,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6895
[2019-04-24 09:41:10,065] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.666666666666667, 100.0, 0.0, 0.0, 19.0, 21.01832768850571, -0.7639656544099735, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3133200.0000, 
sim time next is 3134400.0000, 
raw observation next is [5.333333333333334, 100.0, 0.0, 0.0, 19.0, 21.00934621170595, -0.5317260076949378, 0.0, 1.0, 55.0, 89.0773540766247], 
processed observation next is [1.0, 0.2608695652173913, 0.6103416435826409, 1.0, 0.0, 0.0, 0.08333333333333333, 0.2507788509754958, 0.3227579974350207, 0.0, 1.0, 0.8, 0.890773540766247], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.74053544], dtype=float32), -0.28953755]. 
=============================================
[2019-04-24 09:41:12,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0840622e-01 1.6383663e-03 3.4711561e-03 4.2693379e-08 2.8610538e-12
 1.0469005e-09 2.5903216e-10 3.1237875e-03 4.8336050e-01 1.4895796e-11
 1.6788820e-12], sum to 1.0000
[2019-04-24 09:41:12,689] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6562
[2019-04-24 09:41:13,006] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.0, 100.0, 0.0, 0.0, 22.5, 21.15932553011323, -0.6978253089307397, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3136800.0000, 
sim time next is 3138000.0000, 
raw observation next is [6.0, 100.0, 14.66666666666666, 133.6666666666667, 22.5, 21.92154647974994, -0.2829523362699313, 1.0, 1.0, 55.0, 111.67593858442679], 
processed observation next is [1.0, 0.30434782608695654, 0.6288088642659281, 1.0, 0.04888888888888887, 0.1476979742173113, 0.375, 0.32679553997916155, 0.40568255457668956, 1.0, 1.0, 0.8, 1.116759385844268], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37243775], dtype=float32), -0.21837485]. 
=============================================
[2019-04-24 09:41:22,197] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.2751663e-01 2.6313874e-03 2.0075943e-03 5.3083670e-07 3.1816789e-11
 1.2503218e-08 6.0677968e-10 1.7588172e-03 3.6608517e-01 8.4656122e-11
 2.5114244e-11], sum to 1.0000
[2019-04-24 09:41:22,199] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4901
[2019-04-24 09:41:22,330] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.0, 77.0, 95.0, 505.5, 22.5, 22.5807066294026, -0.3114895830433616, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3315600.0000, 
sim time next is 3316800.0000, 
raw observation next is [-8.666666666666668, 74.66666666666667, 101.0, 578.5, 22.5, 22.60558369190588, -0.310061762912435, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.22253000923361033, 0.7466666666666667, 0.33666666666666667, 0.6392265193370166, 0.375, 0.38379864099215677, 0.39664607902918836, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23256768], dtype=float32), -1.2715138]. 
=============================================
[2019-04-24 09:41:24,369] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2798268e-01 3.5871298e-03 1.5405257e-03 5.0553308e-07 3.9350904e-11
 4.3978371e-08 6.2506761e-10 3.2870597e-03 3.6360207e-01 7.5592338e-11
 2.8967100e-11], sum to 1.0000
[2019-04-24 09:41:24,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4480
[2019-04-24 09:41:24,680] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 19.0, 22.94429496474298, -0.1149333656745809, 0.0, 1.0, 55.0, 51.54125151376503], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3291600.0000, 
sim time next is 3292800.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 22.86146675266219, -0.3049817827028519, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.4051222293885157, 0.39833940576571597, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.631547], dtype=float32), -1.6066928]. 
=============================================
[2019-04-24 09:41:32,097] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4254366e-01 3.4569434e-04 8.6184777e-04 4.2186279e-08 3.2476394e-12
 4.6323700e-09 3.3609799e-11 1.2382388e-03 5.5501056e-01 3.3134686e-12
 6.8158283e-13], sum to 1.0000
[2019-04-24 09:41:32,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4079
[2019-04-24 09:41:32,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5707442e-01 1.4561446e-03 2.9241478e-03 4.1519351e-07 1.0090843e-10
 5.5648517e-08 3.8824535e-09 2.1318146e-03 2.3641299e-01 1.7609739e-10
 5.4845590e-11], sum to 1.0000
[2019-04-24 09:41:32,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1862
[2019-04-24 09:41:32,293] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 19.0, 24.67860463967549, 0.2593382055159127, 0.0, 1.0, 55.0, 48.627272451768356], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3462000.0000, 
sim time next is 3463200.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 19.0, 24.61991777415684, 0.1035127692729659, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.79, 0.0, 0.0, 0.08333333333333333, 0.5516598145130699, 0.534504256424322, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01946272], dtype=float32), 2.5529916]. 
=============================================
[2019-04-24 09:41:32,378] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 61.66666666666667, 0.0, 0.0, 19.0, 21.22385280847292, -0.6717987706859058, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3392400.0000, 
sim time next is 3393600.0000, 
raw observation next is [-3.0, 63.33333333333333, 0.0, 0.0, 19.0, 20.70568010789714, -0.7746563509005719, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.6333333333333333, 0.0, 0.0, 0.08333333333333333, 0.22547334232476177, 0.241781216366476, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3581877], dtype=float32), -0.2790477]. 
=============================================
[2019-04-24 09:41:39,013] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.5268031e-01 1.2308624e-02 3.6052600e-03 3.5915568e-07 5.5574195e-11
 1.7520575e-08 7.0498984e-10 2.5002852e-03 4.2890519e-01 9.9801903e-11
 2.7050574e-11], sum to 1.0000
[2019-04-24 09:41:39,014] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8972
[2019-04-24 09:41:39,093] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 21.1945530289089, -0.5578358566134037, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3476400.0000, 
sim time next is 3477600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 21.56847554230594, -0.2988369052857033, 0.0, 1.0, 55.0, 85.13755228346332], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.29737296185882833, 0.4003876982380989, 0.0, 1.0, 0.8, 0.8513755228346332], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04071631], dtype=float32), 0.4619099]. 
=============================================
[2019-04-24 09:41:48,146] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-24 09:41:48,148] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:41:48,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:41:48,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run2
[2019-04-24 09:41:48,196] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:41:48,197] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:41:48,200] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run2
[2019-04-24 09:41:48,220] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:41:48,221] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:41:48,234] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run2
[2019-04-24 09:43:27,076] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2830.3053 90824.3212 193.1364
[2019-04-24 09:43:27,111] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:43:27,111] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:43:27,241] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:43:27,241] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:43:37,312] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2649.1315 100192.9356 -182.0045
[2019-04-24 09:43:37,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:43:37,333] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:43:37,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:43:37,438] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:43:40,907] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2601.8397 103526.9118 -263.3736
[2019-04-24 09:43:40,930] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:43:40,930] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:43:41,039] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:43:41,039] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:43:41,932] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 50000, evaluation results [50000.0, 2649.1314932205496, 100192.93563899785, -182.00448374208003, 2830.305293781906, 90824.32121623047, 193.13638441836804, 2601.8396540953167, 103526.91179483935, -263.37362063524307]
[2019-04-24 09:43:51,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2629322e-01 3.0897001e-03 4.6859020e-03 1.1184048e-06 6.3376082e-10
 1.6899533e-07 1.7384799e-08 6.8476414e-03 4.5908228e-01 6.4508698e-10
 4.7488952e-10], sum to 1.0000
[2019-04-24 09:43:51,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6496
[2019-04-24 09:43:51,565] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666667, 38.66666666666667, 0.0, 0.0, 22.5, 21.26596909810573, -0.5008449390396325, 0.0, 1.0, 55.0, 85.7915174876192], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4087200.0000, 
sim time next is 4088400.0000, 
raw observation next is [-4.333333333333334, 36.33333333333333, 15.33333333333333, 78.16666666666664, 22.5, 22.32108389743251, -0.3668207098935234, 1.0, 1.0, 55.0, 64.3486999882382], 
processed observation next is [1.0, 0.30434782608695654, 0.3425669436749769, 0.3633333333333333, 0.0511111111111111, 0.08637200736648248, 0.375, 0.36009032478604236, 0.37772643003549217, 1.0, 1.0, 0.8, 0.643486999882382], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0255581], dtype=float32), 0.6732671]. 
=============================================
[2019-04-24 09:43:52,808] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6865259e-01 4.4777812e-03 1.1478019e-02 5.3703144e-07 5.8919492e-10
 1.3642961e-07 7.6174702e-09 2.0549998e-03 3.1333587e-01 8.6781071e-10
 3.5008793e-10], sum to 1.0000
[2019-04-24 09:43:52,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9469
[2019-04-24 09:43:52,870] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 19.0, 21.59746284223929, -0.307948290459403, 0.0, 1.0, 55.0, 84.36684097539339], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4060800.0000, 
sim time next is 4062000.0000, 
raw observation next is [-6.0, 38.33333333333334, 0.0, 0.0, 19.0, 22.34304661374486, -0.2382637570780518, 0.0, 1.0, 55.0, 53.556075841763914], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.3833333333333334, 0.0, 0.0, 0.08333333333333333, 0.36192055114540506, 0.42057874764064945, 0.0, 1.0, 0.8, 0.5355607584176392], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53639114], dtype=float32), -0.8115496]. 
=============================================
[2019-04-24 09:43:53,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1961834e-01 8.3980587e-04 1.2374781e-03 3.8184550e-07 3.9562426e-11
 1.6406133e-08 3.2867370e-10 1.1546770e-03 1.7714928e-01 4.9623253e-11
 8.4259778e-12], sum to 1.0000
[2019-04-24 09:43:53,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4478
[2019-04-24 09:43:53,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 41.0, 0.0, 0.0, 22.5, 23.85096666029133, 0.08425664089740208, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4131600.0000, 
sim time next is 4132800.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 22.5, 23.73468535486831, 0.05501232581183702, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.375, 0.47789044623902593, 0.518337441937279, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([3.3045738], dtype=float32), 1.3034363]. 
=============================================
[2019-04-24 09:43:55,443] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.3436173e-01 1.2584693e-03 1.6873273e-03 5.6670448e-08 1.5528315e-11
 9.2358388e-09 1.3987257e-10 8.1283849e-04 1.6187957e-01 5.9092294e-11
 3.2159785e-12], sum to 1.0000
[2019-04-24 09:43:55,444] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0671
[2019-04-24 09:43:55,467] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 35.0, 93.5, 566.0, 22.5, 25.27958035104841, 0.346395381581956, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4118400.0000, 
sim time next is 4119600.0000, 
raw observation next is [3.666666666666667, 35.66666666666667, 93.16666666666666, 480.0, 22.5, 25.63489167423251, 0.3840196027491683, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.564173591874423, 0.3566666666666667, 0.31055555555555553, 0.5303867403314917, 0.375, 0.6362409728527091, 0.6280065342497227, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.9975767], dtype=float32), -1.3302528]. 
=============================================
[2019-04-24 09:43:56,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.20420241e-01 5.57216257e-03 8.23602173e-03 1.72031321e-06
 1.33006637e-08 4.20852189e-07 1.19683378e-07 1.78406052e-02
 2.47928739e-01 1.33052565e-08 6.87363666e-10], sum to 1.0000
[2019-04-24 09:43:56,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9669
[2019-04-24 09:43:56,382] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 19.0, 23.1612493730294, -0.05219302882961837, 0.0, 1.0, 55.0, 66.29667101799204], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4158000.0000, 
sim time next is 4159200.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 19.0, 23.48153041910331, -0.01485695212910688, 0.0, 1.0, 55.0, 47.51153351306904], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.5, 0.0, 0.0, 0.08333333333333333, 0.4567942015919426, 0.495047682623631, 0.0, 1.0, 0.8, 0.4751153351306904], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16986115], dtype=float32), -1.3595176]. 
=============================================
[2019-04-24 09:43:58,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2871664e-01 6.9365749e-04 2.1306067e-03 3.6584512e-07 5.8886583e-11
 1.8544789e-08 3.8387286e-11 5.4628623e-04 1.6791245e-01 1.4785171e-11
 1.7651836e-12], sum to 1.0000
[2019-04-24 09:43:58,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6957
[2019-04-24 09:43:58,075] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 22.5, 24.89523275036202, 0.4425207604309387, 1.0, 1.0, 55.0, 70.95836367077285], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4129200.0000, 
sim time next is 4130400.0000, 
raw observation next is [2.333333333333333, 39.0, 0.0, 0.0, 22.5, 25.49400695377003, 0.3702427865859297, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5272391505078486, 0.39, 0.0, 0.0, 0.375, 0.6245005794808357, 0.6234142621953099, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80312055], dtype=float32), 1.570718]. 
=============================================
[2019-04-24 09:43:58,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6786462e-01 6.5549929e-03 6.5290076e-03 1.4491494e-06 3.9136716e-09
 2.7700500e-07 4.4188152e-08 3.6316796e-03 3.1541795e-01 1.0660054e-08
 9.9725417e-10], sum to 1.0000
[2019-04-24 09:43:58,653] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2365
[2019-04-24 09:43:58,663] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 19.0, 22.64155247921246, -0.3811612248712655, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4246800.0000, 
sim time next is 4248000.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 19.0, 22.14257387847327, -0.4494134435238786, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.5457063711911359, 0.45, 0.0, 0.0, 0.08333333333333333, 0.34521448987277265, 0.3501955188253738, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.45951933], dtype=float32), 0.28559768]. 
=============================================
[2019-04-24 09:43:59,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3459866e-01 4.4332255e-04 8.2601665e-04 1.4670502e-08 2.3815888e-12
 5.0228910e-10 3.5468198e-11 7.9524680e-04 1.6333675e-01 1.2564007e-12
 2.0777053e-13], sum to 1.0000
[2019-04-24 09:43:59,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3756
[2019-04-24 09:43:59,475] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.199999999999999, 62.66666666666667, 94.5, 522.0, 22.5, 23.4230487637701, -0.1043145889588631, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4351200.0000, 
sim time next is 4352400.0000, 
raw observation next is [6.3, 57.0, 99.5, 584.0, 22.5, 23.58225458872603, -0.07939563178418592, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6371191135734073, 0.57, 0.33166666666666667, 0.6453038674033149, 0.375, 0.46518788239383585, 0.47353478940527133, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4046087], dtype=float32), 0.27644736]. 
=============================================
[2019-04-24 09:43:59,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1179318e-01 6.1322027e-04 5.9972638e-03 1.2928554e-07 3.9413108e-11
 1.3064588e-08 1.5289783e-09 2.0172279e-03 2.7957898e-01 1.3888186e-10
 1.4167126e-11], sum to 1.0000
[2019-04-24 09:43:59,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5871
[2019-04-24 09:43:59,825] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.433333333333334, 75.33333333333334, 0.0, 0.0, 19.0, 24.73244586857055, 0.08544028746318272, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4317600.0000, 
sim time next is 4318800.0000, 
raw observation next is [4.466666666666667, 75.66666666666667, 0.0, 0.0, 19.0, 23.90835718736928, -0.05283845812427768, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5863342566943676, 0.7566666666666667, 0.0, 0.0, 0.08333333333333333, 0.49236309894743996, 0.4823871806252407, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5955546], dtype=float32), 0.7842608]. 
=============================================
[2019-04-24 09:44:05,252] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6884204e-01 7.2198373e-04 3.0360899e-03 1.5868204e-07 2.4431471e-11
 8.5110337e-09 2.4440430e-10 9.4674935e-04 2.2645299e-01 5.0792578e-11
 2.4133112e-11], sum to 1.0000
[2019-04-24 09:44:05,253] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8818
[2019-04-24 09:44:05,303] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-0.9333333333333333, 73.0, 0.0, 0.0, 19.0, 22.33893582173039, -0.3669013422561396, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4506000.0000, 
sim time next is 4507200.0000, 
raw observation next is [-0.9, 73.0, 0.0, 0.0, 19.0, 22.10916234155838, -0.2134132628685337, 0.0, 1.0, 55.0, 78.48526738899331], 
processed observation next is [1.0, 0.17391304347826086, 0.43767313019390586, 0.73, 0.0, 0.0, 0.08333333333333333, 0.3424301951298651, 0.42886224571048875, 0.0, 1.0, 0.8, 0.7848526738899331], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.587817], dtype=float32), 1.2475871]. 
=============================================
[2019-04-24 09:44:05,780] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.2814721e-01 7.6331472e-04 2.5051122e-03 1.2252576e-07 3.4456261e-11
 8.2793630e-09 1.9516333e-10 1.4256808e-03 2.6715860e-01 3.9143827e-11
 1.7899555e-11], sum to 1.0000
[2019-04-24 09:44:05,780] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6276
[2019-04-24 09:44:05,845] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 73.0, 55.5, 33.0, 22.5, 21.776293619839, -0.2239156123000607, 1.0, 1.0, 55.0, 106.41156362906705], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4521600.0000, 
sim time next is 4522800.0000, 
raw observation next is [-0.5333333333333334, 72.66666666666667, 92.5, 55.0, 22.5, 22.81044396327912, -0.2326148344215005, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44783010156971376, 0.7266666666666667, 0.30833333333333335, 0.06077348066298342, 0.375, 0.40087033027325997, 0.4224617218594999, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.587817], dtype=float32), 1.2475871]. 
=============================================
[2019-04-24 09:44:09,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5666853e-01 3.5991083e-04 1.8601537e-03 2.6442777e-07 2.5731046e-11
 7.1301800e-09 8.1326682e-11 3.6593530e-04 1.4074519e-01 5.4371830e-11
 3.3973842e-12], sum to 1.0000
[2019-04-24 09:44:09,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5129
[2019-04-24 09:44:09,017] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 68.5, 48.0, 22.5, 23.00379833676729, -0.1957597068430676, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4554000.0000, 
sim time next is 4555200.0000, 
raw observation next is [2.0, 52.0, 41.5, 34.66666666666666, 22.5, 23.08563689765229, -0.3175523052602831, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.52, 0.13833333333333334, 0.03830570902394106, 0.375, 0.42380307480435747, 0.3941492315799056, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.11281401], dtype=float32), -0.30427688]. 
=============================================
[2019-04-24 09:44:09,343] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0544326e-01 1.8241962e-03 3.5007703e-03 3.8879509e-07 4.2616202e-11
 1.0752702e-08 1.1415526e-10 6.2549784e-04 2.8860584e-01 9.1482592e-11
 3.6128739e-11], sum to 1.0000
[2019-04-24 09:44:09,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3723
[2019-04-24 09:44:09,382] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 22.83589901692551, -0.1727403800313486, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4560000.0000, 
sim time next is 4561200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 22.63202851785993, -0.194932838066045, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.3860023764883274, 0.4350223873113183, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03906536], dtype=float32), 1.0640076]. 
=============================================
[2019-04-24 09:44:09,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6868391e-01 5.6441099e-04 1.4323456e-03 5.3006257e-08 5.0960351e-12
 4.3218629e-09 4.5871272e-11 4.2142638e-04 2.2889790e-01 1.8410076e-11
 1.3947525e-12], sum to 1.0000
[2019-04-24 09:44:09,815] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1803
[2019-04-24 09:44:09,830] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 22.5, 21.96019921274518, -0.3163158619995686, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4734000.0000, 
sim time next is 4735200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 22.5, 21.87966425943195, -0.3453500356817274, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.78, 0.0, 0.0, 0.375, 0.3233053549526626, 0.3848833214394242, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9254873], dtype=float32), -1.9134656]. 
=============================================
[2019-04-24 09:44:12,355] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.6534404e-01 4.5965670e-04 1.4482511e-03 1.0983575e-08 1.5036894e-12
 1.0015466e-09 9.2302485e-11 7.1005500e-04 4.3203801e-01 9.1784837e-13
 2.0306098e-13], sum to 1.0000
[2019-04-24 09:44:12,359] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1265
[2019-04-24 09:44:12,384] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 24.06136586037273, 0.1090185937258701, 0.0, 1.0, 55.0, 45.48525498916143], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4687200.0000, 
sim time next is 4688400.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 19.0, 24.05612459260228, -0.03562529413667581, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5046770493835234, 0.48812490195444136, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16863032], dtype=float32), -0.4854727]. 
=============================================
[2019-04-24 09:44:12,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3886204e-01 2.1020274e-03 1.8271329e-02 3.9887090e-07 2.0043696e-09
 1.6402383e-07 7.9357259e-09 3.5857721e-03 2.3717827e-01 4.0686476e-09
 3.2038333e-10], sum to 1.0000
[2019-04-24 09:44:12,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1023
[2019-04-24 09:44:12,727] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.8, 44.33333333333334, 266.0, 385.6666666666667, 19.0, 22.06383302010665, -0.3085545466821198, 0.0, 1.0, 55.0, 47.14858874037928], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4887600.0000, 
sim time next is 4888800.0000, 
raw observation next is [2.0, 44.0, 254.0, 381.0, 19.0, 22.45711310232029, -0.3860673524584359, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.44, 0.8466666666666667, 0.42099447513812155, 0.08333333333333333, 0.37142609186002407, 0.3713108825138547, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07432742], dtype=float32), -0.42202964]. 
=============================================
[2019-04-24 09:44:18,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:18,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:19,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:19,486] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:19,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run2
[2019-04-24 09:44:19,838] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:20,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:20,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:20,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:20,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:20,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:20,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run2
[2019-04-24 09:44:21,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3260602e-01 3.9416747e-03 2.0066139e-03 3.6933557e-07 8.7031361e-11
 1.8925412e-08 1.6448040e-09 2.0954700e-03 1.5934983e-01 1.4728602e-10
 1.2577081e-10], sum to 1.0000
[2019-04-24 09:44:21,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6808
[2019-04-24 09:44:21,114] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 30.0, 112.5, 760.0, 22.5, 22.23066780948494, -0.4827058110654415, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4960800.0000, 
sim time next is 4962000.0000, 
raw observation next is [1.666666666666667, 29.66666666666667, 115.5, 788.6666666666667, 22.5, 22.42202025599824, -0.4463850881141679, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5087719298245615, 0.2966666666666667, 0.385, 0.8714548802946593, 0.375, 0.36850168799985344, 0.3512049706286107, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.48627824], dtype=float32), 1.9034991]. 
=============================================
[2019-04-24 09:44:21,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:21,266] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:21,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run2
[2019-04-24 09:44:21,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:21,685] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:21,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:21,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:21,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:22,019] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:22,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:22,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:22,174] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:22,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:22,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:22,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:22,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:22,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:22,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run2
[2019-04-24 09:44:22,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:22,624] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:22,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6759622e-01 1.3361904e-03 2.6588780e-03 1.8829371e-07 2.3193432e-11
 1.3410143e-08 3.5932984e-10 1.9008678e-03 3.2650772e-01 2.0977832e-11
 5.9371470e-12], sum to 1.0000
[2019-04-24 09:44:22,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3597
[2019-04-24 09:44:22,674] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 78.0, 317.0, 22.5, 21.86655470625848, -0.4450795123999915, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5040000.0000, 
sim time next is 5041200.0000, 
raw observation next is [-1.0, 59.0, 90.66666666666667, 461.0, 22.5, 21.70740630110319, -0.4197066258928592, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4349030470914128, 0.59, 0.3022222222222222, 0.5093922651933702, 0.375, 0.3089505250919326, 0.3600977913690469, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6026305], dtype=float32), 0.54501086]. 
=============================================
[2019-04-24 09:44:22,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:22,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:22,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run2
[2019-04-24 09:44:22,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:22,878] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:22,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run2
[2019-04-24 09:44:22,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:22,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:22,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:22,951] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run2
[2019-04-24 09:44:23,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:23,175] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:23,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:23,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run2
[2019-04-24 09:44:23,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:23,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:23,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:23,364] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run2
[2019-04-24 09:44:23,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:23,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:23,471] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run2
[2019-04-24 09:44:23,679] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:23,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:23,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:23,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run2
[2019-04-24 09:44:24,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:24,320] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:24,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run2
[2019-04-24 09:44:24,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:24,482] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:24,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:24,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:24,692] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:24,767] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:24,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:25,018] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:25,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:25,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:25,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run2
[2019-04-24 09:44:25,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:25,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:25,471] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run2
[2019-04-24 09:44:25,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:25,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:25,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run2
[2019-04-24 09:44:25,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:44:25,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:44:25,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run2
[2019-04-24 09:44:36,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9585243e-01 4.5024054e-03 7.7420790e-03 2.9047027e-07 3.3701841e-10
 3.6348233e-08 9.1232062e-09 4.7756811e-03 3.8712707e-01 1.2471074e-10
 1.2742683e-10], sum to 1.0000
[2019-04-24 09:44:36,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7962
[2019-04-24 09:44:36,424] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 76.66666666666667, 0.0, 0.0, 19.0, 20.75580257655722, -0.6896757909598933, 0.0, 1.0, 55.0, 73.33050603034336], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 182400.0000, 
sim time next is 183600.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 21.0629036010653, -0.65468682856686, 0.0, 1.0, 55.0, 52.56373484749585], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.25524196675544175, 0.28177105714438, 0.0, 1.0, 0.8, 0.5256373484749585], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5085818], dtype=float32), -0.5505839]. 
=============================================
[2019-04-24 09:44:38,030] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7779566e-01 6.6583984e-02 6.3213244e-02 4.8794053e-03 2.2065734e-04
 1.2897584e-03 4.2751967e-04 7.8595892e-02 3.0654845e-01 2.7419563e-04
 1.7126476e-04], sum to 1.0000
[2019-04-24 09:44:38,030] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8278
[2019-04-24 09:44:38,060] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.8, 95.66666666666667, 0.0, 0.0, 19.0, 20.91645833671058, -0.5048498151457741, 0.0, 1.0, 50.0, 49.94877585917986], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2400.0000, 
sim time next is 3600.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 21.39416359959767, -0.3915183515254457, 0.0, 1.0, 55.0, 53.109397098308065], 
processed observation next is [0.0, 0.043478260869565216, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.282846966633139, 0.36949388282485146, 0.0, 1.0, 0.8, 0.5310939709830806], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3843891], dtype=float32), 0.0049027153]. 
=============================================
[2019-04-24 09:44:38,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1451817e-01 2.8255042e-03 5.6739375e-03 1.1880810e-07 1.6780915e-11
 2.1036175e-08 6.8397149e-10 1.3258745e-03 3.7565637e-01 3.9432090e-11
 1.9950383e-11], sum to 1.0000
[2019-04-24 09:44:38,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5495
[2019-04-24 09:44:38,961] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.799999999999999, 82.0, 189.0, 32.16666666666666, 22.5, 22.92931370393458, -0.3914734616674533, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 124800.0000, 
sim time next is 126000.0000, 
raw observation next is [-7.8, 86.0, 187.0, 24.5, 22.5, 22.33166556555238, -0.4724819609898883, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.24653739612188366, 0.86, 0.6233333333333333, 0.02707182320441989, 0.375, 0.36097213046269844, 0.3425060130033706, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8707395], dtype=float32), 1.6770229]. 
=============================================
[2019-04-24 09:44:40,306] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.66805470e-01 1.79887295e-03 1.26659684e-03 1.16892465e-07
 1.55250379e-11 9.09132147e-09 3.36881162e-10 2.04855599e-03
 2.28080422e-01 2.05772604e-11 2.43326518e-12], sum to 1.0000
[2019-04-24 09:44:40,308] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4675
[2019-04-24 09:44:40,328] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.933333333333334, 77.33333333333334, 0.0, 0.0, 19.0, 21.70055687217831, -0.4244165206753414, 0.0, 1.0, 55.0, 53.54141044691369], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 102000.0000, 
sim time next is 103200.0000, 
raw observation next is [-4.466666666666667, 75.66666666666666, 0.0, 0.0, 19.0, 21.59396278805311, -0.6154505487672717, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.3388734995383195, 0.7566666666666666, 0.0, 0.0, 0.08333333333333333, 0.2994968990044257, 0.2948498170775761, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74258804], dtype=float32), -0.28222087]. 
=============================================
[2019-04-24 09:45:05,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.18939418e-01 1.26089081e-02 2.93578729e-02 9.72677117e-06
 3.73433195e-09 4.82112739e-07 1.03547556e-07 5.92058105e-03
 6.33162916e-01 1.17270025e-08 1.04511617e-08], sum to 1.0000
[2019-04-24 09:45:05,352] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4581
[2019-04-24 09:45:05,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-9.866666666666667, 46.66666666666667, 0.0, 0.0, 19.0, 18.47067192305021, -1.379372785781864, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 452400.0000, 
sim time next is 453600.0000, 
raw observation next is [-9.5, 44.0, 0.0, 0.0, 19.0, 18.2436370403811, -1.230149603866073, 0.0, 1.0, 55.0, 79.95626021244057], 
processed observation next is [1.0, 0.2608695652173913, 0.1994459833795014, 0.44, 0.0, 0.0, 0.08333333333333333, 0.020303086698424917, 0.0899501320446423, 0.0, 1.0, 0.8, 0.7995626021244057], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14505361], dtype=float32), 0.47090337]. 
=============================================
[2019-04-24 09:45:14,365] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4916655e-01 2.2202395e-03 5.4002036e-03 1.0196721e-06 6.5128408e-10
 7.3456860e-08 1.5760099e-08 6.7520058e-03 2.3645984e-01 1.7944978e-09
 1.0439553e-10], sum to 1.0000
[2019-04-24 09:45:14,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2826
[2019-04-24 09:45:14,389] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.966666666666667, 86.66666666666666, 0.0, 0.0, 19.0, 19.9101312259409, -0.9620119063792402, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 528000.0000, 
sim time next is 529200.0000, 
raw observation next is [3.8, 86.0, 0.0, 0.0, 19.0, 19.66004171556422, -1.005338777809026, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.5678670360110805, 0.86, 0.0, 0.0, 0.08333333333333333, 0.13833680963035158, 0.16488707406365802, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25571936], dtype=float32), 0.73867273]. 
=============================================
[2019-04-24 09:45:18,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5394902e-01 5.4036295e-03 8.7084835e-03 5.3566305e-07 3.5190914e-10
 6.6240275e-08 1.5168116e-09 1.4505434e-03 3.3048776e-01 3.4762557e-10
 7.1416179e-11], sum to 1.0000
[2019-04-24 09:45:18,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0588
[2019-04-24 09:45:18,514] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 34.0, 38.0, 0.0, 22.5, 21.98077513359663, -0.6364357401351463, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 489600.0000, 
sim time next is 490800.0000, 
raw observation next is [1.1, 37.0, 26.0, 0.0, 22.5, 21.79064995985864, -0.6651177194115586, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.37, 0.08666666666666667, 0.0, 0.375, 0.31588749665488675, 0.2782940935294805, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.3184, 
noisyNet noise sample is [array([0.31342256], dtype=float32), -0.86069167]. 
=============================================
[2019-04-24 09:45:23,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2831676e-01 2.0635070e-03 1.2022054e-02 1.0081942e-06 1.3955634e-09
 4.8532108e-08 1.2950802e-08 2.0700973e-03 3.5552651e-01 5.3344071e-09
 1.4136489e-10], sum to 1.0000
[2019-04-24 09:45:23,846] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6771
[2019-04-24 09:45:23,882] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.2, 80.0, 136.1666666666667, 573.6666666666667, 19.0, 21.28394107337274, -0.6482619975594827, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 567600.0000, 
sim time next is 568800.0000, 
raw observation next is [-1.2, 80.0, 132.5, 531.0, 19.0, 21.06505926552678, -0.5170058297110113, 0.0, 1.0, 55.0, 69.91116781631855], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.8, 0.44166666666666665, 0.5867403314917127, 0.08333333333333333, 0.2554216054605651, 0.3276647234296629, 0.0, 1.0, 0.8, 0.6991116781631855], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37955227], dtype=float32), -0.44031453]. 
=============================================
[2019-04-24 09:45:27,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.79236931e-01 3.70697980e-03 1.11007812e-02 3.34906485e-06
 2.34734259e-08 3.75872929e-07 1.99163651e-07 1.00708995e-02
 4.95880365e-01 1.77911765e-08 3.82536625e-09], sum to 1.0000
[2019-04-24 09:45:27,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8047
[2019-04-24 09:45:27,508] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 75.33333333333333, 0.0, 0.0, 19.0, 19.36025815959619, -0.9944873071387234, 0.0, 1.0, 55.0, 72.93772391959538], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 632400.0000, 
sim time next is 633600.0000, 
raw observation next is [-4.5, 79.0, 9.5, 0.0, 19.0, 19.67152248177758, -0.9571245701043817, 0.0, 1.0, 55.0, 52.49266616644312], 
processed observation next is [0.0, 0.34782608695652173, 0.3379501385041552, 0.79, 0.03166666666666667, 0.0, 0.08333333333333333, 0.13929354014813158, 0.18095847663187278, 0.0, 1.0, 0.8, 0.5249266616644312], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1117135], dtype=float32), 0.8524532]. 
=============================================
[2019-04-24 09:45:39,089] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9943523e-01 8.7852194e-04 7.0613605e-04 5.5382792e-08 6.1805886e-12
 2.0557842e-09 4.5330781e-11 7.0792489e-04 2.9827204e-01 1.7831017e-12
 4.4515051e-13], sum to 1.0000
[2019-04-24 09:45:39,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1116
[2019-04-24 09:45:39,221] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 82.66666666666667, 52.83333333333333, 0.0, 22.5, 23.3775292544732, -0.1756969144050889, 1.0, 1.0, 55.0, 64.39535716247939], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 898800.0000, 
sim time next is 900000.0000, 
raw observation next is [1.1, 84.0, 62.5, 0.0, 22.5, 23.66166460241845, -0.2387620597020265, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.49307479224376743, 0.84, 0.20833333333333334, 0.0, 0.375, 0.47180538353487095, 0.42041264676599116, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.62985325], dtype=float32), 0.45203957]. 
=============================================
[2019-04-24 09:45:39,263] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.05343 ]
 [64.81823 ]
 [64.73093 ]
 [63.99571 ]
 [64.42427 ]
 [63.283108]
 [61.725193]
 [62.014526]
 [60.55815 ]
 [59.504147]
 [60.204685]
 [61.15864 ]
 [62.190727]
 [61.85743 ]
 [61.157413]
 [60.510117]
 [61.37033 ]
 [60.722557]
 [60.089146]
 [60.664402]
 [61.498566]
 [60.887398]
 [59.85189 ]
 [59.135845]
 [59.484383]], R is [[66.0515976 ]
 [65.39108276]
 [65.73717499]
 [65.07980347]
 [65.42900848]
 [64.77471924]
 [64.12697601]
 [64.25845337]
 [63.61586761]
 [62.97970963]
 [63.34991455]
 [63.71641541]
 [64.07925415]
 [63.4384613 ]
 [62.80407715]
 [62.17603683]
 [62.55427551]
 [61.92873383]
 [61.30944824]
 [61.69635391]
 [62.07939148]
 [61.45859909]
 [60.84401321]
 [60.23557281]
 [60.63321686]].
[2019-04-24 09:45:44,632] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5009907e-01 8.7629691e-05 9.0618746e-04 9.5049666e-09 4.2601120e-13
 2.9160516e-10 8.3576514e-12 5.7453307e-04 4.4833255e-01 9.0702890e-13
 1.2127154e-13], sum to 1.0000
[2019-04-24 09:45:44,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9175
[2019-04-24 09:45:44,733] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [14.4, 75.66666666666667, 0.0, 0.0, 19.0, 22.73449408617429, 0.04990022907069506, 0.0, 1.0, 55.0, 74.29967792605578], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1028400.0000, 
sim time next is 1029600.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 19.0, 23.67083807436052, 0.1668673199485931, 0.0, 1.0, 55.0, 46.62407894443918], 
processed observation next is [1.0, 0.9565217391304348, 0.8614958448753465, 0.75, 0.0, 0.0, 0.08333333333333333, 0.47256983953004345, 0.5556224399828643, 0.0, 1.0, 0.8, 0.4662407894443918], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13647752], dtype=float32), -0.58670866]. 
=============================================
[2019-04-24 09:45:50,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9958060e-01 3.4061633e-04 2.3379864e-03 4.0016255e-07 1.3517952e-09
 6.9600723e-08 2.0055284e-09 7.6462631e-04 9.6975669e-02 7.8476975e-10
 8.1323261e-11], sum to 1.0000
[2019-04-24 09:45:50,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3113
[2019-04-24 09:45:50,678] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.46666666666667, 64.33333333333334, 88.0, 0.0, 19.0, 25.45689737583729, 0.5690777698901027, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1178400.0000, 
sim time next is 1179600.0000, 
raw observation next is [18.63333333333333, 63.66666666666667, 71.5, 0.0, 19.0, 25.37529208636796, 0.559760307918394, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.9787626962142197, 0.6366666666666667, 0.23833333333333334, 0.0, 0.08333333333333333, 0.6146076738639966, 0.6865867693061314, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5838463], dtype=float32), 2.3662732]. 
=============================================
[2019-04-24 09:45:51,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7996613e-01 6.4592808e-04 1.2728082e-03 2.3200423e-08 5.2272388e-12
 3.8958086e-09 1.2107611e-10 3.8719701e-04 5.1772785e-01 3.1964075e-12
 5.8859119e-13], sum to 1.0000
[2019-04-24 09:45:51,850] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0975
[2019-04-24 09:45:51,867] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 23.43664136835239, -0.06553753358295854, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1387200.0000, 
sim time next is 1388400.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 22.6732656826447, -0.2069681495179293, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.3894388068870584, 0.43101061682735686, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.31830874], dtype=float32), 0.29930905]. 
=============================================
[2019-04-24 09:45:59,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.6225188e-01 6.6481378e-05 1.5488343e-04 1.0543150e-08 1.7132088e-13
 4.4110268e-10 1.2610148e-12 4.2650805e-04 1.3710028e-01 2.2381053e-13
 3.7324239e-14], sum to 1.0000
[2019-04-24 09:45:59,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1756
[2019-04-24 09:46:00,037] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 100.1666666666667, 0.0, 22.5, 25.32926828299315, 0.5090318403150066, 1.0, 1.0, 55.0, 69.19996538741378], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1345200.0000, 
sim time next is 1346400.0000, 
raw observation next is [1.1, 92.0, 88.5, 0.0, 22.5, 25.71751225528815, 0.4297506479788956, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.295, 0.0, 0.375, 0.6431260212740124, 0.6432502159929653, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4116923], dtype=float32), -1.2526078]. 
=============================================
[2019-04-24 09:46:02,840] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.20734179e-01 1.60191616e-03 2.33512954e-03 5.15773770e-08
 9.03653367e-12 1.57732871e-09 2.11841350e-10 1.87970721e-03
 2.73448974e-01 1.16225415e-11 3.15960230e-13], sum to 1.0000
[2019-04-24 09:46:02,862] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5428
[2019-04-24 09:46:02,908] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 22.1895931913151, -0.1912250219673094, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1314000.0000, 
sim time next is 1315200.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 22.15304571316477, -0.2231472244832368, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.3460871427637307, 0.42561759183892106, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7086523], dtype=float32), -1.5047307]. 
=============================================
[2019-04-24 09:46:04,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4548030e-01 1.9876988e-04 5.1137229e-04 1.8349418e-08 2.5751959e-12
 3.4505432e-09 4.8238375e-11 2.9628916e-04 2.5351331e-01 1.0885972e-11
 6.7885405e-13], sum to 1.0000
[2019-04-24 09:46:04,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6994
[2019-04-24 09:46:04,556] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 19.0, 22.69594673057563, -0.2220251497971583, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1461600.0000, 
sim time next is 1462800.0000, 
raw observation next is [1.266666666666667, 92.0, 0.0, 0.0, 19.0, 22.14855805635231, -0.372206100347968, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4976915974145891, 0.92, 0.0, 0.0, 0.08333333333333333, 0.3457131713626926, 0.3759312998840107, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03922931], dtype=float32), 0.45862424]. 
=============================================
[2019-04-24 09:46:05,197] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0078126e-01 3.6556434e-04 3.9459832e-04 5.0266986e-09 2.2462868e-13
 3.0099073e-10 1.7504997e-11 6.1774207e-04 3.9784080e-01 2.8037512e-13
 3.7933791e-14], sum to 1.0000
[2019-04-24 09:46:05,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5694
[2019-04-24 09:46:05,227] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 24.84776741007161, 0.3426013045907285, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1314000.0000, 
sim time next is 1315200.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 24.49757306604027, 0.2513591777816275, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.5414644221700226, 0.5837863925938759, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5712485], dtype=float32), -1.602524]. 
=============================================
[2019-04-24 09:46:06,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1164920e-01 2.8186254e-04 1.1293980e-03 2.2945632e-09 1.0463421e-13
 1.7074585e-10 3.0315412e-12 3.9259082e-04 1.8654689e-01 3.2942220e-13
 5.1222356e-14], sum to 1.0000
[2019-04-24 09:46:06,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7266
[2019-04-24 09:46:06,124] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.133333333333333, 69.66666666666667, 87.5, 700.8333333333334, 22.5, 24.5995372803861, 0.2234404926723627, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1516800.0000, 
sim time next is 1518000.0000, 
raw observation next is [9.066666666666666, 66.33333333333334, 83.33333333333334, 694.6666666666667, 22.5, 24.39001857100385, 0.1931804662803399, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.713758079409049, 0.6633333333333334, 0.2777777777777778, 0.7675874769797423, 0.375, 0.5325015475836542, 0.5643934887601133, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3129563], dtype=float32), 0.09843785]. 
=============================================
[2019-04-24 09:46:06,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4306095e-01 2.9543563e-04 8.2995015e-04 3.3869205e-09 2.2497337e-13
 2.6822083e-10 7.4702579e-12 2.6313489e-04 2.5555050e-01 1.3391665e-13
 3.8145936e-14], sum to 1.0000
[2019-04-24 09:46:06,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7411
[2019-04-24 09:46:06,271] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.566666666666667, 98.66666666666667, 68.66666666666667, 0.0, 22.5, 24.85739007967446, 0.1485224919413536, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1506000.0000, 
sim time next is 1507200.0000, 
raw observation next is [2.933333333333333, 97.33333333333334, 75.5, 118.0, 22.5, 24.48562996866725, 0.08349712479071865, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.543859649122807, 0.9733333333333334, 0.25166666666666665, 0.13038674033149172, 0.375, 0.5404691640556042, 0.5278323749302395, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3085816], dtype=float32), -0.18813862]. 
=============================================
[2019-04-24 09:46:07,922] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.0887645e-01 2.1613338e-04 1.0286378e-03 6.3644858e-09 7.2322107e-13
 1.5358934e-09 2.6424687e-11 5.2192423e-04 1.8935682e-01 1.0350204e-12
 1.8022598e-13], sum to 1.0000
[2019-04-24 09:46:07,923] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9492
[2019-04-24 09:46:07,976] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 19.0, 24.06528060688397, 0.09297555672994855, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1648800.0000, 
sim time next is 1650000.0000, 
raw observation next is [7.0, 96.33333333333333, 0.0, 0.0, 19.0, 23.94213932551584, 0.2778914604849781, 0.0, 1.0, 55.0, 73.258649487411], 
processed observation next is [1.0, 0.08695652173913043, 0.6565096952908588, 0.9633333333333333, 0.0, 0.0, 0.08333333333333333, 0.49517827712631995, 0.592630486828326, 0.0, 1.0, 0.8, 0.7325864948741101], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1542214], dtype=float32), 0.17700279]. 
=============================================
[2019-04-24 09:46:08,001] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[68.65582 ]
 [68.52731 ]
 [68.565384]
 [67.50395 ]
 [66.12464 ]
 [66.31232 ]
 [66.687744]
 [67.12114 ]
 [67.267845]
 [67.125824]
 [66.70991 ]
 [67.04604 ]
 [67.84709 ]
 [67.80838 ]
 [68.428764]
 [68.9755  ]
 [69.39579 ]
 [70.54361 ]
 [71.25389 ]
 [71.72388 ]
 [71.375046]
 [72.15646 ]
 [70.78061 ]
 [71.27263 ]
 [70.175125]], R is [[69.48600769]
 [69.79114532]
 [70.0932312 ]
 [69.39229584]
 [68.69837189]
 [69.01139069]
 [69.3212738 ]
 [69.62805939]
 [69.93177795]
 [70.23246002]
 [70.53013611]
 [70.82483673]
 [71.11659241]
 [71.40542603]
 [71.69137573]
 [71.97446442]
 [72.2547226 ]
 [72.53217316]
 [72.80685425]
 [73.07878876]
 [73.34799957]
 [73.61451721]
 [72.87837219]
 [73.14958954]
 [72.41809082]].
[2019-04-24 09:46:09,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8754470e-01 9.4147719e-05 2.5845985e-03 9.9936059e-09 2.3479790e-12
 5.4662325e-10 2.9431232e-11 7.9742161e-04 3.0897906e-01 2.3403959e-12
 5.4044341e-14], sum to 1.0000
[2019-04-24 09:46:09,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5386
[2019-04-24 09:46:09,077] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 19.0, 24.11872639365617, 0.3514347061600167, 0.0, 1.0, 55.0, 72.31105573470148], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1556400.0000, 
sim time next is 1557600.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 19.0, 24.67602455114989, 0.2736506344219638, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6011080332409973, 0.82, 0.0, 0.0, 0.08333333333333333, 0.5563353792624909, 0.5912168781406546, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7488917], dtype=float32), -0.7920435]. 
=============================================
[2019-04-24 09:46:12,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8706626e-01 1.0171315e-03 3.6060910e-03 3.1789675e-08 5.8433559e-13
 2.4161477e-09 1.9919184e-11 9.1281359e-04 3.0739757e-01 3.2625957e-12
 1.6004857e-13], sum to 1.0000
[2019-04-24 09:46:12,842] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5695
[2019-04-24 09:46:12,852] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 100.0, 32.5, 0.0, 22.5, 23.12377518095894, -0.2103181739230942, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1501200.0000, 
sim time next is 1502400.0000, 
raw observation next is [1.8, 100.0, 42.16666666666667, 0.0, 22.5, 22.91882636022636, -0.2335502536081179, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.5124653739612189, 1.0, 0.14055555555555557, 0.0, 0.375, 0.40990219668553013, 0.4221499154639607, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1495567], dtype=float32), 0.46363035]. 
=============================================
[2019-04-24 09:46:13,200] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.1695018e-01 2.1057490e-03 2.0550056e-03 3.2986303e-08 1.5712463e-12
 2.4061215e-09 1.8850191e-10 1.0991535e-03 2.7778995e-01 9.4061937e-12
 5.6339232e-13], sum to 1.0000
[2019-04-24 09:46:13,220] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0443
[2019-04-24 09:46:13,254] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.633333333333334, 84.66666666666667, 0.0, 0.0, 19.0, 23.47066770558566, -0.03387900596810217, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1570800.0000, 
sim time next is 1572000.0000, 
raw observation next is [4.666666666666667, 84.33333333333334, 0.0, 0.0, 19.0, 23.08629004387523, -0.1000007488842731, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5918744228993538, 0.8433333333333334, 0.0, 0.0, 0.08333333333333333, 0.42385750365626923, 0.46666641703857564, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7315312], dtype=float32), 0.22384727]. 
=============================================
[2019-04-24 09:46:16,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0666373e-01 7.4844167e-04 1.0268133e-03 5.4502280e-08 1.9270573e-12
 2.0267346e-09 2.0959274e-11 3.2392135e-04 2.9123706e-01 6.3659971e-12
 3.5109784e-13], sum to 1.0000
[2019-04-24 09:46:16,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6362
[2019-04-24 09:46:16,376] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 21.3570316071244, -0.4087511233665601, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1712400.0000, 
sim time next is 1713600.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 21.18817400904437, -0.4420036562346144, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.26568116742036424, 0.3526654479217952, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21136235], dtype=float32), -1.6988395]. 
=============================================
[2019-04-24 09:46:16,863] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.0415287e-01 9.2319089e-05 2.1507413e-04 2.2344373e-09 2.8124058e-13
 8.4051027e-10 1.7680008e-12 1.7270949e-04 9.5367111e-02 8.2404932e-13
 2.2376046e-14], sum to 1.0000
[2019-04-24 09:46:16,863] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2793
[2019-04-24 09:46:16,891] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.766666666666667, 64.33333333333334, 0.0, 0.0, 22.5, 25.74673450696136, 0.4920627555223141, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1622400.0000, 
sim time next is 1623600.0000, 
raw observation next is [9.4, 66.0, 0.0, 0.0, 22.5, 25.29032842330623, 0.4358608270335849, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7229916897506927, 0.66, 0.0, 0.0, 0.375, 0.6075273686088526, 0.6452869423445283, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7151449], dtype=float32), -0.312462]. 
=============================================
[2019-04-24 09:46:20,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1213770e-01 6.2941143e-04 5.8098009e-04 5.9429972e-09 2.9634200e-13
 4.4275580e-10 1.4608301e-11 1.7988821e-03 2.8485301e-01 6.4277013e-13
 6.2976547e-14], sum to 1.0000
[2019-04-24 09:46:20,969] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5363
[2019-04-24 09:46:21,035] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 19.0, 24.07266125508653, 0.3142035035397682, 0.0, 1.0, 55.0, 73.90087275158676], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1652400.0000, 
sim time next is 1653600.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 19.0, 24.44873167839305, 0.2254866831304451, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6454293628808865, 0.97, 0.0, 0.0, 0.08333333333333333, 0.5373943065327541, 0.5751622277101484, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1847732], dtype=float32), 1.8206737]. 
=============================================
[2019-04-24 09:46:22,726] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.77391267e-01 9.86474450e-04 9.17547091e-04 6.78429188e-08
 7.00000127e-12 2.89459079e-09 9.88010229e-11 5.63012378e-04
 4.20141608e-01 1.27306065e-11 1.73152486e-12], sum to 1.0000
[2019-04-24 09:46:22,731] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8720
[2019-04-24 09:46:22,774] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 22.02685047666743, -0.3427240317891049, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1724400.0000, 
sim time next is 1725600.0000, 
raw observation next is [0.1666666666666667, 94.0, 0.0, 0.0, 19.0, 21.89147558674827, -0.1496761322493276, 0.0, 1.0, 55.0, 82.62626962261704], 
processed observation next is [1.0, 1.0, 0.4672206832871654, 0.94, 0.0, 0.0, 0.08333333333333333, 0.3242896322290226, 0.4501079559168908, 0.0, 1.0, 0.8, 0.8262626962261704], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46331477], dtype=float32), 0.5193882]. 
=============================================
[2019-04-24 09:46:23,407] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.1135163e-01 2.2536230e-03 2.1490422e-03 2.8730321e-07 2.3394331e-10
 1.5039790e-08 1.7297449e-09 3.9572087e-03 2.8028813e-01 4.6340970e-10
 1.6051762e-11], sum to 1.0000
[2019-04-24 09:46:23,493] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0837
[2019-04-24 09:46:23,522] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 87.0, 0.0, 0.0, 19.0, 21.95475791926047, -0.3332942888577038, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1742400.0000, 
sim time next is 1743600.0000, 
raw observation next is [-0.6, 85.66666666666667, 0.0, 0.0, 19.0, 21.63745280332034, -0.391726049624005, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.44598337950138506, 0.8566666666666667, 0.0, 0.0, 0.08333333333333333, 0.30312106694336166, 0.3694246501253317, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04916836], dtype=float32), 0.2503865]. 
=============================================
[2019-04-24 09:46:26,976] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.0841672e-01 8.4663107e-04 1.4166487e-03 7.6483481e-08 3.0952449e-11
 1.5427377e-08 9.7789950e-11 5.8352115e-04 1.8873642e-01 2.4520830e-11
 4.6134034e-12], sum to 1.0000
[2019-04-24 09:46:26,979] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2810
[2019-04-24 09:46:27,011] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.866666666666667, 75.0, 0.0, 0.0, 22.5, 21.59627360657355, -0.592806757801908, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1970400.0000, 
sim time next is 1971600.0000, 
raw observation next is [-5.233333333333333, 79.0, 0.0, 0.0, 22.5, 20.97089064944193, -0.6935815399374691, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.31763619575253926, 0.79, 0.0, 0.0, 0.375, 0.24757422078682753, 0.26880615335417696, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0632, 
noisyNet noise sample is [array([-0.1727421], dtype=float32), 0.004292681]. 
=============================================
[2019-04-24 09:46:31,065] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5168615e-01 2.8502012e-03 1.1855759e-02 3.8166627e-06 1.1660896e-08
 1.1711417e-06 1.4628796e-07 3.3121107e-03 6.3029057e-01 1.6819770e-08
 2.2542987e-09], sum to 1.0000
[2019-04-24 09:46:31,113] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1830
[2019-04-24 09:46:31,127] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.333333333333334, 78.0, 127.8333333333333, 78.33333333333334, 19.0, 19.78856975590496, -1.023534303000933, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1848000.0000, 
sim time next is 1849200.0000, 
raw observation next is [-5.966666666666667, 78.0, 143.3333333333333, 86.83333333333334, 19.0, 18.94346603939525, -1.159580608830628, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.2973222530009234, 0.78, 0.47777777777777763, 0.09594843462246778, 0.08333333333333333, 0.0786221699496042, 0.11347313038979068, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9872, 
noisyNet noise sample is [array([-0.76506096], dtype=float32), -0.4708561]. 
=============================================
[2019-04-24 09:46:34,004] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3203458e-01 2.0278988e-03 1.1082351e-02 3.0878246e-07 1.6420408e-09
 1.3813465e-07 5.9145475e-09 2.6075337e-03 4.5224726e-01 7.9204543e-10
 2.2629465e-10], sum to 1.0000
[2019-04-24 09:46:34,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0226
[2019-04-24 09:46:34,081] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.466666666666667, 76.0, 0.0, 0.0, 19.0, 19.90873169906595, -0.8804011535160338, 0.0, 1.0, 55.0, 74.2384674697651], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1905600.0000, 
sim time next is 1906800.0000, 
raw observation next is [-7.633333333333333, 77.0, 0.0, 0.0, 19.0, 20.04354925756026, -1.015021371583553, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.2511542012927055, 0.77, 0.0, 0.0, 0.08333333333333333, 0.17029577146335514, 0.16165954280548234, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.73452616], dtype=float32), -1.4604034]. 
=============================================
[2019-04-24 09:46:34,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7529581e-01 1.5936696e-03 3.3809782e-03 4.2197769e-07 2.5722766e-10
 1.8135079e-08 8.3301394e-10 1.5906329e-03 4.1813844e-01 1.2357088e-10
 7.5435568e-11], sum to 1.0000
[2019-04-24 09:46:34,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5463
[2019-04-24 09:46:34,302] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 91.0, 0.0, 0.0, 22.5, 20.50146198287505, -0.8675855464575046, 1.0, 1.0, 55.0, 69.91056165916442], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1928400.0000, 
sim time next is 1929600.0000, 
raw observation next is [-9.5, 91.0, 17.5, 11.0, 22.5, 20.39465999135611, -1.027463551023247, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.1994459833795014, 0.91, 0.058333333333333334, 0.012154696132596685, 0.375, 0.1995549992796759, 0.15751214965891766, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05842429], dtype=float32), 0.9055091]. 
=============================================
[2019-04-24 09:46:48,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1670491e-01 1.2842289e-03 2.9320219e-03 2.7502111e-07 4.1831535e-11
 2.4490189e-08 7.1020251e-10 8.4307365e-04 2.7823544e-01 4.9162466e-11
 2.2728970e-11], sum to 1.0000
[2019-04-24 09:46:48,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4228
[2019-04-24 09:46:48,280] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 22.5, 20.73220138009129, -0.8010772388119051, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2224800.0000, 
sim time next is 2226000.0000, 
raw observation next is [-4.533333333333333, 68.66666666666667, 0.0, 0.0, 22.5, 20.07841699071294, -0.8350999691473134, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3370267774699908, 0.6866666666666668, 0.0, 0.0, 0.375, 0.17320141589274515, 0.22163334361756218, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4981495], dtype=float32), -1.8077829]. 
=============================================
[2019-04-24 09:46:53,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4164468e-01 3.3995873e-04 1.6936415e-03 5.2570236e-08 5.8324613e-12
 6.9645547e-09 3.9228107e-11 6.4964325e-04 2.5567204e-01 4.1529007e-12
 8.9122693e-13], sum to 1.0000
[2019-04-24 09:46:53,382] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3031
[2019-04-24 09:46:53,428] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 68.0, 135.5, 0.0, 22.5, 23.17350894843476, -0.3079735153221501, 1.0, 1.0, 55.0, 69.34582956399561], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2203200.0000, 
sim time next is 2204400.0000, 
raw observation next is [-3.733333333333333, 67.0, 130.5, 0.0, 22.5, 23.1433549436383, -0.3015439136698067, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.35918744228993543, 0.67, 0.435, 0.0, 0.375, 0.42861291196985835, 0.39948536211006447, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3815686], dtype=float32), -0.11995901]. 
=============================================
[2019-04-24 09:46:53,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.46876073e-01 8.11170507e-03 6.54030126e-03 5.75016156e-06
 2.94435214e-08 5.33329512e-07 7.29763414e-08 1.23027805e-02
 4.26162690e-01 2.72632334e-08 6.83741641e-09], sum to 1.0000
[2019-04-24 09:46:53,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7561
[2019-04-24 09:46:53,572] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 19.0, 21.39697799029855, -0.6491779071345217, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2343600.0000, 
sim time next is 2344800.0000, 
raw observation next is [-2.466666666666667, 63.0, 0.0, 0.0, 19.0, 21.20185897031277, -0.5243128931791604, 0.0, 1.0, 55.0, 70.83592585615538], 
processed observation next is [0.0, 0.13043478260869565, 0.39427516158818104, 0.63, 0.0, 0.0, 0.08333333333333333, 0.2668215808593975, 0.32522903560694655, 0.0, 1.0, 0.8, 0.7083592585615538], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16537386], dtype=float32), 0.6205025]. 
=============================================
[2019-04-24 09:46:54,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.98554099e-01 3.17874830e-03 3.28818639e-03 4.01985631e-07
 1.77712123e-10 6.61294663e-08 4.54243726e-10 1.49977615e-03
 2.93478727e-01 1.03434206e-10 2.45943144e-11], sum to 1.0000
[2019-04-24 09:46:54,355] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7628
[2019-04-24 09:46:54,444] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 68.0, 0.0, 0.0, 19.0, 20.48084317097625, -0.5384756723636575, 0.0, 1.0, 55.0, 89.47463559805702], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2235600.0000, 
sim time next is 2236800.0000, 
raw observation next is [-5.2, 69.0, 0.0, 0.0, 19.0, 21.40772257226143, -0.4493358431081536, 0.0, 1.0, 55.0, 56.67412071755118], 
processed observation next is [1.0, 0.9130434782608695, 0.31855955678670367, 0.69, 0.0, 0.0, 0.08333333333333333, 0.2839768810217859, 0.3502213856306155, 0.0, 1.0, 0.8, 0.5667412071755118], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6257538], dtype=float32), -0.83293885]. 
=============================================
[2019-04-24 09:46:57,015] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7416686e-01 3.9753527e-03 1.5087406e-03 4.4131420e-07 4.7384947e-11
 2.4583116e-08 9.2484981e-10 9.6349150e-04 3.1938517e-01 2.0964042e-10
 6.5476864e-12], sum to 1.0000
[2019-04-24 09:46:57,017] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5912
[2019-04-24 09:46:57,029] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 22.5, 21.08392873232881, -0.6362711422598282, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2232000.0000, 
sim time next is 2233200.0000, 
raw observation next is [-5.0, 70.0, 0.0, 0.0, 19.0, 20.72997014159609, -0.6983943356016148, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.7, 0.0, 0.0, 0.08333333333333333, 0.22749751179967426, 0.26720188813279505, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8745123], dtype=float32), -0.7146561]. 
=============================================
[2019-04-24 09:47:01,120] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-24 09:47:01,159] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:47:01,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:01,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run3
[2019-04-24 09:47:01,161] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:47:01,182] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:01,184] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run3
[2019-04-24 09:47:01,243] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:47:01,244] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:01,259] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run3
[2019-04-24 09:48:28,704] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.20812261], dtype=float32), 0.29904434]
[2019-04-24 09:48:28,704] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-4.666666666666667, 43.0, 0.0, 0.0, 19.0, 19.52567624229322, -0.8274501115970541, 0.0, 1.0, 55.0, 86.69741652150925]
[2019-04-24 09:48:28,704] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 09:48:28,705] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [5.5142599e-01 6.5833577e-03 1.6858337e-02 1.0002804e-05 4.7512064e-08
 2.4461058e-06 2.7778862e-07 5.1185279e-03 4.2000094e-01 6.8145440e-08
 7.6708160e-09], sampled 0.30711077304212164
[2019-04-24 09:48:29,208] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.20812261], dtype=float32), 0.29904434]
[2019-04-24 09:48:29,208] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [3.2, 72.66666666666666, 59.16666666666666, 207.1666666666667, 22.5, 23.74228146676299, -0.1628552975603552, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 09:48:29,208] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 09:48:29,209] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [8.1718904e-01 6.0194364e-04 1.5960997e-03 1.1780662e-07 2.2857737e-11
 8.1788585e-09 1.9240005e-10 4.2844677e-04 1.8018444e-01 5.3836331e-11
 3.5188386e-12], sampled 0.7226201973618674
[2019-04-24 09:48:39,366] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.20812261], dtype=float32), 0.29904434]
[2019-04-24 09:48:39,366] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [-2.2, 88.0, 0.0, 0.0, 19.0, 23.63785859244819, 0.1984821323443069, 0.0, 1.0, 55.0, 61.48313930099209]
[2019-04-24 09:48:39,366] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 09:48:39,367] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [5.39644122e-01 1.71274354e-03 2.11617677e-03 1.18699489e-07
 1.98586581e-11 1.45088785e-08 5.53296187e-10 1.08092127e-03
 4.55445915e-01 2.76689002e-11 6.02028106e-12], sampled 0.17934124187931266
[2019-04-24 09:48:58,313] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2824.6836 91392.9189 256.6382
[2019-04-24 09:48:58,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:48:58,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:48:58,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:48:58,443] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:48:58,443] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:48:58,443] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:06,084] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2563.9619 104040.1379 -80.0078
[2019-04-24 09:49:06,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:49:06,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:49:06,105] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:49:06,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:06,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:06,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:10,456] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2556.0173 104793.2416 -245.8249
[2019-04-24 09:49:10,476] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:49:10,476] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:49:10,476] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:49:10,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:10,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:10,582] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:49:11,478] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 100000, evaluation results [100000.0, 2563.961947579623, 104040.13792722317, -80.00783960053157, 2824.6835921244974, 91392.91894011035, 256.6381990031371, 2556.0173264779282, 104793.2415593007, -245.82493991049455]
[2019-04-24 09:49:12,089] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.9268874e-01 3.0929805e-03 6.8432167e-03 1.6071479e-06 9.9727604e-10
 2.9108693e-07 2.4416403e-08 4.6957824e-03 3.9267734e-01 2.1267290e-09
 5.2629190e-10], sum to 1.0000
[2019-04-24 09:49:12,100] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7588
[2019-04-24 09:49:12,133] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.633333333333333, 64.0, 0.0, 0.0, 19.0, 22.27038532907229, -0.3249706430530769, 0.0, 1.0, 55.0, 65.57373948998942], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2346000.0000, 
sim time next is 2347200.0000, 
raw observation next is [-2.8, 65.0, 0.0, 0.0, 19.0, 22.50757781691065, -0.2948852039591873, 0.0, 1.0, 55.0, 47.46091718760727], 
processed observation next is [0.0, 0.17391304347826086, 0.38504155124653744, 0.65, 0.0, 0.0, 0.08333333333333333, 0.3756314847425542, 0.4017049320136042, 0.0, 1.0, 0.8, 0.4746091718760727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4919015], dtype=float32), -0.64427096]. 
=============================================
[2019-04-24 09:49:14,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4443187e-01 1.4872126e-03 1.1784741e-02 2.8183199e-06 1.4975400e-09
 1.8537088e-07 2.0820185e-08 2.3777841e-03 4.3991533e-01 1.7153277e-09
 1.0612912e-09], sum to 1.0000
[2019-04-24 09:49:14,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0628
[2019-04-24 09:49:14,176] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 47.0, 209.5, 365.0, 19.0, 21.77801314594399, -0.5393443674984125, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2376000.0000, 
sim time next is 2377200.0000, 
raw observation next is [-1.0, 49.33333333333334, 237.8333333333333, 404.3333333333334, 19.0, 21.20303413431641, -0.6383698002441721, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4349030470914128, 0.4933333333333334, 0.7927777777777776, 0.44677716390423583, 0.08333333333333333, 0.26691951119303425, 0.287210066585276, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25740904], dtype=float32), -0.5862543]. 
=============================================
[2019-04-24 09:49:20,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3865983e-01 1.6177288e-03 1.3714922e-03 1.6778633e-07 1.8296352e-11
 1.0262771e-08 1.2258762e-10 3.6857859e-04 3.5798213e-01 1.2734162e-11
 8.6409525e-12], sum to 1.0000
[2019-04-24 09:49:20,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9810
[2019-04-24 09:49:20,320] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-0.8, 47.66666666666667, 149.5, 49.33333333333333, 22.5, 23.76431923296166, -0.2542660348172323, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2544000.0000, 
sim time next is 2545200.0000, 
raw observation next is [-0.6, 47.0, 182.5, 58.0, 22.5, 23.85117247980942, -0.06135881196938055, 1.0, 1.0, 55.0, 69.25609920610275], 
processed observation next is [1.0, 0.4782608695652174, 0.44598337950138506, 0.47, 0.6083333333333333, 0.06408839779005525, 0.375, 0.48759770665078506, 0.47954706267687314, 1.0, 1.0, 0.8, 0.6925609920610275], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73748153], dtype=float32), 0.43163955]. 
=============================================
[2019-04-24 09:49:20,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8269510e-01 1.5245242e-03 4.6592108e-03 1.9870690e-07 1.2032446e-10
 2.5600471e-08 1.3079675e-09 7.3185848e-04 5.1038903e-01 1.4763846e-10
 1.0127364e-11], sum to 1.0000
[2019-04-24 09:49:20,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8043
[2019-04-24 09:49:20,447] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.366666666666666, 69.0, 0.0, 0.0, 19.0, 20.75116126208228, -0.4752378549548146, 0.0, 1.0, 55.0, 89.54816415369683], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2673600.0000, 
sim time next is 2674800.0000, 
raw observation next is [-5.0, 69.0, 0.0, 0.0, 19.0, 21.55227274262124, -0.4021810907497583, 0.0, 1.0, 55.0, 56.22131533189466], 
processed observation next is [1.0, 1.0, 0.32409972299168976, 0.69, 0.0, 0.0, 0.08333333333333333, 0.2960227285517701, 0.36593963641674726, 0.0, 1.0, 0.8, 0.5622131533189466], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.26674291], dtype=float32), -0.04868684]. 
=============================================
[2019-04-24 09:49:22,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9305424e-01 3.7276438e-03 3.9129294e-03 1.5231703e-07 6.4007090e-12
 5.0866849e-09 2.4504543e-10 3.9217164e-04 4.9891284e-01 1.1409540e-11
 1.7324158e-11], sum to 1.0000
[2019-04-24 09:49:22,339] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3245
[2019-04-24 09:49:22,357] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.333333333333334, 62.33333333333334, 112.8333333333333, 796.0, 22.5, 23.66631809783929, -0.1778550601247448, 1.0, 1.0, 55.0, 62.43493886486331], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2722800.0000, 
sim time next is 2724000.0000, 
raw observation next is [-6.666666666666667, 60.66666666666666, 112.3333333333333, 797.1666666666667, 22.5, 23.52830207296267, -0.1721954374234748, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.27793167128347185, 0.6066666666666666, 0.37444444444444436, 0.8808471454880296, 0.375, 0.4606918394135559, 0.4426015208588417, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6230476], dtype=float32), 0.6424601]. 
=============================================
[2019-04-24 09:49:29,209] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.9722277e-01 1.2618831e-03 1.6309413e-03 2.5306480e-07 2.7185003e-12
 4.1770987e-09 4.6539345e-11 9.8019233e-04 2.9890388e-01 4.1857854e-12
 2.8051962e-12], sum to 1.0000
[2019-04-24 09:49:29,252] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0059
[2019-04-24 09:49:29,273] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 31.66666666666667, 227.1666666666667, 144.1666666666667, 22.5, 24.04517581144076, -0.17656092845655, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2814000.0000, 
sim time next is 2815200.0000, 
raw observation next is [6.0, 30.0, 183.5, 86.5, 22.5, 23.24514002601665, -0.3078628780904114, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.6288088642659281, 0.3, 0.6116666666666667, 0.09558011049723757, 0.375, 0.43709500216805414, 0.39737904063652957, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0791284], dtype=float32), 0.32018852]. 
=============================================
[2019-04-24 09:49:30,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7736157e-01 3.5292885e-04 6.6115434e-04 3.6528409e-09 1.3536238e-13
 2.4270208e-10 1.4701762e-11 1.6202593e-04 2.2146225e-01 2.4306490e-13
 2.1190057e-14], sum to 1.0000
[2019-04-24 09:49:30,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7307
[2019-04-24 09:49:30,520] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 93.0, 95.66666666666666, 130.0, 22.5, 24.18035355219698, -0.1192877310556543, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2882400.0000, 
sim time next is 2883600.0000, 
raw observation next is [1.0, 93.0, 77.0, 78.0, 22.5, 23.60416842778568, -0.2340156817364431, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4903047091412743, 0.93, 0.25666666666666665, 0.0861878453038674, 0.375, 0.46701403564880667, 0.42199477275451897, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1238406], dtype=float32), -1.1662968]. 
=============================================
[2019-04-24 09:49:33,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7826353e-01 5.4326199e-04 1.1055975e-03 1.0048267e-08 9.0766918e-13
 1.7500215e-09 2.5995166e-11 7.2746258e-04 5.1936013e-01 6.2908153e-13
 4.0896876e-13], sum to 1.0000
[2019-04-24 09:49:33,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8191
[2019-04-24 09:49:33,751] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.666666666666667, 100.0, 0.0, 0.0, 19.0, 21.92557200251938, -0.3981668840422705, 0.0, 1.0, 55.0, 81.89920851142264], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3133200.0000, 
sim time next is 3134400.0000, 
raw observation next is [5.333333333333334, 100.0, 0.0, 0.0, 19.0, 22.37445548202395, -0.339215932265412, 0.0, 1.0, 55.0, 58.028812261521196], 
processed observation next is [1.0, 0.2608695652173913, 0.6103416435826409, 1.0, 0.0, 0.0, 0.08333333333333333, 0.36453795683532925, 0.386928022578196, 0.0, 1.0, 0.8, 0.580288122615212], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4394666], dtype=float32), -1.4138545]. 
=============================================
[2019-04-24 09:49:37,052] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2147965e-01 3.4340861e-04 1.0059808e-03 4.5549534e-08 2.2596525e-12
 9.7551345e-10 1.5994794e-11 1.6593168e-04 2.7700496e-01 4.2034527e-12
 3.4203155e-13], sum to 1.0000
[2019-04-24 09:49:37,053] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2702
[2019-04-24 09:49:37,077] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 100.0, 87.5, 0.0, 22.5, 22.3762198310262, -0.4826749637628343, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2905200.0000, 
sim time next is 2906400.0000, 
raw observation next is [2.0, 100.0, 85.83333333333334, 0.0, 22.5, 21.77652730127895, -0.4837425625720273, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.518005540166205, 1.0, 0.28611111111111115, 0.0, 0.375, 0.3147106084399125, 0.33875247914265755, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7229639], dtype=float32), 0.9803244]. 
=============================================
[2019-04-24 09:49:37,548] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3521025e-01 6.2463577e-03 1.3939110e-02 2.8086340e-06 1.1226111e-08
 6.7350470e-07 3.8577856e-08 3.8262135e-03 4.4077456e-01 1.5741024e-08
 2.2733395e-09], sum to 1.0000
[2019-04-24 09:49:37,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7902
[2019-04-24 09:49:37,614] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.6666666666666666, 39.66666666666666, 79.5, 641.8333333333334, 19.0, 21.24503419007821, -0.5729804228827432, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3080400.0000, 
sim time next is 3081600.0000, 
raw observation next is [1.0, 40.0, 70.5, 579.5, 19.0, 21.58895231282719, -0.3449646824852863, 0.0, 1.0, 55.0, 70.5152572841461], 
processed observation next is [0.0, 0.6956521739130435, 0.4903047091412743, 0.4, 0.235, 0.6403314917127072, 0.08333333333333333, 0.29907935940226577, 0.38501177250490454, 0.0, 1.0, 0.8, 0.705152572841461], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2703046], dtype=float32), 0.9142612]. 
=============================================
[2019-04-24 09:49:38,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.9561424e-01 4.5942524e-04 2.9511863e-04 4.1852189e-08 3.6615117e-13
 2.9783317e-10 8.5810274e-12 3.0355211e-04 2.0332761e-01 6.1310250e-13
 8.0671960e-14], sum to 1.0000
[2019-04-24 09:49:38,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2967
[2019-04-24 09:49:38,367] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 100.0, 63.5, 0.0, 22.5, 24.97645483659946, 0.1368434688454935, 1.0, 1.0, 55.0, 65.94118758266953], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2887200.0000, 
sim time next is 2888400.0000, 
raw observation next is [0.3333333333333333, 97.66666666666667, 73.16666666666666, 0.0, 22.5, 24.92500503068261, 0.006814377666807194, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4718374884579871, 0.9766666666666667, 0.24388888888888885, 0.0, 0.375, 0.577083752556884, 0.5022714592222691, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8085706], dtype=float32), 0.9855497]. 
=============================================
[2019-04-24 09:49:38,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5971180e-01 3.0999753e-04 2.6423304e-04 1.8113536e-08 3.2720061e-13
 2.4654054e-10 3.4956463e-12 2.7664899e-04 2.3943722e-01 2.3937414e-13
 2.8793943e-14], sum to 1.0000
[2019-04-24 09:49:38,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6735
[2019-04-24 09:49:38,851] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 100.0, 165.8333333333333, 0.0, 22.5, 23.88858375801897, 0.1065260035600277, 1.0, 1.0, 55.0, 80.77317142334668], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2899200.0000, 
sim time next is 2900400.0000, 
raw observation next is [2.0, 100.0, 151.6666666666667, 0.0, 22.5, 24.44361445302258, 0.03401438237297, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.518005540166205, 1.0, 0.5055555555555558, 0.0, 0.375, 0.5369678710852149, 0.5113381274576566, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8085706], dtype=float32), 0.9855497]. 
=============================================
[2019-04-24 09:49:42,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0281003e-01 7.5737044e-04 1.1916775e-03 8.8585939e-09 2.3678895e-12
 8.1666601e-10 2.8928235e-11 5.1012880e-04 3.9473081e-01 1.5680704e-12
 5.9347513e-14], sum to 1.0000
[2019-04-24 09:49:42,589] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1186
[2019-04-24 09:49:42,622] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 95.33333333333334, 0.0, 0.0, 19.0, 23.84822033934011, 0.09577601526981468, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3198000.0000, 
sim time next is 3199200.0000, 
raw observation next is [1.333333333333333, 97.66666666666666, 0.0, 0.0, 19.0, 23.36771908611279, 0.03236580256188089, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4995383194829178, 0.9766666666666666, 0.0, 0.0, 0.08333333333333333, 0.44730992384273244, 0.5107886008539603, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.40803233], dtype=float32), -0.6510453]. 
=============================================
[2019-04-24 09:49:43,043] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3130987e-01 1.5566965e-03 6.4929165e-03 5.3977419e-07 3.2468275e-10
 4.2478273e-08 1.0174719e-08 1.2629376e-03 3.5937694e-01 1.0754677e-09
 5.4975708e-11], sum to 1.0000
[2019-04-24 09:49:43,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2938
[2019-04-24 09:49:43,075] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 19.0, 21.14777665708859, -0.4881440698150202, 0.0, 1.0, 55.0, 80.74689417593699], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3096000.0000, 
sim time next is 3097200.0000, 
raw observation next is [-1.0, 94.66666666666667, 0.0, 0.0, 19.0, 21.70077991319559, -0.5767447832739275, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4349030470914128, 0.9466666666666668, 0.0, 0.0, 0.08333333333333333, 0.3083983260996324, 0.30775173890869084, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.73787504], dtype=float32), 0.1928086]. 
=============================================
[2019-04-24 09:49:43,144] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5548525e-01 3.5267193e-03 2.3241645e-02 2.5710347e-06 6.6357444e-09
 8.5120064e-08 3.6192208e-08 4.8972499e-03 4.1284648e-01 8.9989234e-09
 9.0168900e-10], sum to 1.0000
[2019-04-24 09:49:43,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1465
[2019-04-24 09:49:43,165] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 75.33333333333334, 15.33333333333333, 154.3333333333333, 19.0, 22.49805285338705, -0.446232439790009, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3086400.0000, 
sim time next is 3087600.0000, 
raw observation next is [-0.4, 78.66666666666667, 0.0, 0.0, 19.0, 21.68376244311669, -0.6001368263585422, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.45152354570637127, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.3069802035930576, 0.2999543912138193, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.317824], dtype=float32), -0.39657804]. 
=============================================
[2019-04-24 09:49:46,712] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4667189e-01 4.0250435e-03 1.4705794e-03 1.0598702e-07 9.1138676e-12
 1.7610006e-08 2.4694863e-10 9.2087261e-04 3.4691152e-01 1.7599167e-11
 2.2102136e-12], sum to 1.0000
[2019-04-24 09:49:46,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0827
[2019-04-24 09:49:46,752] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 22.79042418025611, -0.3095119145330463, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3481200.0000, 
sim time next is 3482400.0000, 
raw observation next is [-0.3333333333333333, 71.66666666666667, 0.0, 0.0, 22.5, 21.99482273728685, -0.410899249490835, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.4533702677747, 0.7166666666666667, 0.0, 0.0, 0.375, 0.33290189477390414, 0.363033583503055, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8956077], dtype=float32), -0.2734449]. 
=============================================
[2019-04-24 09:49:50,269] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.7474679e-01 1.1886782e-03 7.6297293e-03 1.4176946e-07 4.3277690e-11
 2.0328107e-08 1.0259521e-09 8.6291204e-04 5.1557165e-01 7.5681829e-11
 1.2856410e-11], sum to 1.0000
[2019-04-24 09:49:50,271] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5130
[2019-04-24 09:49:50,332] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 19.0, 21.49225091393946, -0.3917543088808171, 0.0, 1.0, 55.0, 76.37844466635015], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3387600.0000, 
sim time next is 3388800.0000, 
raw observation next is [-4.333333333333334, 67.33333333333334, 0.0, 0.0, 19.0, 22.22639639456623, -0.3453094922431419, 0.0, 1.0, 55.0, 51.05242532240905], 
processed observation next is [1.0, 0.21739130434782608, 0.3425669436749769, 0.6733333333333335, 0.0, 0.0, 0.08333333333333333, 0.35219969954718583, 0.3848968359189527, 0.0, 1.0, 0.8, 0.5105242532240905], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58279437], dtype=float32), -0.63266265]. 
=============================================
[2019-04-24 09:49:50,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6756386e-01 2.9520255e-03 1.0476563e-03 9.0100912e-08 4.1222607e-12
 4.7940318e-09 8.9709712e-11 3.7554331e-04 3.2806087e-01 1.0392757e-11
 3.6779078e-12], sum to 1.0000
[2019-04-24 09:49:50,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0392
[2019-04-24 09:49:50,476] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 47.66666666666666, 116.3333333333333, 815.1666666666667, 22.5, 24.87106850771781, 0.186646665884794, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3415200.0000, 
sim time next is 3416400.0000, 
raw observation next is [3.0, 49.0, 115.0, 811.5, 22.5, 24.50065281944217, 0.05190440917957987, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.38333333333333336, 0.8966850828729281, 0.375, 0.5417210682868475, 0.5173014697265267, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.59913594], dtype=float32), -0.8364026]. 
=============================================
[2019-04-24 09:49:52,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9145515e-01 4.1814402e-04 8.0017344e-04 5.9162620e-08 3.3973839e-12
 4.4931756e-09 1.3589601e-11 1.3512291e-04 2.0719126e-01 1.7578470e-11
 9.7136383e-13], sum to 1.0000
[2019-04-24 09:49:52,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5839
[2019-04-24 09:49:52,142] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 24.97944761210414, 0.1183709901651039, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3523200.0000, 
sim time next is 3524400.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 23.92734128062853, 0.1042259288259492, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.49394510671904407, 0.5347419762753164, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.394594], dtype=float32), 0.83761185]. 
=============================================
[2019-04-24 09:49:54,791] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9961348e-01 7.6018489e-04 7.5981452e-04 4.5201659e-08 3.3970517e-12
 3.0245011e-09 1.2371608e-10 6.7443296e-04 1.9819209e-01 1.0800709e-11
 1.1392531e-12], sum to 1.0000
[2019-04-24 09:49:54,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7705
[2019-04-24 09:49:54,831] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 116.0, 810.5, 22.5, 23.43600540019182, -0.08296296008393973, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3412800.0000, 
sim time next is 3414000.0000, 
raw observation next is [3.0, 46.33333333333334, 116.6666666666667, 814.8333333333334, 22.5, 23.60724630387405, -0.06503433659597134, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.46333333333333343, 0.388888888888889, 0.9003683241252303, 0.375, 0.46727052532283747, 0.4783218878013429, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.19234043], dtype=float32), 0.35783106]. 
=============================================
[2019-04-24 09:49:54,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6417459e-01 2.8437306e-03 5.4783719e-03 1.4968131e-06 2.8990628e-09
 1.5247325e-07 2.5659606e-08 8.0507882e-03 4.1945094e-01 2.9331129e-09
 2.2615064e-10], sum to 1.0000
[2019-04-24 09:49:54,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4408
[2019-04-24 09:49:54,951] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 61.33333333333334, 109.1666666666667, 744.3333333333334, 19.0, 21.37596129408475, -0.2492585125495986, 0.0, 1.0, 55.0, 78.2329273616802], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3579600.0000, 
sim time next is 3580800.0000, 
raw observation next is [-4.333333333333334, 57.66666666666667, 111.5, 767.6666666666667, 19.0, 22.15213028832122, -0.3039357306874568, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3425669436749769, 0.5766666666666667, 0.37166666666666665, 0.8482504604051566, 0.08333333333333333, 0.34601085736010173, 0.39868808977084774, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1380534], dtype=float32), 0.44663426]. 
=============================================
[2019-04-24 09:50:01,433] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6821035e-01 1.1703988e-03 5.7231967e-04 7.8262438e-08 2.2832862e-12
 1.8918525e-09 4.5082035e-11 3.1112693e-04 2.2973567e-01 1.0710333e-11
 1.3839932e-12], sum to 1.0000
[2019-04-24 09:50:01,440] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2809
[2019-04-24 09:50:01,462] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 69.0, 0.0, 0.0, 19.0, 24.67371777316909, 0.1761366776908053, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3789600.0000, 
sim time next is 3790800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 23.99436054345234, 0.04967568846529652, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.4995300452876951, 0.5165585628217655, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9477445], dtype=float32), -0.70826083]. 
=============================================
[2019-04-24 09:50:02,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4709687e-01 2.1837987e-03 1.1031138e-02 2.1525732e-06 5.7090621e-09
 3.5759294e-07 5.6223982e-08 5.2361912e-03 3.3444944e-01 7.1551702e-09
 1.6467425e-09], sum to 1.0000
[2019-04-24 09:50:02,297] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5071
[2019-04-24 09:50:02,312] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.333333333333334, 26.33333333333334, 0.0, 0.0, 19.0, 22.34679129671716, -0.1974090698276207, 0.0, 1.0, 55.0, 76.34970652379405], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3648000.0000, 
sim time next is 3649200.0000, 
raw observation next is [9.666666666666666, 25.66666666666666, 0.0, 0.0, 19.0, 23.06760657179624, -0.257326632761476, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.7303785780240075, 0.2566666666666666, 0.0, 0.0, 0.08333333333333333, 0.42230054764968666, 0.41422445574617467, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27039185], dtype=float32), 0.72721153]. 
=============================================
[2019-04-24 09:50:04,395] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.2896526e-01 7.7497214e-04 4.7579543e-03 5.5579767e-07 5.5972454e-10
 8.8710692e-08 1.6203674e-09 2.0638853e-03 3.6343718e-01 8.0708623e-10
 5.7626494e-11], sum to 1.0000
[2019-04-24 09:50:04,396] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5763
[2019-04-24 09:50:04,412] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 59.0, 0.0, 0.0, 19.0, 24.77125685416979, 0.1253262448640145, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3694800.0000, 
sim time next is 3696000.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 19.0, 24.17848458399158, 0.0201966598686028, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5734072022160666, 0.59, 0.0, 0.0, 0.08333333333333333, 0.5148737153326316, 0.5067322199562009, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.45977202], dtype=float32), 0.8429557]. 
=============================================
[2019-04-24 09:50:04,763] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.5116365e-01 1.0536293e-03 7.4321129e-03 4.7538214e-07 4.6780874e-10
 5.2902763e-08 2.4616842e-09 1.9954494e-03 5.3835458e-01 7.2695389e-10
 5.3111255e-11], sum to 1.0000
[2019-04-24 09:50:04,769] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3222
[2019-04-24 09:50:04,790] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 23.68041272740888, 0.03265454941462132, 0.0, 1.0, 55.0, 49.32421508718356], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3708000.0000, 
sim time next is 3709200.0000, 
raw observation next is [-1.0, 69.66666666666667, 0.0, 0.0, 19.0, 23.76548555050878, -0.1070132515917723, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.48045712920906514, 0.4643289161360759, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.45977202], dtype=float32), 0.8429557]. 
=============================================
[2019-04-24 09:50:04,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1030188e-01 3.7651995e-04 6.3501188e-04 4.8421946e-08 8.2281196e-12
 1.1431194e-08 5.0291851e-11 7.3232071e-04 2.8795430e-01 6.1653165e-12
 9.2016683e-13], sum to 1.0000
[2019-04-24 09:50:04,895] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1555
[2019-04-24 09:50:04,912] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 49.0, 0.0, 0.0, 22.5, 25.82260342891169, 0.4198250439182746, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3867600.0000, 
sim time next is 3868800.0000, 
raw observation next is [1.333333333333333, 50.0, 0.0, 0.0, 22.5, 25.22287981217746, 0.3220454307969889, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4995383194829178, 0.5, 0.0, 0.0, 0.375, 0.6019066510147884, 0.6073484769323296, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1792994], dtype=float32), 0.3009974]. 
=============================================
[2019-04-24 09:50:06,483] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5148039e-01 1.4839968e-02 9.2562074e-03 1.5396711e-06 3.3137124e-10
 3.0179513e-07 1.3189099e-08 1.8595915e-03 5.2256197e-01 8.8892416e-10
 3.8990078e-10], sum to 1.0000
[2019-04-24 09:50:06,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9974
[2019-04-24 09:50:06,534] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666667, 38.66666666666667, 0.0, 0.0, 19.0, 21.71383024187656, -0.5838379716562976, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4076400.0000, 
sim time next is 4077600.0000, 
raw observation next is [-4.333333333333334, 36.33333333333333, 0.0, 0.0, 19.0, 21.43282318466639, -0.487832885392927, 0.0, 1.0, 55.0, 69.8518958583396], 
processed observation next is [1.0, 0.17391304347826086, 0.3425669436749769, 0.3633333333333333, 0.0, 0.0, 0.08333333333333333, 0.28606859872219914, 0.33738903820235766, 0.0, 1.0, 0.8, 0.6985189585833961], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3627163], dtype=float32), -1.0688701]. 
=============================================
[2019-04-24 09:50:06,738] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.9972917e-01 5.0380663e-04 5.1781366e-04 4.2039453e-08 4.4817219e-12
 4.9291682e-09 2.3624640e-11 5.6902494e-04 1.9868009e-01 2.6891458e-11
 5.8872335e-13], sum to 1.0000
[2019-04-24 09:50:06,741] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9907
[2019-04-24 09:50:06,786] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.0, 48.0, 102.8333333333333, 771.1666666666667, 22.5, 24.92114881808126, 0.2750079676273245, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3854400.0000, 
sim time next is 3855600.0000, 
raw observation next is [2.0, 48.0, 96.5, 749.5, 22.5, 25.25669107915501, 0.5172531039517368, 1.0, 1.0, 55.0, 73.49464556204795], 
processed observation next is [1.0, 0.6521739130434783, 0.518005540166205, 0.48, 0.32166666666666666, 0.8281767955801105, 0.375, 0.604724256596251, 0.6724177013172455, 1.0, 1.0, 0.8, 0.7349464556204794], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3766518], dtype=float32), -1.025629]. 
=============================================
[2019-04-24 09:50:10,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7937430e-01 2.0283686e-03 1.3425377e-03 6.9326376e-07 1.9184992e-10
 4.1414381e-08 9.7034225e-10 1.5416128e-03 2.1571249e-01 2.6543473e-10
 5.6077507e-11], sum to 1.0000
[2019-04-24 09:50:10,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9873
[2019-04-24 09:50:10,926] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.0, 22.0, 78.0, 630.0, 22.5, 24.42743443778376, 0.2269417259780853, 1.0, 1.0, 55.0, 70.3413320138803], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4032000.0000, 
sim time next is 4033200.0000, 
raw observation next is [-1.333333333333333, 22.66666666666667, 70.66666666666667, 575.3333333333334, 22.5, 25.5387348994883, 0.3402893708538017, 1.0, 1.0, 55.0, 45.57734215251536], 
processed observation next is [1.0, 0.6956521739130435, 0.42566943674976926, 0.2266666666666667, 0.23555555555555557, 0.6357274401473297, 0.375, 0.6282279082906918, 0.6134297902846005, 1.0, 1.0, 0.8, 0.45577342152515354], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03357808], dtype=float32), 0.42860764]. 
=============================================
[2019-04-24 09:50:13,368] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1734259e-01 2.7073538e-03 1.0369730e-02 3.0777030e-06 2.6354341e-09
 3.5339667e-07 2.9631277e-08 1.7839912e-03 3.6779284e-01 3.0083194e-09
 7.0482248e-10], sum to 1.0000
[2019-04-24 09:50:13,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8870
[2019-04-24 09:50:13,562] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-13.66666666666667, 67.0, 0.0, 0.0, 22.5, 19.0822128407455, -1.154140597977988, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4000800.0000, 
sim time next is 4002000.0000, 
raw observation next is [-13.33333333333333, 65.0, 15.5, 73.99999999999999, 22.5, 19.35423201457293, -0.811014093917323, 1.0, 1.0, 55.0, 109.54092841157805], 
processed observation next is [1.0, 0.30434782608695654, 0.09325946445060027, 0.65, 0.051666666666666666, 0.08176795580110496, 0.375, 0.11285266788107744, 0.22966196869422564, 1.0, 1.0, 0.8, 1.0954092841157805], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.61541176], dtype=float32), 1.4585708]. 
=============================================
[2019-04-24 09:50:17,230] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5686182e-01 2.7443294e-03 8.8328933e-03 1.1290261e-06 2.9183238e-09
 9.8649866e-07 9.4624237e-09 1.2661798e-03 4.3029264e-01 1.0299412e-09
 5.9544220e-10], sum to 1.0000
[2019-04-24 09:50:17,231] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6135
[2019-04-24 09:50:17,287] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 19.0, 20.78651725342509, -0.7141274779923933, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4066800.0000, 
sim time next is 4068000.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 19.0, 20.97312795349269, -0.4978227877156991, 0.0, 1.0, 55.0, 83.18905697268522], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.41, 0.0, 0.0, 0.08333333333333333, 0.24776066279105743, 0.33405907076143365, 0.0, 1.0, 0.8, 0.8318905697268523], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9317173], dtype=float32), 1.664212]. 
=============================================
[2019-04-24 09:50:19,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8497715e-01 9.7633008e-04 1.8480847e-03 7.6152613e-09 1.4258883e-12
 5.1058885e-10 5.0529018e-11 9.0402050e-04 4.1129443e-01 2.4998211e-12
 4.3591606e-13], sum to 1.0000
[2019-04-24 09:50:19,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5386
[2019-04-24 09:50:19,949] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.166666666666667, 72.33333333333334, 0.0, 0.0, 19.0, 24.34312216949974, 0.1014966867161005, 0.0, 1.0, 55.0, 46.1356353188411], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4342800.0000, 
sim time next is 4344000.0000, 
raw observation next is [3.033333333333333, 73.66666666666667, 0.0, 0.0, 19.0, 24.17510142331069, -0.04378644498120445, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.5466297322253002, 0.7366666666666667, 0.0, 0.0, 0.08333333333333333, 0.5145917852758908, 0.4854045183395985, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6329253], dtype=float32), -0.30489564]. 
=============================================
[2019-04-24 09:50:21,102] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5123072e-01 9.8565163e-04 2.4714507e-03 3.7946182e-07 1.1658643e-10
 7.8240312e-08 1.9482564e-09 2.1845209e-03 2.4312720e-01 8.4857399e-10
 1.9423957e-11], sum to 1.0000
[2019-04-24 09:50:21,105] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4570
[2019-04-24 09:50:21,119] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 69.0, 0.0, 0.0, 19.0, 23.34801604576558, 0.05665771832000353, 0.0, 1.0, 55.0, 75.73469439989134], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4302000.0000, 
sim time next is 4303200.0000, 
raw observation next is [5.8, 70.33333333333334, 0.0, 0.0, 19.0, 23.95252736935027, -0.02120171725864285, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.6232686980609419, 0.7033333333333335, 0.0, 0.0, 0.08333333333333333, 0.49604394744585595, 0.4929327609137857, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42156094], dtype=float32), -0.390401]. 
=============================================
[2019-04-24 09:50:21,669] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.5860354e-01 1.1450088e-03 1.7606373e-03 3.2662662e-08 5.6453887e-12
 3.8898316e-09 1.8964740e-11 7.4964931e-04 1.3774112e-01 7.2920047e-12
 1.5093434e-12], sum to 1.0000
[2019-04-24 09:50:21,670] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0598
[2019-04-24 09:50:21,691] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 255.5, 80.5, 22.5, 23.2500300279419, -0.1301203005278041, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4543200.0000, 
sim time next is 4544400.0000, 
raw observation next is [3.0, 47.66666666666667, 261.1666666666666, 102.1666666666667, 22.5, 23.2315775733851, -0.1203023772946471, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.47666666666666674, 0.8705555555555552, 0.11289134438305713, 0.375, 0.4359647977820916, 0.45989920756845093, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.1157818], dtype=float32), 1.8592213]. 
=============================================
[2019-04-24 09:50:23,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3839703e-01 4.3846760e-04 1.0710112e-03 1.3257335e-07 1.9063195e-11
 9.6893933e-09 1.3390018e-10 2.5929525e-04 1.5983412e-01 3.5937978e-11
 5.6300099e-12], sum to 1.0000
[2019-04-24 09:50:23,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1185
[2019-04-24 09:50:23,329] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 22.61089252297383, -0.2120146105984154, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4558800.0000, 
sim time next is 4560000.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 22.47127822647455, -0.2539071165735274, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.3726065188728791, 0.4153642944754909, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.74859583], dtype=float32), -0.14303087]. 
=============================================
[2019-04-24 09:50:23,354] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.007854]
 [60.39538 ]
 [60.889774]
 [61.34731 ]
 [61.849483]
 [62.165207]
 [62.555737]
 [63.194447]
 [63.48586 ]
 [64.01863 ]
 [64.32784 ]
 [64.67511 ]
 [65.28226 ]
 [65.46758 ]
 [65.49604 ]
 [65.46014 ]
 [65.748405]
 [64.99035 ]
 [65.49488 ]
 [66.18776 ]
 [67.17644 ]
 [68.12089 ]
 [67.023865]
 [67.55021 ]
 [67.988754]], R is [[60.13119888]
 [60.52988815]
 [60.92459106]
 [61.31534576]
 [61.70219421]
 [62.08517456]
 [62.46432495]
 [62.83968353]
 [63.21128845]
 [63.57917786]
 [63.94338608]
 [64.30395508]
 [64.66091919]
 [65.01431274]
 [65.36417389]
 [65.71053314]
 [66.05342865]
 [65.39289856]
 [65.7389679 ]
 [66.08158112]
 [66.42076874]
 [66.75656128]
 [66.08899689]
 [66.42810822]
 [66.76382446]].
[2019-04-24 09:50:23,584] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.9943060e-01 1.5399932e-03 5.3507295e-03 1.2564934e-07 1.4340876e-11
 7.3261228e-09 1.0091303e-10 7.5798662e-04 4.9292055e-01 9.7253117e-12
 3.8556445e-12], sum to 1.0000
[2019-04-24 09:50:23,587] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2471
[2019-04-24 09:50:23,644] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 73.0, 20.5, 28.49999999999999, 22.5, 22.98129902402979, -0.1000007172465239, 1.0, 1.0, 55.0, 61.69333769053276], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4606800.0000, 
sim time next is 4608000.0000, 
raw observation next is [-2.0, 71.0, 61.5, 85.5, 22.5, 23.61297446383832, -0.1653219577938872, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.71, 0.205, 0.09447513812154697, 0.375, 0.4677478719865267, 0.44489268073537097, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9358092], dtype=float32), -0.65682316]. 
=============================================
[2019-04-24 09:50:30,686] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.4238964e-01 4.4114576e-04 1.0069093e-03 2.3938332e-08 7.9997953e-12
 2.0292099e-09 2.6156376e-11 4.9726490e-04 1.5566495e-01 5.5783373e-12
 6.3965678e-13], sum to 1.0000
[2019-04-24 09:50:30,698] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0359
[2019-04-24 09:50:30,731] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 255.5, 80.5, 22.5, 23.64868025391954, -0.05597496999480468, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4543200.0000, 
sim time next is 4544400.0000, 
raw observation next is [3.0, 47.66666666666667, 261.1666666666666, 102.1666666666667, 22.5, 23.42789024364482, -0.05450813275671607, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.47666666666666674, 0.8705555555555552, 0.11289134438305713, 0.375, 0.4523241869704018, 0.481830622414428, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8377626], dtype=float32), -0.26959014]. 
=============================================
[2019-04-24 09:50:31,779] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.9544171e-01 5.3919830e-05 4.8954610e-04 2.9169540e-09 2.4675346e-13
 2.5653102e-10 2.0862767e-12 1.1934002e-04 1.0389549e-01 2.4805161e-13
 1.7029665e-13], sum to 1.0000
[2019-04-24 09:50:31,780] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6489
[2019-04-24 09:50:31,815] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 160.5, 3.0, 22.5, 23.62525169459029, -0.1343457000553359, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4708800.0000, 
sim time next is 4710000.0000, 
raw observation next is [1.0, 86.0, 125.5, 0.9999999999999998, 22.5, 22.95686545378162, -0.2510631041677841, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 0.86, 0.41833333333333333, 0.0011049723756906074, 0.375, 0.4130721211484684, 0.41631229861073865, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6291542], dtype=float32), 1.4329067]. 
=============================================
[2019-04-24 09:50:31,853] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[70.08773 ]
 [70.23912 ]
 [69.99213 ]
 [69.753975]
 [69.464325]
 [69.002106]
 [67.739655]
 [66.67373 ]
 [66.643105]
 [65.16728 ]
 [65.52225 ]
 [66.11508 ]
 [66.218605]
 [66.46159 ]
 [66.531654]
 [66.27807 ]
 [66.900444]
 [66.80796 ]
 [66.71788 ]
 [66.36537 ]
 [66.17518 ]
 [64.59336 ]
 [64.26649 ]
 [63.02763 ]
 [62.599415]], R is [[70.06150055]
 [70.36088562]
 [70.65727997]
 [70.95070648]
 [71.24120331]
 [71.52879333]
 [70.81350708]
 [70.10536957]
 [70.40431976]
 [69.70027924]
 [70.00328064]
 [70.30324554]
 [70.6002121 ]
 [70.89421082]
 [71.18527222]
 [71.47341919]
 [71.75868225]
 [72.04109955]
 [72.32068634]
 [72.59748077]
 [72.87150574]
 [72.14279175]
 [72.42136383]
 [71.69715118]
 [71.98017883]].
[2019-04-24 09:50:37,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:37,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1930065e-01 3.8004776e-03 1.8341594e-03 1.5621033e-07 2.1607037e-11
 6.1794396e-09 1.8400131e-10 6.9176272e-04 1.7437281e-01 1.8406582e-11
 9.6238104e-12], sum to 1.0000
[2019-04-24 09:50:37,528] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4707
[2019-04-24 09:50:37,560] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 27.66666666666667, 121.1666666666667, 838.0, 22.5, 24.81997203135118, 0.1196447660695427, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4965600.0000, 
sim time next is 4966800.0000, 
raw observation next is [5.0, 26.33333333333333, 122.1666666666667, 848.3333333333334, 22.5, 24.85368658309249, 0.1384611159323225, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6011080332409973, 0.2633333333333333, 0.4072222222222223, 0.9373848987108656, 0.375, 0.5711405485910408, 0.5461537053107742, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16564672], dtype=float32), 0.5452379]. 
=============================================
[2019-04-24 09:50:37,712] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:38,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:38,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:38,503] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run3
[2019-04-24 09:50:38,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6376426e-01 7.7578874e-04 1.1409557e-03 8.0000007e-08 1.1393370e-11
 9.1131707e-09 3.2232009e-11 5.1396823e-04 2.3380491e-01 7.2234423e-12
 5.5938842e-13], sum to 1.0000
[2019-04-24 09:50:38,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6245
[2019-04-24 09:50:38,629] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 25.0, 17.0, 152.0, 22.5, 25.41093848662791, 0.365746958718867, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4989600.0000, 
sim time next is 4990800.0000, 
raw observation next is [6.0, 24.33333333333334, 0.0, 0.0, 22.5, 25.41329973804985, 0.3531076898546314, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.2433333333333334, 0.0, 0.0, 0.375, 0.6177749781708209, 0.6177025632848772, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3460513], dtype=float32), -1.2486602]. 
=============================================
[2019-04-24 09:50:42,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:42,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:43,236] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:43,236] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:43,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run3
[2019-04-24 09:50:43,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:43,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:43,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:43,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:43,933] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:43,988] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:44,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6800579e-01 9.7773247e-04 8.0759911e-04 1.7514218e-07 4.7575669e-11
 4.2245546e-08 4.8974058e-10 1.8657317e-03 2.2834292e-01 9.1293327e-11
 1.3028014e-11], sum to 1.0000
[2019-04-24 09:50:44,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2160
[2019-04-24 09:50:44,424] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 47.33333333333333, 15.5, 93.33333333333331, 22.5, 22.27746133294231, -0.320285923101248, 1.0, 1.0, 55.0, 91.4551342753062], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4952400.0000, 
sim time next is 4953600.0000, 
raw observation next is [-2.0, 46.0, 46.5, 280.0, 22.5, 22.84078170543371, -0.3737541748490565, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.46, 0.155, 0.30939226519337015, 0.375, 0.4033984754528091, 0.3754152750503145, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4678077], dtype=float32), 0.06434502]. 
=============================================
[2019-04-24 09:50:44,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:44,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:44,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:44,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run3
[2019-04-24 09:50:44,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:44,719] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:44,720] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:44,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run3
[2019-04-24 09:50:44,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:44,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:44,823] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run3
[2019-04-24 09:50:45,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:45,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:45,455] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run3
[2019-04-24 09:50:47,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:47,310] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:48,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:48,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:48,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run3
[2019-04-24 09:50:48,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:48,467] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:48,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:48,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:49,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:49,126] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:49,126] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:49,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run3
[2019-04-24 09:50:49,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:49,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:49,759] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:49,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run3
[2019-04-24 09:50:49,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:49,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:49,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run3
[2019-04-24 09:50:50,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8459513e-01 8.7066519e-04 8.5334794e-04 5.3638303e-08 9.7553797e-12
 4.9318136e-09 1.8138335e-11 2.9080367e-04 2.1338992e-01 4.5539076e-12
 1.5795081e-12], sum to 1.0000
[2019-04-24 09:50:50,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2666
[2019-04-24 09:50:50,272] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.666666666666666, 25.33333333333333, 115.6666666666667, 853.1666666666667, 22.5, 24.70722118217341, 0.2036384159862519, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4974000.0000, 
sim time next is 4975200.0000, 
raw observation next is [8.0, 26.0, 113.0, 839.5, 22.5, 24.69859798490279, 0.2380951353403698, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.6842105263157896, 0.26, 0.37666666666666665, 0.9276243093922651, 0.375, 0.5582164987418992, 0.5793650451134565, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.048771], dtype=float32), -0.38232958]. 
=============================================
[2019-04-24 09:50:50,623] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:50,799] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:51,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:51,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:51,624] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run3
[2019-04-24 09:50:52,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:52,436] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:52,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:52,703] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:52,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:53,063] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:53,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:53,253] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:53,255] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run3
[2019-04-24 09:50:53,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:53,437] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:53,439] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run3
[2019-04-24 09:50:53,704] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:53,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:53,706] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run3
[2019-04-24 09:50:54,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:55,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:55,183] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:55,527] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:50:55,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:55,666] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:55,668] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run3
[2019-04-24 09:50:56,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:50:56,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:50:56,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run3
[2019-04-24 09:51:25,877] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.0933773e-01 1.8204744e-03 5.5082515e-03 2.7980076e-07 2.9034178e-10
 3.3403953e-08 2.3716098e-09 5.7308743e-04 5.8276021e-01 1.4433536e-10
 3.7135680e-11], sum to 1.0000
[2019-04-24 09:51:25,877] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7406
[2019-04-24 09:51:25,994] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 19.0, 20.00513436983077, -0.9540286680102521, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 171600.0000, 
sim time next is 172800.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 19.0, 19.96918794181492, -0.7507325984472989, 0.0, 1.0, 55.0, 86.83926991895744], 
processed observation next is [1.0, 0.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.08333333333333333, 0.16409899515124327, 0.24975580051756704, 0.0, 1.0, 0.8, 0.8683926991895744], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30854687], dtype=float32), 0.0367514]. 
=============================================
[2019-04-24 09:51:33,329] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2028960e-01 5.8528311e-03 5.2271564e-03 8.6919380e-07 5.3303195e-10
 3.1406705e-07 1.7609427e-08 2.6687325e-03 4.6596047e-01 1.1158269e-09
 5.3513760e-10], sum to 1.0000
[2019-04-24 09:51:33,329] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1883
[2019-04-24 09:51:33,346] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 53.0, 0.0, 0.0, 19.0, 19.84839246673869, -0.9298983996640015, 0.0, 1.0, 55.0, 55.26104891217763], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 440400.0000, 
sim time next is 441600.0000, 
raw observation next is [-10.8, 51.0, 0.0, 0.0, 19.0, 19.85047520059407, -1.103693263925479, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.1634349030470914, 0.51, 0.0, 0.0, 0.08333333333333333, 0.1542062667161724, 0.13210224535817364, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.740747], dtype=float32), -1.094011]. 
=============================================
[2019-04-24 09:51:47,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2601782e-01 4.9111727e-03 2.0098550e-02 4.5223824e-06 1.4540121e-08
 2.9191943e-07 2.3369974e-07 6.7338278e-03 5.4223359e-01 2.1333882e-08
 6.0730740e-09], sum to 1.0000
[2019-04-24 09:51:47,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0129
[2019-04-24 09:51:47,575] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.433333333333334, 59.66666666666666, 123.6666666666667, 98.83333333333334, 19.0, 19.8600725676527, -0.8877460193032563, 0.0, 1.0, 55.0, 69.21636368300196], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 650400.0000, 
sim time next is 651600.0000, 
raw observation next is [-2.3, 59.0, 147.0, 96.5, 19.0, 20.18655123526703, -1.009934749811103, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.3988919667590028, 0.59, 0.49, 0.10662983425414364, 0.08333333333333333, 0.18221260293891905, 0.16335508339629898, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09875259], dtype=float32), 1.2073202]. 
=============================================
[2019-04-24 09:51:48,479] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0981367e-01 4.7921455e-03 7.5585227e-03 2.5168752e-06 4.2800279e-09
 3.0242089e-07 1.8177069e-08 2.7879020e-03 4.7504500e-01 3.6424863e-09
 7.3594247e-10], sum to 1.0000
[2019-04-24 09:51:48,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3272
[2019-04-24 09:51:48,582] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.33333333333334, 0.0, 0.0, 19.0, 20.19222636462654, -0.8173463175048141, 0.0, 1.0, 55.0, 52.055155090952084], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 613200.0000, 
sim time next is 614400.0000, 
raw observation next is [-3.899999999999999, 78.66666666666667, 0.0, 0.0, 19.0, 20.15427869087179, -0.9751518325213983, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.35457063711911363, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.17952322423931596, 0.17494938915953392, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0950577], dtype=float32), -1.1811645]. 
=============================================
[2019-04-24 09:51:55,838] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.8214779e-01 7.9655397e-04 8.2676793e-03 1.8710629e-07 1.0010174e-10
 5.4396541e-08 4.0290811e-09 1.1248230e-03 6.0766292e-01 3.9679457e-10
 1.9441247e-11], sum to 1.0000
[2019-04-24 09:51:55,840] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8931
[2019-04-24 09:51:55,919] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 85.66666666666667, 0.0, 0.0, 19.0, 21.67386593180797, -0.5125623695619558, 0.0, 1.0, 55.0, 49.076137147217665], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 591600.0000, 
sim time next is 592800.0000, 
raw observation next is [-2.8, 84.33333333333333, 0.0, 0.0, 19.0, 21.71444331504473, -0.5047958505830236, 0.0, 1.0, 55.0, 48.942474518103005], 
processed observation next is [0.0, 0.8695652173913043, 0.38504155124653744, 0.8433333333333333, 0.0, 0.0, 0.08333333333333333, 0.3095369429203941, 0.3317347164723255, 0.0, 1.0, 0.8, 0.4894247451810301], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2914158], dtype=float32), -0.13932997]. 
=============================================
[2019-04-24 09:52:08,706] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.8756918e-01 8.3224068e-04 1.0519671e-03 3.6735990e-08 2.6095567e-12
 1.0525997e-09 1.6190941e-11 2.9886112e-04 4.1024768e-01 3.7986788e-12
 2.0679075e-12], sum to 1.0000
[2019-04-24 09:52:08,781] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2515
[2019-04-24 09:52:08,849] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 46.66666666666667, 87.5, 763.1666666666667, 22.5, 23.85504703001713, -0.2527969164639268, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 740400.0000, 
sim time next is 741600.0000, 
raw observation next is [0.5, 45.0, 84.5, 743.5, 22.5, 23.30483253306753, -0.2422195400105116, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.4764542936288089, 0.45, 0.2816666666666667, 0.8215469613259668, 0.375, 0.44206937775562744, 0.41926015332982947, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.82066816], dtype=float32), 1.2154148]. 
=============================================
[2019-04-24 09:52:13,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2200661e-01 5.6786678e-04 3.1546154e-04 4.3026073e-08 1.8227603e-11
 1.7397207e-08 2.5543949e-11 4.6435691e-04 7.6645613e-02 2.1523377e-11
 7.1603812e-12], sum to 1.0000
[2019-04-24 09:52:13,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9577
[2019-04-24 09:52:14,035] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [17.7, 50.0, 18.0, 1.5, 22.5, 26.89044537081408, 0.7670327370581074, 1.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1098000.0000, 
sim time next is 1099200.0000, 
raw observation next is [17.16666666666667, 51.0, 0.0, 0.0, 22.5, 27.27201711311642, 0.7615049553540342, 1.0, 0.0, 55.0, 55.06852943471697], 
processed observation next is [1.0, 0.7391304347826086, 0.9381348107109884, 0.51, 0.0, 0.0, 0.375, 0.7726680927597016, 0.7538349851180114, 1.0, 0.0, 0.8, 0.5506852943471697], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39812374], dtype=float32), 0.09387835]. 
=============================================
[2019-04-24 09:52:15,627] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4301947e-01 9.9711958e-04 2.8074523e-03 1.8697899e-07 1.7093462e-11
 7.1914226e-09 2.7753805e-10 1.3334971e-03 4.5184222e-01 2.4210287e-11
 6.2210966e-12], sum to 1.0000
[2019-04-24 09:52:15,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2393
[2019-04-24 09:52:15,686] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.9, 70.66666666666666, 107.3333333333333, 52.16666666666666, 22.5, 23.19275439632752, -0.4475083979704499, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 726000.0000, 
sim time next is 727200.0000, 
raw observation next is [-1.7, 68.0, 120.0, 58.5, 22.5, 22.63025858024074, -0.5416477475754254, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4155124653739613, 0.68, 0.4, 0.06464088397790055, 0.375, 0.3858548816867282, 0.3194507508081915, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9566, 
noisyNet noise sample is [array([-0.930421], dtype=float32), 0.045242887]. 
=============================================
[2019-04-24 09:52:16,549] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2647235e-01 8.2598184e-04 1.7973679e-03 2.1412040e-08 2.1075210e-12
 8.3353840e-10 1.0151080e-10 1.2791820e-03 3.6962506e-01 7.5370618e-13
 5.0395799e-13], sum to 1.0000
[2019-04-24 09:52:16,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1179
[2019-04-24 09:52:16,588] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 19.0, 22.48532090854654, -0.2015186919331831, 0.0, 1.0, 55.0, 71.6585236440302], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 969600.0000, 
sim time next is 970800.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 19.0, 22.83154352242212, -0.2910956626147611, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.08333333333333333, 0.40262862686851, 0.4029681124617463, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9728554], dtype=float32), -0.6145676]. 
=============================================
[2019-04-24 09:52:19,792] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.2170687e-01 7.1624888e-04 1.6890453e-03 3.9680472e-08 1.0181525e-11
 3.4451244e-09 2.7484887e-10 2.0165115e-03 2.7387130e-01 5.0832425e-11
 1.4180061e-12], sum to 1.0000
[2019-04-24 09:52:19,801] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1697
[2019-04-24 09:52:19,880] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.1, 77.0, 0.0, 0.0, 19.0, 24.62471666276628, 0.4457077972162444, 0.0, 1.0, 55.0, 64.23081220238404], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1134000.0000, 
sim time next is 1135200.0000, 
raw observation next is [11.1, 77.0, 0.0, 0.0, 19.0, 24.99153790639274, 0.3592917097142139, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.7700831024930749, 0.77, 0.0, 0.0, 0.08333333333333333, 0.5826281588660617, 0.6197639032380713, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9020154], dtype=float32), -0.71063]. 
=============================================
[2019-04-24 09:52:25,848] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2114143e-01 5.2250858e-04 2.3039025e-03 1.7979422e-08 5.7021874e-12
 6.0164473e-10 3.2442233e-11 8.7797194e-04 3.7515411e-01 9.1961222e-12
 1.7487640e-13], sum to 1.0000
[2019-04-24 09:52:25,848] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5982
[2019-04-24 09:52:26,061] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 91.33333333333333, 0.0, 0.0, 19.0, 22.08322440617627, -0.4335580461968453, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 952800.0000, 
sim time next is 954000.0000, 
raw observation next is [5.5, 89.0, 0.0, 0.0, 19.0, 21.56110301723529, -0.5309710283818464, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6149584487534627, 0.89, 0.0, 0.0, 0.08333333333333333, 0.2967585847696075, 0.3230096572060512, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6899022], dtype=float32), 0.018438177]. 
=============================================
[2019-04-24 09:52:26,658] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-24 09:52:26,669] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:52:26,669] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:52:26,672] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run4
[2019-04-24 09:52:26,681] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:52:26,742] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:52:26,745] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run4
[2019-04-24 09:52:26,816] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:52:26,817] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:52:26,819] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run4
[2019-04-24 09:53:16,250] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.21197201], dtype=float32), 0.30377156]
[2019-04-24 09:53:16,250] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [17.10222722, 72.241776, 197.85549865, 0.0, 19.0, 24.80831193614957, 0.3818337762690814, 0.0, 0.0, 15.0, 0.0]
[2019-04-24 09:53:16,250] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 09:53:16,251] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [8.6896908e-01 5.8913202e-04 2.4708582e-03 6.5419351e-07 1.1733978e-09
 5.5141047e-08 2.1100361e-09 1.5871729e-03 1.2638308e-01 1.4534619e-09
 1.1368770e-10], sampled 0.11608189702201344
[2019-04-24 09:54:09,851] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2850.2165 89229.9680 174.6198
[2019-04-24 09:54:09,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:09,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:09,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:09,871] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:10,017] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:10,017] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:10,017] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:10,017] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:15,085] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.21197201], dtype=float32), 0.30377156]
[2019-04-24 09:54:15,085] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-2.026270846333333, 34.71534051, 68.15084400833334, 355.99255075, 22.5, 22.85377520361768, -0.3410398239605019, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 09:54:15,086] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 09:54:15,086] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [7.1839726e-01 5.9931702e-03 6.1303983e-03 2.4590922e-06 2.5322653e-09
 3.2261192e-07 1.6693869e-08 3.6625084e-03 2.6581383e-01 4.1952832e-09
 8.5401258e-10], sampled 0.6676787756315118
[2019-04-24 09:54:18,871] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2597.5150 100486.4179 -171.2522
[2019-04-24 09:54:18,891] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:18,891] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:18,891] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:18,891] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:18,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:18,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:18,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:18,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:25,988] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2583.0422 103594.9545 -246.7317
[2019-04-24 09:54:26,009] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:26,009] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:26,009] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:26,009] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:54:26,110] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:26,110] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:26,110] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:26,110] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:54:27,011] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 150000, evaluation results [150000.0, 2597.5150202478035, 100486.41789139678, -171.25222177876205, 2850.2165176570056, 89229.96803255867, 174.61982462687465, 2583.042198304563, 103594.95451872352, -246.7317164278761]
[2019-04-24 09:54:28,770] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5693178e-01 2.0425476e-03 2.5994256e-03 7.7469184e-07 7.8086637e-10
 7.0224083e-08 3.7207040e-09 1.5993596e-03 2.3682605e-01 9.6518893e-10
 8.1757920e-11], sum to 1.0000
[2019-04-24 09:54:28,774] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3231
[2019-04-24 09:54:28,787] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 24.68419512030239, 0.3515875025522242, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1233600.0000, 
sim time next is 1234800.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 24.44765504403692, 0.3163613043059147, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.5373045870030767, 0.6054537681019716, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5173963], dtype=float32), -1.0536685]. 
=============================================
[2019-04-24 09:54:34,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8513948e-01 1.6258698e-03 1.9498056e-03 1.6753186e-08 2.3855941e-12
 1.2551882e-09 5.2797083e-11 1.3053936e-03 3.0997941e-01 3.6773670e-12
 4.4513015e-13], sum to 1.0000
[2019-04-24 09:54:34,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3447
[2019-04-24 09:54:34,557] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 92.0, 0.0, 0.0, 19.0, 22.06956166247691, -0.2249143765854239, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1310400.0000, 
sim time next is 1311600.0000, 
raw observation next is [2.0, 92.0, 0.0, 0.0, 19.0, 21.92227214626227, -0.2539697602931167, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.518005540166205, 0.92, 0.0, 0.0, 0.08333333333333333, 0.32685601218852245, 0.4153434132356278, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2985657], dtype=float32), 0.9467866]. 
=============================================
[2019-04-24 09:54:38,129] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6708165e-01 2.8093248e-03 8.3756523e-04 3.0891989e-08 6.6425896e-13
 6.2000094e-10 6.9291868e-12 9.7513164e-04 3.2829633e-01 3.9909528e-13
 2.4664201e-13], sum to 1.0000
[2019-04-24 09:54:38,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3496
[2019-04-24 09:54:38,148] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.966666666666667, 73.33333333333334, 102.0, 119.1666666666667, 22.5, 24.39927293867682, 0.2627353195796284, 1.0, 1.0, 55.0, 64.71124078153503], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1588800.0000, 
sim time next is 1590000.0000, 
raw observation next is [7.333333333333333, 70.66666666666666, 129.1666666666667, 128.0, 22.5, 25.08098058694913, 0.2228505674931516, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6657433056325024, 0.7066666666666666, 0.4305555555555557, 0.1414364640883978, 0.375, 0.5900817155790943, 0.5742835224977172, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.2993708], dtype=float32), 1.0761238]. 
=============================================
[2019-04-24 09:54:38,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.84734 ]
 [70.556496]
 [71.0114  ]
 [69.7859  ]
 [69.696045]
 [69.875275]
 [69.72263 ]
 [69.03988 ]
 [67.92213 ]
 [68.164696]
 [67.007835]
 [67.10245 ]
 [65.80717 ]
 [65.99571 ]
 [66.26894 ]
 [65.38662 ]
 [65.72986 ]
 [66.277306]
 [66.578766]
 [66.89914 ]
 [67.49642 ]
 [67.94888 ]
 [68.32683 ]
 [68.64774 ]
 [69.09639 ]], R is [[71.789711  ]
 [71.07181549]
 [71.36109924]
 [70.64749146]
 [70.94101715]
 [71.23160553]
 [71.51928711]
 [71.80409241]
 [71.08605194]
 [71.37519073]
 [70.66143799]
 [70.95482635]
 [70.2452774 ]
 [70.54282379]
 [70.83739471]
 [70.12902069]
 [70.42773438]
 [70.72345734]
 [71.01622009]
 [71.30606079]
 [71.59300232]
 [71.8770752 ]
 [72.15830231]
 [72.4367218 ]
 [72.71235657]].
[2019-04-24 09:54:43,416] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4034418e-01 1.6767376e-03 1.6888710e-02 6.1658113e-07 6.2919612e-09
 8.2591392e-08 3.2891396e-08 2.8866709e-03 4.3820295e-01 2.9854750e-09
 3.3232264e-10], sum to 1.0000
[2019-04-24 09:54:43,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3129
[2019-04-24 09:54:43,438] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 75.0, 183.3333333333333, 76.66666666666667, 19.0, 19.77037801473824, -0.9850911886101851, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1866000.0000, 
sim time next is 1867200.0000, 
raw observation next is [-4.5, 79.0, 167.0, 70.0, 19.0, 19.21433668614738, -1.060364658569555, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.3379501385041552, 0.79, 0.5566666666666666, 0.07734806629834254, 0.08333333333333333, 0.10119472384561501, 0.14654511381014834, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8738986], dtype=float32), -0.62552035]. 
=============================================
[2019-04-24 09:54:44,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2672272e-01 3.9161093e-04 4.1070112e-04 8.9318526e-09 3.1757176e-13
 1.6896949e-10 4.6340948e-12 4.7320774e-04 2.7200171e-01 1.9196637e-13
 1.3019802e-13], sum to 1.0000
[2019-04-24 09:54:44,672] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5061
[2019-04-24 09:54:44,698] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 100.0, 60.0, 0.0, 22.5, 24.93551979203311, 0.1056238703551528, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1504800.0000, 
sim time next is 1506000.0000, 
raw observation next is [2.566666666666667, 98.66666666666667, 68.66666666666667, 0.0, 22.5, 24.43005545489108, 0.0511934762328848, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5337026777469991, 0.9866666666666667, 0.2288888888888889, 0.0, 0.375, 0.5358379545742565, 0.5170644920776283, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5441108], dtype=float32), 0.7881652]. 
=============================================
[2019-04-24 09:54:47,223] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.3428854e-01 4.3991258e-04 3.5507255e-04 7.4137358e-09 4.4006267e-13
 1.7217652e-10 3.6415823e-12 1.4445915e-04 1.6477196e-01 5.1143183e-13
 9.4637141e-14], sum to 1.0000
[2019-04-24 09:54:47,224] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5876
[2019-04-24 09:54:47,265] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.3, 96.0, 80.5, 354.0, 22.5, 23.96633542229918, 0.002044038056204955, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1508400.0000, 
sim time next is 1509600.0000, 
raw observation next is [3.666666666666667, 95.0, 85.5, 590.0, 22.5, 23.90800677949133, 0.02334848298780402, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.564173591874423, 0.95, 0.285, 0.6519337016574586, 0.375, 0.4923338982909442, 0.5077828276626014, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09462702], dtype=float32), 0.6515329]. 
=============================================
[2019-04-24 09:54:47,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.14115763e-01 1.43865109e-04 1.00228086e-03 1.24922810e-08
 1.12872704e-13 2.89727436e-10 7.76022801e-13 1.42654229e-04
 1.84595540e-01 2.20033803e-13 3.59835114e-14], sum to 1.0000
[2019-04-24 09:54:47,485] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0557
[2019-04-24 09:54:47,512] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 49.0, 171.5, 20.66666666666666, 22.5, 24.50270215663706, 0.208448746411096, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1603200.0000, 
sim time next is 1604400.0000, 
raw observation next is [13.8, 49.0, 170.8333333333333, 0.0, 22.5, 24.72470825388746, 0.2600211638866283, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.844875346260388, 0.49, 0.5694444444444443, 0.0, 0.375, 0.5603923544906216, 0.5866737212955427, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24182968], dtype=float32), 0.92034554]. 
=============================================
[2019-04-24 09:54:47,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1460601e-01 2.8173567e-04 1.2245897e-04 1.3271778e-08 4.1965593e-13
 7.3677314e-10 1.1642128e-11 2.0663404e-04 1.8478318e-01 8.0144582e-13
 3.9371853e-13], sum to 1.0000
[2019-04-24 09:54:47,870] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3333
[2019-04-24 09:54:47,891] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 23.52924532677973, -0.02965367557658706, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1707600.0000, 
sim time next is 1708800.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 23.00334058965443, -0.1331614377809053, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.4169450491378693, 0.45561285407303154, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.7311814], dtype=float32), 0.321129]. 
=============================================
[2019-04-24 09:54:50,219] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2035160e-01 7.7758479e-04 6.8221596e-04 4.4856243e-08 7.9895948e-13
 6.0778127e-10 1.2346335e-11 2.3709603e-04 1.7795148e-01 4.8349654e-13
 1.8908086e-13], sum to 1.0000
[2019-04-24 09:54:50,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9754
[2019-04-24 09:54:50,294] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 22.39333881968905, -0.1742393200681595, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1710000.0000, 
sim time next is 1711200.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 22.75144173590216, 0.09069981114037519, 0.0, 1.0, 55.0, 85.43773575480101], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.39595347799184655, 0.530233270380125, 0.0, 1.0, 0.8, 0.8543773575480101], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0057514], dtype=float32), -0.17361808]. 
=============================================
[2019-04-24 09:54:54,346] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.6085170e-01 1.6167668e-03 1.1179154e-02 1.5272410e-06 7.2911508e-09
 9.1337206e-08 4.9847834e-08 2.0133781e-03 5.2433729e-01 6.4331660e-09
 4.9407062e-10], sum to 1.0000
[2019-04-24 09:54:54,369] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2094
[2019-04-24 09:54:54,396] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.566666666666666, 76.33333333333334, 0.0, 0.0, 19.0, 19.34834120397032, -0.9840904092660301, 0.0, 1.0, 55.0, 76.59188272679685], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1894800.0000, 
sim time next is 1896000.0000, 
raw observation next is [-6.933333333333334, 77.66666666666667, 0.0, 0.0, 19.0, 19.5168119541274, -1.128949969415428, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.270544783010157, 0.7766666666666667, 0.0, 0.0, 0.08333333333333333, 0.12640099617728348, 0.1236833435281907, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6541663], dtype=float32), -0.60400087]. 
=============================================
[2019-04-24 09:54:56,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8411012e-01 2.2788860e-03 2.9208015e-03 1.8538742e-07 3.0378911e-11
 1.2116848e-08 6.7005468e-10 2.3291591e-03 6.0836083e-01 1.9956176e-11
 1.7013288e-11], sum to 1.0000
[2019-04-24 09:54:56,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9226
[2019-04-24 09:54:56,206] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3187625e-01 3.0028033e-03 4.3376148e-04 7.3941401e-08 3.0267505e-12
 4.3458019e-09 2.6036704e-11 3.1713655e-04 2.6436996e-01 6.5504568e-12
 4.6509268e-12], sum to 1.0000
[2019-04-24 09:54:56,207] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8176
[2019-04-24 09:54:56,275] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 65.0, 229.5, 7.0, 22.5, 22.49536977748406, -0.5071727825245312, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1944000.0000, 
sim time next is 1945200.0000, 
raw observation next is [-4.633333333333334, 65.0, 227.8333333333333, 5.0, 22.5, 22.6489734988417, -0.3347911557646019, 1.0, 1.0, 55.0, 75.90139355696536], 
processed observation next is [1.0, 0.5217391304347826, 0.3342566943674977, 0.65, 0.7594444444444443, 0.0055248618784530384, 0.375, 0.3874144582368082, 0.38840294807846604, 1.0, 1.0, 0.8, 0.7590139355696536], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1747054], dtype=float32), 1.34844]. 
=============================================
[2019-04-24 09:54:56,315] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 87.0, 15.0, 0.0, 22.5, 21.22917046400265, -0.7864973884166612, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2016000.0000, 
sim time next is 2017200.0000, 
raw observation next is [-6.133333333333334, 86.66666666666667, 24.33333333333334, 0.0, 22.5, 21.21933002823856, -0.548807634590699, 1.0, 1.0, 55.0, 88.14068913600065], 
processed observation next is [1.0, 0.34782608695652173, 0.2927054478301016, 0.8666666666666667, 0.08111111111111113, 0.0, 0.375, 0.2682775023532133, 0.31706412180310034, 1.0, 1.0, 0.8, 0.8814068913600065], 
reward next is 0.2440, 
noisyNet noise sample is [array([-1.2973901], dtype=float32), -0.39765435]. 
=============================================
[2019-04-24 09:54:56,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9374658e-01 3.4221655e-03 1.6613590e-02 1.0072956e-06 3.0977172e-09
 1.1379108e-07 2.6837018e-08 1.9118241e-03 4.8430473e-01 1.6098417e-09
 5.0933097e-10], sum to 1.0000
[2019-04-24 09:54:56,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7944
[2019-04-24 09:54:56,596] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 77.66666666666667, 36.16666666666666, 0.0, 19.0, 19.11431309474185, -1.077817526105914, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1873200.0000, 
sim time next is 1874400.0000, 
raw observation next is [-4.5, 80.33333333333333, 24.33333333333334, 0.0, 19.0, 19.34865014255365, -0.84672488331405, 0.0, 1.0, 55.0, 85.00961094526579], 
processed observation next is [0.0, 0.6956521739130435, 0.3379501385041552, 0.8033333333333332, 0.08111111111111113, 0.0, 0.08333333333333333, 0.11238751187947098, 0.21775837222865, 0.0, 1.0, 0.8, 0.8500961094526579], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.254882], dtype=float32), 0.0015380757]. 
=============================================
[2019-04-24 09:54:56,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1663572e-01 4.3105209e-04 3.3490013e-03 3.7810000e-08 3.2577036e-12
 3.0078122e-09 1.1882850e-10 6.1359146e-04 4.7897056e-01 9.8133975e-12
 2.7734707e-12], sum to 1.0000
[2019-04-24 09:54:56,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8921
[2019-04-24 09:54:56,683] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.9, 82.0, 6.999999999999999, 0.0, 22.5, 23.15700836783259, -0.4920674141929539, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2049600.0000, 
sim time next is 2050800.0000, 
raw observation next is [-3.899999999999999, 82.0, 0.0, 0.0, 22.5, 22.29898503006388, -0.3076818772182126, 1.0, 1.0, 55.0, 75.58494484439801], 
processed observation next is [1.0, 0.7391304347826086, 0.35457063711911363, 0.82, 0.0, 0.0, 0.375, 0.35824875250532323, 0.3974393742605958, 1.0, 1.0, 0.8, 0.75584944844398], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3792948], dtype=float32), 1.1561838]. 
=============================================
[2019-04-24 09:55:00,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8315666e-01 5.1349733e-04 3.3184988e-04 1.1171791e-08 2.5546253e-12
 1.2608470e-09 1.5929740e-11 7.1071042e-04 1.1528727e-01 1.5381925e-12
 6.1223596e-13], sum to 1.0000
[2019-04-24 09:55:00,413] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1995
[2019-04-24 09:55:00,431] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 67.66666666666667, 269.3333333333334, 106.5, 22.5, 23.48125524441672, -0.06997915774044577, 1.0, 1.0, 55.0, 66.71125531024711], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2115600.0000, 
sim time next is 2116800.0000, 
raw observation next is [-6.7, 64.0, 222.0, 117.5, 22.5, 23.87140957926782, -0.1749017789124694, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.2770083102493075, 0.64, 0.74, 0.1298342541436464, 0.375, 0.4892841316056516, 0.44169940702917687, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0220367], dtype=float32), -0.6303502]. 
=============================================
[2019-04-24 09:55:09,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.19043648e-01 5.03547490e-04 1.46441557e-03 1.03732440e-07
 1.18106965e-11 8.61370264e-09 1.93037808e-10 1.36831275e-03
 3.77619952e-01 8.41945177e-12 3.60052027e-12], sum to 1.0000
[2019-04-24 09:55:09,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9307
[2019-04-24 09:55:09,110] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 22.5, 22.39624027322856, -0.325414766194097, 1.0, 1.0, 55.0, 67.06569260041215], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2106000.0000, 
sim time next is 2107200.0000, 
raw observation next is [-7.8, 82.0, 157.0, 104.5, 22.5, 23.06959149718022, -0.2385403222031678, 1.0, 1.0, 55.0, 48.37036911155423], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.5233333333333333, 0.11546961325966851, 0.375, 0.42246595809835163, 0.4204865592656108, 1.0, 1.0, 0.8, 0.48370369111554234], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.115502], dtype=float32), -0.6109023]. 
=============================================
[2019-04-24 09:55:10,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7339168e-01 9.9140720e-04 1.1603653e-03 1.5957625e-07 8.2070678e-12
 7.1569777e-09 1.7524976e-10 4.1936865e-04 4.2403701e-01 1.2620015e-11
 5.7975139e-12], sum to 1.0000
[2019-04-24 09:55:10,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9074
[2019-04-24 09:55:10,226] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.533333333333333, 55.33333333333333, 0.0, 0.0, 22.5, 23.73968718612727, -0.02328110871380487, 0.0, 1.0, 55.0, 46.49658299675404], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2317200.0000, 
sim time next is 2318400.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 22.5, 23.71794092313122, -0.02042747771254505, 0.0, 1.0, 55.0, 45.868043600007994], 
processed observation next is [1.0, 0.8695652173913043, 0.4155124653739613, 0.56, 0.0, 0.0, 0.375, 0.4764950769276017, 0.493190840762485, 0.0, 1.0, 0.8, 0.45868043600007996], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2591601], dtype=float32), -1.217176]. 
=============================================
[2019-04-24 09:55:12,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2766367e-01 2.0795218e-03 5.6744525e-03 1.5307583e-07 5.9225985e-11
 6.1707297e-08 8.4235918e-10 1.6998188e-03 3.6288229e-01 1.5111311e-10
 2.4306156e-11], sum to 1.0000
[2019-04-24 09:55:12,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6232
[2019-04-24 09:55:12,562] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 56.0, 0.0, 0.0, 19.0, 21.6716366381573, -0.3084193356269476, 0.0, 1.0, 55.0, 79.58901772179728], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2325600.0000, 
sim time next is 2326800.0000, 
raw observation next is [-1.9, 57.0, 0.0, 0.0, 19.0, 22.39614304776163, -0.4441307115423674, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4099722991689751, 0.57, 0.0, 0.0, 0.08333333333333333, 0.3663452539801358, 0.3519564294858775, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.451392], dtype=float32), 1.1547039]. 
=============================================
[2019-04-24 09:55:21,827] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.2782335e-01 2.7567684e-03 1.6288892e-03 2.4257406e-07 1.0754867e-10
 3.4784577e-08 9.2263830e-10 1.9828251e-03 3.6580786e-01 8.7219239e-11
 2.7569884e-11], sum to 1.0000
[2019-04-24 09:55:21,827] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3116
[2019-04-24 09:55:21,854] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 19.0, 20.66622125521321, -0.6087415533477096, 0.0, 1.0, 55.0, 83.60017820213773], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2600400.0000, 
sim time next is 2601600.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 19.0, 21.17191988795335, -0.7055459357476241, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.32409972299168976, 0.74, 0.0, 0.0, 0.08333333333333333, 0.2643266573294459, 0.26481802141745864, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13128579], dtype=float32), 1.0795066]. 
=============================================
[2019-04-24 09:55:24,661] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.3119384e-01 9.8441914e-04 2.1398030e-03 2.4930458e-07 3.0447533e-11
 1.8004499e-08 2.1610899e-10 3.6998282e-04 2.6531178e-01 6.4872094e-11
 1.6337726e-11], sum to 1.0000
[2019-04-24 09:55:24,663] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5101
[2019-04-24 09:55:24,700] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 58.0, 0.0, 0.0, 22.5, 22.05266356799073, -0.4772191966572334, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2659200.0000, 
sim time next is 2660400.0000, 
raw observation next is [-1.2, 60.0, 0.0, 0.0, 22.5, 21.55499790543806, -0.536437076537834, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.6, 0.0, 0.0, 0.375, 0.29624982545317174, 0.32118764115405535, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9668, 
noisyNet noise sample is [array([0.60593337], dtype=float32), -0.26868358]. 
=============================================
[2019-04-24 09:55:40,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2187585e-01 3.0081789e-03 6.0382029e-03 7.8905759e-07 1.2487955e-09
 5.0338674e-08 3.1798205e-08 4.7367923e-03 2.6434007e-01 9.9344699e-10
 2.8606850e-10], sum to 1.0000
[2019-04-24 09:55:40,054] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1130
[2019-04-24 09:55:40,070] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 119.0, 90.5, 19.0, 20.64961612065828, -0.5783592284159194, 0.0, 1.0, 55.0, 83.59046985407412], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2970000.0000, 
sim time next is 2971200.0000, 
raw observation next is [-4.0, 71.0, 142.3333333333333, 118.1666666666667, 19.0, 20.95108806694645, -0.6857616841221192, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.71, 0.4744444444444443, 0.13057090239410685, 0.08333333333333333, 0.24592400557887087, 0.2714127719592936, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5494231], dtype=float32), 0.39390802]. 
=============================================
[2019-04-24 09:55:40,657] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.91501760e-01 2.13193707e-04 1.65592966e-04 4.50998616e-09
 2.41191805e-13 1.02532184e-10 4.80142488e-12 2.18237590e-04
 2.07901180e-01 6.65158521e-13 3.56248844e-14], sum to 1.0000
[2019-04-24 09:55:40,657] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6763
[2019-04-24 09:55:40,698] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 95.33333333333334, 60.16666666666667, 51.83333333333333, 22.5, 23.8757074044487, -0.08768932569698219, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2911200.0000, 
sim time next is 2912400.0000, 
raw observation next is [2.0, 93.0, 38.5, 47.5, 22.5, 23.69654022054882, -0.1986268268319502, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.93, 0.12833333333333333, 0.052486187845303865, 0.375, 0.4747116850457349, 0.4337910577226833, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4541223], dtype=float32), 0.25934768]. 
=============================================
[2019-04-24 09:55:40,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5604601e-01 2.5595156e-03 6.5129586e-03 1.6962188e-06 3.2791412e-09
 2.7454985e-07 2.4323384e-08 2.2684056e-03 4.3261111e-01 9.8891730e-09
 5.9944694e-10], sum to 1.0000
[2019-04-24 09:55:40,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3632
[2019-04-24 09:55:40,814] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 32.0, 287.0, 19.0, 22.04066496668408, -0.4838884338111613, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3085200.0000, 
sim time next is 3086400.0000, 
raw observation next is [-0.2, 75.33333333333334, 15.33333333333333, 154.3333333333333, 19.0, 21.52639687844343, -0.5704064729876673, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.4570637119113574, 0.7533333333333334, 0.0511111111111111, 0.17053406998158374, 0.08333333333333333, 0.29386640653695234, 0.3098645090041109, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9536598], dtype=float32), -0.6980169]. 
=============================================
[2019-04-24 09:55:42,395] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8562933e-01 6.2548998e-04 3.4860324e-04 4.5027027e-09 1.1409206e-12
 9.2302582e-10 1.1494945e-11 1.1754168e-04 2.1327908e-01 9.5845619e-13
 2.4362546e-13], sum to 1.0000
[2019-04-24 09:55:42,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2589
[2019-04-24 09:55:42,432] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 69.0, 0.0, 0.0, 22.5, 24.77541066744928, 0.2994254995934741, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3260400.0000, 
sim time next is 3261600.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 22.5, 24.56273117266493, 0.2812265660285009, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.65, 0.0, 0.0, 0.375, 0.5468942643887441, 0.593742188676167, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5500145], dtype=float32), 1.4821975]. 
=============================================
[2019-04-24 09:55:48,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1637201e-01 1.2746796e-03 9.8275393e-04 2.5626678e-08 6.0104954e-13
 2.0829842e-09 8.8900423e-12 4.2339755e-04 2.8094709e-01 7.5279765e-12
 2.2655559e-13], sum to 1.0000
[2019-04-24 09:55:48,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4678
[2019-04-24 09:55:48,443] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 90.0, 111.6666666666667, 813.8333333333334, 22.5, 23.46001225382239, 0.1296831347986314, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3244800.0000, 
sim time next is 3246000.0000, 
raw observation next is [-3.333333333333333, 95.0, 109.3333333333333, 804.8333333333334, 22.5, 23.95932662212384, 0.1903931920835021, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.37026777469990774, 0.95, 0.36444444444444435, 0.8893186003683242, 0.375, 0.49661055184365327, 0.5634643973611674, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.67355883], dtype=float32), -2.313762]. 
=============================================
[2019-04-24 09:55:48,693] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.70340514e-01 1.24557770e-03 9.02755710e-04 9.34723232e-08
 1.31724085e-11 7.11828285e-09 2.23608396e-10 7.99638219e-04
 4.26711321e-01 3.37428245e-11 3.85885985e-12], sum to 1.0000
[2019-04-24 09:55:48,760] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0573
[2019-04-24 09:55:48,802] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.333333333333334, 74.33333333333334, 0.0, 0.0, 19.0, 22.24402615224182, -0.01484178700235158, 0.0, 1.0, 55.0, 86.58351548976364], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3270000.0000, 
sim time next is 3271200.0000, 
raw observation next is [-4.666666666666666, 77.66666666666667, 0.0, 0.0, 19.0, 22.85412331733763, -0.1136632226938559, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.33333333333333337, 0.7766666666666667, 0.0, 0.0, 0.08333333333333333, 0.4045102764448026, 0.46211225910204806, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.974152], dtype=float32), 0.22154859]. 
=============================================
[2019-04-24 09:55:53,251] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.5382046e-01 1.1801529e-03 1.0612912e-03 6.6113408e-08 4.7755857e-12
 1.9821023e-09 9.1642992e-11 5.9205928e-04 3.4334585e-01 9.5645757e-12
 1.3585754e-12], sum to 1.0000
[2019-04-24 09:55:53,252] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4760
[2019-04-24 09:55:53,262] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 94.66666666666666, 0.0, 0.0, 19.0, 21.61492130662981, -0.4587630471975261, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3220800.0000, 
sim time next is 3222000.0000, 
raw observation next is [-3.0, 92.0, 0.0, 0.0, 19.0, 21.08392257884567, -0.537447277227018, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.92, 0.0, 0.0, 0.08333333333333333, 0.2569935482371391, 0.320850907590994, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.726858], dtype=float32), 1.0014135]. 
=============================================
[2019-04-24 09:56:05,825] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.0347273e-01 6.6383700e-03 1.1976521e-03 2.2373193e-07 5.4742155e-11
 1.4350374e-08 5.1116888e-10 8.7957527e-04 2.8781146e-01 5.5507366e-11
 1.0624200e-11], sum to 1.0000
[2019-04-24 09:56:05,826] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5745
[2019-04-24 09:56:06,018] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 52.66666666666667, 114.6666666666667, 801.8333333333334, 22.5, 24.59004644420635, 0.231213537307241, 1.0, 1.0, 55.0, 59.71151503898181], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3331200.0000, 
sim time next is 3332400.0000, 
raw observation next is [-4.333333333333334, 51.33333333333333, 112.6666666666667, 792.0, 22.5, 25.17019005665316, 0.174107191488507, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3425669436749769, 0.5133333333333333, 0.37555555555555564, 0.8751381215469614, 0.375, 0.5975158380544299, 0.5580357304961691, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2012122], dtype=float32), -0.760888]. 
=============================================
[2019-04-24 09:56:07,452] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.1354272e-01 4.1887034e-03 7.5418735e-04 3.2487546e-07 8.8212819e-11
 2.1225775e-08 7.6585138e-10 6.0661341e-04 1.8090738e-01 1.0353291e-10
 1.3316111e-11], sum to 1.0000
[2019-04-24 09:56:07,452] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9900
[2019-04-24 09:56:07,550] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 22.5, 23.27080290771999, -0.1124490535243995, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3352800.0000, 
sim time next is 3354000.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 22.5, 23.19319950624205, 0.07612036517159627, 1.0, 1.0, 55.0, 80.46392046218995], 
processed observation next is [1.0, 0.8260869565217391, 0.3795013850415513, 0.55, 0.0, 0.0, 0.375, 0.43276662552017076, 0.5253734550571988, 1.0, 1.0, 0.8, 0.8046392046218994], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2012122], dtype=float32), -0.760888]. 
=============================================
[2019-04-24 09:56:10,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2213403e-01 7.3898036e-04 1.9928261e-03 4.9556224e-08 2.2157376e-12
 1.3123049e-09 1.7643026e-10 7.0186856e-04 3.7443221e-01 8.1623397e-12
 1.5330617e-12], sum to 1.0000
[2019-04-24 09:56:10,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7741
[2019-04-24 09:56:10,426] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 81.33333333333334, 0.0, 0.0, 19.0, 23.21550402799988, -0.1319698199102457, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3458400.0000, 
sim time next is 3459600.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 19.0, 23.13314302979292, 0.004598099281635556, 0.0, 1.0, 55.0, 70.16815607353868], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.79, 0.0, 0.0, 0.08333333333333333, 0.4277619191494099, 0.5015326997605452, 0.0, 1.0, 0.8, 0.7016815607353868], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5052313], dtype=float32), -0.6275353]. 
=============================================
[2019-04-24 09:56:11,030] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7290914e-01 1.6190205e-03 9.2087630e-03 1.2089282e-06 2.7097484e-09
 1.1565542e-07 1.2961756e-08 2.6510970e-03 3.1361058e-01 6.3362993e-10
 1.2081397e-10], sum to 1.0000
[2019-04-24 09:56:11,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8663
[2019-04-24 09:56:11,239] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 48.33333333333334, 0.0, 0.0, 19.0, 22.88822911844035, -0.1602286058045924, 0.0, 1.0, 55.0, 63.859086467959315], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3626400.0000, 
sim time next is 3627600.0000, 
raw observation next is [5.0, 36.66666666666667, 0.0, 0.0, 19.0, 23.28208679926955, -0.1042933382995381, 0.0, 1.0, 55.0, 45.69818801244917], 
processed observation next is [0.0, 1.0, 0.6011080332409973, 0.3666666666666667, 0.0, 0.0, 0.08333333333333333, 0.44017389993912914, 0.465235553900154, 0.0, 1.0, 0.8, 0.4569818801244917], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2939398], dtype=float32), -0.76198405]. 
=============================================
[2019-04-24 09:56:12,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.93244159e-01 7.52659002e-03 1.27989193e-02 2.39377869e-06
 1.40087755e-08 6.76766092e-07 1.17675313e-07 1.05505725e-02
 2.75876582e-01 1.01316830e-08 2.22759744e-09], sum to 1.0000
[2019-04-24 09:56:12,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0100
[2019-04-24 09:56:12,789] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.066666666666666, 28.33333333333334, 0.0, 0.0, 19.0, 22.07008704597459, -0.3157587604755774, 0.0, 1.0, 20.0, 63.49984398791912], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3642000.0000, 
sim time next is 3643200.0000, 
raw observation next is [8.0, 29.0, 0.0, 0.0, 19.0, 22.68483025976935, -0.366344784582097, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.6842105263157896, 0.29, 0.0, 0.0, 0.08333333333333333, 0.39040252164744577, 0.37788507180596764, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3482765], dtype=float32), 1.9270233]. 
=============================================
[2019-04-24 09:56:12,995] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2082276e-01 1.4817640e-03 3.3194169e-03 4.2854862e-07 4.1967954e-10
 2.5725425e-08 2.6049962e-09 3.8941510e-03 4.7048151e-01 3.5786413e-10
 3.1221668e-11], sum to 1.0000
[2019-04-24 09:56:13,057] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2177
[2019-04-24 09:56:13,127] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 19.0, 22.53960403914049, -0.1995400871339112, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3546000.0000, 
sim time next is 3547200.0000, 
raw observation next is [-2.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 22.33133439498685, -0.2453413169454438, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.3979686057248385, 0.6366666666666667, 0.0, 0.0, 0.08333333333333333, 0.3609445329155709, 0.41821956101818536, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7550875], dtype=float32), 0.01275046]. 
=============================================
[2019-04-24 09:56:15,017] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.99213564e-01 2.46877992e-03 1.43762268e-02 1.01484750e-06
 3.71798747e-09 1.79727223e-07 1.27410384e-08 2.09405483e-03
 2.81846076e-01 7.13368697e-09 6.21616647e-10], sum to 1.0000
[2019-04-24 09:56:15,081] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0754
[2019-04-24 09:56:15,144] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.333333333333334, 30.33333333333334, 18.16666666666666, 168.0, 19.0, 22.43376326124567, -0.3656663895813781, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3656400.0000, 
sim time next is 3657600.0000, 
raw observation next is [8.0, 32.0, 46.5, 262.0, 19.0, 22.22860691657597, -0.3796204704226351, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.6842105263157896, 0.32, 0.155, 0.28950276243093925, 0.08333333333333333, 0.35238390971466416, 0.37345984319245495, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24710175], dtype=float32), 0.44102648]. 
=============================================
[2019-04-24 09:56:28,609] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.9587066e-01 1.1207761e-03 3.6751790e-04 1.6035344e-08 1.7778441e-12
 6.1585170e-10 2.9418239e-11 1.2404079e-04 2.0251693e-01 5.2271291e-12
 5.6695783e-13], sum to 1.0000
[2019-04-24 09:56:28,609] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4301
[2019-04-24 09:56:28,794] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 66.33333333333334, 552.0, 22.5, 25.73586625505131, 0.4441429214137201, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3514800.0000, 
sim time next is 3516000.0000, 
raw observation next is [3.0, 49.0, 53.83333333333334, 462.6666666666667, 22.5, 25.73838037667239, 0.4118579863391319, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.49, 0.1794444444444445, 0.5112338858195212, 0.375, 0.6448650313893657, 0.6372859954463773, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.571432], dtype=float32), 1.0692048]. 
=============================================
[2019-04-24 09:56:43,218] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.3662648e-01 6.3165682e-03 3.0252950e-03 1.3733194e-07 1.4959648e-11
 5.1207274e-09 5.1114740e-10 1.4072914e-03 3.5262418e-01 2.0091206e-11
 7.5006503e-12], sum to 1.0000
[2019-04-24 09:56:43,219] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6607
[2019-04-24 09:56:43,403] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 77.0, 48.0, 298.0, 22.5, 22.84205637531339, -0.1915946836666954, 1.0, 1.0, 20.0, 49.00257594777251], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3830400.0000, 
sim time next is 3831600.0000, 
raw observation next is [-4.666666666666667, 75.0, 76.66666666666667, 397.3333333333333, 22.5, 23.20962729736296, -0.03905526121577202, 1.0, 1.0, 55.0, 65.6380372827673], 
processed observation next is [1.0, 0.34782608695652173, 0.3333333333333333, 0.75, 0.2555555555555556, 0.43904235727440144, 0.375, 0.43413560811358004, 0.4869815795947427, 1.0, 1.0, 0.8, 0.656380372827673], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.72005105], dtype=float32), -1.9064202]. 
=============================================
[2019-04-24 09:56:48,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8342030e-01 3.8992940e-03 1.6518011e-03 4.8373045e-07 8.1711950e-11
 1.4662392e-07 1.9917852e-09 1.9858624e-03 3.0904210e-01 9.0116262e-11
 5.4183501e-11], sum to 1.0000
[2019-04-24 09:56:48,995] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3076
[2019-04-24 09:56:49,086] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 35.33333333333334, 76.66666666666667, 390.8333333333334, 22.5, 22.72307127450693, -0.255471617779946, 1.0, 1.0, 55.0, 60.2113471077913], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4090800.0000, 
sim time next is 4092000.0000, 
raw observation next is [-3.333333333333333, 36.66666666666666, 94.0, 504.0, 22.5, 23.41563081593223, -0.2685492484195264, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.37026777469990774, 0.3666666666666666, 0.31333333333333335, 0.5569060773480663, 0.375, 0.45130256799435237, 0.4104835838601579, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0369923], dtype=float32), -1.523438]. 
=============================================
[2019-04-24 09:56:58,290] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1342894e-01 4.9649039e-04 1.1787458e-03 7.6560774e-08 2.1981738e-11
 1.0256279e-08 2.4441768e-10 5.9061020e-04 1.8430512e-01 3.1170327e-11
 7.8430639e-12], sum to 1.0000
[2019-04-24 09:56:58,364] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7431
[2019-04-24 09:56:58,394] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 19.0, 24.00499063492369, 0.2855915266293975, 0.0, 1.0, 55.0, 74.97091831138115], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4136400.0000, 
sim time next is 4137600.0000, 
raw observation next is [1.0, 37.33333333333334, 0.0, 0.0, 19.0, 24.60471267336469, 0.209207449469358, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.3733333333333334, 0.0, 0.0, 0.08333333333333333, 0.550392722780391, 0.569735816489786, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4516451], dtype=float32), -0.5708806]. 
=============================================
[2019-04-24 09:57:06,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0983735e-01 2.2308794e-03 5.1547484e-03 9.1243828e-07 2.6341174e-09
 1.9290371e-07 2.2923494e-08 3.8479695e-03 3.7892792e-01 1.4280178e-09
 4.7049548e-10], sum to 1.0000
[2019-04-24 09:57:06,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8514
[2019-04-24 09:57:06,069] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 19.0, 21.75156577845113, -0.3664622343862323, 0.0, 1.0, 55.0, 76.65659979855594], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4250400.0000, 
sim time next is 4251600.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 19.0, 22.51873099353327, -0.2770837933267047, 0.0, 1.0, 55.0, 49.75414665125648], 
processed observation next is [0.0, 0.21739130434782608, 0.5457063711911359, 0.45, 0.0, 0.0, 0.08333333333333333, 0.3765609161277726, 0.4076387355577651, 0.0, 1.0, 0.8, 0.49754146651256476], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14093682], dtype=float32), -0.93546903]. 
=============================================
[2019-04-24 09:57:06,898] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.5144140e-01 4.7318665e-03 9.7290697e-03 3.1499524e-06 2.2216751e-08
 3.9629765e-07 1.5207492e-07 1.1592611e-02 3.2250133e-01 4.6720018e-08
 1.3910360e-09], sum to 1.0000
[2019-04-24 09:57:06,898] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3299
[2019-04-24 09:57:06,952] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 19.0, 21.10848564243873, -0.6556060842301311, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4243200.0000, 
sim time next is 4244400.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 19.0, 20.91208441453093, -0.6911609588860474, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.5457063711911359, 0.45, 0.0, 0.0, 0.08333333333333333, 0.2426737012109109, 0.26961301370465085, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7360109], dtype=float32), 0.4155669]. 
=============================================
[2019-04-24 09:57:09,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.27631927e-01 2.88637844e-03 3.61442682e-03 9.04465765e-07
 1.84840421e-09 5.18858023e-08 1.00326165e-08 1.06876446e-02
 2.55178630e-01 1.64596270e-09 2.17446464e-10], sum to 1.0000
[2019-04-24 09:57:09,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9140
[2019-04-24 09:57:09,164] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.0, 45.0, 0.0, 0.0, 19.0, 23.37054162705396, -0.1309456972903984, 0.0, 1.0, 55.0, 47.72414779318608], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4249200.0000, 
sim time next is 4250400.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 19.0, 23.50256073624345, -0.1141785985275956, 0.0, 1.0, 55.0, 47.17002910254159], 
processed observation next is [0.0, 0.17391304347826086, 0.5457063711911359, 0.45, 0.0, 0.0, 0.08333333333333333, 0.45854672802028745, 0.4619404671574681, 0.0, 1.0, 0.8, 0.4717002910254159], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35604098], dtype=float32), -0.23516229]. 
=============================================
[2019-04-24 09:57:12,430] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.6055086e-01 1.1749786e-03 7.3343432e-03 2.5871128e-07 3.6568734e-10
 7.2409406e-08 2.3678615e-09 1.5166410e-03 2.2942293e-01 2.9861164e-10
 1.5468847e-11], sum to 1.0000
[2019-04-24 09:57:12,443] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7900
[2019-04-24 09:57:12,537] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.8, 70.33333333333334, 0.0, 0.0, 19.0, 22.96001371248205, -0.1922927512882551, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4303200.0000, 
sim time next is 4304400.0000, 
raw observation next is [5.6, 71.66666666666667, 0.0, 0.0, 19.0, 23.21301923280839, 0.03655713341204635, 0.0, 1.0, 55.0, 76.43378985998432], 
processed observation next is [0.0, 0.8260869565217391, 0.6177285318559557, 0.7166666666666667, 0.0, 0.0, 0.08333333333333333, 0.43441826940069905, 0.5121857111373488, 0.0, 1.0, 0.8, 0.7643378985998431], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30297533], dtype=float32), -0.0247046]. 
=============================================
[2019-04-24 09:57:23,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2531017e-01 5.1338709e-04 1.1337333e-03 2.9407316e-08 9.2012910e-13
 1.0872435e-09 1.5947675e-11 4.0951776e-04 1.7263316e-01 3.8001924e-12
 2.1392081e-13], sum to 1.0000
[2019-04-24 09:57:23,081] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0066
[2019-04-24 09:57:23,154] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 72.0, 64.5, 19.5, 22.5, 23.54122734587236, -0.06664233432022593, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4726800.0000, 
sim time next is 4728000.0000, 
raw observation next is [0.6666666666666667, 74.0, 40.83333333333333, 25.16666666666667, 22.5, 23.5980705041034, -0.1065841682148239, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4810710987996307, 0.74, 0.1361111111111111, 0.0278084714548803, 0.375, 0.46650587534195004, 0.46447194392839203, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08887609], dtype=float32), 0.96351624]. 
=============================================
[2019-04-24 09:57:25,701] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0840558e-01 7.4973743e-04 1.6925413e-03 3.3767119e-08 2.2314442e-12
 8.7085417e-10 9.6627581e-11 3.2299990e-04 1.8882905e-01 5.0973353e-12
 2.5591833e-12], sum to 1.0000
[2019-04-24 09:57:25,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7075
[2019-04-24 09:57:25,766] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666666, 57.33333333333334, 134.8333333333333, 724.0, 22.5, 25.15656712353646, 0.200538984518936, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4616400.0000, 
sim time next is 4617600.0000, 
raw observation next is [1.333333333333333, 54.66666666666667, 127.8333333333333, 778.0, 22.5, 24.79952821549031, 0.1527929793507151, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4995383194829178, 0.5466666666666667, 0.426111111111111, 0.8596685082872928, 0.375, 0.5666273512908591, 0.550930993116905, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55557656], dtype=float32), -1.089189]. 
=============================================
[2019-04-24 09:57:26,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4438006e-01 1.5425250e-04 3.0235454e-04 9.4173842e-09 7.8239661e-13
 7.8843049e-10 1.0673965e-11 7.8949792e-04 2.5437385e-01 1.4756709e-12
 7.8614074e-13], sum to 1.0000
[2019-04-24 09:57:26,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7516
[2019-04-24 09:57:26,879] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 92.0, 106.3333333333333, 0.0, 22.5, 24.81893168175355, 0.1346162888044173, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4699200.0000, 
sim time next is 4700400.0000, 
raw observation next is [0.0, 92.0, 130.5, 0.9999999999999998, 22.5, 24.99082692796413, 0.2922273951538846, 1.0, 1.0, 55.0, 64.34832185811071], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.92, 0.435, 0.0011049723756906074, 0.375, 0.5825689106636774, 0.5974091317179615, 1.0, 1.0, 0.8, 0.6434832185811071], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.092813], dtype=float32), 1.691747]. 
=============================================
[2019-04-24 09:57:30,650] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5897378e-01 2.8418498e-03 7.7364654e-03 5.1608652e-07 1.2102799e-09
 7.4538228e-08 7.8612183e-09 2.7832978e-03 2.2766392e-01 1.9767463e-09
 2.0053562e-10], sum to 1.0000
[2019-04-24 09:57:30,654] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0898
[2019-04-24 09:57:30,696] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 19.0, 22.887147967596, -0.1699452457780693, 0.0, 1.0, 55.0, 47.78618718481516], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4831200.0000, 
sim time next is 4832400.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 19.0, 22.89074916349422, -0.3149683281938535, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.08333333333333333, 0.40756243029118505, 0.3950105572687155, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.877651], dtype=float32), 0.043219395]. 
=============================================
[2019-04-24 09:57:32,035] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-04-24 09:57:32,036] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:57:32,037] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:57:32,039] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run5
[2019-04-24 09:57:32,058] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:57:32,066] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:57:32,063] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:57:32,069] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:57:32,069] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run5
[2019-04-24 09:57:32,110] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run5
[2019-04-24 09:57:47,199] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.21456586], dtype=float32), 0.3070994]
[2019-04-24 09:57:47,199] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [8.5, 89.0, 0.0, 0.0, 19.0, 22.39499944086837, -0.3204541612043858, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:57:47,199] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 09:57:47,200] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [6.9468778e-01 5.5784575e-04 1.9192854e-03 3.4024701e-08 1.5204841e-11
 5.0877000e-09 2.1269038e-10 5.6248863e-04 3.0227259e-01 2.2698874e-11
 1.0358911e-12], sampled 0.2961725694910734
[2019-04-24 09:59:04,306] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.21456586], dtype=float32), 0.3070994]
[2019-04-24 09:59:04,306] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-3.666666666666667, 52.66666666666667, 88.66666666666667, 633.8333333333334, 22.5, 24.3386282338156, -0.01621081700137038, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 09:59:04,307] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 09:59:04,307] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.20462739e-01 2.18035583e-03 4.99393651e-03 5.79874950e-07
 5.70130387e-10 6.90071644e-08 3.94231625e-09 1.70215697e-03
 2.70660192e-01 8.65774119e-10 1.08852385e-10], sampled 0.2426159203188879
[2019-04-24 09:59:10,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.21456586], dtype=float32), 0.3070994]
[2019-04-24 09:59:10,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [11.16666666666667, 52.33333333333333, 164.5, 621.0, 19.0, 22.58744043005279, -0.284373277062615, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:59:10,758] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 09:59:10,759] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [7.5151414e-01 8.3935977e-04 5.3936164e-03 1.3876709e-07 3.6846490e-10
 2.2486271e-08 1.5390439e-09 2.3213711e-03 2.3993140e-01 3.4026967e-10
 2.3218620e-11], sampled 0.9207559682859647
[2019-04-24 09:59:25,086] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2950.6890 83687.3195 34.6299
[2019-04-24 09:59:25,118] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:25,118] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:25,118] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:25,118] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:25,118] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:25,229] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:25,229] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:25,229] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:25,229] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:25,229] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:35,000] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2720.4229 92461.1249 -313.3801
[2019-04-24 09:59:35,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:35,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:35,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:35,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:35,022] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:35,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:35,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:35,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:35,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:35,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:39,443] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2604.1522 99271.1396 -323.1396
[2019-04-24 09:59:39,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:39,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:39,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:39,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:39,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:39,568] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:39,568] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:39,568] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:39,568] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:39,568] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:59:40,466] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 200000, evaluation results [200000.0, 2720.4228829628896, 92461.12489144683, -313.38011707156573, 2950.688975147366, 83687.31953056464, 34.62986506145775, 2604.15222110847, 99271.13958625012, -323.13961766610106]
[2019-04-24 09:59:41,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:42,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:42,862] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:42,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:42,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run4
[2019-04-24 09:59:45,232] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:45,426] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:46,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:46,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:46,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:46,243] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run4
[2019-04-24 09:59:46,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:46,358] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:46,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:47,177] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:47,178] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:47,180] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run4
[2019-04-24 09:59:47,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:47,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:47,238] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run4
[2019-04-24 09:59:47,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:47,867] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.4501566e-01 2.8608886e-03 1.1690244e-02 5.1272679e-07 1.7567408e-09
 6.3113127e-08 6.6056605e-09 3.4475431e-03 3.3698514e-01 2.0375557e-09
 6.9595496e-11], sum to 1.0000
[2019-04-24 09:59:47,868] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4519
[2019-04-24 09:59:47,900] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 132.5, 369.5, 19.0, 22.29098732928117, -0.1558637506817438, 0.0, 1.0, 55.0, 68.95923692952137], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4896000.0000, 
sim time next is 4897200.0000, 
raw observation next is [3.0, 45.0, 112.1666666666667, 334.5, 19.0, 23.05927507213484, -0.1914265650839059, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.373888888888889, 0.3696132596685083, 0.08333333333333333, 0.4216062560112368, 0.4361911449720313, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16985895], dtype=float32), -1.9128603]. 
=============================================
[2019-04-24 09:59:47,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:48,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:48,729] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:48,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run4
[2019-04-24 09:59:48,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:49,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:49,244] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:49,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:49,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:49,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:49,907] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run4
[2019-04-24 09:59:50,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:50,247] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:50,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run4
[2019-04-24 09:59:50,498] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:50,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:50,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:50,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:50,900] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:51,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:51,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:51,498] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:51,499] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:51,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run4
[2019-04-24 09:59:51,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:51,522] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:51,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run4
[2019-04-24 09:59:51,662] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:51,797] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:51,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:51,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:51,831] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run4
[2019-04-24 09:59:52,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:52,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:52,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:52,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:52,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:52,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run4
[2019-04-24 09:59:52,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:52,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:52,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run4
[2019-04-24 09:59:53,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:53,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:53,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run4
[2019-04-24 09:59:53,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:54,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:54,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:54,771] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:54,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:54,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:54,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run4
[2019-04-24 09:59:55,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:55,545] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:55,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run4
[2019-04-24 09:59:56,468] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:59:56,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:59:57,469] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:59:57,470] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:59:57,471] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run4
[2019-04-24 10:00:00,938] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.0865786e-01 7.8912434e-04 1.5839370e-02 2.7416380e-07 1.4736841e-10
 1.5911956e-08 2.4890938e-09 5.9967034e-04 2.7411366e-01 5.5468152e-10
 2.8846441e-11], sum to 1.0000
[2019-04-24 10:00:00,938] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9151
[2019-04-24 10:00:01,001] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.1, 95.0, 0.0, 0.0, 19.0, 20.2390728968767, -0.7523704071995456, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 85200.0000, 
sim time next is 86400.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 20.4121080985343, -0.5202643952030791, 0.0, 1.0, 55.0, 81.32632720474889], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.20100900821119172, 0.326578534932307, 0.0, 1.0, 0.8, 0.8132632720474889], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1064634], dtype=float32), -0.89829284]. 
=============================================
[2019-04-24 10:00:01,101] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.8066466e-01 4.9452035e-04 1.0496464e-02 1.0405441e-07 3.9472169e-11
 9.9056692e-09 4.8913384e-10 5.0971715e-04 3.0783448e-01 8.9631441e-11
 7.2990832e-12], sum to 1.0000
[2019-04-24 10:00:01,101] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6276
[2019-04-24 10:00:01,113] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 92.33333333333334, 0.0, 0.0, 19.0, 21.76732608640487, -0.5326399451699382, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 88800.0000, 
sim time next is 90000.0000, 
raw observation next is [-0.6, 91.0, 0.0, 0.0, 19.0, 21.01752071343852, -0.664278394936526, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.44598337950138506, 0.91, 0.0, 0.0, 0.08333333333333333, 0.25146005945320987, 0.2785738683544913, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1064634], dtype=float32), -0.89829284]. 
=============================================
[2019-04-24 10:00:01,117] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[59.03008 ]
 [58.65748 ]
 [57.372555]
 [55.674744]
 [55.962738]
 [56.48043 ]
 [56.913437]
 [56.21373 ]
 [56.960995]
 [57.24473 ]
 [57.788284]
 [58.193817]
 [57.598923]
 [56.625496]
 [57.22056 ]
 [58.011173]
 [58.795322]
 [57.902294]
 [56.868443]
 [57.383377]
 [58.039143]
 [58.813747]
 [59.36831 ]
 [59.939453]
 [60.534653]], R is [[60.08146286]
 [60.48064804]
 [59.87584305]
 [59.27708435]
 [59.68431473]
 [60.08747101]
 [60.48659515]
 [59.88172913]
 [60.28291321]
 [60.68008423]
 [61.07328415]
 [61.46255112]
 [60.84792709]
 [60.23944855]
 [60.63705444]
 [61.03068542]
 [61.42037964]
 [60.80617523]
 [60.19811249]
 [60.59613037]
 [60.99016953]
 [61.3802681 ]
 [61.76646423]
 [62.1487999 ]
 [62.52731323]].
[2019-04-24 10:00:08,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.19916832e-01 7.07157608e-03 1.36492131e-02 1.51385375e-05
 1.81620692e-07 4.24811515e-06 1.31094168e-06 1.99364163e-02
 4.39404815e-01 1.81859178e-07 2.33652262e-08], sum to 1.0000
[2019-04-24 10:00:08,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5108
[2019-04-24 10:00:08,111] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 19.0, 22.48091745327213, -0.2457308213223406, 0.0, 1.0, 55.0, 46.196536373407596], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 6000.0000, 
sim time next is 7200.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 22.42000795936227, -0.3815723035069014, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.36833399661352245, 0.3728092321643662, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3805824], dtype=float32), -0.9141643]. 
=============================================
[2019-04-24 10:00:08,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9861636e-01 1.6183440e-03 4.3263929e-03 9.0198185e-08 4.3643887e-11
 1.0329912e-08 1.2571442e-09 7.3215831e-04 3.9470664e-01 1.8844371e-10
 7.2409249e-12], sum to 1.0000
[2019-04-24 10:00:09,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3021
[2019-04-24 10:00:09,013] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.133333333333334, 87.0, 0.0, 0.0, 19.0, 21.51705282147873, -0.4584019040811265, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 62400.0000, 
sim time next is 63600.0000, 
raw observation next is [4.766666666666667, 88.0, 0.0, 0.0, 19.0, 21.2500219602837, -0.5028515307875114, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5946445060018468, 0.88, 0.0, 0.0, 0.08333333333333333, 0.270835163356975, 0.3323828230708295, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17842665], dtype=float32), 0.84109825]. 
=============================================
[2019-04-24 10:00:22,198] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3299439e-01 7.9078861e-03 9.0521406e-03 9.3319579e-07 6.3392946e-10
 2.6441731e-07 8.8573220e-09 3.2709218e-03 4.4677341e-01 7.1702205e-10
 3.5506070e-10], sum to 1.0000
[2019-04-24 10:00:22,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5611
[2019-04-24 10:00:22,233] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 19.0, 19.14016945327065, -1.065897333862366, 0.0, 1.0, 55.0, 78.66058790829197], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 363600.0000, 
sim time next is 364800.0000, 
raw observation next is [-15.8, 74.66666666666667, 0.0, 0.0, 19.0, 19.45989992991174, -1.032447373568577, 0.0, 1.0, 55.0, 56.59851616779024], 
processed observation next is [1.0, 0.21739130434782608, 0.024930747922437636, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.1216583274926449, 0.15585087547714097, 0.0, 1.0, 0.8, 0.5659851616779024], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47179228], dtype=float32), -0.6816055]. 
=============================================
[2019-04-24 10:00:29,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7464719e-01 1.1748207e-02 3.3854360e-03 1.8170944e-07 6.5934327e-11
 2.1002965e-08 5.6551541e-10 2.0847672e-03 4.0813419e-01 7.0606729e-11
 3.4793095e-11], sum to 1.0000
[2019-04-24 10:00:29,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2168
[2019-04-24 10:00:29,243] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.23333333333333, 82.0, 36.66666666666666, 694.5, 22.5, 22.14850446167872, -0.5269631391332671, 1.0, 1.0, 55.0, 65.12133002795233], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 379200.0000, 
sim time next is 380400.0000, 
raw observation next is [-14.86666666666667, 74.0, 44.33333333333333, 736.5, 22.5, 22.27918537441982, -0.6214595182732583, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.05078485687903958, 0.74, 0.14777777777777776, 0.8138121546961326, 0.375, 0.3565987812016518, 0.29284682724224725, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.6312, 
noisyNet noise sample is [array([-1.1534944], dtype=float32), 1.9936696]. 
=============================================
[2019-04-24 10:00:29,987] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3065354e-01 1.1679198e-03 9.1423225e-03 5.0981123e-07 2.2651772e-09
 1.1226206e-07 2.2814946e-08 5.1327082e-03 4.5390284e-01 5.2832654e-09
 6.3095756e-10], sum to 1.0000
[2019-04-24 10:00:29,988] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2822
[2019-04-24 10:00:30,007] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.1, 87.0, 0.0, 0.0, 19.0, 19.50648330313152, -0.986278610537629, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 582000.0000, 
sim time next is 583200.0000, 
raw observation next is [-2.3, 87.0, 0.0, 0.0, 19.0, 19.24078612665865, -1.037052086608953, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.3988919667590028, 0.87, 0.0, 0.0, 0.08333333333333333, 0.10339884388822096, 0.154315971130349, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8932501], dtype=float32), -1.5056459]. 
=============================================
[2019-04-24 10:00:34,297] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.42347836e-01 3.13291349e-03 7.45017314e-03 8.43568046e-07
 5.65967606e-10 7.41005550e-08 6.72779432e-09 1.05824159e-03
 2.46009827e-01 6.90539625e-10 1.07970466e-10], sum to 1.0000
[2019-04-24 10:00:34,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4204
[2019-04-24 10:00:34,342] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.366666666666667, 65.0, 0.0, 0.0, 19.0, 19.5673604173183, -0.9886510286697326, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 771600.0000, 
sim time next is 772800.0000, 
raw observation next is [-6.533333333333333, 66.0, 0.0, 0.0, 19.0, 19.39635736764398, -1.027663861602254, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2816251154201293, 0.66, 0.0, 0.0, 0.08333333333333333, 0.11636311397033161, 0.15744537946591533, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.010195], dtype=float32), -0.3223705]. 
=============================================
[2019-04-24 10:00:36,568] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.4764124e-01 6.3232281e-03 5.9988024e-03 1.6929752e-06 6.5412359e-10
 2.0911224e-07 7.3073916e-09 1.3657705e-03 3.3866903e-01 1.2784860e-09
 5.7527916e-10], sum to 1.0000
[2019-04-24 10:00:36,569] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8254
[2019-04-24 10:00:36,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8332220e-01 1.0562172e-02 2.4015626e-02 1.0123922e-05 4.5475691e-08
 1.4086571e-06 2.6827678e-07 7.1390206e-03 4.7494900e-01 5.2177334e-08
 3.9544044e-08], sum to 1.0000
[2019-04-24 10:00:36,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7747
[2019-04-24 10:00:36,715] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 19.0, 18.02390936779433, -1.434216393404361, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 630000.0000, 
sim time next is 631200.0000, 
raw observation next is [-4.5, 71.66666666666667, 0.0, 0.0, 19.0, 17.8907407807867, -1.231127158606842, 0.0, 1.0, 55.0, 85.30634831268077], 
processed observation next is [0.0, 0.30434782608695654, 0.3379501385041552, 0.7166666666666667, 0.0, 0.0, 0.08333333333333333, -0.009104934934441644, 0.08962428046438602, 0.0, 1.0, 0.8, 0.8530634831268077], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7698774], dtype=float32), 0.32611367]. 
=============================================
[2019-04-24 10:00:36,724] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 32.0, 80.0, 0.0, 22.5, 20.663235839247, -0.9805224202093356, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 468000.0000, 
sim time next is 469200.0000, 
raw observation next is [-3.766666666666667, 30.66666666666667, 92.0, 0.0, 22.5, 21.53494129203209, -0.6151111514735027, 1.0, 1.0, 55.0, 105.40988930839558], 
processed observation next is [1.0, 0.43478260869565216, 0.358264081255771, 0.3066666666666667, 0.30666666666666664, 0.0, 0.375, 0.2945784410026742, 0.29496294950883245, 1.0, 1.0, 0.8, 1.0540988930839559], 
reward next is 0.5756, 
noisyNet noise sample is [array([-0.1387726], dtype=float32), 0.054733288]. 
=============================================
[2019-04-24 10:00:39,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8899107e-01 1.4380561e-03 8.7778354e-03 2.9836895e-06 9.7597361e-09
 3.1335230e-07 5.0821733e-08 2.6355451e-03 2.9815409e-01 9.4085557e-09
 1.7234089e-09], sum to 1.0000
[2019-04-24 10:00:39,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0063
[2019-04-24 10:00:39,639] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 57.00000000000001, 0.0, 0.0, 19.0, 19.9218121417962, -0.8663152696129234, 0.0, 1.0, 55.0, 73.65430481463486], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 667200.0000, 
sim time next is 668400.0000, 
raw observation next is [-1.2, 57.0, 0.0, 0.0, 19.0, 20.09659719098989, -1.003252949025474, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.57, 0.0, 0.0, 0.08333333333333333, 0.1747164325824908, 0.165582350324842, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.72808933], dtype=float32), -0.38692126]. 
=============================================
[2019-04-24 10:00:46,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7342651e-01 1.8942648e-03 2.2918312e-03 8.2694768e-08 9.4383477e-12
 1.9608928e-09 9.4957917e-11 1.1192408e-03 3.2126814e-01 9.5368262e-12
 7.6557502e-12], sum to 1.0000
[2019-04-24 10:00:46,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6477
[2019-04-24 10:00:46,116] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.9, 70.66666666666666, 107.3333333333333, 52.16666666666666, 22.5, 22.92238310873106, -0.362337648334695, 1.0, 1.0, 55.0, 49.93475672965502], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 726000.0000, 
sim time next is 727200.0000, 
raw observation next is [-1.7, 68.0, 120.0, 58.5, 22.5, 22.95688449091217, -0.473218882183348, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4155124653739613, 0.68, 0.4, 0.06464088397790055, 0.375, 0.4130737075760142, 0.34226037260555064, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.37171778], dtype=float32), -0.51997066]. 
=============================================
[2019-04-24 10:00:54,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7777904e-01 5.2183407e-04 4.7468109e-04 3.4808995e-08 2.7244925e-12
 1.8965858e-09 2.8742821e-11 3.4974396e-04 2.2087462e-01 1.4761196e-12
 6.1665056e-13], sum to 1.0000
[2019-04-24 10:00:54,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3269
[2019-04-24 10:00:54,451] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.066666666666667, 95.66666666666667, 102.8333333333333, 0.0, 22.5, 22.42916861972672, -0.4683800346678335, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 908400.0000, 
sim time next is 909600.0000, 
raw observation next is [3.433333333333334, 94.33333333333334, 102.6666666666667, 0.0, 22.5, 21.96080251415967, -0.4998008038642063, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5577100646352725, 0.9433333333333335, 0.3422222222222223, 0.0, 0.375, 0.33006687617997255, 0.3333997320452646, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.54540837], dtype=float32), 0.6479685]. 
=============================================
[2019-04-24 10:00:56,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0544358e-01 4.9085444e-04 1.1760413e-03 1.2598389e-07 1.2877467e-10
 1.4902394e-08 8.6596541e-10 1.4061895e-03 1.9148320e-01 3.2324032e-10
 1.2587122e-11], sum to 1.0000
[2019-04-24 10:00:56,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9818
[2019-04-24 10:00:56,913] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [17.56666666666667, 66.33333333333334, 122.1666666666667, 0.0, 19.0, 23.75522921265012, 0.1717545750393634, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1160400.0000, 
sim time next is 1161600.0000, 
raw observation next is [17.93333333333333, 65.66666666666666, 135.0, 0.0, 19.0, 24.16112997852206, 0.4437784683435907, 0.0, 0.0, 55.0, 71.34176725729004], 
processed observation next is [0.0, 0.43478260869565216, 0.9593721144967682, 0.6566666666666666, 0.45, 0.0, 0.08333333333333333, 0.5134274982101715, 0.6479261561145302, 0.0, 0.0, 0.8, 0.7134176725729005], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2083279], dtype=float32), 0.23475799]. 
=============================================
[2019-04-24 10:00:57,413] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.6137968e-01 1.0607737e-04 3.9953829e-04 9.7663690e-09 5.0058214e-14
 9.0569718e-11 1.3140004e-12 2.2728248e-04 1.3788740e-01 1.8085961e-13
 3.9312808e-14], sum to 1.0000
[2019-04-24 10:00:57,413] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6389
[2019-04-24 10:00:57,432] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.8, 93.0, 93.0, 0.0, 22.5, 24.42549622746577, -0.04208321718509089, 1.0, 1.0, 55.0, 64.62349964315248], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 914400.0000, 
sim time next is 915600.0000, 
raw observation next is [4.0, 93.0, 91.0, 0.0, 22.5, 24.37795756852524, -0.02265833744973155, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5734072022160666, 0.93, 0.30333333333333334, 0.0, 0.375, 0.5314964640437699, 0.49244722085008946, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2337772], dtype=float32), 1.021043]. 
=============================================
[2019-04-24 10:00:59,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.1750941e-01 4.8428850e-05 2.2476436e-04 1.1385241e-09 2.2426436e-14
 8.7943049e-11 4.6480956e-13 2.0382873e-04 1.8201359e-01 5.7399574e-14
 3.5089646e-15], sum to 1.0000
[2019-04-24 10:00:59,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2800
[2019-04-24 10:00:59,312] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.53333333333333, 86.0, 126.5, 0.0, 22.5, 24.68662490852883, 0.1864193176297449, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 996000.0000, 
sim time next is 997200.0000, 
raw observation next is [12.7, 86.0, 123.5, 0.0, 22.5, 24.28300807120678, 0.137581987400612, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8144044321329641, 0.86, 0.4116666666666667, 0.0, 0.375, 0.5235840059338983, 0.5458606624668706, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.1634374], dtype=float32), 0.47428337]. 
=============================================
[2019-04-24 10:01:01,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.7322611e-01 5.9538364e-04 9.1487652e-04 2.0194400e-07 5.1944116e-11
 3.1408188e-08 4.3755038e-10 1.0349434e-03 1.2422845e-01 4.4048867e-10
 1.6165460e-11], sum to 1.0000
[2019-04-24 10:01:01,488] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0290
[2019-04-24 10:01:01,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 63.66666666666667, 161.8333333333333, 0.0, 19.0, 25.56289661773053, 0.5245771757310371, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1165200.0000, 
sim time next is 1166400.0000, 
raw observation next is [18.8, 63.0, 165.5, 0.0, 19.0, 25.35651606533122, 0.4918478707635264, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.9833795013850417, 0.63, 0.5516666666666666, 0.0, 0.08333333333333333, 0.6130430054442684, 0.6639492902545088, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8270705], dtype=float32), -0.5369429]. 
=============================================
[2019-04-24 10:01:02,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4110969e-01 5.8748381e-04 1.1671957e-03 1.5448819e-08 2.9858622e-12
 1.9606869e-09 4.5602164e-11 5.5621297e-04 5.5657941e-01 2.3027541e-12
 9.0226687e-13], sum to 1.0000
[2019-04-24 10:01:02,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8833
[2019-04-24 10:01:02,530] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 19.0, 21.17523006511146, -0.5228846959161731, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1405200.0000, 
sim time next is 1406400.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 21.31455254685125, -0.2955254855840661, 0.0, 1.0, 55.0, 78.22618305038986], 
processed observation next is [1.0, 0.2608695652173913, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.27621271223760413, 0.4014915048053113, 0.0, 1.0, 0.8, 0.7822618305038986], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.76351357], dtype=float32), 1.0665662]. 
=============================================
[2019-04-24 10:01:02,850] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.11779428e-01 6.64462277e-04 7.79146678e-04 1.36121185e-08
 3.94053973e-12 1.17774468e-09 1.17530707e-10 1.12685945e-03
 4.85650092e-01 6.07409002e-12 3.42883951e-13], sum to 1.0000
[2019-04-24 10:01:02,851] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6971
[2019-04-24 10:01:02,888] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [14.56666666666667, 78.0, 39.66666666666666, 0.0, 19.0, 25.12848741919871, 0.3848917384108972, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1154400.0000, 
sim time next is 1155600.0000, 
raw observation next is [15.5, 75.0, 57.0, 0.0, 19.0, 25.09202343823091, 0.5155015625662179, 0.0, 1.0, 55.0, 59.330594411388624], 
processed observation next is [0.0, 0.391304347826087, 0.8919667590027703, 0.75, 0.19, 0.0, 0.08333333333333333, 0.5910019531859092, 0.6718338541887393, 0.0, 1.0, 0.8, 0.5933059441138863], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.64584017], dtype=float32), -1.5245526]. 
=============================================
[2019-04-24 10:01:03,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.41717422e-01 6.16903882e-04 4.11433866e-04 1.35753995e-08
 1.82824296e-13 3.81706916e-10 3.73094784e-12 1.59921619e-04
 1.57094404e-01 1.22645373e-12 1.21077112e-13], sum to 1.0000
[2019-04-24 10:01:03,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1919
[2019-04-24 10:01:03,609] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 90.66666666666666, 0.0, 0.0, 22.5, 23.15210475337703, -0.08549046366924169, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1449600.0000, 
sim time next is 1450800.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 22.87764580086604, -0.1346277355315217, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.40647048340550346, 0.4551240881561594, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1355275], dtype=float32), -0.4041397]. 
=============================================
[2019-04-24 10:01:07,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1298927e-01 3.9037634e-04 4.1503800e-04 4.1477222e-09 1.1646353e-13
 6.0710914e-10 2.8537489e-12 1.1158469e-04 2.8609371e-01 3.5192598e-13
 4.4914058e-14], sum to 1.0000
[2019-04-24 10:01:07,252] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4219
[2019-04-24 10:01:07,270] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 50.66666666666666, 78.66666666666667, 403.0000000000001, 22.5, 25.83422823239417, 0.4710439249086342, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1525200.0000, 
sim time next is 1526400.0000, 
raw observation next is [12.2, 50.0, 82.0, 253.0, 22.5, 25.7111234273641, 0.3630700736418306, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8005540166204987, 0.5, 0.2733333333333333, 0.2795580110497238, 0.375, 0.6425936189470084, 0.6210233578806102, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28864577], dtype=float32), 0.09125029]. 
=============================================
[2019-04-24 10:01:09,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6845980e-01 9.1306469e-04 2.5724579e-04 9.6859143e-09 2.1483316e-12
 8.4217344e-10 7.7867178e-11 1.1216945e-03 2.2924814e-01 3.0393685e-12
 3.0620249e-13], sum to 1.0000
[2019-04-24 10:01:09,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6330
[2019-04-24 10:01:09,520] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 79.0, 0.0, 0.0, 19.0, 23.23881993991485, -0.01636285076400423, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1562400.0000, 
sim time next is 1563600.0000, 
raw observation next is [4.800000000000001, 81.33333333333334, 0.0, 0.0, 19.0, 23.05091666133978, -0.04843083993214814, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5955678670360112, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.42090972177831504, 0.483856386689284, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.61554164], dtype=float32), -0.5374363]. 
=============================================
[2019-04-24 10:01:12,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3828826e-01 1.1153048e-03 3.1002811e-03 3.7699067e-07 1.2318557e-09
 3.8032681e-08 1.7851656e-08 1.8640524e-03 3.5563174e-01 4.3857623e-10
 5.1415362e-11], sum to 1.0000
[2019-04-24 10:01:12,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2284
[2019-04-24 10:01:12,640] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 85.66666666666667, 0.0, 0.0, 19.0, 20.86272063308927, -0.3842821686883164, 0.0, 1.0, 55.0, 86.65222777543237], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1743600.0000, 
sim time next is 1744800.0000, 
raw observation next is [-0.6, 84.33333333333333, 0.0, 0.0, 19.0, 21.47055087269602, -0.4912963475196895, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.44598337950138506, 0.8433333333333333, 0.0, 0.0, 0.08333333333333333, 0.2892125727246683, 0.3362345508267702, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38369048], dtype=float32), -0.6970408]. 
=============================================
[2019-04-24 10:01:13,845] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.7203143e-01 6.4523355e-04 4.5759298e-04 5.4399329e-09 1.5195651e-12
 3.6817113e-10 1.8054586e-11 4.8064094e-04 2.2638515e-01 6.2811312e-13
 2.4077200e-13], sum to 1.0000
[2019-04-24 10:01:13,858] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6967
[2019-04-24 10:01:13,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8983785e-01 8.3730224e-04 1.5573604e-02 1.3438895e-06 1.2405747e-08
 9.7799926e-08 4.5977913e-08 4.8918072e-03 3.8885793e-01 4.8315378e-09
 6.6619693e-10], sum to 1.0000
[2019-04-24 10:01:13,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5637
[2019-04-24 10:01:13,954] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 22.5, 21.99206551094892, -0.3260675267489235, 1.0, 1.0, 55.0, 65.37565754661486], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1496400.0000, 
sim time next is 1497600.0000, 
raw observation next is [1.1, 100.0, 9.0, 0.0, 22.5, 22.09506798830515, -0.4362850278342615, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.49307479224376743, 1.0, 0.03, 0.0, 0.375, 0.3412556656920958, 0.35457165738857954, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1618829], dtype=float32), -0.70725954]. 
=============================================
[2019-04-24 10:01:13,980] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.0, 14.5, 0.0, 19.0, 19.59253861831255, -0.9287777386879457, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1789200.0000, 
sim time next is 1790400.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 19.0, 19.31089803182846, -0.9845803026112233, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.3545706371191136, 0.82, 0.0, 0.0, 0.08333333333333333, 0.1092415026523718, 0.1718065657962589, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0978715], dtype=float32), 0.18148142]. 
=============================================
[2019-04-24 10:01:15,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2618051e-01 1.7436838e-03 1.5208731e-02 2.3835273e-06 1.9375488e-09
 1.1984905e-07 6.4641505e-08 8.4264937e-04 4.5602185e-01 4.7080939e-09
 2.8216063e-10], sum to 1.0000
[2019-04-24 10:01:15,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2825
[2019-04-24 10:01:15,114] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 79.0, 0.0, 0.0, 19.0, 18.77643521439358, -1.151408368931922, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1814400.0000, 
sim time next is 1815600.0000, 
raw observation next is [-5.2, 78.66666666666667, 0.0, 0.0, 19.0, 18.43222852176162, -1.210945741533836, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.31855955678670367, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.036019043480134925, 0.09635141948872132, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5224692], dtype=float32), 0.10121159]. 
=============================================
[2019-04-24 10:01:26,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8465958e-01 1.0735203e-03 3.7113298e-03 7.6266730e-08 1.5541710e-11
 7.0294215e-09 4.7600540e-10 6.0189544e-04 5.0995350e-01 1.7468584e-11
 4.7929646e-12], sum to 1.0000
[2019-04-24 10:01:26,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3040
[2019-04-24 10:01:26,942] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 22.5, 23.16181200125512, -0.1212737866352616, 1.0, 1.0, 55.0, 65.60767269196722], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2142000.0000, 
sim time next is 2143200.0000, 
raw observation next is [-5.2, 77.0, 0.0, 0.0, 22.5, 23.61562026259595, -0.2503697465414874, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.31855955678670367, 0.77, 0.0, 0.0, 0.375, 0.4679683552163292, 0.4165434178195042, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6756329], dtype=float32), 0.25816318]. 
=============================================
[2019-04-24 10:01:27,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5341928e-01 8.1990764e-04 1.1406470e-03 6.7682315e-08 8.0591029e-12
 3.4827827e-09 1.7978466e-10 6.4250856e-04 2.4397762e-01 1.1290228e-11
 3.2773317e-12], sum to 1.0000
[2019-04-24 10:01:27,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4149
[2019-04-24 10:01:27,784] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.133333333333334, 86.66666666666667, 24.33333333333334, 0.0, 22.5, 20.53893533703765, -0.8616880450534988, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2017200.0000, 
sim time next is 2018400.0000, 
raw observation next is [-6.066666666666666, 86.33333333333333, 35.66666666666666, 0.0, 22.5, 20.50362343648404, -0.876209068331543, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2945521698984303, 0.8633333333333333, 0.11888888888888886, 0.0, 0.375, 0.2086352863736701, 0.20793031055615233, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.79057634], dtype=float32), -0.054035287]. 
=============================================
[2019-04-24 10:01:32,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2111477e-01 1.0843017e-03 1.4701807e-03 5.1584792e-08 1.8182763e-11
 1.4030220e-08 9.1658547e-10 1.5805947e-03 4.7475016e-01 2.5690859e-11
 1.3247696e-11], sum to 1.0000
[2019-04-24 10:01:32,659] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9526
[2019-04-24 10:01:32,754] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.8, 84.33333333333333, 0.0, 0.0, 19.0, 20.65039261488228, -0.6163484653075026, 0.0, 1.0, 55.0, 77.52904665957212], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1993200.0000, 
sim time next is 1994400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 21.24846997817119, -0.559890266818785, 0.0, 1.0, 55.0, 51.38473550946776], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.27070583151426586, 0.313369911060405, 0.0, 1.0, 0.8, 0.5138473550946776], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8803519], dtype=float32), -0.6079269]. 
=============================================
[2019-04-24 10:01:34,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4534665e-01 2.6145221e-03 3.9039014e-03 9.0540048e-08 6.1230417e-11
 1.8058875e-08 1.4530482e-09 1.2057108e-03 5.4692912e-01 3.5486957e-11
 1.1590688e-11], sum to 1.0000
[2019-04-24 10:01:34,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4534
[2019-04-24 10:01:35,023] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 19.0, 21.01800640408997, -0.5905366341843298, 0.0, 1.0, 55.0, 52.92005792369284], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1995600.0000, 
sim time next is 1996800.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 21.64762386463871, -0.5362380515902732, 0.0, 1.0, 55.0, 50.92324466912091], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.3039686553865592, 0.3212539828032423, 0.0, 1.0, 0.8, 0.5092324466912092], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4743253], dtype=float32), 0.8613387]. 
=============================================
[2019-04-24 10:01:39,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0039061e-01 6.3832605e-04 1.4186666e-03 1.2063352e-07 5.2035081e-11
 1.9998497e-08 1.1645007e-09 1.0950543e-03 3.9645723e-01 7.9828873e-11
 1.0988499e-11], sum to 1.0000
[2019-04-24 10:01:39,527] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0876
[2019-04-24 10:01:39,594] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 21.24716797025604, -0.5853919729340418, 0.0, 1.0, 55.0, 71.54364680118059], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2172000.0000, 
sim time next is 2173200.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 21.18678640098367, -0.7340580469645882, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.2655655334153059, 0.25531398434513725, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1571752], dtype=float32), 0.5169388]. 
=============================================
[2019-04-24 10:01:45,477] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5956820e-01 2.2800947e-03 1.0591825e-02 3.0366533e-07 2.5214345e-10
 5.6919522e-08 3.8376387e-09 2.9523103e-03 5.2460718e-01 2.1514712e-10
 5.9371598e-11], sum to 1.0000
[2019-04-24 10:01:45,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9937
[2019-04-24 10:01:45,560] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 20.93650057430964, -0.6535059097712298, 0.0, 1.0, 55.0, 57.948715130413255], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2168400.0000, 
sim time next is 2169600.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 21.31075508194726, -0.6038717395935285, 0.0, 1.0, 55.0, 55.90323677420554], 
processed observation next is [1.0, 0.08695652173913043, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.2758962568289383, 0.2987094201354905, 0.0, 1.0, 0.8, 0.5590323677420553], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7298543], dtype=float32), -0.09091052]. 
=============================================
[2019-04-24 10:01:46,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9207764e-01 4.9405964e-03 3.3748827e-03 2.3800901e-07 1.5497918e-10
 2.7010300e-08 3.8302974e-09 3.9749360e-03 2.9563162e-01 1.4090629e-10
 2.6388792e-11], sum to 1.0000
[2019-04-24 10:01:46,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9593
[2019-04-24 10:01:46,100] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.633333333333333, 84.66666666666666, 0.0, 0.0, 19.0, 20.56595961451808, -0.8874370469059949, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2256000.0000, 
sim time next is 2257200.0000, 
raw observation next is [-7.8, 86.0, 0.0, 0.0, 19.0, 20.13548501442945, -0.7647961731920893, 0.0, 1.0, 55.0, 75.14651314448506], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.86, 0.0, 0.0, 0.08333333333333333, 0.1779570845357874, 0.2450679422693036, 0.0, 1.0, 0.8, 0.7514651314448506], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0210595], dtype=float32), -0.24376313]. 
=============================================
[2019-04-24 10:02:00,555] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.81366289e-01 1.18340505e-03 6.21373765e-04 7.39589652e-08
 1.14390485e-11 3.92244104e-09 1.29278754e-10 6.01097592e-04
 2.16227755e-01 2.12141936e-11 1.97917529e-12], sum to 1.0000
[2019-04-24 10:02:00,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3738
[2019-04-24 10:02:00,635] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 65.0, 122.5, 183.0, 22.5, 23.62559929048953, -0.1394853854000682, 1.0, 1.0, 55.0, 73.56747164468592], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2628000.0000, 
sim time next is 2629200.0000, 
raw observation next is [-4.633333333333334, 64.0, 142.1666666666667, 244.3333333333333, 22.5, 23.79791895417342, -0.2346498879834324, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3342566943674977, 0.64, 0.473888888888889, 0.26998158379373843, 0.375, 0.48315991284778487, 0.4217833706721892, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5780276], dtype=float32), 0.08727266]. 
=============================================
[2019-04-24 10:02:03,645] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.6913666e-01 6.5922020e-03 1.6065285e-02 1.5773825e-06 4.9917079e-09
 3.9612019e-07 3.0902797e-08 6.6729975e-03 6.0153079e-01 1.3000511e-08
 1.1034690e-09], sum to 1.0000
[2019-04-24 10:02:03,665] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6928
[2019-04-24 10:02:03,785] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.2, 67.66666666666667, 0.0, 0.0, 19.0, 21.49507631471608, -0.7007354692646768, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2356800.0000, 
sim time next is 2358000.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 19.0, 21.09522555412028, -0.599114717753612, 0.0, 1.0, 55.0, 70.59882001109524], 
processed observation next is [0.0, 0.30434782608695654, 0.368421052631579, 0.69, 0.0, 0.0, 0.08333333333333333, 0.2579354628433566, 0.30029509408212934, 0.0, 1.0, 0.8, 0.7059882001109524], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39412937], dtype=float32), -0.6701664]. 
=============================================
[2019-04-24 10:02:06,421] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.6229872e-01 8.6426381e-03 3.4412351e-02 8.7902199e-06 1.9846337e-07
 2.0604114e-06 9.7615384e-07 9.8942537e-03 3.8473997e-01 1.2630579e-07
 2.9282951e-08], sum to 1.0000
[2019-04-24 10:02:06,423] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6078
[2019-04-24 10:02:06,447] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.8802744e-01 3.6323774e-03 7.4760495e-03 1.0007178e-06 3.0953551e-09
 2.6070848e-07 1.4388926e-08 1.9929560e-03 2.9886991e-01 2.4083395e-09
 3.2461681e-10], sum to 1.0000
[2019-04-24 10:02:06,447] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7474
[2019-04-24 10:02:06,462] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 46.33333333333334, 0.0, 0.0, 19.0, 19.86964023783032, -1.030733827517684, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2421600.0000, 
sim time next is 2422800.0000, 
raw observation next is [-6.2, 48.0, 0.0, 0.0, 19.0, 19.50680997497308, -0.9107483608510024, 0.0, 1.0, 50.0, 70.91057807911076], 
processed observation next is [0.0, 0.043478260869565216, 0.2908587257617729, 0.48, 0.0, 0.0, 0.08333333333333333, 0.12556749791442337, 0.19641721304966586, 0.0, 1.0, 0.7, 0.7091057807911076], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20604952], dtype=float32), 1.4771993]. 
=============================================
[2019-04-24 10:02:06,496] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 40.0, 0.0, 0.0, 19.0, 21.47076430172851, -0.5383034390064336, 0.0, 1.0, 25.0, 60.349119030674856], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2509200.0000, 
sim time next is 2510400.0000, 
raw observation next is [-1.7, 39.33333333333334, 0.0, 0.0, 19.0, 21.78777353720202, -0.486567589621509, 0.0, 1.0, 55.0, 48.06146050327826], 
processed observation next is [1.0, 0.043478260869565216, 0.4155124653739613, 0.3933333333333334, 0.0, 0.0, 0.08333333333333333, 0.3156477947668351, 0.33781080345949704, 0.0, 1.0, 0.8, 0.48061460503278264], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.133869], dtype=float32), -1.031052]. 
=============================================
[2019-04-24 10:02:11,152] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0051665e-01 1.4629053e-02 5.6602224e-03 8.2768554e-07 4.2453319e-10
 5.5748675e-08 5.9189036e-09 3.4206777e-03 4.7577247e-01 6.1538957e-10
 1.4984947e-10], sum to 1.0000
[2019-04-24 10:02:11,152] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5115
[2019-04-24 10:02:11,207] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 20.90542106699086, -0.7043991316335233, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2766000.0000, 
sim time next is 2767200.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 20.84934338684324, -0.572740506969104, 0.0, 1.0, 20.0, 63.04564194369167], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.23744528223693676, 0.30908649767696533, 0.0, 1.0, 0.1, 0.6304564194369167], 
reward next is 0.2695, 
noisyNet noise sample is [array([0.7968561], dtype=float32), -0.8194993]. 
=============================================
[2019-04-24 10:02:19,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7275134e-01 3.2640051e-03 9.2699211e-03 1.4155100e-06 6.0560388e-09
 2.9250842e-07 5.1230185e-08 5.3137094e-03 4.0939915e-01 8.2366123e-09
 1.4049746e-09], sum to 1.0000
[2019-04-24 10:02:19,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8547
[2019-04-24 10:02:19,143] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 77.0, 0.0, 0.0, 19.0, 18.75873626875647, -0.8869006539197565, 0.0, 1.0, 55.0, 105.51077745710151], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2964000.0000, 
sim time next is 2965200.0000, 
raw observation next is [-4.0, 77.0, 14.0, 15.66666666666666, 19.0, 19.81274755142978, -0.7720383748219639, 0.0, 1.0, 55.0, 68.16497954614378], 
processed observation next is [0.0, 0.30434782608695654, 0.3518005540166205, 0.77, 0.04666666666666667, 0.017311233885819514, 0.08333333333333333, 0.15106229595248166, 0.24265387505934535, 0.0, 1.0, 0.8, 0.6816497954614378], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03566711], dtype=float32), -0.9693465]. 
=============================================
[2019-04-24 10:02:25,675] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.20922863e-01 4.31153603e-04 1.97807443e-03 2.18053042e-08
 9.43932432e-13 1.53021951e-09 1.02344626e-10 5.18893707e-04
 3.76148939e-01 9.54691708e-12 2.52505211e-13], sum to 1.0000
[2019-04-24 10:02:25,675] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9269
[2019-04-24 10:02:25,710] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.666666666666667, 82.66666666666667, 0.0, 0.0, 19.0, 22.6084247636685, -0.1786747056124138, 0.0, 1.0, 55.0, 51.36639593445789], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2932800.0000, 
sim time next is 2934000.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 22.73541509595908, -0.167906579900637, 0.0, 1.0, 55.0, 50.53790291234205], 
processed observation next is [1.0, 1.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.3946179246632567, 0.444031140033121, 0.0, 1.0, 0.8, 0.5053790291234205], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15799345], dtype=float32), 0.4439346]. 
=============================================
[2019-04-24 10:02:25,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0033137e-01 6.2962680e-04 1.7811053e-03 3.4652924e-08 5.9816632e-13
 2.1544158e-09 1.2885915e-10 2.5452703e-04 3.9700335e-01 8.4881165e-12
 4.8337251e-13], sum to 1.0000
[2019-04-24 10:02:25,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9746
[2019-04-24 10:02:26,057] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.6794831144009, -0.4746852158939165, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2936400.0000, 
sim time next is 2937600.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.54884179071425, -0.3217121894295009, 0.0, 1.0, 55.0, 77.93587560818898], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.2957368158928541, 0.3927626035234997, 0.0, 1.0, 0.8, 0.7793587560818898], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15799345], dtype=float32), 0.4439346]. 
=============================================
[2019-04-24 10:02:28,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4721142e-01 3.4020926e-04 2.1500542e-04 5.6410818e-09 4.0909889e-13
 2.4861413e-10 2.3024282e-11 1.9395302e-04 1.5203939e-01 5.8307260e-13
 1.4632291e-13], sum to 1.0000
[2019-04-24 10:02:28,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5961
[2019-04-24 10:02:28,885] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 22.5, 22.64011964333732, -0.2724530264930214, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2919600.0000, 
sim time next is 2920800.0000, 
raw observation next is [-1.0, 87.33333333333334, 0.0, 0.0, 22.5, 22.25482770677027, -0.3582299023963551, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.8733333333333334, 0.0, 0.0, 0.375, 0.35456897556418926, 0.3805900325345483, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16017333], dtype=float32), 0.42782202]. 
=============================================
[2019-04-24 10:02:37,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7522637e-01 7.3166704e-03 4.1148365e-03 4.3221428e-07 4.2225754e-11
 1.9809312e-08 2.5820535e-09 1.1431507e-03 4.1219851e-01 1.5160670e-10
 4.0303014e-11], sum to 1.0000
[2019-04-24 10:02:37,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7111
[2019-04-24 10:02:37,263] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-11.0, 84.0, 44.0, 245.0, 22.5, 21.56355310087347, -0.5925499273606933, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3312000.0000, 
sim time next is 3313200.0000, 
raw observation next is [-10.33333333333333, 81.66666666666667, 72.0, 345.6666666666667, 22.5, 21.55107979765348, -0.3256023135311739, 1.0, 1.0, 55.0, 92.22527191209807], 
processed observation next is [1.0, 0.34782608695652173, 0.17636195752539252, 0.8166666666666668, 0.24, 0.3819521178637201, 0.375, 0.29592331647112324, 0.3914658954896087, 1.0, 1.0, 0.8, 0.9222527191209806], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.240163], dtype=float32), 0.71216667]. 
=============================================
[2019-04-24 10:02:50,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1229601e-01 3.4018799e-03 3.5689957e-03 1.9255103e-07 1.2939591e-10
 1.9158435e-08 2.1289728e-09 1.1268578e-03 2.7960601e-01 1.5134206e-10
 1.6209024e-11], sum to 1.0000
[2019-04-24 10:02:50,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9067
[2019-04-24 10:02:50,366] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.333333333333333, 61.66666666666667, 0.0, 0.0, 19.0, 23.64514136377764, 0.1042939702126525, 0.0, 1.0, 55.0, 71.36857490922826], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3699600.0000, 
sim time next is 3700800.0000, 
raw observation next is [3.0, 63.0, 0.0, 0.0, 19.0, 24.24767105821817, 0.1749309327776966, 0.0, 1.0, 55.0, 47.60683690650146], 
processed observation next is [0.0, 0.8695652173913043, 0.5457063711911359, 0.63, 0.0, 0.0, 0.08333333333333333, 0.5206392548515142, 0.5583103109258989, 0.0, 1.0, 0.8, 0.47606836906501454], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3185731], dtype=float32), 1.7078301]. 
=============================================
[2019-04-24 10:02:51,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.4878412e-01 7.1473565e-04 5.7777594e-04 5.3085190e-09 1.6340342e-13
 1.1542872e-10 8.2058457e-12 2.8330524e-04 2.4964006e-01 6.9021601e-13
 1.8085040e-13], sum to 1.0000
[2019-04-24 10:02:51,889] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5195
[2019-04-24 10:02:52,005] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 88.0, 107.6666666666667, 735.5, 22.5, 24.51161575151708, 0.3235605505136318, 1.0, 1.0, 55.0, 69.51167661393947], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3234000.0000, 
sim time next is 3235200.0000, 
raw observation next is [-2.6, 84.0, 109.6666666666667, 761.8333333333334, 22.5, 24.96064332911802, 0.2625785965548558, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3905817174515236, 0.84, 0.3655555555555557, 0.841804788213628, 0.375, 0.5800536107598351, 0.5875261988516186, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1897254], dtype=float32), 0.5576452]. 
=============================================
[2019-04-24 10:02:54,568] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-24 10:02:54,581] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:02:54,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:54,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run6
[2019-04-24 10:02:54,618] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:02:54,636] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:54,637] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:02:54,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:54,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run6
[2019-04-24 10:02:54,794] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run6
[2019-04-24 10:04:53,242] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.21410508], dtype=float32), 0.30771926]
[2019-04-24 10:04:53,242] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [14.36666666666667, 69.66666666666667, 25.83333333333334, 151.6666666666667, 22.5, 26.7941346447586, 0.9617660494676775, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:04:53,242] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:04:53,243] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [8.0461931e-01 3.7582958e-04 5.9856841e-04 6.6099242e-09 8.7505480e-13
 5.0452698e-10 7.7622657e-12 5.3716352e-04 1.9386905e-01 1.1777215e-12
 6.3178975e-14], sampled 0.6203701117521191
[2019-04-24 10:04:56,396] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.21410508], dtype=float32), 0.30771926]
[2019-04-24 10:04:56,396] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [10.2, 59.0, 0.0, 0.0, 19.0, 25.37628575300358, 0.4861265378179625, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:04:56,396] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:04:56,397] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.7883184e-01 5.6943606e-04 1.1135581e-03 7.9161310e-08 3.3296064e-11
 9.0689625e-09 1.5735876e-10 6.0668064e-04 2.1887827e-01 4.3118811e-11
 2.3110131e-12], sampled 0.18837409981185793
[2019-04-24 10:04:56,696] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2898.6491 87935.4962 168.4661
[2019-04-24 10:04:56,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:04:56,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:04:56,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:04:56,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:04:56,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:04:56,716] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:04:56,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:04:56,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:04:56,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:04:56,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:04:56,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:04:56,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:04:59,377] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.21410508], dtype=float32), 0.30771926]
[2019-04-24 10:04:59,377] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [2.783932498, 47.42019546, 0.0, 0.0, 19.0, 22.7236836868258, -0.3273089968686335, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:04:59,377] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:04:59,378] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [5.2821565e-01 3.9447933e-03 1.4579077e-02 1.8378585e-06 3.0233402e-09
 2.1270537e-07 2.5221199e-08 2.3805420e-03 4.5087790e-01 5.7920473e-09
 6.7793526e-10], sampled 0.6813230728935605
[2019-04-24 10:05:04,006] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2634.1098 99471.2442 -149.0968
[2019-04-24 10:05:04,027] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:04,027] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:04,027] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:04,027] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:04,027] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:04,027] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:04,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:04,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:04,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:04,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:04,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:04,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:09,079] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2586.6744 102936.3764 -306.2293
[2019-04-24 10:05:09,099] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:09,099] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:09,099] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:09,099] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:09,099] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:09,099] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:09,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:09,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:09,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:09,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:09,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:09,209] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:05:10,102] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 250000, evaluation results [250000.0, 2634.109810112687, 99471.24419690484, -149.09680748004703, 2898.6490574370982, 87935.49620459895, 168.46610943216473, 2586.674389473733, 102936.37636902426, -306.22928900955304]
[2019-04-24 10:05:15,478] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1975996e-01 1.3536026e-03 9.7358687e-04 3.1523115e-08 1.8393160e-12
 3.5784042e-09 3.5486981e-11 2.9606425e-04 1.7761672e-01 7.6887073e-12
 2.1055698e-13], sum to 1.0000
[2019-04-24 10:05:15,478] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5322
[2019-04-24 10:05:15,513] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 24.03768018456586, 0.1324455600531807, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3530400.0000, 
sim time next is 3531600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 23.68420950847704, 0.07118286048619395, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.47368412570641993, 0.5237276201620646, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8742558], dtype=float32), 1.389578]. 
=============================================
[2019-04-24 10:05:16,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.1984162e-01 1.5439907e-04 3.3552360e-04 1.0678521e-08 3.0129876e-12
 1.0228612e-09 6.9372477e-12 3.1025845e-04 1.7935827e-01 1.3667105e-12
 3.5141559e-13], sum to 1.0000
[2019-04-24 10:05:16,021] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5467
[2019-04-24 10:05:16,076] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 50.0, 21.16666666666666, 213.3333333333333, 22.5, 25.8188645647433, 0.4306677935692719, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3518400.0000, 
sim time next is 3519600.0000, 
raw observation next is [2.333333333333333, 51.0, 10.83333333333333, 125.8333333333333, 22.5, 25.51007975925076, 0.4153034563891909, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5272391505078486, 0.51, 0.0361111111111111, 0.13904235727440142, 0.375, 0.6258399799375635, 0.6384344854630636, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.87260026], dtype=float32), 0.790621]. 
=============================================
[2019-04-24 10:05:24,828] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.1162897e-01 5.3878716e-04 1.0410309e-03 6.1149308e-08 1.6334371e-11
 2.6422875e-08 2.3481689e-11 2.4540719e-04 2.8654575e-01 1.7728695e-11
 2.1456214e-12], sum to 1.0000
[2019-04-24 10:05:24,830] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4615
[2019-04-24 10:05:24,858] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 22.5, 24.15323082028053, 0.2781556035770705, 1.0, 1.0, 55.0, 75.2554659391779], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3955200.0000, 
sim time next is 3956400.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 22.5, 24.58547482290542, 0.1666345786598387, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.296398891966759, 0.41, 0.0, 0.0, 0.375, 0.5487895685754518, 0.5555448595532796, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14859857], dtype=float32), -0.26403362]. 
=============================================
[2019-04-24 10:05:37,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3893199e-01 7.8705774e-04 4.9388609e-03 3.4502730e-08 2.5164199e-11
 6.9569892e-09 1.9342190e-10 2.0532862e-03 3.5328883e-01 4.2248656e-11
 5.4280924e-12], sum to 1.0000
[2019-04-24 10:05:37,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3684
[2019-04-24 10:05:37,145] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.5, 69.0, 0.0, 0.0, 19.0, 22.57516902923483, -0.2888580337444996, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4593600.0000, 
sim time next is 4594800.0000, 
raw observation next is [-1.666666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 22.23692566767752, -0.3459124735088901, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4164358264081256, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.3530771389731268, 0.3846958421637033, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7657442], dtype=float32), 0.84219354]. 
=============================================
[2019-04-24 10:05:37,916] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8516455e-01 2.2626617e-03 1.2343691e-03 2.2529019e-08 9.1958056e-12
 3.3313183e-09 5.9918001e-11 1.1333443e-03 4.1020501e-01 1.3071720e-11
 4.5820173e-13], sum to 1.0000
[2019-04-24 10:05:37,918] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1638
[2019-04-24 10:05:37,948] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 80.0, 0.0, 0.0, 19.0, 24.4661079491741, 0.155799598338196, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4431600.0000, 
sim time next is 4432800.0000, 
raw observation next is [2.0, 80.0, 0.0, 0.0, 22.5, 23.9648651467925, 0.06763635526279355, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.8, 0.0, 0.0, 0.375, 0.49707209556604176, 0.5225454517542646, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6314087], dtype=float32), 0.6161052]. 
=============================================
[2019-04-24 10:05:38,223] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.1454731e-01 3.8340183e-03 1.0440624e-02 9.0269725e-07 3.1031193e-09
 1.8221938e-07 4.5156170e-08 5.3401194e-03 3.6583677e-01 2.9400260e-09
 6.1717342e-10], sum to 1.0000
[2019-04-24 10:05:38,224] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7089
[2019-04-24 10:05:38,263] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.0, 38.0, 209.5, 572.3333333333334, 19.0, 22.5579169549708, -0.06586142669755933, 0.0, 1.0, 55.0, 67.70379121037936], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4196400.0000, 
sim time next is 4197600.0000, 
raw observation next is [2.0, 40.0, 200.5, 379.0, 19.0, 23.50467856154629, 0.03651506905966428, 0.0, 1.0, 55.0, 43.51650747205924], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.4, 0.6683333333333333, 0.41878453038674035, 0.08333333333333333, 0.45872321346219075, 0.5121716896865548, 0.0, 1.0, 0.8, 0.4351650747205924], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.99832296], dtype=float32), 0.49728835]. 
=============================================
[2019-04-24 10:05:38,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3052386e-01 6.9499778e-04 2.5194280e-03 4.9499175e-08 1.1801603e-10
 1.6199621e-08 8.6640517e-10 1.0858487e-03 3.6517581e-01 7.4296888e-11
 1.8249226e-12], sum to 1.0000
[2019-04-24 10:05:38,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0371
[2019-04-24 10:05:38,333] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.199999999999999, 73.0, 0.0, 0.0, 19.0, 24.08274630404333, 0.1190466054362019, 0.0, 1.0, 25.0, 50.64980505538391], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4308000.0000, 
sim time next is 4309200.0000, 
raw observation next is [5.1, 73.0, 0.0, 0.0, 19.0, 24.19645822675765, 0.02300831191313925, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6038781163434903, 0.73, 0.0, 0.0, 0.08333333333333333, 0.5163715188964707, 0.5076694373043797, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7364342], dtype=float32), 1.272292]. 
=============================================
[2019-04-24 10:05:39,194] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.8207222e-01 1.7714811e-03 1.7518423e-02 1.2562070e-06 1.7113888e-09
 1.3371495e-07 1.0745103e-08 1.2919512e-03 2.9734454e-01 1.7998736e-09
 2.2400759e-10], sum to 1.0000
[2019-04-24 10:05:39,194] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3107
[2019-04-24 10:05:39,203] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 19.0, 23.14540050933118, -0.2765762321362766, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4227600.0000, 
sim time next is 4228800.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 19.0, 22.58690584910542, -0.3887926659862355, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4903047091412743, 0.47, 0.0, 0.0, 0.08333333333333333, 0.38224215409211837, 0.3704024446712548, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.93264794], dtype=float32), -1.2475586]. 
=============================================
[2019-04-24 10:05:40,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.74907136e-01 1.05433585e-03 1.19150071e-04 7.75370079e-09
 6.03542891e-14 1.24860192e-10 2.79317845e-12 2.59356952e-04
 1.23659976e-01 1.40244167e-13 5.20791872e-14], sum to 1.0000
[2019-04-24 10:05:40,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9430
[2019-04-24 10:05:40,664] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 86.0, 208.0, 88.5, 22.5, 25.34487137874599, 0.2933214946733873, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4442400.0000, 
sim time next is 4443600.0000, 
raw observation next is [1.0, 86.0, 236.6666666666667, 126.8333333333333, 22.5, 25.52925356498252, 0.5167013368025192, 1.0, 1.0, 55.0, 70.58010173276745], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.86, 0.7888888888888891, 0.14014732965009205, 0.375, 0.6274377970818765, 0.672233778934173, 1.0, 1.0, 0.8, 0.7058010173276744], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9519705], dtype=float32), 0.7479093]. 
=============================================
[2019-04-24 10:05:42,370] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.4648515e-01 5.4667741e-03 6.8402491e-03 4.2417405e-06 1.9711837e-08
 7.7842105e-07 6.2861808e-08 6.3674035e-03 3.3483535e-01 1.2501509e-08
 9.2219343e-10], sum to 1.0000
[2019-04-24 10:05:42,373] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5785
[2019-04-24 10:05:42,407] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 46.0, 0.0, 0.0, 19.0, 21.52961210617413, -0.4089094403025254, 0.0, 1.0, 55.0, 81.12886475974798], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4239600.0000, 
sim time next is 4240800.0000, 
raw observation next is [3.0, 45.0, 0.0, 0.0, 19.0, 22.10220458137166, -0.4986680245528853, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.5457063711911359, 0.45, 0.0, 0.0, 0.08333333333333333, 0.34185038178097155, 0.3337773251490382, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6166884], dtype=float32), 0.29351854]. 
=============================================
[2019-04-24 10:05:42,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4937203e-01 1.2524712e-03 4.0363253e-04 8.7243786e-09 1.4980961e-12
 1.1072567e-09 5.1329787e-12 3.3193183e-04 1.4863993e-01 7.3649436e-13
 1.5742934e-13], sum to 1.0000
[2019-04-24 10:05:42,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7834
[2019-04-24 10:05:42,649] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.1, 31.66666666666666, 179.6666666666667, 524.1666666666667, 22.5, 26.24134908231245, 0.5725402611556691, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4372800.0000, 
sim time next is 4374000.0000, 
raw observation next is [13.9, 32.0, 149.0, 314.5, 22.5, 26.23436509670599, 0.5302347166822773, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.847645429362881, 0.32, 0.49666666666666665, 0.3475138121546961, 0.375, 0.6861970913921658, 0.6767449055607591, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03531453], dtype=float32), -0.64679277]. 
=============================================
[2019-04-24 10:05:43,322] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.7161256e-01 4.4589317e-03 6.9207456e-03 2.9824940e-07 2.8605179e-10
 3.1161306e-08 3.4384746e-09 1.6298130e-03 3.1537762e-01 7.5124074e-10
 4.3201036e-11], sum to 1.0000
[2019-04-24 10:05:43,324] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2154
[2019-04-24 10:05:43,355] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 52.0, 120.1666666666667, 842.8333333333334, 19.0, 22.91185156170871, -0.2303152609367732, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4278000.0000, 
sim time next is 4279200.0000, 
raw observation next is [7.0, 52.0, 131.3333333333333, 825.3333333333334, 19.0, 22.65253177261395, -0.2589450918587393, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.6565096952908588, 0.52, 0.4377777777777776, 0.9119705340699816, 0.08333333333333333, 0.3877109810511626, 0.41368496938042026, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3912538], dtype=float32), 1.3018904]. 
=============================================
[2019-04-24 10:05:47,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9246188e-01 3.5686619e-03 7.4653523e-03 5.2185615e-06 1.1897046e-08
 8.7829051e-07 1.4996060e-07 9.0437876e-03 3.8745403e-01 2.3387576e-08
 4.0149950e-09], sum to 1.0000
[2019-04-24 10:05:47,379] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8459
[2019-04-24 10:05:47,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 20.18569503255594, -0.8199121503506803, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4854000.0000, 
sim time next is 4855200.0000, 
raw observation next is [-3.666666666666667, 67.33333333333333, 0.0, 0.0, 19.0, 20.59180165832524, -0.5576248571894176, 0.0, 1.0, 55.0, 84.67334961658393], 
processed observation next is [0.0, 0.17391304347826086, 0.3610341643582641, 0.6733333333333333, 0.0, 0.0, 0.08333333333333333, 0.21598347152710348, 0.3141250476035275, 0.0, 1.0, 0.8, 0.8467334961658394], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4365641], dtype=float32), 0.61063355]. 
=============================================
[2019-04-24 10:05:49,721] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.17015696e-01 7.35344365e-04 1.23820035e-02 1.06721461e-06
 1.22814203e-08 2.52408341e-07 3.15730944e-08 3.50681413e-03
 4.66358781e-01 7.25381666e-09 9.41945077e-10], sum to 1.0000
[2019-04-24 10:05:49,722] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3359
[2019-04-24 10:05:49,743] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 19.0, 20.63325158479419, -0.7340420598922073, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4834800.0000, 
sim time next is 4836000.0000, 
raw observation next is [-1.333333333333333, 56.66666666666667, 0.0, 0.0, 19.0, 20.45988569737454, -0.7635964548437212, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.42566943674976926, 0.5666666666666668, 0.0, 0.0, 0.08333333333333333, 0.20499047478121155, 0.24546784838542626, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7321137], dtype=float32), -0.66996497]. 
=============================================
[2019-04-24 10:05:51,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:52,032] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:05:52,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:05:52,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:05:52,854] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run5
[2019-04-24 10:05:53,904] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.1738824e-01 1.4024871e-04 3.5179005e-04 5.1218492e-09 1.7114373e-13
 4.5832227e-10 4.8217129e-12 1.5342671e-04 1.8196630e-01 4.4980502e-13
 1.9907195e-14], sum to 1.0000
[2019-04-24 10:05:53,908] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9426
[2019-04-24 10:05:53,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:53,951] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.0, 50.0, 199.0, 364.0, 22.5, 26.00040888306998, 0.6592170179806914, 1.0, 1.0, 55.0, 54.698404286420654], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4633200.0000, 
sim time next is 4634400.0000, 
raw observation next is [5.333333333333334, 47.66666666666667, 196.3333333333333, 207.3333333333333, 22.5, 27.02117549076711, 0.7493359532580642, 1.0, 1.0, 55.0, 31.62815922440133], 
processed observation next is [1.0, 0.6521739130434783, 0.6103416435826409, 0.47666666666666674, 0.6544444444444443, 0.22909760589318595, 0.375, 0.7517646242305925, 0.7497786510860215, 1.0, 1.0, 0.8, 0.3162815922440133], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.86112225], dtype=float32), 0.15722461]. 
=============================================
[2019-04-24 10:05:54,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:05:54,636] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:54,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:05:54,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:05:54,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:05:54,926] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run5
[2019-04-24 10:05:55,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:05:55,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:05:55,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run5
[2019-04-24 10:05:57,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:58,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:05:58,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:05:58,745] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:05:58,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:05:58,937] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:05:58,940] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run5
[2019-04-24 10:05:59,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7752769e-01 2.6397444e-03 7.5236044e-04 1.8985540e-08 1.2045084e-12
 1.8511133e-09 1.1959335e-11 6.0049165e-04 2.1847966e-01 8.3232320e-13
 2.3284193e-13], sum to 1.0000
[2019-04-24 10:05:59,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2225
[2019-04-24 10:05:59,306] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.333333333333334, 25.66666666666667, 123.8333333333333, 861.6666666666667, 22.5, 25.75475245582073, 0.4345924273420358, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5055600.0000, 
sim time next is 5056800.0000, 
raw observation next is [8.666666666666668, 25.33333333333333, 123.0, 864.1666666666667, 22.5, 25.74854203736943, 0.4363518009984466, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.7026777469990768, 0.2533333333333333, 0.41, 0.9548802946593002, 0.375, 0.6457118364474524, 0.6454506003328155, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32744902], dtype=float32), -0.44007605]. 
=============================================
[2019-04-24 10:05:59,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:05:59,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:05:59,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run5
[2019-04-24 10:06:00,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:00,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:00,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:00,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:01,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:01,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:01,342] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run5
[2019-04-24 10:06:01,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:01,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:01,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run5
[2019-04-24 10:06:01,589] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.4816134e-01 1.0759719e-03 1.5855610e-03 7.9821909e-08 1.7263859e-11
 5.3176175e-09 2.6737168e-10 1.5487045e-03 1.4762834e-01 1.4477697e-10
 1.8522052e-11], sum to 1.0000
[2019-04-24 10:06:01,589] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9787
[2019-04-24 10:06:01,666] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.3333333333333333, 33.0, 109.5, 731.3333333333333, 22.5, 23.23908410178296, -0.09069221399106299, 1.0, 1.0, 55.0, 73.58937002889535], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4959600.0000, 
sim time next is 4960800.0000, 
raw observation next is [1.0, 30.0, 112.5, 760.0, 22.5, 24.39510793121107, 0.05773022118572316, 1.0, 1.0, 55.0, 46.147984045890496], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.3, 0.375, 0.8397790055248618, 0.375, 0.5329256609342558, 0.5192434070619077, 1.0, 1.0, 0.8, 0.46147984045890494], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1104144], dtype=float32), -1.3403752]. 
=============================================
[2019-04-24 10:06:02,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:02,782] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:03,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:03,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:03,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run5
[2019-04-24 10:06:05,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:06,104] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:06,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:06,695] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:06,830] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:06,830] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:06,832] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run5
[2019-04-24 10:06:06,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:06,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:06,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:07,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:07,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:07,303] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:07,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:07,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:07,624] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run5
[2019-04-24 10:06:07,699] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:07,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:07,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run5
[2019-04-24 10:06:07,943] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:07,954] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:07,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:07,956] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run5
[2019-04-24 10:06:08,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:08,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:08,119] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run5
[2019-04-24 10:06:08,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:08,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:08,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:08,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run5
[2019-04-24 10:06:09,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:09,770] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:09,895] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:10,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:06:10,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:10,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:10,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run5
[2019-04-24 10:06:10,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:06:10,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:06:10,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run5
[2019-04-24 10:06:11,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6823882e-01 1.2889523e-03 5.4347017e-03 8.9880572e-08 1.6257870e-10
 2.0501153e-08 1.6264640e-09 3.4217949e-03 3.2161549e-01 1.5784922e-10
 2.9075792e-11], sum to 1.0000
[2019-04-24 10:06:11,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0084
[2019-04-24 10:06:11,901] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 21.37306301581684, -0.5559279223600803, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 22800.0000, 
sim time next is 24000.0000, 
raw observation next is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 21.02023815194379, -0.6469255724588818, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.2516865126619825, 0.28435814251370606, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01958316], dtype=float32), -0.19300379]. 
=============================================
[2019-04-24 10:06:12,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0123118e-01 1.7153855e-03 1.1921253e-03 7.3165239e-07 9.5283947e-11
 7.6444429e-08 4.9201665e-10 1.9448386e-03 2.9391560e-01 1.5092776e-10
 2.9679162e-11], sum to 1.0000
[2019-04-24 10:06:12,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6712
[2019-04-24 10:06:12,857] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 68.0, 0.0, 0.0, 22.5, 20.99617181056876, -0.5440011376402601, 0.0, 1.0, 55.0, 98.06233107860297], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 158400.0000, 
sim time next is 159600.0000, 
raw observation next is [-8.4, 68.0, 0.0, 0.0, 19.0, 21.41530545397445, -0.6865600126463903, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.2299168975069252, 0.68, 0.0, 0.0, 0.08333333333333333, 0.28460878783120425, 0.2711466624512032, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8581926], dtype=float32), 1.4527601]. 
=============================================
[2019-04-24 10:06:15,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0156813e-01 3.0711212e-03 5.1310859e-03 2.0120896e-07 2.2672843e-10
 1.3417122e-08 7.8767997e-09 4.0077036e-03 2.8622174e-01 3.2575120e-10
 6.4807555e-11], sum to 1.0000
[2019-04-24 10:06:15,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6226
[2019-04-24 10:06:15,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 19.0, 21.34775797077472, -0.5832695999086788, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 10800.0000, 
sim time next is 12000.0000, 
raw observation next is [7.366666666666667, 95.0, 0.0, 0.0, 19.0, 20.9194286704744, -0.6371510701776012, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.6666666666666667, 0.95, 0.0, 0.0, 0.08333333333333333, 0.2432857225395333, 0.2876163099407996, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6640551], dtype=float32), -0.5498236]. 
=============================================
[2019-04-24 10:06:17,959] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.6366744e-01 2.9703171e-03 3.6769947e-03 3.4194053e-07 1.2206185e-10
 4.4322086e-08 3.0475389e-09 1.4503559e-03 3.2823449e-01 2.0773601e-10
 3.4355196e-11], sum to 1.0000
[2019-04-24 10:06:17,959] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8078
[2019-04-24 10:06:18,027] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 19.0, 20.3735547784297, -0.8870986933421134, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 176400.0000, 
sim time next is 177600.0000, 
raw observation next is [-8.900000000000002, 74.0, 0.0, 0.0, 19.0, 20.27729491429603, -0.6910155302578186, 0.0, 1.0, 55.0, 83.58783758037293], 
processed observation next is [1.0, 0.043478260869565216, 0.2160664819944598, 0.74, 0.0, 0.0, 0.08333333333333333, 0.18977457619133573, 0.26966148991406047, 0.0, 1.0, 0.8, 0.8358783758037294], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.70712197], dtype=float32), 0.6445889]. 
=============================================
[2019-04-24 10:06:27,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.34122431e-01 6.57362444e-03 2.33434816e-03 6.06627566e-07
 1.04487430e-09 1.03554754e-07 3.41981532e-09 1.67808554e-03
 3.55290741e-01 8.25484403e-10 1.24611918e-10], sum to 1.0000
[2019-04-24 10:06:27,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1873
[2019-04-24 10:06:27,287] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 51.0, 56.5, 896.0, 22.5, 20.53073745338323, -0.6774199831487383, 1.0, 1.0, 55.0, 107.23995602923964], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 392400.0000, 
sim time next is 393600.0000, 
raw observation next is [-11.3, 49.33333333333334, 55.5, 890.0, 22.5, 21.34654120660831, -0.7335105889459826, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.14958448753462603, 0.4933333333333334, 0.185, 0.9834254143646409, 0.375, 0.27887843388402594, 0.2554964703513391, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5815523], dtype=float32), 1.8431612]. 
=============================================
[2019-04-24 10:06:27,795] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.76199478e-01 3.96033097e-03 9.18070134e-03 1.22471033e-06
 2.08165507e-09 1.01007586e-07 2.89494277e-08 5.92488097e-03
 5.04733264e-01 1.25984034e-09 5.54262358e-10], sum to 1.0000
[2019-04-24 10:06:27,798] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5412
[2019-04-24 10:06:27,899] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 17.49032039321065, -1.49485835766901, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 193200.0000, 
sim time next is 194400.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 17.7965366348437, -1.212045226815076, 0.0, 1.0, 55.0, 94.98084672337559], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, -0.016955280429691594, 0.09598492439497464, 0.0, 1.0, 0.8, 0.9498084672337559], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.00077], dtype=float32), -0.67909133]. 
=============================================
[2019-04-24 10:06:30,071] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9964997e-01 2.5260353e-03 7.6851835e-03 2.7658345e-07 3.9919373e-10
 1.9918055e-08 1.1510613e-08 8.9890333e-03 3.8114944e-01 3.9571868e-10
 6.2535283e-11], sum to 1.0000
[2019-04-24 10:06:30,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2813
[2019-04-24 10:06:30,118] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 20.4760719301242, -0.7683843953809065, 0.0, 1.0, 55.0, 55.60676955467673], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 186000.0000, 
sim time next is 187200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 20.3675646035273, -0.930013205043743, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.1972970502939416, 0.18999559831875235, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5383268], dtype=float32), 1.8414187]. 
=============================================
[2019-04-24 10:06:35,278] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6196185e-01 7.5216596e-03 1.7678319e-02 1.7148928e-06 1.1249304e-09
 2.8886953e-07 2.3340096e-08 8.8375743e-04 7.1195239e-01 1.9107154e-09
 8.4717156e-10], sum to 1.0000
[2019-04-24 10:06:35,280] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1001
[2019-04-24 10:06:35,290] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 54.0, 0.0, 0.0, 19.0, 18.75521640960238, -1.279776752796069, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 432000.0000, 
sim time next is 433200.0000, 
raw observation next is [-11.53333333333333, 54.33333333333334, 0.0, 0.0, 19.0, 18.31561380141203, -1.362646737154346, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.14312096029547564, 0.5433333333333334, 0.0, 0.0, 0.08333333333333333, 0.02630115011766924, 0.04578442094855132, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1524371], dtype=float32), 3.0054262]. 
=============================================
[2019-04-24 10:06:41,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9972616e-01 4.2765038e-03 1.6614558e-02 3.8971405e-07 4.6809923e-10
 1.0085731e-07 1.0693445e-08 2.7918078e-03 2.7659047e-01 1.9012971e-09
 1.7731902e-10], sum to 1.0000
[2019-04-24 10:06:41,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5296
[2019-04-24 10:06:41,920] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.066666666666667, 80.33333333333333, 131.3333333333333, 429.1666666666666, 19.0, 20.17867383560903, -0.8325024719369815, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 564000.0000, 
sim time next is 565200.0000, 
raw observation next is [-1.2, 80.0, 134.0, 495.5, 19.0, 19.86624374840945, -0.8846304055905868, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.42936288088642666, 0.8, 0.44666666666666666, 0.5475138121546961, 0.08333333333333333, 0.1555203123674541, 0.20512319813647106, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.00518961], dtype=float32), 0.5943216]. 
=============================================
[2019-04-24 10:06:45,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.00952101e-01 3.45850037e-03 2.17187386e-02 1.88647061e-06
 1.42668022e-09 1.20377422e-07 1.27884405e-08 1.60449301e-03
 5.72264135e-01 9.32642852e-10 4.17871293e-10], sum to 1.0000
[2019-04-24 10:06:45,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1708
[2019-04-24 10:06:45,461] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.466666666666667, 71.0, 0.0, 0.0, 19.0, 18.78893155940526, -1.17091773638894, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 782400.0000, 
sim time next is 783600.0000, 
raw observation next is [-7.633333333333333, 71.0, 0.0, 0.0, 19.0, 18.63267993821433, -1.211828399150576, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.2511542012927055, 0.71, 0.0, 0.0, 0.08333333333333333, 0.05272332818452755, 0.09605720028314131, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.4603, 
noisyNet noise sample is [array([2.0401256], dtype=float32), 0.63767487]. 
=============================================
[2019-04-24 10:07:06,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.61586249e-01 5.62832865e-04 6.04710891e-04 1.20902435e-08
 3.02035176e-12 7.36643579e-10 2.00683810e-11 9.63887549e-04
 2.36282378e-01 2.94031834e-12 2.83867195e-13], sum to 1.0000
[2019-04-24 10:07:06,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2396
[2019-04-24 10:07:06,222] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.1, 77.0, 0.0, 0.0, 19.0, 25.97206758559732, 0.7314469581024139, 0.0, 1.0, 55.0, 57.72328232971527], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1137600.0000, 
sim time next is 1138800.0000, 
raw observation next is [11.26666666666667, 77.0, 0.0, 0.0, 19.0, 26.18002643325227, 0.6324454665653224, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.7746999076638967, 0.77, 0.0, 0.0, 0.08333333333333333, 0.6816688694376891, 0.7108151555217742, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9732421], dtype=float32), -0.32742414]. 
=============================================
[2019-04-24 10:07:06,847] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [3.4664905e-01 1.6558302e-03 1.2485126e-02 2.4481571e-07 1.3450874e-10
 3.5708553e-08 6.2147976e-09 1.2796607e-03 6.3793004e-01 2.7228320e-10
 2.0978334e-11], sum to 1.0000
[2019-04-24 10:07:06,861] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4691
[2019-04-24 10:07:06,903] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 19.0, 20.85376688971218, -0.6055151850733924, 0.0, 1.0, 55.0, 55.50792085147365], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 774000.0000, 
sim time next is 775200.0000, 
raw observation next is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 21.20147443276894, -0.5729009447420738, 0.0, 1.0, 55.0, 53.741570285591585], 
processed observation next is [1.0, 1.0, 0.27146814404432135, 0.6833333333333335, 0.0, 0.0, 0.08333333333333333, 0.26678953606407835, 0.30903301841930875, 0.0, 1.0, 0.8, 0.5374157028559159], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8154822], dtype=float32), -0.71922976]. 
=============================================
[2019-04-24 10:07:12,903] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.1541432e-01 1.0160434e-03 8.4836863e-04 2.5730445e-08 5.5369789e-12
 1.8970403e-09 5.8991471e-11 3.3684715e-04 3.8238445e-01 2.0744630e-12
 7.3434211e-13], sum to 1.0000
[2019-04-24 10:07:12,904] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2473
[2019-04-24 10:07:12,962] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.733333333333333, 85.0, 0.0, 0.0, 22.5, 22.77416287104511, -0.3050084750677001, 0.0, 1.0, 55.0, 62.936977239019825], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 847200.0000, 
sim time next is 848400.0000, 
raw observation next is [-3.566666666666666, 84.0, 0.0, 0.0, 22.5, 22.61866452590148, -0.4808248307035302, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3638042474607572, 0.84, 0.0, 0.0, 0.375, 0.38488871049178996, 0.3397250564321566, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6498623], dtype=float32), -0.36789975]. 
=============================================
[2019-04-24 10:07:18,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3986593e-01 9.1165403e-04 9.3133008e-04 6.7075042e-08 2.3224027e-11
 3.3149168e-09 1.9455813e-10 1.0777274e-03 3.5721320e-01 4.2845259e-11
 1.1309805e-12], sum to 1.0000
[2019-04-24 10:07:18,584] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2003
[2019-04-24 10:07:18,654] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.0, 79.0, 0.0, 0.0, 19.0, 23.37015281730376, 0.06565744538973914, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1130400.0000, 
sim time next is 1131600.0000, 
raw observation next is [10.36666666666667, 78.33333333333334, 0.0, 0.0, 19.0, 23.22134707529407, 0.0380928579260758, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.7497691597414591, 0.7833333333333334, 0.0, 0.0, 0.08333333333333333, 0.4351122562745058, 0.512697619308692, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8236208], dtype=float32), -0.033490226]. 
=============================================
[2019-04-24 10:07:23,467] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2117420e-01 3.5023681e-04 1.9006232e-03 2.8579319e-07 4.4844947e-10
 2.3909028e-08 1.8634216e-09 1.3280807e-03 1.7524655e-01 3.5163705e-10
 1.9405422e-11], sum to 1.0000
[2019-04-24 10:07:23,468] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8285
[2019-04-24 10:07:23,571] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [15.0, 98.66666666666666, 35.66666666666666, 0.0, 19.0, 24.93585407020925, 0.3801346025028736, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1240800.0000, 
sim time next is 1242000.0000, 
raw observation next is [15.0, 100.0, 51.0, 0.0, 19.0, 24.97641169934609, 0.5616389173848758, 0.0, 0.0, 55.0, 63.26425954328714], 
processed observation next is [0.0, 0.391304347826087, 0.8781163434903049, 1.0, 0.17, 0.0, 0.08333333333333333, 0.5813676416121742, 0.6872129724616253, 0.0, 0.0, 0.8, 0.6326425954328714], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01926538], dtype=float32), 0.9407327]. 
=============================================
[2019-04-24 10:07:30,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7100691e-01 1.9755278e-04 6.8510388e-04 2.9312619e-09 1.9666287e-12
 4.4952869e-10 7.9590518e-12 1.0325963e-03 1.2707779e-01 3.0646395e-12
 1.5617508e-13], sum to 1.0000
[2019-04-24 10:07:30,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9630
[2019-04-24 10:07:30,573] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [14.0, 98.66666666666666, 100.0, 0.0, 19.0, 25.27515415204397, 0.5253458783035879, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1255200.0000, 
sim time next is 1256400.0000, 
raw observation next is [13.8, 100.0, 98.0, 0.0, 19.0, 25.41206965667306, 0.7194942203332536, 0.0, 1.0, 55.0, 63.88941395965399], 
processed observation next is [0.0, 0.5652173913043478, 0.844875346260388, 1.0, 0.32666666666666666, 0.0, 0.08333333333333333, 0.6176724713894218, 0.7398314067777512, 0.0, 1.0, 0.8, 0.63889413959654], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0525092], dtype=float32), 1.1206977]. 
=============================================
[2019-04-24 10:07:32,824] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1958863e-01 7.4391259e-04 1.2503773e-03 2.1984435e-07 4.2616616e-10
 4.7877556e-08 8.7748031e-10 9.2218368e-04 7.7494562e-02 9.8874020e-10
 3.5735137e-11], sum to 1.0000
[2019-04-24 10:07:32,826] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2568
[2019-04-24 10:07:32,841] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.1, 64.33333333333334, 0.0, 0.0, 19.0, 26.2352021250799, 0.6698444931854769, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1189200.0000, 
sim time next is 1190400.0000, 
raw observation next is [17.9, 65.66666666666667, 0.0, 0.0, 19.0, 25.9618451478778, 0.6230026700402812, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.9584487534626038, 0.6566666666666667, 0.0, 0.0, 0.08333333333333333, 0.6634870956564832, 0.7076675566800937, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8126552], dtype=float32), -0.8341864]. 
=============================================
[2019-04-24 10:07:34,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.7357944e-01 1.4756611e-04 9.5420510e-05 1.4021231e-09 5.8778191e-14
 1.7167698e-10 1.3054057e-12 3.9972725e-05 1.2613761e-01 1.2780605e-13
 1.0198234e-14], sum to 1.0000
[2019-04-24 10:07:34,948] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6404
[2019-04-24 10:07:35,012] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 75.0, 0.0, 22.5, 25.33042663648995, 0.2899903246515979, 1.0, 1.0, 55.0, 62.418427340800456], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1434000.0000, 
sim time next is 1435200.0000, 
raw observation next is [1.1, 92.0, 67.66666666666667, 0.0, 22.5, 25.27223167821346, 0.3062470650425121, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.22555555555555556, 0.0, 0.375, 0.6060193065177882, 0.6020823550141707, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2696209], dtype=float32), 0.366521]. 
=============================================
[2019-04-24 10:07:38,997] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.1553549e-01 8.7824347e-04 2.2892856e-04 8.2785370e-09 5.1566097e-13
 6.7445610e-10 2.8333726e-12 2.4557920e-04 1.8311168e-01 1.3609868e-13
 1.0259227e-13], sum to 1.0000
[2019-04-24 10:07:38,997] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2165
[2019-04-24 10:07:39,072] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.333333333333333, 70.66666666666666, 129.1666666666667, 128.0, 22.5, 23.96985080488872, 0.2062822562161714, 1.0, 1.0, 55.0, 77.65587733812211], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1590000.0000, 
sim time next is 1591200.0000, 
raw observation next is [7.7, 68.0, 157.5, 112.0, 22.5, 24.7489324813048, 0.1868363737480123, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6759002770083103, 0.68, 0.525, 0.12375690607734807, 0.375, 0.5624110401087332, 0.5622787912493374, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6415128], dtype=float32), 0.4330199]. 
=============================================
[2019-04-24 10:07:45,039] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.1554947e-01 9.6876308e-04 2.5619677e-04 1.1484191e-08 6.6799127e-13
 5.8598115e-10 5.1032789e-12 1.3843045e-04 2.8308722e-01 5.0373990e-13
 1.7085392e-13], sum to 1.0000
[2019-04-24 10:07:45,041] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8892
[2019-04-24 10:07:45,194] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 22.5, 22.9253311785044, -0.1754051395299339, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1450800.0000, 
sim time next is 1452000.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 23.04465771358539, 0.02343623634629627, 1.0, 1.0, 55.0, 77.79594299818442], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.42038814279878256, 0.5078120787820988, 1.0, 1.0, 0.8, 0.7779594299818442], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0607396], dtype=float32), -3.3758678]. 
=============================================
[2019-04-24 10:07:45,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2234848e-01 1.5024292e-04 3.4578209e-04 1.2463648e-09 3.5195584e-14
 5.5051221e-11 5.9505807e-12 3.1015486e-04 1.7684543e-01 5.0456425e-14
 1.4888628e-14], sum to 1.0000
[2019-04-24 10:07:45,906] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4890
[2019-04-24 10:07:46,002] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 19.0, 24.01553602117078, 0.3408477648743581, 0.0, 1.0, 55.0, 74.79893477884288], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1656000.0000, 
sim time next is 1657200.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 19.0, 24.69564345472394, 0.2824900483573643, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.6454293628808865, 0.97, 0.0, 0.0, 0.08333333333333333, 0.5579702878936615, 0.5941633494524547, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04180092], dtype=float32), -1.152486]. 
=============================================
[2019-04-24 10:07:47,284] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2952105e-01 6.6288834e-04 9.7149750e-03 4.7232993e-07 7.6940276e-09
 1.6878167e-07 2.6125900e-08 2.2212914e-03 4.5787916e-01 7.2307524e-09
 5.9252847e-10], sum to 1.0000
[2019-04-24 10:07:47,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1343
[2019-04-24 10:07:47,321] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 80.33333333333333, 24.33333333333334, 0.0, 19.0, 20.43193993711823, -0.7548744513458193, 0.0, 1.0, 55.0, 74.14317415571364], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1874400.0000, 
sim time next is 1875600.0000, 
raw observation next is [-4.5, 83.0, 15.0, 0.0, 19.0, 20.5379933907274, -0.8977772507155578, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.3379501385041552, 0.83, 0.05, 0.0, 0.08333333333333333, 0.2114994492272834, 0.2007409164281474, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.274531], dtype=float32), 0.09177492]. 
=============================================
[2019-04-24 10:07:49,443] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.4345598e-01 1.5842078e-03 5.7036187e-03 3.3871996e-07 2.5179533e-10
 2.2121000e-08 7.0386763e-09 1.0661857e-03 3.4818968e-01 1.5125849e-10
 5.3238497e-11], sum to 1.0000
[2019-04-24 10:07:49,453] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4826
[2019-04-24 10:07:49,477] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 87.0, 71.5, 0.0, 19.0, 20.64637832295636, -0.5102097938535349, 0.0, 1.0, 55.0, 81.3574017189025], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1783200.0000, 
sim time next is 1784400.0000, 
raw observation next is [-3.2, 87.0, 59.66666666666666, 0.0, 19.0, 21.19835269709849, -0.6250130170518164, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.37396121883656513, 0.87, 0.19888888888888887, 0.0, 0.08333333333333333, 0.2665293914248741, 0.29166232764939454, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4080952], dtype=float32), -1.2277628]. 
=============================================
[2019-04-24 10:07:51,962] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5865648e-01 1.0000493e-03 4.7614253e-03 3.0109908e-07 2.7672634e-10
 2.9021342e-08 1.7106278e-09 1.3232287e-03 3.3425850e-01 5.9668498e-10
 2.5773260e-11], sum to 1.0000
[2019-04-24 10:07:51,962] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4261
[2019-04-24 10:07:52,013] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 83.0, 122.5, 0.0, 19.0, 21.13236402057614, -0.6026747374536195, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1774800.0000, 
sim time next is 1776000.0000, 
raw observation next is [-2.8, 83.0, 120.1666666666667, 0.0, 19.0, 20.58477599514795, -0.6842508835697516, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.38504155124653744, 0.83, 0.40055555555555566, 0.0, 0.08333333333333333, 0.21539799959566253, 0.27191637214341613, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4357169], dtype=float32), 1.1496303]. 
=============================================
[2019-04-24 10:07:52,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1512419e-01 2.5339730e-03 3.4567446e-03 4.3579831e-07 4.5113724e-10
 4.7143395e-08 8.4352569e-09 4.7903773e-03 2.7409419e-01 1.2752348e-09
 8.0702764e-11], sum to 1.0000
[2019-04-24 10:07:52,843] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8493
[2019-04-24 10:07:52,881] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 85.66666666666667, 115.3333333333333, 0.0, 19.0, 20.36371793403816, -0.5508593000296272, 0.0, 1.0, 55.0, 84.53319495899238], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1768800.0000, 
sim time next is 1770000.0000, 
raw observation next is [-2.3, 84.33333333333333, 120.1666666666667, 0.0, 19.0, 21.17952846196681, -0.4606752160509522, 0.0, 1.0, 55.0, 55.64620510627009], 
processed observation next is [0.0, 0.4782608695652174, 0.3988919667590028, 0.8433333333333333, 0.40055555555555566, 0.0, 0.08333333333333333, 0.2649607051639009, 0.3464415946496826, 0.0, 1.0, 0.8, 0.5564620510627009], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8882186], dtype=float32), 0.6554759]. 
=============================================
[2019-04-24 10:07:52,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[54.586258]
 [53.64034 ]
 [54.263645]
 [54.38465 ]
 [53.04298 ]
 [53.140736]
 [53.50375 ]
 [53.72774 ]
 [54.0552  ]
 [53.05498 ]
 [53.680004]
 [53.09624 ]
 [52.198593]
 [52.61355 ]
 [53.10126 ]
 [53.560856]
 [54.135128]
 [54.618153]
 [55.230976]
 [55.790756]
 [55.385303]
 [54.63126 ]
 [53.505966]
 [53.97816 ]
 [54.591637]], R is [[54.86910248]
 [54.32041168]
 [54.77720642]
 [55.22943497]
 [54.67713928]
 [55.13036728]
 [55.57906342]
 [56.02327347]
 [56.4630394 ]
 [55.8984108 ]
 [56.33942795]
 [55.77603531]
 [55.21827698]
 [55.66609573]
 [56.10943604]
 [56.54834366]
 [56.98286057]
 [57.41303253]
 [57.83890152]
 [58.26051331]
 [57.67790985]
 [57.10113144]
 [56.53012085]
 [56.96482086]
 [57.39517212]].
[2019-04-24 10:07:55,587] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6165755e-01 2.4086954e-04 4.2389563e-04 4.9560702e-09 1.5759455e-13
 1.8742098e-10 3.6213506e-12 4.4306723e-04 4.3723458e-01 5.9590442e-14
 3.0535484e-14], sum to 1.0000
[2019-04-24 10:07:55,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1478
[2019-04-24 10:07:55,615] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 79.33333333333334, 0.0, 0.0, 19.0, 25.75388914109082, 0.6159733710573304, 0.0, 1.0, 55.0, 43.23659497690376], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1632000.0000, 
sim time next is 1633200.0000, 
raw observation next is [6.8, 82.66666666666666, 0.0, 0.0, 19.0, 25.7196499492888, 0.4975925502354768, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.6509695290858727, 0.8266666666666665, 0.0, 0.0, 0.08333333333333333, 0.6433041624407334, 0.6658641834118256, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-3.158399], dtype=float32), -1.3844701]. 
=============================================
[2019-04-24 10:07:56,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0608701e-01 3.3580540e-03 2.6739913e-03 7.4072489e-08 2.4664493e-11
 5.1174780e-09 7.3646683e-10 3.0643796e-03 4.8481646e-01 8.4522993e-11
 2.8332493e-12], sum to 1.0000
[2019-04-24 10:07:56,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5419
[2019-04-24 10:07:56,345] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 19.0, 21.05853503046435, -0.4776204363379655, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1730400.0000, 
sim time next is 1731600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 21.40779306791698, -0.2210601028074661, 0.0, 1.0, 55.0, 87.95817215445841], 
processed observation next is [0.0, 0.043478260869565216, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.28398275565974834, 0.426313299064178, 0.0, 1.0, 0.8, 0.8795817215445841], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.68580663], dtype=float32), -0.77728707]. 
=============================================
[2019-04-24 10:07:56,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1051770e-01 2.2678115e-04 2.1853489e-04 2.3004338e-09 1.5488808e-13
 2.1430577e-10 5.1767488e-12 5.6031992e-04 2.8847668e-01 4.5050247e-14
 1.2041450e-14], sum to 1.0000
[2019-04-24 10:07:56,409] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9901
[2019-04-24 10:07:56,452] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.0, 95.0, 0.0, 0.0, 19.0, 25.27193317261981, 0.5348563439992394, 0.0, 1.0, 55.0, 61.31917213633462], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1647600.0000, 
sim time next is 1648800.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 25.90246874877928, 0.5849082778932436, 0.0, 1.0, 55.0, 43.58597300800696], 
processed observation next is [1.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.6585390623982734, 0.6949694259644145, 0.0, 1.0, 0.8, 0.4358597300800696], 
reward next is 0.0000, 
noisyNet noise sample is [array([-3.158399], dtype=float32), -1.3844701]. 
=============================================
[2019-04-24 10:08:01,448] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.21099460e-01 2.40159919e-04 6.11800351e-04 8.26583246e-09
 1.54069696e-13 2.14213175e-10 1.36311979e-12 7.32539280e-04
 1.77316129e-01 5.47645086e-14 1.02924634e-13], sum to 1.0000
[2019-04-24 10:08:01,456] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9956
[2019-04-24 10:08:01,517] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.1, 88.0, 90.0, 0.0, 22.5, 24.78265747812375, 0.4120961863787864, 1.0, 1.0, 55.0, 77.58403476479631], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1692000.0000, 
sim time next is 1693200.0000, 
raw observation next is [1.1, 88.0, 83.33333333333334, 0.0, 22.5, 25.44962061050524, 0.4928612053650694, 1.0, 1.0, 55.0, 50.440836737253534], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.88, 0.2777777777777778, 0.0, 0.375, 0.6208017175421032, 0.6642870684550232, 1.0, 1.0, 0.8, 0.5044083673725354], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9884678], dtype=float32), -1.2829857]. 
=============================================
[2019-04-24 10:08:01,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1698694e-01 3.1042837e-03 5.8996719e-03 4.0657562e-07 8.1837520e-10
 2.5410539e-08 5.6476668e-09 2.1746599e-03 5.7183409e-01 7.3873851e-10
 1.0693712e-10], sum to 1.0000
[2019-04-24 10:08:01,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4628
[2019-04-24 10:08:01,924] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 85.66666666666667, 21.83333333333334, 0.0, 19.0, 20.79556697625547, -0.6294789633453194, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1758000.0000, 
sim time next is 1759200.0000, 
raw observation next is [-1.7, 84.33333333333333, 32.5, 0.0, 19.0, 20.93277345098804, -0.3931400834334897, 0.0, 1.0, 55.0, 85.28593134924967], 
processed observation next is [0.0, 0.34782608695652173, 0.4155124653739613, 0.8433333333333333, 0.10833333333333334, 0.0, 0.08333333333333333, 0.24439778758233674, 0.3689533055221701, 0.0, 1.0, 0.8, 0.8528593134924967], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1176473], dtype=float32), -1.6087244]. 
=============================================
[2019-04-24 10:08:13,667] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.9230214e-01 1.6796951e-03 3.6736929e-03 1.4990844e-07 2.2903474e-11
 6.0581855e-09 7.6192713e-10 3.0438328e-04 4.0203992e-01 2.5306325e-11
 1.1137550e-11], sum to 1.0000
[2019-04-24 10:08:13,694] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5371
[2019-04-24 10:08:13,739] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 82.66666666666667, 0.0, 0.0, 19.0, 20.61388567456214, -0.8348083381778367, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2154000.0000, 
sim time next is 2155200.0000, 
raw observation next is [-7.1, 82.33333333333334, 0.0, 0.0, 19.0, 19.88535592255464, -0.9316518676649731, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2659279778393352, 0.8233333333333335, 0.0, 0.0, 0.08333333333333333, 0.1571129935462201, 0.18944937744500898, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9379091], dtype=float32), 1.8339733]. 
=============================================
[2019-04-24 10:08:16,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1588250e-01 4.4024509e-04 2.9476141e-03 4.6531774e-08 2.0068920e-11
 5.1189515e-09 5.3175752e-11 4.6632401e-04 1.8026319e-01 9.4434686e-12
 3.2099831e-12], sum to 1.0000
[2019-04-24 10:08:16,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6928
[2019-04-24 10:08:16,998] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 65.33333333333334, 149.3333333333333, 22.33333333333333, 22.5, 22.10113834701577, -0.2010514066017996, 1.0, 1.0, 55.0, 104.02214322563259], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2121600.0000, 
sim time next is 2122800.0000, 
raw observation next is [-5.8, 66.66666666666666, 145.0, 0.0, 22.5, 23.5739115528362, -0.3274989759940306, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.30193905817174516, 0.6666666666666665, 0.48333333333333334, 0.0, 0.375, 0.4644926294030167, 0.3908336746686565, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3100992], dtype=float32), -1.8886275]. 
=============================================
[2019-04-24 10:08:17,664] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-24 10:08:17,677] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:08:17,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:08:17,679] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run7
[2019-04-24 10:08:17,701] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:08:17,706] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:08:17,711] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run7
[2019-04-24 10:08:17,708] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:08:17,757] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:08:17,759] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run7
[2019-04-24 10:08:43,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.21623485], dtype=float32), 0.3108528]
[2019-04-24 10:08:43,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-14.14539844, 46.6764882, 0.0, 0.0, 19.0, 20.61253929056141, -0.7585124635560638, 0.0, 1.0, 55.0, 56.902362290051045]
[2019-04-24 10:08:43,705] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:08:43,706] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [6.9482553e-01 3.6618118e-03 2.0336213e-02 6.7798292e-06 3.1225795e-08
 8.3331031e-07 2.1811732e-07 2.8114936e-03 2.7835700e-01 5.4380440e-08
 7.7122566e-09], sampled 0.5371496064013237
[2019-04-24 10:10:10,748] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.21623485], dtype=float32), 0.3108528]
[2019-04-24 10:10:10,748] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-4.666666666666666, 75.0, 0.0, 0.0, 19.0, 22.22461808887827, -0.25283637611256, 0.0, 1.0, 55.0, 55.92847457691665]
[2019-04-24 10:10:10,748] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:10:10,749] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [5.6124878e-01 3.9578625e-03 6.7001279e-03 8.8253455e-07 1.2610493e-09
 8.7597684e-08 1.3592564e-08 4.6878662e-03 4.2340443e-01 1.6935517e-09
 2.0244269e-10], sampled 0.840857830356209
[2019-04-24 10:10:18,738] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2854.0504 90605.5965 198.8605
[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,773] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:18,888] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,698] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2651.6243 100145.0383 -154.8478
[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:25,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,501] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2612.1133 101241.2254 -312.9945
[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,527] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:30,637] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:10:31,529] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 300000, evaluation results [300000.0, 2651.6243456936063, 100145.03833227402, -154.84778664935732, 2854.050421873161, 90605.59650264657, 198.8604613179346, 2612.1133491103305, 101241.22543667843, -312.99454735942123]
[2019-04-24 10:10:37,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2083385e-01 1.4663344e-03 3.1937130e-03 4.3558828e-08 8.8313055e-12
 5.1566498e-09 3.7661341e-10 2.3892641e-04 4.7426713e-01 8.6650036e-12
 1.5616779e-12], sum to 1.0000
[2019-04-24 10:10:37,481] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8346
[2019-04-24 10:10:37,526] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 19.0, 22.08439637020767, -0.4192183394540072, 0.0, 1.0, 55.0, 50.95378338404865], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2246400.0000, 
sim time next is 2247600.0000, 
raw observation next is [-6.700000000000001, 77.0, 0.0, 0.0, 19.0, 22.07071986334462, -0.4166856782336343, 0.0, 1.0, 55.0, 50.80863263631116], 
processed observation next is [1.0, 0.0, 0.2770083102493075, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3392266552787184, 0.36110477392212187, 0.0, 1.0, 0.8, 0.5080863263631116], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3397105], dtype=float32), -1.472935]. 
=============================================
[2019-04-24 10:10:40,692] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.1565733e-01 1.9027018e-03 2.3191583e-03 1.8886951e-07 1.5070573e-11
 3.9751789e-09 3.4175607e-10 1.0348876e-03 3.7908572e-01 8.8030043e-12
 9.4282802e-12], sum to 1.0000
[2019-04-24 10:10:40,694] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3310
[2019-04-24 10:10:40,769] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 22.5, 21.72165632172281, -0.2520239950348983, 1.0, 1.0, 55.0, 106.48479556921771], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2142000.0000, 
sim time next is 2143200.0000, 
raw observation next is [-5.2, 77.0, 0.0, 0.0, 22.5, 22.95873801237608, -0.3311344507808264, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.31855955678670367, 0.77, 0.0, 0.0, 0.375, 0.41322816769800674, 0.3896218497397245, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01487556], dtype=float32), 0.6552455]. 
=============================================
[2019-04-24 10:10:42,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.17448640e-01 1.82768342e-03 1.72723935e-03 7.73565745e-08
 7.11454784e-11 1.24402435e-08 1.05607323e-09 1.56800961e-03
 5.77428341e-01 5.21445491e-11 1.42895548e-11], sum to 1.0000
[2019-04-24 10:10:42,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2344
[2019-04-24 10:10:42,949] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.633333333333333, 84.66666666666666, 0.0, 0.0, 19.0, 20.8957927493603, -0.6484270467745114, 0.0, 1.0, 55.0, 72.4863542150986], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2256000.0000, 
sim time next is 2257200.0000, 
raw observation next is [-7.8, 86.0, 0.0, 0.0, 19.0, 20.89478707212701, -0.7916994985669618, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.86, 0.0, 0.0, 0.08333333333333333, 0.2412322560105841, 0.2361001671443461, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1038878], dtype=float32), 0.6425842]. 
=============================================
[2019-04-24 10:10:44,773] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2163679e-01 2.6207289e-03 2.7365271e-02 3.3393405e-06 2.2980670e-08
 1.1643806e-06 1.6841078e-07 2.2587182e-03 5.4611385e-01 3.0464424e-08
 1.8038243e-09], sum to 1.0000
[2019-04-24 10:10:44,780] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9905
[2019-04-24 10:10:44,835] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.6, 43.0, 0.0, 0.0, 19.0, 20.7495583629027, -0.8723856429678425, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2419200.0000, 
sim time next is 2420400.0000, 
raw observation next is [-5.8, 44.66666666666667, 0.0, 0.0, 19.0, 20.39039386252334, -0.7531232301260896, 0.0, 1.0, 55.0, 71.84545584066677], 
processed observation next is [0.0, 0.0, 0.30193905817174516, 0.4466666666666667, 0.0, 0.0, 0.08333333333333333, 0.1991994885436116, 0.24895892329130345, 0.0, 1.0, 0.8, 0.7184545584066677], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9485743], dtype=float32), 1.047662]. 
=============================================
[2019-04-24 10:10:46,941] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2229232e-01 4.6084835e-03 3.1376727e-02 4.8555967e-06 7.7140591e-08
 1.9982137e-06 1.1071784e-06 1.2305539e-02 5.2940887e-01 9.1064059e-08
 1.2431577e-08], sum to 1.0000
[2019-04-24 10:10:46,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7879
[2019-04-24 10:10:46,985] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.733333333333333, 34.33333333333334, 84.33333333333334, 820.3333333333334, 19.0, 19.97033386165273, -0.9927785190145088, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2460000.0000, 
sim time next is 2461200.0000, 
raw observation next is [-1.166666666666667, 32.66666666666666, 86.66666666666667, 831.6666666666667, 19.0, 19.94151611427638, -0.7673326022040586, 0.0, 1.0, 55.0, 74.36227570546211], 
processed observation next is [0.0, 0.4782608695652174, 0.43028624192059095, 0.32666666666666655, 0.2888888888888889, 0.9189686924493555, 0.08333333333333333, 0.16179300952303155, 0.24422246593198046, 0.0, 1.0, 0.8, 0.7436227570546211], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5369934], dtype=float32), 1.1159511]. 
=============================================
[2019-04-24 10:10:53,958] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.5662174e-01 1.2096669e-02 2.8131822e-02 1.1991095e-05 5.5551503e-08
 1.2360158e-06 5.9892898e-07 7.3853200e-03 4.9575037e-01 8.5403833e-08
 3.2746176e-08], sum to 1.0000
[2019-04-24 10:10:53,982] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0842
[2019-04-24 10:10:54,018] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 61.0, 0.0, 0.0, 19.0, 19.41487508238373, -1.148813722086973, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2433600.0000, 
sim time next is 2434800.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 19.0, 18.54637650315104, -1.29815517043513, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2299168975069252, 0.61, 0.0, 0.0, 0.08333333333333333, 0.04553137526258677, 0.06728160985495668, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.1769, 
noisyNet noise sample is [array([-0.37648612], dtype=float32), -0.3135132]. 
=============================================
[2019-04-24 10:10:55,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1863601e-01 1.0199660e-03 2.2461843e-03 7.7872059e-08 4.4576134e-11
 1.0506163e-08 2.9804428e-10 1.2363861e-03 3.7686133e-01 1.5445915e-10
 9.3481932e-12], sum to 1.0000
[2019-04-24 10:10:55,189] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0066
[2019-04-24 10:10:55,207] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 64.33333333333333, 0.0, 0.0, 19.0, 21.99803611855817, -0.2845304863435529, 0.0, 1.0, 55.0, 56.401843272018496], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2666400.0000, 
sim time next is 2667600.0000, 
raw observation next is [-1.2, 65.0, 0.0, 0.0, 19.0, 22.30226122088795, -0.3975003896630849, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.42936288088642666, 0.65, 0.0, 0.0, 0.08333333333333333, 0.35852176840732913, 0.36749987011230506, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8735944], dtype=float32), -1.5403148]. 
=============================================
[2019-04-24 10:10:57,247] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3522726e-01 2.7701948e-03 1.7657691e-03 5.8495482e-07 2.0258351e-10
 2.9899642e-08 1.3908967e-09 1.1941475e-03 3.5904205e-01 2.3055326e-10
 5.8592395e-11], sum to 1.0000
[2019-04-24 10:10:57,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5655
[2019-04-24 10:10:57,274] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.066666666666667, 48.0, 0.0, 0.0, 19.0, 21.597183846138, -0.5196333965451847, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2578800.0000, 
sim time next is 2580000.0000, 
raw observation next is [-2.433333333333333, 52.0, 0.0, 0.0, 19.0, 21.31123217553563, -0.5657266870287577, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.3951985226223454, 0.52, 0.0, 0.0, 0.08333333333333333, 0.2759360146279691, 0.3114244376570808, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.63805526], dtype=float32), -1.1198148]. 
=============================================
[2019-04-24 10:10:57,338] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[56.441948]
 [57.068066]
 [57.84207 ]
 [58.42632 ]
 [58.193264]
 [58.414337]
 [58.78167 ]
 [59.169647]
 [59.649426]
 [59.02547 ]
 [57.926712]
 [58.23228 ]
 [58.45644 ]
 [58.642895]
 [57.48675 ]
 [58.044746]
 [58.7376  ]
 [59.133434]
 [59.58257 ]
 [59.890587]
 [60.11897 ]
 [60.26788 ]
 [60.536457]
 [61.05855 ]
 [61.176712]], R is [[56.21758652]
 [56.65541077]
 [57.08885574]
 [57.51796722]
 [56.94278717]
 [57.37335968]
 [57.7996254 ]
 [58.2216301 ]
 [58.63941574]
 [58.05302048]
 [57.47249222]
 [57.89776611]
 [58.31879044]
 [58.73560333]
 [58.14824677]
 [58.56676483]
 [58.98109818]
 [59.39128876]
 [59.79737473]
 [60.19940186]
 [60.59740829]
 [60.991436  ]
 [61.38152313]
 [61.76770782]
 [62.15003204]].
[2019-04-24 10:11:09,939] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.3583450e-01 5.3211011e-04 1.9035971e-03 1.5220252e-07 3.3254323e-11
 1.3761404e-08 1.2845559e-10 4.2409927e-04 1.6130556e-01 3.3694932e-11
 4.6746149e-12], sum to 1.0000
[2019-04-24 10:11:09,951] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1972
[2019-04-24 10:11:10,024] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 19.0, 22.34054116251981, -0.3569964018446894, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2840400.0000, 
sim time next is 2841600.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 19.0, 21.98500729614376, -0.4116360287773904, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.08333333333333333, 0.3320839413453133, 0.36278799040753656, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8740959], dtype=float32), -0.68197113]. 
=============================================
[2019-04-24 10:11:33,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6303103e-01 8.3192531e-04 8.3849300e-04 1.9043229e-08 2.6057964e-12
 2.2872926e-09 2.5894675e-11 1.3174592e-04 1.3516681e-01 3.1137965e-12
 3.2664176e-13], sum to 1.0000
[2019-04-24 10:11:33,079] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3522
[2019-04-24 10:11:33,097] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 25.12808296950896, 0.3636824222601147, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3520800.0000, 
sim time next is 3522000.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 25.04869930906452, 0.3326642137139313, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.58739160908871, 0.6108880712379771, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.23870583], dtype=float32), 0.23840962]. 
=============================================
[2019-04-24 10:11:34,623] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.4088118e-01 3.4278256e-03 2.4223663e-02 2.6551550e-06 3.7021659e-09
 1.7520328e-07 4.6636536e-08 7.0274207e-03 3.2443699e-01 4.9184377e-09
 7.3919559e-10], sum to 1.0000
[2019-04-24 10:11:34,633] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7221
[2019-04-24 10:11:34,682] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 54.0, 112.5, 787.0, 19.0, 21.7747503505982, -0.3648820424546028, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3582000.0000, 
sim time next is 3583200.0000, 
raw observation next is [-3.666666666666667, 54.33333333333334, 113.5, 806.3333333333333, 19.0, 22.02260031664001, -0.1237708128678132, 0.0, 1.0, 55.0, 76.27645039030777], 
processed observation next is [0.0, 0.4782608695652174, 0.3610341643582641, 0.5433333333333334, 0.37833333333333335, 0.8909760589318599, 0.08333333333333333, 0.33521669305333407, 0.4587430623773956, 0.0, 1.0, 0.8, 0.7627645039030777], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03357073], dtype=float32), 2.6842766]. 
=============================================
[2019-04-24 10:11:35,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7607963e-01 1.9705768e-03 1.1545172e-03 4.4885265e-08 5.7206466e-12
 2.0091273e-09 1.1727896e-10 7.7345868e-04 3.2002175e-01 7.6677553e-12
 7.8005278e-13], sum to 1.0000
[2019-04-24 10:11:35,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2695
[2019-04-24 10:11:35,353] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 75.0, 90.83333333333334, 470.0, 22.5, 22.95565704766177, -0.102679515488472, 1.0, 1.0, 55.0, 75.30861418830585], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3746400.0000, 
sim time next is 3747600.0000, 
raw observation next is [-4.0, 77.0, 94.5, 552.0, 22.5, 23.50927342347988, -0.1466791199477449, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3518005540166205, 0.77, 0.315, 0.6099447513812155, 0.375, 0.45910611862332323, 0.4511069600174184, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29907376], dtype=float32), 0.9748736]. 
=============================================
[2019-04-24 10:11:37,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0526717e-01 3.6387981e-03 1.8340815e-02 2.3530697e-06 6.4438814e-09
 3.2972605e-07 2.1894627e-08 5.8870693e-03 3.6686355e-01 2.5661537e-09
 3.9086412e-10], sum to 1.0000
[2019-04-24 10:11:37,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6228
[2019-04-24 10:11:37,184] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [11.0, 27.33333333333333, 102.6666666666667, 679.6666666666666, 19.0, 22.81983348697316, -0.2741685928836269, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3663600.0000, 
sim time next is 3664800.0000, 
raw observation next is [11.0, 28.0, 106.0, 713.0, 19.0, 22.92065949841848, -0.1427199694896493, 0.0, 1.0, 25.0, 49.34825270402133], 
processed observation next is [0.0, 0.43478260869565216, 0.7673130193905818, 0.28, 0.35333333333333333, 0.7878453038674034, 0.08333333333333333, 0.41005495820154003, 0.45242667683678356, 0.0, 1.0, 0.2, 0.4934825270402133], 
reward next is 0.3065, 
noisyNet noise sample is [array([0.2198157], dtype=float32), -1.0973116]. 
=============================================
[2019-04-24 10:11:42,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3609266e-01 7.1559432e-03 4.1625067e-03 1.2974443e-06 3.2544925e-09
 3.7139517e-07 1.5228595e-08 4.3266197e-03 3.4826064e-01 3.1292720e-09
 4.8943277e-10], sum to 1.0000
[2019-04-24 10:11:42,224] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3640
[2019-04-24 10:11:42,235] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.0, 26.0, 95.0, 533.0, 19.0, 22.26088720926782, -0.3223125304548218, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3661200.0000, 
sim time next is 3662400.0000, 
raw observation next is [11.0, 26.66666666666667, 99.0, 619.6666666666666, 19.0, 22.31243637854671, -0.3137644433815674, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.7673130193905818, 0.2666666666666667, 0.33, 0.6847145488029466, 0.08333333333333333, 0.35936969821222586, 0.3954118522061442, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5860473], dtype=float32), -0.44373295]. 
=============================================
[2019-04-24 10:11:42,355] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8913183e-01 4.2370772e-03 1.2333732e-02 2.0983143e-06 4.1448693e-09
 2.8682703e-07 3.5725844e-08 3.4071710e-03 3.9088771e-01 1.3453425e-08
 1.0088183e-09], sum to 1.0000
[2019-04-24 10:11:42,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5217
[2019-04-24 10:11:42,376] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 30.0, 118.5, 834.5, 19.0, 22.48286240802304, -0.3206774857361184, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4190400.0000, 
sim time next is 4191600.0000, 
raw observation next is [1.333333333333333, 31.33333333333334, 118.1666666666667, 842.8333333333334, 19.0, 22.07709711659826, -0.3678102382190347, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4995383194829178, 0.3133333333333334, 0.393888888888889, 0.9313075506445673, 0.08333333333333333, 0.339758093049855, 0.37739658726032177, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.96610373], dtype=float32), -0.74848974]. 
=============================================
[2019-04-24 10:11:42,466] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.7293468e-01 3.3830735e-04 9.8746957e-04 9.1979970e-09 4.6476213e-12
 1.4984217e-09 7.5494805e-11 6.2481192e-04 2.2511473e-01 1.8157837e-12
 8.9314607e-13], sum to 1.0000
[2019-04-24 10:11:42,469] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3175
[2019-04-24 10:11:42,484] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 24.0956012976155, 0.1897566005465985, 0.0, 1.0, 55.0, 64.6933556504501], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3891600.0000, 
sim time next is 3892800.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 24.32557638962015, 0.06963612117939195, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.5271313658016791, 0.5232120403931306, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16533001], dtype=float32), 1.5077595]. 
=============================================
[2019-04-24 10:11:47,306] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9477755e-01 1.6637744e-03 5.6457112e-04 1.7040101e-08 1.7333979e-12
 6.4808409e-10 2.6110291e-11 4.7818825e-04 3.0251583e-01 2.1402934e-12
 3.5847592e-13], sum to 1.0000
[2019-04-24 10:11:47,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7670
[2019-04-24 10:11:47,373] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.3, 57.0, 99.5, 584.0, 22.5, 24.1139295549319, -0.001219359199439607, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4352400.0000, 
sim time next is 4353600.0000, 
raw observation next is [7.533333333333333, 52.00000000000001, 104.5, 646.0, 22.5, 24.38234619853448, 0.2160591819910297, 1.0, 1.0, 55.0, 63.58317479370605], 
processed observation next is [1.0, 0.391304347826087, 0.6712834718374886, 0.52, 0.34833333333333333, 0.7138121546961326, 0.375, 0.5318621832112068, 0.5720197273303432, 1.0, 1.0, 0.8, 0.6358317479370605], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6910589], dtype=float32), -1.7095337]. 
=============================================
[2019-04-24 10:11:47,677] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6459394e-01 4.0255813e-03 5.8742655e-03 5.6306334e-07 2.1792759e-09
 3.9891776e-07 8.6683007e-09 4.9988879e-03 3.2050648e-01 2.2273632e-09
 1.8917010e-10], sum to 1.0000
[2019-04-24 10:11:47,678] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9716
[2019-04-24 10:11:47,722] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.666666666666667, 43.66666666666666, 0.0, 0.0, 19.0, 22.64049800784487, -0.067533840789217, 0.0, 1.0, 55.0, 78.8224334836986], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4153200.0000, 
sim time next is 4154400.0000, 
raw observation next is [-2.0, 46.0, 0.0, 0.0, 19.0, 23.37154069821526, -0.0007859679897093038, 0.0, 1.0, 55.0, 50.05425197028279], 
processed observation next is [0.0, 0.08695652173913043, 0.40720221606648205, 0.46, 0.0, 0.0, 0.08333333333333333, 0.44762839151793826, 0.4997380106700969, 0.0, 1.0, 0.8, 0.5005425197028279], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8431257], dtype=float32), 1.0037501]. 
=============================================
[2019-04-24 10:11:48,423] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.4348499e-01 3.5842960e-03 1.1545229e-02 2.6112489e-06 5.0744133e-09
 2.0424483e-07 4.2200348e-08 4.9557504e-03 4.3642685e-01 7.3182158e-09
 5.1717419e-10], sum to 1.0000
[2019-04-24 10:11:48,426] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8824
[2019-04-24 10:11:48,463] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 54.0, 46.0, 244.0, 19.0, 22.28057666537662, -0.3962124095676351, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4176000.0000, 
sim time next is 4177200.0000, 
raw observation next is [-4.666666666666667, 51.00000000000001, 76.66666666666667, 406.6666666666667, 19.0, 22.22383107306191, -0.2456919166000958, 0.0, 1.0, 55.0, 68.78888477308053], 
processed observation next is [0.0, 0.34782608695652173, 0.3333333333333333, 0.5100000000000001, 0.2555555555555556, 0.44935543278084716, 0.08333333333333333, 0.3519859227551591, 0.4181026944666348, 0.0, 1.0, 0.8, 0.6878888477308053], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10600059], dtype=float32), -0.33374736]. 
=============================================
[2019-04-24 10:11:49,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1073192e-01 9.9744764e-04 1.7523797e-03 3.3818178e-08 1.1775369e-11
 3.7343653e-09 2.2682223e-10 2.4011943e-03 2.8411698e-01 1.9158826e-11
 1.9754281e-12], sum to 1.0000
[2019-04-24 10:11:49,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9330
[2019-04-24 10:11:49,521] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.0, 80.0, 0.0, 0.0, 19.0, 22.69594038232348, -0.158105163788032, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4431600.0000, 
sim time next is 4432800.0000, 
raw observation next is [2.0, 80.0, 0.0, 0.0, 22.5, 22.98622887626542, 0.1211935580250767, 1.0, 1.0, 55.0, 85.32941891460746], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.8, 0.0, 0.0, 0.375, 0.4155190730221185, 0.5403978526750256, 1.0, 1.0, 0.8, 0.8532941891460746], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5108618], dtype=float32), -0.044495594]. 
=============================================
[2019-04-24 10:11:50,857] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.3162853e-01 4.2714477e-03 2.2582191e-03 2.0418123e-07 3.1562997e-10
 8.0575653e-08 3.1786545e-09 2.0792482e-03 5.5976224e-01 2.3790761e-10
 4.1008447e-11], sum to 1.0000
[2019-04-24 10:11:50,857] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9808
[2019-04-24 10:11:50,890] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-11.33333333333333, 59.66666666666667, 0.0, 0.0, 19.0, 22.20692366197756, -0.3122442261681452, 0.0, 1.0, 55.0, 53.43000131907273], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3979200.0000, 
sim time next is 3980400.0000, 
raw observation next is [-11.66666666666667, 61.33333333333334, 0.0, 0.0, 19.0, 22.30235976127454, -0.3160915321652233, 0.0, 1.0, 55.0, 52.73341668634538], 
processed observation next is [1.0, 0.043478260869565216, 0.13942751615881802, 0.6133333333333334, 0.0, 0.0, 0.08333333333333333, 0.3585299801062118, 0.39463615594492557, 0.0, 1.0, 0.8, 0.5273341668634538], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06566864], dtype=float32), 0.6831399]. 
=============================================
[2019-04-24 10:11:55,862] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6892139e-01 1.2333463e-02 9.0210438e-03 1.0347294e-06 1.5131258e-09
 2.1176214e-07 6.7030448e-09 3.4632995e-03 4.0625954e-01 8.3931090e-10
 2.5284941e-10], sum to 1.0000
[2019-04-24 10:11:55,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3771
[2019-04-24 10:11:55,885] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666666, 40.0, 0.0, 0.0, 19.0, 21.23608590695164, -0.6819264290790393, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4084800.0000, 
sim time next is 4086000.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 19.0, 20.76570925490219, -0.7965054432685691, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.32409972299168976, 0.41, 0.0, 0.0, 0.08333333333333333, 0.23047577124184926, 0.23449818557714364, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2347854], dtype=float32), 1.3070598]. 
=============================================
[2019-04-24 10:11:56,153] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9406911e-01 4.5184972e-04 1.0664980e-03 1.3906206e-08 1.5221263e-13
 9.0431734e-10 1.1168324e-12 1.5403195e-04 2.0425849e-01 7.2353901e-13
 5.3599262e-14], sum to 1.0000
[2019-04-24 10:11:56,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7978
[2019-04-24 10:11:56,216] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [9.4, 61.0, 0.0, 0.0, 19.0, 25.36892392382266, 0.4633511343481745, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4399200.0000, 
sim time next is 4400400.0000, 
raw observation next is [9.100000000000001, 61.33333333333334, 0.0, 0.0, 19.0, 25.48165845799801, 0.5961377094303589, 0.0, 1.0, 55.0, 71.08924150724373], 
processed observation next is [1.0, 0.9565217391304348, 0.7146814404432135, 0.6133333333333334, 0.0, 0.0, 0.08333333333333333, 0.6234715381665007, 0.6987125698101196, 0.0, 1.0, 0.8, 0.7108924150724373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0081196], dtype=float32), -0.5128508]. 
=============================================
[2019-04-24 10:11:58,513] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.5641981e-01 2.5810315e-03 4.5901723e-03 4.7861920e-07 4.2485557e-09
 4.2359378e-07 2.1744672e-08 1.6958907e-03 3.3471218e-01 5.8994587e-09
 1.7514892e-10], sum to 1.0000
[2019-04-24 10:11:58,514] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6099
[2019-04-24 10:11:58,531] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 47.66666666666667, 0.0, 0.0, 19.0, 21.79712354420224, -0.4800617456052687, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4232400.0000, 
sim time next is 4233600.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 19.0, 21.60797513909985, -0.5173858893248521, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.518005540166205, 0.48, 0.0, 0.0, 0.08333333333333333, 0.3006645949249875, 0.32753803689171596, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6079477], dtype=float32), 0.70226103]. 
=============================================
[2019-04-24 10:12:00,751] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0302062e-01 4.7594094e-05 1.4101813e-04 6.3045311e-09 1.1096004e-13
 1.9678216e-10 3.4213340e-12 1.8268971e-04 9.6608117e-02 2.2381481e-13
 3.6088787e-14], sum to 1.0000
[2019-04-24 10:12:00,757] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5945
[2019-04-24 10:12:00,776] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 74.0, 20.83333333333334, 45.83333333333334, 22.5, 24.73034493110992, 0.225260176681544, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4470000.0000, 
sim time next is 4471200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 24.0713269298281, 0.184623545356744, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.5059439108190084, 0.5615411817855813, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49623752], dtype=float32), 2.1619084]. 
=============================================
[2019-04-24 10:12:01,445] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7097262e-01 5.2161487e-03 1.0132102e-02 1.1304113e-06 1.5745875e-09
 8.3054658e-08 2.0088727e-08 2.5648023e-03 4.1111302e-01 1.6254815e-09
 4.4962015e-10], sum to 1.0000
[2019-04-24 10:12:01,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3361
[2019-04-24 10:12:01,459] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 174.0, 246.0, 19.0, 21.5369816937631, -0.5941928826727695, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4870800.0000, 
sim time next is 4872000.0000, 
raw observation next is [-2.666666666666667, 63.33333333333334, 196.0, 201.3333333333333, 19.0, 21.0285145936221, -0.6972953298287218, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.38873499538319484, 0.6333333333333334, 0.6533333333333333, 0.2224677716390423, 0.08333333333333333, 0.25237621613517486, 0.2675682233904261, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7429001], dtype=float32), 0.27333283]. 
=============================================
[2019-04-24 10:12:05,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:05,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:06,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:06,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:06,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run6
[2019-04-24 10:12:06,608] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.8689481e-01 1.5765371e-03 1.6248368e-03 3.8031956e-08 1.6401302e-11
 2.9507090e-09 1.7436673e-10 2.6609891e-04 4.0963772e-01 2.9969555e-11
 1.6771098e-12], sum to 1.0000
[2019-04-24 10:12:06,609] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.1933
[2019-04-24 10:12:06,636] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 84.0, 0.0, 0.0, 19.0, 21.89318566946191, -0.2702963968775732, 0.0, 1.0, 55.0, 54.39406683275986], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4752000.0000, 
sim time next is 4753200.0000, 
raw observation next is [-4.0, 79.66666666666667, 0.0, 0.0, 19.0, 22.21477343990189, -0.4043141729868605, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.3518005540166205, 0.7966666666666667, 0.0, 0.0, 0.08333333333333333, 0.35123111999182416, 0.36522860900437987, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0903498], dtype=float32), 0.18278119]. 
=============================================
[2019-04-24 10:12:07,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:07,312] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:07,642] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:07,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:08,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:08,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run6
[2019-04-24 10:12:08,553] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.89266574e-01 1.51761086e-03 9.98810213e-03 3.66562858e-07
 7.20220050e-10 1.10771644e-07 1.12677707e-08 3.46003030e-03
 4.95767146e-01 5.72166203e-10 1.14154630e-10], sum to 1.0000
[2019-04-24 10:12:08,554] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0931
[2019-04-24 10:12:08,577] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.466666666666667, 57.33333333333334, 284.5, 166.5, 19.0, 22.12674581562867, -0.3435955917779742, 0.0, 1.0, 55.0, 47.48761183354773], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4875600.0000, 
sim time next is 4876800.0000, 
raw observation next is [-0.9333333333333333, 54.66666666666667, 297.1666666666666, 188.0, 19.0, 22.2004105834915, -0.4470778262771437, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.4367497691597415, 0.5466666666666667, 0.9905555555555552, 0.20773480662983426, 0.08333333333333333, 0.35003421529095835, 0.35097405790761876, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3130825], dtype=float32), 0.57871234]. 
=============================================
[2019-04-24 10:12:08,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:08,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:08,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run6
[2019-04-24 10:12:09,170] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6431040e-01 8.0648268e-04 1.3443725e-03 1.9213694e-08 2.7731747e-12
 1.7716114e-09 9.6693669e-12 3.5327298e-04 3.3318549e-01 2.6807161e-12
 5.4838344e-13], sum to 1.0000
[2019-04-24 10:12:09,197] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5632
[2019-04-24 10:12:09,281] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 57.0, 0.0, 0.0, 19.0, 25.06044601916824, 0.3864744812353944, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4658400.0000, 
sim time next is 4659600.0000, 
raw observation next is [2.0, 57.00000000000001, 0.0, 0.0, 19.0, 24.81108281876553, 0.2805169677776894, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.5700000000000001, 0.0, 0.0, 0.08333333333333333, 0.5675902348971276, 0.5935056559258965, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3931618], dtype=float32), -0.43115005]. 
=============================================
[2019-04-24 10:12:17,283] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:17,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:17,943] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:18,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:18,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:18,252] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run6
[2019-04-24 10:12:18,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:18,942] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:18,942] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:18,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run6
[2019-04-24 10:12:19,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:19,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:20,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:20,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:20,167] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:20,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4650812e-01 9.6677570e-04 4.9282857e-03 1.2601757e-07 1.0445493e-10
 1.6801202e-08 2.4970472e-09 8.5184735e-04 2.4674481e-01 1.6923338e-10
 5.8693649e-12], sum to 1.0000
[2019-04-24 10:12:20,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9120
[2019-04-24 10:12:20,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run6
[2019-04-24 10:12:20,293] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.9, 86.0, 85.66666666666666, 0.0, 19.0, 20.09120901904351, -0.744904175493013, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 49200.0000, 
sim time next is 50400.0000, 
raw observation next is [7.7, 86.0, 83.0, 0.0, 19.0, 20.45877632632055, -0.4784039861119494, 0.0, 1.0, 55.0, 80.59504009661657], 
processed observation next is [0.0, 0.6086956521739131, 0.6759002770083103, 0.86, 0.27666666666666667, 0.0, 0.08333333333333333, 0.20489802719337913, 0.34053200462935024, 0.0, 1.0, 0.8, 0.8059504009661658], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.800571], dtype=float32), 2.1363974]. 
=============================================
[2019-04-24 10:12:20,370] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:20,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:20,730] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:21,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:21,201] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:21,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run6
[2019-04-24 10:12:21,450] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:21,450] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:21,453] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run6
[2019-04-24 10:12:22,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:22,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:23,289] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:23,290] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:23,341] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run6
[2019-04-24 10:12:23,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:24,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:24,145] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:24,543] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:24,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:24,648] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:24,652] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run6
[2019-04-24 10:12:25,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:25,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:25,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:25,149] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run6
[2019-04-24 10:12:25,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:26,002] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:26,002] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:26,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run6
[2019-04-24 10:12:27,788] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:28,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:28,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:28,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:28,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run6
[2019-04-24 10:12:30,995] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:31,032] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:31,240] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:31,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:31,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:31,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:32,000] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run6
[2019-04-24 10:12:32,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:32,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:32,060] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run6
[2019-04-24 10:12:32,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:33,080] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:12:33,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:12:33,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:12:33,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run6
[2019-04-24 10:12:35,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2084047e-01 4.4928721e-04 5.7595563e-03 9.2782777e-08 2.9881032e-11
 1.3989201e-08 1.1327433e-09 7.5604685e-04 4.7219443e-01 7.5790131e-11
 1.6241874e-12], sum to 1.0000
[2019-04-24 10:12:35,973] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8977
[2019-04-24 10:12:36,051] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.4, 89.0, 0.0, 0.0, 19.0, 21.91825553736798, -0.4406334973907566, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 64800.0000, 
sim time next is 66000.0000, 
raw observation next is [4.200000000000001, 88.0, 0.0, 0.0, 19.0, 21.64450158984815, -0.2818430291737974, 0.0, 1.0, 55.0, 74.15501054072035], 
processed observation next is [0.0, 0.782608695652174, 0.5789473684210527, 0.88, 0.0, 0.0, 0.08333333333333333, 0.30370846582067923, 0.40605232360873417, 0.0, 1.0, 0.8, 0.7415501054072036], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42764392], dtype=float32), -0.9508248]. 
=============================================
[2019-04-24 10:12:44,717] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6639147e-01 3.3746513e-03 1.1927180e-03 2.0063960e-07 5.5656837e-11
 6.0023315e-09 1.8421770e-09 1.5453020e-03 4.2749557e-01 3.0468128e-11
 1.4717583e-11], sum to 1.0000
[2019-04-24 10:12:44,717] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5713
[2019-04-24 10:12:44,901] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.666666666666666, 76.0, 86.5, 0.0, 22.5, 21.65916528069359, -0.5935610698057424, 1.0, 1.0, 55.0, 89.27494127545665], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 207600.0000, 
sim time next is 208800.0000, 
raw observation next is [-7.3, 75.0, 101.5, 0.0, 22.5, 22.27429898940366, -0.5301259763742486, 1.0, 1.0, 50.0, 50.183043313468346], 
processed observation next is [1.0, 0.43478260869565216, 0.26038781163434904, 0.75, 0.3383333333333333, 0.0, 0.375, 0.3561915824503051, 0.32329134120858377, 1.0, 1.0, 0.7, 0.5018304331346835], 
reward next is 0.1506, 
noisyNet noise sample is [array([-2.3809137], dtype=float32), 0.6734264]. 
=============================================
[2019-04-24 10:12:48,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6535443e-01 1.0362824e-03 1.4017805e-03 9.0202086e-08 2.5414495e-11
 7.9090885e-09 1.8329979e-10 1.5761687e-03 3.3063132e-01 3.7101083e-11
 7.0563681e-12], sum to 1.0000
[2019-04-24 10:12:48,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2229
[2019-04-24 10:12:48,260] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 64.33333333333333, 0.0, 0.0, 22.5, 22.19285117818823, -0.2732009087792276, 1.0, 1.0, 55.0, 111.00265129157424], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 150000.0000, 
sim time next is 151200.0000, 
raw observation next is [-7.3, 61.0, 0.0, 0.0, 22.5, 22.79082598189081, -0.3748022581134345, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.26038781163434904, 0.61, 0.0, 0.0, 0.375, 0.39923549849090073, 0.3750659139621885, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0825425], dtype=float32), 2.7282777]. 
=============================================
[2019-04-24 10:12:48,459] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6153148e-01 3.2757509e-03 5.4445481e-03 2.5897052e-07 5.8667370e-11
 2.8539715e-08 9.8853736e-10 1.0966690e-03 4.2865118e-01 6.1463529e-11
 2.0678691e-11], sum to 1.0000
[2019-04-24 10:12:48,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1686
[2019-04-24 10:12:48,519] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 19.0, 19.75293540228144, -0.8617331149195694, 0.0, 1.0, 55.0, 83.87085306038381], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 266400.0000, 
sim time next is 267600.0000, 
raw observation next is [-7.833333333333334, 69.66666666666667, 0.0, 0.0, 19.0, 20.08531220461354, -0.993138782548359, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.2456140350877193, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.17377601705112836, 0.168953739150547, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9581047], dtype=float32), -1.282874]. 
=============================================
[2019-04-24 10:12:49,357] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1895112e-01 1.4144258e-03 4.6661501e-03 7.1573857e-07 1.9558705e-10
 4.2867100e-08 5.4069513e-09 2.4662109e-03 4.7250137e-01 4.5470322e-10
 1.5173703e-10], sum to 1.0000
[2019-04-24 10:12:49,373] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0162
[2019-04-24 10:12:49,421] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.799999999999999, 69.66666666666666, 69.16666666666666, 5.999999999999998, 22.5, 20.04050658353707, -0.9160888274801225, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 121200.0000, 
sim time next is 122400.0000, 
raw observation next is [-7.8, 74.0, 117.5, 18.0, 22.5, 20.02813510998666, -0.9258111527127526, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.24653739612188366, 0.74, 0.39166666666666666, 0.019889502762430938, 0.375, 0.16901125916555504, 0.19139628242908246, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5359546], dtype=float32), -1.0128715]. 
=============================================
[2019-04-24 10:12:55,925] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6217667e-01 5.4431618e-03 9.2905974e-03 1.4658463e-06 4.6706289e-10
 1.3082587e-07 7.7932141e-09 2.1158857e-03 3.2097206e-01 1.3819691e-09
 2.1470545e-10], sum to 1.0000
[2019-04-24 10:12:55,926] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7291
[2019-04-24 10:12:56,127] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-13.76666666666667, 62.0, 68.83333333333334, 734.8333333333333, 22.5, 19.99541877690429, -1.08135774357569, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 384000.0000, 
sim time next is 385200.0000, 
raw observation next is [-13.4, 60.0, 64.5, 746.5, 22.5, 20.59636121324284, -0.7416561422445073, 1.0, 1.0, 55.0, 107.20915154856883], 
processed observation next is [1.0, 0.4782608695652174, 0.09141274238227146, 0.6, 0.215, 0.8248618784530387, 0.375, 0.21636343443690334, 0.2527812859184976, 1.0, 1.0, 0.8, 1.0720915154856883], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9671751], dtype=float32), -0.10976677]. 
=============================================
[2019-04-24 10:12:59,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5520111e-01 2.3271353e-03 8.4853983e-03 2.3729287e-06 8.9431369e-09
 3.9140053e-07 2.9780423e-08 1.8225648e-03 4.3216103e-01 9.8698161e-09
 7.5147166e-10], sum to 1.0000
[2019-04-24 10:12:59,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7360
[2019-04-24 10:12:59,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.733333333333333, 70.33333333333333, 0.0, 0.0, 19.0, 19.34736224132894, -1.172821147740053, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 686400.0000, 
sim time next is 687600.0000, 
raw observation next is [-3.9, 71.0, 0.0, 0.0, 19.0, 19.05904750882459, -1.013413749906728, 0.0, 1.0, 55.0, 78.49651631557737], 
processed observation next is [0.0, 1.0, 0.3545706371191136, 0.71, 0.0, 0.0, 0.08333333333333333, 0.08825395906871591, 0.16219541669775736, 0.0, 1.0, 0.8, 0.7849651631557737], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7323909], dtype=float32), 0.051403005]. 
=============================================
[2019-04-24 10:12:59,921] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.6894333e-01 6.0622109e-04 1.1999568e-03 9.3085269e-08 1.6135740e-11
 2.2871898e-09 1.5283783e-10 3.9895222e-04 1.2885141e-01 1.7104353e-11
 3.6269824e-12], sum to 1.0000
[2019-04-24 10:12:59,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6549
[2019-04-24 10:12:59,984] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 22.5, 21.57187005230665, -0.6773088293884486, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 237600.0000, 
sim time next is 238800.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 22.5, 21.26313843052688, -0.743752430110701, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.368421052631579, 0.65, 0.0, 0.0, 0.375, 0.27192820254390665, 0.252082523296433, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29303718], dtype=float32), -0.10442371]. 
=============================================
[2019-04-24 10:13:00,508] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.2980769e-01 1.9981693e-03 2.3918091e-03 5.9014216e-08 4.6238599e-12
 2.7573008e-09 2.0423475e-10 2.2294186e-04 4.6557939e-01 2.1809110e-11
 4.2005678e-12], sum to 1.0000
[2019-04-24 10:13:00,509] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4600
[2019-04-24 10:13:00,658] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 22.5, 22.20285108056494, -0.5564678292167892, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 243600.0000, 
sim time next is 244800.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 22.5, 21.45253699789064, -0.6999566807066535, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.368421052631579, 0.65, 0.0, 0.0, 0.375, 0.28771141649088666, 0.2666811064311155, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9075419], dtype=float32), -0.8045191]. 
=============================================
[2019-04-24 10:13:01,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.4051390e-01 1.3961806e-03 5.3662998e-03 1.0841923e-07 1.1208704e-10
 2.2505867e-08 1.7151361e-09 1.0052994e-03 3.5171819e-01 1.5686999e-10
 2.3261471e-11], sum to 1.0000
[2019-04-24 10:13:01,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6098
[2019-04-24 10:13:01,265] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.566666666666667, 68.33333333333334, 0.0, 0.0, 19.0, 20.49270092638187, -0.6534115514520621, 0.0, 1.0, 55.0, 88.42477576116379], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 249600.0000, 
sim time next is 250800.0000, 
raw observation next is [-3.733333333333333, 71.66666666666667, 0.0, 0.0, 19.0, 20.98109612055594, -0.7738657817129889, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.35918744228993543, 0.7166666666666667, 0.0, 0.0, 0.08333333333333333, 0.24842467671299495, 0.2420447394290037, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8616709], dtype=float32), 0.20858768]. 
=============================================
[2019-04-24 10:13:07,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5061181e-01 1.8250654e-03 9.6744206e-04 7.6053453e-08 2.2615492e-12
 7.0453647e-09 2.5942902e-11 3.7310933e-04 1.4622240e-01 6.0174582e-12
 1.1745302e-12], sum to 1.0000
[2019-04-24 10:13:07,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3550
[2019-04-24 10:13:07,100] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 60.0, 91.83333333333333, 724.0, 22.5, 22.95424402755801, -0.3844503137130498, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 733200.0000, 
sim time next is 734400.0000, 
raw observation next is [-0.6, 57.0, 107.5, 614.0, 22.5, 22.70485133383296, -0.419498575532667, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.44598337950138506, 0.57, 0.35833333333333334, 0.6784530386740332, 0.375, 0.39207094448607993, 0.360167141489111, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2207764], dtype=float32), 0.8252287]. 
=============================================
[2019-04-24 10:13:08,385] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.9369388e-01 1.5495542e-03 3.6252604e-03 5.3935605e-07 7.6526063e-10
 9.5993165e-08 5.9811316e-09 1.2588833e-03 2.9987186e-01 4.7870158e-10
 2.1364885e-10], sum to 1.0000
[2019-04-24 10:13:08,403] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6759
[2019-04-24 10:13:08,434] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-14.1, 67.0, 0.0, 0.0, 19.0, 18.97870973790418, -1.068394251711317, 0.0, 1.0, 55.0, 79.72196037708252], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 346800.0000, 
sim time next is 348000.0000, 
raw observation next is [-14.3, 68.0, 0.0, 0.0, 19.0, 19.05319666378011, -1.224857320388609, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.06648199445983377, 0.68, 0.0, 0.0, 0.08333333333333333, 0.08776638864834248, 0.09171422653713031, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02377927], dtype=float32), -0.093563735]. 
=============================================
[2019-04-24 10:13:13,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9516249e-01 2.2424315e-03 1.1919521e-02 1.0284326e-06 2.7346476e-09
 2.1076012e-07 4.3570648e-08 3.8000899e-03 5.8687425e-01 2.4741982e-09
 1.7625751e-10], sum to 1.0000
[2019-04-24 10:13:13,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3008
[2019-04-24 10:13:13,281] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 19.0, 20.0315004300997, -0.7843802463964975, 0.0, 1.0, 55.0, 73.63086436383188], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 609600.0000, 
sim time next is 610800.0000, 
raw observation next is [-3.899999999999999, 86.0, 0.0, 0.0, 19.0, 20.28707230445166, -0.9252348132395355, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.35457063711911363, 0.86, 0.0, 0.0, 0.08333333333333333, 0.1905893587043049, 0.1915883955868215, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6239228], dtype=float32), 0.46897167]. 
=============================================
[2019-04-24 10:13:22,134] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.3234780e-01 6.1072255e-03 2.0724682e-02 6.9618309e-06 1.3731567e-08
 4.2197195e-07 1.0241351e-07 3.5548026e-03 4.3725803e-01 1.4663140e-08
 2.8758180e-09], sum to 1.0000
[2019-04-24 10:13:22,138] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6907
[2019-04-24 10:13:22,415] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.566666666666666, 65.0, 98.16666666666667, 6.333333333333332, 19.0, 18.22947211215857, -1.313511085433241, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 643200.0000, 
sim time next is 644400.0000, 
raw observation next is [-3.4, 65.0, 94.5, 19.0, 19.0, 18.89512042762946, -0.9382505985403032, 0.0, 1.0, 55.0, 113.04569556155437], 
processed observation next is [0.0, 0.4782608695652174, 0.368421052631579, 0.65, 0.315, 0.020994475138121547, 0.08333333333333333, 0.07459336896912176, 0.1872498004865656, 0.0, 1.0, 0.8, 1.1304569556155437], 
reward next is 0.2098, 
noisyNet noise sample is [array([-1.001307], dtype=float32), -0.5869165]. 
=============================================
[2019-04-24 10:13:24,875] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-24 10:13:24,882] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:13:24,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:13:24,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run8
[2019-04-24 10:13:24,883] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:13:24,901] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:13:24,903] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:13:24,905] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:13:24,910] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run8
[2019-04-24 10:13:24,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run8
[2019-04-24 10:15:15,952] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.21799317], dtype=float32), 0.31359762]
[2019-04-24 10:15:15,953] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [10.0, 25.0, 0.0, 0.0, 19.0, 22.69035482223851, -0.2148842418725118, 0.0, 1.0, 55.0, 66.1044425881074]
[2019-04-24 10:15:15,953] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:15:15,955] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [6.4849353e-01 3.9721308e-03 4.8521189e-03 1.7869534e-06 5.2342588e-09
 3.5230445e-07 1.9322069e-08 5.2393265e-03 3.3744073e-01 4.7613766e-09
 6.2539596e-10], sampled 0.04072214081927861
[2019-04-24 10:15:26,577] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2877.0263 88256.3929 152.7455
[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,597] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:26,714] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,337] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2640.0814 100184.4011 -188.1149
[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:33,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,230] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2597.9608 102568.9337 -245.4636
[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,250] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:40,357] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:15:41,252] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 350000, evaluation results [350000.0, 2640.081393350747, 100184.40107329577, -188.1149010509519, 2877.0263357243066, 88256.39293785793, 152.7454625910645, 2597.9607752288152, 102568.93371898723, -245.46355214908903]
[2019-04-24 10:15:42,343] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2434914e-01 1.6621583e-03 7.8061982e-03 5.4357247e-07 2.9401968e-09
 1.8539434e-07 1.0104354e-07 2.1485949e-03 2.6403308e-01 6.8292940e-09
 5.8720656e-10], sum to 1.0000
[2019-04-24 10:15:42,344] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4823
[2019-04-24 10:15:42,361] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.566666666666667, 60.33333333333334, 108.1666666666667, 89.66666666666667, 19.0, 18.94063315200822, -1.005023566190058, 0.0, 1.0, 55.0, 81.93710745056302], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 649200.0000, 
sim time next is 650400.0000, 
raw observation next is [-2.433333333333334, 59.66666666666666, 123.6666666666667, 98.83333333333334, 19.0, 19.49972170532755, -1.098958617525344, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3951985226223454, 0.5966666666666666, 0.4122222222222223, 0.10920810313075507, 0.08333333333333333, 0.12497680877729571, 0.1336804608248853, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7841778], dtype=float32), -0.9024419]. 
=============================================
[2019-04-24 10:15:54,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8687026e-01 2.7512733e-03 2.7994155e-03 1.3018906e-07 7.9646055e-12
 3.3727146e-09 2.4739480e-10 1.4674206e-03 5.0611144e-01 1.4213674e-11
 4.7492297e-12], sum to 1.0000
[2019-04-24 10:15:54,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7829
[2019-04-24 10:15:54,158] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 21.96944574590755, -0.5908611053727859, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 889200.0000, 
sim time next is 890400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 21.63600933305619, -0.4113344415427748, 1.0, 1.0, 55.0, 80.5521699705543], 
processed observation next is [1.0, 0.30434782608695654, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.30300077775468254, 0.3628885194857417, 1.0, 1.0, 0.8, 0.805521699705543], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0615763], dtype=float32), 1.0319395]. 
=============================================
[2019-04-24 10:15:55,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5710992e-01 1.7340282e-04 1.4264291e-03 4.0509773e-09 7.2501506e-12
 4.5797133e-10 1.8845604e-11 1.2952001e-03 3.3999503e-01 3.6277574e-12
 1.5728575e-13], sum to 1.0000
[2019-04-24 10:15:55,595] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1886
[2019-04-24 10:15:55,628] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.7, 82.66666666666667, 0.0, 0.0, 19.0, 25.5805630756114, 0.6729560876015167, 0.0, 1.0, 55.0, 63.51429759384366], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1150800.0000, 
sim time next is 1152000.0000, 
raw observation next is [12.7, 84.0, 16.0, 0.5, 19.0, 26.03755480279231, 0.5982375162107082, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.8144044321329641, 0.84, 0.05333333333333334, 0.0005524861878453039, 0.08333333333333333, 0.6697962335660259, 0.6994125054035694, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2381771], dtype=float32), -0.82704514]. 
=============================================
[2019-04-24 10:15:57,757] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7583749e-01 1.3742372e-03 8.4259181e-04 2.8889179e-08 2.3521387e-12
 1.2978297e-09 4.5340155e-11 6.8366347e-04 4.2126197e-01 2.1300730e-12
 5.0500245e-13], sum to 1.0000
[2019-04-24 10:15:57,761] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1489
[2019-04-24 10:15:57,773] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 92.0, 0.0, 0.0, 19.0, 22.42914489162678, -0.1432789905506182, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1311600.0000, 
sim time next is 1312800.0000, 
raw observation next is [1.8, 92.0, 0.0, 0.0, 19.0, 22.29120541647254, -0.1809064015438892, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5124653739612189, 0.92, 0.0, 0.0, 0.08333333333333333, 0.3576004513727116, 0.43969786615203693, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16431051], dtype=float32), -2.323186]. 
=============================================
[2019-04-24 10:16:00,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0171292e-01 1.2321463e-03 8.2898221e-04 3.6179127e-08 1.1401497e-12
 4.7629589e-10 9.3362554e-11 3.5397694e-04 5.9587193e-01 3.2084853e-12
 4.6816202e-13], sum to 1.0000
[2019-04-24 10:16:00,449] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2265
[2019-04-24 10:16:00,480] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 22.5, 21.34766335511569, -0.5127331687814884, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1410000.0000, 
sim time next is 1411200.0000, 
raw observation next is [-0.6, 100.0, 9.0, 0.0, 22.5, 21.04026133677307, -0.5514770982161936, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44598337950138506, 1.0, 0.03, 0.0, 0.375, 0.2533551113977559, 0.3161743005946021, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9338, 
noisyNet noise sample is [array([0.6535295], dtype=float32), -0.8493781]. 
=============================================
[2019-04-24 10:16:01,416] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2662956e-01 2.2537888e-04 1.5009090e-03 1.2090278e-08 7.2234731e-12
 1.0656590e-09 3.2586593e-11 6.8030530e-04 2.7096391e-01 1.3566092e-11
 1.3275703e-13], sum to 1.0000
[2019-04-24 10:16:01,422] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0045
[2019-04-24 10:16:01,442] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.2, 97.33333333333333, 100.0, 0.0, 19.0, 25.4165064087715, 0.5580357653937568, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1254000.0000, 
sim time next is 1255200.0000, 
raw observation next is [14.0, 98.66666666666666, 100.0, 0.0, 19.0, 25.18826822675314, 0.5001410053291598, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.8504155124653741, 0.9866666666666666, 0.3333333333333333, 0.0, 0.08333333333333333, 0.5990223522294285, 0.6667136684430534, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1238343], dtype=float32), 0.11775643]. 
=============================================
[2019-04-24 10:16:02,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0401067e-01 5.2609795e-04 3.2909042e-03 1.4151699e-08 1.8342990e-12
 1.8507830e-10 1.8072537e-11 3.9512472e-04 2.9177716e-01 2.6953767e-13
 3.8143813e-13], sum to 1.0000
[2019-04-24 10:16:02,896] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5142
[2019-04-24 10:16:02,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4792017e-01 2.2574284e-03 1.6793296e-03 5.7853566e-09 1.5402184e-12
 2.9620245e-10 1.5211256e-11 5.0584495e-04 4.4763720e-01 2.3985443e-12
 1.6953093e-13], sum to 1.0000
[2019-04-24 10:16:02,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5946
[2019-04-24 10:16:02,910] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 92.0, 22.5, 0.0, 22.5, 24.41201289334797, 0.1619901090678307, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1327200.0000, 
sim time next is 1328400.0000, 
raw observation next is [0.5, 92.0, 31.5, 0.0, 22.5, 24.2188957084932, 0.1029777471826577, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.105, 0.0, 0.375, 0.5182413090411, 0.5343259157275525, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0476007], dtype=float32), -0.34977293]. 
=============================================
[2019-04-24 10:16:02,951] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.8, 92.0, 0.0, 0.0, 19.0, 23.76447693778275, -0.02830436809966074, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1473600.0000, 
sim time next is 1474800.0000, 
raw observation next is [2.0, 92.0, 0.0, 0.0, 19.0, 23.57101948467523, 0.07939404108429443, 0.0, 1.0, 55.0, 63.7093227502679], 
processed observation next is [1.0, 0.043478260869565216, 0.518005540166205, 0.92, 0.0, 0.0, 0.08333333333333333, 0.46425162372293577, 0.5264646803614315, 0.0, 1.0, 0.8, 0.637093227502679], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26404238], dtype=float32), 0.26444224]. 
=============================================
[2019-04-24 10:16:06,991] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3149425e-01 6.1319256e-04 1.1884006e-03 3.0810723e-09 3.6250966e-13
 2.6600694e-10 9.7582957e-12 7.1856624e-04 2.6598561e-01 2.5620285e-12
 1.2444424e-14], sum to 1.0000
[2019-04-24 10:16:07,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2793
[2019-04-24 10:16:07,050] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 88.33333333333334, 0.0, 0.0, 19.0, 23.88278135282869, 0.1793918869381881, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1642800.0000, 
sim time next is 1644000.0000, 
raw observation next is [6.8, 90.66666666666667, 0.0, 0.0, 19.0, 23.80931412596026, 0.1513077792134775, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6509695290858727, 0.9066666666666667, 0.0, 0.0, 0.08333333333333333, 0.4841095104966883, 0.5504359264044925, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2294602], dtype=float32), 1.4978187]. 
=============================================
[2019-04-24 10:16:12,282] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3246200e-01 4.1844388e-03 2.3141790e-03 1.7247957e-07 5.4587875e-12
 6.9118395e-09 7.8683227e-11 9.1280381e-04 4.6012637e-01 3.3683015e-11
 2.2698402e-11], sum to 1.0000
[2019-04-24 10:16:12,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9287
[2019-04-24 10:16:12,387] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.866666666666666, 85.0, 62.33333333333333, 0.0, 22.5, 22.22508987427487, -0.5929155455158078, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2020800.0000, 
sim time next is 2022000.0000, 
raw observation next is [-5.733333333333333, 84.0, 74.5, 0.0, 22.5, 22.3785170212997, -0.4095115093815077, 1.0, 1.0, 55.0, 73.13634380148922], 
processed observation next is [1.0, 0.391304347826087, 0.30378578024007385, 0.84, 0.24833333333333332, 0.0, 0.375, 0.3648764184416417, 0.3634961635394974, 1.0, 1.0, 0.8, 0.7313634380148922], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6230701], dtype=float32), -0.12699364]. 
=============================================
[2019-04-24 10:16:12,772] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.55849457e-01 5.61732566e-04 2.24301853e-04 1.09692975e-08
 4.61328729e-13 6.67212174e-10 7.12659706e-12 1.54859299e-04
 3.43209684e-01 3.42337730e-13 5.81332535e-14], sum to 1.0000
[2019-04-24 10:16:12,773] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2344
[2019-04-24 10:16:12,808] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 82.0, 19.0, 20.0, 22.5, 23.50777849995631, -0.05071559232153994, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1584000.0000, 
sim time next is 1585200.0000, 
raw observation next is [5.533333333333333, 80.0, 31.0, 30.0, 22.5, 23.04482634756452, -0.06832643550919842, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6158818097876271, 0.8, 0.10333333333333333, 0.03314917127071823, 0.375, 0.4204021956303767, 0.4772245214969339, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.19414939], dtype=float32), -1.4866999]. 
=============================================
[2019-04-24 10:16:14,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7995853e-01 1.0560382e-03 2.8125828e-03 1.9313229e-07 3.4109760e-11
 8.7057899e-09 3.6386483e-10 8.2189369e-04 5.1535070e-01 2.3007207e-11
 8.0039230e-12], sum to 1.0000
[2019-04-24 10:16:14,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6264
[2019-04-24 10:16:14,250] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 19.0, 20.8672201447007, -0.7510587445439706, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1983600.0000, 
sim time next is 1984800.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 20.76098968164569, -0.5664886386732528, 0.0, 1.0, 55.0, 80.91227822818308], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.23008247347047414, 0.3111704537755824, 0.0, 1.0, 0.8, 0.8091227822818309], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8411315], dtype=float32), 0.3294303]. 
=============================================
[2019-04-24 10:16:17,641] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.18827677e-01 2.23668898e-03 1.25777945e-02 1.20106313e-06
 1.46305190e-09 2.23633464e-07 4.31922942e-08 1.40425877e-03
 4.64952171e-01 5.11511189e-09 3.77291837e-10], sum to 1.0000
[2019-04-24 10:16:17,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3774
[2019-04-24 10:16:17,705] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 19.0, 19.53773099499822, -1.102118035482678, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1890000.0000, 
sim time next is 1891200.0000, 
raw observation next is [-5.8, 80.33333333333334, 0.0, 0.0, 19.0, 18.77670870084584, -1.241487750594876, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.30193905817174516, 0.8033333333333335, 0.0, 0.0, 0.08333333333333333, 0.06472572507048675, 0.08617074980170798, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.8006, 
noisyNet noise sample is [array([1.6291139], dtype=float32), 0.5491836]. 
=============================================
[2019-04-24 10:16:20,261] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8872604e-01 1.4878825e-03 1.4150797e-02 1.5523204e-06 7.4588904e-09
 1.4658839e-07 2.9107673e-08 3.0943840e-03 3.9253905e-01 7.2853550e-09
 1.5950319e-09], sum to 1.0000
[2019-04-24 10:16:20,263] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5414
[2019-04-24 10:16:20,292] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 71.0, 128.3333333333333, 6.666666666666665, 19.0, 18.8963212565397, -0.9623828425164423, 0.0, 1.0, 55.0, 84.35292255667528], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1860000.0000, 
sim time next is 1861200.0000, 
raw observation next is [-4.5, 71.0, 145.0, 20.0, 19.0, 19.45155406283216, -1.064981079440021, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.3379501385041552, 0.71, 0.48333333333333334, 0.022099447513812154, 0.08333333333333333, 0.12096283856934657, 0.14500630685332636, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.37078023], dtype=float32), -2.187607]. 
=============================================
[2019-04-24 10:16:20,941] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.4318392e-01 4.5397741e-04 1.6842096e-03 8.2416705e-09 1.4818333e-12
 4.3843262e-10 2.8448485e-11 3.0284101e-04 4.5437506e-01 2.4136168e-12
 8.1895462e-14], sum to 1.0000
[2019-04-24 10:16:20,943] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1445
[2019-04-24 10:16:20,987] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1666666666666667, 94.0, 0.0, 0.0, 19.0, 22.85193224480748, -0.205356969350166, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1725600.0000, 
sim time next is 1726800.0000, 
raw observation next is [0.3333333333333333, 93.0, 0.0, 0.0, 19.0, 22.19665657889686, -0.3302125587565218, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4718374884579871, 0.93, 0.0, 0.0, 0.08333333333333333, 0.34972138157473837, 0.3899291470811594, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.126165], dtype=float32), -0.4966167]. 
=============================================
[2019-04-24 10:16:27,811] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7844698e-01 2.1004604e-04 3.3473026e-03 5.1142507e-08 7.0861220e-11
 7.6428712e-09 2.9205194e-10 4.6651909e-04 4.1752911e-01 3.6800694e-11
 7.2719907e-12], sum to 1.0000
[2019-04-24 10:16:27,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9534
[2019-04-24 10:16:27,842] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 83.0, 0.0, 0.0, 19.0, 21.25489239722302, -0.5017665227293845, 0.0, 1.0, 55.0, 73.93965912951595], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1980000.0000, 
sim time next is 1981200.0000, 
raw observation next is [-6.0, 83.0, 0.0, 0.0, 19.0, 21.66551238385822, -0.5053258599174397, 0.0, 1.0, 55.0, 52.782758689484496], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.83, 0.0, 0.0, 0.08333333333333333, 0.30545936532151846, 0.33155804669418676, 0.0, 1.0, 0.8, 0.527827586894845], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36968607], dtype=float32), 0.75609595]. 
=============================================
[2019-04-24 10:16:30,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.0305359e-01 9.0165233e-04 1.1792281e-03 3.1476951e-08 1.3679667e-11
 3.2651211e-09 9.5951587e-11 4.6740944e-04 2.9439798e-01 6.9754389e-12
 1.0692633e-12], sum to 1.0000
[2019-04-24 10:16:30,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8987
[2019-04-24 10:16:30,672] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 22.5, 22.59313161717665, -0.1125150578602967, 1.0, 1.0, 55.0, 103.33255620362951], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2138400.0000, 
sim time next is 2139600.0000, 
raw observation next is [-5.0, 72.0, 0.0, 0.0, 22.5, 23.76161141801911, -0.00726248995081467, 1.0, 1.0, 55.0, 64.63842114291863], 
processed observation next is [1.0, 0.782608695652174, 0.32409972299168976, 0.72, 0.0, 0.0, 0.375, 0.48013428483492593, 0.4975791700163951, 1.0, 1.0, 0.8, 0.6463842114291863], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8519042], dtype=float32), 0.55012524]. 
=============================================
[2019-04-24 10:16:37,497] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.6615872e-01 2.8043063e-03 5.8347248e-03 1.2023627e-07 8.5877685e-12
 1.6673344e-09 3.0702188e-10 5.3977175e-04 5.2466244e-01 1.3878785e-11
 3.3383819e-12], sum to 1.0000
[2019-04-24 10:16:37,499] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9762
[2019-04-24 10:16:37,609] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.8, 82.0, 123.0, 77.5, 22.5, 22.36288928832727, -0.3432315041206461, 1.0, 1.0, 55.0, 68.96932863781322], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2106000.0000, 
sim time next is 2107200.0000, 
raw observation next is [-7.8, 82.0, 157.0, 104.5, 22.5, 23.04025663099544, -0.2541037436442972, 1.0, 1.0, 55.0, 49.53852490872376], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.5233333333333333, 0.11546961325966851, 0.375, 0.4200213859162867, 0.4152987521185676, 1.0, 1.0, 0.8, 0.4953852490872376], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6736605], dtype=float32), 0.76350814]. 
=============================================
[2019-04-24 10:16:38,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3739554e-01 7.3986659e-03 1.9739289e-03 2.1136546e-07 1.1247276e-11
 1.0035560e-08 5.5173949e-10 5.4858136e-04 4.5268303e-01 1.4169268e-11
 3.6714290e-12], sum to 1.0000
[2019-04-24 10:16:38,447] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9377
[2019-04-24 10:16:38,633] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.833333333333334, 84.0, 91.66666666666667, 35.16666666666666, 22.5, 22.43943259646868, -0.395972951065176, 1.0, 1.0, 55.0, 65.79906790639], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2280000.0000, 
sim time next is 2281200.0000, 
raw observation next is [-7.266666666666667, 81.0, 113.8333333333333, 40.83333333333333, 22.5, 23.05686666117453, -0.2912857618639669, 1.0, 1.0, 55.0, 63.382622702313114], 
processed observation next is [1.0, 0.391304347826087, 0.26131117266851345, 0.81, 0.3794444444444443, 0.04511970534069981, 0.375, 0.42140555509787764, 0.4029047460453444, 1.0, 1.0, 0.8, 0.6338262270231312], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0161743], dtype=float32), 1.1017433]. 
=============================================
[2019-04-24 10:16:41,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2336174e-01 2.9680065e-03 3.7640180e-03 1.0329271e-06 1.0180273e-09
 3.2004937e-07 9.1771915e-09 2.9643504e-03 4.6694055e-01 3.0503433e-09
 2.2976666e-10], sum to 1.0000
[2019-04-24 10:16:41,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6394
[2019-04-24 10:16:41,850] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 19.0, 21.78700628896035, -0.5832809180733057, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2341200.0000, 
sim time next is 2342400.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 19.0, 21.39751282456035, -0.4545874629276934, 0.0, 1.0, 55.0, 72.6095953978184], 
processed observation next is [0.0, 0.08695652173913043, 0.3988919667590028, 0.62, 0.0, 0.0, 0.08333333333333333, 0.2831260687133626, 0.34847084569076886, 0.0, 1.0, 0.8, 0.7260959539781839], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.602256], dtype=float32), 0.11529695]. 
=============================================
[2019-04-24 10:16:46,144] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.1339051e-01 2.6932640e-03 1.4728484e-03 5.0188827e-08 2.0227706e-12
 2.6147293e-09 2.9083555e-11 8.6563894e-05 3.8235676e-01 2.1754332e-12
 3.5048674e-12], sum to 1.0000
[2019-04-24 10:16:46,145] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2072
[2019-04-24 10:16:46,210] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 69.0, 0.0, 0.0, 22.5, 22.67131766485722, -0.363060537434762, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2223600.0000, 
sim time next is 2224800.0000, 
raw observation next is [-4.5, 68.0, 0.0, 0.0, 22.5, 22.10751540706973, -0.4417977167839468, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3379501385041552, 0.68, 0.0, 0.0, 0.375, 0.34229295058914416, 0.35273409440535103, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5723958], dtype=float32), 2.414242]. 
=============================================
[2019-04-24 10:16:46,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2252579e-01 1.0216240e-03 3.5595493e-03 1.5352853e-07 8.3990287e-11
 1.8414420e-08 1.2699433e-09 1.6923635e-03 4.7120047e-01 3.2368930e-10
 1.8940495e-11], sum to 1.0000
[2019-04-24 10:16:46,520] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8126
[2019-04-24 10:16:46,559] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 63.0, 0.0, 0.0, 19.0, 21.89884099129315, -0.3880173456292276, 0.0, 1.0, 55.0, 48.34390407441004], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2335200.0000, 
sim time next is 2336400.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 19.0, 22.18860438604579, -0.3499494674597542, 0.0, 1.0, 55.0, 47.070728296244816], 
processed observation next is [0.0, 0.043478260869565216, 0.3988919667590028, 0.62, 0.0, 0.0, 0.08333333333333333, 0.34905036550381574, 0.3833501775134153, 0.0, 1.0, 0.8, 0.4707072829624482], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41881296], dtype=float32), -0.08471749]. 
=============================================
[2019-04-24 10:16:46,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3661506e-01 1.6540051e-02 4.7050629e-02 6.7494479e-06 1.5241334e-07
 1.8182636e-06 1.4977439e-06 9.8260622e-03 5.8995777e-01 1.6490314e-07
 4.1348393e-08], sum to 1.0000
[2019-04-24 10:16:46,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8712
[2019-04-24 10:16:46,892] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-9.3, 60.66666666666667, 0.0, 0.0, 19.0, 18.52471164325143, -1.317618140393963, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2443200.0000, 
sim time next is 2444400.0000, 
raw observation next is [-9.5, 61.0, 0.0, 0.0, 19.0, 18.34870757612078, -1.183410982273509, 0.0, 1.0, 55.0, 77.29842472457707], 
processed observation next is [0.0, 0.30434782608695654, 0.1994459833795014, 0.61, 0.0, 0.0, 0.08333333333333333, 0.02905896467673171, 0.10552967257549699, 0.0, 1.0, 0.8, 0.7729842472457708], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58863616], dtype=float32), 0.17629948]. 
=============================================
[2019-04-24 10:16:48,975] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.4095698e-01 2.5270162e-03 9.3311733e-03 3.7094603e-07 4.6387751e-11
 1.4149187e-08 9.5876462e-10 9.2657609e-04 5.4625785e-01 8.8912190e-11
 1.8151539e-11], sum to 1.0000
[2019-04-24 10:16:48,976] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5616
[2019-04-24 10:16:49,053] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 19.0, 21.2128851944357, -0.7076714813949018, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2600400.0000, 
sim time next is 2601600.0000, 
raw observation next is [-5.0, 74.0, 0.0, 0.0, 19.0, 21.09372687659935, -0.5001268060973888, 0.0, 1.0, 55.0, 81.91259894106096], 
processed observation next is [1.0, 0.08695652173913043, 0.32409972299168976, 0.74, 0.0, 0.0, 0.08333333333333333, 0.257810573049946, 0.3332910646342037, 0.0, 1.0, 0.8, 0.8191259894106097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73533905], dtype=float32), 0.18220031]. 
=============================================
[2019-04-24 10:16:51,599] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.7235299e-01 7.7870936e-04 1.8271317e-03 7.0678823e-08 1.0829468e-11
 1.0721420e-08 4.7667707e-11 2.4628188e-04 2.2479476e-01 1.4373885e-11
 1.8517647e-11], sum to 1.0000
[2019-04-24 10:16:51,601] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0484
[2019-04-24 10:16:51,638] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 115.0, 165.0, 22.5, 22.57849293357808, -0.3613529660563883, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2649600.0000, 
sim time next is 2650800.0000, 
raw observation next is [0.5, 50.0, 88.33333333333333, 137.6666666666667, 22.5, 22.5725142733083, -0.3621920006975788, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4764542936288089, 0.5, 0.29444444444444445, 0.15211786372007371, 0.375, 0.38104285610902505, 0.37926933310080707, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.160242], dtype=float32), 0.5626613]. 
=============================================
[2019-04-24 10:17:01,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4423749e-01 9.1427605e-04 2.4929079e-03 1.4463696e-08 4.9772682e-12
 2.2311952e-09 1.6517382e-10 1.2260400e-03 4.5112935e-01 2.3315976e-12
 6.3806312e-13], sum to 1.0000
[2019-04-24 10:17:01,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6586
[2019-04-24 10:17:01,378] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 19.0, 22.23763059869619, -0.3716104542018533, 0.0, 1.0, 55.0, 47.43992273230414], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3117600.0000, 
sim time next is 3118800.0000, 
raw observation next is [1.333333333333333, 100.0, 0.0, 0.0, 19.0, 22.46958864987315, -0.3357629119446359, 0.0, 1.0, 55.0, 46.506034443858155], 
processed observation next is [1.0, 0.08695652173913043, 0.4995383194829178, 1.0, 0.0, 0.0, 0.08333333333333333, 0.3724657208227624, 0.388079029351788, 0.0, 1.0, 0.8, 0.4650603444385816], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48683634], dtype=float32), -0.057479087]. 
=============================================
[2019-04-24 10:17:03,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0484284e-01 1.6755562e-03 5.0585042e-03 1.4768021e-06 1.6067504e-09
 1.9164214e-07 3.6882099e-08 3.9335019e-03 3.8448793e-01 3.1519007e-09
 1.5454090e-09], sum to 1.0000
[2019-04-24 10:17:03,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1821
[2019-04-24 10:17:03,060] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.333333333333334, 73.0, 0.0, 0.0, 19.0, 20.67999009355444, -0.6750534493091559, 0.0, 1.0, 55.0, 67.45608247588187], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3032400.0000, 
sim time next is 3033600.0000, 
raw observation next is [-5.666666666666667, 75.0, 0.0, 0.0, 19.0, 20.80309779791007, -0.8109435844025338, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.30563250230840255, 0.75, 0.0, 0.0, 0.08333333333333333, 0.23359148315917247, 0.22968547186582208, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34583685], dtype=float32), -0.8250256]. 
=============================================
[2019-04-24 10:17:03,324] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.20863104e-01 4.05172759e-04 1.52029446e-03 6.10125852e-08
 2.74082684e-11 1.22930865e-08 1.00733706e-10 4.90080041e-04
 2.76721269e-01 3.61476682e-11 3.07859662e-12], sum to 1.0000
[2019-04-24 10:17:03,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9035
[2019-04-24 10:17:03,406] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 22.5, 22.41402683457653, -0.408437135476168, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2833200.0000, 
sim time next is 2834400.0000, 
raw observation next is [2.666666666666667, 39.33333333333334, 0.0, 0.0, 22.5, 22.33166204838166, -0.1948349057830651, 0.0, 1.0, 55.0, 94.70859066018524], 
processed observation next is [1.0, 0.8260869565217391, 0.5364727608494922, 0.3933333333333334, 0.0, 0.0, 0.375, 0.36097183736513827, 0.43505503140564494, 0.0, 1.0, 0.8, 0.9470859066018523], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.852671], dtype=float32), 1.4144686]. 
=============================================
[2019-04-24 10:17:09,326] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.2738405e-01 2.6071360e-03 5.2694990e-03 1.5285201e-07 2.8538613e-10
 2.1933273e-08 3.1100935e-09 2.4474980e-03 5.6229168e-01 3.6756725e-10
 3.5640772e-11], sum to 1.0000
[2019-04-24 10:17:09,327] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2131
[2019-04-24 10:17:09,358] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 21.91185094393293, -0.6150314603525274, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2775600.0000, 
sim time next is 2776800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 21.03623350891326, -0.762421186621613, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.25301945907610496, 0.24585960445946234, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42227006], dtype=float32), 0.72395235]. 
=============================================
[2019-04-24 10:17:11,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5670755e-01 2.4664972e-04 4.4554402e-03 9.0506312e-08 8.8801640e-12
 3.7982346e-09 6.9482226e-11 3.4286978e-04 2.3824739e-01 9.4558059e-12
 1.0368145e-12], sum to 1.0000
[2019-04-24 10:17:11,579] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9377
[2019-04-24 10:17:11,646] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666666, 77.66666666666667, 0.0, 0.0, 19.0, 23.86590070400698, 0.09240516361556726, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3271200.0000, 
sim time next is 3272400.0000, 
raw observation next is [-5.0, 81.0, 0.0, 0.0, 19.0, 23.75369971242669, 0.214697194184491, 0.0, 1.0, 55.0, 70.1088704836775], 
processed observation next is [1.0, 0.9130434782608695, 0.32409972299168976, 0.81, 0.0, 0.0, 0.08333333333333333, 0.4794749760355576, 0.5715657313948304, 0.0, 1.0, 0.8, 0.7010887048367751], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1269876], dtype=float32), -0.4238567]. 
=============================================
[2019-04-24 10:17:13,729] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.0340585e-01 3.6749071e-03 3.0489489e-03 4.0706047e-07 2.4816454e-10
 6.2261783e-08 2.1862685e-09 3.0628096e-03 5.8680707e-01 7.0015416e-10
 6.1183225e-11], sum to 1.0000
[2019-04-24 10:17:13,731] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4321
[2019-04-24 10:17:13,799] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 21.35172213803868, -0.4919174764651906, 0.0, 1.0, 55.0, 52.36010034799416], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2953200.0000, 
sim time next is 2954400.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 21.55388092391327, -0.47372488784368, 0.0, 1.0, 55.0, 51.42811242875912], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.29615674365943906, 0.3420917040521067, 0.0, 1.0, 0.8, 0.5142811242875912], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.515398], dtype=float32), -1.927473]. 
=============================================
[2019-04-24 10:17:15,441] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6109025e-01 2.1480292e-03 8.5188523e-03 9.0699524e-07 5.6379754e-09
 6.7700526e-08 2.5497711e-08 5.1855133e-03 3.2305640e-01 2.4034696e-09
 1.0688380e-10], sum to 1.0000
[2019-04-24 10:17:15,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5344
[2019-04-24 10:17:15,478] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 20.74648450772668, -0.5149684738456389, 0.0, 1.0, 20.0, 67.04102856038699], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2952000.0000, 
sim time next is 2953200.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 21.0447508002378, -0.6126324336246666, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.25372923335315, 0.2957891887917778, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30902955], dtype=float32), -1.1245203]. 
=============================================
[2019-04-24 10:17:17,566] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.08078635e-01 4.60830575e-04 3.75501066e-03 1.21537724e-07
 1.49146265e-10 1.41217065e-08 3.93948607e-09 3.84149462e-04
 4.87321198e-01 9.14061674e-11 6.50995056e-12], sum to 1.0000
[2019-04-24 10:17:17,567] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2251
[2019-04-24 10:17:17,589] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333334, 100.0, 0.0, 0.0, 19.0, 21.41855117289314, -0.653192985145602, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3105600.0000, 
sim time next is 3106800.0000, 
raw observation next is [0.0, 100.0, 0.0, 0.0, 19.0, 20.82817025015505, -0.745614892133188, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.46260387811634357, 1.0, 0.0, 0.0, 0.08333333333333333, 0.23568085417958753, 0.2514617026222707, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5314018], dtype=float32), 2.0386705]. 
=============================================
[2019-04-24 10:17:20,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8761235e-01 1.8720648e-03 2.8984738e-03 1.8070227e-07 5.1202192e-10
 2.6236680e-08 3.2902003e-09 1.5360573e-03 3.0608091e-01 7.3503831e-10
 5.9900349e-11], sum to 1.0000
[2019-04-24 10:17:20,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7224
[2019-04-24 10:17:20,585] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.666666666666666, 38.0, 116.1666666666667, 818.1666666666666, 19.0, 24.68769107823591, 0.152988607835199, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3670800.0000, 
sim time next is 3672000.0000, 
raw observation next is [4.0, 45.0, 116.5, 822.5, 19.0, 24.50521921874397, 0.286135368591153, 0.0, 1.0, 55.0, 58.87831649472497], 
processed observation next is [0.0, 0.5217391304347826, 0.5734072022160666, 0.45, 0.3883333333333333, 0.9088397790055248, 0.08333333333333333, 0.5421016015619976, 0.595378456197051, 0.0, 1.0, 0.8, 0.5887831649472497], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8547665], dtype=float32), 0.10926214]. 
=============================================
[2019-04-24 10:17:24,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.49743235e-01 4.08973778e-03 2.80267559e-03 2.24898130e-07
 1.04394465e-10 1.52991682e-08 1.37574119e-09 1.96946668e-03
 4.41394627e-01 2.35284375e-10 1.93925691e-11], sum to 1.0000
[2019-04-24 10:17:24,244] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4467
[2019-04-24 10:17:24,264] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 70.33333333333334, 0.0, 0.0, 19.0, 20.38720063986846, -0.7308168328085012, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3468000.0000, 
sim time next is 3469200.0000, 
raw observation next is [1.0, 68.66666666666667, 0.0, 0.0, 19.0, 20.35730115631713, -0.7417665938082164, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.4903047091412743, 0.6866666666666668, 0.0, 0.0, 0.08333333333333333, 0.1964417630264276, 0.25274446873059453, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10340311], dtype=float32), 0.4345173]. 
=============================================
[2019-04-24 10:17:27,465] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.4345882e-01 2.5501505e-03 1.8051949e-03 1.5379270e-07 1.7748674e-11
 2.2421959e-08 2.8356151e-10 2.3181358e-04 4.5195386e-01 1.1664201e-11
 6.4039381e-12], sum to 1.0000
[2019-04-24 10:17:27,465] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3106
[2019-04-24 10:17:27,490] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 22.43231958651396, -0.3231732936400589, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3378000.0000, 
sim time next is 3379200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.99301811162739, -0.4288994252093218, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3327515093022824, 0.35703352493022605, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7446232], dtype=float32), 2.1131418]. 
=============================================
[2019-04-24 10:17:27,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1080295e-01 1.1092932e-03 1.0830592e-03 1.4667728e-07 1.3085894e-11
 8.7108152e-09 8.6348782e-11 1.2288602e-03 3.8577566e-01 8.5947811e-12
 1.1532610e-11], sum to 1.0000
[2019-04-24 10:17:27,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5681
[2019-04-24 10:17:27,512] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 73.0, 0.0, 0.0, 19.0, 23.4443314983865, -0.173110866275325, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3811200.0000, 
sim time next is 3812400.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 19.0, 22.52963160400315, -0.3100470586547736, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.3518005540166205, 0.71, 0.0, 0.0, 0.08333333333333333, 0.3774693003335958, 0.3966509804484088, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.44313186], dtype=float32), -0.43361577]. 
=============================================
[2019-04-24 10:17:27,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9849132e-01 2.3349116e-03 1.5624921e-03 7.8754233e-08 9.7662625e-12
 8.2073415e-09 2.4436997e-10 9.4821653e-04 4.9666297e-01 1.0825577e-11
 1.1532387e-11], sum to 1.0000
[2019-04-24 10:17:27,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3866
[2019-04-24 10:17:27,832] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 22.62796604792748, -0.1572796675372113, 0.0, 1.0, 55.0, 71.28641704738237], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3909600.0000, 
sim time next is 3910800.0000, 
raw observation next is [-6.333333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 22.90121128976071, -0.2803807850293813, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.28716528162511545, 0.6066666666666667, 0.0, 0.0, 0.08333333333333333, 0.4084342741467258, 0.40653973832353957, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4795142], dtype=float32), -0.027593829]. 
=============================================
[2019-04-24 10:17:28,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4275590e-01 3.9136806e-03 8.0284793e-03 5.2334158e-06 4.7211959e-09
 2.5500049e-07 3.0611282e-08 2.3534154e-03 4.4294307e-01 5.9917147e-09
 1.0803703e-09], sum to 1.0000
[2019-04-24 10:17:28,383] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5933
[2019-04-24 10:17:28,439] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 19.0, 21.56888419178956, -0.5530572268049078, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3625200.0000, 
sim time next is 3626400.0000, 
raw observation next is [1.0, 48.33333333333334, 0.0, 0.0, 19.0, 21.66820663602744, -0.3425340846929304, 0.0, 1.0, 55.0, 74.49650696062906], 
processed observation next is [0.0, 1.0, 0.4903047091412743, 0.48333333333333345, 0.0, 0.0, 0.08333333333333333, 0.3056838863356199, 0.3858219717690232, 0.0, 1.0, 0.8, 0.7449650696062906], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.625993], dtype=float32), 1.6572196]. 
=============================================
[2019-04-24 10:17:35,800] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5750005e-01 9.8478526e-04 8.4559969e-04 4.6974371e-08 1.0284891e-11
 3.2847089e-09 1.7267247e-10 3.6622045e-04 2.4030326e-01 1.9927992e-11
 3.9661013e-12], sum to 1.0000
[2019-04-24 10:17:35,803] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4879
[2019-04-24 10:17:35,821] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 43.0, 0.0, 0.0, 19.0, 23.08129650135132, 0.04752759408680363, 0.0, 1.0, 55.0, 77.49638750717824], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4143600.0000, 
sim time next is 4144800.0000, 
raw observation next is [-0.3333333333333333, 42.66666666666667, 0.0, 0.0, 19.0, 23.56685154392092, -0.057802530647376, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4533702677747, 0.4266666666666667, 0.0, 0.0, 0.08333333333333333, 0.4639042953267432, 0.480732489784208, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6581779], dtype=float32), 0.6519084]. 
=============================================
[2019-04-24 10:17:41,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0685891e-01 5.7587926e-03 2.1376195e-03 1.0125802e-06 1.7286800e-09
 1.2872003e-07 1.6104352e-08 2.7508847e-03 3.8249263e-01 1.4051120e-09
 1.4878344e-10], sum to 1.0000
[2019-04-24 10:17:41,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4596
[2019-04-24 10:17:41,168] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 19.0, 21.90470660660152, -0.3248076310608795, 0.0, 1.0, 55.0, 76.7398042801282], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4256400.0000, 
sim time next is 4257600.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 19.0, 22.44893621646132, -0.4120718763094478, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.08333333333333333, 0.37074468470510996, 0.36264270789685077, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.61938477], dtype=float32), 2.9477265]. 
=============================================
[2019-04-24 10:17:41,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5097153e-01 5.0979131e-04 2.5565913e-03 7.2916912e-08 2.4876403e-11
 3.3166974e-09 3.2371403e-10 2.8443274e-03 3.4311771e-01 8.4649327e-12
 2.1820336e-12], sum to 1.0000
[2019-04-24 10:17:41,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9676
[2019-04-24 10:17:41,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 19.0, 22.87854508582629, -0.1302896415824444, 0.0, 1.0, 55.0, 53.12474870772117], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3819600.0000, 
sim time next is 3820800.0000, 
raw observation next is [-4.333333333333334, 73.0, 0.0, 0.0, 19.0, 23.32020375792835, -0.1000046730989814, 0.0, 1.0, 55.0, 51.350158257107026], 
processed observation next is [1.0, 0.21739130434782608, 0.3425669436749769, 0.73, 0.0, 0.0, 0.08333333333333333, 0.4433503131606959, 0.4666651089670062, 0.0, 1.0, 0.8, 0.5135015825710703], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5117121], dtype=float32), -2.1318898]. 
=============================================
[2019-04-24 10:17:42,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9745543e-01 3.3075991e-04 8.4351143e-04 4.5477016e-08 1.0952588e-11
 2.8638412e-09 1.4869170e-10 4.4890115e-04 2.0092136e-01 5.3415926e-12
 1.3103125e-12], sum to 1.0000
[2019-04-24 10:17:42,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5661
[2019-04-24 10:17:42,863] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 60.0, 113.5, 798.5, 22.5, 24.86161830637546, 0.148321602402595, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3841200.0000, 
sim time next is 3842400.0000, 
raw observation next is [-1.0, 60.00000000000001, 115.8333333333333, 814.1666666666666, 22.5, 24.41329889184694, 0.06937394422004517, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4349030470914128, 0.6000000000000001, 0.386111111111111, 0.8996316758747698, 0.375, 0.5344415743205783, 0.5231246480733484, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39997816], dtype=float32), -0.074521475]. 
=============================================
[2019-04-24 10:17:46,222] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.6725537e-01 1.2411609e-03 7.3453673e-04 1.5918218e-07 2.0286293e-11
 1.9249210e-08 1.8925583e-10 3.5266066e-04 2.3041600e-01 4.3256503e-11
 1.2969069e-11], sum to 1.0000
[2019-04-24 10:17:46,229] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4384
[2019-04-24 10:17:46,304] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.666666666666666, 43.66666666666667, 0.0, 0.0, 22.5, 23.42028887008947, -0.06680320094257707, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3958800.0000, 
sim time next is 3960000.0000, 
raw observation next is [-7.0, 45.0, 0.0, 0.0, 22.5, 22.81611968836127, -0.1632995761660345, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.2686980609418283, 0.45, 0.0, 0.0, 0.375, 0.4013433073634391, 0.44556680794465514, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09519253], dtype=float32), -0.16942254]. 
=============================================
[2019-04-24 10:17:46,345] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[57.351994]
 [57.690098]
 [57.839138]
 [56.812542]
 [57.30223 ]
 [56.446217]
 [57.303875]
 [57.900467]
 [58.4325  ]
 [58.93299 ]
 [59.4948  ]
 [60.01698 ]
 [60.27144 ]
 [60.556103]
 [60.86103 ]
 [61.27471 ]
 [60.61472 ]
 [61.328785]
 [61.664165]
 [62.27139 ]
 [62.458683]
 [61.39044 ]
 [61.718452]
 [61.781803]
 [61.88706 ]], R is [[57.04496765]
 [57.47451782]
 [57.89977264]
 [57.32077408]
 [57.74756622]
 [57.17008972]
 [57.59838867]
 [58.02240372]
 [58.44218063]
 [58.85775757]
 [59.2691803 ]
 [59.67649078]
 [60.07972717]
 [60.47893143]
 [60.87414169]
 [61.26539993]
 [60.65274811]
 [61.04622269]
 [61.4357605 ]
 [61.8214035 ]
 [62.20318985]
 [61.58115768]
 [61.96534729]
 [62.3456955 ]
 [62.72224045]].
[2019-04-24 10:18:04,227] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8137871e-01 3.0934077e-04 8.3463165e-05 3.2476279e-09 2.0934333e-13
 1.6314368e-10 2.7881423e-12 8.2826286e-05 1.1814566e-01 2.2622461e-13
 1.8206970e-14], sum to 1.0000
[2019-04-24 10:18:04,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6603
[2019-04-24 10:18:04,314] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666666, 88.0, 195.5, 5.0, 22.5, 24.79904164751852, 0.1454413652774487, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4707600.0000, 
sim time next is 4708800.0000, 
raw observation next is [1.0, 86.0, 160.5, 3.0, 22.5, 24.5508020321392, 0.08701413257366652, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 0.86, 0.535, 0.0033149171270718232, 0.375, 0.5459001693449332, 0.5290047108578889, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.86542803], dtype=float32), 1.4648616]. 
=============================================
[2019-04-24 10:18:05,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0679978e-01 1.4584993e-03 9.3942611e-03 1.4112956e-06 8.3652024e-10
 3.1681478e-07 8.1117184e-09 1.9277446e-03 3.8041791e-01 1.5437345e-09
 2.0136157e-10], sum to 1.0000
[2019-04-24 10:18:05,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3867
[2019-04-24 10:18:05,628] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 47.33333333333334, 0.0, 0.0, 19.0, 21.75476833590559, -0.3508714376024881, 0.0, 1.0, 55.0, 77.27739662061235], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4231200.0000, 
sim time next is 4232400.0000, 
raw observation next is [1.666666666666667, 47.66666666666667, 0.0, 0.0, 19.0, 22.29944760061102, -0.440346129447145, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5087719298245615, 0.47666666666666674, 0.0, 0.0, 0.08333333333333333, 0.3582873000509184, 0.3532179568509517, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.18899685], dtype=float32), -0.97380286]. 
=============================================
[2019-04-24 10:18:09,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.9025165e-01 2.7476272e-03 1.1898117e-02 3.5557598e-06 2.5162054e-08
 8.3375994e-07 5.1782440e-08 4.0516797e-03 2.9104653e-01 9.2397219e-09
 1.9491657e-09], sum to 1.0000
[2019-04-24 10:18:09,455] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6943
[2019-04-24 10:18:09,564] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.666666666666666, 49.33333333333333, 0.0, 0.0, 19.0, 20.73073082647137, -0.6835215435204735, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4171200.0000, 
sim time next is 4172400.0000, 
raw observation next is [-5.0, 49.0, 0.0, 0.0, 19.0, 20.91573875927536, -0.5004291396713639, 0.0, 1.0, 25.0, 70.00780985513995], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.49, 0.0, 0.0, 0.08333333333333333, 0.24297822993961335, 0.33319028677621204, 0.0, 1.0, 0.2, 0.7000780985513996], 
reward next is 0.0999, 
noisyNet noise sample is [array([-0.16118696], dtype=float32), -0.5523391]. 
=============================================
[2019-04-24 10:18:14,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6912460e-01 1.4257921e-03 8.4240874e-04 1.5955889e-08 1.9584642e-12
 3.1198355e-09 1.6836696e-10 1.2155533e-03 3.2739159e-01 4.3755563e-12
 6.0595105e-13], sum to 1.0000
[2019-04-24 10:18:14,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3728
[2019-04-24 10:18:14,819] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.166666666666667, 71.33333333333333, 0.0, 0.0, 19.0, 23.49327392158259, -0.04794589295734514, 0.0, 1.0, 55.0, 49.473427629251745], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4329600.0000, 
sim time next is 4330800.0000, 
raw observation next is [4.0, 71.0, 0.0, 0.0, 19.0, 23.53274950353238, -0.1862584275841528, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5734072022160666, 0.71, 0.0, 0.0, 0.08333333333333333, 0.4610624586276983, 0.43791385747194905, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4020145], dtype=float32), 0.60739315]. 
=============================================
[2019-04-24 10:18:20,592] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4283487e-01 5.3005270e-04 4.2591133e-04 8.2100033e-09 1.0058989e-12
 3.3469780e-10 7.7786250e-12 2.7215778e-04 2.5593707e-01 2.8646909e-13
 1.5176407e-13], sum to 1.0000
[2019-04-24 10:18:20,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0265
[2019-04-24 10:18:20,721] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.2, 84.66666666666667, 157.5, 64.5, 22.5, 24.35384658209223, 0.1369901953932442, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4440000.0000, 
sim time next is 4441200.0000, 
raw observation next is [1.1, 85.33333333333333, 179.3333333333333, 50.16666666666666, 22.5, 24.44092243611784, 0.1498242587109547, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8533333333333333, 0.5977777777777776, 0.05543278084714548, 0.375, 0.5367435363431534, 0.5499414195703182, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4509436], dtype=float32), -0.19498664]. 
=============================================
[2019-04-24 10:18:20,767] A3C_AGENT_WORKER-Thread-5 INFO:Evaluating...
[2019-04-24 10:18:20,794] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:18:20,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:20,799] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run9
[2019-04-24 10:18:20,823] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:18:20,855] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:20,860] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run9
[2019-04-24 10:18:20,877] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:18:20,877] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:20,880] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run9
[2019-04-24 10:20:36,293] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2993.7035 81146.7848 27.2549
[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:36,438] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,367] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2740.4512 92661.7644 -290.4757
[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:44,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,118] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2601.6180 96487.6544 -411.3548
[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,142] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:47,248] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:20:48,144] A3C_AGENT_WORKER-Thread-5 INFO:Global step: 400000, evaluation results [400000.0, 2740.4511904342917, 92661.76443024413, -290.4756872368712, 2993.7035179585346, 81146.78478860694, 27.25486264279851, 2601.618015171158, 96487.65443956618, -411.3547861072733]
[2019-04-24 10:20:50,152] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6454968e-01 4.2681838e-03 8.4384326e-03 1.8489520e-06 7.7772508e-09
 4.6815259e-07 6.3683345e-08 7.5128237e-03 4.1522846e-01 6.7554331e-09
 1.1413478e-09], sum to 1.0000
[2019-04-24 10:20:50,152] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2551
[2019-04-24 10:20:50,161] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 19.0, 21.28509483397744, -0.7008981147658111, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4849200.0000, 
sim time next is 4850400.0000, 
raw observation next is [-3.0, 60.00000000000001, 0.0, 0.0, 19.0, 20.6303040256177, -0.8218052945596493, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.6000000000000001, 0.0, 0.0, 0.08333333333333333, 0.21919200213480838, 0.2260649018134502, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7086796], dtype=float32), 0.48391014]. 
=============================================
[2019-04-24 10:20:50,837] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.17415738e-01 5.34488820e-04 1.77991067e-04 4.25209645e-09
 2.08076611e-13 1.67218434e-10 7.10465486e-13 1.12957096e-04
 8.17587823e-02 9.96914411e-14 3.35977821e-14], sum to 1.0000
[2019-04-24 10:20:50,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0449
[2019-04-24 10:20:50,857] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.1813327e-01 6.8553217e-04 5.8739906e-04 1.2729790e-08 7.4168400e-13
 1.0186770e-09 1.3793388e-11 8.9174829e-04 2.7970204e-01 4.5213364e-13
 2.5661461e-13], sum to 1.0000
[2019-04-24 10:20:50,859] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8827
[2019-04-24 10:20:50,884] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 50.0, 0.0, 0.0, 22.5, 26.31337873249537, 0.6083206801940139, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4388400.0000, 
sim time next is 4389600.0000, 
raw observation next is [11.66666666666667, 52.66666666666667, 0.0, 0.0, 22.5, 26.06748178955225, 0.5607634746500749, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.785780240073869, 0.5266666666666667, 0.0, 0.0, 0.375, 0.6722901491293541, 0.6869211582166916, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1523116], dtype=float32), 0.58126616]. 
=============================================
[2019-04-24 10:20:50,907] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.5, 67.0, 0.0, 0.0, 19.0, 25.60116312465755, 0.3680642622472263, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4420800.0000, 
sim time next is 4422000.0000, 
raw observation next is [4.266666666666667, 67.33333333333334, 0.0, 0.0, 19.0, 25.37758768685865, 0.4918103258937165, 0.0, 1.0, 55.0, 63.83465610176077], 
processed observation next is [1.0, 0.17391304347826086, 0.5807940904893814, 0.6733333333333335, 0.0, 0.0, 0.08333333333333333, 0.6147989739048875, 0.6639367752979055, 0.0, 1.0, 0.8, 0.6383465610176077], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5588555], dtype=float32), -1.3231448]. 
=============================================
[2019-04-24 10:20:50,928] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1697333e-01 5.3999847e-04 2.8905787e-03 3.0320614e-08 1.0709438e-11
 5.4223621e-09 5.4709334e-11 3.9794401e-04 1.7919809e-01 9.4510094e-12
 1.0667842e-12], sum to 1.0000
[2019-04-24 10:20:50,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1293
[2019-04-24 10:20:50,954] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 49.33333333333333, 125.5, 0.0, 22.5, 22.95657034377503, -0.3286312815954959, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4537200.0000, 
sim time next is 4538400.0000, 
raw observation next is [2.0, 50.66666666666666, 147.0, 7.999999999999998, 22.5, 22.61062034915235, -0.3634940779090635, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.5066666666666666, 0.49, 0.008839779005524859, 0.375, 0.3842183624293624, 0.3788353073636455, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5797707], dtype=float32), -0.9535224]. 
=============================================
[2019-04-24 10:20:52,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3871356e-01 2.0808631e-03 7.0041948e-04 5.0194341e-08 1.2909080e-12
 6.3532790e-10 1.7889570e-11 4.6907907e-04 2.5803596e-01 2.0812902e-12
 4.0421055e-13], sum to 1.0000
[2019-04-24 10:20:52,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3424
[2019-04-24 10:20:52,186] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666666, 64.66666666666667, 139.3333333333333, 2.999999999999999, 22.5, 24.59650615838351, 0.1548138990604598, 1.0, 1.0, 55.0, 48.328642107451], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4527600.0000, 
sim time next is 4528800.0000, 
raw observation next is [1.0, 61.0, 172.0, 9.0, 22.5, 24.80385835191912, 0.08314787529680259, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4903047091412743, 0.61, 0.5733333333333334, 0.009944751381215469, 0.375, 0.5669881959932601, 0.5277159584322676, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7949604], dtype=float32), -0.3206236]. 
=============================================
[2019-04-24 10:20:52,748] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.2708451e-01 2.5551111e-04 2.1010134e-04 1.4061105e-08 3.8874616e-13
 8.4943141e-10 2.3297872e-12 9.4148447e-05 7.2355777e-02 2.6192639e-13
 2.9696569e-13], sum to 1.0000
[2019-04-24 10:20:52,751] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3642
[2019-04-24 10:20:52,770] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 59.66666666666667, 204.6666666666667, 15.0, 22.5, 24.74731831236749, 0.1112314201786423, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4530000.0000, 
sim time next is 4531200.0000, 
raw observation next is [1.666666666666667, 58.33333333333334, 203.8333333333333, 15.0, 22.5, 24.46741969041359, 0.05847884321870268, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5087719298245615, 0.5833333333333335, 0.6794444444444443, 0.016574585635359115, 0.375, 0.5389516408677991, 0.5194929477395676, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.969864], dtype=float32), 1.1668923]. 
=============================================
[2019-04-24 10:20:52,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8691986e-01 4.8306902e-04 3.1351630e-04 5.5343343e-09 3.8277194e-13
 9.8991315e-10 3.0994048e-12 3.0933181e-04 1.1197414e-01 5.3373213e-13
 1.2981520e-13], sum to 1.0000
[2019-04-24 10:20:52,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5878
[2019-04-24 10:20:53,020] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 19.0, 92.66666666666666, 718.3333333333334, 22.5, 27.08721890195788, 0.741701987244126, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5067600.0000, 
sim time next is 5068800.0000, 
raw observation next is [12.0, 19.0, 86.0, 665.0, 22.5, 27.23331923968852, 0.6435939481525635, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7950138504155125, 0.19, 0.2866666666666667, 0.7348066298342542, 0.375, 0.7694432699740433, 0.7145313160508545, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7338345], dtype=float32), 0.7662193]. 
=============================================
[2019-04-24 10:20:53,161] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.9292768e-01 6.3791923e-04 1.0158957e-03 6.4840657e-09 1.4797624e-12
 7.6394663e-10 3.1840003e-11 8.1173050e-05 2.0533729e-01 1.5542037e-12
 2.3813763e-13], sum to 1.0000
[2019-04-24 10:20:53,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4135
[2019-04-24 10:20:53,184] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 81.66666666666667, 0.0, 0.0, 19.0, 23.05460216272382, -0.1890372607182502, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4746000.0000, 
sim time next is 4747200.0000, 
raw observation next is [-3.0, 79.33333333333333, 0.0, 0.0, 19.0, 22.29463386105594, -0.2956298398402957, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.7933333333333333, 0.0, 0.0, 0.08333333333333333, 0.3578861550879949, 0.4014567200532348, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6341142], dtype=float32), 0.058030386]. 
=============================================
[2019-04-24 10:20:53,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:54,082] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:20:54,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:20:54,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:20:54,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run7
[2019-04-24 10:20:55,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:55,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:20:56,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:20:56,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:20:56,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run7
[2019-04-24 10:20:58,189] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:20:58,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:20:59,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:20:59,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:20:59,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run7
[2019-04-24 10:21:03,157] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.4983068e-01 1.9735300e-03 2.3900665e-02 5.8560147e-07 2.3299682e-09
 4.7870643e-08 1.2707754e-08 3.6699534e-03 4.2062446e-01 2.8671234e-09
 1.7014699e-10], sum to 1.0000
[2019-04-24 10:21:03,158] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6316
[2019-04-24 10:21:03,199] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 65.0, 174.0, 246.0, 19.0, 21.69987692221344, -0.5545602080738204, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4870800.0000, 
sim time next is 4872000.0000, 
raw observation next is [-2.666666666666667, 63.33333333333334, 196.0, 201.3333333333333, 19.0, 21.55856906744349, -0.4284537933413195, 0.0, 1.0, 55.0, 65.29566793814186], 
processed observation next is [0.0, 0.391304347826087, 0.38873499538319484, 0.6333333333333334, 0.6533333333333333, 0.2224677716390423, 0.08333333333333333, 0.29654742228695746, 0.35718206888622683, 0.0, 1.0, 0.8, 0.6529566793814187], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4147561], dtype=float32), -0.14725955]. 
=============================================
[2019-04-24 10:21:03,358] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:03,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:04,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:04,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:04,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:04,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run7
[2019-04-24 10:21:04,467] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:05,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:05,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:05,175] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run7
[2019-04-24 10:21:05,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:05,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:06,420] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:06,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:06,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:06,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run7
[2019-04-24 10:21:06,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:06,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6965621e-01 7.7667326e-04 3.3664017e-04 3.0617844e-08 7.1497916e-12
 1.2855673e-08 4.2307602e-11 1.8862932e-04 1.2904176e-01 7.0686382e-12
 1.3047936e-12], sum to 1.0000
[2019-04-24 10:21:06,670] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:06,678] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3805
[2019-04-24 10:21:06,698] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 23.0, 0.0, 0.0, 22.5, 24.46848781794363, 0.1638423605297014, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4994400.0000, 
sim time next is 4995600.0000, 
raw observation next is [6.0, 23.0, 0.0, 0.0, 22.5, 24.19146890976799, 0.1217938620491308, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.6288088642659281, 0.23, 0.0, 0.0, 0.375, 0.5159557424806659, 0.5405979540163769, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.123455], dtype=float32), 1.9457824]. 
=============================================
[2019-04-24 10:21:06,782] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:07,423] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:07,423] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:07,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run7
[2019-04-24 10:21:07,582] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:07,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:07,587] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run7
[2019-04-24 10:21:08,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:08,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:09,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:09,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:09,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:09,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:09,379] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run7
[2019-04-24 10:21:09,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:09,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:09,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:10,078] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:10,078] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:10,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run7
[2019-04-24 10:21:10,150] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.4681077e-01 4.9467757e-03 1.7502054e-03 8.5323045e-08 8.0169510e-11
 3.7082774e-08 6.2429445e-10 1.0502820e-03 3.4544179e-01 8.2845258e-11
 2.2618457e-11], sum to 1.0000
[2019-04-24 10:21:10,153] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1184
[2019-04-24 10:21:10,192] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 19.0, 22.51301885886645, -0.2654987992308569, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5016000.0000, 
sim time next is 5017200.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 19.0, 22.32071221267128, -0.3088006355707939, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.4, 0.0, 0.0, 0.08333333333333333, 0.36005935105593984, 0.39706645480973535, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0524385], dtype=float32), -0.2816102]. 
=============================================
[2019-04-24 10:21:10,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:10,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:10,557] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:10,561] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run7
[2019-04-24 10:21:10,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:10,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:11,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run7
[2019-04-24 10:21:11,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:11,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:12,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:12,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:12,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run7
[2019-04-24 10:21:12,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:12,966] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:13,395] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:13,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:13,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:13,746] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run7
[2019-04-24 10:21:13,790] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:14,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:21:14,342] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:21:14,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:14,396] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:14,400] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run7
[2019-04-24 10:21:15,050] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:21:15,050] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:21:15,054] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run7
[2019-04-24 10:21:25,912] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1812642e-01 1.4201115e-03 2.0215949e-03 6.8665024e-08 6.0191990e-12
 1.7190773e-09 8.2073848e-11 2.7388957e-04 2.7815786e-01 6.9061948e-12
 2.2199896e-12], sum to 1.0000
[2019-04-24 10:21:25,913] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0204
[2019-04-24 10:21:25,998] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 77.66666666666667, 185.0, 16.83333333333333, 22.5, 23.19307187624381, -0.3268488070010648, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 127200.0000, 
sim time next is 128400.0000, 
raw observation next is [-8.2, 69.33333333333334, 175.0, 111.3333333333333, 22.5, 22.60367177860638, -0.4137848503685316, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.23545706371191139, 0.6933333333333335, 0.5833333333333334, 0.12302025782688762, 0.375, 0.383639314883865, 0.3620717165438228, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2892439], dtype=float32), -1.4156954]. 
=============================================
[2019-04-24 10:21:27,324] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.7859868e-01 1.0074414e-03 6.0687410e-03 1.2451801e-07 1.6556199e-10
 3.1257732e-09 1.2146697e-09 2.7995417e-03 4.1152543e-01 4.1278033e-11
 1.4722600e-11], sum to 1.0000
[2019-04-24 10:21:27,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8573
[2019-04-24 10:21:27,388] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 21.59290457297584, -0.5161721442894966, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 15600.0000, 
sim time next is 16800.0000, 
raw observation next is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 21.57239284010399, -0.3761667584308395, 0.0, 1.0, 55.0, 67.70699274523987], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.29769940334199924, 0.37461108052305353, 0.0, 1.0, 0.8, 0.6770699274523987], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47967294], dtype=float32), 0.5886595]. 
=============================================
[2019-04-24 10:21:28,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9912095e-01 7.6360074e-03 7.5208056e-03 3.5599110e-06 3.9142836e-09
 4.6120695e-07 3.5045890e-08 2.1698871e-03 4.8354828e-01 4.4730322e-09
 1.5794513e-09], sum to 1.0000
[2019-04-24 10:21:28,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8781
[2019-04-24 10:21:28,249] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-11.7, 54.00000000000001, 0.0, 0.0, 19.0, 17.82065958448909, -1.438870190857857, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 429600.0000, 
sim time next is 430800.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 19.0, 18.12342627910721, -1.154845445442973, 0.0, 1.0, 55.0, 96.03087818401244], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.08333333333333333, 0.010285523258934207, 0.11505151818567565, 0.0, 1.0, 0.8, 0.9603087818401244], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17469487], dtype=float32), 0.40261132]. 
=============================================
[2019-04-24 10:21:32,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6226134e-01 5.7114451e-04 2.7808945e-03 5.2514398e-08 7.8067219e-11
 8.5834726e-09 1.3810113e-09 3.7967841e-04 4.3400687e-01 6.2183182e-11
 3.3857630e-12], sum to 1.0000
[2019-04-24 10:21:32,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1001
[2019-04-24 10:21:32,566] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 79.0, 0.0, 0.0, 19.0, 20.65582393887961, -0.8620355008803459, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 259200.0000, 
sim time next is 260400.0000, 
raw observation next is [-5.233333333333334, 75.0, 0.0, 0.0, 19.0, 19.97193813045445, -0.9558582595545481, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.31763619575253926, 0.75, 0.0, 0.0, 0.08333333333333333, 0.16432817753787088, 0.181380580148484, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04268919], dtype=float32), 1.1488484]. 
=============================================
[2019-04-24 10:21:35,641] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.0362009e-01 2.2968259e-03 3.3267480e-03 4.6658681e-07 2.7887631e-10
 2.3526042e-08 1.8261070e-09 2.0133920e-03 4.8874253e-01 5.3070220e-10
 4.5378104e-11], sum to 1.0000
[2019-04-24 10:21:35,642] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7176
[2019-04-24 10:21:35,693] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.733333333333334, 73.0, 0.0, 0.0, 19.0, 20.15452379676495, -0.9474526739074918, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 175200.0000, 
sim time next is 176400.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 19.0, 19.97282872065365, -0.7643649998825176, 0.0, 1.0, 55.0, 84.48247992977903], 
processed observation next is [1.0, 0.043478260869565216, 0.21606648199445982, 0.74, 0.0, 0.0, 0.08333333333333333, 0.16440239338780405, 0.24521166670582747, 0.0, 1.0, 0.8, 0.8448247992977903], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6947976], dtype=float32), 0.4704002]. 
=============================================
[2019-04-24 10:21:39,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.1235361e-01 2.5846956e-03 2.0803122e-03 1.3774894e-07 4.5792075e-11
 7.6030817e-09 2.2294992e-10 3.7089078e-04 1.8261029e-01 4.3561540e-11
 1.9074128e-11], sum to 1.0000
[2019-04-24 10:21:39,162] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0635
[2019-04-24 10:21:39,191] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.2, 61.0, 122.3333333333333, 0.0, 22.5, 21.34407475141472, -0.6815065689363742, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 224400.0000, 
sim time next is 225600.0000, 
raw observation next is [-3.0, 60.0, 106.8333333333333, 0.0, 22.5, 21.23086155617927, -0.6887223027919737, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3795013850415513, 0.6, 0.356111111111111, 0.0, 0.375, 0.2692384630149392, 0.2704258990693421, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.1096, 
noisyNet noise sample is [array([-1.3172204], dtype=float32), -0.32811472]. 
=============================================
[2019-04-24 10:21:41,999] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9580410e-01 2.4913992e-03 5.2674185e-03 2.0278074e-07 4.9064443e-11
 1.1386923e-08 2.9926810e-09 1.6619279e-03 4.9477485e-01 1.3709431e-10
 1.0891861e-10], sum to 1.0000
[2019-04-24 10:21:42,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9200
[2019-04-24 10:21:42,071] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 67.0, 0.0, 0.0, 19.0, 20.74729105797127, -0.7411535082108663, 0.0, 1.0, 55.0, 56.20557834695879], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 270000.0000, 
sim time next is 271200.0000, 
raw observation next is [-9.100000000000001, 68.0, 0.0, 0.0, 19.0, 20.84649980407936, -0.7319295462073939, 0.0, 1.0, 55.0, 55.25322107019806], 
processed observation next is [1.0, 0.13043478260869565, 0.21052631578947364, 0.68, 0.0, 0.0, 0.08333333333333333, 0.2372083170066134, 0.2560234845975354, 0.0, 1.0, 0.8, 0.5525322107019806], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.065861], dtype=float32), -0.34859994]. 
=============================================
[2019-04-24 10:21:44,195] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.1834958e-01 3.6653769e-03 8.5857604e-03 2.1785154e-06 4.8277093e-10
 1.0537308e-07 7.8271425e-09 1.0022328e-03 2.6839486e-01 9.1247432e-10
 2.6357116e-10], sum to 1.0000
[2019-04-24 10:21:44,197] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2438
[2019-04-24 10:21:44,327] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.2, 43.66666666666667, 0.0, 0.0, 19.0, 21.08297374718473, -0.7897653840637463, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 418800.0000, 
sim time next is 420000.0000, 
raw observation next is [-10.4, 45.33333333333334, 0.0, 0.0, 19.0, 20.41984746501131, -0.9367336757001352, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.1745152354570637, 0.4533333333333334, 0.0, 0.0, 0.08333333333333333, 0.20165395541760903, 0.18775544143328826, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17662576], dtype=float32), 0.0722072]. 
=============================================
[2019-04-24 10:21:44,339] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[50.46239 ]
 [51.658203]
 [51.16124 ]
 [51.954144]
 [52.747204]
 [52.949028]
 [53.23681 ]
 [53.324825]
 [52.518597]
 [51.400677]
 [52.00907 ]
 [52.386375]
 [51.473003]
 [52.21662 ]
 [50.934364]
 [51.799633]
 [52.554474]
 [53.435097]
 [54.409107]
 [55.289078]
 [55.750988]
 [56.342365]
 [56.78991 ]
 [56.42129 ]
 [56.984833]], R is [[49.99889755]
 [50.498909  ]
 [49.99391937]
 [49.49398041]
 [48.99904251]
 [48.50905228]
 [48.06278992]
 [48.58215714]
 [48.09633636]
 [47.6153717 ]
 [47.6373291 ]
 [48.16095734]
 [47.67934799]
 [48.20255661]
 [47.72053146]
 [47.52832031]
 [47.05303574]
 [46.58250427]
 [46.18628693]
 [45.811203  ]
 [45.70344543]
 [46.10651779]
 [46.63875961]
 [46.17237091]
 [46.65417862]].
[2019-04-24 10:21:47,631] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.47203922e-01 2.99248332e-03 9.07329097e-03 8.01914041e-07
 1.21332822e-09 3.24492504e-08 1.38884815e-08 7.10284163e-04
 3.40019107e-01 1.25659672e-09 2.61733329e-10], sum to 1.0000
[2019-04-24 10:21:47,671] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6540
[2019-04-24 10:21:47,746] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-1.9, 87.0, 0.0, 0.0, 19.0, 20.50302607097934, -0.8583306798238305, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 580800.0000, 
sim time next is 582000.0000, 
raw observation next is [-2.1, 87.0, 0.0, 0.0, 19.0, 20.2630570769694, -0.7694175595717941, 0.0, 1.0, 25.0, 59.38200979791734], 
processed observation next is [0.0, 0.7391304347826086, 0.404432132963989, 0.87, 0.0, 0.0, 0.08333333333333333, 0.18858808974744998, 0.2435274801427353, 0.0, 1.0, 0.2, 0.5938200979791735], 
reward next is 0.2062, 
noisyNet noise sample is [array([2.3582945], dtype=float32), -0.03155733]. 
=============================================
[2019-04-24 10:21:52,853] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.9953293e-01 5.4219482e-03 4.1778744e-03 4.4293920e-06 3.7030787e-09
 4.6466906e-07 2.4455895e-08 1.2120330e-03 2.8965026e-01 5.4446212e-09
 1.1937455e-09], sum to 1.0000
[2019-04-24 10:21:52,858] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3202
[2019-04-24 10:21:52,904] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.4, 45.33333333333334, 0.0, 0.0, 19.0, 18.86133852601203, -1.203197217992999, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 420000.0000, 
sim time next is 421200.0000, 
raw observation next is [-10.6, 47.0, 0.0, 0.0, 19.0, 18.63581841731033, -1.252005009300657, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.1689750692520776, 0.47, 0.0, 0.0, 0.08333333333333333, 0.05298486810919408, 0.08266499689978102, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.4695, 
noisyNet noise sample is [array([0.42153102], dtype=float32), 0.21696174]. 
=============================================
[2019-04-24 10:21:53,172] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.0155602e-01 6.6320589e-03 1.0883539e-02 2.4295412e-06 6.5782131e-09
 3.7247420e-07 4.7611035e-08 1.7185805e-03 5.7920706e-01 7.3659847e-09
 7.9820744e-10], sum to 1.0000
[2019-04-24 10:21:53,193] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9904
[2019-04-24 10:21:53,256] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-11.7, 54.0, 0.0, 0.0, 19.0, 18.20868546882557, -1.3680335242824, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 428400.0000, 
sim time next is 429600.0000, 
raw observation next is [-11.7, 54.00000000000001, 0.0, 0.0, 19.0, 18.4677185942036, -1.102728201805433, 0.0, 1.0, 55.0, 95.20354312092218], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.08333333333333333, 0.03897654951696664, 0.13242393273152234, 0.0, 1.0, 0.8, 0.9520354312092217], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42153102], dtype=float32), 0.21696174]. 
=============================================
[2019-04-24 10:21:56,260] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.4247018e-01 3.3057528e-03 1.0784709e-02 1.7041656e-06 4.2989008e-09
 1.3434949e-07 4.4686516e-08 3.4723806e-03 3.3996511e-01 6.8193109e-09
 1.2473298e-09], sum to 1.0000
[2019-04-24 10:21:56,260] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2241
[2019-04-24 10:21:56,279] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 19.0, 19.36791675097391, -1.113793438840386, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 622800.0000, 
sim time next is 624000.0000, 
raw observation next is [-4.5, 67.0, 0.0, 0.0, 19.0, 18.81025506609569, -1.194218733943596, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.3379501385041552, 0.67, 0.0, 0.0, 0.08333333333333333, 0.06752125550797405, 0.10192708868546803, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.8560, 
noisyNet noise sample is [array([0.03698568], dtype=float32), -1.2146907]. 
=============================================
[2019-04-24 10:21:58,581] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0348443e-01 6.0352501e-03 2.2023174e-03 7.8646657e-08 2.0454909e-11
 6.3420984e-09 4.4731627e-10 9.1804366e-04 4.8735994e-01 1.0854759e-11
 1.2008594e-11], sum to 1.0000
[2019-04-24 10:21:58,582] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5167
[2019-04-24 10:21:58,755] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.7, 75.0, 16.0, 0.0, 22.5, 21.48158135079428, -0.609154893062199, 1.0, 1.0, 55.0, 63.5583118462926], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 806400.0000, 
sim time next is 807600.0000, 
raw observation next is [-6.533333333333334, 75.0, 26.66666666666667, 0.0, 22.5, 21.84609275580426, -0.5037998525240122, 1.0, 1.0, 55.0, 61.813139775409724], 
processed observation next is [1.0, 0.34782608695652173, 0.28162511542012925, 0.75, 0.0888888888888889, 0.0, 0.375, 0.32050772965035507, 0.33206671582532926, 1.0, 1.0, 0.8, 0.6181313977540972], 
reward next is 0.0190, 
noisyNet noise sample is [array([-0.10003784], dtype=float32), 0.7021926]. 
=============================================
[2019-04-24 10:22:04,188] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5789584e-01 7.5927316e-03 1.8990882e-02 2.6856782e-07 3.3935729e-10
 2.0377843e-08 4.1244439e-09 1.5309980e-03 4.1398928e-01 2.4158495e-10
 3.2729725e-11], sum to 1.0000
[2019-04-24 10:22:04,199] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1261
[2019-04-24 10:22:04,213] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.100000000000001, 69.66666666666667, 0.0, 0.0, 19.0, 19.56661758961807, -1.09638138161494, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 800400.0000, 
sim time next is 801600.0000, 
raw observation next is [-6.9, 68.33333333333333, 0.0, 0.0, 19.0, 19.03852948474363, -1.170082743881548, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.27146814404432135, 0.6833333333333332, 0.0, 0.0, 0.08333333333333333, 0.08654412372863589, 0.10997241870615067, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.002804], dtype=float32), 0.27000776]. 
=============================================
[2019-04-24 10:22:05,723] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0669426e-01 7.5000757e-04 1.1831091e-03 1.6853747e-08 1.5910033e-12
 2.1018067e-09 3.0666237e-11 3.9600045e-04 4.9097660e-01 1.1552002e-12
 2.1212547e-13], sum to 1.0000
[2019-04-24 10:22:05,724] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7258
[2019-04-24 10:22:05,786] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.233333333333333, 84.33333333333334, 0.0, 0.0, 19.0, 22.23713061140761, -0.2210446283841764, 0.0, 1.0, 55.0, 50.282314792883895], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 956400.0000, 
sim time next is 957600.0000, 
raw observation next is [6.6, 82.0, 0.0, 0.0, 19.0, 22.97316324259155, -0.1452199609914095, 0.0, 1.0, 55.0, 48.2867725589329], 
processed observation next is [1.0, 0.08695652173913043, 0.6454293628808865, 0.82, 0.0, 0.0, 0.08333333333333333, 0.4144302702159625, 0.4515933463361968, 0.0, 1.0, 0.8, 0.482867725589329], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02964808], dtype=float32), 1.2739096]. 
=============================================
[2019-04-24 10:22:08,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8949469e-01 2.6913895e-04 4.4122225e-04 4.6639252e-09 4.7451474e-13
 7.3593154e-10 3.1219808e-12 1.1290022e-04 2.0968202e-01 2.4307368e-13
 6.8054225e-14], sum to 1.0000
[2019-04-24 10:22:08,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9064
[2019-04-24 10:22:08,293] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.1, 92.0, 66.5, 0.0, 22.5, 23.83234146056161, -0.02496309755433638, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1348800.0000, 
sim time next is 1350000.0000, 
raw observation next is [1.1, 92.0, 57.5, 0.0, 22.5, 23.50645457583399, 0.261464030097287, 1.0, 1.0, 55.0, 83.65121334428596], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19166666666666668, 0.0, 0.375, 0.45887121465283237, 0.5871546766990957, 1.0, 1.0, 0.8, 0.8365121334428597], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41024512], dtype=float32), -0.1779778]. 
=============================================
[2019-04-24 10:22:08,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.48435 ]
 [72.094444]
 [72.32551 ]
 [72.51045 ]
 [72.70005 ]
 [72.9259  ]
 [73.12234 ]
 [73.494   ]
 [73.62762 ]
 [73.91782 ]
 [73.91344 ]
 [72.65858 ]
 [72.903145]
 [72.705505]
 [73.17726 ]
 [73.96757 ]
 [74.73669 ]
 [74.02971 ]
 [74.36184 ]
 [73.56277 ]
 [73.569046]
 [72.51287 ]
 [71.1311  ]
 [70.98979 ]
 [71.824715]], R is [[71.78788757]
 [72.07000732]
 [72.3493042 ]
 [72.62580872]
 [72.89955139]
 [73.17055511]
 [73.4388504 ]
 [73.70446014]
 [73.96741486]
 [74.22774506]
 [74.485466  ]
 [73.74061584]
 [74.00321198]
 [74.26318359]
 [74.52055359]
 [74.77535248]
 [75.02760315]
 [74.27732849]
 [74.53455353]
 [73.78920746]
 [74.05131531]
 [73.31080627]
 [72.57769775]
 [72.85192108]
 [73.12340546]].
[2019-04-24 10:22:08,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1538391e-01 3.6363045e-04 2.6118470e-04 4.7202309e-09 7.8424691e-13
 2.0871710e-10 3.2217263e-12 7.5271426e-05 1.8391606e-01 4.8146047e-13
 1.0815472e-13], sum to 1.0000
[2019-04-24 10:22:08,857] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1392
[2019-04-24 10:22:08,865] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 22.5, 22.25037728143523, -0.1996320696977288, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1363200.0000, 
sim time next is 1364400.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 22.03211109307162, -0.2259595734740891, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.33600925775596835, 0.42468014217530364, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9558034], dtype=float32), 1.5939591]. 
=============================================
[2019-04-24 10:22:12,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6090981e-01 3.7245962e-03 7.6115126e-04 4.3588333e-08 7.8369776e-12
 1.5357569e-09 1.7924938e-10 1.4231363e-03 4.3318129e-01 4.0320299e-12
 2.3258238e-12], sum to 1.0000
[2019-04-24 10:22:12,459] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4848
[2019-04-24 10:22:12,467] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.699999999999999, 82.0, 0.0, 0.0, 19.0, 20.30038504496535, -0.7697735641159991, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 963600.0000, 
sim time next is 964800.0000, 
raw observation next is [7.7, 83.0, 0.0, 0.0, 19.0, 20.2938965835558, -0.7776772015994137, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.6759002770083103, 0.83, 0.0, 0.0, 0.08333333333333333, 0.19115804862964994, 0.24077426613352879, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06648272], dtype=float32), 0.15888555]. 
=============================================
[2019-04-24 10:22:13,384] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.8016084e-01 2.9969044e-04 8.0729969e-04 2.1348319e-08 2.6976389e-13
 2.6270425e-10 1.9497980e-12 1.9953855e-04 2.1853259e-01 4.2118061e-13
 3.6065619e-14], sum to 1.0000
[2019-04-24 10:22:13,405] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3821
[2019-04-24 10:22:13,431] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.8, 93.0, 95.0, 0.0, 22.5, 22.9786120840925, -0.2774714131241553, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 913200.0000, 
sim time next is 914400.0000, 
raw observation next is [3.8, 93.0, 93.0, 0.0, 22.5, 22.88160810645385, -0.2815371409774443, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5678670360110805, 0.93, 0.31, 0.0, 0.375, 0.40680067553782084, 0.4061542863408519, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47135302], dtype=float32), -0.84995264]. 
=============================================
[2019-04-24 10:22:18,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1088463e-01 2.8630183e-04 1.5800010e-04 2.6681617e-09 3.9770562e-14
 1.3488093e-10 2.6086961e-13 2.4274833e-04 2.8842837e-01 1.4259319e-13
 9.8090617e-15], sum to 1.0000
[2019-04-24 10:22:18,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1079
[2019-04-24 10:22:18,133] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.63333333333333, 78.66666666666667, 0.0, 0.0, 19.0, 25.26215410667262, 0.3705151864302562, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1056000.0000, 
sim time next is 1057200.0000, 
raw observation next is [13.46666666666667, 79.33333333333333, 0.0, 0.0, 19.0, 24.98669119972286, 0.2984323639191696, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.8356417359187445, 0.7933333333333333, 0.0, 0.0, 0.08333333333333333, 0.5822242666435716, 0.5994774546397231, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.53997535], dtype=float32), 0.52365786]. 
=============================================
[2019-04-24 10:22:23,132] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.7732289e-01 1.0333994e-03 2.6479483e-04 5.5882192e-09 5.5343127e-13
 2.7059519e-10 1.8083256e-12 1.5732930e-04 2.2122160e-01 4.1565438e-13
 3.2103220e-14], sum to 1.0000
[2019-04-24 10:22:23,134] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2273
[2019-04-24 10:22:23,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.06230581e-01 1.12724036e-03 1.26455550e-03 1.13551195e-08
 2.60751490e-12 1.96893696e-10 2.66388387e-11 6.65415020e-04
 2.90712327e-01 1.74032869e-12 3.54478762e-13], sum to 1.0000
[2019-04-24 10:22:23,155] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.4, 61.0, 0.0, 0.0, 22.5, 24.21858254720955, 0.1906267176982903, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1537200.0000, 
sim time next is 1538400.0000, 
raw observation next is [8.666666666666668, 65.0, 0.0, 0.0, 22.5, 24.0500827832347, 0.1621481721648426, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7026777469990768, 0.65, 0.0, 0.0, 0.375, 0.5041735652695584, 0.5540493907216142, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9753599], dtype=float32), 0.8599382]. 
=============================================
[2019-04-24 10:22:23,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1777
[2019-04-24 10:22:23,191] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 19.0, 22.64798554247614, -0.170921984684857, 0.0, 1.0, 55.0, 48.18807575443952], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1407600.0000, 
sim time next is 1408800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 22.5, 22.65570174030622, -0.2966259889298506, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.44598337950138506, 1.0, 0.0, 0.0, 0.375, 0.3879751450255184, 0.40112467035671645, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07389288], dtype=float32), -1.0380656]. 
=============================================
[2019-04-24 10:22:24,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1537794e-01 2.1451902e-04 4.5692510e-04 1.6505149e-08 2.8942899e-13
 1.4855986e-10 2.9498680e-12 9.5991229e-05 4.8385459e-01 2.9048530e-13
 1.1039320e-13], sum to 1.0000
[2019-04-24 10:22:24,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1773
[2019-04-24 10:22:24,178] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 23.29432723036643, -0.05495220501401399, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1378800.0000, 
sim time next is 1380000.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 22.75012552865808, -0.1745922168031585, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.3958437940548401, 0.44180259439894715, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.22003219], dtype=float32), -0.49540412]. 
=============================================
[2019-04-24 10:22:24,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.375145]
 [73.8903  ]
 [73.525665]
 [73.88154 ]
 [72.2228  ]
 [71.18482 ]
 [71.845406]
 [72.25164 ]
 [71.46692 ]
 [71.390686]
 [70.39087 ]
 [69.567726]
 [70.54504 ]
 [70.992584]
 [71.61564 ]
 [71.83971 ]
 [72.31363 ]
 [72.72272 ]
 [73.11232 ]
 [73.72375 ]
 [73.98571 ]
 [72.97484 ]
 [73.18844 ]
 [73.58039 ]
 [72.613365]], R is [[73.25427246]
 [73.52172852]
 [72.78651428]
 [73.05864716]
 [72.32806396]
 [71.6047821 ]
 [71.88873291]
 [72.16984558]
 [71.44815063]
 [70.7336731 ]
 [70.02633667]
 [69.32607269]
 [69.6328125 ]
 [69.93648529]
 [70.23712158]
 [70.53475189]
 [70.82940674]
 [71.12111664]
 [71.40990448]
 [71.69580841]
 [71.97885132]
 [71.25906372]
 [71.54647064]
 [71.83100891]
 [71.11270142]].
[2019-04-24 10:22:30,381] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9015871e-01 7.3162909e-04 3.8781911e-04 6.6595569e-09 7.3622109e-13
 1.0838963e-09 2.1892935e-12 1.5622488e-04 1.0856563e-01 7.8985446e-13
 2.0170668e-13], sum to 1.0000
[2019-04-24 10:22:30,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0867
[2019-04-24 10:22:30,395] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 58.66666666666667, 0.0, 0.0, 22.5, 24.281001067632, 0.1097766680955886, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1531200.0000, 
sim time next is 1532400.0000, 
raw observation next is [10.16666666666667, 59.33333333333334, 0.0, 0.0, 22.5, 24.322193392003, 0.1393117368116639, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7442289935364729, 0.5933333333333334, 0.0, 0.0, 0.375, 0.5268494493335835, 0.546437245603888, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16226579], dtype=float32), 0.8286591]. 
=============================================
[2019-04-24 10:22:32,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6038512e-01 1.6972527e-03 1.0136006e-03 6.3058536e-08 3.3635703e-12
 2.4161027e-09 2.7802302e-11 1.4160534e-04 1.3676237e-01 8.3795583e-12
 4.0167388e-12], sum to 1.0000
[2019-04-24 10:22:32,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9848
[2019-04-24 10:22:32,296] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 65.0, 229.5, 7.0, 22.5, 22.07156918890268, -0.5984430162578981, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1944000.0000, 
sim time next is 1945200.0000, 
raw observation next is [-4.633333333333334, 65.0, 227.8333333333333, 5.0, 22.5, 22.34533947501716, -0.3973314698856127, 1.0, 1.0, 55.0, 79.53430469898298], 
processed observation next is [1.0, 0.5217391304347826, 0.3342566943674977, 0.65, 0.7594444444444443, 0.0055248618784530384, 0.375, 0.36211162291809657, 0.36755617670479573, 1.0, 1.0, 0.8, 0.7953430469898298], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5691352], dtype=float32), 2.2447205]. 
=============================================
[2019-04-24 10:22:33,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.24124038e-01 5.64558315e-04 4.59352013e-04 1.47261305e-08
 4.44751874e-13 2.55487131e-10 4.58194897e-12 9.88000393e-05
 1.74753219e-01 3.69471164e-13 5.84367556e-14], sum to 1.0000
[2019-04-24 10:22:33,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3109
[2019-04-24 10:22:33,326] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 15.5, 0.0, 22.5, 23.89885441997146, 0.2397988411947825, 1.0, 1.0, 55.0, 84.5430087032043], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1702800.0000, 
sim time next is 1704000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 24.50731981344138, 0.1147994558344943, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.542276651120115, 0.5382664852781648, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35847056], dtype=float32), 2.148974]. 
=============================================
[2019-04-24 10:22:33,554] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.3687872e-01 4.5544325e-04 1.3264448e-03 1.5631281e-08 2.5424327e-13
 5.0718385e-10 2.2882616e-12 6.9761569e-05 1.6126959e-01 4.5838355e-13
 7.8166010e-14], sum to 1.0000
[2019-04-24 10:22:33,556] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0363
[2019-04-24 10:22:33,570] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.06666666666667, 58.66666666666667, 0.0, 0.0, 22.5, 24.94900748588652, 0.2727439811021631, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1618800.0000, 
sim time next is 1620000.0000, 
raw observation next is [10.5, 61.0, 0.0, 0.0, 22.5, 24.58058440043273, 0.2228375731876001, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.7534626038781165, 0.61, 0.0, 0.0, 0.375, 0.5483820333693942, 0.5742791910625334, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3650838], dtype=float32), 0.49173447]. 
=============================================
[2019-04-24 10:22:33,615] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[71.391624]
 [71.61469 ]
 [70.43287 ]
 [70.5439  ]
 [70.647446]
 [70.79161 ]
 [70.88466 ]
 [71.04196 ]
 [71.17946 ]
 [71.21142 ]
 [71.23959 ]
 [71.27306 ]
 [71.272285]
 [71.242485]
 [71.19621 ]
 [71.185455]
 [71.21399 ]
 [71.17029 ]
 [70.9188  ]
 [70.517685]
 [70.12718 ]
 [69.78077 ]
 [69.41886 ]
 [69.45923 ]
 [69.81025 ]], R is [[71.47317505]
 [71.75844574]
 [71.04086304]
 [71.33045197]
 [71.61714935]
 [71.90097809]
 [72.18196869]
 [72.46015167]
 [72.73554993]
 [73.00819397]
 [73.27811432]
 [73.54533386]
 [73.80988312]
 [74.07178497]
 [74.33106995]
 [74.58776093]
 [74.8418808 ]
 [75.09346008]
 [75.3425293 ]
 [75.5891037 ]
 [75.83321381]
 [76.07488251]
 [76.31413269]
 [76.55099487]
 [76.78548431]].
[2019-04-24 10:22:34,332] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5001494e-01 1.8380492e-04 5.8456947e-04 6.6674527e-10 8.4452329e-14
 4.4803970e-11 9.6556790e-13 1.5018041e-04 3.4906656e-01 3.8602903e-14
 3.0565364e-15], sum to 1.0000
[2019-04-24 10:22:34,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8655
[2019-04-24 10:22:34,364] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.2, 86.0, 0.0, 0.0, 19.0, 25.11935294760436, 0.4412365833455119, 0.0, 1.0, 55.0, 46.20535987372301], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1641600.0000, 
sim time next is 1642800.0000, 
raw observation next is [7.0, 88.33333333333334, 0.0, 0.0, 19.0, 25.2252943454636, 0.4648883313519424, 0.0, 1.0, 55.0, 45.43414924399835], 
processed observation next is [1.0, 0.0, 0.6565096952908588, 0.8833333333333334, 0.0, 0.0, 0.08333333333333333, 0.6021078621219665, 0.6549627771173142, 0.0, 1.0, 0.8, 0.4543414924399835], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8252562], dtype=float32), 0.9146572]. 
=============================================
[2019-04-24 10:22:40,199] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0494748e-01 1.8227175e-03 1.1319377e-02 2.4935065e-07 2.2088809e-10
 4.2097970e-09 2.2210747e-09 8.4164890e-04 4.8106849e-01 4.9054677e-11
 2.1828374e-11], sum to 1.0000
[2019-04-24 10:22:40,233] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3319
[2019-04-24 10:22:40,257] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 22.5, 19.99987434622256, -1.084796266848915, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2013600.0000, 
sim time next is 2014800.0000, 
raw observation next is [-6.199999999999999, 87.0, 0.0, 0.0, 22.5, 19.15710634526296, -1.222790124590508, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.2908587257617729, 0.87, 0.0, 0.0, 0.375, 0.09642552877191335, 0.09240329180316402, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19872555], dtype=float32), -0.18941182]. 
=============================================
[2019-04-24 10:22:41,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2704890e-01 4.4141817e-04 1.2107553e-03 5.3766119e-08 2.4947449e-12
 1.8131431e-09 2.7314061e-11 3.4315267e-04 1.7095578e-01 3.2875595e-12
 2.6871816e-12], sum to 1.0000
[2019-04-24 10:22:41,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1227
[2019-04-24 10:22:41,929] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 66.66666666666666, 145.0, 0.0, 22.5, 22.65466256666253, -0.4126432045828627, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2122800.0000, 
sim time next is 2124000.0000, 
raw observation next is [-5.6, 68.0, 137.0, 0.0, 22.5, 22.50849860616633, -0.4411924519463243, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.30747922437673136, 0.68, 0.45666666666666667, 0.0, 0.375, 0.37570821718052755, 0.3529358493512252, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7019779], dtype=float32), -0.26338807]. 
=============================================
[2019-04-24 10:22:42,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6516197e-01 1.7950271e-03 8.6074776e-04 9.1255927e-08 2.7877249e-12
 3.6043435e-09 9.4586068e-11 3.5602279e-04 3.3182618e-01 9.1036432e-12
 1.5940712e-11], sum to 1.0000
[2019-04-24 10:22:42,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6438
[2019-04-24 10:22:42,870] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 79.0, 128.0, 392.5, 22.5, 22.56716783256285, -0.556890969952342, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1936800.0000, 
sim time next is 1938000.0000, 
raw observation next is [-6.733333333333333, 77.66666666666667, 156.6666666666667, 288.1666666666667, 22.5, 22.14068524122412, -0.6360030528518593, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2760849492151431, 0.7766666666666667, 0.5222222222222224, 0.3184162062615101, 0.375, 0.3450571034353433, 0.28799898238271354, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.5376, 
noisyNet noise sample is [array([-0.26247582], dtype=float32), -0.67033726]. 
=============================================
[2019-04-24 10:22:43,956] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.4184520e-01 1.7705325e-03 3.7665477e-03 2.0716375e-07 1.3219673e-10
 1.7596612e-08 4.4631867e-09 9.5146365e-04 4.5166600e-01 1.8692718e-10
 6.1453155e-11], sum to 1.0000
[2019-04-24 10:22:43,957] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4670
[2019-04-24 10:22:43,965] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 19.15466465339037, -1.123336263550368, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1990800.0000, 
sim time next is 1992000.0000, 
raw observation next is [-6.0, 85.66666666666667, 0.0, 0.0, 19.0, 18.94895751513549, -1.160722494456765, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.8566666666666667, 0.0, 0.0, 0.08333333333333333, 0.07907979292795748, 0.11309250184774504, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9896, 
noisyNet noise sample is [array([-1.2419385], dtype=float32), -0.4398149]. 
=============================================
[2019-04-24 10:22:56,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2364583e-01 1.4945007e-02 2.5662675e-02 1.2207544e-05 1.5640756e-08
 1.6105854e-06 4.2283099e-07 4.2834231e-03 6.3144869e-01 4.5816417e-08
 2.1617101e-08], sum to 1.0000
[2019-04-24 10:22:56,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0087
[2019-04-24 10:22:56,476] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.2, 59.0, 0.0, 0.0, 19.0, 19.51385702653828, -0.9623258789758165, 0.0, 1.0, 55.0, 55.52408800649334], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2432400.0000, 
sim time next is 2433600.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 19.0, 19.56904385375101, -1.121991967783467, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2299168975069252, 0.61, 0.0, 0.0, 0.08333333333333333, 0.1307536544792507, 0.12600267740551097, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5306972], dtype=float32), 0.1127192]. 
=============================================
[2019-04-24 10:22:58,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2899574e-01 7.5252069e-04 4.2917591e-04 7.3421198e-08 3.0607749e-11
 7.0475643e-09 4.1512793e-11 1.2237464e-04 2.6970014e-01 1.2271159e-11
 9.4063223e-13], sum to 1.0000
[2019-04-24 10:22:58,237] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1501
[2019-04-24 10:22:58,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 22.5, 22.34902667998049, -0.2866341837090415, 1.0, 1.0, 55.0, 75.49625252917355], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2224800.0000, 
sim time next is 2226000.0000, 
raw observation next is [-4.533333333333333, 68.66666666666667, 0.0, 0.0, 22.5, 22.75480906505856, -0.4104513626454873, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3370267774699908, 0.6866666666666668, 0.0, 0.0, 0.375, 0.3962340887548799, 0.3631828791181709, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6376684], dtype=float32), -1.07491]. 
=============================================
[2019-04-24 10:23:02,278] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.30548060e-01 6.27946865e-04 2.26883008e-03 9.56488790e-08
 1.10882475e-11 8.18742762e-09 3.15679816e-10 2.27065146e-04
 3.66328001e-01 2.45347492e-11 5.34573080e-12], sum to 1.0000
[2019-04-24 10:23:02,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0031
[2019-04-24 10:23:02,305] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 63.0, 0.0, 0.0, 19.0, 22.10981223026022, -0.4980165623157241, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2331600.0000, 
sim time next is 2332800.0000, 
raw observation next is [-2.3, 65.0, 0.0, 0.0, 19.0, 21.55231661883752, -0.593306913301068, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.3988919667590028, 0.65, 0.0, 0.0, 0.08333333333333333, 0.2960263849031266, 0.302231028899644, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.56816185], dtype=float32), 0.1856298]. 
=============================================
[2019-04-24 10:23:02,572] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3622616e-01 5.6826961e-03 2.3558750e-03 1.2642993e-06 3.8926875e-09
 2.5724236e-07 5.0661900e-08 3.3967996e-03 5.5233681e-01 2.5836002e-09
 1.2635536e-09], sum to 1.0000
[2019-04-24 10:23:02,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1712
[2019-04-24 10:23:02,615] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 19.0, 21.42876060105305, -0.5132259682129052, 0.0, 1.0, 55.0, 51.91796260371805], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2342400.0000, 
sim time next is 2343600.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 19.0, 21.48790790003345, -0.656783611031157, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3988919667590028, 0.62, 0.0, 0.0, 0.08333333333333333, 0.290658991669454, 0.281072129656281, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4250453], dtype=float32), 1.1065307]. 
=============================================
[2019-04-24 10:23:04,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4587611e-01 3.6822271e-03 2.5173835e-03 6.9384718e-08 1.7157558e-11
 3.1566523e-09 3.4571032e-10 3.6307427e-04 3.4756115e-01 1.1926863e-11
 1.0412621e-11], sum to 1.0000
[2019-04-24 10:23:04,891] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3764
[2019-04-24 10:23:04,931] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 23.08566578104073, -0.3341910513228314, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2769600.0000, 
sim time next is 2770800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 22.15618255180095, -0.4834752725064597, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.3463485459834124, 0.3388415758311801, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.51082], dtype=float32), 2.292106]. 
=============================================
[2019-04-24 10:23:04,942] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.7397175e-01 3.8788249e-03 3.6881408e-03 1.8956398e-07 4.4840930e-11
 5.1166584e-08 7.9350065e-10 7.4522593e-04 5.1771581e-01 1.8556720e-10
 1.7639923e-11], sum to 1.0000
[2019-04-24 10:23:04,942] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3147
[2019-04-24 10:23:04,977] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 64.0, 0.0, 0.0, 19.0, 21.71782146412674, -0.4598934070814614, 0.0, 1.0, 55.0, 49.77677914050568], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2334000.0000, 
sim time next is 2335200.0000, 
raw observation next is [-2.3, 63.0, 0.0, 0.0, 19.0, 21.72035672252415, -0.6053485514767317, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.3988919667590028, 0.63, 0.0, 0.0, 0.08333333333333333, 0.31002972687701263, 0.2982171495077561, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28987026], dtype=float32), -0.02230886]. 
=============================================
[2019-04-24 10:23:22,196] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6566792e-01 7.9175684e-04 4.2857358e-04 4.8999485e-08 1.4844936e-12
 9.9379838e-09 3.5145834e-11 2.5851431e-04 2.3285326e-01 6.9518748e-12
 2.5833177e-12], sum to 1.0000
[2019-04-24 10:23:22,208] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8070
[2019-04-24 10:23:22,290] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.333333333333333, 51.33333333333334, 11.5, 119.8333333333333, 22.5, 23.20318124623041, -0.07506500454865404, 1.0, 1.0, 55.0, 101.98921969080877], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2740800.0000, 
sim time next is 2742000.0000, 
raw observation next is [-3.666666666666667, 52.66666666666667, 0.0, 0.0, 22.5, 23.72038074293055, 0.05055595956304094, 1.0, 1.0, 55.0, 66.26371510347388], 
processed observation next is [1.0, 0.7391304347826086, 0.3610341643582641, 0.5266666666666667, 0.0, 0.0, 0.375, 0.4766983952442126, 0.5168519865210136, 1.0, 1.0, 0.8, 0.6626371510347389], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21428475], dtype=float32), 1.1914766]. 
=============================================
[2019-04-24 10:23:26,960] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.8621122e-01 3.6092221e-03 4.5278510e-03 2.6682122e-07 4.7471965e-10
 2.3278142e-08 1.2695514e-08 1.3682161e-03 6.0428315e-01 1.3484766e-09
 7.2580303e-11], sum to 1.0000
[2019-04-24 10:23:26,969] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9372
[2019-04-24 10:23:27,019] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.52547855974466, -0.6159621319377664, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2944800.0000, 
sim time next is 2946000.0000, 
raw observation next is [-2.333333333333333, 84.66666666666667, 0.0, 0.0, 19.0, 21.18185543760062, -0.5002227755088275, 0.0, 1.0, 55.0, 73.69476186841885], 
processed observation next is [0.0, 0.08695652173913043, 0.3979686057248385, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.2651546198000518, 0.3332590748303908, 0.0, 1.0, 0.8, 0.7369476186841886], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24081865], dtype=float32), -1.4844561]. 
=============================================
[2019-04-24 10:23:33,293] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6081140e-01 2.0880981e-03 9.6177766e-03 1.2150664e-06 8.5572243e-09
 4.5492305e-07 6.7621890e-08 1.6145514e-03 4.2586637e-01 1.2457600e-08
 7.1636114e-10], sum to 1.0000
[2019-04-24 10:23:33,294] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6543
[2019-04-24 10:23:33,345] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.3333333333333334, 61.33333333333334, 48.66666666666666, 419.6666666666667, 19.0, 21.58135147467938, -0.5951415918283721, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3084000.0000, 
sim time next is 3085200.0000, 
raw observation next is [0.0, 72.0, 32.0, 287.0, 19.0, 21.40464519959315, -0.4525891557745281, 0.0, 1.0, 55.0, 69.15808608339297], 
processed observation next is [0.0, 0.7391304347826086, 0.46260387811634357, 0.72, 0.10666666666666667, 0.31712707182320443, 0.08333333333333333, 0.28372043329942925, 0.3491369480751573, 0.0, 1.0, 0.8, 0.6915808608339298], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2584127], dtype=float32), 1.5485747]. 
=============================================
[2019-04-24 10:23:43,397] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-24 10:23:43,398] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:23:43,400] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:23:43,419] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:23:43,420] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:23:43,425] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run10
[2019-04-24 10:23:43,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run10
[2019-04-24 10:23:43,429] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:23:43,488] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:23:43,490] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run10
[2019-04-24 10:24:03,979] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.2196843], dtype=float32), 0.31712124]
[2019-04-24 10:24:03,979] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [-8.9, 77.0, 0.0, 0.0, 19.0, 19.93605173691983, -1.020772568818998, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:24:03,979] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:24:03,981] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [4.5970663e-01 5.7460750e-03 5.8751907e-03 2.8620084e-06 3.2402558e-09
 5.0123839e-07 4.2021959e-08 2.0917815e-03 5.2657694e-01 3.3922245e-09
 1.2984089e-09], sampled 0.3393268050905044
[2019-04-24 10:25:26,145] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.2196843], dtype=float32), 0.31712124]
[2019-04-24 10:25:26,146] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-12.89494169666667, 77.52390657000001, 0.0, 0.0, 19.0, 20.81142245604838, -0.6532672369789169, 0.0, 1.0, 55.0, 53.43567286779813]
[2019-04-24 10:25:26,147] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:25:26,148] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [5.9475756e-01 3.4047544e-03 8.1200274e-03 1.3843844e-06 4.4967572e-09
 1.4353216e-07 4.4944105e-08 4.9572983e-03 3.8875881e-01 3.5356433e-09
 9.1717001e-10], sampled 0.4970843150565858
[2019-04-24 10:25:40,615] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.2196843], dtype=float32), 0.31712124]
[2019-04-24 10:25:40,615] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [1.0, 86.0, 0.0, 0.0, 19.0, 22.0459620860409, -0.3464296465051445, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:25:40,615] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:25:40,616] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [5.6816995e-01 1.0270616e-03 4.0489538e-03 9.2875894e-08 4.9582033e-11
 8.4341805e-09 8.1087786e-10 4.3923844e-04 4.2631465e-01 8.6502708e-11
 5.0273843e-12], sampled 0.7735255736513315
[2019-04-24 10:25:56,546] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2930.1703 85815.0396 83.4549
[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:25:56,679] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,254] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2709.2194 95689.6679 -216.8562
[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,274] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:06,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,205] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2613.2960 99186.0004 -349.9594
[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:11,333] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:26:12,228] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 450000, evaluation results [450000.0, 2709.2193758221606, 95689.6679375736, -216.8561626469315, 2930.1702785438756, 85815.03955432789, 83.45493296704919, 2613.296034518603, 99186.00041859964, -349.9593993804355]
[2019-04-24 10:26:12,492] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.9215021e-01 2.9353143e-03 1.9514224e-02 4.6006744e-07 7.9714724e-09
 7.9967641e-08 2.1447738e-08 4.7257286e-03 3.8067389e-01 4.2412629e-09
 1.9549684e-10], sum to 1.0000
[2019-04-24 10:26:12,492] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6339
[2019-04-24 10:26:12,558] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.6666666666666667, 50.66666666666667, 61.5, 517.1666666666666, 19.0, 22.72936543203146, -0.249186108362548, 0.0, 1.0, 55.0, 43.6991629283059], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3082800.0000, 
sim time next is 3084000.0000, 
raw observation next is [0.3333333333333334, 61.33333333333334, 48.66666666666666, 419.6666666666667, 19.0, 23.00486204427209, -0.2211147110567345, 0.0, 1.0, 55.0, 43.241243597450506], 
processed observation next is [0.0, 0.6956521739130435, 0.4718374884579871, 0.6133333333333334, 0.16222222222222218, 0.4637200736648251, 0.08333333333333333, 0.41707183702267425, 0.42629509631442186, 0.0, 1.0, 0.8, 0.43241243597450507], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0594649], dtype=float32), 1.8407887]. 
=============================================
[2019-04-24 10:26:12,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9856683e-01 7.2870794e-04 4.7331589e-04 4.2707522e-09 1.3995958e-13
 1.3046335e-10 2.6663118e-12 7.8802972e-05 4.0015236e-01 7.8190742e-13
 6.0073603e-14], sum to 1.0000
[2019-04-24 10:26:12,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2489
[2019-04-24 10:26:12,732] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 96.33333333333333, 604.5, 22.5, 23.39350732003424, -0.2186910208116778, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3144000.0000, 
sim time next is 3145200.0000, 
raw observation next is [7.0, 100.0, 100.5, 663.5, 22.5, 23.31024111205598, -0.2126427835916019, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6565096952908588, 1.0, 0.335, 0.7331491712707182, 0.375, 0.4425200926713317, 0.4291190721361327, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5143755], dtype=float32), 1.2552518]. 
=============================================
[2019-04-24 10:26:22,316] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.04524040e-01 1.93167746e-03 7.28424732e-03 1.42480565e-06
 3.11648818e-09 1.02540625e-07 1.77249753e-08 2.92073749e-03
 2.83337712e-01 4.75972373e-09 8.28530744e-10], sum to 1.0000
[2019-04-24 10:26:22,329] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0718
[2019-04-24 10:26:22,348] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.666666666666666, 70.0, 17.16666666666666, 171.6666666666667, 19.0, 21.1413159513637, -0.6110622452378823, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3570000.0000, 
sim time next is 3571200.0000, 
raw observation next is [-7.0, 70.0, 45.5, 273.0, 19.0, 20.64954167966903, -0.6708576259465185, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.2686980609418283, 0.7, 0.15166666666666667, 0.30165745856353593, 0.08333333333333333, 0.22079513997241929, 0.2763807913511605, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02910981], dtype=float32), -0.5852802]. 
=============================================
[2019-04-24 10:26:23,934] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.7931166e-01 8.0775336e-04 4.9221818e-04 2.2308503e-08 7.7951952e-13
 8.7569507e-10 2.3447265e-11 1.1024518e-04 2.1927811e-01 1.1739418e-12
 4.1363421e-13], sum to 1.0000
[2019-04-24 10:26:23,936] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4116
[2019-04-24 10:26:23,966] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 71.0, 0.0, 0.0, 22.5, 24.15059848871552, 0.1089652164039348, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3435600.0000, 
sim time next is 3436800.0000, 
raw observation next is [1.333333333333333, 75.0, 0.0, 0.0, 22.5, 23.79771817340339, 0.05553323408997992, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4995383194829178, 0.75, 0.0, 0.0, 0.375, 0.4831431811169491, 0.5185110780299933, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4845622], dtype=float32), 0.85996735]. 
=============================================
[2019-04-24 10:26:25,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8440231e-01 8.3947915e-04 5.7097315e-04 2.3427482e-08 6.7235306e-12
 3.3484646e-09 5.7411458e-11 6.4390450e-04 2.1354327e-01 8.2333810e-12
 1.6926014e-12], sum to 1.0000
[2019-04-24 10:26:25,629] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4953
[2019-04-24 10:26:25,665] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 116.0, 810.5, 22.5, 23.58934974596127, -0.06639035236683201, 1.0, 1.0, 55.0, 91.14453045527154], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3412800.0000, 
sim time next is 3414000.0000, 
raw observation next is [3.0, 46.33333333333334, 116.6666666666667, 814.8333333333334, 22.5, 23.85674120828758, -0.06182285752833803, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.46333333333333343, 0.388888888888889, 0.9003683241252303, 0.375, 0.4880617673572984, 0.47939238082388735, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8782794], dtype=float32), 2.0697052]. 
=============================================
[2019-04-24 10:26:26,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4917859e-01 2.9620612e-03 9.1340421e-03 1.5031681e-06 1.6020110e-09
 1.3411153e-07 1.1987968e-08 2.8179458e-03 2.3590569e-01 3.4908145e-09
 3.1238845e-10], sum to 1.0000
[2019-04-24 10:26:26,010] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7516
[2019-04-24 10:26:26,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.333333333333334, 30.33333333333334, 18.16666666666666, 168.0, 19.0, 22.46165888075933, -0.2363163511943513, 0.0, 1.0, 55.0, 69.02283742219805], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 3656400.0000, 
sim time next is 3657600.0000, 
raw observation next is [8.0, 32.0, 46.5, 262.0, 19.0, 23.13104080329246, -0.1625210111987974, 0.0, 1.0, 20.0, 35.547780723552265], 
processed observation next is [0.0, 0.34782608695652173, 0.6842105263157896, 0.32, 0.155, 0.28950276243093925, 0.08333333333333333, 0.42758673360770505, 0.44582632960040086, 0.0, 1.0, 0.1, 0.35547780723552264], 
reward next is 0.5445, 
noisyNet noise sample is [array([2.4397602], dtype=float32), 0.19071326]. 
=============================================
[2019-04-24 10:26:26,942] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0697802e-01 1.7806618e-03 6.0835620e-04 3.4750979e-08 1.2951035e-12
 1.8717226e-09 2.1017485e-11 1.5110773e-04 2.9048181e-01 1.4727825e-12
 3.3968490e-13], sum to 1.0000
[2019-04-24 10:26:26,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9173
[2019-04-24 10:26:26,995] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-0.3333333333333334, 57.00000000000001, 117.0, 832.8333333333334, 22.5, 25.21945781069102, 0.3709266271808786, 1.0, 1.0, 55.0, 64.21323792163795], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3846000.0000, 
sim time next is 3847200.0000, 
raw observation next is [0.3333333333333333, 54.0, 116.3333333333333, 833.1666666666667, 22.5, 25.67597181526378, 0.4449946263708657, 1.0, 1.0, 55.0, 45.373467458078736], 
processed observation next is [1.0, 0.5217391304347826, 0.4718374884579871, 0.54, 0.38777777777777767, 0.9206261510128915, 0.375, 0.6396643179386482, 0.6483315421236219, 1.0, 1.0, 0.8, 0.45373467458078737], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56828004], dtype=float32), 1.4442353]. 
=============================================
[2019-04-24 10:26:28,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3942186e-01 6.2206443e-03 1.4708558e-02 5.9930068e-07 2.0645348e-09
 2.0336228e-07 1.9281764e-08 1.3362799e-03 5.3831184e-01 2.1692419e-09
 1.8552766e-10], sum to 1.0000
[2019-04-24 10:26:28,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5518
[2019-04-24 10:26:28,682] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-0.6666666666666667, 42.33333333333334, 88.66666666666667, 713.8333333333333, 19.0, 23.20377848810973, -0.08203853496875611, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3597600.0000, 
sim time next is 3598800.0000, 
raw observation next is [-0.3333333333333334, 42.66666666666666, 82.16666666666667, 668.3333333333333, 19.0, 23.48732160194336, 0.07026033779047539, 0.0, 1.0, 55.0, 59.69584312858352], 
processed observation next is [0.0, 0.6521739130434783, 0.4533702677747, 0.4266666666666666, 0.2738888888888889, 0.7384898710865561, 0.08333333333333333, 0.4572768001619467, 0.5234201125968251, 0.0, 1.0, 0.8, 0.5969584312858351], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.343116], dtype=float32), -2.1836574]. 
=============================================
[2019-04-24 10:26:30,788] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.1629882e-01 1.4435416e-03 3.4059088e-03 1.1573761e-06 3.4914935e-09
 9.2133341e-08 8.9082937e-09 2.3136314e-03 2.7653676e-01 1.5214154e-09
 7.0235001e-10], sum to 1.0000
[2019-04-24 10:26:30,801] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7510
[2019-04-24 10:26:30,877] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [10.0, 25.0, 0.0, 0.0, 19.0, 23.26536470690753, -0.2324185109168924, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3650400.0000, 
sim time next is 3651600.0000, 
raw observation next is [9.666666666666668, 25.66666666666667, 0.0, 0.0, 19.0, 23.30534922159426, -0.107656936972046, 0.0, 1.0, 55.0, 62.037855479242765], 
processed observation next is [0.0, 0.2608695652173913, 0.7303785780240075, 0.2566666666666667, 0.0, 0.0, 0.08333333333333333, 0.4421124351328549, 0.46411435434265136, 0.0, 1.0, 0.8, 0.6203785547924276], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17669515], dtype=float32), -0.4018836]. 
=============================================
[2019-04-24 10:26:30,960] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4629973e-01 4.1475240e-03 7.5852568e-03 1.8059922e-06 2.0335944e-09
 1.4929448e-07 2.8741100e-08 3.7387374e-03 5.3822678e-01 2.3530025e-09
 5.6521304e-10], sum to 1.0000
[2019-04-24 10:26:30,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6062
[2019-04-24 10:26:31,045] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.333333333333334, 36.33333333333333, 0.0, 0.0, 19.0, 20.08775082795601, -0.8895989052554779, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4077600.0000, 
sim time next is 4078800.0000, 
raw observation next is [-4.0, 34.0, 0.0, 0.0, 19.0, 20.4854337108768, -0.6088176513500684, 0.0, 1.0, 55.0, 88.14916752157008], 
processed observation next is [1.0, 0.21739130434782608, 0.3518005540166205, 0.34, 0.0, 0.0, 0.08333333333333333, 0.20711947590640012, 0.29706078288331056, 0.0, 1.0, 0.8, 0.8814916752157008], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12818561], dtype=float32), -0.756854]. 
=============================================
[2019-04-24 10:26:31,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2359194e-01 5.7844110e-03 6.6872691e-03 1.3460044e-06 8.2026336e-10
 5.2671322e-08 1.6371617e-08 3.7888344e-03 4.6014613e-01 2.6320068e-09
 8.2279866e-10], sum to 1.0000
[2019-04-24 10:26:31,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3506
[2019-04-24 10:26:31,584] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.0, 63.0, 0.0, 0.0, 19.0, 19.35283876528752, -1.015886999431681, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3996000.0000, 
sim time next is 3997200.0000, 
raw observation next is [-13.33333333333333, 65.0, 0.0, 0.0, 19.0, 19.12817388432888, -1.065572972759276, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.09325946445060027, 0.65, 0.0, 0.0, 0.08333333333333333, 0.09401449036074006, 0.14480900908024133, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13491623], dtype=float32), -0.2125518]. 
=============================================
[2019-04-24 10:26:32,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4501342e-01 3.4968759e-04 4.0068736e-04 1.8600009e-08 1.6917742e-12
 1.8335189e-09 6.2614254e-12 4.2570554e-04 2.5381041e-01 1.0971441e-12
 1.8054713e-13], sum to 1.0000
[2019-04-24 10:26:32,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7527
[2019-04-24 10:26:32,249] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6306210e-01 1.3338178e-03 1.1819655e-03 4.5424549e-08 3.0467021e-11
 7.4317930e-09 1.1337806e-10 2.3036693e-04 3.3419168e-01 8.8490231e-12
 1.7184843e-12], sum to 1.0000
[2019-04-24 10:26:32,250] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3403
[2019-04-24 10:26:32,266] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 71.0, 113.0, 795.5, 22.5, 25.19202067350862, 0.380309234379958, 1.0, 1.0, 55.0, 73.96813509734292], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3754800.0000, 
sim time next is 3756000.0000, 
raw observation next is [-2.666666666666667, 69.0, 114.3333333333333, 813.1666666666666, 22.5, 25.97988355363029, 0.4851821012150177, 1.0, 1.0, 55.0, 45.3959871203336], 
processed observation next is [1.0, 0.4782608695652174, 0.38873499538319484, 0.69, 0.381111111111111, 0.8985267034990791, 0.375, 0.6649902961358576, 0.6617273670716726, 1.0, 1.0, 0.8, 0.45395987120333603], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21315084], dtype=float32), -0.31209117]. 
=============================================
[2019-04-24 10:26:32,273] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 19.0, 22.85773386312925, 0.07814970603115338, 0.0, 1.0, 55.0, 82.78206115062149], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3880800.0000, 
sim time next is 3882000.0000, 
raw observation next is [-1.0, 56.66666666666667, 0.0, 0.0, 19.0, 23.50563563065156, -0.07158001341305836, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.5666666666666668, 0.0, 0.0, 0.08333333333333333, 0.4588029692209634, 0.4761399955289805, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09816482], dtype=float32), 0.67525357]. 
=============================================
[2019-04-24 10:26:32,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.4071540e-01 4.4945385e-03 1.9322357e-03 1.3085024e-07 3.1499331e-11
 3.2698537e-09 4.0057180e-10 1.0156791e-03 4.5184195e-01 5.2319277e-11
 3.2029060e-12], sum to 1.0000
[2019-04-24 10:26:32,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0666
[2019-04-24 10:26:32,554] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 47.0, 282.5, 22.5, 23.12940834758489, -0.1939374447372253, 0.0, 1.0, 55.0, 65.19583299275857], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3744000.0000, 
sim time next is 3745200.0000, 
raw observation next is [-4.0, 73.0, 75.0, 380.1666666666667, 22.5, 23.25014651487052, -0.2691023256724664, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3518005540166205, 0.73, 0.25, 0.42007366482504604, 0.375, 0.4375122095725432, 0.4102992247758445, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.693591], dtype=float32), -0.47711805]. 
=============================================
[2019-04-24 10:26:35,946] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.7635820e-01 1.1593476e-03 9.1168674e-04 2.2538940e-08 1.2603171e-10
 9.8617772e-09 2.1686795e-10 1.7831268e-03 4.1978765e-01 1.8187507e-11
 8.3102509e-12], sum to 1.0000
[2019-04-24 10:26:35,946] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3842
[2019-04-24 10:26:35,982] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 77.0, 0.0, 0.0, 19.0, 21.63289511319981, -0.3427252658490742, 0.0, 1.0, 55.0, 80.89155567687146], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3823200.0000, 
sim time next is 3824400.0000, 
raw observation next is [-5.0, 77.0, 0.0, 0.0, 19.0, 22.15137720067143, -0.4812207090244107, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.32409972299168976, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3459481000559525, 0.3395930969918631, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.37038592], dtype=float32), -0.73665583]. 
=============================================
[2019-04-24 10:26:36,433] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.0604060e-01 4.4016112e-03 2.4901843e-03 9.0561549e-08 2.5051684e-12
 9.3418686e-09 7.2735880e-11 2.0263153e-04 3.8686484e-01 4.7985218e-12
 2.6123118e-12], sum to 1.0000
[2019-04-24 10:26:36,445] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5345
[2019-04-24 10:26:36,505] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 75.0, 76.66666666666667, 397.3333333333333, 22.5, 22.02260337317306, -0.4340975792333108, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3831600.0000, 
sim time next is 3832800.0000, 
raw observation next is [-4.333333333333334, 73.0, 92.66666666666667, 485.8333333333333, 22.5, 22.16304833452396, -0.4079433479003454, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3425669436749769, 0.73, 0.3088888888888889, 0.5368324125230203, 0.375, 0.34692069454366337, 0.3640188840332182, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00226594], dtype=float32), 0.8410048]. 
=============================================
[2019-04-24 10:26:39,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0327598e-01 4.9965014e-03 9.0495311e-03 5.0799656e-07 7.5994072e-10
 6.1451850e-08 1.1959559e-09 9.3140581e-04 2.8174600e-01 3.7110373e-10
 1.9733847e-10], sum to 1.0000
[2019-04-24 10:26:39,845] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7698
[2019-04-24 10:26:39,895] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.333333333333334, 46.33333333333334, 0.0, 0.0, 19.0, 22.04691749763273, -0.3312809045539805, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3964800.0000, 
sim time next is 3966000.0000, 
raw observation next is [-7.666666666666666, 47.66666666666666, 0.0, 0.0, 19.0, 22.24544830148353, -0.1010724361910217, 0.0, 1.0, 55.0, 84.81142172107727], 
processed observation next is [1.0, 0.9130434782608695, 0.25023084025854114, 0.47666666666666657, 0.0, 0.0, 0.08333333333333333, 0.3537873584569609, 0.4663091879363261, 0.0, 1.0, 0.8, 0.8481142172107726], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19603395], dtype=float32), -0.8029374]. 
=============================================
[2019-04-24 10:26:52,071] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.45999658e-01 3.41038482e-04 6.98256597e-04 1.23715935e-08
 1.57638919e-12 6.85662527e-10 1.38987294e-11 2.02767536e-04
 1.52758256e-01 6.45987007e-13 2.19502815e-13], sum to 1.0000
[2019-04-24 10:26:52,073] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8571
[2019-04-24 10:26:52,153] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.233333333333333, 49.0, 135.8333333333333, 820.6666666666666, 22.5, 24.77034829268061, 0.2489441230377052, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4627200.0000, 
sim time next is 4628400.0000, 
raw observation next is [4.466666666666667, 49.0, 149.6666666666667, 777.3333333333333, 22.5, 25.14019395005826, 0.4773803834547893, 1.0, 1.0, 55.0, 59.98333538048318], 
processed observation next is [1.0, 0.5652173913043478, 0.5863342566943676, 0.49, 0.49888888888888905, 0.8589318600368323, 0.375, 0.5950161625048551, 0.6591267944849298, 1.0, 1.0, 0.8, 0.5998333538048318], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6574847], dtype=float32), -0.09642143]. 
=============================================
[2019-04-24 10:26:56,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8826046e-01 3.7795980e-04 6.1758020e-04 6.1260170e-09 2.6757326e-13
 2.2907401e-10 4.7208817e-12 5.4024399e-04 2.1020369e-01 1.2879853e-13
 6.5851519e-14], sum to 1.0000
[2019-04-24 10:26:56,057] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9342
[2019-04-24 10:26:56,114] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.2, 84.66666666666667, 157.5, 64.5, 22.5, 24.54276574600798, 0.1936907620458221, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4440000.0000, 
sim time next is 4441200.0000, 
raw observation next is [1.1, 85.33333333333333, 179.3333333333333, 50.16666666666666, 22.5, 25.23697124836891, 0.4821955297206724, 1.0, 1.0, 55.0, 76.460477618227], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8533333333333333, 0.5977777777777776, 0.05543278084714548, 0.375, 0.6030809373640759, 0.6607318432402242, 1.0, 1.0, 0.8, 0.7646047761822701], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43507397], dtype=float32), -0.8782065]. 
=============================================
[2019-04-24 10:26:56,752] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2286444e-01 3.2776312e-04 7.7634002e-05 1.9419737e-09 3.3655050e-13
 2.2523754e-10 2.5519750e-13 9.5340671e-05 7.6634809e-02 1.4443473e-13
 5.2887623e-15], sum to 1.0000
[2019-04-24 10:26:56,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8722
[2019-04-24 10:26:56,791] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 38.0, 24.0, 0.0, 22.5, 26.69524519341208, 0.6159411635043889, 1.0, 1.0, 55.0, 64.82291208362649], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4381200.0000, 
sim time next is 4382400.0000, 
raw observation next is [12.8, 40.0, 14.0, 0.0, 22.5, 26.94808753828653, 0.6664767923024818, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.8171745152354571, 0.4, 0.04666666666666667, 0.0, 0.375, 0.7456739615238774, 0.7221589307674939, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2521856], dtype=float32), 1.0549556]. 
=============================================
[2019-04-24 10:26:56,970] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.1492879e-01 1.0583350e-04 5.5202287e-05 7.5218892e-10 6.9274657e-14
 3.4338393e-11 3.4929443e-13 1.5166556e-04 8.4758535e-02 4.7367712e-14
 8.0089438e-15], sum to 1.0000
[2019-04-24 10:26:56,971] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8781
[2019-04-24 10:26:56,993] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 92.0, 177.5, 5.0, 22.5, 25.12802997822894, 0.3141932987927057, 1.0, 1.0, 55.0, 77.0832275934681], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4455600.0000, 
sim time next is 4456800.0000, 
raw observation next is [0.0, 92.0, 140.5, 3.0, 22.5, 25.24707738510384, 0.3510444486020263, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.46260387811634357, 0.92, 0.4683333333333333, 0.0033149171270718232, 0.375, 0.60392311542532, 0.6170148162006754, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.044141], dtype=float32), -2.2907176]. 
=============================================
[2019-04-24 10:26:58,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2288554e-01 1.0329796e-04 1.1106546e-04 9.3473285e-10 7.1606817e-14
 2.5045910e-10 1.6163377e-12 4.1416013e-05 7.6858699e-02 9.4201543e-14
 1.7574133e-14], sum to 1.0000
[2019-04-24 10:26:58,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3093
[2019-04-24 10:26:58,962] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 90.0, 117.6666666666667, 0.9999999999999998, 22.5, 24.98793988850402, 0.4359815243656291, 1.0, 1.0, 55.0, 81.02742194593115], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4452000.0000, 
sim time next is 4453200.0000, 
raw observation next is [0.0, 92.0, 149.0, 3.0, 22.5, 25.45730459038706, 0.3424946304091946, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.46260387811634357, 0.92, 0.49666666666666665, 0.0033149171270718232, 0.375, 0.6214420491989218, 0.6141648768030649, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2357646], dtype=float32), 0.27572173]. 
=============================================
[2019-04-24 10:27:02,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:02,221] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:03,044] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:03,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:03,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run8
[2019-04-24 10:27:04,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:05,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:05,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4228472e-01 7.4371707e-04 1.3757690e-03 2.8902274e-08 2.0911533e-11
 3.1331844e-09 8.6922580e-11 2.7906392e-03 2.5280508e-01 9.5788559e-12
 4.2473334e-12], sum to 1.0000
[2019-04-24 10:27:05,381] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9339
[2019-04-24 10:27:05,435] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.233333333333333, 67.66666666666667, 0.0, 0.0, 19.0, 22.7789133895694, -0.1634248139408543, 0.0, 1.0, 55.0, 64.90862890372273], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4591200.0000, 
sim time next is 4592400.0000, 
raw observation next is [-1.366666666666667, 68.33333333333334, 0.0, 0.0, 19.0, 23.24147786865841, -0.1227824014185173, 0.0, 1.0, 55.0, 46.10684828569278], 
processed observation next is [1.0, 0.13043478260869565, 0.42474607571560485, 0.6833333333333335, 0.0, 0.0, 0.08333333333333333, 0.4367898223882009, 0.45907253286049426, 0.0, 1.0, 0.8, 0.46106848285692775], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7776716], dtype=float32), -0.7743128]. 
=============================================
[2019-04-24 10:27:05,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6510676e-01 4.1645722e-04 7.5265422e-04 2.2791957e-08 8.6050724e-12
 3.3191887e-09 1.5604674e-11 2.7329181e-04 1.3345085e-01 4.5986422e-12
 2.0128951e-12], sum to 1.0000
[2019-04-24 10:27:05,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3063
[2019-04-24 10:27:05,977] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.4, 20.0, 0.0, 0.0, 19.0, 24.51173292093458, 0.1953311620967819, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5094000.0000, 
sim time next is 5095200.0000, 
raw observation next is [8.3, 25.0, 0.0, 0.0, 19.0, 24.30594890332494, 0.1558829071938839, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.6925207756232689, 0.25, 0.0, 0.0, 0.08333333333333333, 0.5254957419437449, 0.551960969064628, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5432999], dtype=float32), -2.801665]. 
=============================================
[2019-04-24 10:27:05,998] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:05,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:06,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run8
[2019-04-24 10:27:06,158] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:06,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:07,155] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:07,155] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:07,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run8
[2019-04-24 10:27:08,920] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5250021e-01 2.6459810e-03 4.2984588e-03 2.9152821e-07 4.5253146e-10
 7.2035213e-08 2.5372915e-09 7.4204797e-04 3.3981293e-01 6.1368499e-10
 6.2586734e-11], sum to 1.0000
[2019-04-24 10:27:08,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5798
[2019-04-24 10:27:08,938] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 16.5, 93.5, 19.0, 23.25601248823041, -0.1592040742895556, 0.0, 1.0, 55.0, 44.06819835983269], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4903200.0000, 
sim time next is 4904400.0000, 
raw observation next is [1.666666666666667, 45.0, 0.0, 0.0, 19.0, 23.14779331257783, -0.3017992982805589, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5087719298245615, 0.45, 0.0, 0.0, 0.08333333333333333, 0.4289827760481524, 0.3994002339064804, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.051694], dtype=float32), 0.37863818]. 
=============================================
[2019-04-24 10:27:09,336] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.2389364e-01 1.3574940e-03 9.2428154e-04 9.7132213e-09 1.8671288e-13
 3.6324588e-10 4.8847593e-12 1.9276048e-04 2.7363175e-01 2.0635799e-13
 1.9416133e-14], sum to 1.0000
[2019-04-24 10:27:09,337] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8142
[2019-04-24 10:27:09,388] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 92.0, 71.66666666666666, 0.0, 22.5, 23.86224983991139, 0.05219836562924355, 1.0, 1.0, 55.0, 66.23019288202332], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4696800.0000, 
sim time next is 4698000.0000, 
raw observation next is [0.0, 92.0, 89.0, 0.0, 22.5, 24.36955378927428, 0.1276433122936331, 1.0, 1.0, 55.0, 46.61693990474569], 
processed observation next is [1.0, 0.391304347826087, 0.46260387811634357, 0.92, 0.2966666666666667, 0.0, 0.375, 0.5307961491061901, 0.5425477707645444, 1.0, 1.0, 0.8, 0.4661693990474569], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3334919], dtype=float32), 1.2463162]. 
=============================================
[2019-04-24 10:27:10,739] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:10,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:11,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:11,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:11,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run8
[2019-04-24 10:27:11,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:11,986] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9094716e-01 1.0843367e-01 8.9197837e-02 4.7551841e-03 2.9459468e-04
 9.9712296e-04 5.1140279e-04 5.5842031e-02 3.4840497e-01 3.8612486e-04
 2.2990938e-04], sum to 1.0000
[2019-04-24 10:27:11,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4883
[2019-04-24 10:27:12,037] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [4.8, 95.66666666666667, 0.0, 0.0, 19.0, 20.51306781464177, -0.698129853890677, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2400.0000, 
sim time next is 3600.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 20.48130193337057, -0.616328204671422, 0.0, 1.0, 20.0, 36.72991284256508], 
processed observation next is [0.0, 0.043478260869565216, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.2067751611142142, 0.294557265109526, 0.0, 1.0, 0.1, 0.36729912842565077], 
reward next is 0.5327, 
noisyNet noise sample is [array([0.5116337], dtype=float32), -0.13295333]. 
=============================================
[2019-04-24 10:27:12,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:12,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:12,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:12,844] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run8
[2019-04-24 10:27:14,696] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:14,930] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:15,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.0570173e-01 7.1233272e-04 7.7264197e-03 2.9049991e-07 6.3056643e-10
 3.9372519e-08 3.0499137e-09 7.4056821e-04 1.8511869e-01 2.0081066e-09
 1.6435697e-10], sum to 1.0000
[2019-04-24 10:27:15,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9152
[2019-04-24 10:27:15,330] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.6, 44.66666666666667, 273.5, 388.3333333333334, 19.0, 21.28495141245826, -0.5388726851581117, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4886400.0000, 
sim time next is 4887600.0000, 
raw observation next is [1.8, 44.33333333333334, 266.0, 385.6666666666667, 19.0, 21.61630290430748, -0.282876133430343, 0.0, 1.0, 55.0, 73.27020052937732], 
processed observation next is [0.0, 0.5652173913043478, 0.5124653739612189, 0.4433333333333334, 0.8866666666666667, 0.4261510128913444, 0.08333333333333333, 0.30135857535895677, 0.405707955523219, 0.0, 1.0, 0.8, 0.7327020052937732], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.62037843], dtype=float32), 1.4219129]. 
=============================================
[2019-04-24 10:27:15,356] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:15,632] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:15,676] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:15,676] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:15,679] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run8
[2019-04-24 10:27:16,114] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:16,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:16,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:16,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:16,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run8
[2019-04-24 10:27:16,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:16,559] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:16,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:17,107] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:17,107] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:17,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:17,119] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run8
[2019-04-24 10:27:17,185] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:17,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:17,377] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:17,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run8
[2019-04-24 10:27:17,411] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:17,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:17,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:17,831] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:17,831] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:17,836] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run8
[2019-04-24 10:27:18,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:18,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:18,198] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run8
[2019-04-24 10:27:18,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:18,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:18,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run8
[2019-04-24 10:27:18,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:19,284] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:19,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:19,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:19,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run8
[2019-04-24 10:27:20,403] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:20,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:21,404] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:21,404] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:21,407] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run8
[2019-04-24 10:27:21,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:22,073] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:22,103] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:22,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:27:22,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:22,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:22,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run8
[2019-04-24 10:27:23,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:27:23,075] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:27:23,078] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run8
[2019-04-24 10:27:33,027] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6367885e-01 1.7963542e-03 9.2517916e-04 9.0882118e-08 1.4266340e-11
 1.1475901e-08 2.5918598e-10 3.2158423e-04 2.3327790e-01 3.2477517e-11
 7.8738439e-12], sum to 1.0000
[2019-04-24 10:27:33,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6352
[2019-04-24 10:27:33,164] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.933333333333334, 74.0, 116.5, 0.0, 22.5, 21.69289603891468, -0.7235063610690723, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 210000.0000, 
sim time next is 211200.0000, 
raw observation next is [-6.566666666666666, 73.0, 128.8333333333333, 0.0, 22.5, 21.29543123365411, -0.7709861793757855, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.28070175438596495, 0.73, 0.4294444444444443, 0.0, 0.375, 0.2746192694711758, 0.24300460687473815, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6785004], dtype=float32), -0.18632427]. 
=============================================
[2019-04-24 10:27:34,556] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.6894308e-01 6.6199824e-03 2.1172280e-03 1.1792927e-07 1.1819301e-10
 1.1824001e-08 3.0198126e-09 1.1191833e-03 4.2120042e-01 3.9476443e-11
 3.2754036e-11], sum to 1.0000
[2019-04-24 10:27:34,556] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8359
[2019-04-24 10:27:34,787] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.3, 68.0, 0.0, 0.0, 22.5, 20.61590475102391, -0.7873205778328577, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 114000.0000, 
sim time next is 115200.0000, 
raw observation next is [-7.3, 68.0, 18.5, 4.5, 22.5, 20.80588868172883, -0.5465390011974243, 1.0, 1.0, 55.0, 93.82959227197719], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.68, 0.06166666666666667, 0.004972375690607734, 0.375, 0.23382405681073593, 0.31782033293419193, 1.0, 1.0, 0.8, 0.9382959227197719], 
reward next is 0.2327, 
noisyNet noise sample is [array([-0.40533084], dtype=float32), 0.99193025]. 
=============================================
[2019-04-24 10:27:42,093] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.4797202e-01 1.0300111e-02 1.1466980e-02 2.0042394e-06 1.5342850e-09
 2.8252649e-07 2.9009975e-08 1.3763164e-03 4.2888224e-01 9.0718050e-10
 1.9243476e-09], sum to 1.0000
[2019-04-24 10:27:42,094] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7487
[2019-04-24 10:27:42,174] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 19.0, 17.7534778424433, -1.506371815055652, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 354000.0000, 
sim time next is 355200.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 19.0, 17.81258859494399, -1.270724143180082, 0.0, 1.0, 55.0, 95.57705060303327], 
processed observation next is [1.0, 0.08695652173913043, 0.04709141274238226, 0.69, 0.0, 0.0, 0.08333333333333333, -0.015617617088000912, 0.07642528560663935, 0.0, 1.0, 0.8, 0.9557705060303328], 
reward next is 0.2956, 
noisyNet noise sample is [array([-0.2093985], dtype=float32), -0.39114842]. 
=============================================
[2019-04-24 10:27:44,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3750611e-01 6.9758524e-03 2.9750466e-03 2.4690888e-07 1.5364680e-10
 3.8583913e-08 2.9435547e-09 1.5032382e-03 5.5103946e-01 1.3520982e-10
 1.0804590e-10], sum to 1.0000
[2019-04-24 10:27:44,535] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2768
[2019-04-24 10:27:44,633] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.63333333333333, 69.0, 25.0, 325.8333333333334, 22.5, 20.72506639674943, -0.7469123947717549, 1.0, 1.0, 55.0, 67.83101420440161], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 289200.0000, 
sim time next is 290400.0000, 
raw observation next is [-12.46666666666667, 68.0, 40.83333333333333, 385.5, 22.5, 21.17080480562905, -0.8406529536127354, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.11726685133887339, 0.68, 0.1361111111111111, 0.42596685082872926, 0.375, 0.2642337338024208, 0.21978234879575487, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.366297], dtype=float32), -0.9679368]. 
=============================================
[2019-04-24 10:27:46,317] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3751636e-01 2.0578103e-03 2.7057561e-03 8.0198717e-08 1.0247759e-10
 8.6987777e-09 3.9937784e-10 8.5748930e-04 4.5686251e-01 1.8209526e-11
 9.5389564e-12], sum to 1.0000
[2019-04-24 10:27:46,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7524
[2019-04-24 10:27:46,352] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 21.40315726856429, -0.6349001950085009, 0.0, 1.0, 55.0, 53.04069477153419], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 264000.0000, 
sim time next is 265200.0000, 
raw observation next is [-7.1, 69.66666666666666, 0.0, 0.0, 19.0, 21.43003394076501, -0.6232397612726889, 0.0, 1.0, 55.0, 52.83136403757699], 
processed observation next is [1.0, 0.043478260869565216, 0.2659279778393352, 0.6966666666666665, 0.0, 0.0, 0.08333333333333333, 0.28583616173041754, 0.2922534129091037, 0.0, 1.0, 0.8, 0.5283136403757699], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4264009], dtype=float32), -0.13188872]. 
=============================================
[2019-04-24 10:27:52,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4246224e-01 4.7519836e-03 1.4700056e-02 5.6786831e-07 5.0454413e-10
 2.9394094e-08 6.6844965e-09 3.3827932e-03 5.3470224e-01 8.2168627e-10
 1.6208070e-10], sum to 1.0000
[2019-04-24 10:27:52,358] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1354
[2019-04-24 10:27:52,376] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 75.0, 0.0, 0.0, 19.0, 19.10102398177835, -1.266341070464877, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 704400.0000, 
sim time next is 705600.0000, 
raw observation next is [-2.8, 75.0, 0.0, 0.0, 19.0, 18.33461766018947, -1.412952469931383, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.38504155124653744, 0.75, 0.0, 0.0, 0.08333333333333333, 0.027884805015789087, 0.0290158433562057, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45606261], dtype=float32), -0.6091487]. 
=============================================
[2019-04-24 10:27:58,417] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9028941e-01 1.8346664e-03 3.0537995e-03 1.6584599e-07 4.5990406e-11
 7.2843460e-09 5.7828903e-10 1.0236900e-03 4.0379816e-01 6.5089482e-11
 9.1734996e-12], sum to 1.0000
[2019-04-24 10:27:58,417] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4567
[2019-04-24 10:27:58,513] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 75.0, 16.0, 0.0, 22.5, 21.4925077169182, -0.6111139752959485, 1.0, 1.0, 55.0, 63.92442536920947], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 806400.0000, 
sim time next is 807600.0000, 
raw observation next is [-6.533333333333334, 75.0, 26.66666666666667, 0.0, 22.5, 21.60082955782295, -0.7057795540924131, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.28162511542012925, 0.75, 0.0888888888888889, 0.0, 0.375, 0.3000691298185793, 0.2647401486358623, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8416213], dtype=float32), 2.0756395]. 
=============================================
[2019-04-24 10:27:59,640] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.6861520e-01 4.5789098e-03 5.9082345e-03 3.0099020e-06 4.2094195e-09
 1.6520727e-07 2.6185393e-08 2.9365392e-03 4.1795790e-01 1.4100406e-09
 1.6963079e-09], sum to 1.0000
[2019-04-24 10:27:59,650] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0387
[2019-04-24 10:27:59,672] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 51.0, 0.0, 0.0, 19.0, 19.68295491898897, -1.184772280160588, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 445200.0000, 
sim time next is 446400.0000, 
raw observation next is [-11.2, 52.0, 0.0, 0.0, 19.0, 18.47109612362324, -1.378997216472259, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.15235457063711913, 0.52, 0.0, 0.0, 0.08333333333333333, 0.03925801030193673, 0.040334261175913655, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1742924], dtype=float32), 3.0402513]. 
=============================================
[2019-04-24 10:28:06,205] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5733992e-01 5.5107306e-04 9.0808593e-05 1.9394650e-09 2.8697663e-14
 5.0421885e-11 6.4531361e-13 1.4237546e-04 1.4187579e-01 1.4506588e-14
 4.0511485e-15], sum to 1.0000
[2019-04-24 10:28:06,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6373
[2019-04-24 10:28:06,233] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 86.0, 121.3333333333333, 0.0, 22.5, 24.55080241943414, 0.1043120886976689, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 992400.0000, 
sim time next is 993600.0000, 
raw observation next is [12.2, 86.0, 124.0, 0.0, 22.5, 24.00791124638847, 0.04454769424430208, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8005540166204987, 0.86, 0.41333333333333333, 0.0, 0.375, 0.5006592705323726, 0.5148492314147673, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.38887954], dtype=float32), -0.87814736]. 
=============================================
[2019-04-24 10:28:06,419] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.4041868e-01 4.4655795e-03 6.2063653e-03 9.0952494e-07 3.1772840e-09
 1.9583867e-07 7.8748066e-08 1.9510143e-03 4.4695723e-01 1.9226556e-09
 3.6564715e-10], sum to 1.0000
[2019-04-24 10:28:06,421] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9146
[2019-04-24 10:28:06,546] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.899999999999999, 67.0, 129.1666666666667, 42.5, 19.0, 19.93900128235171, -1.028171158020611, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 639600.0000, 
sim time next is 640800.0000, 
raw observation next is [-3.9, 65.0, 117.5, 25.5, 19.0, 19.83184651052247, -0.8405722320059924, 0.0, 1.0, 55.0, 81.74651964079561], 
processed observation next is [0.0, 0.43478260869565216, 0.3545706371191136, 0.65, 0.39166666666666666, 0.0281767955801105, 0.08333333333333333, 0.1526538758768726, 0.21980925599800252, 0.0, 1.0, 0.8, 0.8174651964079561], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4486368], dtype=float32), 0.6226306]. 
=============================================
[2019-04-24 10:28:08,230] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4979706e-01 1.5270588e-03 3.6622910e-03 2.7265168e-07 3.0776864e-10
 1.5045018e-08 4.3096149e-09 8.7291771e-04 4.4414040e-01 3.5736802e-10
 3.2298490e-11], sum to 1.0000
[2019-04-24 10:28:08,230] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2708
[2019-04-24 10:28:08,263] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.2, 83.0, 0.0, 0.0, 19.0, 21.42390795600573, -0.5569564653785856, 0.0, 1.0, 55.0, 51.25608230082524], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 600000.0000, 
sim time next is 601200.0000, 
raw observation next is [-3.4, 83.0, 0.0, 0.0, 19.0, 21.25727703161606, -0.7268482458455746, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.368421052631579, 0.83, 0.0, 0.0, 0.08333333333333333, 0.2714397526346716, 0.25771725138480844, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21317981], dtype=float32), -0.24286419]. 
=============================================
[2019-04-24 10:28:08,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9766164e-01 3.8870194e-04 1.7003996e-03 2.2054341e-08 1.6722179e-12
 3.4946104e-10 1.6467990e-11 4.3305181e-04 2.9981625e-01 5.5872071e-13
 3.5593997e-13], sum to 1.0000
[2019-04-24 10:28:08,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4767
[2019-04-24 10:28:08,548] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 19.0, 22.06374055460597, -0.3980296902724851, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 961200.0000, 
sim time next is 962400.0000, 
raw observation next is [7.7, 81.0, 0.0, 0.0, 19.0, 21.75678986754365, -0.4390359377717112, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.81, 0.0, 0.0, 0.08333333333333333, 0.31306582229530405, 0.35365468740942957, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20764998], dtype=float32), -1.1905818]. 
=============================================
[2019-04-24 10:28:11,666] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.5471301e-01 1.3985971e-03 4.9825213e-03 1.7832620e-07 4.9006438e-11
 1.6856726e-08 4.5042969e-10 7.9656451e-04 4.3810913e-01 7.3093510e-11
 1.1684271e-11], sum to 1.0000
[2019-04-24 10:28:11,667] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7452
[2019-04-24 10:28:11,706] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.1, 69.66666666666666, 0.0, 0.0, 19.0, 21.53730833845591, -0.6452373198000682, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 776400.0000, 
sim time next is 777600.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 19.0, 21.2030224420045, -0.5402398342033805, 0.0, 1.0, 55.0, 71.10132096211639], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.71, 0.0, 0.0, 0.08333333333333333, 0.2669185368337083, 0.31992005526553985, 0.0, 1.0, 0.8, 0.7110132096211639], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3896734], dtype=float32), 0.4339566]. 
=============================================
[2019-04-24 10:28:15,293] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.3705769e-01 1.0199593e-03 1.9224409e-03 1.2864243e-07 1.0995963e-11
 2.9176208e-09 1.1433060e-10 3.9917009e-04 2.5960058e-01 8.2644698e-12
 5.6243244e-12], sum to 1.0000
[2019-04-24 10:28:15,298] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9051
[2019-04-24 10:28:15,441] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.899999999999999, 83.66666666666666, 57.33333333333334, 0.0, 22.5, 22.93137694456972, -0.547648839016911, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 830400.0000, 
sim time next is 831600.0000, 
raw observation next is [-3.9, 86.0, 54.0, 0.0, 22.5, 22.70320005391884, -0.2844994535473089, 1.0, 1.0, 55.0, 78.12141928726497], 
processed observation next is [1.0, 0.6521739130434783, 0.3545706371191136, 0.86, 0.18, 0.0, 0.375, 0.39193333782657014, 0.4051668488175637, 1.0, 1.0, 0.8, 0.7812141928726497], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41194484], dtype=float32), 0.6936107]. 
=============================================
[2019-04-24 10:28:20,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.02832305e-01 5.86280003e-05 2.23275609e-04 9.55723944e-10
 3.34764497e-14 4.84572729e-11 3.41865750e-13 3.42115673e-05
 1.96851552e-01 1.05058865e-13 4.10873575e-15], sum to 1.0000
[2019-04-24 10:28:20,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6004
[2019-04-24 10:28:20,076] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.83333333333333, 82.66666666666667, 114.8333333333333, 0.0, 22.5, 23.67923619290242, -0.0005028168165158534, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 999600.0000, 
sim time next is 1000800.0000, 
raw observation next is [14.4, 81.0, 106.5, 0.0, 22.5, 23.83961616400155, 0.01759411877051638, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.8614958448753465, 0.81, 0.355, 0.0, 0.375, 0.48663468033346263, 0.5058647062568388, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.56057155], dtype=float32), -0.6858677]. 
=============================================
[2019-04-24 10:28:20,870] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.3367347e-01 5.7819427e-04 1.0803388e-03 2.7127289e-09 1.6983302e-13
 4.5156621e-11 4.1524739e-12 2.0524107e-04 4.6446282e-01 1.7896795e-13
 1.8712792e-14], sum to 1.0000
[2019-04-24 10:28:20,873] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2535
[2019-04-24 10:28:20,892] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.8, 92.0, 0.0, 0.0, 19.0, 24.80010076755879, 0.4102243850236324, 0.0, 1.0, 55.0, 47.040811496541025], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1312800.0000, 
sim time next is 1314000.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 24.81521646844251, 0.3016052588026132, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.5679347057035425, 0.6005350862675377, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42205167], dtype=float32), 0.39096135]. 
=============================================
[2019-04-24 10:28:21,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5530154e-01 2.2493443e-04 2.2078794e-04 4.3361230e-09 5.1734584e-14
 8.3488147e-11 4.7721825e-13 4.5718210e-05 2.4420699e-01 3.9979674e-14
 1.8302632e-14], sum to 1.0000
[2019-04-24 10:28:21,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8814
[2019-04-24 10:28:21,593] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [10.16666666666667, 59.33333333333334, 0.0, 0.0, 22.5, 26.50219994294132, 0.6727851797429447, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1532400.0000, 
sim time next is 1533600.0000, 
raw observation next is [10.0, 60.0, 0.0, 0.0, 22.5, 26.5215108731538, 0.7869977143725725, 1.0, 1.0, 55.0, 44.38380538788799], 
processed observation next is [1.0, 0.782608695652174, 0.739612188365651, 0.6, 0.0, 0.0, 0.375, 0.7101259060961501, 0.7623325714575242, 1.0, 1.0, 0.8, 0.44383805387887987], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46868756], dtype=float32), -0.23222208]. 
=============================================
[2019-04-24 10:28:21,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3023758e-01 1.3649556e-03 1.0795505e-03 8.5999261e-09 4.1461227e-13
 4.7159743e-10 1.2119613e-11 4.1743627e-04 3.6690053e-01 7.3231769e-13
 3.4739949e-13], sum to 1.0000
[2019-04-24 10:28:21,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1949
[2019-04-24 10:28:21,624] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.533333333333333, 85.33333333333334, 0.0, 0.0, 19.0, 22.9572859173212, -0.1008035539865793, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1568400.0000, 
sim time next is 1569600.0000, 
raw observation next is [4.6, 85.0, 0.0, 0.0, 19.0, 22.84395483692445, -0.1201088313369678, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.590027700831025, 0.85, 0.0, 0.0, 0.08333333333333333, 0.4036629030770375, 0.4599637228876774, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.875011], dtype=float32), -0.64951867]. 
=============================================
[2019-04-24 10:28:24,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0719039e-01 1.4870233e-03 1.5801642e-03 3.6327013e-09 2.8164279e-13
 1.3067458e-10 3.0191910e-12 2.2169032e-04 2.8952071e-01 2.7083514e-13
 1.5804959e-14], sum to 1.0000
[2019-04-24 10:28:24,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4296
[2019-04-24 10:28:24,055] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.8, 90.66666666666667, 0.0, 0.0, 19.0, 24.24786651386251, 0.2308080997306279, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1644000.0000, 
sim time next is 1645200.0000, 
raw observation next is [6.6, 93.0, 0.0, 0.0, 19.0, 23.95956384873162, 0.1959576008779803, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6454293628808865, 0.93, 0.0, 0.0, 0.08333333333333333, 0.49663032072763497, 0.56531920029266, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9209308], dtype=float32), -0.6235597]. 
=============================================
[2019-04-24 10:28:24,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1556226e-01 7.2955794e-05 3.9866884e-04 2.4181788e-09 1.8387620e-13
 1.2372889e-10 8.0936944e-13 8.0224745e-05 3.8388583e-01 3.2468478e-13
 1.0358461e-14], sum to 1.0000
[2019-04-24 10:28:24,837] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0223
[2019-04-24 10:28:24,860] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 78.33333333333333, 0.0, 0.0, 22.5, 23.15156915959175, 0.1000018194711039, 1.0, 1.0, 55.0, 72.71971125188007], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1021200.0000, 
sim time next is 1022400.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 22.5, 23.75543292671386, 0.02837848094299989, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.8614958448753465, 0.77, 0.0, 0.0, 0.375, 0.4796194105594882, 0.5094594936476666, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9517773], dtype=float32), 0.7728122]. 
=============================================
[2019-04-24 10:28:25,022] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.10966527e-01 5.34664374e-04 5.17943699e-04 1.14980265e-08
 1.52680047e-13 2.09815887e-10 4.79257129e-12 2.92130455e-04
 2.87688792e-01 3.99201017e-13 1.89114173e-13], sum to 1.0000
[2019-04-24 10:28:25,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2099
[2019-04-24 10:28:25,036] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 95.0, 15.0, 0.0, 22.5, 24.39423511685294, 0.1627373823828568, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1356000.0000, 
sim time next is 1357200.0000, 
raw observation next is [0.5, 96.0, 9.0, 0.0, 22.5, 24.28343617582389, 0.1141254983326465, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.96, 0.03, 0.0, 0.375, 0.5236196813186575, 0.5380418327775488, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2664333], dtype=float32), -0.24639142]. 
=============================================
[2019-04-24 10:28:28,235] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.5750166e-01 3.3486731e-04 3.0025485e-04 3.8465191e-09 1.7209587e-13
 3.2910605e-10 3.7023392e-12 4.3371264e-04 2.4142958e-01 4.7802447e-13
 1.9104583e-13], sum to 1.0000
[2019-04-24 10:28:28,296] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2629
[2019-04-24 10:28:28,362] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.9, 82.66666666666667, 0.0, 0.0, 19.0, 24.35612420514719, 0.3091518085830026, 0.0, 1.0, 55.0, 65.08934639887751], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1575600.0000, 
sim time next is 1576800.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 19.0, 24.79829335177042, 0.2268941726928843, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.6011080332409973, 0.82, 0.0, 0.0, 0.08333333333333333, 0.5665244459808682, 0.5756313908976282, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30744505], dtype=float32), 2.5733237]. 
=============================================
[2019-04-24 10:28:28,445] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.02302361e-01 1.80469826e-04 3.32687632e-04 1.09215215e-08
 2.65170806e-13 2.88064711e-10 4.07847714e-12 1.25887600e-04
 1.97058678e-01 2.04127934e-13 4.80922844e-14], sum to 1.0000
[2019-04-24 10:28:28,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5249
[2019-04-24 10:28:28,502] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 90.66666666666666, 0.0, 0.0, 22.5, 22.39520907360606, -0.1986042137643285, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1449600.0000, 
sim time next is 1450800.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 22.2635068245693, -0.2242553024243402, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.3552922353807751, 0.42524823252522, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5139118], dtype=float32), -0.6207674]. 
=============================================
[2019-04-24 10:28:31,002] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6191369e-01 1.1946850e-02 1.0752026e-03 2.5039602e-08 5.1714037e-13
 6.3220457e-10 1.7795241e-11 3.4693172e-04 3.2471734e-01 1.1832269e-12
 2.1799172e-13], sum to 1.0000
[2019-04-24 10:28:31,074] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5816
[2019-04-24 10:28:31,114] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 54.5, 0.0, 22.5, 23.37902031052427, -0.01829379673878716, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1330800.0000, 
sim time next is 1332000.0000, 
raw observation next is [0.5, 92.0, 73.5, 0.0, 22.5, 23.42942509708685, -0.01579909869402911, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4764542936288089, 0.92, 0.245, 0.0, 0.375, 0.4524520914239041, 0.494733633768657, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5829016], dtype=float32), -2.3874054]. 
=============================================
[2019-04-24 10:28:31,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2582070e-01 6.0949853e-04 1.1886617e-03 2.4630461e-08 7.9123643e-13
 5.9457278e-10 2.0340585e-11 3.0448998e-04 3.7207660e-01 1.1362185e-12
 2.5786846e-13], sum to 1.0000
[2019-04-24 10:28:31,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6001
[2019-04-24 10:28:31,793] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 23.19601538928116, -0.1396650738529226, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1390800.0000, 
sim time next is 1392000.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 22.59879955553598, -0.2445628393270756, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.38323329629466496, 0.4184790535576415, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06753409], dtype=float32), 0.3412548]. 
=============================================
[2019-04-24 10:28:35,939] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.0673320e-01 3.6509754e-04 6.4384169e-04 5.2311635e-09 3.3006460e-12
 1.2007569e-09 4.9063982e-11 2.2288780e-04 3.9203501e-01 2.9467461e-12
 1.2824922e-13], sum to 1.0000
[2019-04-24 10:28:35,957] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5037
[2019-04-24 10:28:36,016] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 19.0, 21.75788044709798, -0.2838275014342467, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1719600.0000, 
sim time next is 1720800.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 21.60875693233507, -0.314579427653468, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.30072974436125577, 0.3951401907821774, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8964804], dtype=float32), 0.8189137]. 
=============================================
[2019-04-24 10:28:36,989] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.4987549e-01 3.8331060e-04 5.7335221e-04 2.0829571e-08 1.6837753e-13
 3.9990428e-10 1.5561732e-11 1.7881044e-04 2.4898909e-01 3.2080743e-13
 2.2702532e-13], sum to 1.0000
[2019-04-24 10:28:37,050] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7896
[2019-04-24 10:28:37,177] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 95.0, 91.0, 0.0, 22.5, 23.05858220503139, -0.1958641467816935, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1424400.0000, 
sim time next is 1425600.0000, 
raw observation next is [0.0, 95.0, 93.0, 0.0, 22.5, 23.46779958757931, -0.0894032966259621, 1.0, 1.0, 55.0, 76.53482302393942], 
processed observation next is [1.0, 0.5217391304347826, 0.46260387811634357, 0.95, 0.31, 0.0, 0.375, 0.45564996563160926, 0.47019890112467927, 1.0, 1.0, 0.8, 0.7653482302393942], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4765123], dtype=float32), 0.95456326]. 
=============================================
[2019-04-24 10:28:37,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4909981e-01 2.0393489e-04 3.9818656e-04 2.0661397e-09 2.1121572e-13
 7.4951427e-11 3.7393260e-13 6.4053078e-05 1.5023392e-01 4.6099514e-14
 7.0399060e-15], sum to 1.0000
[2019-04-24 10:28:37,587] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8351
[2019-04-24 10:28:37,633] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 49.0, 171.5, 20.66666666666666, 22.5, 25.26787294846694, 0.3725116682574126, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1603200.0000, 
sim time next is 1604400.0000, 
raw observation next is [13.8, 49.0, 170.8333333333333, 0.0, 22.5, 25.39745868894462, 0.4088618513366051, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.844875346260388, 0.49, 0.5694444444444443, 0.0, 0.375, 0.6164548907453851, 0.6362872837788683, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8158695], dtype=float32), 1.6915871]. 
=============================================
[2019-04-24 10:28:47,305] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.31592655e-01 1.17949647e-04 1.21894362e-03 7.24876692e-09
 5.56558380e-14 9.09490885e-12 2.07955029e-12 1.40027012e-04
 2.66930401e-01 1.01325164e-13 3.25992793e-14], sum to 1.0000
[2019-04-24 10:28:47,307] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6276
[2019-04-24 10:28:47,353] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.4, 86.0, 0.0, 0.0, 19.0, 24.93296932862911, 0.3463882818102348, 0.0, 1.0, 55.0, 44.76175737347297], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1566000.0000, 
sim time next is 1567200.0000, 
raw observation next is [4.466666666666667, 85.66666666666667, 0.0, 0.0, 19.0, 24.86237142352493, 0.2061114125976302, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5863342566943676, 0.8566666666666667, 0.0, 0.0, 0.08333333333333333, 0.5718642852937442, 0.5687038041992101, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0854193], dtype=float32), -1.6170228]. 
=============================================
[2019-04-24 10:28:48,274] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.0384636e-01 1.7641386e-04 2.3784062e-04 3.3582874e-09 1.3889711e-13
 1.9453736e-10 1.0505528e-12 6.8085705e-05 1.9567120e-01 2.4314790e-13
 5.6059995e-15], sum to 1.0000
[2019-04-24 10:28:48,274] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0804
[2019-04-24 10:28:48,330] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 84.0, 95.0, 0.0, 22.5, 24.65730327153473, 0.2017216772473433, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1684800.0000, 
sim time next is 1686000.0000, 
raw observation next is [1.1, 85.33333333333334, 103.0, 0.0, 22.5, 24.52050066531511, 0.1626445626166505, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.8533333333333334, 0.3433333333333333, 0.0, 0.375, 0.543375055442926, 0.5542148542055502, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0628958], dtype=float32), 1.4207569]. 
=============================================
[2019-04-24 10:28:55,035] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-04-24 10:28:55,062] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:28:55,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:28:55,087] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run11
[2019-04-24 10:28:55,148] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:28:55,149] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:28:55,161] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:28:55,164] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run11
[2019-04-24 10:28:55,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:28:55,240] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run11
[2019-04-24 10:31:11,449] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2930.3561 83455.3715 97.1813
[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,485] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:11,684] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,287] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2697.9688 94129.7346 -332.7088
[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,314] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:20,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:25,906] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2618.2099 96900.7763 -411.8353
[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:25,926] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:31:26,928] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 500000, evaluation results [500000.0, 2697.9687827016155, 94129.73463604985, -332.70882936182693, 2930.3560504402985, 83455.37149937288, 97.18126494773169, 2618.2099282654453, 96900.77631823505, -411.83529800103116]
[2019-04-24 10:31:29,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1216927e-01 7.3530426e-04 5.3238781e-04 1.1990909e-07 2.3811725e-11
 4.7157922e-09 7.6094832e-11 1.9349931e-04 3.8636950e-01 4.2581147e-12
 1.0309650e-12], sum to 1.0000
[2019-04-24 10:31:29,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3148
[2019-04-24 10:31:29,274] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 22.5, 22.0600980012848, -0.2474075384942159, 1.0, 1.0, 55.0, 102.3394962552943], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2142000.0000, 
sim time next is 2143200.0000, 
raw observation next is [-5.2, 77.0, 0.0, 0.0, 22.5, 23.10063108429434, -0.336401903184135, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.31855955678670367, 0.77, 0.0, 0.0, 0.375, 0.4250525903578615, 0.387866032271955, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1953565], dtype=float32), 3.1375597]. 
=============================================
[2019-04-24 10:31:39,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8900226e-01 9.5788657e-04 1.6599293e-03 2.3926079e-08 2.3177668e-11
 4.1873744e-09 4.1638776e-10 3.8943774e-04 5.0799042e-01 1.7632370e-11
 5.0523270e-12], sum to 1.0000
[2019-04-24 10:31:39,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9871
[2019-04-24 10:31:39,665] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 85.66666666666667, 0.0, 0.0, 19.0, 20.97817354746206, -0.6138852875144062, 0.0, 1.0, 55.0, 52.92500907069928], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1989600.0000, 
sim time next is 1990800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 19.0, 21.30977389113858, -0.5825159845532829, 0.0, 1.0, 55.0, 51.585014128607924], 
processed observation next is [1.0, 0.043478260869565216, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.275814490928215, 0.3058280051489057, 0.0, 1.0, 0.8, 0.5158501412860792], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08936103], dtype=float32), 0.7819829]. 
=============================================
[2019-04-24 10:31:42,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7153815e-01 2.5853771e-03 1.9513402e-03 5.0045188e-08 8.0789160e-11
 9.1684953e-09 6.0091399e-10 1.0225627e-03 4.2290258e-01 7.5660971e-11
 1.8176131e-11], sum to 1.0000
[2019-04-24 10:31:42,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4750
[2019-04-24 10:31:42,373] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.1, 58.0, 0.0, 0.0, 19.0, 20.75025619350884, -0.5526514945891252, 0.0, 1.0, 55.0, 78.39312596376331], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2328000.0000, 
sim time next is 2329200.0000, 
raw observation next is [-2.3, 59.0, 0.0, 0.0, 19.0, 21.17438411658359, -0.655972604365371, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.3988919667590028, 0.59, 0.0, 0.0, 0.08333333333333333, 0.26453200971529905, 0.281342465211543, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6062811], dtype=float32), 0.3964131]. 
=============================================
[2019-04-24 10:31:45,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2875813e-01 4.0050503e-03 8.8860551e-03 4.7423569e-06 3.3127673e-08
 6.2624821e-07 1.1084963e-07 2.0045927e-03 3.5634062e-01 3.2600767e-08
 2.8112932e-09], sum to 1.0000
[2019-04-24 10:31:45,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2976
[2019-04-24 10:31:45,114] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 37.0, 0.0, 0.0, 19.0, 19.81075006163273, -0.8132726354447891, 0.0, 1.0, 55.0, 82.66708660281519], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2504400.0000, 
sim time next is 2505600.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 19.0, 20.47598878645438, -0.9042088647790242, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.38, 0.0, 0.0, 0.08333333333333333, 0.20633239887119834, 0.1985970450736586, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9514617], dtype=float32), -0.47596383]. 
=============================================
[2019-04-24 10:31:48,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.49910176e-01 6.55793701e-04 1.31867174e-03 3.07680423e-08
 8.07317060e-12 1.29873390e-09 1.03384384e-10 7.82947100e-05
 2.48036966e-01 3.08805672e-12 1.43539510e-12], sum to 1.0000
[2019-04-24 10:31:48,301] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0785
[2019-04-24 10:31:48,314] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.1, 69.0, 55.33333333333333, 47.49999999999999, 22.5, 23.43167061145319, -0.3122044830042073, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2218800.0000, 
sim time next is 2220000.0000, 
raw observation next is [-4.3, 70.0, 29.66666666666667, 0.0, 22.5, 22.75561244871927, -0.5244715781230452, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.34349030470914127, 0.7, 0.0988888888888889, 0.0, 0.375, 0.39630103739327244, 0.3251761406256516, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9850, 
noisyNet noise sample is [array([1.6381865], dtype=float32), -1.294631]. 
=============================================
[2019-04-24 10:31:48,333] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.392296]
 [65.10825 ]
 [63.662884]
 [63.71552 ]
 [63.49139 ]
 [62.221546]
 [62.440704]
 [62.69709 ]
 [62.839054]
 [61.857063]
 [62.046185]
 [60.78429 ]
 [61.02319 ]
 [61.387627]
 [61.825703]
 [62.198963]
 [62.101593]
 [62.33659 ]
 [62.5215  ]
 [62.309082]
 [63.263912]
 [62.119278]
 [62.374264]
 [62.52624 ]
 [61.550663]], R is [[63.7666626 ]
 [64.1289978 ]
 [63.48770905]
 [63.85283279]
 [64.21430969]
 [63.57216644]
 [63.9296608 ]
 [64.2903595 ]
 [64.64746094]
 [64.00098419]
 [64.36097717]
 [63.71736908]
 [63.08019638]
 [62.44939423]
 [61.82490158]
 [61.65429688]
 [61.87243652]
 [62.25057983]
 [62.62807465]
 [62.00179291]
 [62.3817749 ]
 [61.75795746]
 [61.68455124]
 [61.96486282]
 [61.34521484]].
[2019-04-24 10:31:51,639] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.7838669e-01 4.5371489e-03 1.3185113e-03 1.5697471e-07 3.2803343e-11
 6.6199326e-09 3.5330541e-10 9.8251156e-04 3.1477496e-01 6.6450123e-11
 3.6503153e-12], sum to 1.0000
[2019-04-24 10:31:51,641] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4015
[2019-04-24 10:31:51,722] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 51.16666666666667, 293.5, 22.5, 21.47861950641515, -0.5347646670272322, 1.0, 1.0, 55.0, 87.5471757863663], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2191200.0000, 
sim time next is 2192400.0000, 
raw observation next is [-5.6, 75.0, 71.5, 356.5, 22.5, 22.24596774232462, -0.5849917566733471, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.30747922437673136, 0.75, 0.23833333333333334, 0.3939226519337017, 0.375, 0.3538306451937183, 0.305002747775551, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8194, 
noisyNet noise sample is [array([0.4195693], dtype=float32), -0.13949092]. 
=============================================
[2019-04-24 10:31:52,980] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8609284e-01 1.3400193e-02 1.8747987e-02 7.5919202e-06 5.3857420e-08
 1.8377740e-06 4.4176119e-07 4.1328454e-03 5.7761610e-01 3.0049900e-08
 9.7288311e-09], sum to 1.0000
[2019-04-24 10:31:52,980] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4354
[2019-04-24 10:31:53,078] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.166666666666667, 32.66666666666666, 86.66666666666667, 831.6666666666667, 19.0, 19.35948667372147, -1.073639376345883, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2461200.0000, 
sim time next is 2462400.0000, 
raw observation next is [-0.6, 31.0, 88.0, 837.0, 19.0, 19.55056825493526, -0.8647685906182853, 0.0, 1.0, 55.0, 73.42415989118193], 
processed observation next is [0.0, 0.5217391304347826, 0.44598337950138506, 0.31, 0.29333333333333333, 0.9248618784530387, 0.08333333333333333, 0.12921402124460504, 0.21174380312723826, 0.0, 1.0, 0.8, 0.7342415989118193], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02677167], dtype=float32), 0.9684121]. 
=============================================
[2019-04-24 10:31:54,243] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.35836643e-01 1.05949165e-02 1.67995063e-03 8.58264713e-08
 8.77459286e-11 2.38082034e-08 9.97757210e-10 1.39296101e-03
 5.50495386e-01 3.40860049e-11 2.72098611e-11], sum to 1.0000
[2019-04-24 10:31:54,244] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5770
[2019-04-24 10:31:54,277] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 20.23598604526757, -0.7497641920642025, 0.0, 1.0, 55.0, 84.03342133669761], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2172000.0000, 
sim time next is 2173200.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 20.82153849804592, -0.6845553743919736, 0.0, 1.0, 55.0, 53.61833940034333], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.23512820817049343, 0.2718148752026755, 0.0, 1.0, 0.8, 0.5361833940034333], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0590994], dtype=float32), 1.8852776]. 
=============================================
[2019-04-24 10:31:55,395] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.7402015e-01 1.9062615e-03 6.6721521e-04 5.8990231e-08 2.4693247e-12
 4.7948361e-09 6.6688460e-11 1.2934113e-04 4.2327690e-01 1.7945020e-11
 3.3634194e-12], sum to 1.0000
[2019-04-24 10:31:55,397] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7495
[2019-04-24 10:31:55,461] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.833333333333334, 71.0, 114.5, 75.16666666666664, 22.5, 23.02371461999088, -0.4241387561921323, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2197200.0000, 
sim time next is 2198400.0000, 
raw observation next is [-4.666666666666667, 71.0, 121.3333333333333, 0.0, 22.5, 22.86849848363257, -0.2995052318713152, 1.0, 1.0, 55.0, 68.87271035246883], 
processed observation next is [1.0, 0.43478260869565216, 0.3333333333333333, 0.71, 0.40444444444444433, 0.0, 0.375, 0.4057082069693809, 0.4001649227095616, 1.0, 1.0, 0.8, 0.6887271035246882], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7160618], dtype=float32), -0.6808205]. 
=============================================
[2019-04-24 10:31:57,143] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.0932560e-01 9.2923203e-03 2.3163164e-02 1.1734707e-06 8.3519760e-09
 1.7833010e-07 5.9136816e-08 2.4666889e-03 5.5575079e-01 1.3331917e-08
 4.3957435e-10], sum to 1.0000
[2019-04-24 10:31:57,151] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9133
[2019-04-24 10:31:57,271] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.566666666666667, 52.0, 181.1666666666667, 325.6666666666666, 19.0, 19.58269959441254, -0.9644259578709707, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2374800.0000, 
sim time next is 2376000.0000, 
raw observation next is [-1.2, 47.0, 209.5, 365.0, 19.0, 19.83860794390923, -0.7050549221788066, 0.0, 1.0, 55.0, 81.23588607655873], 
processed observation next is [0.0, 0.5217391304347826, 0.42936288088642666, 0.47, 0.6983333333333334, 0.40331491712707185, 0.08333333333333333, 0.15321732865910262, 0.26498169260706445, 0.0, 1.0, 0.8, 0.8123588607655873], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5938462], dtype=float32), 2.3984828]. 
=============================================
[2019-04-24 10:32:04,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.00649297e-01 4.95625241e-03 3.55803524e-03 1.48792083e-07
 6.13491410e-11 1.42401948e-08 7.89441623e-10 1.68310909e-03
 3.89153183e-01 1.07441334e-10 8.03505179e-11], sum to 1.0000
[2019-04-24 10:32:04,371] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9479
[2019-04-24 10:32:04,466] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.2, 75.33333333333334, 0.0, 0.0, 19.0, 20.48854415687123, -0.8260331405427629, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2604000.0000, 
sim time next is 2605200.0000, 
raw observation next is [-5.4, 76.66666666666667, 0.0, 0.0, 19.0, 20.52552912652593, -0.6170749341392666, 0.0, 1.0, 55.0, 84.24701290918762], 
processed observation next is [1.0, 0.13043478260869565, 0.31301939058171746, 0.7666666666666667, 0.0, 0.0, 0.08333333333333333, 0.21046076054382765, 0.2943083552869111, 0.0, 1.0, 0.8, 0.8424701290918761], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3083216], dtype=float32), 0.49220136]. 
=============================================
[2019-04-24 10:32:15,088] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.5227221e-01 1.1476945e-02 6.7582107e-03 3.9753249e-07 1.3833942e-10
 2.4688944e-08 1.6766591e-09 1.1704757e-03 5.2832174e-01 1.6881785e-10
 1.5380600e-10], sum to 1.0000
[2019-04-24 10:32:15,089] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0676
[2019-04-24 10:32:15,148] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 13.33333333333333, 54.99999999999999, 22.5, 21.31071736590409, -0.6182018862644006, 1.0, 1.0, 55.0, 68.40922932702617], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2706000.0000, 
sim time next is 2707200.0000, 
raw observation next is [-15.0, 83.0, 40.0, 165.0, 22.5, 21.26265047579779, -0.7619135573520563, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.04709141274238226, 0.83, 0.13333333333333333, 0.18232044198895028, 0.375, 0.27188753964981593, 0.24602881421598122, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15390557], dtype=float32), -1.501262]. 
=============================================
[2019-04-24 10:32:20,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6470832e-01 1.7835126e-03 1.7559774e-03 1.3019027e-07 1.9448419e-11
 1.0094823e-08 1.9065349e-10 4.2053664e-04 3.3133149e-01 2.4367832e-11
 9.0277048e-12], sum to 1.0000
[2019-04-24 10:32:20,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5985
[2019-04-24 10:32:20,298] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 48.66666666666667, 90.16666666666666, 687.0, 22.5, 24.73079261386246, 0.008414565255873854, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3338400.0000, 
sim time next is 3339600.0000, 
raw observation next is [-2.333333333333333, 47.33333333333333, 82.5, 645.1666666666667, 22.5, 24.19244560190972, 0.04190805508210468, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3979686057248385, 0.4733333333333333, 0.275, 0.7128913443830571, 0.375, 0.5160371334924768, 0.5139693516940349, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7677563], dtype=float32), -0.60161394]. 
=============================================
[2019-04-24 10:32:28,364] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1183773e-01 4.7021263e-04 8.0996615e-05 1.2086052e-09 7.4632466e-14
 5.7926691e-11 6.0718287e-13 3.4033870e-05 1.8757705e-01 4.0978451e-14
 1.0635602e-15], sum to 1.0000
[2019-04-24 10:32:28,364] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6233
[2019-04-24 10:32:28,383] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 100.0, 33.0, 307.5, 22.5, 25.12904034631938, 0.351472679252995, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3171600.0000, 
sim time next is 3172800.0000, 
raw observation next is [6.0, 100.0, 16.33333333333333, 179.8333333333333, 22.5, 25.26142735890224, 0.2882588914864573, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6288088642659281, 1.0, 0.05444444444444443, 0.19871086556169423, 0.375, 0.6051189465751866, 0.5960862971621524, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5181084], dtype=float32), 0.45803425]. 
=============================================
[2019-04-24 10:32:28,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.5201038e-01 1.1937472e-03 7.3804415e-04 7.2567140e-08 5.2116363e-11
 1.1293350e-08 2.6670180e-10 2.8485226e-04 3.4577289e-01 2.9435721e-11
 1.7144203e-12], sum to 1.0000
[2019-04-24 10:32:28,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4692
[2019-04-24 10:32:28,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 58.33333333333334, 0.0, 0.0, 19.0, 22.59003046006943, -0.1916175231822255, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3356400.0000, 
sim time next is 3357600.0000, 
raw observation next is [-3.666666666666667, 61.66666666666666, 0.0, 0.0, 19.0, 22.35184582971765, -0.234572464512919, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.3610341643582641, 0.6166666666666666, 0.0, 0.0, 0.08333333333333333, 0.3626538191431375, 0.42180917849569366, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01195251], dtype=float32), -1.1859963]. 
=============================================
[2019-04-24 10:32:29,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1888903e-01 1.1800292e-03 8.1438752e-04 6.4415167e-09 2.2432984e-12
 3.5172390e-10 9.1814112e-11 1.1734597e-03 3.7794316e-01 2.7754613e-12
 3.4960050e-13], sum to 1.0000
[2019-04-24 10:32:29,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5070
[2019-04-24 10:32:29,370] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 97.33333333333334, 0.0, 0.0, 19.0, 22.54611370785937, -0.2728578515700974, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3219600.0000, 
sim time next is 3220800.0000, 
raw observation next is [-3.0, 94.66666666666666, 0.0, 0.0, 19.0, 21.79453761361158, -0.4091066015398195, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.3795013850415513, 0.9466666666666665, 0.0, 0.0, 0.08333333333333333, 0.3162114678009651, 0.36363113282006015, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7591438], dtype=float32), -0.9143596]. 
=============================================
[2019-04-24 10:32:30,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6170745e-01 7.4087072e-04 2.8903496e-03 3.2538612e-08 6.3308130e-12
 5.5880287e-09 2.9238018e-10 4.0407080e-04 6.3425720e-01 1.5549199e-11
 3.9803842e-12], sum to 1.0000
[2019-04-24 10:32:30,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6259
[2019-04-24 10:32:30,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.6666666666666666, 100.0, 0.0, 0.0, 19.0, 21.44794859328533, -0.5261218603963722, 0.0, 1.0, 55.0, 49.61298592454105], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3112800.0000, 
sim time next is 3114000.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 19.0, 21.86998825817919, -0.4627295381724347, 0.0, 1.0, 55.0, 48.54750938092601], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.08333333333333333, 0.3224990215149326, 0.3457568206091885, 0.0, 1.0, 0.8, 0.48547509380926007], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23906052], dtype=float32), -0.8170141]. 
=============================================
[2019-04-24 10:32:30,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1180245e-01 9.3835749e-04 1.9070272e-04 1.0485484e-08 8.6577566e-13
 5.6978983e-10 2.2724299e-12 2.3187778e-04 1.8683656e-01 6.4012288e-13
 1.9760609e-13], sum to 1.0000
[2019-04-24 10:32:30,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2121
[2019-04-24 10:32:30,834] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 73.0, 63.33333333333334, 540.1666666666667, 22.5, 25.51506220639482, 0.2586035779858532, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3255600.0000, 
sim time next is 3256800.0000, 
raw observation next is [-3.666666666666667, 75.0, 50.66666666666667, 443.1666666666667, 22.5, 24.94828544106322, 0.3024221862284182, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3610341643582641, 0.75, 0.1688888888888889, 0.48968692449355433, 0.375, 0.5790237867552683, 0.6008073954094727, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.70021677], dtype=float32), 1.1208642]. 
=============================================
[2019-04-24 10:32:31,374] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.2577878e-01 8.4972056e-04 3.0842313e-04 1.8182114e-08 5.0374662e-13
 1.4629613e-09 2.0431093e-11 2.1275949e-04 1.7285031e-01 4.6019650e-13
 1.3959699e-13], sum to 1.0000
[2019-04-24 10:32:31,374] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7553
[2019-04-24 10:32:31,405] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 47.66666666666667, 114.0, 797.3333333333333, 22.5, 24.73896946311305, 0.3151523199240036, 1.0, 1.0, 55.0, 89.81550398166237], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3410400.0000, 
sim time next is 3411600.0000, 
raw observation next is [3.0, 46.33333333333334, 115.3333333333333, 806.1666666666666, 22.5, 25.45800213949867, 0.2485307712275163, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.46333333333333343, 0.3844444444444443, 0.8907918968692449, 0.375, 0.6215001782915559, 0.5828435904091721, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7770988], dtype=float32), -0.2909992]. 
=============================================
[2019-04-24 10:32:32,228] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5770738e-01 6.1029857e-03 7.2415611e-03 1.1426538e-06 3.5418226e-09
 3.0945313e-07 3.3547586e-08 3.0632871e-03 5.2588332e-01 5.8941301e-09
 3.0250685e-10], sum to 1.0000
[2019-04-24 10:32:32,229] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9963
[2019-04-24 10:32:32,304] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.333333333333334, 69.0, 0.0, 0.0, 19.0, 21.3530398239385, -0.5456634526966152, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3558000.0000, 
sim time next is 3559200.0000, 
raw observation next is [-4.666666666666666, 67.0, 0.0, 0.0, 19.0, 21.3925286597386, -0.3591963920301906, 0.0, 1.0, 55.0, 79.00234899079399], 
processed observation next is [0.0, 0.17391304347826086, 0.33333333333333337, 0.67, 0.0, 0.0, 0.08333333333333333, 0.2827107216448832, 0.3802678693232698, 0.0, 1.0, 0.8, 0.7900234899079399], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.167908], dtype=float32), 1.6118144]. 
=============================================
[2019-04-24 10:32:32,694] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0773132e-01 1.0008192e-02 8.2672974e-03 3.6286519e-06 1.5661788e-08
 6.1159096e-07 8.1579529e-08 4.1395957e-03 4.6984932e-01 5.9340093e-09
 1.5428088e-09], sum to 1.0000
[2019-04-24 10:32:32,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1045
[2019-04-24 10:32:32,765] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.666666666666667, 70.0, 73.83333333333334, 374.3333333333334, 19.0, 19.59945918346275, -0.8674936339051769, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3572400.0000, 
sim time next is 3573600.0000, 
raw observation next is [-6.333333333333334, 70.0, 90.0, 466.8333333333333, 19.0, 19.49061131060921, -0.8803279599574244, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.28716528162511545, 0.7, 0.3, 0.5158379373848987, 0.08333333333333333, 0.12421760921743423, 0.20655734668085854, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.76735574], dtype=float32), 1.6757005]. 
=============================================
[2019-04-24 10:32:34,515] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.9325697e-01 7.8816019e-04 1.5079710e-03 7.8816980e-09 1.9069097e-12
 2.5923191e-10 1.1395071e-11 3.0754466e-04 3.0413941e-01 5.1420001e-13
 2.6144800e-14], sum to 1.0000
[2019-04-24 10:32:34,523] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5065
[2019-04-24 10:32:34,558] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 95.33333333333334, 0.0, 0.0, 19.0, 23.06320426837107, -0.06065834129528811, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3198000.0000, 
sim time next is 3199200.0000, 
raw observation next is [1.333333333333333, 97.66666666666666, 0.0, 0.0, 19.0, 22.8346194688242, -0.09735153461153412, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4995383194829178, 0.9766666666666666, 0.0, 0.0, 0.08333333333333333, 0.40288495573535005, 0.46754948846282196, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.77352184], dtype=float32), -0.44242603]. 
=============================================
[2019-04-24 10:32:35,378] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.8064264e-01 3.1914745e-04 1.3217047e-03 2.9766030e-09 6.5461438e-13
 5.4260102e-10 1.5461908e-11 1.1940670e-03 4.1652238e-01 4.3439942e-13
 1.4039224e-13], sum to 1.0000
[2019-04-24 10:32:35,379] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9817
[2019-04-24 10:32:35,423] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 94.66666666666666, 0.0, 0.0, 19.0, 22.59392315504387, -0.1016323457753628, 0.0, 1.0, 55.0, 69.40576221835002], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3220800.0000, 
sim time next is 3222000.0000, 
raw observation next is [-3.0, 92.0, 0.0, 0.0, 19.0, 22.92272933843444, -0.0675034250078058, 0.0, 1.0, 55.0, 49.701832911256005], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.92, 0.0, 0.0, 0.08333333333333333, 0.41022744486953666, 0.4774988583307314, 0.0, 1.0, 0.8, 0.49701832911256005], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5771008], dtype=float32), -0.34743637]. 
=============================================
[2019-04-24 10:32:36,738] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.4680830e-01 4.9529923e-03 1.2936158e-02 1.9106951e-06 6.4951144e-10
 1.4665038e-07 1.1801497e-08 1.9905642e-03 4.3330994e-01 1.8123192e-09
 2.4286029e-10], sum to 1.0000
[2019-04-24 10:32:36,739] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0622
[2019-04-24 10:32:36,767] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.333333333333334, 70.0, 90.0, 466.8333333333333, 19.0, 21.89822899849244, -0.4218542600785109, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3573600.0000, 
sim time next is 3574800.0000, 
raw observation next is [-6.0, 70.0, 94.0, 550.5, 19.0, 21.39050522441459, -0.5151754438179333, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.296398891966759, 0.7, 0.31333333333333335, 0.6082872928176796, 0.08333333333333333, 0.2825421020345491, 0.3282748520606889, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.64238626], dtype=float32), -0.74996704]. 
=============================================
[2019-04-24 10:32:41,932] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6934928e-01 8.6975686e-04 1.7140972e-03 3.3735805e-09 8.7849172e-13
 9.3818098e-10 4.7102634e-12 7.2585608e-05 2.2799425e-01 1.1893045e-12
 1.3850058e-13], sum to 1.0000
[2019-04-24 10:32:41,933] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9994
[2019-04-24 10:32:41,998] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 81.33333333333334, 0.0, 0.0, 19.0, 23.65108561227958, -0.1068527968962482, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3458400.0000, 
sim time next is 3459600.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 19.0, 23.37037940411312, 0.00891711587277721, 0.0, 1.0, 55.0, 69.0202818461891], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.79, 0.0, 0.0, 0.08333333333333333, 0.4475316170094266, 0.5029723719575924, 0.0, 1.0, 0.8, 0.690202818461891], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.92660147], dtype=float32), -1.2049361]. 
=============================================
[2019-04-24 10:32:44,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9169942e-01 5.2860226e-03 5.7507283e-03 3.4352397e-06 1.2714800e-08
 7.6068716e-07 4.3734588e-08 7.8277243e-03 3.8943174e-01 2.6270586e-08
 1.5544713e-09], sum to 1.0000
[2019-04-24 10:32:44,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7698
[2019-04-24 10:32:44,332] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [9.666666666666666, 25.66666666666666, 0.0, 0.0, 19.0, 21.09481873569033, -0.6501196254687226, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3649200.0000, 
sim time next is 3650400.0000, 
raw observation next is [10.0, 25.0, 0.0, 0.0, 19.0, 21.49146202078587, -0.3782936151726247, 0.0, 1.0, 55.0, 79.54560638280165], 
processed observation next is [0.0, 0.2608695652173913, 0.739612188365651, 0.25, 0.0, 0.0, 0.08333333333333333, 0.2909551683988226, 0.3739021282757918, 0.0, 1.0, 0.8, 0.7954560638280165], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2603481], dtype=float32), -0.11470563]. 
=============================================
[2019-04-24 10:32:44,721] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.3412472e-01 7.0003379e-04 2.7970953e-03 4.5551300e-08 2.4050774e-12
 2.4219109e-09 4.0414391e-11 1.7231154e-04 2.6220569e-01 1.8657320e-11
 6.6912567e-13], sum to 1.0000
[2019-04-24 10:32:44,722] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6583
[2019-04-24 10:32:44,747] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 19.0, 23.19582881731586, -0.1707452176990071, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3542400.0000, 
sim time next is 3543600.0000, 
raw observation next is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 22.59340607766607, -0.2791249513999605, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6000000000000001, 0.0, 0.0, 0.08333333333333333, 0.3827838398055059, 0.4069583495333465, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.94066525], dtype=float32), -0.1310153]. 
=============================================
[2019-04-24 10:32:45,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2521147e-01 5.6978257e-04 7.6521380e-04 2.2166679e-08 4.5517154e-13
 1.5503930e-09 6.8225447e-12 6.2901265e-05 1.7339058e-01 1.3632161e-12
 5.2764173e-13], sum to 1.0000
[2019-04-24 10:32:45,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9308
[2019-04-24 10:32:45,868] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.0, 41.0, 41.0, 365.0, 22.5, 26.573687898358, 0.5221731040569234, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3862800.0000, 
sim time next is 3864000.0000, 
raw observation next is [2.666666666666667, 43.33333333333334, 25.66666666666666, 241.0, 22.5, 26.53654791772056, 0.6048414726070314, 1.0, 1.0, 55.0, 58.09103617140465], 
processed observation next is [1.0, 0.7391304347826086, 0.5364727608494922, 0.4333333333333334, 0.08555555555555554, 0.2662983425414365, 0.375, 0.7113789931433802, 0.7016138242023437, 1.0, 1.0, 0.8, 0.5809103617140465], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22982918], dtype=float32), -0.4634045]. 
=============================================
[2019-04-24 10:32:48,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8159500e-01 1.8842266e-03 3.6517021e-03 1.3555676e-07 3.0791182e-11
 6.2376029e-09 3.4307635e-10 2.0739445e-03 4.1079497e-01 2.4613618e-11
 1.0125656e-11], sum to 1.0000
[2019-04-24 10:32:48,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0011
[2019-04-24 10:32:48,903] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 22.30998050040026, -0.3180739600859558, 0.0, 1.0, 55.0, 53.52201939998372], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3726000.0000, 
sim time next is 3727200.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 22.46295147533479, -0.4554403564722498, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.3719126229445659, 0.3481865478425834, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3710091], dtype=float32), 1.6115705]. 
=============================================
[2019-04-24 10:32:49,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0840440e-01 2.4616807e-03 1.8167964e-03 4.5827724e-07 2.6984737e-10
 6.5875881e-08 4.6117937e-10 5.0672155e-04 3.8680986e-01 2.5117783e-10
 4.5013521e-11], sum to 1.0000
[2019-04-24 10:32:49,507] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8494
[2019-04-24 10:32:49,566] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.333333333333334, 46.33333333333334, 0.0, 0.0, 19.0, 22.42017794076067, -0.2269892731109262, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3964800.0000, 
sim time next is 3966000.0000, 
raw observation next is [-7.666666666666666, 47.66666666666666, 0.0, 0.0, 19.0, 22.66851372057556, 0.009719024813332658, 0.0, 1.0, 55.0, 86.08217446541553], 
processed observation next is [1.0, 0.9130434782608695, 0.25023084025854114, 0.47666666666666657, 0.0, 0.0, 0.08333333333333333, 0.3890428100479634, 0.5032396749377775, 0.0, 1.0, 0.8, 0.8608217446541553], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29567772], dtype=float32), 2.2111917]. 
=============================================
[2019-04-24 10:32:50,144] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.8304527e-01 2.7943479e-03 6.3505997e-03 5.6943344e-07 2.5902878e-09
 2.2775413e-07 1.5992375e-08 1.8365845e-03 3.0597240e-01 1.8830428e-09
 9.7475389e-11], sum to 1.0000
[2019-04-24 10:32:50,146] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2041
[2019-04-24 10:32:50,181] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.333333333333334, 30.33333333333334, 18.16666666666666, 168.0, 19.0, 22.57185531011004, -0.4011125844312098, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3656400.0000, 
sim time next is 3657600.0000, 
raw observation next is [8.0, 32.0, 46.5, 262.0, 19.0, 22.17536799768559, -0.4438717147740006, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.6842105263157896, 0.32, 0.155, 0.28950276243093925, 0.08333333333333333, 0.3479473331404659, 0.35204276174199983, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8234551], dtype=float32), 0.13515034]. 
=============================================
[2019-04-24 10:32:51,359] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8390362e-01 4.3509787e-04 1.3227673e-04 1.7307045e-08 1.0022071e-12
 1.0443149e-09 6.5694542e-12 1.7075229e-04 1.1535826e-01 1.8124033e-12
 3.4651009e-13], sum to 1.0000
[2019-04-24 10:32:51,377] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0962
[2019-04-24 10:32:51,425] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 45.66666666666667, 15.0, 149.1666666666667, 22.5, 25.50277250596943, 0.5532285036720201, 1.0, 1.0, 55.0, 60.84547421379841], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3865200.0000, 
sim time next is 3866400.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 22.5, 26.12302271735719, 0.4693866850965815, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.48, 0.0, 0.0, 0.375, 0.6769185597797659, 0.6564622283655271, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.544215], dtype=float32), 0.8361561]. 
=============================================
[2019-04-24 10:32:54,018] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.2223458e-01 2.8705548e-03 1.4732182e-03 1.8122654e-07 2.3911682e-11
 1.2006401e-08 3.6274939e-10 7.2518038e-04 3.7269631e-01 3.0987900e-11
 5.2030420e-12], sum to 1.0000
[2019-04-24 10:32:54,018] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3610
[2019-04-24 10:32:54,046] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 69.0, 0.0, 0.0, 19.0, 21.99350177946459, -0.479541146844861, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3901200.0000, 
sim time next is 3902400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 21.37896668908582, -0.5640629767573563, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.28158055742381843, 0.3119790077475479, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.6193116], dtype=float32), 0.1291749]. 
=============================================
[2019-04-24 10:32:54,421] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.5202203e-01 8.7062912e-03 1.1692384e-03 2.2058329e-07 2.9121910e-11
 9.3036981e-08 6.5705169e-10 5.0674781e-04 2.3759529e-01 8.6950246e-11
 1.4081979e-11], sum to 1.0000
[2019-04-24 10:32:54,422] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4877
[2019-04-24 10:32:54,511] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 36.66666666666666, 94.0, 504.0, 22.5, 22.72824479613353, -0.3760124681913931, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4092000.0000, 
sim time next is 4093200.0000, 
raw observation next is [-3.0, 38.0, 98.0, 574.0, 22.5, 22.65688228356034, -0.4014876779685372, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.38, 0.32666666666666666, 0.6342541436464089, 0.375, 0.3880735236300283, 0.3661707740104876, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1958675], dtype=float32), 0.21995614]. 
=============================================
[2019-04-24 10:32:57,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0500606e-01 8.6253108e-03 2.9496425e-03 6.4682763e-07 1.5621284e-09
 1.1251816e-07 5.3635554e-09 1.4462942e-03 2.8197190e-01 1.2894132e-09
 2.1212482e-10], sum to 1.0000
[2019-04-24 10:32:57,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0379
[2019-04-24 10:32:57,779] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 39.66666666666666, 0.0, 0.0, 19.0, 20.70910759840821, -0.7051731894629866, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4063200.0000, 
sim time next is 4064400.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 19.0, 20.50170782242178, -0.7470417414548516, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.41, 0.0, 0.0, 0.08333333333333333, 0.20847565186848152, 0.25098608618171614, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.40007848], dtype=float32), 0.9154879]. 
=============================================
[2019-04-24 10:33:00,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1814474e-01 1.1377553e-03 1.1880872e-03 1.0932183e-07 9.2601569e-12
 7.1037305e-09 4.9063795e-11 4.1636373e-04 1.7911290e-01 2.0392221e-11
 5.7771674e-12], sum to 1.0000
[2019-04-24 10:33:00,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4465
[2019-04-24 10:33:00,094] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 28.66666666666666, 119.3333333333333, 839.1666666666667, 22.5, 24.69129317086266, 0.1182661791824189, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4106400.0000, 
sim time next is 4107600.0000, 
raw observation next is [3.0, 29.0, 118.0, 835.5, 22.5, 24.16224251753006, 0.02276871305743277, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.29, 0.3933333333333333, 0.9232044198895027, 0.375, 0.5135202097941717, 0.5075895710191443, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22625944], dtype=float32), 0.4900068]. 
=============================================
[2019-04-24 10:33:01,412] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5566975e-01 2.3718695e-03 4.9487120e-03 1.6272162e-06 1.3725799e-08
 2.0079138e-07 4.6137686e-08 3.5210291e-03 3.3348677e-01 1.1576838e-08
 2.2209707e-09], sum to 1.0000
[2019-04-24 10:33:01,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4891
[2019-04-24 10:33:01,452] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 50.0, 0.0, 0.0, 19.0, 21.57435134215113, -0.5514949138167019, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4168800.0000, 
sim time next is 4170000.0000, 
raw observation next is [-4.333333333333334, 49.66666666666667, 0.0, 0.0, 19.0, 21.11479717213075, -0.6239656915600966, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.3425669436749769, 0.4966666666666667, 0.0, 0.0, 0.08333333333333333, 0.2595664310108958, 0.29201143614663444, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7620859], dtype=float32), -0.6215695]. 
=============================================
[2019-04-24 10:33:01,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[48.289833]
 [48.838768]
 [49.454044]
 [48.46197 ]
 [48.92991 ]
 [49.556038]
 [48.500965]
 [48.89062 ]
 [49.39825 ]
 [50.13506 ]
 [52.223587]
 [53.189415]
 [54.10352 ]
 [55.41815 ]
 [57.081497]
 [57.716656]
 [59.700592]
 [61.482727]
 [63.358795]
 [64.56628 ]
 [64.03246 ]
 [64.76569 ]
 [64.271065]
 [63.87059 ]
 [64.13419 ]], R is [[48.247715  ]
 [48.76523972]
 [49.27758789]
 [48.78481293]
 [49.29696655]
 [49.80399704]
 [49.30595779]
 [49.81290054]
 [50.31477356]
 [50.81162643]
 [51.30350876]
 [51.79047394]
 [51.27257156]
 [51.75984573]
 [52.24224854]
 [51.71982574]
 [52.20262909]
 [52.68060303]
 [53.15379715]
 [52.62226105]
 [52.09603882]
 [52.57507706]
 [52.04932785]
 [51.5288353 ]
 [52.01354599]].
[2019-04-24 10:33:02,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3781917e-01 1.2151637e-03 7.7198939e-03 9.9222143e-07 1.5268523e-09
 9.8558161e-08 1.2364644e-08 1.5740549e-03 3.5167062e-01 1.8252259e-09
 2.3195762e-10], sum to 1.0000
[2019-04-24 10:33:02,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2885
[2019-04-24 10:33:02,930] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.4, 42.0, 0.0, 0.0, 19.0, 22.47247041290929, -0.3333493513409715, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4215600.0000, 
sim time next is 4216800.0000, 
raw observation next is [1.266666666666667, 42.33333333333334, 0.0, 0.0, 19.0, 22.2311906301684, -0.3746661382697796, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.4976915974145891, 0.42333333333333345, 0.0, 0.0, 0.08333333333333333, 0.3525992191806999, 0.3751112872434068, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7725934], dtype=float32), 0.16455832]. 
=============================================
[2019-04-24 10:33:03,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.30537951e-01 3.28163337e-03 3.86192952e-03 1.42628903e-06
 1.28167832e-09 2.11294306e-07 1.11160245e-08 2.23787222e-03
 2.60078967e-01 2.02801109e-09 3.83262783e-10], sum to 1.0000
[2019-04-24 10:33:03,478] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5271
[2019-04-24 10:33:03,496] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 44.33333333333334, 0.0, 0.0, 19.0, 21.56822752485967, -0.3629706650515011, 0.0, 1.0, 55.0, 80.68917396369842], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4224000.0000, 
sim time next is 4225200.0000, 
raw observation next is [1.0, 45.66666666666667, 0.0, 0.0, 19.0, 22.17021255152127, -0.4433247140145896, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.4903047091412743, 0.4566666666666667, 0.0, 0.0, 0.08333333333333333, 0.34751771262677256, 0.3522250953284701, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14370814], dtype=float32), 0.78876805]. 
=============================================
[2019-04-24 10:33:04,409] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.8267232e-01 4.1723358e-03 8.1005618e-03 1.6005183e-06 3.8741850e-09
 1.8839667e-07 3.2979095e-08 7.0182052e-03 2.9803473e-01 4.7581357e-09
 1.9336179e-09], sum to 1.0000
[2019-04-24 10:33:04,409] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3393
[2019-04-24 10:33:04,432] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 41.66666666666667, 105.3333333333333, 631.3333333333333, 19.0, 22.05150428939352, -0.2520970301221906, 0.0, 1.0, 55.0, 67.16058300275814], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4180800.0000, 
sim time next is 4182000.0000, 
raw observation next is [-2.666666666666667, 38.33333333333334, 109.0, 679.0, 19.0, 22.43082699738788, -0.3418179577929343, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.38873499538319484, 0.3833333333333334, 0.36333333333333334, 0.7502762430939226, 0.08333333333333333, 0.3692355831156566, 0.38606068073568856, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12546776], dtype=float32), -0.16028826]. 
=============================================
[2019-04-24 10:33:11,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2849292e-01 1.2403502e-03 3.8155699e-03 7.5871645e-07 2.5883220e-09
 5.2084705e-08 4.5944057e-09 1.5294234e-03 2.6492104e-01 9.2411712e-10
 1.1508234e-10], sum to 1.0000
[2019-04-24 10:33:11,130] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9350
[2019-04-24 10:33:11,190] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.0, 42.66666666666667, 182.5, 163.8333333333333, 19.0, 22.23663567641128, -0.1613074596683785, 0.0, 1.0, 55.0, 70.95662790209207], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4200000.0000, 
sim time next is 4201200.0000, 
raw observation next is [2.0, 44.0, 173.5, 313.5, 19.0, 23.1408570613311, -0.03906561357024929, 0.0, 1.0, 55.0, 45.61130496332777], 
processed observation next is [0.0, 0.6521739130434783, 0.518005540166205, 0.44, 0.5783333333333334, 0.34640883977900555, 0.08333333333333333, 0.4284047551109251, 0.4869781288099169, 0.0, 1.0, 0.8, 0.4561130496332777], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7230299], dtype=float32), 1.3169322]. 
=============================================
[2019-04-24 10:33:14,232] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9910077e-01 3.5790300e-03 1.9299880e-03 5.2279034e-08 1.1472537e-11
 1.5642430e-09 9.9631657e-11 4.5720668e-04 3.9493299e-01 7.5659088e-12
 4.9740676e-12], sum to 1.0000
[2019-04-24 10:33:14,234] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3564
[2019-04-24 10:33:14,248] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 77.0, 0.0, 0.0, 19.0, 21.65771973502976, -0.4726338566655917, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4604400.0000, 
sim time next is 4605600.0000, 
raw observation next is [-2.666666666666667, 75.0, 0.0, 0.0, 22.5, 21.39209747867154, -0.5230700603162958, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.38873499538319484, 0.75, 0.0, 0.0, 0.375, 0.2826747898892951, 0.3256433132279014, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16039243], dtype=float32), 1.1382203]. 
=============================================
[2019-04-24 10:33:16,256] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:16,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:16,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.25849390e-01 4.85347497e-04 4.89985710e-03 4.69775792e-08
 1.64108640e-11 4.57146898e-09 1.03171936e-10 5.64813497e-04
 2.68200576e-01 1.24847988e-11 5.70072255e-13], sum to 1.0000
[2019-04-24 10:33:16,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7797
[2019-04-24 10:33:16,845] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 19.0, 22.06435085811328, -0.1732484539100142, 0.0, 1.0, 55.0, 77.45319476190568], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4579200.0000, 
sim time next is 4580400.0000, 
raw observation next is [0.8, 61.66666666666667, 0.0, 0.0, 19.0, 22.82571968964798, -0.0828346730325543, 0.0, 1.0, 55.0, 48.96367481467668], 
processed observation next is [1.0, 0.0, 0.4847645429362882, 0.6166666666666667, 0.0, 0.0, 0.08333333333333333, 0.4021433074706649, 0.47238844232248195, 0.0, 1.0, 0.8, 0.4896367481467668], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2453023], dtype=float32), 0.8971648]. 
=============================================
[2019-04-24 10:33:17,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:17,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:17,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run9
[2019-04-24 10:33:17,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:17,548] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:17,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4314886e-01 2.9686091e-03 9.6872431e-04 3.9543096e-08 3.0158402e-12
 2.6411346e-09 8.7802876e-11 7.6073979e-04 2.5215304e-01 5.9175473e-12
 1.3624995e-12], sum to 1.0000
[2019-04-24 10:33:17,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2597
[2019-04-24 10:33:17,636] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 71.0, 129.8333333333333, 227.3333333333333, 22.5, 21.43045532114963, -0.4958587536273331, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4610400.0000, 
sim time next is 4611600.0000, 
raw observation next is [-2.0, 71.0, 143.5, 340.0, 22.5, 21.73127720722028, -0.463607506529329, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.40720221606648205, 0.71, 0.47833333333333333, 0.3756906077348066, 0.375, 0.3109397672683567, 0.34546416449022366, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10032266], dtype=float32), 1.129224]. 
=============================================
[2019-04-24 10:33:18,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:18,353] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:18,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run9
[2019-04-24 10:33:21,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:22,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:22,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:22,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run9
[2019-04-24 10:33:22,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8815162e-01 2.2387542e-03 7.1899086e-04 9.0742802e-08 5.5900826e-11
 1.0823026e-08 5.9223870e-10 1.0201404e-03 2.0787033e-01 1.1905793e-10
 6.9401750e-12], sum to 1.0000
[2019-04-24 10:33:22,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8055
[2019-04-24 10:33:22,840] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.666666666666667, 43.66666666666667, 77.5, 466.6666666666667, 22.5, 21.83222285257695, -0.3242307020425058, 1.0, 1.0, 55.0, 92.78451339799408], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4954800.0000, 
sim time next is 4956000.0000, 
raw observation next is [-1.333333333333333, 41.33333333333334, 95.5, 586.1666666666666, 22.5, 23.36657032227047, -0.1354720414423798, 1.0, 1.0, 55.0, 59.46822738555764], 
processed observation next is [1.0, 0.34782608695652173, 0.42566943674976926, 0.41333333333333344, 0.31833333333333336, 0.6476979742173112, 0.375, 0.4472141935225391, 0.45484265285254005, 1.0, 1.0, 0.8, 0.5946822738555764], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4463758], dtype=float32), 0.564558]. 
=============================================
[2019-04-24 10:33:23,257] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:23,450] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:23,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0563555e-01 1.3609037e-03 1.8855315e-03 4.7718114e-08 6.3482292e-12
 4.5089656e-09 7.7218017e-11 4.3750272e-04 2.9068047e-01 2.8356779e-12
 1.6200717e-12], sum to 1.0000
[2019-04-24 10:33:23,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6325
[2019-04-24 10:33:23,670] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 22.15958231022599, -0.3444976167478737, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4687200.0000, 
sim time next is 4688400.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 19.0, 21.98378460679297, -0.3881484770611869, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 1.0, 0.0, 0.0, 0.08333333333333333, 0.3319820505660808, 0.37061717431293767, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.259903], dtype=float32), 0.09062205]. 
=============================================
[2019-04-24 10:33:23,916] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:24,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:24,159] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.07743466e-01 1.93658704e-03 1.06438985e-02 3.38524529e-07
 2.16757567e-09 4.64301912e-08 6.68801015e-09 1.99130410e-03
 2.77684420e-01 8.04534883e-10 1.19626101e-10], sum to 1.0000
[2019-04-24 10:33:24,159] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8216
[2019-04-24 10:33:24,214] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.0, 45.0, 90.5, 295.3333333333334, 19.0, 22.14491460125418, -0.435398208781651, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4898400.0000, 
sim time next is 4899600.0000, 
raw observation next is [3.0, 45.0, 67.5, 252.0, 19.0, 22.17179170971254, -0.2448340128992184, 0.0, 1.0, 55.0, 69.34070318954305], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.45, 0.225, 0.27845303867403315, 0.08333333333333333, 0.3476493091427117, 0.41838866236692723, 0.0, 1.0, 0.8, 0.6934070318954305], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2159481], dtype=float32), 0.9221588]. 
=============================================
[2019-04-24 10:33:24,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:24,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:24,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run9
[2019-04-24 10:33:24,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:24,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:24,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run9
[2019-04-24 10:33:25,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6245993e-01 1.3730169e-03 3.9416377e-04 6.9379866e-09 4.6325411e-13
 2.4486146e-10 3.3269472e-12 1.0073968e-04 2.3567210e-01 7.0266937e-13
 1.5770508e-13], sum to 1.0000
[2019-04-24 10:33:25,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0981
[2019-04-24 10:33:25,614] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 72.0, 155.1666666666667, 0.9999999999999998, 22.5, 24.42159682605141, 0.004528252909662189, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4720800.0000, 
sim time next is 4722000.0000, 
raw observation next is [1.0, 72.0, 139.1666666666667, 1.833333333333333, 22.5, 23.78481317395409, -0.06421774252805887, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4903047091412743, 0.72, 0.4638888888888891, 0.002025782688766114, 0.375, 0.482067764496174, 0.4785940858239804, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17625725], dtype=float32), -0.4778229]. 
=============================================
[2019-04-24 10:33:26,705] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2413230e-01 6.2188976e-03 1.3767528e-02 6.0048865e-07 6.5519001e-10
 1.1248769e-07 6.9310997e-09 1.6308583e-03 2.5424963e-01 1.1477908e-09
 4.8429882e-10], sum to 1.0000
[2019-04-24 10:33:26,707] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2430
[2019-04-24 10:33:26,725] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.8, 44.33333333333334, 266.0, 385.6666666666667, 19.0, 20.54379732100893, -0.691122663572694, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4887600.0000, 
sim time next is 4888800.0000, 
raw observation next is [2.0, 44.0, 254.0, 381.0, 19.0, 20.50844652495956, -0.6962983963662293, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.518005540166205, 0.44, 0.8466666666666667, 0.42099447513812155, 0.08333333333333333, 0.20903721041329662, 0.26790053454459023, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6931077], dtype=float32), -1.2021924]. 
=============================================
[2019-04-24 10:33:27,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:27,259] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:27,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:28,005] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:28,068] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:28,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:28,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:28,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run9
[2019-04-24 10:33:28,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:28,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:28,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:28,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run9
[2019-04-24 10:33:29,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:29,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:29,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run9
[2019-04-24 10:33:30,361] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:30,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:30,555] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:30,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:30,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:30,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:31,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,302] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:31,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:31,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:31,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run9
[2019-04-24 10:33:31,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:31,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:31,517] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run9
[2019-04-24 10:33:31,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:31,625] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:31,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run9
[2019-04-24 10:33:32,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:32,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:32,107] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run9
[2019-04-24 10:33:32,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:33,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:33,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:33,849] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:33,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run9
[2019-04-24 10:33:35,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:35,580] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:36,082] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:36,082] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:36,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run9
[2019-04-24 10:33:37,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:37,680] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:38,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:38,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:38,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run9
[2019-04-24 10:33:39,571] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:40,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:33:40,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:33:40,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:33:40,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run9
[2019-04-24 10:33:46,989] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9554925e-01 1.1976406e-03 4.7192071e-03 4.1870162e-08 4.0566200e-10
 1.9856570e-08 3.8099937e-09 1.4415550e-03 2.9709217e-01 1.7887922e-10
 3.0434634e-11], sum to 1.0000
[2019-04-24 10:33:46,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9537
[2019-04-24 10:33:47,105] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 19.98042735554949, -0.7919071234570598, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 24000.0000, 
sim time next is 25200.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 20.32781667509299, -0.5279623991476806, 0.0, 1.0, 55.0, 81.57858722475176], 
processed observation next is [0.0, 0.30434782608695654, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.19398472292441582, 0.3240125336174398, 0.0, 1.0, 0.8, 0.8157858722475175], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2018219], dtype=float32), -0.43536884]. 
=============================================
[2019-04-24 10:33:54,030] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3618152e-01 4.3751686e-04 4.5023058e-04 5.9789770e-08 9.6110550e-12
 1.1796231e-08 2.4726879e-11 2.0749068e-04 1.6272321e-01 7.1296441e-12
 1.9484228e-12], sum to 1.0000
[2019-04-24 10:33:54,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6492
[2019-04-24 10:33:54,049] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 61.0, 104.5, 75.5, 22.5, 22.47582566759181, -0.3470343328506738, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 140400.0000, 
sim time next is 141600.0000, 
raw observation next is [-6.700000000000001, 62.0, 75.5, 55.16666666666666, 22.5, 22.07711988928548, -0.4347809376849428, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.2770083102493075, 0.62, 0.25166666666666665, 0.06095764272559852, 0.375, 0.33975999077379004, 0.35507302077168573, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03145981], dtype=float32), 0.64527273]. 
=============================================
[2019-04-24 10:34:09,256] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3410195e-01 9.3020750e-03 4.3832120e-03 1.5335048e-07 1.1244903e-10
 1.2937313e-08 3.2606935e-09 3.6815178e-04 6.5184444e-01 2.1644793e-10
 3.5017746e-11], sum to 1.0000
[2019-04-24 10:34:09,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0702
[2019-04-24 10:34:09,282] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 19.0, 20.12432724264195, -0.9367275000450573, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 172800.0000, 
sim time next is 174000.0000, 
raw observation next is [-8.566666666666666, 72.0, 0.0, 0.0, 19.0, 19.60296819109299, -1.045206665784054, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.22530009233610343, 0.72, 0.0, 0.0, 0.08333333333333333, 0.13358068259108258, 0.15159777807198202, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33521384], dtype=float32), 0.21919328]. 
=============================================
[2019-04-24 10:34:11,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2261919e-01 1.4504854e-03 1.8999284e-03 9.3230163e-08 1.6719040e-10
 1.1313565e-08 8.6877849e-10 4.1709069e-04 4.7361320e-01 4.0403628e-11
 1.1728202e-11], sum to 1.0000
[2019-04-24 10:34:11,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8300
[2019-04-24 10:34:11,390] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.3, 80.0, 0.0, 0.0, 19.0, 19.3950564476778, -1.052285885646474, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 258000.0000, 
sim time next is 259200.0000, 
raw observation next is [-4.5, 79.0, 0.0, 0.0, 19.0, 19.62470396889318, -0.7954490488625666, 0.0, 1.0, 55.0, 91.63098380096638], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.79, 0.0, 0.0, 0.08333333333333333, 0.13539199740776495, 0.23485031704581114, 0.0, 1.0, 0.8, 0.9163098380096638], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9218284], dtype=float32), 0.18967853]. 
=============================================
[2019-04-24 10:34:14,122] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.1573175e-01 3.7956384e-03 6.3826768e-03 5.7224463e-07 1.4953376e-10
 1.5017129e-08 1.0017407e-08 1.5777304e-03 4.7251165e-01 3.3499292e-10
 2.0464822e-10], sum to 1.0000
[2019-04-24 10:34:14,124] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9137
[2019-04-24 10:34:14,328] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-10.96666666666667, 68.0, 0.0, 0.0, 19.0, 19.2569426422447, -1.186823989492577, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 278400.0000, 
sim time next is 279600.0000, 
raw observation next is [-11.33333333333333, 69.0, 0.0, 0.0, 19.0, 19.05547909997411, -1.005287406690853, 0.0, 1.0, 55.0, 86.46403469707586], 
processed observation next is [1.0, 0.21739130434782608, 0.14866112650046176, 0.69, 0.0, 0.0, 0.08333333333333333, 0.08795659166450924, 0.16490419776971565, 0.0, 1.0, 0.8, 0.8646403469707586], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2560971], dtype=float32), -0.2766748]. 
=============================================
[2019-04-24 10:34:19,552] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.9156100e-01 3.6789470e-03 4.5760553e-03 5.1094702e-07 1.3105152e-10
 6.4832562e-08 4.1906838e-09 5.6426821e-04 4.9961919e-01 2.3646460e-10
 5.7329422e-11], sum to 1.0000
[2019-04-24 10:34:19,552] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6414
[2019-04-24 10:34:19,644] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-13.9, 68.66666666666667, 0.0, 0.0, 19.0, 18.55733946055798, -1.252709872706529, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 343200.0000, 
sim time next is 344400.0000, 
raw observation next is [-13.9, 67.33333333333334, 0.0, 0.0, 19.0, 18.75557531905067, -0.9906948389349998, 0.0, 1.0, 55.0, 95.2161045665625], 
processed observation next is [1.0, 1.0, 0.07756232686980608, 0.6733333333333335, 0.0, 0.0, 0.08333333333333333, 0.06296460992088922, 0.16976838702166674, 0.0, 1.0, 0.8, 0.9521610456656251], 
reward next is 0.4888, 
noisyNet noise sample is [array([0.16648646], dtype=float32), -1.1886705]. 
=============================================
[2019-04-24 10:34:21,866] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-24 10:34:21,867] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:34:21,868] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:34:21,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run12
[2019-04-24 10:34:21,926] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:34:21,943] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:34:21,947] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:34:21,947] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:34:21,948] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run12
[2019-04-24 10:34:21,982] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run12
[2019-04-24 10:34:39,150] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.22456512], dtype=float32), 0.32392305]
[2019-04-24 10:34:39,150] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-6.109365744, 66.15768823, 0.0, 0.0, 22.5, 20.27096819746365, -0.8989685980755536, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:34:39,151] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:34:39,153] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [7.3142421e-01 1.6658308e-03 2.7608937e-03 8.0038643e-07 1.3176793e-09
 1.1187191e-07 5.2698375e-09 8.2686648e-04 2.6332125e-01 1.1095231e-09
 1.5622055e-10], sampled 0.12722795968849165
[2019-04-24 10:36:16,369] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.22456512], dtype=float32), 0.32392305]
[2019-04-24 10:36:16,369] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [11.0, 26.0, 95.0, 533.0, 19.0, 21.97124480791028, -0.2517570833151679, 0.0, 1.0, 55.0, 71.63079299491557]
[2019-04-24 10:36:16,369] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:36:16,370] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.0842510e-01 3.1705052e-03 4.2414539e-03 4.1037143e-07 2.0778432e-09
 1.0003698e-07 7.6545836e-09 3.9849440e-03 2.8017753e-01 1.4990656e-09
 9.5500691e-11], sampled 0.7355422026292073
[2019-04-24 10:36:29,277] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3004.7678 80684.0804 30.5178
[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,297] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:29,404] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,037] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2776.2941 94639.8311 -248.8126
[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:36,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,761] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2627.3472 95923.4416 -433.0241
[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,791] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:40,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:36:41,793] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 550000, evaluation results [550000.0, 2776.2940556461335, 94639.83106734522, -248.81263267539302, 3004.7678356706197, 80684.08037134493, 30.517776932033755, 2627.347209578059, 95923.44155022249, -433.0240967451176]
[2019-04-24 10:36:44,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7800379e-01 6.5428317e-03 5.5156201e-03 1.5051410e-06 8.7545560e-10
 1.5259978e-07 3.3243144e-09 3.3412972e-03 3.0659482e-01 6.8433309e-10
 7.5924367e-10], sum to 1.0000
[2019-04-24 10:36:44,238] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3487
[2019-04-24 10:36:44,328] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 28.0, 110.0, 0.0, 22.5, 21.18180855824169, -0.8859899444982345, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 471600.0000, 
sim time next is 472800.0000, 
raw observation next is [-2.1, 27.0, 118.0, 0.0, 22.5, 20.92561796420932, -0.9559055751973179, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.404432132963989, 0.27, 0.3933333333333333, 0.0, 0.375, 0.24380149701744327, 0.1813648082675607, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.41312042], dtype=float32), -0.5884507]. 
=============================================
[2019-04-24 10:36:47,936] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.0081747e-01 4.4397060e-03 3.4164563e-03 9.5366801e-07 7.9238366e-10
 8.6389676e-08 4.1595607e-09 7.2966702e-04 2.9059562e-01 9.9655961e-10
 5.2470944e-10], sum to 1.0000
[2019-04-24 10:36:47,937] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7213
[2019-04-24 10:36:48,086] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 28.0, 110.0, 0.0, 22.5, 20.76713852281961, -0.9363900851659088, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 471600.0000, 
sim time next is 472800.0000, 
raw observation next is [-2.1, 27.0, 118.0, 0.0, 22.5, 21.6825643346103, -0.5828532290542934, 1.0, 1.0, 55.0, 106.59457019196165], 
processed observation next is [1.0, 0.4782608695652174, 0.404432132963989, 0.27, 0.3933333333333333, 0.0, 0.375, 0.3068803612175251, 0.30571559031523554, 1.0, 1.0, 0.8, 1.0659457019196166], 
reward next is 0.4143, 
noisyNet noise sample is [array([1.4510576], dtype=float32), -0.2690492]. 
=============================================
[2019-04-24 10:36:52,965] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8458941e-01 7.6973002e-04 7.9514558e-04 6.5838357e-08 1.0098550e-11
 2.7939078e-09 1.4503194e-10 4.1556222e-04 2.1343008e-01 2.7324342e-11
 2.7986875e-12], sum to 1.0000
[2019-04-24 10:36:52,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6959
[2019-04-24 10:36:53,043] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.9000000000000001, 92.0, 0.0, 0.0, 22.5, 20.86869121118686, -0.5284422999707596, 1.0, 1.0, 55.0, 106.33207775850826], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 499200.0000, 
sim time next is 500400.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 22.5, 21.99650332955405, -0.6194927778869713, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.96, 0.0, 0.0, 0.375, 0.33304194412950405, 0.2935024073710096, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.96799093], dtype=float32), -0.9774115]. 
=============================================
[2019-04-24 10:36:59,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0207193e-01 8.1017162e-05 3.1981803e-04 3.9951994e-10 1.5331561e-13
 1.0072857e-10 4.8441345e-13 4.4727549e-05 1.9748248e-01 6.2069287e-14
 1.4438088e-14], sum to 1.0000
[2019-04-24 10:36:59,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0733
[2019-04-24 10:36:59,162] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.53333333333333, 64.66666666666667, 0.0, 0.0, 19.0, 24.9005696380035, 0.4191582374087741, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1117200.0000, 
sim time next is 1118400.0000, 
raw observation next is [12.36666666666667, 65.33333333333334, 0.0, 0.0, 19.0, 24.72528404914177, 0.387021262257927, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.8051708217913206, 0.6533333333333334, 0.0, 0.0, 0.08333333333333333, 0.5604403374284809, 0.629007087419309, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42718345], dtype=float32), 0.89781994]. 
=============================================
[2019-04-24 10:37:03,157] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2132566e-01 1.0580316e-03 7.4013893e-04 2.5919004e-08 5.3869405e-12
 1.7235137e-09 7.1106704e-11 4.5122660e-04 1.7642498e-01 8.3117532e-12
 2.7141527e-13], sum to 1.0000
[2019-04-24 10:37:03,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9725
[2019-04-24 10:37:03,246] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [16.06666666666667, 72.33333333333334, 74.33333333333334, 0.0, 19.0, 24.45047285378165, 0.2368996698988169, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1156800.0000, 
sim time next is 1158000.0000, 
raw observation next is [16.63333333333333, 69.66666666666667, 90.83333333333333, 0.0, 19.0, 24.61687897047142, 0.4339254255733814, 0.0, 0.0, 55.0, 67.5308513391694], 
processed observation next is [0.0, 0.391304347826087, 0.9233610341643583, 0.6966666666666668, 0.30277777777777776, 0.0, 0.08333333333333333, 0.5514065808726182, 0.6446418085244604, 0.0, 0.0, 0.8, 0.6753085133916941], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8230708], dtype=float32), 1.2350827]. 
=============================================
[2019-04-24 10:37:08,730] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.84323275e-01 1.39713549e-04 2.77701271e-04 4.34306635e-09
 1.36817641e-13 2.10375287e-10 1.19344996e-12 1.00466197e-04
 2.15158865e-01 2.90999619e-13 1.03053366e-14], sum to 1.0000
[2019-04-24 10:37:08,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2246
[2019-04-24 10:37:08,763] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 19.0, 23.40937978833117, -0.03708652925656319, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1026000.0000, 
sim time next is 1027200.0000, 
raw observation next is [14.4, 76.33333333333334, 0.0, 0.0, 19.0, 23.17825906484294, -0.07358544541523808, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.7633333333333334, 0.0, 0.0, 0.08333333333333333, 0.4315215887369117, 0.4754715181949207, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.650093], dtype=float32), -0.2927091]. 
=============================================
[2019-04-24 10:37:11,184] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6819739e-01 5.2790320e-04 1.8384954e-04 5.2319509e-09 5.4740582e-14
 7.0231321e-11 1.1276521e-12 7.5964104e-05 3.3101490e-01 1.1947642e-13
 1.3659263e-14], sum to 1.0000
[2019-04-24 10:37:11,195] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0631
[2019-04-24 10:37:11,208] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.86666666666667, 90.66666666666667, 90.0, 0.0, 22.5, 24.00381189790797, -0.02812547816294751, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 987600.0000, 
sim time next is 988800.0000, 
raw observation next is [11.23333333333333, 88.33333333333333, 100.0, 0.0, 22.5, 23.93192137479373, -0.03369185873750024, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7737765466297323, 0.8833333333333333, 0.3333333333333333, 0.0, 0.375, 0.49432678123281093, 0.4887693804208333, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2457073], dtype=float32), -0.10440499]. 
=============================================
[2019-04-24 10:37:12,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0469725e-01 7.3275476e-04 5.4869393e-04 1.5157263e-09 3.5256208e-13
 7.9169399e-10 1.3661422e-11 7.3131981e-05 2.9394814e-01 4.4863980e-13
 1.3057899e-14], sum to 1.0000
[2019-04-24 10:37:12,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0260
[2019-04-24 10:37:12,692] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 80.0, 0.0, 0.0, 19.0, 23.75146230573062, 0.05584902848775524, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1561200.0000, 
sim time next is 1562400.0000, 
raw observation next is [5.0, 79.0, 0.0, 0.0, 19.0, 23.31006035011412, -0.005815380823251032, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.6011080332409973, 0.79, 0.0, 0.0, 0.08333333333333333, 0.44250502917617673, 0.498061539725583, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5927231], dtype=float32), -1.8386716]. 
=============================================
[2019-04-24 10:37:13,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7543637e-01 6.2497519e-04 6.5465114e-04 4.8091698e-07 4.9785770e-10
 5.0572535e-08 1.0708870e-09 5.6750537e-04 1.2271591e-01 5.9350069e-10
 4.1148383e-11], sum to 1.0000
[2019-04-24 10:37:13,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2336
[2019-04-24 10:37:13,477] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 78.0, 0.0, 0.0, 19.0, 25.37734239282812, 0.479246158363716, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1209600.0000, 
sim time next is 1210800.0000, 
raw observation next is [16.1, 78.66666666666667, 0.0, 0.0, 19.0, 25.07484049474706, 0.4330938125101596, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.5895700412289218, 0.6443646041700531, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.22988433], dtype=float32), -3.1667206]. 
=============================================
[2019-04-24 10:37:14,040] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7523780e-01 1.1060539e-03 1.7193505e-03 2.1929336e-07 2.9940550e-10
 2.9016638e-08 1.3869320e-09 9.1301778e-04 2.2102347e-01 1.5161444e-10
 4.3127529e-11], sum to 1.0000
[2019-04-24 10:37:14,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3920
[2019-04-24 10:37:14,055] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 25.40387811037261, 0.5171699395771753, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1236000.0000, 
sim time next is 1237200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 25.14365069460645, 0.458026649373861, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.5953042245505374, 0.652675549791287, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.583639], dtype=float32), 1.0850302]. 
=============================================
[2019-04-24 10:37:19,388] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5962300e-01 4.9651839e-04 1.1622903e-03 1.1730852e-08 1.0490686e-12
 8.3739260e-10 2.0984355e-11 2.7322411e-04 4.3844494e-01 6.3044416e-13
 4.6400644e-13], sum to 1.0000
[2019-04-24 10:37:19,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9994
[2019-04-24 10:37:19,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.43343468570323, -0.4602649875855762, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1392000.0000, 
sim time next is 1393200.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 21.75644810622947, -0.2024575010242705, 0.0, 1.0, 55.0, 80.26286970890698], 
processed observation next is [1.0, 0.13043478260869565, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.3130373421857892, 0.4325141663252432, 0.0, 1.0, 0.8, 0.8026286970890698], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07750659], dtype=float32), 0.62766755]. 
=============================================
[2019-04-24 10:37:21,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2521108e-01 2.1138915e-04 1.0756312e-03 5.4289271e-09 2.2577368e-13
 3.3859615e-10 2.6874700e-11 1.5062605e-04 2.7335125e-01 1.7734274e-12
 2.1688675e-14], sum to 1.0000
[2019-04-24 10:37:21,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8506
[2019-04-24 10:37:21,042] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.566666666666666, 96.0, 0.0, 0.0, 19.0, 23.43712651586819, 0.1455474585419367, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1276800.0000, 
sim time next is 1278000.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 23.64838510111473, 0.3713799359936572, 0.0, 1.0, 55.0, 74.60801353440033], 
processed observation next is [0.0, 0.8260869565217391, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.4706987584262275, 0.6237933119978857, 0.0, 1.0, 0.8, 0.7460801353440033], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.53709453], dtype=float32), -0.23479088]. 
=============================================
[2019-04-24 10:37:21,493] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2992891e-01 1.2973975e-03 9.4459002e-04 8.4199403e-09 1.3547990e-12
 2.9984551e-10 5.5526500e-11 4.9291912e-04 2.6733613e-01 1.6388473e-12
 6.9247451e-13], sum to 1.0000
[2019-04-24 10:37:21,493] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0386
[2019-04-24 10:37:21,507] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 96.66666666666667, 0.0, 0.0, 19.0, 21.61388726961968, -0.4217181893336998, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1394400.0000, 
sim time next is 1395600.0000, 
raw observation next is [-0.4, 98.33333333333333, 0.0, 0.0, 19.0, 21.38585487142155, -0.4737722848589168, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.45152354570637127, 0.9833333333333333, 0.0, 0.0, 0.08333333333333333, 0.2821545726184625, 0.34207590504702773, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42848003], dtype=float32), -0.73727334]. 
=============================================
[2019-04-24 10:37:24,015] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5116765e-01 5.5827678e-04 1.1513038e-03 6.7586279e-09 2.7397017e-12
 8.1926904e-10 1.0308459e-10 6.2660431e-04 2.4649611e-01 1.5752339e-11
 6.8151967e-13], sum to 1.0000
[2019-04-24 10:37:24,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7837
[2019-04-24 10:37:24,074] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.5, 100.0, 0.0, 0.0, 19.0, 23.43144256820399, 0.1190629543911993, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1286400.0000, 
sim time next is 1287600.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 19.0, 23.5868100311616, 0.3389118699236664, 0.0, 1.0, 55.0, 76.89339274743288], 
processed observation next is [0.0, 0.9130434782608695, 0.6149584487534627, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4655675025968001, 0.6129706233078888, 0.0, 1.0, 0.8, 0.7689339274743289], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15784162], dtype=float32), -0.4630729]. 
=============================================
[2019-04-24 10:37:32,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5209967e-01 2.0926036e-03 3.6802297e-03 1.2568822e-07 1.6823554e-10
 1.4012771e-08 6.3641798e-09 1.7604523e-03 3.4036693e-01 3.3574871e-10
 1.8091110e-11], sum to 1.0000
[2019-04-24 10:37:32,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9896
[2019-04-24 10:37:32,189] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 87.0, 0.0, 0.0, 19.0, 21.04642422081685, -0.6125509133016185, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1754400.0000, 
sim time next is 1755600.0000, 
raw observation next is [-1.7, 87.0, 0.0, 0.0, 19.0, 21.01418733017139, -0.4050390073923106, 0.0, 1.0, 55.0, 81.95940903584119], 
processed observation next is [0.0, 0.30434782608695654, 0.4155124653739613, 0.87, 0.0, 0.0, 0.08333333333333333, 0.2511822775142824, 0.3649869975358964, 0.0, 1.0, 0.8, 0.8195940903584119], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01939848], dtype=float32), 1.5770221]. 
=============================================
[2019-04-24 10:38:00,215] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.7501811e-01 9.0128020e-04 2.4722661e-03 7.1817198e-08 3.4838403e-11
 5.1993942e-09 4.1130574e-10 6.8365294e-04 4.2092460e-01 3.4443559e-11
 3.7111308e-12], sum to 1.0000
[2019-04-24 10:38:00,216] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2002
[2019-04-24 10:38:00,239] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.700000000000001, 77.0, 0.0, 0.0, 19.0, 20.95481269309464, -0.5501821526337755, 0.0, 1.0, 55.0, 76.26762274091134], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2247600.0000, 
sim time next is 2248800.0000, 
raw observation next is [-6.700000000000001, 76.0, 0.0, 0.0, 19.0, 21.30640871445141, -0.6861949974614663, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.2770083102493075, 0.76, 0.0, 0.0, 0.08333333333333333, 0.2755340595376176, 0.27126833417951124, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06080719], dtype=float32), -0.31825426]. 
=============================================
[2019-04-24 10:38:00,637] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.4505191e-01 4.8574940e-03 1.6828334e-02 2.6858420e-06 6.1327214e-08
 8.0032197e-07 3.3591581e-07 4.5656376e-03 5.2869266e-01 3.9058534e-08
 3.2400786e-09], sum to 1.0000
[2019-04-24 10:38:00,638] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0760
[2019-04-24 10:38:00,696] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 40.66666666666667, 73.5, 758.3333333333333, 19.0, 20.61605916451386, -0.738261130014938, 0.0, 1.0, 55.0, 69.80146717485114], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2456400.0000, 
sim time next is 2457600.0000, 
raw observation next is [-3.4, 38.33333333333334, 77.66666666666667, 785.6666666666666, 19.0, 20.77319130069379, -0.8423740708320926, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.368421052631579, 0.3833333333333334, 0.2588888888888889, 0.8681399631675875, 0.08333333333333333, 0.23109927505781572, 0.21920864305596913, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.08926319], dtype=float32), -0.2528248]. 
=============================================
[2019-04-24 10:38:03,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9152097e-01 1.8947858e-03 7.6448256e-03 3.7412892e-07 1.4771656e-09
 5.4257637e-08 2.2287217e-08 2.4277708e-03 3.9651117e-01 2.2258104e-09
 2.3623403e-10], sum to 1.0000
[2019-04-24 10:38:03,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0022
[2019-04-24 10:38:03,799] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.633333333333333, 64.0, 136.0, 435.0, 19.0, 20.40505630243572, -0.6076567903783531, 0.0, 1.0, 55.0, 75.1183072718855], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2370000.0000, 
sim time next is 2371200.0000, 
raw observation next is [-2.466666666666667, 63.0, 143.6666666666667, 426.0, 19.0, 20.95992818520591, -0.6872374908390597, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.39427516158818104, 0.63, 0.47888888888888903, 0.4707182320441989, 0.08333333333333333, 0.24666068210049255, 0.2709208363869801, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9044917], dtype=float32), 2.055586]. 
=============================================
[2019-04-24 10:38:05,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1997778e-01 5.7912786e-03 2.4285965e-02 6.6707562e-06 4.5856968e-08
 1.2681955e-06 2.6476764e-07 2.7710099e-03 5.4716563e-01 7.5161573e-08
 5.4402793e-09], sum to 1.0000
[2019-04-24 10:38:05,291] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0562
[2019-04-24 10:38:05,328] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.833333333333333, 42.0, 0.0, 0.0, 19.0, 19.66907900713188, -1.042929515206495, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2414400.0000, 
sim time next is 2415600.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 19.0, 19.13996894488344, -1.158283507734004, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.32409972299168976, 0.41, 0.0, 0.0, 0.08333333333333333, 0.09499741207361989, 0.1139054974219987, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47347862], dtype=float32), -1.029597]. 
=============================================
[2019-04-24 10:38:05,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4386169e-01 2.2387137e-03 7.8372601e-03 1.6048937e-06 5.5228075e-09
 1.4043104e-07 1.7920195e-08 2.7117478e-03 4.4334882e-01 5.1111728e-09
 1.1782668e-09], sum to 1.0000
[2019-04-24 10:38:05,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3777
[2019-04-24 10:38:05,600] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 53.33333333333334, 201.1666666666667, 70.66666666666666, 19.0, 20.96686184387912, -0.7404077840907631, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2380800.0000, 
sim time next is 2382000.0000, 
raw observation next is [-0.2, 52.66666666666667, 185.8333333333333, 0.0, 19.0, 20.41858878851176, -0.8560740869756751, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.4570637119113574, 0.5266666666666667, 0.6194444444444442, 0.0, 0.08333333333333333, 0.20154906570931322, 0.2146419710081083, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9267771], dtype=float32), 0.9863318]. 
=============================================
[2019-04-24 10:38:08,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0917628e-01 8.3518410e-03 4.9350429e-03 7.8105796e-07 1.1625532e-09
 3.9528220e-07 2.4003480e-08 1.4171135e-03 3.7611845e-01 1.3850180e-09
 4.0269130e-10], sum to 1.0000
[2019-04-24 10:38:08,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0281
[2019-04-24 10:38:08,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 38.66666666666667, 0.0, 0.0, 19.0, 20.4440723642044, -0.8926930040044126, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2511600.0000, 
sim time next is 2512800.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 19.0, 20.06259247886535, -1.001000560716596, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.38, 0.0, 0.0, 0.08333333333333333, 0.1718827065721126, 0.16633314642780136, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2047434], dtype=float32), 0.13646655]. 
=============================================
[2019-04-24 10:38:17,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1943966e-01 7.5231883e-04 1.0930824e-03 2.6337114e-08 9.6862579e-13
 1.8827986e-09 2.3206463e-11 1.0195335e-04 3.7861291e-01 3.7379930e-12
 9.2913524e-13], sum to 1.0000
[2019-04-24 10:38:17,073] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1555
[2019-04-24 10:38:17,103] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 19.0, 21.3406320417961, -0.4842695195109992, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2930400.0000, 
sim time next is 2931600.0000, 
raw observation next is [-1.333333333333333, 80.33333333333334, 0.0, 0.0, 19.0, 21.01690197993901, -0.6018003031990723, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.42566943674976926, 0.8033333333333335, 0.0, 0.0, 0.08333333333333333, 0.2514084983282509, 0.29939989893364255, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33858112], dtype=float32), -0.9590321]. 
=============================================
[2019-04-24 10:38:20,892] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1052155e-01 1.1711548e-03 5.0331559e-04 1.0712497e-07 1.3896859e-11
 8.2209812e-09 1.3197503e-10 1.4882670e-04 3.8765499e-01 1.1375954e-11
 6.1666466e-12], sum to 1.0000
[2019-04-24 10:38:20,901] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4105
[2019-04-24 10:38:20,946] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 62.0, 0.0, 0.0, 22.5, 22.31137492414717, -0.3954272556858593, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2662800.0000, 
sim time next is 2664000.0000, 
raw observation next is [-1.2, 63.0, 0.0, 0.0, 22.5, 21.67654143813113, -0.4898935428142594, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.63, 0.0, 0.0, 0.375, 0.3063784531775943, 0.33670215239524687, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10894995], dtype=float32), -0.14720821]. 
=============================================
[2019-04-24 10:38:21,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5313616e-01 2.5354692e-04 6.0745271e-05 4.4964746e-10 7.1443307e-15
 1.7026821e-11 2.2402325e-13 3.0513431e-05 2.4651900e-01 7.2567261e-15
 9.8221475e-16], sum to 1.0000
[2019-04-24 10:38:21,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9378
[2019-04-24 10:38:21,183] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.0, 100.0, 103.5, 696.5, 22.5, 24.57091581692342, 0.2270794664170243, 1.0, 1.0, 55.0, 61.110548840069825], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3146400.0000, 
sim time next is 3147600.0000, 
raw observation next is [7.0, 100.0, 106.5, 729.5, 22.5, 25.17210638228349, 0.3243028275972932, 1.0, 1.0, 55.0, 41.95289199576001], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.355, 0.8060773480662984, 0.375, 0.5976755318569577, 0.6081009425324311, 1.0, 1.0, 0.8, 0.4195289199576001], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07935995], dtype=float32), -1.6157945]. 
=============================================
[2019-04-24 10:38:21,259] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.0659649e-01 1.9419202e-04 3.1562938e-04 2.8130809e-09 1.2596602e-13
 1.0021528e-10 2.9825226e-12 8.5858264e-05 2.9280782e-01 1.7473912e-13
 8.7743050e-15], sum to 1.0000
[2019-04-24 10:38:21,271] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1351
[2019-04-24 10:38:21,281] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 93.0, 0.0, 0.0, 22.5, 23.00264953736247, -0.1123007701105064, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2916000.0000, 
sim time next is 2917200.0000, 
raw observation next is [0.3333333333333334, 92.66666666666667, 0.0, 0.0, 22.5, 22.98878035429454, -0.1531192715639921, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4718374884579871, 0.9266666666666667, 0.0, 0.0, 0.375, 0.4157316961912117, 0.4489602428120026, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4333322], dtype=float32), 0.8941461]. 
=============================================
[2019-04-24 10:38:21,718] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6818550e-01 1.1018817e-03 2.7987412e-03 5.0706809e-08 1.9417041e-11
 4.2622257e-09 6.2617833e-10 4.9753522e-04 2.2741631e-01 5.0769246e-11
 5.4475946e-12], sum to 1.0000
[2019-04-24 10:38:21,723] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8139
[2019-04-24 10:38:21,798] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 62.33333333333334, 0.0, 0.0, 19.0, 21.65028605962708, -0.5140829066905904, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2755200.0000, 
sim time next is 2756400.0000, 
raw observation next is [-6.0, 60.66666666666666, 0.0, 0.0, 19.0, 21.54987350871739, -0.3143056901120149, 0.0, 1.0, 55.0, 88.4251773896952], 
processed observation next is [1.0, 0.9130434782608695, 0.296398891966759, 0.6066666666666666, 0.0, 0.0, 0.08333333333333333, 0.2958227923931158, 0.39523143662932836, 0.0, 1.0, 0.8, 0.884251773896952], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21993752], dtype=float32), 0.37980083]. 
=============================================
[2019-04-24 10:38:22,396] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.4879558e-01 2.3228980e-03 4.4408394e-03 1.2971296e-07 3.3224250e-11
 6.1442602e-09 4.1463968e-10 1.7632208e-04 4.4426420e-01 2.4915157e-11
 6.3654971e-12], sum to 1.0000
[2019-04-24 10:38:22,396] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8243
[2019-04-24 10:38:22,466] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.333333333333333, 71.0, 0.0, 0.0, 19.0, 20.8480344325892, -0.6987286118168193, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2677200.0000, 
sim time next is 2678400.0000, 
raw observation next is [-7.0, 72.0, 0.0, 0.0, 19.0, 20.64662485266978, -0.5272651009333399, 0.0, 1.0, 55.0, 84.55744065722759], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.72, 0.0, 0.0, 0.08333333333333333, 0.2205520710558151, 0.3242449663555534, 0.0, 1.0, 0.8, 0.8455744065722759], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3169602], dtype=float32), 0.49824992]. 
=============================================
[2019-04-24 10:38:29,043] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6940199e-01 1.4667764e-03 5.9047421e-03 2.7603005e-07 1.4743161e-10
 8.7655678e-09 1.8554221e-09 2.7945463e-03 5.2043164e-01 2.5321450e-10
 3.1303009e-11], sum to 1.0000
[2019-04-24 10:38:29,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6616
[2019-04-24 10:38:29,101] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 20.64610159894815, -0.6566082146347292, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2941200.0000, 
sim time next is 2942400.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 20.80383786003603, -0.4311382798977779, 0.0, 1.0, 55.0, 86.83863337797798], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.23365315500300246, 0.356287240034074, 0.0, 1.0, 0.8, 0.8683863337797798], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4561889], dtype=float32), 1.3285489]. 
=============================================
[2019-04-24 10:38:29,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1287717e-01 5.1706950e-03 1.4927276e-02 4.5321670e-07 1.1313551e-09
 7.6778413e-08 9.5704076e-09 3.9906967e-03 4.6303359e-01 2.9135030e-09
 6.4508549e-10], sum to 1.0000
[2019-04-24 10:38:29,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2988
[2019-04-24 10:38:29,139] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 70.5, 579.5, 19.0, 23.0044117310286, -0.1396546401944183, 0.0, 1.0, 55.0, 42.49946335672325], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3081600.0000, 
sim time next is 3082800.0000, 
raw observation next is [0.6666666666666667, 50.66666666666667, 61.5, 517.1666666666666, 19.0, 23.07145177347083, -0.2508063568075196, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.4810710987996307, 0.5066666666666667, 0.205, 0.5714548802946593, 0.08333333333333333, 0.4226209811225692, 0.41639788106416015, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.58301866], dtype=float32), -1.6409237]. 
=============================================
[2019-04-24 10:38:29,474] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8670672e-01 8.5729407e-04 3.5539356e-03 3.4053656e-07 4.0569140e-10
 1.5686462e-08 3.0131710e-09 2.6434357e-03 3.0623829e-01 5.0300236e-10
 5.8963806e-11], sum to 1.0000
[2019-04-24 10:38:29,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6970
[2019-04-24 10:38:29,548] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 21.07527450483823, -0.6374820734624778, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2952000.0000, 
sim time next is 2953200.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 20.94548307310635, -0.4567192462986896, 0.0, 1.0, 55.0, 78.68492399189795], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.2454569227588624, 0.34776025123377013, 0.0, 1.0, 0.8, 0.7868492399189795], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4561889], dtype=float32), 1.3285489]. 
=============================================
[2019-04-24 10:38:32,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4734010e-01 4.6977954e-04 1.2421889e-03 8.5236724e-09 1.9899519e-13
 5.8050031e-10 2.7878565e-12 5.6089510e-05 4.5089182e-01 3.4736206e-13
 2.4327503e-14], sum to 1.0000
[2019-04-24 10:38:32,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1107
[2019-04-24 10:38:32,061] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 23.81438203518725, 0.07804170654153147, 0.0, 1.0, 55.0, 50.415929965905775], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3453600.0000, 
sim time next is 3454800.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 23.74326519566062, -0.08543411543610273, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.47860543297171826, 0.4715219615212991, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3083205], dtype=float32), -1.7084633]. 
=============================================
[2019-04-24 10:38:34,616] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.4869080e-01 2.1247293e-03 1.9340945e-03 9.9029108e-08 8.4793991e-11
 4.2797241e-09 4.6228515e-10 1.0729549e-03 4.4617733e-01 1.4408463e-10
 2.5897715e-12], sum to 1.0000
[2019-04-24 10:38:34,618] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5153
[2019-04-24 10:38:34,644] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666666, 100.0, 0.0, 0.0, 19.0, 19.97522258901096, -0.8931241173532908, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3112800.0000, 
sim time next is 3114000.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 19.0, 19.8902016286512, -0.9082570023342788, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.08333333333333333, 0.15751680238760013, 0.19724766588857376, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08624292], dtype=float32), -0.8751637]. 
=============================================
[2019-04-24 10:38:36,912] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2106613e-01 4.2570173e-03 7.7455100e-03 1.8365381e-06 4.5855777e-09
 1.8523187e-07 2.8666122e-08 3.4105103e-03 4.6351874e-01 6.8108399e-09
 4.5925075e-10], sum to 1.0000
[2019-04-24 10:38:36,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0638
[2019-04-24 10:38:36,936] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 104.0, 790.5, 19.0, 21.42188258808748, -0.6078771635335595, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3074400.0000, 
sim time next is 3075600.0000, 
raw observation next is [-0.6666666666666667, 41.0, 100.6666666666667, 780.1666666666667, 19.0, 20.92940488004731, -0.7017566559853057, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.44413665743305636, 0.41, 0.33555555555555566, 0.8620626151012892, 0.08333333333333333, 0.24411707333727595, 0.26608111467156476, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03633868], dtype=float32), -0.10207272]. 
=============================================
[2019-04-24 10:38:46,465] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4581456e-01 2.3740043e-03 1.4323543e-03 6.4639131e-08 2.1095372e-12
 1.7250964e-09 8.6231170e-12 3.3717373e-04 2.5004184e-01 1.4309470e-12
 4.6060161e-13], sum to 1.0000
[2019-04-24 10:38:46,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1502
[2019-04-24 10:38:46,486] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 115.0, 811.5, 22.5, 24.541476951044, 0.1240299374252059, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3416400.0000, 
sim time next is 3417600.0000, 
raw observation next is [3.0, 49.0, 113.6666666666667, 807.8333333333334, 22.5, 24.38996362130717, 0.09611598900181391, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.378888888888889, 0.892633517495396, 0.375, 0.5324969684422642, 0.5320386630006047, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17417106], dtype=float32), 1.0853682]. 
=============================================
[2019-04-24 10:38:49,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4368215e-01 2.1092223e-03 2.7611477e-03 6.1207049e-07 2.4317777e-09
 1.5515214e-07 6.8921429e-09 2.2199249e-03 2.4922684e-01 1.2219865e-09
 1.5982816e-10], sum to 1.0000
[2019-04-24 10:38:49,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3663
[2019-04-24 10:38:49,251] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.0, 30.0, 74.83333333333334, 356.0000000000001, 19.0, 22.03131089631121, -0.2457166819210925, 0.0, 1.0, 55.0, 74.46899081779588], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3658800.0000, 
sim time next is 3660000.0000, 
raw observation next is [10.0, 28.0, 91.0, 446.3333333333334, 19.0, 22.82160420340445, -0.2729558169316752, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.739612188365651, 0.28, 0.30333333333333334, 0.49318600368324134, 0.08333333333333333, 0.40180035028370426, 0.4090147276894416, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.011668], dtype=float32), -1.0650847]. 
=============================================
[2019-04-24 10:38:49,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[53.171383]
 [51.422215]
 [51.362976]
 [51.37312 ]
 [51.720196]
 [52.040627]
 [52.38347 ]
 [51.28331 ]
 [51.31962 ]
 [50.35029 ]
 [49.167442]
 [49.328403]
 [49.496964]
 [49.663124]
 [49.91159 ]
 [50.183216]
 [49.269695]
 [49.908623]
 [49.94506 ]
 [50.36696 ]
 [50.850693]
 [51.560184]
 [51.957363]
 [52.515068]
 [52.970173]], R is [[53.69089127]
 [53.15398407]
 [53.62244415]
 [54.08621979]
 [54.54535675]
 [54.99990463]
 [55.4499054 ]
 [54.89540863]
 [55.34645462]
 [54.79299164]
 [54.24506378]
 [54.70261383]
 [55.15559006]
 [55.60403442]
 [56.04799271]
 [56.4875145 ]
 [55.92264175]
 [56.36341476]
 [56.7997818 ]
 [57.23178482]
 [57.65946579]
 [58.08287048]
 [58.50204086]
 [58.91702271]
 [59.32785416]].
[2019-04-24 10:38:50,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0693823e-01 2.3081680e-03 3.7778361e-04 7.5948527e-09 2.8080297e-13
 9.2355767e-10 1.6383788e-12 1.2912728e-04 1.9024673e-01 3.3261249e-13
 1.0383876e-13], sum to 1.0000
[2019-04-24 10:38:50,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8443
[2019-04-24 10:38:50,729] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.0, 49.0, 90.33333333333334, 702.6666666666666, 22.5, 26.70710707174489, 0.645606089788603, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3511200.0000, 
sim time next is 3512400.0000, 
raw observation next is [3.0, 49.0, 83.66666666666667, 660.0, 22.5, 26.96558813935206, 0.782175539580306, 1.0, 1.0, 55.0, 52.71609276673972], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.49, 0.2788888888888889, 0.7292817679558011, 0.375, 0.7471323449460051, 0.7607251798601019, 1.0, 1.0, 0.8, 0.5271609276673972], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00621239], dtype=float32), -0.7758463]. 
=============================================
[2019-04-24 10:38:55,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2556920e-01 2.1725812e-03 1.0912949e-02 5.6825564e-07 2.1087350e-09
 8.1837356e-08 7.1844446e-09 1.1312161e-03 4.6021342e-01 1.8909754e-09
 5.4745208e-11], sum to 1.0000
[2019-04-24 10:38:55,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6475
[2019-04-24 10:38:55,607] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.0, 36.66666666666667, 0.0, 0.0, 19.0, 22.40732882933887, -0.3711511916930523, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3627600.0000, 
sim time next is 3628800.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 19.0, 22.52263959730041, -0.2088067122874278, 0.0, 1.0, 55.0, 65.44782226912056], 
processed observation next is [0.0, 0.0, 0.7119113573407203, 0.25, 0.0, 0.0, 0.08333333333333333, 0.3768866331083676, 0.43039776257085743, 0.0, 1.0, 0.8, 0.6544782226912056], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8805032], dtype=float32), -1.0062237]. 
=============================================
[2019-04-24 10:38:58,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6519573e-01 7.5967039e-04 1.7036448e-03 5.5154221e-08 1.3627498e-10
 2.2008701e-08 1.4465151e-09 1.0220805e-03 2.3131879e-01 1.0860105e-10
 1.2561034e-11], sum to 1.0000
[2019-04-24 10:38:58,173] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2274
[2019-04-24 10:38:58,215] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 47.0, 95.5, 740.5, 19.0, 24.11430372831258, 0.2353019809705693, 0.0, 1.0, 55.0, 65.42014937886246], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3682800.0000, 
sim time next is 3684000.0000, 
raw observation next is [5.666666666666666, 48.0, 89.83333333333333, 716.8333333333333, 19.0, 24.70565112814626, 0.1916545212861303, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.6195752539242845, 0.48, 0.2994444444444444, 0.7920810313075506, 0.08333333333333333, 0.5588042606788551, 0.5638848404287101, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4106102], dtype=float32), -0.62314665]. 
=============================================
[2019-04-24 10:39:05,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1446196e-01 1.3288348e-03 3.5687287e-03 1.3572792e-07 9.2124273e-11
 4.1120645e-09 1.0218904e-09 1.0668896e-03 3.7957343e-01 6.0590137e-11
 7.1073711e-12], sum to 1.0000
[2019-04-24 10:39:05,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5578
[2019-04-24 10:39:05,237] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 71.0, 0.0, 0.0, 19.0, 20.82914648033798, -0.6620966819461596, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4515600.0000, 
sim time next is 4516800.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 19.0, 20.54432137095851, -0.7005942565942038, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.71, 0.0, 0.0, 0.08333333333333333, 0.21202678091320917, 0.2664685811352654, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3463488], dtype=float32), 0.59736025]. 
=============================================
[2019-04-24 10:39:06,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.5708568e-01 8.5392100e-04 1.7063678e-03 1.2171638e-07 5.3168695e-11
 5.9071517e-09 3.2086361e-10 1.3336791e-03 2.3902020e-01 7.1529928e-11
 5.3617575e-12], sum to 1.0000
[2019-04-24 10:39:06,513] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6372
[2019-04-24 10:39:06,573] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 21.64996732159931, -0.4609664882691127, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3890400.0000, 
sim time next is 3891600.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 21.41965634625157, -0.5042394945785925, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.2849713621876309, 0.3319201684738025, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.48601875], dtype=float32), -1.3512034]. 
=============================================
[2019-04-24 10:39:07,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.31927836e-01 4.14530339e-04 6.09888928e-04 5.16569409e-09
 2.89628239e-13 1.59768865e-10 1.81520543e-12 1.18242133e-04
 1.66929454e-01 2.39966928e-13 1.16259245e-14], sum to 1.0000
[2019-04-24 10:39:07,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8367
[2019-04-24 10:39:07,753] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 76.0, 29.0, 45.83333333333334, 22.5, 24.92681397531092, 0.1914524185150258, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4468800.0000, 
sim time next is 4470000.0000, 
raw observation next is [0.0, 74.0, 20.83333333333334, 45.83333333333334, 22.5, 24.63204729036603, 0.162112432185797, 1.0, 1.0, 55.0, 73.12880972726403], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.74, 0.06944444444444446, 0.050644567219152864, 0.375, 0.5526706075305027, 0.5540374773952657, 1.0, 1.0, 0.8, 0.7312880972726403], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0315163], dtype=float32), -1.390174]. 
=============================================
[2019-04-24 10:39:07,762] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.52034 ]
 [72.19846 ]
 [71.67723 ]
 [72.17278 ]
 [71.20483 ]
 [71.59533 ]
 [72.28129 ]
 [72.781685]
 [73.295845]
 [73.787735]
 [74.13222 ]
 [74.28289 ]
 [72.771515]
 [72.78308 ]
 [73.12417 ]
 [73.41608 ]
 [73.60409 ]
 [73.73051 ]
 [73.92337 ]
 [73.98105 ]
 [73.75219 ]
 [73.40412 ]
 [73.67633 ]
 [74.275826]
 [72.7845  ]], R is [[71.35042572]
 [71.63692474]
 [70.92055511]
 [71.21134949]
 [70.49923706]
 [70.79424286]
 [71.08630371]
 [71.3754425 ]
 [71.66168976]
 [71.94507599]
 [72.22562408]
 [72.50337219]
 [71.77833557]
 [72.0605545 ]
 [72.33995056]
 [72.61655426]
 [72.89038849]
 [73.16148376]
 [73.42987061]
 [73.6955719 ]
 [73.95861816]
 [74.21903229]
 [74.47684479]
 [74.73207855]
 [73.98475647]].
[2019-04-24 10:39:07,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.70396852e-01 3.26901744e-03 1.37067796e-03 2.16041528e-07
 6.31208419e-11 1.07707425e-08 3.61595698e-10 6.97400654e-04
 1.24265902e-01 5.34143632e-11 1.55054095e-11], sum to 1.0000
[2019-04-24 10:39:07,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7214
[2019-04-24 10:39:07,825] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 24.0, 43.5, 370.5, 22.5, 24.51444501277257, 0.08124916440570595, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4035600.0000, 
sim time next is 4036800.0000, 
raw observation next is [-2.333333333333333, 24.66666666666666, 27.83333333333333, 252.1666666666667, 22.5, 24.5157168710998, -0.06893376056379845, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3979686057248385, 0.24666666666666662, 0.09277777777777776, 0.2786372007366483, 0.375, 0.5429764059249834, 0.4770220798120672, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6550327], dtype=float32), -1.0430325]. 
=============================================
[2019-04-24 10:39:12,794] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-24 10:39:12,803] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:39:12,804] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:12,804] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:39:12,817] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:12,818] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:39:12,820] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:12,822] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run13
[2019-04-24 10:39:12,820] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run13
[2019-04-24 10:39:12,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run13
[2019-04-24 10:41:33,605] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3008.4277 81273.7035 38.6072
[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,641] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:33,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,238] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2727.4388 93644.2550 -276.2630
[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:46,387] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,081] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2621.2358 96154.5813 -441.7761
[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,100] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:41:51,103] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 600000, evaluation results [600000.0, 2727.4388113321897, 93644.25500939746, -276.26301506869305, 3008.427662056494, 81273.70352662768, 38.607159139761514, 2621.2358299493094, 96154.58133333082, -441.7760578270998]
[2019-04-24 10:41:51,574] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.9879410e-01 4.8794537e-03 9.8290434e-03 1.3411179e-06 7.4188398e-09
 2.8994859e-07 4.5596114e-08 4.2393166e-03 3.8225654e-01 5.7610721e-09
 1.5849492e-09], sum to 1.0000
[2019-04-24 10:41:51,575] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2363
[2019-04-24 10:41:51,601] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666666, 49.33333333333333, 0.0, 0.0, 19.0, 21.68155938492179, -0.5325749101815019, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4171200.0000, 
sim time next is 4172400.0000, 
raw observation next is [-5.0, 49.0, 0.0, 0.0, 19.0, 21.1689927021718, -0.6443237229933324, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.49, 0.0, 0.0, 0.08333333333333333, 0.26408272518098325, 0.2852254256688892, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4596267], dtype=float32), 0.30311382]. 
=============================================
[2019-04-24 10:41:57,624] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.8729739e-01 4.0965321e-04 2.0815694e-04 8.4868592e-09 2.4095496e-13
 5.6508986e-10 1.3987046e-12 1.1342776e-04 1.1197139e-01 2.5927033e-13
 3.6947906e-14], sum to 1.0000
[2019-04-24 10:41:57,627] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0712
[2019-04-24 10:41:57,644] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.1, 31.66666666666666, 179.6666666666667, 524.1666666666667, 22.5, 25.8901162983072, 0.5347389106739685, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4372800.0000, 
sim time next is 4374000.0000, 
raw observation next is [13.9, 32.0, 149.0, 314.5, 22.5, 26.08958516255503, 0.5160806637758243, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.847645429362881, 0.32, 0.49666666666666665, 0.3475138121546961, 0.375, 0.6741320968795858, 0.6720268879252748, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8548049], dtype=float32), 0.21866672]. 
=============================================
[2019-04-24 10:42:00,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5870327e-01 4.1103474e-04 1.2297122e-03 1.7028752e-08 8.6476156e-12
 9.9277586e-10 7.3917657e-11 4.3547442e-04 3.3922046e-01 2.6405297e-12
 6.5542076e-13], sum to 1.0000
[2019-04-24 10:42:00,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2582
[2019-04-24 10:42:00,430] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 23.05024593331972, 0.001909302873852538, 0.0, 1.0, 55.0, 54.586240124130086], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4484400.0000, 
sim time next is 4485600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 23.36037543538064, -0.114821130605421, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.4466979529483866, 0.461726289798193, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.75186336], dtype=float32), -0.7613075]. 
=============================================
[2019-04-24 10:42:00,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2241042e-01 3.2752694e-03 6.6209002e-03 2.7702993e-07 9.2805696e-10
 7.8845730e-09 5.2790639e-09 1.7047799e-03 3.6598834e-01 3.7575931e-10
 4.6217662e-11], sum to 1.0000
[2019-04-24 10:42:00,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2546
[2019-04-24 10:42:00,591] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 69.0, 170.5, 472.5, 19.0, 20.68656684896049, -0.6439769822558199, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4786800.0000, 
sim time next is 4788000.0000, 
raw observation next is [-3.0, 65.0, 163.5, 575.5, 19.0, 20.46619373294833, -0.6766350330227614, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3795013850415513, 0.65, 0.545, 0.6359116022099448, 0.08333333333333333, 0.20551614441236085, 0.2744549889924129, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.64789253], dtype=float32), 0.08603838]. 
=============================================
[2019-04-24 10:42:03,732] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:03,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:04,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1789731e-01 1.0582821e-03 2.9766643e-03 1.3036191e-07 1.1205691e-10
 1.2067957e-08 9.2513014e-10 1.1693088e-03 4.7689828e-01 6.6025560e-11
 1.0345277e-11], sum to 1.0000
[2019-04-24 10:42:04,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0729
[2019-04-24 10:42:04,177] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 75.0, 0.0, 0.0, 22.5, 20.19419004480304, -0.8065365812084743, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4605600.0000, 
sim time next is 4606800.0000, 
raw observation next is [-2.333333333333333, 73.0, 20.5, 28.49999999999999, 22.5, 20.0444777913577, -0.8171816924264713, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.3979686057248385, 0.73, 0.06833333333333333, 0.03149171270718231, 0.375, 0.17037314927980832, 0.22760610252450955, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1046981], dtype=float32), -0.5569332]. 
=============================================
[2019-04-24 10:42:04,747] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:04,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:04,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run10
[2019-04-24 10:42:04,909] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9275119e-01 1.3759353e-03 2.4265076e-04 8.4838980e-09 9.4087997e-13
 4.6247988e-09 7.5865789e-12 7.2535287e-05 2.0555764e-01 1.2474791e-12
 1.1416070e-12], sum to 1.0000
[2019-04-24 10:42:04,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2845
[2019-04-24 10:42:04,937] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.0, 26.0, 123.5, 855.0, 22.5, 25.57717864411192, 0.4714273315539284, 1.0, 1.0, 55.0, 51.95969401924311], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5054400.0000, 
sim time next is 5055600.0000, 
raw observation next is [8.333333333333334, 25.66666666666667, 123.8333333333333, 861.6666666666667, 22.5, 26.04346639558488, 0.3903895481961281, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6934441366574331, 0.2566666666666667, 0.4127777777777777, 0.9521178637200738, 0.375, 0.67028886629874, 0.6301298493987094, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6096904], dtype=float32), -0.68022954]. 
=============================================
[2019-04-24 10:42:05,827] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.0686251e-01 5.2723911e-04 1.9720746e-03 4.6584802e-08 1.3715845e-11
 1.0195489e-08 1.4362252e-10 6.6328456e-04 2.8997490e-01 1.9409556e-11
 1.6846074e-12], sum to 1.0000
[2019-04-24 10:42:05,828] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2526
[2019-04-24 10:42:05,846] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.6, 74.0, 0.0, 0.0, 19.0, 21.84442442498375, -0.4744490962811757, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4600800.0000, 
sim time next is 4602000.0000, 
raw observation next is [-2.733333333333333, 75.0, 0.0, 0.0, 19.0, 21.42530719329014, -0.5713973224814299, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.3868882733148662, 0.75, 0.0, 0.0, 0.08333333333333333, 0.2854422661075118, 0.30953422583952334, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5740899], dtype=float32), -0.23325893]. 
=============================================
[2019-04-24 10:42:06,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:06,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:07,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:07,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:07,095] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run10
[2019-04-24 10:42:07,759] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.4854591e-01 3.3295466e-04 1.7561682e-04 4.4520503e-09 2.1329901e-13
 1.9054353e-10 2.1520056e-12 8.1334947e-05 1.5086418e-01 5.2681866e-13
 4.0285161e-14], sum to 1.0000
[2019-04-24 10:42:07,764] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9912
[2019-04-24 10:42:07,858] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.333333333333333, 72.33333333333334, 187.8333333333333, 5.0, 22.5, 23.3508235098967, 0.09019433716771451, 1.0, 1.0, 55.0, 92.72609576324308], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4718400.0000, 
sim time next is 4719600.0000, 
raw observation next is [1.0, 72.0, 171.5, 3.0, 22.5, 24.44650895777273, 0.2204122587791263, 1.0, 1.0, 55.0, 56.78320907227105], 
processed observation next is [1.0, 0.6521739130434783, 0.4903047091412743, 0.72, 0.5716666666666667, 0.0033149171270718232, 0.375, 0.537209079814394, 0.5734707529263754, 1.0, 1.0, 0.8, 0.5678320907227105], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2947824], dtype=float32), 0.22200646]. 
=============================================
[2019-04-24 10:42:10,398] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:10,615] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:11,400] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:11,401] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:11,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run10
[2019-04-24 10:42:11,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:11,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:12,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:12,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:12,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run10
[2019-04-24 10:42:15,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:15,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:16,710] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:16,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:16,716] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run10
[2019-04-24 10:42:17,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:18,048] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:18,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:18,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:18,751] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run10
[2019-04-24 10:42:19,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:20,132] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:20,271] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.5826403e-01 9.0384815e-04 2.5957546e-04 1.0781808e-08 9.3568426e-13
 3.2297860e-09 7.5490161e-12 1.5399606e-04 1.4041862e-01 1.8773182e-12
 4.8888308e-13], sum to 1.0000
[2019-04-24 10:42:20,279] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8411
[2019-04-24 10:42:20,323] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.666666666666668, 19.0, 0.0, 0.0, 19.0, 25.6431691012388, 0.4844881040157444, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5084400.0000, 
sim time next is 5085600.0000, 
raw observation next is [9.333333333333334, 19.0, 0.0, 0.0, 19.0, 25.4986862339656, 0.4610632546552707, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.7211449676823639, 0.19, 0.0, 0.0, 0.08333333333333333, 0.6248905194971334, 0.6536877515517568, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.106305], dtype=float32), -0.64862394]. 
=============================================
[2019-04-24 10:42:20,734] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:20,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:20,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:20,841] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:20,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run10
[2019-04-24 10:42:20,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:20,993] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:21,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:21,714] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:21,714] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:21,718] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run10
[2019-04-24 10:42:21,751] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:21,751] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:21,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run10
[2019-04-24 10:42:21,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:21,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:22,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:22,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:22,499] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:22,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:22,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:22,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run10
[2019-04-24 10:42:22,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:22,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:22,820] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run10
[2019-04-24 10:42:23,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:23,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:23,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run10
[2019-04-24 10:42:24,406] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:24,763] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:25,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:25,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:25,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run10
[2019-04-24 10:42:25,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:25,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:26,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:26,351] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:26,422] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:42:26,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:42:26,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:26,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:26,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run10
[2019-04-24 10:42:26,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:26,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:27,003] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run10
[2019-04-24 10:42:27,423] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:42:27,423] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:42:27,427] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run10
[2019-04-24 10:42:38,852] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.2208889e-01 1.9887472e-03 2.5508890e-03 6.7492564e-08 2.8069946e-11
 1.0898503e-08 1.4980192e-09 3.7905530e-04 4.7299230e-01 6.3522708e-11
 3.9977149e-12], sum to 1.0000
[2019-04-24 10:42:38,853] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0213
[2019-04-24 10:42:38,875] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.1, 81.0, 0.0, 0.0, 19.0, 20.40454407361354, -0.7871745414502808, 0.0, 1.0, 55.0, 57.29357129834368], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 256800.0000, 
sim time next is 258000.0000, 
raw observation next is [-4.3, 80.0, 0.0, 0.0, 19.0, 20.40346326655757, -0.9453703817142277, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.34349030470914127, 0.8, 0.0, 0.0, 0.08333333333333333, 0.2002886055464641, 0.18487653942859075, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.180045], dtype=float32), -0.6589327]. 
=============================================
[2019-04-24 10:42:59,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7736897e-01 4.2752940e-03 1.5134036e-02 2.5555228e-06 4.8518540e-09
 5.6545741e-07 6.7515451e-08 2.3621724e-03 4.0085626e-01 1.2320079e-08
 1.2604346e-09], sum to 1.0000
[2019-04-24 10:42:59,838] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3290
[2019-04-24 10:42:59,855] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 57.0, 13.5, 8.5, 19.0, 19.71127665759776, -1.048096354759833, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 666000.0000, 
sim time next is 667200.0000, 
raw observation next is [-1.2, 57.00000000000001, 0.0, 0.0, 19.0, 19.28270127848774, -1.155144625137729, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.5700000000000001, 0.0, 0.0, 0.08333333333333333, 0.10689177320731158, 0.11495179162075697, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5630963], dtype=float32), -0.38862088]. 
=============================================
[2019-04-24 10:43:08,059] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7593498e-01 2.2720206e-03 2.9317434e-03 1.2120383e-07 1.1642198e-10
 2.1248241e-08 1.8214241e-09 5.4347538e-04 5.1831770e-01 1.3560528e-10
 2.1950273e-11], sum to 1.0000
[2019-04-24 10:43:08,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2887
[2019-04-24 10:43:08,094] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 19.0, 19.86386496301638, -1.083527643623371, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 711600.0000, 
sim time next is 712800.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 19.0, 19.3684969871549, -1.1917152350994, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.3988919667590028, 0.76, 0.0, 0.0, 0.08333333333333333, 0.11404141559624155, 0.10276158830019999, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5142803], dtype=float32), 1.5161849]. 
=============================================
[2019-04-24 10:43:13,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1483175e-01 1.5859447e-03 1.6158912e-02 1.6187521e-06 7.7237869e-09
 2.3602520e-07 2.1052569e-08 2.5721921e-03 3.6484942e-01 6.8246475e-09
 4.1561277e-10], sum to 1.0000
[2019-04-24 10:43:13,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7618
[2019-04-24 10:43:13,388] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 19.0, 20.0872954145032, -0.9299964369322953, 0.0, 1.0, 55.0, 53.32878577135328], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 684000.0000, 
sim time next is 685200.0000, 
raw observation next is [-3.566666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 20.18743641533322, -0.9180802990233875, 0.0, 1.0, 55.0, 52.48413204747335], 
processed observation next is [0.0, 0.9565217391304348, 0.3638042474607572, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.182286367944435, 0.19397323365887084, 0.0, 1.0, 0.8, 0.5248413204747335], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9262401], dtype=float32), 0.56163025]. 
=============================================
[2019-04-24 10:43:13,423] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.7059391e-01 1.9090016e-03 4.6131718e-03 7.9866595e-08 1.4872542e-11
 1.4893002e-08 7.0680661e-10 8.4437727e-04 6.2203950e-01 1.3308541e-11
 7.7680761e-12], sum to 1.0000
[2019-04-24 10:43:13,424] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7405
[2019-04-24 10:43:13,474] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 19.45866317397171, -0.8673109425418692, 0.0, 1.0, 55.0, 82.62266694307534], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 885600.0000, 
sim time next is 886800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 20.36511927583431, -0.789594091031902, 0.0, 1.0, 55.0, 52.511202238042486], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.1970932729861925, 0.23680196965603265, 0.0, 1.0, 0.8, 0.5251120223804249], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8494358], dtype=float32), -2.8819623]. 
=============================================
[2019-04-24 10:43:21,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2899473e-01 1.1684148e-04 8.6551812e-04 3.9649568e-09 7.9280712e-13
 1.2479187e-10 1.3656736e-12 9.4591160e-05 2.6992828e-01 2.6061653e-13
 2.2863381e-14], sum to 1.0000
[2019-04-24 10:43:21,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3681
[2019-04-24 10:43:21,515] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 93.0, 31.0, 0.0, 22.5, 23.3111414918677, -0.0005767959081263893, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1353600.0000, 
sim time next is 1354800.0000, 
raw observation next is [0.9000000000000001, 94.0, 22.33333333333333, 0.0, 22.5, 23.57996104437649, 0.01776379543712838, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.48753462603878117, 0.94, 0.07444444444444442, 0.0, 0.375, 0.4649967536980408, 0.5059212651457095, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7020605], dtype=float32), -0.65996623]. 
=============================================
[2019-04-24 10:43:21,635] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.6798898e-01 3.1204094e-04 1.2341958e-04 2.1246254e-09 3.5708798e-13
 1.6890171e-10 1.2676564e-12 3.9130246e-05 2.3153636e-01 2.7435603e-13
 9.2846337e-14], sum to 1.0000
[2019-04-24 10:43:21,638] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1203
[2019-04-24 10:43:21,654] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.4, 93.0, 60.0, 0.0, 22.5, 22.73195985917924, -0.3270717438061505, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 919200.0000, 
sim time next is 920400.0000, 
raw observation next is [4.4, 93.0, 48.0, 0.0, 22.5, 22.78463487946678, -0.3255054469700284, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5844875346260389, 0.93, 0.16, 0.0, 0.375, 0.39871957328889823, 0.39149818434332384, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.609671], dtype=float32), -0.5121518]. 
=============================================
[2019-04-24 10:43:22,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3355070e-01 1.5673247e-03 7.4745185e-04 8.1469063e-09 2.2573011e-13
 1.4705773e-10 2.0330780e-11 1.7745471e-04 3.6395708e-01 3.0683924e-13
 8.2014846e-14], sum to 1.0000
[2019-04-24 10:43:22,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5455
[2019-04-24 10:43:22,536] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 19.0, 23.27235367741849, -0.1339590062674079, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1399200.0000, 
sim time next is 1400400.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 22.5627007917966, -0.2796463063037446, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.3802250659830501, 0.40678456456541845, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.84156644], dtype=float32), 0.113204055]. 
=============================================
[2019-04-24 10:43:22,731] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7787828e-01 5.4625259e-04 9.0066074e-05 2.0377995e-09 4.2901080e-14
 6.3833827e-11 1.3121066e-12 2.8305112e-05 2.2145715e-01 2.8071964e-14
 5.8181800e-15], sum to 1.0000
[2019-04-24 10:43:22,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1442
[2019-04-24 10:43:22,753] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 19.0, 23.89745050868971, 0.05775104341900076, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1024800.0000, 
sim time next is 1026000.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 19.0, 23.56824751487348, 0.008909257940577267, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.77, 0.0, 0.0, 0.08333333333333333, 0.46402062623945667, 0.5029697526468591, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46837085], dtype=float32), 0.6875085]. 
=============================================
[2019-04-24 10:43:26,378] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.0584323e-01 9.0705224e-05 2.2467214e-04 2.8454747e-09 1.1972789e-12
 2.2313595e-10 2.7141532e-11 1.1333472e-04 1.9372800e-01 1.8408849e-12
 1.8217209e-14], sum to 1.0000
[2019-04-24 10:43:26,389] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4090
[2019-04-24 10:43:26,398] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.5, 100.0, 0.0, 0.0, 19.0, 24.43088399665029, 0.3167819260284612, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1285200.0000, 
sim time next is 1286400.0000, 
raw observation next is [5.5, 100.0, 0.0, 0.0, 19.0, 23.96447863808351, 0.2485961858010598, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.6149584487534627, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4970398865069591, 0.58286539526702, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2293174], dtype=float32), 1.2194229]. 
=============================================
[2019-04-24 10:43:27,739] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.4046805e-01 1.9014331e-04 3.1181256e-04 2.1582243e-09 1.0710317e-14
 1.7813391e-11 2.3541249e-13 2.9324374e-05 1.5900068e-01 1.3931450e-14
 2.3005195e-15], sum to 1.0000
[2019-04-24 10:43:27,739] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5599
[2019-04-24 10:43:27,752] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.26666666666667, 84.33333333333334, 120.5, 0.0, 22.5, 23.95756408096146, 0.04646798453426102, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 998400.0000, 
sim time next is 999600.0000, 
raw observation next is [13.83333333333333, 82.66666666666667, 114.8333333333333, 0.0, 22.5, 24.00351908185945, 0.05915030510801903, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8457987072945522, 0.8266666666666667, 0.38277777777777766, 0.0, 0.375, 0.500293256821621, 0.5197167683693397, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15893003], dtype=float32), -0.32513323]. 
=============================================
[2019-04-24 10:43:31,466] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2216866e-01 8.5327378e-04 2.6256728e-04 3.3594152e-09 5.0356296e-13
 4.7519577e-10 2.4261667e-12 1.7330110e-04 3.7654221e-01 8.8899909e-14
 7.1032278e-14], sum to 1.0000
[2019-04-24 10:43:31,468] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3197
[2019-04-24 10:43:31,481] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 94.66666666666667, 0.0, 0.0, 19.0, 23.1580927199124, -0.06033266450273369, 0.0, 1.0, 55.0, 46.03339716719542], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1480800.0000, 
sim time next is 1482000.0000, 
raw observation next is [2.2, 95.33333333333334, 0.0, 0.0, 19.0, 23.25078641027694, -0.1964904100027493, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5235457063711911, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.4375655341897451, 0.4345031966657502, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1054306], dtype=float32), -1.7167938]. 
=============================================
[2019-04-24 10:43:42,437] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8505220e-01 3.4031374e-04 1.3464810e-04 2.5352378e-09 3.1659324e-13
 9.1090337e-11 2.4942010e-12 3.4030672e-05 1.1443878e-01 1.8520440e-13
 6.1156111e-14], sum to 1.0000
[2019-04-24 10:43:42,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9099
[2019-04-24 10:43:42,492] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 95.0, 91.0, 0.0, 22.5, 23.95660700106703, -0.04901584424990158, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1424400.0000, 
sim time next is 1425600.0000, 
raw observation next is [0.0, 95.0, 93.0, 0.0, 22.5, 24.1471780314334, 0.1606603064296257, 1.0, 1.0, 55.0, 72.44485185233853], 
processed observation next is [1.0, 0.5217391304347826, 0.46260387811634357, 0.95, 0.31, 0.0, 0.375, 0.5122648359527832, 0.5535534354765419, 1.0, 1.0, 0.8, 0.7244485185233853], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1093936], dtype=float32), 0.06846298]. 
=============================================
[2019-04-24 10:43:44,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4052478e-01 6.5424177e-04 2.5886600e-03 1.4183784e-08 1.0804957e-11
 1.4951709e-09 5.1939571e-11 2.6630718e-04 4.5596603e-01 2.8664599e-12
 2.3329982e-13], sum to 1.0000
[2019-04-24 10:43:44,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8387
[2019-04-24 10:43:44,597] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.2, 92.0, 0.0, 0.0, 19.0, 21.38824596119216, -0.4755396251772799, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1476000.0000, 
sim time next is 1477200.0000, 
raw observation next is [2.2, 92.66666666666667, 0.0, 0.0, 19.0, 21.75189749013373, -0.2058931214778047, 0.0, 1.0, 55.0, 77.38311200345495], 
processed observation next is [1.0, 0.08695652173913043, 0.5235457063711911, 0.9266666666666667, 0.0, 0.0, 0.08333333333333333, 0.31265812417781075, 0.4313689595073984, 0.0, 1.0, 0.8, 0.7738311200345496], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4693618], dtype=float32), -0.5290781]. 
=============================================
[2019-04-24 10:43:46,783] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.4111366e-01 1.0797159e-03 1.4923450e-04 1.0443464e-08 1.5898059e-13
 9.8820685e-10 1.8869450e-12 3.0008330e-05 2.5762740e-01 9.9089248e-14
 5.9321675e-14], sum to 1.0000
[2019-04-24 10:43:46,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4619
[2019-04-24 10:43:46,810] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 23.50194956721138, -0.02142594283646711, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1710000.0000, 
sim time next is 1711200.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 22.97636328781912, -0.09726164258664997, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.41469694065159324, 0.4675794524711167, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3051687], dtype=float32), 0.18716116]. 
=============================================
[2019-04-24 10:43:56,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6314314e-01 2.8765949e-03 9.5621711e-03 5.5414051e-07 5.9529852e-09
 8.3636380e-08 2.4969104e-08 1.8544735e-03 5.2256304e-01 1.0854849e-09
 3.4289979e-10], sum to 1.0000
[2019-04-24 10:43:56,587] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4951
[2019-04-24 10:43:56,717] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.6, 78.0, 134.0, 72.5, 19.0, 19.98894145835796, -0.8593678370468543, 0.0, 1.0, 55.0, 76.78593506467621], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1850400.0000, 
sim time next is 1851600.0000, 
raw observation next is [-5.6, 77.0, 124.6666666666667, 58.16666666666666, 19.0, 20.39652770566026, -0.8136509534700377, 0.0, 1.0, 55.0, 55.49139071529921], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.77, 0.4155555555555557, 0.06427255985267034, 0.08333333333333333, 0.19971064213835513, 0.22878301550998745, 0.0, 1.0, 0.8, 0.5549139071529922], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5986293], dtype=float32), 0.823977]. 
=============================================
[2019-04-24 10:43:58,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3483701e-01 8.0352154e-04 1.5245950e-03 1.3014999e-08 5.5922194e-12
 2.9572631e-09 1.8558065e-10 5.3010805e-04 4.6230480e-01 2.2442263e-12
 1.1074164e-12], sum to 1.0000
[2019-04-24 10:43:58,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6249
[2019-04-24 10:43:58,440] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 86.0, 0.0, 0.0, 19.0, 21.15923379768987, -0.5568351444239282, 0.0, 1.0, 55.0, 72.52403557043016], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2084400.0000, 
sim time next is 2085600.0000, 
raw observation next is [-5.2, 87.66666666666667, 0.0, 0.0, 19.0, 21.58528024178877, -0.5114051629450228, 0.0, 1.0, 55.0, 52.102572565826925], 
processed observation next is [1.0, 0.13043478260869565, 0.31855955678670367, 0.8766666666666667, 0.0, 0.0, 0.08333333333333333, 0.2987733534823975, 0.32953161235165906, 0.0, 1.0, 0.8, 0.5210257256582692], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17282519], dtype=float32), -0.73384035]. 
=============================================
[2019-04-24 10:44:02,931] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6418540e-01 1.3900575e-03 1.5499577e-03 5.0220343e-08 2.8652984e-11
 9.3988515e-09 2.2282146e-10 5.3451181e-04 3.3233997e-01 4.2653350e-11
 4.9534626e-12], sum to 1.0000
[2019-04-24 10:44:02,932] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6450
[2019-04-24 10:44:02,960] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.566666666666666, 69.33333333333333, 0.0, 0.0, 22.5, 21.07510492879531, -0.6313740551707034, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2227200.0000, 
sim time next is 2228400.0000, 
raw observation next is [-4.6, 70.0, 0.0, 0.0, 22.5, 20.89709825024792, -0.6820918499738138, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.33518005540166207, 0.7, 0.0, 0.0, 0.375, 0.24142485418732682, 0.27263605000872876, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9069169], dtype=float32), -0.75956523]. 
=============================================
[2019-04-24 10:44:26,494] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1896387e-01 8.3937831e-03 3.7506454e-02 8.5915690e-06 5.4718672e-08
 1.6029985e-06 5.0619605e-07 2.5791863e-03 4.3254578e-01 9.3399358e-08
 1.5692958e-08], sum to 1.0000
[2019-04-24 10:44:26,503] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1001
[2019-04-24 10:44:26,537] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 44.66666666666667, 0.0, 0.0, 19.0, 18.86141532325182, -1.196033334359525, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2420400.0000, 
sim time next is 2421600.0000, 
raw observation next is [-6.0, 46.33333333333334, 0.0, 0.0, 19.0, 18.53295556370497, -1.261523091386779, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.296398891966759, 0.46333333333333343, 0.0, 0.0, 0.08333333333333333, 0.04441296364208084, 0.07949230287107367, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.1275, 
noisyNet noise sample is [array([-0.5373374], dtype=float32), -0.3282927]. 
=============================================
[2019-04-24 10:44:28,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8460442e-01 2.0242964e-03 8.8511151e-04 6.8076162e-08 2.6922948e-11
 8.1578939e-09 1.5429956e-09 7.6725398e-04 5.1171887e-01 2.5402820e-11
 1.3980955e-11], sum to 1.0000
[2019-04-24 10:44:28,721] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7927
[2019-04-24 10:44:28,842] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.533333333333333, 79.66666666666667, 0.0, 0.0, 19.0, 20.11771818757435, -0.7795806574045548, 0.0, 1.0, 55.0, 75.70973962569917], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2612400.0000, 
sim time next is 2613600.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 19.0, 20.50759225775088, -0.7396500154390312, 0.0, 1.0, 55.0, 54.29358580780274], 
processed observation next is [1.0, 0.2608695652173913, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.20896602147923993, 0.25344999485365627, 0.0, 1.0, 0.8, 0.5429358580780275], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42147985], dtype=float32), 0.22023441]. 
=============================================
[2019-04-24 10:44:42,471] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-24 10:44:42,472] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:44:42,473] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:44:42,475] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:44:42,476] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:44:42,475] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run14
[2019-04-24 10:44:42,478] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run14
[2019-04-24 10:44:42,553] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:44:42,556] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:44:42,559] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run14
[2019-04-24 10:46:33,732] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.22496794], dtype=float32), 0.32621044]
[2019-04-24 10:46:33,732] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [1.933333333333333, 47.33333333333333, 245.1666666666667, 348.8333333333334, 22.5, 23.42874595833339, -0.09081690106496425, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:46:33,733] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:46:33,734] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [8.0595481e-01 1.0704570e-03 1.8486151e-03 1.6198810e-07 1.7262405e-10
 1.7772827e-08 4.0002857e-10 5.6942058e-04 1.9055657e-01 1.2954172e-10
 1.6964229e-11], sampled 0.806766666099961
[2019-04-24 10:46:42,455] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([0.22496794], dtype=float32), 0.32621044]
[2019-04-24 10:46:42,455] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [4.8, 45.0, 143.0, 757.5, 22.5, 23.75719019682663, -0.02710170846075871, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:46:42,455] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:46:42,456] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [7.94388950e-01 1.39545836e-03 1.45246054e-03 1.08376419e-07
 8.29287888e-11 1.33971385e-08 4.18316298e-10 5.22067887e-04
 2.02240929e-01 8.85450255e-11 7.37597657e-12], sampled 0.8984776927625674
[2019-04-24 10:46:56,663] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2920.6365 87298.4719 148.1387
[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:46:56,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:04,898] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2679.8222 98055.6783 -211.8111
[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:05,026] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,023] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2636.2206 101137.1113 -288.9413
[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,043] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:12,148] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:47:13,045] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 650000, evaluation results [650000.0, 2679.8221769131505, 98055.67825263353, -211.81109373861474, 2920.6365084958493, 87298.47185234302, 148.13873855466585, 2636.220552033623, 101137.11133127369, -288.9412805505102]
[2019-04-24 10:47:13,307] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.3727628e-01 4.1655128e-04 7.9609232e-04 3.0007467e-08 1.2355936e-11
 3.7591930e-09 1.8292158e-11 1.5226753e-04 1.6135882e-01 2.9972283e-12
 5.6936633e-13], sum to 1.0000
[2019-04-24 10:47:13,313] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7980
[2019-04-24 10:47:13,341] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.733333333333333, 24.66666666666666, 91.0, 12.66666666666666, 22.5, 23.97954831108979, 0.03481047412547315, 1.0, 1.0, 55.0, 84.22580430239528], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2821200.0000, 
sim time next is 2822400.0000, 
raw observation next is [6.6, 25.0, 83.0, 38.0, 22.5, 24.33879288889509, -0.06854252258271905, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.6454293628808865, 0.25, 0.27666666666666667, 0.041988950276243095, 0.375, 0.5282327407412574, 0.477152492472427, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1479796], dtype=float32), 1.9872358]. 
=============================================
[2019-04-24 10:47:13,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6182996e-01 1.7002376e-03 2.1773067e-03 4.9546994e-08 5.0039421e-12
 5.5445328e-09 4.3809337e-10 4.9573305e-04 5.3379673e-01 1.0276395e-11
 5.7362708e-12], sum to 1.0000
[2019-04-24 10:47:13,433] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1366
[2019-04-24 10:47:13,459] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 88.33333333333334, 0.0, 0.0, 19.0, 21.89956244244544, -0.5696499813723921, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2863200.0000, 
sim time next is 2864400.0000, 
raw observation next is [1.0, 90.66666666666667, 0.0, 0.0, 19.0, 21.1346333766133, -0.7317810376153804, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.4903047091412743, 0.9066666666666667, 0.0, 0.0, 0.08333333333333333, 0.26121944805110847, 0.2560729874615399, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16373004], dtype=float32), 1.9541843]. 
=============================================
[2019-04-24 10:47:16,369] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5303884e-01 6.8316254e-04 7.3488720e-04 1.6969091e-08 1.2929781e-12
 3.0324010e-10 2.7371263e-11 1.2692717e-04 4.4541612e-01 1.5730193e-12
 1.8611703e-13], sum to 1.0000
[2019-04-24 10:47:16,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0329
[2019-04-24 10:47:16,387] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 19.0, 22.60861058829004, -0.1368600564229937, 0.0, 1.0, 55.0, 52.49862790648126], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2930400.0000, 
sim time next is 2931600.0000, 
raw observation next is [-1.333333333333333, 80.33333333333334, 0.0, 0.0, 19.0, 22.54774653956543, -0.3638024505386328, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.42566943674976926, 0.8033333333333335, 0.0, 0.0, 0.08333333333333333, 0.37897887829711924, 0.3787325164871224, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48027793], dtype=float32), 0.27562025]. 
=============================================
[2019-04-24 10:47:17,475] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6224296e-01 2.3892934e-03 9.6272416e-03 3.9193208e-07 1.8037660e-10
 2.8469959e-08 2.8120286e-09 7.7041471e-04 5.2496958e-01 3.8973424e-10
 6.9823008e-11], sum to 1.0000
[2019-04-24 10:47:17,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0624
[2019-04-24 10:47:17,492] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 19.75172874256146, -0.8341128603016196, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2757600.0000, 
sim time next is 2758800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 19.59452423747199, -0.9255760324804382, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.13287701978933253, 0.19147465583985393, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8211442], dtype=float32), -0.06283643]. 
=============================================
[2019-04-24 10:47:17,962] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.5255219e-01 4.0422552e-04 2.3914204e-04 8.5792218e-09 8.5966488e-13
 4.0505185e-10 9.0893881e-12 1.2979603e-04 3.4667462e-01 5.0400016e-13
 5.3030117e-14], sum to 1.0000
[2019-04-24 10:47:17,963] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.7327
[2019-04-24 10:47:17,999] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 22.52836276196966, -0.2151169644065025, 0.0, 1.0, 55.0, 50.193733639545414], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2936400.0000, 
sim time next is 2937600.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 22.65871741175222, -0.212736647463339, 0.0, 1.0, 55.0, 49.83269519773857], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.38822645097935177, 0.429087784178887, 0.0, 1.0, 0.8, 0.49832695197738575], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5605406], dtype=float32), 0.6302665]. 
=============================================
[2019-04-24 10:47:21,169] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.75956678e-01 1.97387137e-03 3.53648653e-03 6.95448961e-08
 1.36165263e-11 9.79095827e-09 1.14228314e-10 3.19077459e-04
 5.18213809e-01 1.05223165e-11 2.89199025e-12], sum to 1.0000
[2019-04-24 10:47:21,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9284
[2019-04-24 10:47:21,207] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 19.0, 22.89541198971064, -0.2052465206238604, 0.0, 1.0, 55.0, 53.086507273630005], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2844000.0000, 
sim time next is 2845200.0000, 
raw observation next is [2.0, 50.0, 0.0, 0.0, 19.0, 22.9988360706755, -0.2369702517422888, 0.0, 1.0, 55.0, 52.148243355348974], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.5, 0.0, 0.0, 0.08333333333333333, 0.4165696725562918, 0.42100991608590377, 0.0, 1.0, 0.8, 0.5214824335534898], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9467156], dtype=float32), -0.15461266]. 
=============================================
[2019-04-24 10:47:25,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3359871e-01 1.7239644e-04 1.5542285e-04 2.2515177e-10 9.4783512e-15
 1.6002564e-11 3.5262407e-13 1.8084582e-05 2.6605543e-01 4.6108937e-15
 7.8403397e-16], sum to 1.0000
[2019-04-24 10:47:25,708] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2491
[2019-04-24 10:47:25,754] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.866666666666667, 99.66666666666667, 86.83333333333333, 693.0, 22.5, 26.19756168702398, 0.5385135706091443, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3165600.0000, 
sim time next is 3166800.0000, 
raw observation next is [6.733333333333333, 99.33333333333334, 79.66666666666666, 649.0, 22.5, 26.11260783050539, 0.5185728586360278, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.649122807017544, 0.9933333333333334, 0.26555555555555554, 0.7171270718232045, 0.375, 0.6760506525421158, 0.6728576195453426, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6144109], dtype=float32), -1.0469897]. 
=============================================
[2019-04-24 10:47:29,740] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7252765e-01 9.9505309e-04 1.7953977e-02 1.9738422e-07 8.8478713e-10
 1.6809384e-08 5.0905786e-09 9.8525721e-04 5.0753784e-01 8.7381885e-10
 2.5885606e-11], sum to 1.0000
[2019-04-24 10:47:29,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0499
[2019-04-24 10:47:29,773] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 19.0, 18.58381933658246, -1.200692488005582, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3110400.0000, 
sim time next is 3111600.0000, 
raw observation next is [0.3333333333333333, 100.0, 0.0, 0.0, 19.0, 18.48198491962355, -1.223951074229204, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4718374884579871, 1.0, 0.0, 0.0, 0.08333333333333333, 0.04016540996862913, 0.09201630859026537, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15522477], dtype=float32), 0.52657014]. 
=============================================
[2019-04-24 10:47:31,287] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.7995131e-01 6.4885482e-04 4.8415325e-04 1.6883318e-08 6.7761156e-13
 4.0804421e-10 3.4056046e-11 3.2862395e-04 3.1858709e-01 1.0987483e-12
 7.9250856e-14], sum to 1.0000
[2019-04-24 10:47:31,287] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4411
[2019-04-24 10:47:31,309] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 102.3333333333333, 669.5, 22.5, 23.81975613904347, 0.04653030732152776, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3231600.0000, 
sim time next is 3232800.0000, 
raw observation next is [-3.0, 92.0, 105.0, 702.5, 22.5, 23.82920660318325, 0.05698716469009179, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.92, 0.35, 0.7762430939226519, 0.375, 0.48576721693193736, 0.5189957215633639, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.10406014], dtype=float32), -0.29533774]. 
=============================================
[2019-04-24 10:47:33,140] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1109754e-01 2.5088454e-04 1.5095336e-04 1.1664720e-09 5.6048800e-14
 5.5352382e-11 6.5702429e-13 3.5640169e-05 2.8846496e-01 2.9263230e-14
 2.3983185e-15], sum to 1.0000
[2019-04-24 10:47:33,140] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5578
[2019-04-24 10:47:33,171] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 97.66666666666667, 0.0, 0.0, 19.0, 24.33264944791141, 0.3585720041433852, 0.0, 1.0, 55.0, 71.50598071259131], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3190800.0000, 
sim time next is 3192000.0000, 
raw observation next is [2.0, 95.33333333333334, 0.0, 0.0, 19.0, 24.54675360084791, 0.2366190837214601, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.5455628000706593, 0.5788730279071533, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3267196], dtype=float32), -0.6702217]. 
=============================================
[2019-04-24 10:47:35,804] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3647834e-01 1.9012516e-03 8.0901233e-04 2.6364159e-08 2.9226871e-11
 1.1755996e-08 5.6052985e-11 3.1942208e-04 4.6049190e-01 1.9155717e-11
 2.2920609e-12], sum to 1.0000
[2019-04-24 10:47:35,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1117
[2019-04-24 10:47:35,840] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 23.0273000406933, -0.1645301475092156, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3891600.0000, 
sim time next is 3892800.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 22.61442066757764, -0.2325583406241064, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.38453505563147, 0.4224805531252979, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.96852154], dtype=float32), -0.14067978]. 
=============================================
[2019-04-24 10:47:36,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7942357e-01 1.5013564e-03 3.3747130e-03 3.6380392e-08 7.3484691e-11
 7.5750357e-09 5.4881222e-10 7.7086844e-04 3.1492946e-01 3.5838315e-11
 3.5142306e-12], sum to 1.0000
[2019-04-24 10:47:36,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5269
[2019-04-24 10:47:36,803] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 22.01564956842713, -0.3845755222458503, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3892800.0000, 
sim time next is 3894000.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 21.72311297844444, -0.4451911502550404, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.31025941487037006, 0.3516029499149866, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5498711], dtype=float32), -1.0526135]. 
=============================================
[2019-04-24 10:47:38,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2235719e-01 1.7063656e-03 6.1064708e-04 3.3373311e-08 1.2556810e-12
 4.3919193e-09 4.8226360e-11 1.8761700e-04 3.7513816e-01 7.4021979e-13
 5.8891103e-13], sum to 1.0000
[2019-04-24 10:47:38,790] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0108
[2019-04-24 10:47:38,841] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 76.66666666666667, 0.0, 0.0, 19.0, 22.59976565206967, -0.1335020943817968, 0.0, 1.0, 55.0, 72.80879835467594], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3464400.0000, 
sim time next is 3465600.0000, 
raw observation next is [1.0, 74.33333333333334, 0.0, 0.0, 19.0, 22.92213481119325, -0.2683174465093711, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.4101779009327708, 0.41056085116354296, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4651921], dtype=float32), 1.1243984]. 
=============================================
[2019-04-24 10:47:44,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0388627e-01 2.1078992e-03 2.2555818e-03 8.2649149e-07 1.5456428e-09
 2.2237400e-07 4.3817967e-09 8.0679671e-04 2.9094237e-01 6.5987377e-10
 2.0989541e-10], sum to 1.0000
[2019-04-24 10:47:44,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7647
[2019-04-24 10:47:44,092] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 19.0, 22.42070163901996, -0.4085683657086108, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3636000.0000, 
sim time next is 3637200.0000, 
raw observation next is [8.733333333333334, 25.66666666666667, 0.0, 0.0, 19.0, 22.54993380459418, -0.2103122661682497, 0.0, 1.0, 55.0, 70.48530980883557], 
processed observation next is [0.0, 0.08695652173913043, 0.7045244690674055, 0.2566666666666667, 0.0, 0.0, 0.08333333333333333, 0.37916115038284826, 0.4298959112772501, 0.0, 1.0, 0.8, 0.7048530980883556], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26672], dtype=float32), -0.26568416]. 
=============================================
[2019-04-24 10:47:44,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2093680e-01 9.9472946e-04 8.6433272e-04 1.0532086e-07 5.2908420e-12
 7.1154904e-09 3.3541867e-11 1.2995406e-04 1.7707402e-01 3.3275878e-12
 2.8727431e-12], sum to 1.0000
[2019-04-24 10:47:44,739] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7177
[2019-04-24 10:47:44,757] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 35.0, 93.5, 566.0, 22.5, 25.0116967003674, 0.2497729154887296, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4118400.0000, 
sim time next is 4119600.0000, 
raw observation next is [3.666666666666667, 35.66666666666667, 93.16666666666666, 480.0, 22.5, 25.17892976695266, 0.1809908721418542, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.564173591874423, 0.3566666666666667, 0.31055555555555553, 0.5303867403314917, 0.375, 0.598244147246055, 0.5603302907139515, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2832386], dtype=float32), -0.44766888]. 
=============================================
[2019-04-24 10:47:49,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3254266e-01 1.4920782e-03 5.4891873e-04 1.3548319e-07 1.7963056e-11
 8.1558511e-09 1.6641918e-10 2.1810213e-04 1.6519809e-01 4.3739679e-11
 1.0685230e-11], sum to 1.0000
[2019-04-24 10:47:49,045] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2204
[2019-04-24 10:47:49,072] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 20.66666666666667, 91.5, 725.6666666666667, 22.5, 24.86147290424576, 0.07423261928821762, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4029600.0000, 
sim time next is 4030800.0000, 
raw observation next is [-1.333333333333333, 21.33333333333334, 85.33333333333334, 684.6666666666667, 22.5, 23.63170430668934, 0.007253244085993944, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.42566943674976926, 0.2133333333333334, 0.2844444444444445, 0.7565377532228362, 0.375, 0.46930869222411165, 0.5024177480286647, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.589117], dtype=float32), -0.102312066]. 
=============================================
[2019-04-24 10:47:51,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5524700e-01 9.7043393e-04 1.6655308e-03 5.9783041e-08 4.6016930e-11
 9.0121786e-09 3.2188185e-10 5.2861753e-04 2.4158835e-01 2.2207135e-11
 3.3562118e-12], sum to 1.0000
[2019-04-24 10:47:51,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8978
[2019-04-24 10:47:51,471] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.0, 50.0, 75.5, 613.5, 19.0, 24.67481139262344, 0.2085008157068674, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3686400.0000, 
sim time next is 3687600.0000, 
raw observation next is [4.666666666666667, 53.0, 67.83333333333333, 552.5, 19.0, 24.8539378080142, 0.3987257978535823, 0.0, 1.0, 55.0, 63.437753251548315], 
processed observation next is [0.0, 0.6956521739130435, 0.5918744228993538, 0.53, 0.2261111111111111, 0.6104972375690608, 0.08333333333333333, 0.5711614840011835, 0.6329085992845275, 0.0, 1.0, 0.8, 0.6343775325154831], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3133515], dtype=float32), -0.24289505]. 
=============================================
[2019-04-24 10:47:51,677] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.8683668e-01 9.1716816e-04 4.9824902e-04 8.1750393e-08 4.7034113e-12
 3.4100072e-09 3.1716300e-11 1.7853842e-04 2.1156932e-01 3.3069159e-12
 3.2781582e-13], sum to 1.0000
[2019-04-24 10:47:51,695] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1402
[2019-04-24 10:47:51,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3571702e-01 2.7936671e-04 1.4743046e-04 4.3197272e-09 1.4700746e-13
 1.2027265e-10 8.4570171e-13 1.5113423e-04 1.6370513e-01 1.5414009e-13
 1.6907801e-14], sum to 1.0000
[2019-04-24 10:47:51,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3057
[2019-04-24 10:47:51,712] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 71.0, 0.0, 0.0, 22.5, 23.14340448646126, -0.1252479018498625, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3782400.0000, 
sim time next is 3783600.0000, 
raw observation next is [-2.0, 71.0, 0.0, 0.0, 22.5, 22.92991073450353, -0.1780160581432176, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.40720221606648205, 0.71, 0.0, 0.0, 0.375, 0.4108258945419608, 0.4406613139522608, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.59603465], dtype=float32), -0.54740083]. 
=============================================
[2019-04-24 10:47:51,724] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.1, 31.66666666666666, 179.6666666666667, 524.1666666666667, 22.5, 26.95786279564233, 0.6111339868234898, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4372800.0000, 
sim time next is 4374000.0000, 
raw observation next is [13.9, 32.0, 149.0, 314.5, 22.5, 25.72527653605299, 0.5576569876755928, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.847645429362881, 0.32, 0.49666666666666665, 0.3475138121546961, 0.375, 0.6437730446710827, 0.6858856625585309, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6434865], dtype=float32), -0.5638611]. 
=============================================
[2019-04-24 10:47:52,073] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0677521e-01 7.9166994e-04 2.4470519e-03 2.7440711e-07 2.3546018e-10
 3.8056783e-08 1.2215845e-09 3.0803474e-04 1.8967772e-01 7.8537822e-11
 4.4383986e-11], sum to 1.0000
[2019-04-24 10:47:52,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2094
[2019-04-24 10:47:52,100] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.333333333333334, 46.33333333333334, 0.0, 0.0, 19.0, 22.54907489909919, -0.2782309147612739, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3964800.0000, 
sim time next is 3966000.0000, 
raw observation next is [-7.666666666666666, 47.66666666666666, 0.0, 0.0, 19.0, 21.96056414338096, -0.3680608867040065, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.25023084025854114, 0.47666666666666657, 0.0, 0.0, 0.08333333333333333, 0.33004701194841335, 0.37731303776533115, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5610892], dtype=float32), -2.3193133]. 
=============================================
[2019-04-24 10:47:52,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.8907708e-01 9.8137208e-04 7.0515875e-04 4.0430340e-08 3.7765589e-12
 2.2808062e-09 6.3742019e-11 7.5919792e-04 3.0847719e-01 3.4672180e-12
 1.2748615e-12], sum to 1.0000
[2019-04-24 10:47:52,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0862
[2019-04-24 10:47:52,764] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 23.52052862823477, -0.1984213172810947, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3726000.0000, 
sim time next is 3727200.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 22.89246759969081, -0.3141574939788566, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.40770563330756754, 0.3952808353403811, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8801987], dtype=float32), -0.8222512]. 
=============================================
[2019-04-24 10:47:54,998] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.0754483e-01 8.2083186e-04 3.9407047e-03 3.3711436e-07 1.0579919e-09
 6.7767232e-08 4.1379300e-09 6.7216984e-04 1.8702111e-01 1.1378559e-09
 7.6079365e-11], sum to 1.0000
[2019-04-24 10:47:55,023] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0292
[2019-04-24 10:47:55,045] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.7, 41.0, 0.0, 0.0, 19.0, 23.23483572141161, -0.207380744513594, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4212000.0000, 
sim time next is 4213200.0000, 
raw observation next is [1.6, 41.33333333333334, 0.0, 0.0, 19.0, 22.71547482204887, -0.2912820150264367, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5069252077562327, 0.41333333333333344, 0.0, 0.0, 0.08333333333333333, 0.392956235170739, 0.40290599499118773, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05243632], dtype=float32), -0.17435248]. 
=============================================
[2019-04-24 10:47:59,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3909643e-01 1.1572426e-03 4.8241368e-04 4.3406068e-08 1.7394693e-11
 4.1586952e-09 3.4609601e-10 4.3283301e-04 1.5883099e-01 1.9535122e-11
 6.8298527e-12], sum to 1.0000
[2019-04-24 10:47:59,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7280
[2019-04-24 10:47:59,873] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 33.0, 115.1666666666667, 776.8333333333334, 22.5, 24.95869614800995, 0.09311336326014304, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4099200.0000, 
sim time next is 4100400.0000, 
raw observation next is [-1.0, 32.0, 117.5, 792.5, 22.5, 24.75270647277892, 0.05519663406144292, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4349030470914128, 0.32, 0.39166666666666666, 0.8756906077348067, 0.375, 0.5627255393982434, 0.518398878020481, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.161867], dtype=float32), -0.6780223]. 
=============================================
[2019-04-24 10:48:00,365] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.49913549e-01 5.22949267e-03 6.77061407e-03 6.42768782e-07
 9.94058280e-10 1.42941147e-07 1.15282495e-08 1.58813596e-03
 3.36497396e-01 1.16144949e-09 5.09208786e-10], sum to 1.0000
[2019-04-24 10:48:00,366] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5709
[2019-04-24 10:48:00,388] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 35.0, 116.5, 798.0, 19.0, 23.17723725939781, -0.1314298963037362, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4186800.0000, 
sim time next is 4188000.0000, 
raw observation next is [-0.3333333333333334, 33.33333333333334, 118.1666666666667, 814.0, 19.0, 22.91052345228992, -0.2016136352812312, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.4533702677747, 0.3333333333333334, 0.393888888888889, 0.8994475138121547, 0.08333333333333333, 0.40921028769082657, 0.43279545490625626, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2641275], dtype=float32), -1.5162295]. 
=============================================
[2019-04-24 10:48:02,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7143583e-01 3.7348869e-03 4.5603081e-03 4.5211740e-07 4.4052115e-10
 2.9254531e-08 4.6427009e-09 2.2317346e-03 3.1803676e-01 3.6519024e-10
 1.4581533e-10], sum to 1.0000
[2019-04-24 10:48:02,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5534
[2019-04-24 10:48:02,071] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 19.0, 21.46388944672416, -0.6686887112263468, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3988800.0000, 
sim time next is 3990000.0000, 
raw observation next is [-12.33333333333333, 65.0, 0.0, 0.0, 19.0, 20.53726136789625, -0.8136877896730913, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.12096029547553101, 0.65, 0.0, 0.0, 0.08333333333333333, 0.21143844732468745, 0.22877073677563622, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1420892], dtype=float32), -0.7886755]. 
=============================================
[2019-04-24 10:48:02,081] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.267685]
 [55.891453]
 [55.440094]
 [54.7742  ]
 [54.07676 ]
 [54.60965 ]
 [55.51797 ]
 [54.698803]
 [55.750206]
 [56.687984]
 [57.649925]
 [58.259613]
 [57.71799 ]
 [58.581066]
 [59.108925]
 [58.375385]
 [57.110573]
 [56.874527]
 [55.830574]
 [54.92473 ]
 [53.533695]
 [53.95708 ]
 [54.47201 ]
 [55.670803]
 [56.707844]], R is [[55.20281219]
 [55.65078354]
 [55.09427643]
 [54.54333496]
 [53.99790192]
 [54.45792389]
 [54.91334534]
 [54.36421204]
 [54.8205719 ]
 [55.27236557]
 [55.71964264]
 [56.16244507]
 [55.60082245]
 [56.04481506]
 [56.48436737]
 [55.91952515]
 [55.36032867]
 [55.80672455]
 [55.24865723]
 [54.69617081]
 [54.14920807]
 [54.60771561]
 [55.06163788]
 [55.51102066]
 [55.95590973]].
[2019-04-24 10:48:03,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9905981e-01 1.4622727e-03 2.6810393e-03 4.0354854e-07 1.5781995e-09
 9.6587755e-08 3.1647438e-09 2.6391314e-03 1.9415729e-01 1.0032585e-09
 5.1651565e-11], sum to 1.0000
[2019-04-24 10:48:03,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5978
[2019-04-24 10:48:03,087] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 39.33333333333333, 144.6666666666667, 540.0, 19.0, 22.7780704217778, -0.01371809915370286, 0.0, 1.0, 55.0, 71.5313342794786], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4203600.0000, 
sim time next is 4204800.0000, 
raw observation next is [3.0, 37.0, 114.0, 544.0, 19.0, 23.54151518833539, -0.05158794014728622, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.37, 0.38, 0.6011049723756906, 0.08333333333333333, 0.4617929323612824, 0.48280401995090455, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6054675], dtype=float32), 1.6871136]. 
=============================================
[2019-04-24 10:48:05,786] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.4906107e-01 1.0795268e-03 3.8601225e-04 8.5812442e-09 1.1719531e-12
 7.3327733e-10 2.9437561e-12 1.4302191e-04 1.4933032e-01 3.2835635e-13
 5.7911595e-14], sum to 1.0000
[2019-04-24 10:48:05,787] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5440
[2019-04-24 10:48:05,803] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.6, 29.0, 116.5, 847.5, 22.5, 24.81738783059714, 0.3553143084360197, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4366800.0000, 
sim time next is 4368000.0000, 
raw observation next is [14.56666666666667, 29.66666666666667, 115.5, 843.8333333333334, 22.5, 25.23129725787515, 0.426015726764767, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8661126500461682, 0.2966666666666667, 0.385, 0.9324125230202579, 0.375, 0.602608104822929, 0.6420052422549224, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04603034], dtype=float32), -0.55575424]. 
=============================================
[2019-04-24 10:48:08,042] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.9848154e-01 2.6557101e-03 1.3561576e-03 1.3016726e-08 1.4570869e-12
 2.9079552e-09 9.4426529e-11 5.1680475e-04 3.9698973e-01 2.4778933e-12
 6.6487235e-13], sum to 1.0000
[2019-04-24 10:48:08,042] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2766
[2019-04-24 10:48:08,062] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.9, 75.0, 0.0, 0.0, 19.0, 21.93768746057728, -0.2793670376418555, 0.0, 1.0, 55.0, 78.49086774244248], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4345200.0000, 
sim time next is 4346400.0000, 
raw observation next is [2.933333333333334, 74.66666666666667, 0.0, 0.0, 22.5, 22.68011728489645, -0.3561968486422655, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.543859649122807, 0.7466666666666667, 0.0, 0.0, 0.375, 0.39000977374137086, 0.38126771711924484, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2981844], dtype=float32), 0.8311574]. 
=============================================
[2019-04-24 10:48:12,397] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5254941e-01 1.5286052e-03 4.1481596e-04 2.5713446e-08 3.1818125e-12
 1.1301255e-09 4.2793759e-12 2.6267476e-04 2.4524447e-01 3.6428902e-12
 9.3824135e-13], sum to 1.0000
[2019-04-24 10:48:12,397] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9690
[2019-04-24 10:48:12,462] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.0, 32.66666666666667, 121.8333333333333, 839.0, 22.5, 24.94869997740772, 0.2664375160092404, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 5052000.0000, 
sim time next is 5053200.0000, 
raw observation next is [7.0, 29.33333333333334, 123.1666666666667, 848.3333333333334, 22.5, 25.48740622567159, 0.5204375496521946, 1.0, 1.0, 55.0, 62.45685440254205], 
processed observation next is [1.0, 0.4782608695652174, 0.6565096952908588, 0.2933333333333334, 0.4105555555555557, 0.9373848987108656, 0.375, 0.623950518805966, 0.6734791832173982, 1.0, 1.0, 0.8, 0.6245685440254205], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34347382], dtype=float32), 1.4901307]. 
=============================================
[2019-04-24 10:48:13,462] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:13,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:13,758] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:13,948] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:14,222] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:14,407] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:14,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:14,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:14,478] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run11
[2019-04-24 10:48:14,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:14,769] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:14,784] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run11
[2019-04-24 10:48:15,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:15,225] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:15,239] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run11
[2019-04-24 10:48:21,384] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:21,576] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:21,772] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.9961363e-01 1.4027879e-03 8.1433384e-03 3.6535408e-07 4.9745302e-10
 2.6951637e-08 2.1772204e-09 3.9826889e-04 2.9044163e-01 3.8707704e-10
 4.2506238e-11], sum to 1.0000
[2019-04-24 10:48:21,774] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8087
[2019-04-24 10:48:21,818] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.333333333333333, 46.0, 0.0, 0.0, 19.0, 23.2644845129106, -0.2587520139069736, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4905600.0000, 
sim time next is 4906800.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 19.0, 22.89105086650181, -0.1821287921788222, 0.0, 1.0, 55.0, 60.237138262472314], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.47, 0.0, 0.0, 0.08333333333333333, 0.40758757220848424, 0.43929040260705926, 0.0, 1.0, 0.8, 0.6023713826247231], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71517354], dtype=float32), -1.1156392]. 
=============================================
[2019-04-24 10:48:22,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:22,230] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:22,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:22,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:22,386] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run11
[2019-04-24 10:48:23,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:23,061] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:23,065] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run11
[2019-04-24 10:48:24,144] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.6793647e-01 8.0039622e-03 1.2818546e-03 2.4120536e-07 2.9360746e-11
 9.0090646e-09 1.9300447e-10 7.8804058e-04 2.2198939e-01 4.0645973e-11
 3.6026392e-12], sum to 1.0000
[2019-04-24 10:48:24,145] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7280
[2019-04-24 10:48:24,238] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 41.33333333333334, 95.5, 586.1666666666666, 22.5, 21.79300602831793, -0.5472857840347936, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4956000.0000, 
sim time next is 4957200.0000, 
raw observation next is [-1.0, 39.0, 100.5, 638.5, 22.5, 21.93823278984438, -0.4938832732019556, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4349030470914128, 0.39, 0.335, 0.7055248618784531, 0.375, 0.3281860658203651, 0.3353722422660148, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1906894], dtype=float32), -0.26668224]. 
=============================================
[2019-04-24 10:48:26,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:26,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:27,463] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:27,464] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:27,468] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run11
[2019-04-24 10:48:27,699] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:27,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:28,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:28,355] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:28,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:28,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:28,674] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:28,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:28,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:28,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run11
[2019-04-24 10:48:28,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:29,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:29,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:29,250] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run11
[2019-04-24 10:48:29,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:29,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:29,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run11
[2019-04-24 10:48:29,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:29,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:29,649] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run11
[2019-04-24 10:48:31,675] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:31,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:32,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:32,677] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:32,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run11
[2019-04-24 10:48:33,034] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:33,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:34,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:34,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:34,029] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run11
[2019-04-24 10:48:34,422] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:34,741] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:34,802] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:34,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:35,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:35,421] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:35,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run11
[2019-04-24 10:48:35,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:35,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:35,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run11
[2019-04-24 10:48:35,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:36,254] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:36,982] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:36,982] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:36,986] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run11
[2019-04-24 10:48:38,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:48:38,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:48:39,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:48:39,087] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:48:39,090] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run11
[2019-04-24 10:48:41,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7836601e-01 4.9738539e-03 2.7466735e-03 7.8141784e-07 3.1822503e-10
 9.0511591e-08 1.1648450e-09 5.3611986e-04 3.1337649e-01 2.1415451e-10
 6.2552595e-11], sum to 1.0000
[2019-04-24 10:48:41,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6302
[2019-04-24 10:48:41,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8949586e-01 5.2800858e-03 1.6332953e-03 1.4742265e-07 4.9742759e-11
 2.3921926e-08 5.6308896e-10 6.9536502e-04 3.0289525e-01 3.7937906e-11
 3.4268029e-11], sum to 1.0000
[2019-04-24 10:48:41,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2518
[2019-04-24 10:48:41,481] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 42.0, 47.0, 358.5, 22.5, 21.87456739430078, -0.4043186089449935, 1.0, 1.0, 55.0, 108.79852681743304], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 316800.0000, 
sim time next is 318000.0000, 
raw observation next is [-9.866666666666667, 44.33333333333334, 31.66666666666666, 279.5, 22.5, 22.70157517880473, -0.5094343367131831, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.18928901200369344, 0.4433333333333334, 0.10555555555555554, 0.30883977900552484, 0.375, 0.39179793156706094, 0.33018855442893896, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9978, 
noisyNet noise sample is [array([0.3819882], dtype=float32), 0.5617507]. 
=============================================
[2019-04-24 10:48:41,506] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 44.0, 92.83333333333334, 629.6666666666667, 22.5, 23.04056425829354, -0.2153305806494139, 1.0, 1.0, 55.0, 54.78999884127637], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 308400.0000, 
sim time next is 309600.0000, 
raw observation next is [-9.5, 44.0, 88.5, 627.0, 22.5, 23.47422715301825, -0.4046506097002704, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.1994459833795014, 0.44, 0.295, 0.6928176795580111, 0.375, 0.45618559608485426, 0.36511646343324317, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1769571], dtype=float32), 1.2245425]. 
=============================================
[2019-04-24 10:48:41,790] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3264712e-01 3.9569940e-04 1.6196960e-03 7.3727612e-08 2.9617676e-11
 9.3876205e-09 6.9337802e-10 7.6546904e-04 2.6457196e-01 1.7765209e-11
 2.9550795e-12], sum to 1.0000
[2019-04-24 10:48:41,791] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5144
[2019-04-24 10:48:41,799] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 21.57326320940913, -0.5049465891502848, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 26400.0000, 
sim time next is 27600.0000, 
raw observation next is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 21.20120766729273, -0.5660706012138034, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.2667673056077276, 0.3113097995953989, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.67225486], dtype=float32), -0.18010381]. 
=============================================
[2019-04-24 10:48:41,967] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.0192263e-01 6.1948169e-03 3.8669393e-03 2.4298100e-07 3.4809332e-11
 5.5508842e-09 1.0713940e-09 1.9908487e-03 3.8602448e-01 6.9183596e-11
 2.7715339e-11], sum to 1.0000
[2019-04-24 10:48:41,967] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8961
[2019-04-24 10:48:42,097] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.033333333333333, 77.0, 71.50000000000001, 49.33333333333332, 22.5, 21.66107319260366, -0.7620908828530363, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 206400.0000, 
sim time next is 207600.0000, 
raw observation next is [-7.666666666666666, 76.0, 86.5, 0.0, 22.5, 21.79633332785707, -0.5638982120586968, 1.0, 1.0, 55.0, 89.4142662450538], 
processed observation next is [1.0, 0.391304347826087, 0.25023084025854114, 0.76, 0.28833333333333333, 0.0, 0.375, 0.31636111065475586, 0.3120339293137677, 1.0, 1.0, 0.8, 0.894142662450538], 
reward next is 0.3195, 
noisyNet noise sample is [array([1.4666193], dtype=float32), -1.3587848]. 
=============================================
[2019-04-24 10:48:50,830] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.8040832e-01 8.9782302e-04 8.0369314e-04 5.3529330e-08 7.6526875e-12
 5.5792619e-09 1.5578086e-10 2.1934502e-04 2.1767078e-01 1.2105591e-11
 4.6500429e-12], sum to 1.0000
[2019-04-24 10:48:50,831] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.2233
[2019-04-24 10:48:50,883] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.0361898e-01 1.9720176e-03 2.0702342e-03 7.3203601e-08 2.2948549e-11
 2.1782045e-09 8.2827467e-10 2.0175825e-03 3.9032120e-01 5.3279690e-11
 2.4300236e-12], sum to 1.0000
[2019-04-24 10:48:50,884] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6559
[2019-04-24 10:48:50,935] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 60.0, 106.8333333333333, 0.0, 22.5, 22.74383577297974, -0.4988758561816871, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 225600.0000, 
sim time next is 226800.0000, 
raw observation next is [-2.8, 59.0, 86.5, 0.0, 22.5, 22.35915108319058, -0.5864242965209973, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.38504155124653744, 0.59, 0.28833333333333333, 0.0, 0.375, 0.36326259026588154, 0.3045252344930009, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8133, 
noisyNet noise sample is [array([-0.5305409], dtype=float32), 0.5728807]. 
=============================================
[2019-04-24 10:48:50,964] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.4, 89.0, 0.0, 0.0, 19.0, 21.38536344538709, -0.4981062031631332, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 64800.0000, 
sim time next is 66000.0000, 
raw observation next is [4.200000000000001, 88.0, 0.0, 0.0, 19.0, 21.51438800133925, -0.2825181736283607, 0.0, 1.0, 55.0, 77.5320429284355], 
processed observation next is [0.0, 0.782608695652174, 0.5789473684210527, 0.88, 0.0, 0.0, 0.08333333333333333, 0.29286566677827075, 0.40582727545721314, 0.0, 1.0, 0.8, 0.775320429284355], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.62266386], dtype=float32), -0.05410082]. 
=============================================
[2019-04-24 10:48:56,251] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.3917682e-01 9.9351350e-03 7.0111006e-03 3.1117042e-07 1.1072724e-09
 2.4183173e-08 1.2047633e-08 3.6663583e-03 4.4021022e-01 3.5177616e-10
 1.3818148e-10], sum to 1.0000
[2019-04-24 10:48:56,258] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2692
[2019-04-24 10:48:56,268] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 18.62928096087852, -1.296225322524053, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 194400.0000, 
sim time next is 195600.0000, 
raw observation next is [-8.900000000000002, 78.0, 0.0, 0.0, 19.0, 18.05514798852766, -1.385435143765332, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2160664819944598, 0.78, 0.0, 0.0, 0.08333333333333333, 0.004595665710638445, 0.03818828541155598, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13407184], dtype=float32), 0.36524814]. 
=============================================
[2019-04-24 10:48:59,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9758590e-01 6.7955479e-03 9.5118824e-03 2.4199602e-07 3.3279339e-09
 8.5248061e-08 1.7665231e-08 6.9411690e-03 5.7916522e-01 6.7668360e-10
 1.8754159e-10], sum to 1.0000
[2019-04-24 10:48:59,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0697
[2019-04-24 10:48:59,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.900000000000002, 78.0, 0.0, 0.0, 19.0, 18.43728302031293, -1.077787966439351, 0.0, 1.0, 55.0, 93.16046182129213], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 192000.0000, 
sim time next is 193200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 19.19856776353804, -1.193264681307162, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.09988064696150338, 0.10224510623094603, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2729605], dtype=float32), 0.09169374]. 
=============================================
[2019-04-24 10:49:03,702] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.27515519e-01 5.58770495e-04 2.05437187e-03 4.80304863e-08
 6.21794560e-11 2.58481969e-09 9.56736468e-10 1.38996087e-03
 2.68481374e-01 1.10332604e-10 7.10502794e-12], sum to 1.0000
[2019-04-24 10:49:03,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9721
[2019-04-24 10:49:03,740] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.8, 86.0, 0.0, 0.0, 19.0, 21.95957448150327, -0.5939368194402807, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 529200.0000, 
sim time next is 530400.0000, 
raw observation next is [3.433333333333334, 84.66666666666667, 0.0, 0.0, 19.0, 21.60449722416586, -0.4914195187119498, 0.0, 1.0, 55.0, 67.43366375165998], 
processed observation next is [0.0, 0.13043478260869565, 0.5577100646352725, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.30037476868048846, 0.33619349376268337, 0.0, 1.0, 0.8, 0.6743366375165998], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0064121], dtype=float32), 0.744518]. 
=============================================
[2019-04-24 10:49:07,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8380404e-01 2.6747638e-03 2.1322502e-03 4.6286320e-07 1.4273363e-10
 7.2249605e-08 1.9773683e-09 7.5907499e-04 3.1062931e-01 2.0446467e-10
 7.0008853e-11], sum to 1.0000
[2019-04-24 10:49:07,035] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2406
[2019-04-24 10:49:07,124] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.9, 47.66666666666667, 53.83333333333334, 877.8333333333334, 22.5, 22.41961052696939, -0.5339554105025291, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 394800.0000, 
sim time next is 396000.0000, 
raw observation next is [-10.5, 46.0, 51.5, 859.5, 22.5, 22.02787112428192, -0.6083493590204884, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.17174515235457063, 0.46, 0.17166666666666666, 0.9497237569060774, 0.375, 0.3356559270234933, 0.2972168803265039, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.778688], dtype=float32), -1.6254673]. 
=============================================
[2019-04-24 10:49:10,237] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.1423659e-01 2.0107876e-03 2.0052781e-03 7.0965449e-08 3.1089152e-11
 8.1972535e-09 1.1529390e-09 8.0725510e-04 3.8093996e-01 3.7646157e-11
 3.9265583e-12], sum to 1.0000
[2019-04-24 10:49:10,239] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0794
[2019-04-24 10:49:10,250] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.966666666666667, 86.66666666666666, 0.0, 0.0, 19.0, 21.24129665854537, -0.7419324932100828, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 528000.0000, 
sim time next is 529200.0000, 
raw observation next is [3.8, 86.0, 0.0, 0.0, 19.0, 20.61723473143145, -0.8594999150865644, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.5678670360110805, 0.86, 0.0, 0.0, 0.08333333333333333, 0.21810289428595406, 0.21350002830447853, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03455755], dtype=float32), -0.1617357]. 
=============================================
[2019-04-24 10:49:14,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.87363744e-01 5.84960217e-04 2.62711965e-03 8.01518851e-08
 2.96359520e-10 1.41756304e-08 4.42299575e-09 1.34998001e-03
 3.08073997e-01 2.17682330e-10 4.90604050e-11], sum to 1.0000
[2019-04-24 10:49:14,453] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1971
[2019-04-24 10:49:14,465] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 87.0, 0.0, 0.0, 19.0, 20.94652389027199, -0.7504959305577859, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 583200.0000, 
sim time next is 584400.0000, 
raw observation next is [-2.466666666666667, 87.0, 0.0, 0.0, 19.0, 20.33929179055389, -0.8704190892923817, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.39427516158818104, 0.87, 0.0, 0.0, 0.08333333333333333, 0.19494098254615752, 0.20986030356920612, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6383906], dtype=float32), 0.28948978]. 
=============================================
[2019-04-24 10:49:15,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1341826e-01 3.7831119e-03 1.1386744e-02 2.7778492e-07 6.2414074e-10
 2.0551321e-08 2.9392666e-09 2.2293173e-03 4.6918234e-01 2.7780409e-10
 2.9221531e-11], sum to 1.0000
[2019-04-24 10:49:15,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6159
[2019-04-24 10:49:15,247] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.266666666666667, 87.0, 0.0, 0.0, 19.0, 20.28754481401861, -0.6931113100244911, 0.0, 1.0, 55.0, 76.75077673468836], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 538800.0000, 
sim time next is 540000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 19.0, 21.08177442888185, -0.6315523993844464, 0.0, 1.0, 55.0, 50.87276127948536], 
processed observation next is [0.0, 0.2608695652173913, 0.49307479224376743, 0.88, 0.0, 0.0, 0.08333333333333333, 0.25681453574015417, 0.2894825335385179, 0.0, 1.0, 0.8, 0.5087276127948536], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.542611], dtype=float32), -2.5867198]. 
=============================================
[2019-04-24 10:49:15,291] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.32088 ]
 [56.854412]
 [57.546616]
 [58.41811 ]
 [58.250984]
 [58.02542 ]
 [57.530407]
 [58.35984 ]
 [59.36773 ]
 [61.322636]
 [61.40652 ]
 [62.23727 ]
 [63.111645]
 [64.67668 ]
 [64.57744 ]
 [66.125114]
 [66.09405 ]
 [67.58719 ]
 [68.16789 ]
 [68.26875 ]
 [66.87587 ]
 [65.0713  ]
 [65.57148 ]
 [64.91918 ]
 [64.999825]], R is [[57.02358627]
 [56.45335007]
 [56.88881683]
 [57.31993103]
 [56.7467308 ]
 [56.17926407]
 [55.6174736 ]
 [56.06129837]
 [56.50068665]
 [56.93568039]
 [56.36632538]
 [55.8026619 ]
 [56.24463654]
 [56.68218994]
 [56.11536789]
 [56.55421448]
 [55.98867416]
 [56.42878723]
 [55.86449814]
 [56.3058548 ]
 [55.74279785]
 [55.1853714 ]
 [55.63351822]
 [55.07718277]
 [55.52641296]].
[2019-04-24 10:49:16,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8676466e-01 4.1609473e-04 2.2079148e-04 9.4158936e-10 5.8449895e-14
 8.3556793e-11 4.8331060e-13 1.7253235e-05 3.1258115e-01 6.6544541e-14
 7.5782852e-15], sum to 1.0000
[2019-04-24 10:49:16,717] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2771
[2019-04-24 10:49:16,737] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.600000000000001, 94.66666666666667, 0.0, 0.0, 22.5, 23.44490024023104, -0.2280345158343402, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 927600.0000, 
sim time next is 928800.0000, 
raw observation next is [4.4, 96.0, 0.0, 0.0, 22.5, 22.83187487120557, -0.2921959384492057, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5844875346260389, 0.96, 0.0, 0.0, 0.375, 0.4026562392671309, 0.4026013538502648, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2002451], dtype=float32), -0.34174114]. 
=============================================
[2019-04-24 10:49:20,391] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4614038e-01 6.6269591e-04 7.0989534e-04 4.9438704e-08 5.9035069e-13
 1.3173510e-09 4.4651878e-12 8.1001410e-05 1.5240604e-01 1.3161686e-12
 4.8720587e-13], sum to 1.0000
[2019-04-24 10:49:20,392] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0454
[2019-04-24 10:49:20,402] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.2, 59.0, 0.0, 0.0, 22.5, 26.61163041605216, 0.7797610970913323, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1107600.0000, 
sim time next is 1108800.0000, 
raw observation next is [13.8, 60.0, 0.0, 0.0, 22.5, 26.2012394930664, 0.6853464432181452, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.844875346260388, 0.6, 0.0, 0.0, 0.375, 0.6834366244222, 0.7284488144060485, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24702758], dtype=float32), -1.0324872]. 
=============================================
[2019-04-24 10:49:20,711] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9516476e-01 6.4766518e-04 1.6096820e-03 1.8824856e-08 2.0082189e-12
 6.1574462e-10 1.8379494e-11 1.7035932e-04 2.0240754e-01 5.8755483e-12
 1.1204145e-12], sum to 1.0000
[2019-04-24 10:49:20,711] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4632
[2019-04-24 10:49:20,732] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2333333333333334, 54.66666666666667, 123.1666666666667, 504.0, 22.5, 22.89420150482906, -0.3963600823223617, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 735600.0000, 
sim time next is 736800.0000, 
raw observation next is [0.1333333333333333, 52.33333333333333, 124.0, 503.0, 22.5, 22.62465723604646, -0.4351878170801911, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.46629732225300097, 0.5233333333333333, 0.41333333333333333, 0.5558011049723757, 0.375, 0.38538810300387166, 0.354937394306603, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39768583], dtype=float32), 0.15783612]. 
=============================================
[2019-04-24 10:49:27,017] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.9501952e-01 1.9995691e-03 1.7722922e-03 4.5728785e-09 6.0066486e-13
 3.9865486e-10 3.5079283e-12 2.9407014e-04 4.0091455e-01 5.7654857e-13
 9.3659991e-14], sum to 1.0000
[2019-04-24 10:49:27,029] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7455
[2019-04-24 10:49:27,098] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [10.5, 77.0, 0.0, 0.0, 19.0, 25.41804242578897, 0.5299943859761932, 0.0, 1.0, 55.0, 43.67732375328322], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1126800.0000, 
sim time next is 1128000.0000, 
raw observation next is [10.33333333333333, 77.66666666666667, 0.0, 0.0, 19.0, 25.53191258514876, 0.5489490476995776, 0.0, 1.0, 55.0, 42.94636452098987], 
processed observation next is [0.0, 0.043478260869565216, 0.7488457987072946, 0.7766666666666667, 0.0, 0.0, 0.08333333333333333, 0.62765938209573, 0.6829830158998592, 0.0, 1.0, 0.8, 0.42946364520989866], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6509781], dtype=float32), -0.88467515]. 
=============================================
[2019-04-24 10:49:28,111] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.7905130e-01 3.1167006e-03 5.1909676e-03 1.2993232e-07 1.9472113e-10
 1.2977844e-08 1.9635253e-09 2.1090461e-03 6.1053181e-01 1.3613471e-10
 3.5262786e-11], sum to 1.0000
[2019-04-24 10:49:28,112] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5531
[2019-04-24 10:49:28,155] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.8, 74.0, 0.0, 0.0, 19.0, 20.50720518576917, -0.868625003918602, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 788400.0000, 
sim time next is 789600.0000, 
raw observation next is [-7.633333333333333, 74.33333333333334, 0.0, 0.0, 19.0, 20.34918508509384, -0.7527817119326793, 0.0, 1.0, 55.0, 71.37803308103969], 
processed observation next is [1.0, 0.13043478260869565, 0.2511542012927055, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.19576542375782, 0.2490727626891069, 0.0, 1.0, 0.8, 0.7137803308103969], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5280404], dtype=float32), -1.4271901]. 
=============================================
[2019-04-24 10:49:31,575] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2137666e-01 8.7161089e-04 4.4250232e-04 6.6419945e-09 3.6954516e-13
 1.3500898e-10 7.3237492e-12 5.2807375e-04 2.7678111e-01 3.2354750e-13
 3.5161283e-14], sum to 1.0000
[2019-04-24 10:49:31,576] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5761
[2019-04-24 10:49:31,584] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 19.0, 22.69060308026425, -0.1520659836237129, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1051200.0000, 
sim time next is 1052400.0000, 
raw observation next is [14.2, 77.33333333333334, 0.0, 0.0, 19.0, 22.57571088327636, -0.179580592862305, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.8559556786703602, 0.7733333333333334, 0.0, 0.0, 0.08333333333333333, 0.3813092402730301, 0.4401398023792316, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1556823], dtype=float32), -0.023455042]. 
=============================================
[2019-04-24 10:49:33,180] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.7769164e-01 8.2196423e-04 3.0652143e-04 7.8761675e-10 5.6524582e-14
 8.6889516e-11 3.4160671e-13 8.6533866e-05 3.2109329e-01 5.1104191e-14
 1.6793453e-15], sum to 1.0000
[2019-04-24 10:49:33,180] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1229
[2019-04-24 10:49:33,193] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.36666666666667, 65.33333333333334, 0.0, 0.0, 19.0, 25.07343872156746, 0.3762610864022194, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1118400.0000, 
sim time next is 1119600.0000, 
raw observation next is [12.2, 66.0, 0.0, 0.0, 19.0, 24.57569470163338, 0.307267913120487, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.8005540166204987, 0.66, 0.0, 0.0, 0.08333333333333333, 0.5479745584694484, 0.602422637706829, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24228595], dtype=float32), 1.5634583]. 
=============================================
[2019-04-24 10:49:36,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1971478e-01 1.5289099e-04 7.4368647e-05 6.2633182e-10 3.7837514e-14
 4.6422210e-11 1.7502865e-13 3.1443964e-05 1.8002658e-01 1.9248517e-14
 1.6289604e-15], sum to 1.0000
[2019-04-24 10:49:36,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0794
[2019-04-24 10:49:36,751] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 22.5, 24.18051648285102, 0.08030338122538018, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1015200.0000, 
sim time next is 1016400.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 22.5, 23.966888962247, 0.04099052121872385, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.375, 0.4972407468539168, 0.513663507072908, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3317277], dtype=float32), -1.47232]. 
=============================================
[2019-04-24 10:49:37,224] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4651895e-01 1.0223996e-04 2.7385907e-04 3.1775063e-10 5.1128891e-14
 3.7524518e-11 1.2578653e-12 6.4737091e-05 3.5304022e-01 5.7118962e-14
 9.2456585e-15], sum to 1.0000
[2019-04-24 10:49:37,224] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2843
[2019-04-24 10:49:37,274] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 76.33333333333334, 0.0, 0.0, 19.0, 24.55141285270705, 0.1772729843007387, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1027200.0000, 
sim time next is 1028400.0000, 
raw observation next is [14.4, 75.66666666666667, 0.0, 0.0, 19.0, 24.02474950818945, 0.08561878307888743, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.7566666666666667, 0.0, 0.0, 0.08333333333333333, 0.5020624590157876, 0.5285395943596292, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16961536], dtype=float32), -0.4848355]. 
=============================================
[2019-04-24 10:49:38,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5195209e-01 7.7559712e-04 5.4894708e-04 3.9024766e-09 5.1050136e-13
 5.0123194e-10 1.2127680e-11 2.4434261e-04 3.4647903e-01 4.2910865e-13
 7.8278062e-14], sum to 1.0000
[2019-04-24 10:49:38,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5678
[2019-04-24 10:49:39,027] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.433333333333334, 83.0, 0.0, 0.0, 19.0, 22.05467614884572, -0.2788426110005585, 0.0, 1.0, 55.0, 65.94644327668374], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 967200.0000, 
sim time next is 968400.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 19.0, 22.42356576701909, -0.3750242584980786, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.08333333333333333, 0.3686304805849243, 0.37499191383397384, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.149726], dtype=float32), 0.27242932]. 
=============================================
[2019-04-24 10:49:39,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.9479694e-01 1.4275345e-03 1.8386097e-03 5.0013512e-07 2.4660005e-09
 5.8113784e-08 4.0237795e-09 8.6298783e-04 2.0107345e-01 1.8836499e-09
 1.4280604e-10], sum to 1.0000
[2019-04-24 10:49:39,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0175
[2019-04-24 10:49:39,643] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 19.0, 23.88243868205234, 0.2050424586578075, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1197600.0000, 
sim time next is 1198800.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 19.0, 23.89040074867845, 0.2009254669500992, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.9529085872576178, 0.67, 0.0, 0.0, 0.08333333333333333, 0.4908667290565374, 0.5669751556500331, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3322097], dtype=float32), 0.30066782]. 
=============================================
[2019-04-24 10:49:50,089] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-24 10:49:50,090] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:49:50,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:49:50,093] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run15
[2019-04-24 10:49:50,140] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:49:50,141] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:49:50,143] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run15
[2019-04-24 10:49:50,198] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:49:50,199] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:49:50,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run15
[2019-04-24 10:51:17,008] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([0.2269814], dtype=float32), 0.32923174]
[2019-04-24 10:51:17,009] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-0.8, 47.66666666666667, 149.5, 49.33333333333333, 22.5, 22.50879665117022, -0.3482974358165594, 1.0, 1.0, 55.0, 100.13804012578083]
[2019-04-24 10:51:17,009] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:51:17,011] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.5544095e-01 4.1879602e-03 2.4042642e-03 9.6860754e-07 5.2414334e-10
 7.2125268e-08 3.8221857e-09 9.1090851e-04 2.3705487e-01 6.0683975e-10
 2.4815178e-10], sampled 0.08220452629632047
[2019-04-24 10:52:04,508] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 2961.9901 82931.5640 53.8811
[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,569] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,802] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,414] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2708.3459 93949.7897 -287.0791
[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:17,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,014] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2646.5910 98516.6766 -351.3272
[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:22,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:52:23,036] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 700000, evaluation results [700000.0, 2708.34586682308, 93949.78970090859, -287.07908309139475, 2961.990103674452, 82931.5640315925, 53.88114276123723, 2646.5910374147393, 98516.67658345484, -351.32719109988125]
[2019-04-24 10:52:35,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7360215e-01 1.1008130e-02 1.0797237e-02 3.9162378e-06 1.4775166e-08
 3.4052505e-07 1.7538424e-07 3.2422352e-03 5.0134587e-01 1.9412033e-08
 3.0342342e-09], sum to 1.0000
[2019-04-24 10:52:35,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3622
[2019-04-24 10:52:35,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 19.0, 18.41029474522334, -1.280568781847906, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1839600.0000, 
sim time next is 1840800.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 17.91202340690312, -1.357942935711397, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, -0.0073313827580732864, 0.047352354762867664, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2903141], dtype=float32), 0.070316084]. 
=============================================
[2019-04-24 10:52:45,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8154123e-01 1.1513697e-03 5.1248417e-04 3.6891006e-08 3.1072924e-12
 9.2418795e-10 4.9565279e-11 8.5960834e-05 2.1670890e-01 5.2134516e-12
 4.2857758e-13], sum to 1.0000
[2019-04-24 10:52:45,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7407
[2019-04-24 10:52:45,161] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 22.5, 21.46524445928415, -0.5708929630078189, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2053200.0000, 
sim time next is 2054400.0000, 
raw observation next is [-3.899999999999999, 82.0, 0.0, 0.0, 22.5, 21.15120618281107, -0.6105026821037793, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.35457063711911363, 0.82, 0.0, 0.0, 0.375, 0.2626005152342558, 0.2964991059654069, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.4248677], dtype=float32), 0.5682328]. 
=============================================
[2019-04-24 10:52:45,329] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5401047e-01 7.3053746e-04 3.3809857e-03 2.0004329e-07 4.9460380e-10
 3.1852174e-08 4.0678811e-09 6.4229604e-04 3.4123540e-01 1.8914689e-10
 7.5624597e-11], sum to 1.0000
[2019-04-24 10:52:45,331] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0816
[2019-04-24 10:52:45,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.566666666666667, 52.0, 181.1666666666667, 325.6666666666666, 19.0, 21.46089165982522, -0.5312716271069348, 0.0, 1.0, 55.0, 48.572315492966], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2374800.0000, 
sim time next is 2376000.0000, 
raw observation next is [-1.2, 47.0, 209.5, 365.0, 19.0, 21.39305822509698, -0.6553318341999141, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.42936288088642666, 0.47, 0.6983333333333334, 0.40331491712707185, 0.08333333333333333, 0.28275485209141493, 0.2815560552666953, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04872364], dtype=float32), -0.15235136]. 
=============================================
[2019-04-24 10:52:49,486] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.5109327e-01 1.0748872e-03 1.3566322e-03 3.8038742e-08 1.6557377e-11
 2.4349565e-09 8.1332732e-11 2.1201614e-04 2.4626306e-01 8.5980502e-12
 1.6756825e-12], sum to 1.0000
[2019-04-24 10:52:49,487] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7618
[2019-04-24 10:52:49,655] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.4, 71.66666666666667, 221.8333333333333, 47.66666666666666, 22.5, 22.20101554781339, -0.4631653232201793, 1.0, 1.0, 55.0, 87.68312283044375], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1941600.0000, 
sim time next is 1942800.0000, 
raw observation next is [-5.199999999999999, 68.33333333333333, 231.1666666666667, 9.0, 22.5, 22.84695252124907, -0.3688412711244456, 1.0, 1.0, 55.0, 63.43536488236339], 
processed observation next is [1.0, 0.4782608695652174, 0.31855955678670367, 0.6833333333333332, 0.7705555555555557, 0.009944751381215469, 0.375, 0.4039127101040891, 0.37705290962518484, 1.0, 1.0, 0.8, 0.6343536488236339], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43047068], dtype=float32), -0.89142036]. 
=============================================
[2019-04-24 10:52:55,908] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [4.3414292e-01 1.0794686e-03 2.6515236e-03 7.0735005e-08 2.1281817e-11
 5.5862017e-09 1.6097031e-10 1.9498171e-04 5.6193095e-01 2.1154172e-11
 2.4876965e-12], sum to 1.0000
[2019-04-24 10:52:55,910] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0654
[2019-04-24 10:52:55,926] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 75.0, 0.0, 0.0, 19.0, 20.92145030564766, -0.5689335645305879, 0.0, 1.0, 55.0, 76.77368563076789], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2242800.0000, 
sim time next is 2244000.0000, 
raw observation next is [-6.366666666666667, 76.0, 0.0, 0.0, 19.0, 21.05696110323057, -0.7214682281996895, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.28624192059095105, 0.76, 0.0, 0.0, 0.08333333333333333, 0.25474675860254753, 0.2595105906001035, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.483236], dtype=float32), -1.2115588]. 
=============================================
[2019-04-24 10:52:56,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8059096e-01 2.3510030e-03 2.3613416e-03 1.5972142e-07 2.0505328e-11
 1.0932730e-08 2.2522943e-10 3.0354250e-04 4.1439304e-01 3.6865164e-11
 1.0730073e-11], sum to 1.0000
[2019-04-24 10:52:56,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7109
[2019-04-24 10:52:56,905] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 70.0, 8.333333333333332, 0.0, 22.5, 20.57453830110556, -0.7983339042698573, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2222400.0000, 
sim time next is 2223600.0000, 
raw observation next is [-4.5, 69.0, 0.0, 0.0, 22.5, 21.4184874093519, -0.3742492730314462, 1.0, 1.0, 55.0, 112.80802787598847], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.69, 0.0, 0.0, 0.375, 0.28487395077932504, 0.37525024232285126, 1.0, 1.0, 0.8, 1.1280802787598847], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.631291], dtype=float32), -1.5936112]. 
=============================================
[2019-04-24 10:52:59,392] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.8333360e-01 4.2837649e-04 3.2010046e-04 5.6154946e-08 1.2636405e-11
 5.0099405e-09 7.5787487e-11 1.8073607e-04 2.1573706e-01 7.5781091e-12
 1.7213893e-12], sum to 1.0000
[2019-04-24 10:52:59,394] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6341
[2019-04-24 10:52:59,417] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 52.0, 0.0, 0.0, 22.5, 22.44437207709117, -0.2275849706457893, 1.0, 1.0, 55.0, 77.17364715363486], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2311200.0000, 
sim time next is 2312400.0000, 
raw observation next is [-1.2, 52.66666666666667, 0.0, 0.0, 22.5, 23.08003304438397, -0.3174852134186673, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.5266666666666667, 0.0, 0.0, 0.375, 0.42333608703199754, 0.39417159552711095, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1091236], dtype=float32), -0.5680563]. 
=============================================
[2019-04-24 10:53:00,045] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.4621722e-01 2.2602836e-03 8.3432021e-04 4.4617707e-08 4.3054043e-11
 5.8391452e-09 4.5663522e-11 2.0050608e-04 1.5048760e-01 1.0272269e-11
 2.1371782e-12], sum to 1.0000
[2019-04-24 10:53:00,048] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9339
[2019-04-24 10:53:00,133] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.9, 29.0, 59.5, 135.8333333333333, 22.5, 23.33636075647673, -0.2210726360595654, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2565600.0000, 
sim time next is 2566800.0000, 
raw observation next is [2.7, 29.0, 38.5, 83.5, 22.5, 23.7885711681141, -0.1246666073339782, 1.0, 1.0, 55.0, 74.59494839718424], 
processed observation next is [1.0, 0.7391304347826086, 0.5373961218836566, 0.29, 0.12833333333333333, 0.09226519337016574, 0.375, 0.482380930676175, 0.4584444642220073, 1.0, 1.0, 0.8, 0.7459494839718424], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18941528], dtype=float32), 1.7232561]. 
=============================================
[2019-04-24 10:53:00,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9470866e-01 1.6879292e-03 1.0612721e-03 2.4527539e-08 1.2496540e-11
 3.0059950e-09 2.3146389e-10 2.6139070e-04 5.0228071e-01 1.4874497e-11
 4.5232980e-12], sum to 1.0000
[2019-04-24 10:53:00,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4513
[2019-04-24 10:53:00,300] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 19.0, 21.9272734182632, -0.5704993363598772, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2167200.0000, 
sim time next is 2168400.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 21.37206501305093, -0.6962113285270796, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.28100541775424404, 0.26792955715764016, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9216905], dtype=float32), 1.8385736]. 
=============================================
[2019-04-24 10:53:03,019] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.6227404e-01 1.5481282e-03 1.0870789e-03 3.7037669e-08 1.2315279e-11
 4.0985215e-09 1.3723189e-10 3.4205167e-04 4.3474871e-01 1.5921995e-11
 5.0677111e-13], sum to 1.0000
[2019-04-24 10:53:03,021] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2026
[2019-04-24 10:53:03,043] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 19.0, 21.33654616761623, -0.5112230454840402, 0.0, 1.0, 55.0, 52.966202686948236], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2160000.0000, 
sim time next is 2161200.0000, 
raw observation next is [-7.300000000000001, 81.0, 0.0, 0.0, 19.0, 21.27396206616326, -0.6534334921969644, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.81, 0.0, 0.0, 0.08333333333333333, 0.2728301721802717, 0.2821888359343452, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.74802154], dtype=float32), 0.6587093]. 
=============================================
[2019-04-24 10:53:05,062] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3392550e-01 1.5779118e-03 1.8187652e-03 2.1229486e-07 1.8115955e-11
 1.1489310e-08 2.1412534e-10 3.1571405e-04 3.6236188e-01 1.7789974e-11
 5.0696105e-12], sum to 1.0000
[2019-04-24 10:53:05,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9788
[2019-04-24 10:53:05,151] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.533333333333333, 55.33333333333333, 0.0, 0.0, 22.5, 23.05731703185265, -0.1456329482629491, 0.0, 1.0, 55.0, 68.77318078394818], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2317200.0000, 
sim time next is 2318400.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 22.5, 23.30322687720946, -0.115467736943938, 0.0, 1.0, 55.0, 49.29312921972024], 
processed observation next is [1.0, 0.8695652173913043, 0.4155124653739613, 0.56, 0.0, 0.0, 0.375, 0.4419355731007884, 0.46151075435202066, 0.0, 1.0, 0.8, 0.49293129219720244], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44155744], dtype=float32), -1.8546108]. 
=============================================
[2019-04-24 10:53:06,297] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.70685613e-01 7.80842791e-04 7.51896587e-04 1.30444690e-07
 8.66999528e-12 2.77783241e-09 2.35118158e-11 1.79168739e-04
 2.27602273e-01 1.38501485e-11 8.87718978e-12], sum to 1.0000
[2019-04-24 10:53:06,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0389
[2019-04-24 10:53:06,320] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.966666666666667, 31.0, 17.5, 31.16666666666666, 22.5, 24.86637898184122, 0.09413112508227024, 1.0, 1.0, 55.0, 46.14673974892345], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2568000.0000, 
sim time next is 2569200.0000, 
raw observation next is [1.233333333333333, 33.0, 0.0, 0.0, 22.5, 24.28518308801898, -0.07426350657196122, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.49676823638042483, 0.33, 0.0, 0.0, 0.375, 0.5237652573349149, 0.4752454978093463, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5537305], dtype=float32), 0.8161584]. 
=============================================
[2019-04-24 10:53:10,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2610297e-01 1.1845374e-03 5.8682350e-04 4.8421292e-08 2.6271886e-11
 8.2910825e-09 7.0579695e-11 2.5882878e-04 1.7186679e-01 2.4800767e-11
 2.9619614e-12], sum to 1.0000
[2019-04-24 10:53:10,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2548
[2019-04-24 10:53:10,254] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 47.0, 182.5, 58.0, 22.5, 22.85078674737495, -0.2908871801054259, 1.0, 1.0, 55.0, 74.59850140630515], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2545200.0000, 
sim time next is 2546400.0000, 
raw observation next is [-0.03333333333333333, 44.33333333333334, 215.5, 66.66666666666667, 22.5, 23.28195307007805, -0.3537566565213701, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.46168051708217916, 0.4433333333333334, 0.7183333333333334, 0.07366482504604052, 0.375, 0.4401627558398375, 0.38208111449287663, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5473066], dtype=float32), 0.9759647]. 
=============================================
[2019-04-24 10:53:17,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6624578e-01 5.8038393e-04 5.9033668e-04 2.9152616e-08 1.5454492e-11
 1.2215544e-09 6.7290597e-11 2.6541587e-04 2.3231806e-01 9.5593386e-12
 1.0040133e-12], sum to 1.0000
[2019-04-24 10:53:17,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5037
[2019-04-24 10:53:17,591] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 54.0, 234.5, 159.0, 22.5, 22.2972761455658, -0.5389402732429838, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2635200.0000, 
sim time next is 2636400.0000, 
raw observation next is [-1.733333333333333, 51.66666666666667, 241.5, 151.0, 22.5, 21.70739503645812, -0.5507254787455081, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.41458910433979695, 0.5166666666666667, 0.805, 0.16685082872928178, 0.375, 0.30894958637151, 0.31642484041816393, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9357, 
noisyNet noise sample is [array([-1.3986751], dtype=float32), 0.08405793]. 
=============================================
[2019-04-24 10:53:23,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8655667e-01 1.5787658e-03 6.9630952e-03 8.1589114e-08 3.7812576e-11
 1.4282368e-08 5.3766730e-10 2.5510989e-04 4.0464631e-01 5.6752575e-11
 2.0384664e-11], sum to 1.0000
[2019-04-24 10:53:23,584] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6066
[2019-04-24 10:53:23,633] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 21.21532814775202, -0.530477234923389, 0.0, 1.0, 55.0, 57.34489903799191], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2761200.0000, 
sim time next is 2762400.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 21.54700896702449, -0.4975839993039983, 0.0, 1.0, 55.0, 55.36716294287366], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.29558408058537405, 0.3341386668986672, 0.0, 1.0, 0.8, 0.5536716294287366], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6162684], dtype=float32), -1.7103447]. 
=============================================
[2019-04-24 10:53:28,032] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.5623307e-01 2.5065916e-03 8.2403561e-04 2.2843567e-08 1.1436404e-12
 4.1746109e-10 4.0393376e-11 1.6615358e-04 3.4027004e-01 4.1073365e-13
 6.7374634e-14], sum to 1.0000
[2019-04-24 10:53:28,033] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0816
[2019-04-24 10:53:28,066] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 93.0, 511.5, 22.5, 22.22751443879386, -0.2706531117340711, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3229200.0000, 
sim time next is 3230400.0000, 
raw observation next is [-3.0, 92.0, 98.33333333333334, 605.8333333333334, 22.5, 22.34541477878623, -0.2417160326957241, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.32777777777777783, 0.6694290976058932, 0.375, 0.3621178982321857, 0.41942798910142526, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0398825], dtype=float32), -1.8787844]. 
=============================================
[2019-04-24 10:53:32,181] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4259242e-01 2.4235635e-03 7.7369343e-04 4.9882556e-09 1.0286060e-12
 4.7197934e-10 2.7978722e-11 1.9009211e-04 6.5402031e-01 1.1513603e-12
 3.7387180e-13], sum to 1.0000
[2019-04-24 10:53:32,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8710
[2019-04-24 10:53:32,250] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 19.0, 22.99672825978084, -0.08690243610660593, 0.0, 1.0, 55.0, 51.44978354484564], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3460800.0000, 
sim time next is 3462000.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 19.0, 23.45992304313844, -0.04997544211006703, 0.0, 1.0, 55.0, 49.50707661546805], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.79, 0.0, 0.0, 0.08333333333333333, 0.4549935869282032, 0.4833415192966443, 0.0, 1.0, 0.8, 0.4950707661546805], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36903742], dtype=float32), -1.4786032]. 
=============================================
[2019-04-24 10:53:33,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3154176e-01 6.2406651e-04 3.0826122e-04 3.9029304e-09 3.8898870e-13
 1.4593639e-10 3.7770837e-12 4.9220274e-05 4.6747670e-01 8.4455568e-14
 1.5586585e-13], sum to 1.0000
[2019-04-24 10:53:33,670] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1523
[2019-04-24 10:53:33,708] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 93.0, 511.5, 22.5, 23.38502481951281, -0.0272407496897467, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3229200.0000, 
sim time next is 3230400.0000, 
raw observation next is [-3.0, 92.0, 98.33333333333334, 605.8333333333334, 22.5, 23.40155459543163, -0.01284968952537154, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.92, 0.32777777777777783, 0.6694290976058932, 0.375, 0.4501295496193025, 0.4957167701582095, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.286291], dtype=float32), 1.2620379]. 
=============================================
[2019-04-24 10:53:35,870] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.2535619e-01 1.8455840e-04 1.7765726e-04 1.1604886e-09 1.2863819e-14
 1.7210369e-11 1.9273614e-13 1.5738351e-05 1.7426586e-01 6.9379613e-15
 4.8849673e-15], sum to 1.0000
[2019-04-24 10:53:35,871] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9959
[2019-04-24 10:53:35,922] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.333333333333333, 100.0, 0.0, 0.0, 22.5, 24.84249892525076, 0.3569554546655684, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3176400.0000, 
sim time next is 3177600.0000, 
raw observation next is [4.666666666666666, 100.0, 0.0, 0.0, 22.5, 24.88782896895125, 0.5502192651684356, 0.0, 1.0, 55.0, 70.67770187145771], 
processed observation next is [1.0, 0.782608695652174, 0.5918744228993538, 1.0, 0.0, 0.0, 0.375, 0.5739857474126042, 0.6834064217228119, 0.0, 1.0, 0.8, 0.7067770187145771], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1839256], dtype=float32), 0.004265055]. 
=============================================
[2019-04-24 10:53:36,106] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6035923e-01 5.3304399e-04 6.7481404e-04 1.5163453e-08 1.1078128e-12
 6.4094968e-10 2.3253042e-11 1.7344514e-04 2.3825942e-01 1.6748082e-12
 2.0375746e-13], sum to 1.0000
[2019-04-24 10:53:36,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8765
[2019-04-24 10:53:36,146] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.0, 82.66666666666667, 0.0, 0.0, 19.0, 21.72582000456513, -0.169404669815025, 0.0, 1.0, 55.0, 86.05378300298212], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2925600.0000, 
sim time next is 2926800.0000, 
raw observation next is [-1.0, 85.0, 0.0, 0.0, 19.0, 22.68114017591894, -0.0876175940484142, 0.0, 1.0, 55.0, 54.42149820831075], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.85, 0.0, 0.0, 0.08333333333333333, 0.39009501465991175, 0.4707941353171952, 0.0, 1.0, 0.8, 0.5442149820831075], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33200833], dtype=float32), 0.56190854]. 
=============================================
[2019-04-24 10:53:36,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5506339e-01 4.3102689e-03 4.2208163e-03 1.0794658e-06 8.3285595e-10
 3.5117188e-07 1.6748185e-08 1.5948506e-03 3.3480921e-01 2.5016378e-09
 2.5228156e-10], sum to 1.0000
[2019-04-24 10:53:36,545] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2294
[2019-04-24 10:53:36,579] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 43.0, 74.5, 607.0, 19.0, 22.64256522776292, -0.2682247232888668, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3600000.0000, 
sim time next is 3601200.0000, 
raw observation next is [0.0, 41.66666666666667, 66.83333333333333, 545.6666666666666, 19.0, 22.21606054071841, -0.3289762338466672, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.41666666666666674, 0.22277777777777777, 0.6029465930018416, 0.08333333333333333, 0.35133837839320076, 0.39034125538444425, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3516543], dtype=float32), 1.0738691]. 
=============================================
[2019-04-24 10:53:38,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.45931995e-01 2.19709589e-03 4.10702545e-03 7.70109452e-08
 1.24565774e-11 9.75298864e-09 2.53112503e-10 3.42453422e-04
 4.47421312e-01 2.72301470e-11 3.64361362e-12], sum to 1.0000
[2019-04-24 10:53:38,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3052
[2019-04-24 10:53:38,068] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 22.88039273193268, -0.1963537114189474, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3543600.0000, 
sim time next is 3544800.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 19.0, 22.44993400023406, -0.3166415432021494, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.40720221606648205, 0.6, 0.0, 0.0, 0.08333333333333333, 0.37082783335283825, 0.39445281893261686, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.827146], dtype=float32), -0.47471133]. 
=============================================
[2019-04-24 10:53:38,359] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3762041e-01 3.6241769e-04 8.4670508e-05 8.2510609e-10 1.8864354e-14
 5.0483225e-11 4.8951809e-13 4.9876202e-05 2.6188263e-01 1.3338053e-14
 1.2384997e-15], sum to 1.0000
[2019-04-24 10:53:38,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1291
[2019-04-24 10:53:38,374] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 112.1666666666667, 808.8333333333334, 22.5, 24.48732240179496, 0.1921793338963345, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3158400.0000, 
sim time next is 3159600.0000, 
raw observation next is [7.0, 100.0, 110.1666666666667, 798.8333333333334, 22.5, 24.55790276291681, 0.2143608003099282, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 1.0, 0.36722222222222234, 0.8826887661141806, 0.375, 0.5464918969097342, 0.5714536001033094, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02311785], dtype=float32), 0.61755574]. 
=============================================
[2019-04-24 10:53:38,710] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5002891e-01 2.5868727e-04 8.6927321e-05 6.2631961e-10 6.8281308e-15
 1.7477823e-11 2.2711249e-13 3.9340004e-05 2.4958619e-01 7.1185462e-15
 5.7778050e-16], sum to 1.0000
[2019-04-24 10:53:38,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7018
[2019-04-24 10:53:38,754] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.2, 99.66666666666666, 49.66666666666667, 435.1666666666667, 22.5, 26.2228274041068, 0.6663967003161518, 1.0, 1.0, 55.0, 34.125961275214394], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3170400.0000, 
sim time next is 3171600.0000, 
raw observation next is [6.0, 100.0, 33.0, 307.5, 22.5, 26.51286712445413, 0.5685666231211035, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6288088642659281, 1.0, 0.11, 0.3397790055248619, 0.375, 0.7094055937045107, 0.6895222077070345, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02311785], dtype=float32), 0.61755574]. 
=============================================
[2019-04-24 10:53:39,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.86846077e-01 5.92874363e-04 4.54745954e-03 1.05958414e-07
 2.50928639e-10 8.40278958e-09 9.45682532e-10 2.96183419e-03
 3.05051595e-01 4.06792738e-10 1.39742957e-11], sum to 1.0000
[2019-04-24 10:53:39,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6617
[2019-04-24 10:53:39,286] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.666666666666667, 53.0, 67.83333333333333, 552.5, 19.0, 24.61179461166049, 0.1307803592184773, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3687600.0000, 
sim time next is 3688800.0000, 
raw observation next is [4.333333333333334, 56.0, 55.83333333333334, 462.5, 19.0, 24.19465089522419, 0.03220486277327727, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.58264081255771, 0.56, 0.18611111111111114, 0.511049723756906, 0.08333333333333333, 0.5162209079353491, 0.510734954257759, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5665095], dtype=float32), 0.8491664]. 
=============================================
[2019-04-24 10:53:40,410] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.4586139e-01 2.8614136e-03 3.6804634e-03 1.4864246e-07 9.3251127e-12
 3.1772687e-09 2.5639171e-10 6.8672647e-04 3.4690982e-01 3.9354506e-11
 9.5022167e-12], sum to 1.0000
[2019-04-24 10:53:40,416] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.5360
[2019-04-24 10:53:40,434] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.0, 76.0, 0.0, 0.0, 19.0, 22.00957878650242, -0.4688747516472517, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3301200.0000, 
sim time next is 3302400.0000, 
raw observation next is [-10.33333333333333, 76.0, 0.0, 0.0, 19.0, 21.26434983221183, -0.620111230285155, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.17636195752539252, 0.76, 0.0, 0.0, 0.08333333333333333, 0.27202915268431926, 0.293296256571615, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7350498], dtype=float32), 0.36859816]. 
=============================================
[2019-04-24 10:53:45,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0372039e-01 2.7097439e-04 1.6036890e-03 1.0776827e-08 4.7013005e-12
 5.6037630e-10 4.0129629e-11 2.2972222e-04 2.9417515e-01 2.6670150e-12
 8.1183443e-13], sum to 1.0000
[2019-04-24 10:53:45,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7122
[2019-04-24 10:53:46,011] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.0, 70.0, 0.0, 0.0, 19.0, 22.92679240962194, -0.1511461938981642, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3537600.0000, 
sim time next is 3538800.0000, 
raw observation next is [-1.0, 66.0, 0.0, 0.0, 19.0, 22.9423528502663, 0.06168061530927466, 0.0, 1.0, 55.0, 82.98101538809279], 
processed observation next is [1.0, 1.0, 0.4349030470914128, 0.66, 0.0, 0.0, 0.08333333333333333, 0.41186273752219166, 0.5205602051030915, 0.0, 1.0, 0.8, 0.8298101538809278], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08471613], dtype=float32), 0.6916819]. 
=============================================
[2019-04-24 10:53:47,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9686201e-01 5.4755691e-04 8.6990641e-03 6.3223297e-07 1.6679446e-09
 7.9292327e-08 1.2534292e-08 1.9663842e-03 1.9192418e-01 1.4772998e-09
 1.4496487e-10], sum to 1.0000
[2019-04-24 10:53:47,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6287
[2019-04-24 10:53:47,983] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 19.0, 23.50884068334129, -0.2236848812075484, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3631200.0000, 
sim time next is 3632400.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 19.0, 22.9425609489393, -0.3363786172451622, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.7119113573407203, 0.25, 0.0, 0.0, 0.08333333333333333, 0.4118800790782749, 0.3878737942516126, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0443733], dtype=float32), 0.38659674]. 
=============================================
[2019-04-24 10:53:53,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5513941e-01 1.3824570e-03 1.9075305e-03 5.5946746e-08 9.1439703e-12
 2.1302116e-09 1.4030185e-10 2.3558001e-04 2.4133496e-01 1.0617474e-11
 3.2720454e-12], sum to 1.0000
[2019-04-24 10:53:53,403] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3120
[2019-04-24 10:53:53,427] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 22.31214630209963, -0.2297323638745399, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3790800.0000, 
sim time next is 3792000.0000, 
raw observation next is [-3.0, 73.0, 0.0, 0.0, 19.0, 22.12971776506998, -0.2672623294723389, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3795013850415513, 0.73, 0.0, 0.0, 0.08333333333333333, 0.344143147089165, 0.41091255684255373, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2919344], dtype=float32), 0.9820539]. 
=============================================
[2019-04-24 10:53:58,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1857694e-01 2.0183821e-03 6.4956106e-04 2.7102145e-08 7.5084184e-12
 3.7890815e-09 2.4021543e-10 2.6651082e-04 3.7848857e-01 8.6700716e-12
 2.3283740e-12], sum to 1.0000
[2019-04-24 10:53:58,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2305
[2019-04-24 10:53:58,546] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 53.0, 95.5, 579.0, 22.5, 23.67550737557858, -0.02985784067643455, 1.0, 1.0, 55.0, 48.59171052605478], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3920400.0000, 
sim time next is 3921600.0000, 
raw observation next is [-7.666666666666667, 51.66666666666667, 98.5, 654.3333333333334, 22.5, 23.67502563958189, -0.1208425410953916, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2502308402585411, 0.5166666666666667, 0.3283333333333333, 0.7230202578268877, 0.375, 0.4729188032984908, 0.4597191529682028, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4677709], dtype=float32), -0.3120262]. 
=============================================
[2019-04-24 10:53:59,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9617656e-01 3.4650015e-03 5.4106638e-03 8.7084281e-08 4.1755269e-11
 1.6168274e-08 1.2457817e-09 7.8209100e-04 3.9416555e-01 1.2328746e-10
 2.2707315e-11], sum to 1.0000
[2019-04-24 10:53:59,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5329
[2019-04-24 10:53:59,677] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 24.0, 113.5, 789.5, 19.0, 24.20464099632148, 0.1449731845901417, 0.0, 1.0, 55.0, 40.59396785038197], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3668400.0000, 
sim time next is 3669600.0000, 
raw observation next is [9.333333333333334, 31.0, 115.1666666666667, 807.1666666666666, 19.0, 24.43663368762255, 0.07377543040260769, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.7211449676823639, 0.31, 0.383888888888889, 0.8918968692449355, 0.08333333333333333, 0.5363861406352125, 0.5245918101342025, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34598288], dtype=float32), 0.050296456]. 
=============================================
[2019-04-24 10:54:05,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.56066024e-01 3.96003103e-04 1.86763250e-03 5.40123892e-08
 1.18884425e-11 9.36775724e-09 6.60499017e-11 2.09302700e-04
 2.41460860e-01 1.41633753e-11 1.20712771e-12], sum to 1.0000
[2019-04-24 10:54:05,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2842
[2019-04-24 10:54:05,912] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 60.0, 0.0, 0.0, 19.0, 22.05185520463974, -0.2876493375508736, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3877200.0000, 
sim time next is 3878400.0000, 
raw observation next is [-1.0, 58.33333333333334, 0.0, 0.0, 19.0, 21.8746605475706, -0.3228260954547785, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.5833333333333335, 0.0, 0.0, 0.08333333333333333, 0.32288837896421657, 0.3923913015150738, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5169402], dtype=float32), 1.3342613]. 
=============================================
[2019-04-24 10:54:11,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6843835e-01 4.5249457e-04 1.1925380e-03 2.5493277e-08 4.4016847e-12
 1.3465740e-09 1.9982078e-10 4.2780003e-04 4.2948875e-01 3.2228671e-12
 1.0202782e-12], sum to 1.0000
[2019-04-24 10:54:11,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3957
[2019-04-24 10:54:11,214] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.9, 75.0, 0.0, 0.0, 19.0, 22.149525941901, -0.5042879482188926, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4345200.0000, 
sim time next is 4346400.0000, 
raw observation next is [2.933333333333334, 74.66666666666667, 0.0, 0.0, 22.5, 21.66712861094233, -0.5785701826595714, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.543859649122807, 0.7466666666666667, 0.0, 0.0, 0.375, 0.3055940509118609, 0.30714327244680956, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6553885], dtype=float32), 0.6171541]. 
=============================================
[2019-04-24 10:54:11,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4277554e-01 3.5045003e-03 1.1879440e-03 6.4077184e-08 5.0299962e-11
 3.6368000e-09 2.3945926e-10 7.1189686e-04 3.5182014e-01 2.3286952e-11
 7.4883381e-12], sum to 1.0000
[2019-04-24 10:54:11,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9519
[2019-04-24 10:54:11,589] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.2, 72.0, 0.0, 0.0, 19.0, 21.31447760023452, -0.615102636645903, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4598400.0000, 
sim time next is 4599600.0000, 
raw observation next is [-2.4, 73.0, 0.0, 0.0, 19.0, 21.23214372868719, -0.40209521621502, 0.0, 1.0, 55.0, 75.64649246715751], 
processed observation next is [1.0, 0.21739130434782608, 0.39612188365650974, 0.73, 0.0, 0.0, 0.08333333333333333, 0.2693453107239326, 0.36596826126166, 0.0, 1.0, 0.8, 0.7564649246715751], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8540996], dtype=float32), 1.8215743]. 
=============================================
[2019-04-24 10:54:14,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0831854e-01 4.8900363e-03 4.8058131e-03 3.6998804e-07 6.3399133e-11
 8.9760377e-09 8.5290935e-10 7.4965542e-04 4.8123556e-01 5.2782851e-11
 7.0742488e-11], sum to 1.0000
[2019-04-24 10:54:14,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7321
[2019-04-24 10:54:14,791] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.666666666666667, 37.0, 102.0, 644.0, 22.5, 22.43360086407646, -0.4085928280554584, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4094400.0000, 
sim time next is 4095600.0000, 
raw observation next is [-2.333333333333333, 36.0, 105.6666666666667, 694.0, 22.5, 23.14295684510725, -0.1212504052717624, 1.0, 1.0, 55.0, 74.35097910817622], 
processed observation next is [1.0, 0.391304347826087, 0.3979686057248385, 0.36, 0.3522222222222223, 0.7668508287292818, 0.375, 0.4285797370922708, 0.45958319824274585, 1.0, 1.0, 0.8, 0.7435097910817622], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16402002], dtype=float32), 1.1675706]. 
=============================================
[2019-04-24 10:54:15,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.5794876e-01 1.1569606e-03 5.7667028e-03 3.5502967e-07 2.0293882e-09
 4.5558526e-08 2.7064899e-09 1.9714138e-03 2.3315570e-01 5.7382649e-10
 9.0473254e-11], sum to 1.0000
[2019-04-24 10:54:15,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6240
[2019-04-24 10:54:15,550] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 44.33333333333334, 242.0, 376.3333333333334, 19.0, 21.28530962221333, -0.3806779672203762, 0.0, 1.0, 55.0, 73.30986354286952], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4890000.0000, 
sim time next is 4891200.0000, 
raw observation next is [2.666666666666667, 44.66666666666667, 223.8333333333333, 382.0, 19.0, 22.00235426164829, -0.4274404754802405, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5364727608494922, 0.4466666666666667, 0.746111111111111, 0.4220994475138122, 0.08333333333333333, 0.3335295218040241, 0.3575198415065865, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8573529], dtype=float32), -0.8710585]. 
=============================================
[2019-04-24 10:54:15,607] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.9335208e-01 1.0522192e-03 2.4625359e-04 1.4186531e-08 5.2282406e-12
 6.2337568e-10 7.1077054e-11 2.8065892e-04 4.0506878e-01 1.0275399e-12
 1.6245093e-12], sum to 1.0000
[2019-04-24 10:54:15,608] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4848
[2019-04-24 10:54:15,629] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666667, 82.0, 0.0, 0.0, 19.0, 23.77401280855658, 0.06761254514899621, 0.0, 1.0, 55.0, 48.0113435812945], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4678800.0000, 
sim time next is 4680000.0000, 
raw observation next is [0.0, 92.0, 0.0, 0.0, 19.0, 23.8813229997023, -0.04807039449244401, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.46260387811634357, 0.92, 0.0, 0.0, 0.08333333333333333, 0.49011024997519154, 0.4839765351691853, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24684173], dtype=float32), -1.0101422]. 
=============================================
[2019-04-24 10:54:15,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2596747e-01 1.4874235e-03 8.5121300e-03 5.8492822e-07 3.7035242e-09
 7.0768728e-08 5.4959663e-09 2.1798189e-03 2.6185250e-01 1.3540206e-09
 1.6872018e-10], sum to 1.0000
[2019-04-24 10:54:15,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4408
[2019-04-24 10:54:15,643] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[66.88924 ]
 [65.61397 ]
 [64.26985 ]
 [64.730316]
 [64.67177 ]
 [63.64392 ]
 [63.85314 ]
 [64.26333 ]
 [64.752045]
 [65.24704 ]
 [65.82128 ]
 [66.550835]
 [67.30916 ]
 [66.59483 ]
 [66.74626 ]
 [65.193855]
 [65.3194  ]
 [65.62361 ]
 [65.3444  ]
 [65.37967 ]
 [66.10405 ]
 [66.430984]
 [67.12305 ]
 [66.44567 ]
 [67.369736]], R is [[67.66674042]
 [66.99007416]
 [66.32017517]
 [66.65697479]
 [66.99040222]
 [66.32049561]
 [66.6572876 ]
 [66.99071503]
 [67.32080841]
 [67.64759827]
 [67.97112274]
 [68.29141235]
 [68.60849762]
 [67.92241669]
 [68.24319458]
 [67.5607605 ]
 [67.88515472]
 [68.20630646]
 [68.52424622]
 [68.83900452]
 [69.15061188]
 [69.45910645]
 [69.76451874]
 [69.06687164]
 [69.37620544]].
[2019-04-24 10:54:15,656] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 132.5, 369.5, 19.0, 21.19474273161217, -0.565742176239765, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4896000.0000, 
sim time next is 4897200.0000, 
raw observation next is [3.0, 45.0, 112.1666666666667, 334.5, 19.0, 21.13671187291153, -0.5728995272465879, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.373888888888889, 0.3696132596685083, 0.08333333333333333, 0.2613926560759608, 0.309033490917804, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8573529], dtype=float32), -0.8710585]. 
=============================================
[2019-04-24 10:54:18,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.08174491e-01 1.29191543e-03 7.44331686e-04 2.62805653e-08
 1.25627384e-12 1.47056567e-09 1.40392351e-11 1.06071864e-04
 1.89683169e-01 1.46599291e-12 1.58785192e-12], sum to 1.0000
[2019-04-24 10:54:18,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2158
[2019-04-24 10:54:18,387] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.666666666666666, 24.33333333333334, 122.0, 864.1666666666667, 22.5, 25.30358645622956, 0.2187621641498416, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4970400.0000, 
sim time next is 4971600.0000, 
raw observation next is [7.0, 24.0, 120.0, 862.5, 22.5, 25.09337207576069, 0.1879831509508761, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 0.24, 0.4, 0.9530386740331491, 0.375, 0.5911143396467242, 0.5626610503169587, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1343566], dtype=float32), 0.666984]. 
=============================================
[2019-04-24 10:54:21,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2052199e-01 2.5589890e-03 6.3998770e-04 3.2026257e-08 2.9453928e-12
 1.0954542e-09 3.8395846e-11 6.5107545e-04 2.7562791e-01 5.0734816e-12
 9.6247977e-13], sum to 1.0000
[2019-04-24 10:54:21,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4057
[2019-04-24 10:54:21,279] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.7, 69.33333333333334, 0.0, 0.0, 19.0, 21.35445025266016, -0.5800669816774959, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4336800.0000, 
sim time next is 4338000.0000, 
raw observation next is [3.6, 69.0, 0.0, 0.0, 19.0, 21.17998928506187, -0.6110083907353578, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5623268698060943, 0.69, 0.0, 0.0, 0.08333333333333333, 0.264999107088489, 0.2963305364215474, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46150297], dtype=float32), 0.96458685]. 
=============================================
[2019-04-24 10:54:21,698] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:21,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:22,699] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:22,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:22,730] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run12
[2019-04-24 10:54:23,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:24,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:24,895] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:24,896] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:24,910] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run12
[2019-04-24 10:54:25,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:25,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:26,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:26,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:26,728] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run12
[2019-04-24 10:54:27,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:27,725] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:28,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:28,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:28,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run12
[2019-04-24 10:54:29,472] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [6.9524491e-01 3.6614214e-03 5.7281773e-03 1.0038151e-06 2.5041440e-09
 7.6583227e-08 3.3456288e-08 1.3916107e-03 2.9397279e-01 3.3452954e-09
 3.6439163e-10], sum to 1.0000
[2019-04-24 10:54:29,497] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.0156
[2019-04-24 10:54:29,556] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 19.0, 20.52825845347791, -0.7504098533933606, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4832400.0000, 
sim time next is 4833600.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 19.0, 20.34585589223254, -0.7882104128107454, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.08333333333333333, 0.19548799101937822, 0.23726319572975152, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0744947], dtype=float32), 0.5408393]. 
=============================================
[2019-04-24 10:54:32,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:33,069] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:33,384] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:33,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:33,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:33,877] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:33,881] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run12
[2019-04-24 10:54:33,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:34,083] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:34,112] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:34,288] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:34,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:34,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:34,395] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run12
[2019-04-24 10:54:34,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:34,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:34,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2312667e-01 9.5754326e-04 7.0373691e-04 1.7198348e-08 4.5486523e-12
 3.6010523e-09 2.2028141e-11 2.1110800e-04 1.7500092e-01 4.0607452e-12
 1.0798866e-12], sum to 1.0000
[2019-04-24 10:54:34,955] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run12
[2019-04-24 10:54:34,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1404
[2019-04-24 10:54:34,996] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.0, 25.0, 82.0, 707.5, 22.5, 24.55890230098751, 0.1872802916028977, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4982400.0000, 
sim time next is 4983600.0000, 
raw observation next is [8.666666666666668, 25.33333333333334, 75.33333333333333, 663.1666666666667, 22.5, 24.94673005139917, 0.2364419693474639, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7026777469990768, 0.2533333333333334, 0.2511111111111111, 0.7327808471454881, 0.375, 0.578894170949931, 0.578813989782488, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0083852], dtype=float32), -1.1507142]. 
=============================================
[2019-04-24 10:54:35,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:35,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:35,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run12
[2019-04-24 10:54:35,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:36,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:36,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2545466e-01 2.2210833e-03 1.9856975e-03 6.9091314e-08 5.7540434e-11
 3.6214967e-09 5.9993627e-10 1.0343487e-03 3.6930415e-01 6.5720387e-11
 5.3182489e-12], sum to 1.0000
[2019-04-24 10:54:36,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0120
[2019-04-24 10:54:36,051] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 20.2611374801204, -0.7242428552916363, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 25200.0000, 
sim time next is 26400.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 20.14079346697003, -0.7448745996431746, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.17839945558083592, 0.2517084667856085, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.56194067], dtype=float32), -2.030349]. 
=============================================
[2019-04-24 10:54:36,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:36,815] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:36,818] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run12
[2019-04-24 10:54:37,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:37,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:37,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5955492e-01 1.0884485e-03 3.6789605e-03 2.8153893e-08 7.7614928e-12
 3.9205612e-09 3.0925809e-10 7.0318021e-04 2.3497444e-01 1.7371903e-11
 5.6213129e-13], sum to 1.0000
[2019-04-24 10:54:37,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0679
[2019-04-24 10:54:37,685] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.6, 19.33333333333334, 0.0, 0.0, 19.0, 23.88004822535741, 0.04771732963211132, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5091600.0000, 
sim time next is 5092800.0000, 
raw observation next is [8.5, 19.66666666666666, 0.0, 0.0, 19.0, 23.56859181975211, -0.001893976976801992, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.698060941828255, 0.1966666666666666, 0.0, 0.0, 0.08333333333333333, 0.46404931831267593, 0.49936867434106597, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2932008], dtype=float32), -0.4548131]. 
=============================================
[2019-04-24 10:54:37,811] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:38,076] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:38,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.53999722e-01 4.64229984e-03 1.44503955e-02 5.69361418e-07
 1.76824555e-09 9.47768939e-08 7.69394326e-09 8.04883661e-04
 4.26101953e-01 2.48436360e-09 3.18295251e-10], sum to 1.0000
[2019-04-24 10:54:38,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1999
[2019-04-24 10:54:38,177] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 19.0, 21.8126019688822, -0.5441429847616042, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4910400.0000, 
sim time next is 4911600.0000, 
raw observation next is [1.0, 38.66666666666667, 0.0, 0.0, 19.0, 21.3904147706256, -0.6500836605817101, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.3866666666666667, 0.0, 0.0, 0.08333333333333333, 0.2825345642188, 0.2833054464727633, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05802632], dtype=float32), 0.15531416]. 
=============================================
[2019-04-24 10:54:38,243] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:38,243] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:38,246] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run12
[2019-04-24 10:54:38,534] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5167317e-01 3.3154839e-03 2.0745276e-03 1.6141266e-07 9.9934623e-11
 4.7459596e-09 8.9369234e-10 1.4259398e-03 4.4151071e-01 4.7534650e-11
 2.4240752e-11], sum to 1.0000
[2019-04-24 10:54:38,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2687
[2019-04-24 10:54:38,635] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 68.0, 0.0, 0.0, 22.5, 18.708702405536, -0.8335740860743921, 1.0, 1.0, 55.0, 110.22434569567523], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 112800.0000, 
sim time next is 114000.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 22.5, 20.05993506028226, -0.9000902909121463, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.375, 0.1716612550235217, 0.19996990302928455, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6202105], dtype=float32), -0.9326691]. 
=============================================
[2019-04-24 10:54:38,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:38,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:38,817] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run12
[2019-04-24 10:54:40,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9813057e-01 1.8848547e-03 8.8289916e-04 6.8556112e-08 4.1835389e-12
 4.8630326e-09 2.4752173e-11 1.6456937e-04 1.9893698e-01 2.4179699e-12
 9.8988667e-13], sum to 1.0000
[2019-04-24 10:54:40,290] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9380
[2019-04-24 10:54:40,360] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [5.333333333333333, 25.0, 0.0, 0.0, 19.0, 24.72395810057541, 0.2056130397480689, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4998000.0000, 
sim time next is 4999200.0000, 
raw observation next is [4.666666666666666, 27.0, 0.0, 0.0, 19.0, 24.66972785756771, 0.3229882083584105, 0.0, 1.0, 55.0, 62.8037849564552], 
processed observation next is [1.0, 0.8695652173913043, 0.5918744228993538, 0.27, 0.0, 0.0, 0.08333333333333333, 0.5558106547973093, 0.6076627361194702, 0.0, 1.0, 0.8, 0.628037849564552], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9865382], dtype=float32), 1.0833577]. 
=============================================
[2019-04-24 10:54:40,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:40,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.1566745e-01 1.2016285e-03 1.9030800e-03 2.9672366e-08 7.3747206e-12
 3.5074721e-09 4.3959957e-11 1.6421307e-04 1.8106359e-01 3.1308120e-12
 8.1525650e-13], sum to 1.0000
[2019-04-24 10:54:40,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3028
[2019-04-24 10:54:40,590] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 36.0, 0.0, 0.0, 19.0, 24.27115389213637, 0.05007805192149736, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5005200.0000, 
sim time next is 5006400.0000, 
raw observation next is [3.0, 35.0, 0.0, 0.0, 19.0, 23.65263273330869, -0.06002490359644148, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.35, 0.0, 0.0, 0.08333333333333333, 0.4710527277757241, 0.47999169880118614, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9865382], dtype=float32), 1.0833577]. 
=============================================
[2019-04-24 10:54:40,867] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:41,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:41,537] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:41,540] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run12
[2019-04-24 10:54:42,603] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:42,926] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:43,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:43,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:43,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run12
[2019-04-24 10:54:43,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:43,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:44,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2736825e-01 1.1934412e-02 1.9739553e-02 2.0842634e-05 1.0992270e-06
 6.1873257e-06 3.4277596e-06 2.6509820e-02 4.1441581e-01 4.7299625e-07
 1.4934760e-07], sum to 1.0000
[2019-04-24 10:54:44,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9646
[2019-04-24 10:54:44,099] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 19.0, 20.47161184143662, -0.7106959250653775, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 6000.0000, 
sim time next is 7200.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 20.48198430068374, -0.569552445516838, 0.0, 1.0, 55.0, 64.00425341650069], 
processed observation next is [0.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.20683202505697848, 0.31014918482772064, 0.0, 1.0, 0.8, 0.6400425341650069], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01584588], dtype=float32), 2.171523]. 
=============================================
[2019-04-24 10:54:44,354] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:44,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:44,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:44,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:44,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:44,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run12
[2019-04-24 10:54:44,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:54:45,355] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:45,355] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:45,359] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run12
[2019-04-24 10:54:45,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:54:45,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:45,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run12
[2019-04-24 10:54:53,165] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.44939208e-01 5.88928489e-03 4.72966465e-04 1.08912552e-07
 5.18705426e-11 1.09221210e-08 1.36827855e-10 1.25935988e-03
 2.47438997e-01 2.61879771e-11 1.31006265e-11], sum to 1.0000
[2019-04-24 10:54:53,167] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8562
[2019-04-24 10:54:53,421] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.8, 65.33333333333334, 43.66666666666666, 1.5, 22.5, 21.94026047129278, -0.3433653692303784, 1.0, 1.0, 55.0, 103.43949141552554], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 120000.0000, 
sim time next is 121200.0000, 
raw observation next is [-7.799999999999999, 69.66666666666666, 69.16666666666666, 5.999999999999998, 22.5, 23.27600798816126, -0.1957826862676835, 1.0, 1.0, 55.0, 68.31816854975247], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188372, 0.6966666666666665, 0.2305555555555555, 0.006629834254143645, 0.375, 0.43966733234677174, 0.43473910457743886, 1.0, 1.0, 0.8, 0.6831816854975247], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2400235], dtype=float32), -0.527191]. 
=============================================
[2019-04-24 10:54:54,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.54737151e-01 2.77016591e-03 3.81088024e-03 2.67982784e-07
 1.04552915e-10 1.35870337e-08 1.81235604e-09 1.70670322e-03
 4.36974823e-01 1.52972038e-10 4.90319486e-11], sum to 1.0000
[2019-04-24 10:54:54,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3706
[2019-04-24 10:54:54,464] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 19.41514326722324, -0.9716732301867178, 0.0, 1.0, 55.0, 56.572798411745545], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 196800.0000, 
sim time next is 198000.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 19.68228741653556, -1.119255345462775, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.14019061804462987, 0.12691488484574168, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.282335], dtype=float32), -1.2694004]. 
=============================================
[2019-04-24 10:54:56,985] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-24 10:54:56,986] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:54:56,986] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:54:56,986] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:56,995] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run16
[2019-04-24 10:54:56,986] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:54:57,072] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:57,074] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run16
[2019-04-24 10:54:57,072] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:54:57,155] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run16
[2019-04-24 10:55:56,604] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([0.23055789], dtype=float32), 0.33351755]
[2019-04-24 10:55:56,605] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [0.320910018, 100.0, 52.795998418, 0.0, 22.5, 22.76890471284638, -0.2912221629755891, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:55:56,605] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:55:56,607] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [7.8119725e-01 7.9566456e-04 9.4397395e-04 3.3184840e-08 3.4242678e-12
 1.1108423e-09 5.0734899e-11 1.1564332e-04 2.1694739e-01 5.6385174e-12
 9.8351980e-13], sampled 0.8127045163972808
[2019-04-24 10:57:13,862] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3072.1138 76319.1324 -74.5240
[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:13,898] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:14,089] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,086] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2754.4612 87396.2067 -422.3184
[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:29,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:33,871] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2739.7450 88637.0337 -545.8404
[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:33,899] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,002] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:57:34,901] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 750000, evaluation results [750000.0, 2754.461202145539, 87396.20674455221, -422.3183511495194, 3072.113791877683, 76319.13240836687, -74.52395466421157, 2739.7449625849376, 88637.03366258596, -545.8404260410276]
[2019-04-24 10:57:38,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6334176e-01 1.3049691e-03 6.1816478e-04 8.3895184e-09 3.0557625e-12
 1.8635971e-09 3.5253162e-11 7.0807780e-04 3.3402699e-01 3.0678743e-12
 1.8372328e-13], sum to 1.0000
[2019-04-24 10:57:38,159] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5157
[2019-04-24 10:57:38,188] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.33333333333334, 0.0, 0.0, 19.0, 20.96454612159035, -0.477060467704669, 0.0, 1.0, 55.0, 78.14726260668002], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 98400.0000, 
sim time next is 99600.0000, 
raw observation next is [-3.2, 81.66666666666667, 0.0, 0.0, 19.0, 21.34558965209862, -0.6004514431462376, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.37396121883656513, 0.8166666666666668, 0.0, 0.0, 0.08333333333333333, 0.27879913767488507, 0.29984951895125417, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35983884], dtype=float32), 0.9125618]. 
=============================================
[2019-04-24 10:57:47,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4642042e-01 2.3976672e-03 8.6324202e-04 4.5346066e-08 6.0337659e-12
 7.1581820e-09 1.4328212e-10 2.8853008e-04 3.5003009e-01 1.5180725e-11
 2.1684900e-12], sum to 1.0000
[2019-04-24 10:57:47,270] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6282
[2019-04-24 10:57:47,372] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 22.5, 22.45988709228497, -0.336225439892295, 1.0, 1.0, 55.0, 67.21251972799732], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 241200.0000, 
sim time next is 242400.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 22.5, 22.81063546919606, -0.4929381248872989, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.368421052631579, 0.65, 0.0, 0.0, 0.375, 0.4008862890996718, 0.3356872917042337, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4278524], dtype=float32), -0.8240134]. 
=============================================
[2019-04-24 10:57:48,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9946057e-01 5.2552503e-03 2.9263473e-03 1.6682302e-06 2.9580360e-10
 6.8382356e-08 4.3541708e-09 4.5287664e-04 2.9190323e-01 6.0309185e-10
 3.3150874e-10], sum to 1.0000
[2019-04-24 10:57:48,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1870
[2019-04-24 10:57:48,572] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.0, 42.0, 0.0, 0.0, 22.5, 21.309227016955, -0.8045013151628971, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 417600.0000, 
sim time next is 418800.0000, 
raw observation next is [-10.2, 43.66666666666667, 0.0, 0.0, 19.0, 20.2666197477837, -0.9806172153432157, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.1800554016620499, 0.4366666666666667, 0.0, 0.0, 0.08333333333333333, 0.188884978981975, 0.1731275948855948, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5405651], dtype=float32), -0.38016784]. 
=============================================
[2019-04-24 10:57:55,070] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0699484e-01 5.2176800e-04 1.2851132e-03 4.8060200e-09 1.4486386e-12
 2.6180200e-10 1.6683344e-11 8.2657389e-05 4.9111563e-01 9.6784928e-13
 9.2435425e-14], sum to 1.0000
[2019-04-24 10:57:55,071] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3328
[2019-04-24 10:57:55,094] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.466666666666667, 96.33333333333333, 0.0, 0.0, 19.0, 21.27988486766624, -0.7260026831405302, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 516000.0000, 
sim time next is 517200.0000, 
raw observation next is [3.633333333333333, 96.66666666666666, 0.0, 0.0, 19.0, 20.7808464335547, -0.8140623705173103, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.5632502308402586, 0.9666666666666666, 0.0, 0.0, 0.08333333333333333, 0.231737202796225, 0.22864587649422988, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17661656], dtype=float32), 0.35719547]. 
=============================================
[2019-04-24 10:57:57,429] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.1249872e-01 2.3005309e-04 1.0033951e-03 6.7733139e-09 9.4718714e-14
 1.9724546e-10 6.1107608e-12 9.8759636e-05 2.8616911e-01 2.8993244e-13
 2.9799903e-14], sum to 1.0000
[2019-04-24 10:57:57,433] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.8900
[2019-04-24 10:57:57,492] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [3.466666666666667, 96.33333333333333, 0.0, 0.0, 19.0, 21.18062596217273, -0.5094419954209731, 0.0, 1.0, 55.0, 77.31703384759503], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 516000.0000, 
sim time next is 517200.0000, 
raw observation next is [3.633333333333333, 96.66666666666666, 0.0, 0.0, 19.0, 21.95397700746093, -0.4183979768416594, 0.0, 1.0, 55.0, 50.04606448591787], 
processed observation next is [1.0, 1.0, 0.5632502308402586, 0.9666666666666666, 0.0, 0.0, 0.08333333333333333, 0.3294980839550776, 0.3605340077194468, 0.0, 1.0, 0.8, 0.5004606448591786], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02023573], dtype=float32), 0.75223714]. 
=============================================
[2019-04-24 10:58:06,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9960735e-01 5.0793081e-03 1.3844443e-02 8.7159930e-07 1.6579313e-09
 1.1321897e-07 2.3608955e-08 1.3278457e-03 3.8014010e-01 2.4363576e-09
 3.7840830e-10], sum to 1.0000
[2019-04-24 10:58:06,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6057
[2019-04-24 10:58:06,388] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-2.933333333333334, 62.33333333333333, 92.83333333333334, 48.33333333333333, 19.0, 18.81370955412885, -1.195967929672303, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 646800.0000, 
sim time next is 648000.0000, 
raw observation next is [-2.7, 61.0, 100.5, 69.0, 19.0, 19.03887955269352, -0.9739406215250366, 0.0, 1.0, 25.0, 73.58001723896399], 
processed observation next is [0.0, 0.5217391304347826, 0.38781163434903054, 0.61, 0.335, 0.07624309392265194, 0.08333333333333333, 0.08657329605779325, 0.17535312615832113, 0.0, 1.0, 0.2, 0.7358001723896399], 
reward next is 0.0642, 
noisyNet noise sample is [array([-0.6826791], dtype=float32), -0.6936841]. 
=============================================
[2019-04-24 10:58:06,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6043526e-01 5.1813439e-04 4.4537691e-04 1.3044908e-09 4.2447840e-13
 9.7105997e-11 2.9366904e-12 6.9697140e-05 3.3853164e-01 7.9974960e-14
 1.9019574e-14], sum to 1.0000
[2019-04-24 10:58:06,489] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1554
[2019-04-24 10:58:06,496] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.0, 92.0, 43.5, 0.0, 22.5, 22.08374344875904, -0.3858781457579175, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 982800.0000, 
sim time next is 984000.0000, 
raw observation next is [10.16666666666667, 92.33333333333334, 54.5, 0.0, 22.5, 22.22283799485306, -0.3657705672069735, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.7442289935364729, 0.9233333333333335, 0.18166666666666667, 0.0, 0.375, 0.3519031662377549, 0.3780764775976755, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.57917905], dtype=float32), 1.6404738]. 
=============================================
[2019-04-24 10:58:09,304] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.4526864e-01 8.0478215e-04 1.0992392e-03 1.1414847e-07 3.6799536e-11
 5.6776792e-09 2.9643699e-10 2.0708362e-04 2.5262016e-01 2.1562968e-11
 8.5762404e-12], sum to 1.0000
[2019-04-24 10:58:09,309] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6057
[2019-04-24 10:58:09,349] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 61.0, 0.0, 0.0, 19.0, 21.56201077049023, -0.6098239185699165, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 766800.0000, 
sim time next is 768000.0000, 
raw observation next is [-5.8, 62.0, 0.0, 0.0, 19.0, 21.03232111810124, -0.6902334293937673, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.30193905817174516, 0.62, 0.0, 0.0, 0.08333333333333333, 0.2526934265084367, 0.2699221902020776, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47561702], dtype=float32), -1.8245367]. 
=============================================
[2019-04-24 10:58:15,434] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4434259e-01 2.6546849e-04 1.8030513e-04 2.6292459e-09 1.3905797e-13
 3.2697126e-11 7.6944988e-13 4.2676431e-05 1.5516905e-01 2.1853023e-14
 9.6906007e-15], sum to 1.0000
[2019-04-24 10:58:15,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8734
[2019-04-24 10:58:15,483] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [4.800000000000001, 93.33333333333334, 0.0, 0.0, 22.5, 24.23383672765233, -0.2133143279731775, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 926400.0000, 
sim time next is 927600.0000, 
raw observation next is [4.600000000000001, 94.66666666666667, 0.0, 0.0, 22.5, 23.53974232130037, -0.0740272587499161, 1.0, 1.0, 55.0, 65.8201986454827], 
processed observation next is [1.0, 0.7391304347826086, 0.5900277008310251, 0.9466666666666668, 0.0, 0.0, 0.375, 0.46164519344169747, 0.47532424708336135, 1.0, 1.0, 0.8, 0.6582019864548271], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.86717224], dtype=float32), 1.0537705]. 
=============================================
[2019-04-24 10:58:19,294] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.4665066e-01 1.9489191e-04 1.0469965e-04 3.3405645e-10 6.9508790e-15
 9.8520714e-12 4.5177315e-14 1.2794390e-05 1.5303700e-01 5.0765332e-15
 1.9733411e-15], sum to 1.0000
[2019-04-24 10:58:19,302] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3096
[2019-04-24 10:58:19,325] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.36666666666667, 86.0, 126.6666666666667, 0.0, 22.5, 24.30934735869313, 0.2373254866217688, 1.0, 1.0, 55.0, 67.58780223140383], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 994800.0000, 
sim time next is 996000.0000, 
raw observation next is [12.53333333333333, 86.0, 126.5, 0.0, 22.5, 24.41980167763982, 0.1184439861772077, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8097876269621421, 0.86, 0.4216666666666667, 0.0, 0.375, 0.5349834731366517, 0.539481328725736, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42172435], dtype=float32), 0.35040322]. 
=============================================
[2019-04-24 10:58:22,597] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3034831e-01 1.3928943e-04 8.7642635e-05 2.4025990e-09 2.9479379e-14
 1.5424652e-10 7.5252288e-13 2.7534668e-05 1.6939726e-01 1.0745681e-13
 6.5079913e-15], sum to 1.0000
[2019-04-24 10:58:22,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0353
[2019-04-24 10:58:22,637] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.86666666666667, 58.33333333333334, 204.8333333333333, 228.1666666666667, 22.5, 24.79195359171614, 0.1929832099221953, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1597200.0000, 
sim time next is 1598400.0000, 
raw observation next is [11.6, 57.0, 182.5, 186.5, 22.5, 24.70882961178355, 0.1781209404426019, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.7839335180055402, 0.57, 0.6083333333333333, 0.20607734806629835, 0.375, 0.5590691343152958, 0.5593736468142007, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6713757], dtype=float32), -0.10809888]. 
=============================================
[2019-04-24 10:58:24,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8778219e-01 1.2254684e-03 1.2618976e-03 4.1227983e-07 4.5223653e-10
 5.7619342e-08 1.9732507e-09 9.1898959e-04 2.0881099e-01 1.8347380e-09
 3.3846134e-11], sum to 1.0000
[2019-04-24 10:58:24,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4615
[2019-04-24 10:58:24,202] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 23.94066352569802, 0.1646950186178286, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1236000.0000, 
sim time next is 1237200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 23.69664874479172, 0.1290710020433717, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.4747207287326433, 0.5430236673477905, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7184849], dtype=float32), -0.3960988]. 
=============================================
[2019-04-24 10:58:24,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5727844e-01 2.0933068e-04 6.0481561e-04 2.9003084e-09 4.7058418e-13
 3.0343114e-10 5.4069908e-12 1.7232625e-04 2.4173507e-01 2.4734381e-12
 1.8188330e-14], sum to 1.0000
[2019-04-24 10:58:24,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5382
[2019-04-24 10:58:24,616] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 98.66666666666666, 100.0, 0.0, 19.0, 24.8729967136762, 0.3721013864022114, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1255200.0000, 
sim time next is 1256400.0000, 
raw observation next is [13.8, 100.0, 98.0, 0.0, 19.0, 24.45910419385196, 0.298057400656147, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.844875346260388, 1.0, 0.32666666666666666, 0.0, 0.08333333333333333, 0.5382586828209966, 0.5993524668853824, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7184849], dtype=float32), -0.3960988]. 
=============================================
[2019-04-24 10:58:29,539] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8106105e-01 5.2804290e-04 5.2072445e-04 8.1753679e-09 2.4741281e-12
 3.4998474e-10 9.8019908e-12 7.6576107e-05 2.1781358e-01 7.5543619e-13
 7.8320407e-14], sum to 1.0000
[2019-04-24 10:58:29,540] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2736
[2019-04-24 10:58:29,548] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.433333333333334, 90.0, 0.0, 0.0, 19.0, 21.5812249863357, -0.3783480108699431, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1459200.0000, 
sim time next is 1460400.0000, 
raw observation next is [1.266666666666667, 91.0, 0.0, 0.0, 19.0, 21.44166433361448, -0.4092488007869724, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4976915974145891, 0.91, 0.0, 0.0, 0.08333333333333333, 0.28680536113453997, 0.3635837330710092, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49509275], dtype=float32), -1.6590334]. 
=============================================
[2019-04-24 10:58:30,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7016393e-01 1.9592326e-03 4.3782205e-03 8.2303444e-07 5.8721999e-10
 4.9406697e-08 1.5302620e-08 1.9789962e-03 3.2151875e-01 7.3999445e-10
 8.4862263e-11], sum to 1.0000
[2019-04-24 10:58:30,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8466
[2019-04-24 10:58:30,228] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 85.66666666666667, 21.83333333333334, 0.0, 19.0, 19.88285487158772, -0.796162328548386, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1758000.0000, 
sim time next is 1759200.0000, 
raw observation next is [-1.7, 84.33333333333333, 32.5, 0.0, 19.0, 20.28359082192168, -0.5047021716887083, 0.0, 1.0, 55.0, 90.77615818788854], 
processed observation next is [0.0, 0.34782608695652173, 0.4155124653739613, 0.8433333333333333, 0.10833333333333334, 0.0, 0.08333333333333333, 0.1902992351601401, 0.33176594277043053, 0.0, 1.0, 0.8, 0.9077615818788854], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7736063], dtype=float32), -0.91315717]. 
=============================================
[2019-04-24 10:58:32,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9870620e-01 5.9172796e-04 8.5972669e-04 2.0390337e-07 2.7587135e-10
 2.2832426e-08 7.4451606e-10 2.5455482e-04 9.9587582e-02 5.5655952e-10
 1.3297177e-11], sum to 1.0000
[2019-04-24 10:58:32,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3459
[2019-04-24 10:58:32,295] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 80.0, 0.0, 0.0, 19.0, 25.10284708136174, 0.4906360847902412, 0.0, 0.0, 25.0, 48.61692790977399], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1213200.0000, 
sim time next is 1214400.0000, 
raw observation next is [16.1, 81.0, 0.0, 0.0, 19.0, 25.23736723639963, 0.410382329192036, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.9085872576177286, 0.81, 0.0, 0.0, 0.08333333333333333, 0.6031139363666359, 0.6367941097306787, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4417295], dtype=float32), -0.702102]. 
=============================================
[2019-04-24 10:58:41,224] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5039454e-01 2.4255763e-03 1.4846161e-02 1.2713934e-06 3.5648895e-09
 1.7584165e-07 3.7944741e-08 1.3728614e-03 4.3095946e-01 4.8790336e-09
 4.1874812e-10], sum to 1.0000
[2019-04-24 10:58:41,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6662
[2019-04-24 10:58:41,266] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.700000000000001, 78.0, 22.66666666666667, 0.0, 19.0, 19.57875629052305, -1.110354450753169, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1844400.0000, 
sim time next is 1845600.0000, 
raw observation next is [-6.700000000000001, 78.0, 47.16666666666666, 15.66666666666666, 19.0, 19.17643668959418, -0.9879589874682316, 0.0, 1.0, 55.0, 76.85494024100933], 
processed observation next is [0.0, 0.34782608695652173, 0.2770083102493075, 0.78, 0.15722222222222218, 0.017311233885819514, 0.08333333333333333, 0.09803639079951498, 0.17068033751058945, 0.0, 1.0, 0.8, 0.7685494024100933], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12984037], dtype=float32), 0.4067956]. 
=============================================
[2019-04-24 10:58:53,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9577335e-01 6.3422453e-03 9.4498228e-03 3.1813772e-07 1.0581662e-09
 8.3121478e-08 1.0508857e-08 8.3546044e-04 5.8759874e-01 1.9656838e-09
 1.6895835e-10], sum to 1.0000
[2019-04-24 10:58:53,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1256
[2019-04-24 10:58:54,011] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 80.33333333333334, 0.0, 0.0, 19.0, 19.63354776403779, -1.0858483453976, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1891200.0000, 
sim time next is 1892400.0000, 
raw observation next is [-6.0, 77.66666666666667, 0.0, 0.0, 19.0, 18.9598633139432, -1.217930212721127, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.296398891966759, 0.7766666666666667, 0.0, 0.0, 0.08333333333333333, 0.07998860949526658, 0.09402326242629104, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9936, 
noisyNet noise sample is [array([-1.0483985], dtype=float32), 1.2055249]. 
=============================================
[2019-04-24 10:59:03,916] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.4426303e-01 2.4172007e-03 5.2885490e-04 3.3235064e-08 4.1640966e-12
 7.7384826e-10 4.6923177e-11 2.0025342e-04 3.5259062e-01 5.1465061e-12
 1.2501241e-12], sum to 1.0000
[2019-04-24 10:59:03,917] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0973
[2019-04-24 10:59:03,982] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.866666666666667, 77.66666666666667, 148.5, 0.0, 22.5, 22.78932246665662, -0.4303689746860767, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2029200.0000, 
sim time next is 2030400.0000, 
raw observation next is [-4.5, 75.0, 151.5, 0.0, 22.5, 22.69817526424572, -0.4870396520230894, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.75, 0.505, 0.0, 0.375, 0.39151460535380994, 0.33765344932563685, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05018846], dtype=float32), -1.7583388]. 
=============================================
[2019-04-24 10:59:07,752] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3285701e-01 7.2437507e-04 8.8397332e-04 5.6860312e-08 2.7030095e-12
 6.9176720e-10 4.4466451e-11 1.1980519e-04 1.6541484e-01 1.6056734e-12
 8.1231853e-13], sum to 1.0000
[2019-04-24 10:59:07,755] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6114
[2019-04-24 10:59:07,768] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 67.66666666666667, 269.3333333333334, 106.5, 22.5, 22.04912609976197, -0.5284393710797008, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2115600.0000, 
sim time next is 2116800.0000, 
raw observation next is [-6.7, 64.0, 222.0, 117.5, 22.5, 21.75269467152826, -0.5586580142497252, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.2770083102493075, 0.64, 0.74, 0.1298342541436464, 0.375, 0.3127245559606884, 0.3137806619167583, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9140, 
noisyNet noise sample is [array([0.05730551], dtype=float32), 0.44603065]. 
=============================================
[2019-04-24 10:59:12,532] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.6486970e-01 6.3418914e-03 1.8513708e-03 4.6316096e-08 2.8265461e-12
 3.6622960e-09 1.5308527e-10 2.7966636e-04 4.2665732e-01 9.3749002e-12
 1.6448528e-12], sum to 1.0000
[2019-04-24 10:59:12,534] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2477
[2019-04-24 10:59:12,590] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 71.5, 356.5, 22.5, 22.43356959688315, -0.4919530300974564, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2192400.0000, 
sim time next is 2193600.0000, 
raw observation next is [-5.4, 73.66666666666667, 91.83333333333333, 419.5, 22.5, 22.10079619878262, -0.5235295359366607, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.31301939058171746, 0.7366666666666667, 0.3061111111111111, 0.46353591160220997, 0.375, 0.34173301656521843, 0.32549015468777975, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9862, 
noisyNet noise sample is [array([-0.85227066], dtype=float32), 0.7933631]. 
=============================================
[2019-04-24 10:59:13,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1721472e-01 6.8206904e-03 1.4333087e-02 9.7775501e-06 6.5587422e-08
 8.2383099e-07 2.8121624e-07 4.6871859e-03 4.5693341e-01 4.5672181e-08
 1.2299418e-08], sum to 1.0000
[2019-04-24 10:59:13,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4564
[2019-04-24 10:59:13,426] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 60.0, 0.0, 0.0, 19.0, 19.50074375637369, -1.041315081546064, 0.0, 1.0, 55.0, 54.26793203647169], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2440800.0000, 
sim time next is 2442000.0000, 
raw observation next is [-9.100000000000001, 60.33333333333334, 0.0, 0.0, 19.0, 19.30003294444145, -1.233716129649548, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.21052631578947364, 0.6033333333333334, 0.0, 0.0, 0.08333333333333333, 0.10833607870345426, 0.08876129011681733, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05736623], dtype=float32), 0.3325841]. 
=============================================
[2019-04-24 10:59:20,510] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [8.0667901e-01 1.4105036e-03 7.0562854e-04 2.3393012e-08 1.5418817e-11
 3.5955730e-09 5.4655485e-11 1.8509035e-04 1.9101977e-01 3.7919364e-12
 1.2765392e-12], sum to 1.0000
[2019-04-24 10:59:20,529] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.9403
[2019-04-24 10:59:20,601] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.833333333333333, 33.0, 210.1666666666667, 98.66666666666666, 22.5, 23.05146758208843, -0.1878684304996758, 1.0, 1.0, 55.0, 75.25400426662225], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2551200.0000, 
sim time next is 2552400.0000, 
raw observation next is [2.2, 30.0, 194.5, 252.0, 22.5, 23.807555313887, -0.2294887331401406, 1.0, 1.0, 55.0, 47.94818511326243], 
processed observation next is [1.0, 0.5652173913043478, 0.5235457063711911, 0.3, 0.6483333333333333, 0.27845303867403315, 0.375, 0.4839629428239167, 0.4235037556199532, 1.0, 1.0, 0.8, 0.4794818511326243], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0104966], dtype=float32), 0.15877374]. 
=============================================
[2019-04-24 10:59:22,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6452738e-01 1.3877158e-03 1.5536130e-03 4.1634962e-08 2.0022063e-12
 6.4318489e-10 4.4424641e-11 8.7492634e-05 2.3244366e-01 2.6740305e-12
 1.8063294e-12], sum to 1.0000
[2019-04-24 10:59:22,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0081
[2019-04-24 10:59:22,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 115.0, 165.0, 22.5, 23.20927484442088, -0.2610222549758123, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2649600.0000, 
sim time next is 2650800.0000, 
raw observation next is [0.5, 50.0, 88.33333333333333, 137.6666666666667, 22.5, 22.91236073776499, -0.2866456271687424, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4764542936288089, 0.5, 0.29444444444444445, 0.15211786372007371, 0.375, 0.409363394813749, 0.40445145761041923, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3426301], dtype=float32), -0.18959631]. 
=============================================
[2019-04-24 10:59:22,321] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.3548700e-01 1.1184474e-02 2.2148017e-02 2.2589777e-06 3.6331901e-08
 6.6729547e-07 1.2438439e-07 6.1286949e-03 4.2504874e-01 3.3909462e-08
 6.4564207e-09], sum to 1.0000
[2019-04-24 10:59:22,322] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6062
[2019-04-24 10:59:22,358] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.1333333333333333, 30.0, 89.33333333333333, 842.3333333333334, 19.0, 19.99325363714959, -0.7891524980964958, 0.0, 1.0, 55.0, 73.70729627383913], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2463600.0000, 
sim time next is 2464800.0000, 
raw observation next is [0.8666666666666667, 29.0, 89.5, 842.8333333333334, 19.0, 20.74523139992278, -0.6961127789349654, 0.0, 1.0, 55.0, 48.19235494526328], 
processed observation next is [0.0, 0.5217391304347826, 0.4866112650046169, 0.29, 0.29833333333333334, 0.9313075506445673, 0.08333333333333333, 0.2287692833268983, 0.26796240702167823, 0.0, 1.0, 0.8, 0.4819235494526328], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0855896], dtype=float32), -2.3943465]. 
=============================================
[2019-04-24 10:59:28,402] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.7003191e-01 6.5296813e-04 8.1699097e-04 1.2622421e-08 1.1560801e-12
 7.0330741e-10 7.4085339e-12 8.4961590e-05 3.2841322e-01 3.8270520e-12
 1.3461064e-13], sum to 1.0000
[2019-04-24 10:59:28,404] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8180
[2019-04-24 10:59:28,488] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.0, 82.66666666666667, 0.0, 0.0, 19.0, 23.41676017934745, -0.1289428907988729, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2925600.0000, 
sim time next is 2926800.0000, 
raw observation next is [-1.0, 85.0, 0.0, 0.0, 19.0, 23.10374491430257, -0.03004290583090714, 0.0, 1.0, 55.0, 73.36331671408323], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.85, 0.0, 0.0, 0.08333333333333333, 0.4253120761918809, 0.4899856980563643, 0.0, 1.0, 0.8, 0.7336331671408323], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47205883], dtype=float32), 0.64494413]. 
=============================================
[2019-04-24 10:59:31,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6310910e-01 3.7728134e-03 2.5879226e-03 4.1131395e-07 3.3383692e-11
 9.4773087e-09 4.8014809e-10 7.4806932e-04 4.2978171e-01 3.4048490e-11
 8.4292000e-12], sum to 1.0000
[2019-04-24 10:59:31,686] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3422
[2019-04-24 10:59:31,697] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 78.0, 0.0, 0.0, 19.0, 20.25841498066548, -0.8550814251485517, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2606400.0000, 
sim time next is 2607600.0000, 
raw observation next is [-5.8, 79.66666666666667, 0.0, 0.0, 19.0, 19.94968819765872, -0.9088729842914236, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.30193905817174516, 0.7966666666666667, 0.0, 0.0, 0.08333333333333333, 0.16247401647155998, 0.19704233856952547, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23176517], dtype=float32), 0.57408816]. 
=============================================
[2019-04-24 10:59:35,389] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2224301e-01 3.0891626e-04 3.0020706e-04 2.9735352e-09 4.9578695e-13
 6.3140146e-11 1.6009083e-12 5.7765494e-05 2.7709001e-01 5.8167115e-14
 3.7830867e-14], sum to 1.0000
[2019-04-24 10:59:35,389] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2491
[2019-04-24 10:59:35,412] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 100.0, 82.66666666666667, 8.999999999999998, 22.5, 22.7528307468822, -0.2550089956253488, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2907600.0000, 
sim time next is 2908800.0000, 
raw observation next is [2.0, 100.0, 78.0, 27.0, 22.5, 22.99587253500518, -0.2305273989938316, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 1.0, 0.26, 0.02983425414364641, 0.375, 0.4163227112504317, 0.4231575336687228, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1857951], dtype=float32), -0.82608545]. 
=============================================
[2019-04-24 10:59:37,696] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.3145897e-01 1.8985894e-03 6.0276832e-03 5.1841045e-07 6.2326799e-10
 4.7575309e-08 5.5707243e-09 2.9377590e-03 4.5767638e-01 3.3634073e-10
 1.8556370e-10], sum to 1.0000
[2019-04-24 10:59:37,706] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.6267
[2019-04-24 10:59:37,798] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 20.83617534049004, -0.5702994483411266, 0.0, 1.0, 55.0, 54.61039961622569], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2955600.0000, 
sim time next is 2956800.0000, 
raw observation next is [-3.333333333333333, 81.66666666666667, 0.0, 0.0, 19.0, 21.18185549966962, -0.5372361740759621, 0.0, 1.0, 55.0, 53.175235757264346], 
processed observation next is [0.0, 0.21739130434782608, 0.37026777469990774, 0.8166666666666668, 0.0, 0.0, 0.08333333333333333, 0.26515462497246833, 0.3209212753080126, 0.0, 1.0, 0.8, 0.5317523575726435], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13077456], dtype=float32), 1.1822155]. 
=============================================
[2019-04-24 10:59:38,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1502054e-01 2.4956893e-03 1.8423912e-03 9.8821459e-08 1.4517261e-10
 1.8555028e-08 5.5234339e-10 1.1946457e-03 2.7944666e-01 9.2799060e-11
 2.6943914e-11], sum to 1.0000
[2019-04-24 10:59:38,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0078
[2019-04-24 10:59:38,135] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 21.20247066151363, -0.5920362271656049, 0.0, 1.0, 55.0, 68.55084732600406], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2782800.0000, 
sim time next is 2784000.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 21.28453799280528, -0.7233646177391161, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.27371149940044, 0.25887846075362797, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3153851], dtype=float32), -1.9966097]. 
=============================================
[2019-04-24 10:59:39,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.67450988e-01 2.14875763e-04 2.93816614e-04 1.91332616e-09
 1.07234757e-13 1.18469790e-10 2.02662366e-12 2.40287900e-05
 2.32016265e-01 1.11127294e-13 1.35967016e-14], sum to 1.0000
[2019-04-24 10:59:39,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4115
[2019-04-24 10:59:39,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 93.0, 38.5, 47.5, 22.5, 23.84812187511137, -0.113629888226734, 1.0, 1.0, 55.0, 71.95282435659186], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2912400.0000, 
sim time next is 2913600.0000, 
raw observation next is [1.666666666666667, 93.0, 16.83333333333333, 43.16666666666667, 22.5, 23.84093820439254, -0.1362104665733999, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5087719298245615, 0.93, 0.0561111111111111, 0.04769797421731124, 0.375, 0.486744850366045, 0.45459651114220007, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2557709], dtype=float32), -1.8358215]. 
=============================================
[2019-04-24 10:59:43,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7557875e-01 1.5536498e-03 7.2389230e-04 1.1316302e-08 1.7937401e-12
 2.7324704e-10 1.1297157e-11 1.6650792e-04 4.2197719e-01 2.9618129e-13
 1.0969719e-13], sum to 1.0000
[2019-04-24 10:59:43,593] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7506
[2019-04-24 10:59:43,732] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [2.0, 93.0, 52.5, 91.5, 22.5, 22.52093915217477, -0.3333574438454684, 1.0, 1.0, 55.0, 72.33634770887954], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2880000.0000, 
sim time next is 2881200.0000, 
raw observation next is [1.666666666666667, 93.0, 87.5, 134.5, 22.5, 22.82624642915835, -0.2106665414436723, 1.0, 1.0, 55.0, 72.36809745875723], 
processed observation next is [1.0, 0.34782608695652173, 0.5087719298245615, 0.93, 0.2916666666666667, 0.14861878453038674, 0.375, 0.40218720242986244, 0.42977781951877586, 1.0, 1.0, 0.8, 0.7236809745875723], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.89020354], dtype=float32), 0.5433689]. 
=============================================
[2019-04-24 10:59:46,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8890271e-01 3.7361335e-04 9.9891284e-04 8.7158708e-10 1.3875552e-13
 1.0076275e-10 1.3593044e-12 2.0212635e-04 4.0952262e-01 2.8721884e-14
 5.4086150e-15], sum to 1.0000
[2019-04-24 10:59:46,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7950
[2019-04-24 10:59:46,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2002712e-01 3.8481986e-03 7.8004766e-03 3.3903308e-07 1.3037487e-09
 5.7642080e-08 6.8657964e-09 1.5366327e-03 3.6678717e-01 1.8870949e-09
 2.0747624e-10], sum to 1.0000
[2019-04-24 10:59:46,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2035
[2019-04-24 10:59:47,011] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.333333333333333, 100.0, 69.33333333333334, 340.3333333333334, 22.5, 22.81287206923009, -0.2274638591243897, 1.0, 1.0, 55.0, 51.67522246161465], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3140400.0000, 
sim time next is 3141600.0000, 
raw observation next is [6.666666666666666, 100.0, 85.66666666666667, 434.5, 22.5, 23.50847711724894, -0.114267989054783, 1.0, 1.0, 55.0, 48.93315273753713], 
processed observation next is [1.0, 0.34782608695652173, 0.6472760849492153, 1.0, 0.28555555555555556, 0.48011049723756904, 0.375, 0.459039759770745, 0.4619106703150723, 1.0, 1.0, 0.8, 0.4893315273753713], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41116798], dtype=float32), 1.4659861]. 
=============================================
[2019-04-24 10:59:47,042] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 217.0, 154.0, 19.0, 19.04501712830601, -1.002671687837695, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2977200.0000, 
sim time next is 2978400.0000, 
raw observation next is [-3.0, 65.0, 243.0, 240.6666666666667, 19.0, 18.91599021660425, -1.019630200324584, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.3795013850415513, 0.65, 0.81, 0.26593001841620634, 0.08333333333333333, 0.07633251805035417, 0.16012326655847198, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9718, 
noisyNet noise sample is [array([-1.2186531], dtype=float32), -0.31162655]. 
=============================================
[2019-04-24 10:59:48,069] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.45075059e-01 1.15221879e-03 1.69371732e-03 5.75520609e-09
 4.60006924e-13 2.70720252e-10 1.07731445e-11 1.69647348e-04
 4.51909393e-01 1.38048362e-12 1.14851027e-13], sum to 1.0000
[2019-04-24 10:59:48,070] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1977
[2019-04-24 10:59:48,095] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.333333333333333, 100.0, 0.0, 0.0, 19.0, 21.57987697298846, -0.6460178920516313, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3129600.0000, 
sim time next is 3130800.0000, 
raw observation next is [3.666666666666667, 100.0, 0.0, 0.0, 19.0, 21.11956525272107, -0.7682471985703585, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.564173591874423, 1.0, 0.0, 0.0, 0.08333333333333333, 0.2599637710600892, 0.24391760047654718, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6967222], dtype=float32), 0.032268833]. 
=============================================
[2019-04-24 10:59:48,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6980487e-01 2.8109993e-03 5.9337686e-03 7.8837428e-07 1.0560096e-09
 4.9586923e-08 4.4776418e-09 1.1256282e-03 3.2032391e-01 7.9290852e-10
 2.8443317e-10], sum to 1.0000
[2019-04-24 10:59:48,626] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9637
[2019-04-24 10:59:48,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.00010979e-01 1.77878141e-03 2.22405558e-03 4.99114421e-08
 1.12854566e-10 1.09002833e-08 1.69495329e-09 3.74352123e-04
 1.95611686e-01 9.19138862e-11 9.74268669e-12], sum to 1.0000
[2019-04-24 10:59:48,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1847
[2019-04-24 10:59:48,650] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333333, 49.0, 83.16666666666666, 674.5, 19.0, 24.42733876830789, 0.1082065012082267, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3685200.0000, 
sim time next is 3686400.0000, 
raw observation next is [5.0, 50.0, 75.5, 613.5, 19.0, 23.98493645764415, 0.05055021495897868, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6011080332409973, 0.5, 0.25166666666666665, 0.6779005524861879, 0.08333333333333333, 0.4987447048036791, 0.5168500716529929, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9356668], dtype=float32), 0.24168292]. 
=============================================
[2019-04-24 10:59:48,686] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.333333333333333, 44.66666666666667, 0.0, 0.0, 19.0, 23.45524182067717, -0.1665071849870633, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3619200.0000, 
sim time next is 3620400.0000, 
raw observation next is [-1.666666666666667, 47.33333333333333, 0.0, 0.0, 19.0, 23.16953673421397, -0.08470955816424802, 0.0, 1.0, 55.0, 61.42957756765554], 
processed observation next is [0.0, 0.9130434782608695, 0.4164358264081256, 0.4733333333333333, 0.0, 0.0, 0.08333333333333333, 0.4307947278511642, 0.4717634806119173, 0.0, 1.0, 0.8, 0.6142957756765555], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2603548], dtype=float32), 1.537958]. 
=============================================
[2019-04-24 10:59:48,993] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.6470947e-01 1.9920396e-03 6.8871188e-04 4.2255209e-08 2.5407487e-11
 4.1788475e-09 1.0381474e-10 6.5945712e-04 2.3195024e-01 5.6096837e-12
 4.5520454e-12], sum to 1.0000
[2019-04-24 10:59:48,995] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4488
[2019-04-24 10:59:49,009] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.13362198897827, -0.4412502338769882, 0.0, 1.0, 55.0, 78.8252157122524], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3378000.0000, 
sim time next is 3379200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.63120548599899, -0.5467308054048723, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3026004571665825, 0.3177563981983759, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17932773], dtype=float32), 1.0189027]. 
=============================================
[2019-04-24 10:59:49,227] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.9217321e-01 2.3753128e-04 2.2192606e-04 7.3564523e-09 2.7515188e-12
 1.3616299e-09 6.4377319e-12 6.6615990e-05 2.0730074e-01 5.6016086e-13
 1.3207164e-13], sum to 1.0000
[2019-04-24 10:59:49,228] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5498
[2019-04-24 10:59:49,255] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 24.99500764277271, 0.4594791140296304, 1.0, 1.0, 55.0, 75.65761510524118], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3522000.0000, 
sim time next is 3523200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 25.35056592602545, 0.3531488597957185, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.6125471605021208, 0.6177162865985728, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47403544], dtype=float32), 0.5518934]. 
=============================================
[2019-04-24 10:59:49,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5419042e-01 2.2199906e-03 2.1435986e-03 5.2808780e-08 2.0429771e-12
 2.2904483e-09 1.2104390e-10 4.0033201e-04 3.4104553e-01 5.2606504e-12
 2.6962514e-12], sum to 1.0000
[2019-04-24 10:59:49,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2135
[2019-04-24 10:59:49,441] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.666666666666668, 74.66666666666667, 101.0, 578.5, 22.5, 23.26845454281147, -0.0640274153069531, 1.0, 1.0, 55.0, 75.03887379407885], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3316800.0000, 
sim time next is 3318000.0000, 
raw observation next is [-8.333333333333334, 72.33333333333333, 105.1666666666667, 635.8333333333333, 22.5, 23.74781054512594, -0.1196660476823778, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.23176361957525393, 0.7233333333333333, 0.3505555555555557, 0.7025782688766113, 0.375, 0.47898421209382835, 0.46011131743920736, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16290633], dtype=float32), -0.20324005]. 
=============================================
[2019-04-24 10:59:56,188] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [7.1224385e-01 9.9011569e-04 7.1688660e-04 1.6726311e-08 2.1484912e-12
 6.4935396e-10 4.3473482e-11 2.5423215e-04 2.8579488e-01 4.1848547e-12
 3.9295959e-13], sum to 1.0000
[2019-04-24 10:59:56,189] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.4034
[2019-04-24 10:59:56,216] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 24.75642146576514, 0.2632405463230658, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3528000.0000, 
sim time next is 3529200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 24.22246339942286, 0.1509775819414396, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.5185386166185717, 0.5503258606471465, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29504648], dtype=float32), -3.1521163]. 
=============================================
[2019-04-24 10:59:59,077] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7041411e-01 1.7942035e-03 1.7467240e-03 1.6164115e-07 3.6014186e-10
 1.6050038e-08 2.0378146e-09 8.7425701e-04 2.2517054e-01 3.7647352e-10
 2.8774073e-11], sum to 1.0000
[2019-04-24 10:59:59,077] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0325
[2019-04-24 10:59:59,102] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.666666666666667, 42.66666666666666, 111.5, 811.0, 19.0, 23.03663743144832, -0.1584631515846385, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3678000.0000, 
sim time next is 3679200.0000, 
raw observation next is [6.0, 43.0, 108.5, 797.0, 19.0, 22.86231998261709, -0.1732571527300998, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6288088642659281, 0.43, 0.3616666666666667, 0.8806629834254144, 0.08333333333333333, 0.4051933318847576, 0.44224761575663335, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3918926], dtype=float32), -0.6936193]. 
=============================================
[2019-04-24 10:59:59,749] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9634163e-01 4.5574610e-03 1.2074492e-03 9.6386898e-09 2.3034447e-13
 2.8088731e-09 1.8438528e-11 7.3425188e-05 2.9782006e-01 5.8004876e-13
 4.2215263e-13], sum to 1.0000
[2019-04-24 10:59:59,750] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2117
[2019-04-24 10:59:59,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 77.0, 105.5, 722.0, 22.5, 24.72540363171359, 0.03776950167704019, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3751200.0000, 
sim time next is 3752400.0000, 
raw observation next is [-3.0, 75.0, 109.1666666666667, 753.3333333333334, 22.5, 24.43263071984693, -0.007915551700218043, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.75, 0.363888888888889, 0.8324125230202579, 0.375, 0.5360525599872442, 0.497361482766594, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.38876367], dtype=float32), -1.07827]. 
=============================================
[2019-04-24 11:00:01,788] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.8388615e-01 2.6130229e-03 1.4859312e-03 7.8747448e-08 9.5055604e-12
 6.4122929e-09 1.3805423e-10 4.4597714e-04 4.1156891e-01 1.2506291e-11
 1.9519540e-12], sum to 1.0000
[2019-04-24 11:00:01,789] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9897
[2019-04-24 11:00:01,854] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 75.0, 0.0, 0.0, 19.0, 22.23356476973256, -0.397536853245291, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3810000.0000, 
sim time next is 3811200.0000, 
raw observation next is [-4.0, 73.0, 0.0, 0.0, 19.0, 22.00671571005095, -0.2456707492050289, 0.0, 1.0, 55.0, 84.28427796314844], 
processed observation next is [1.0, 0.08695652173913043, 0.3518005540166205, 0.73, 0.0, 0.0, 0.08333333333333333, 0.33389297583757926, 0.41810975026499037, 0.0, 1.0, 0.8, 0.8428427796314844], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9787341], dtype=float32), -0.12213235]. 
=============================================
[2019-04-24 11:00:03,843] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.0784084e-01 3.7909308e-03 5.6845853e-03 1.5014518e-06 1.8053411e-09
 1.2277789e-07 9.3472341e-09 1.7614986e-03 3.8092050e-01 8.8679092e-10
 1.6216427e-10], sum to 1.0000
[2019-04-24 11:00:03,845] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4382
[2019-04-24 11:00:03,865] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.66666666666667, 67.0, 0.0, 0.0, 19.0, 19.61473010964046, -0.9720986762336477, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3991200.0000, 
sim time next is 3992400.0000, 
raw observation next is [-13.0, 69.0, 0.0, 0.0, 19.0, 19.24612714928519, -1.03799105531151, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.10249307479224376, 0.69, 0.0, 0.0, 0.08333333333333333, 0.10384392910709916, 0.15400298156283002, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8525329], dtype=float32), -0.66143566]. 
=============================================
[2019-04-24 11:00:12,319] A3C_AGENT_WORKER-Thread-8 INFO:Evaluating...
[2019-04-24 11:00:12,332] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 11:00:12,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:12,340] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 11:00:12,340] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:12,369] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 11:00:12,369] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:12,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run17
[2019-04-24 11:00:12,373] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run17
[2019-04-24 11:00:12,440] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run17
[2019-04-24 11:02:32,467] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3016.4190 80463.6403 -2.6354
[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,503] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:32,767] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,773] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 2737.5753 90452.6961 -379.4797
[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:47,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,176] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 2653.0856 94176.9306 -453.2066
[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,196] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:53,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:02:54,198] A3C_AGENT_WORKER-Thread-8 INFO:Global step: 800000, evaluation results [800000.0, 2737.5752508750174, 90452.6960546061, -379.4796828506286, 3016.418984009542, 80463.64027980594, -2.635400951390117, 2653.0855799871647, 94176.93058693329, -453.2065762391182]
[2019-04-24 11:02:55,926] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7482245e-01 3.5191560e-03 4.6110419e-03 5.7860511e-08 3.5426978e-10
 1.7365522e-08 8.4344937e-10 1.0317552e-03 3.1601548e-01 4.2928505e-10
 1.9778944e-11], sum to 1.0000
[2019-04-24 11:02:55,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3185
[2019-04-24 11:02:55,972] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 50.0, 75.5, 613.5, 19.0, 24.11568928493955, 0.05115826516091037, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3686400.0000, 
sim time next is 3687600.0000, 
raw observation next is [4.666666666666667, 53.0, 67.83333333333333, 552.5, 19.0, 23.89909574684567, -0.008309614798938927, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5918744228993538, 0.53, 0.2261111111111111, 0.6104972375690608, 0.08333333333333333, 0.4915913122371392, 0.4972301284003537, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.69814694], dtype=float32), 1.7657043]. 
=============================================
[2019-04-24 11:02:59,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6169872e-01 1.4455396e-03 9.3343650e-04 4.9281326e-08 1.9411783e-11
 2.0733607e-08 1.2589066e-10 1.9327913e-04 2.3572889e-01 2.1480614e-11
 5.0066461e-12], sum to 1.0000
[2019-04-24 11:02:59,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9682
[2019-04-24 11:02:59,828] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2687513e-01 1.8739802e-04 8.9261733e-04 2.8888461e-08 1.1283258e-11
 2.9657683e-09 1.2409294e-10 2.8482772e-04 2.7176005e-01 5.0165800e-12
 9.6104266e-13], sum to 1.0000
[2019-04-24 11:02:59,834] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3275
[2019-04-24 11:02:59,859] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.666666666666667, 28.33333333333334, 120.1666666666667, 836.8333333333334, 22.5, 24.0068915415585, -0.05903316485596365, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4105200.0000, 
sim time next is 4106400.0000, 
raw observation next is [2.333333333333333, 28.66666666666666, 119.3333333333333, 839.1666666666667, 22.5, 24.35073124230453, 0.02511018723306714, 1.0, 1.0, 55.0, 66.00290200973409], 
processed observation next is [1.0, 0.5217391304347826, 0.5272391505078486, 0.2866666666666666, 0.3977777777777777, 0.9272559852670351, 0.375, 0.5292276035253775, 0.5083700624110224, 1.0, 1.0, 0.8, 0.6600290200973409], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5568631], dtype=float32), -0.73540086]. 
=============================================
[2019-04-24 11:02:59,862] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.4, 75.66666666666667, 0.0, 0.0, 19.0, 23.65995946316208, -0.1658781772377415, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4321200.0000, 
sim time next is 4322400.0000, 
raw observation next is [4.3, 75.33333333333334, 0.0, 0.0, 19.0, 22.87466284961861, -0.2957913025988889, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5817174515235458, 0.7533333333333334, 0.0, 0.0, 0.08333333333333333, 0.40622190413488407, 0.4014028991337037, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28445953], dtype=float32), -0.0049678837]. 
=============================================
[2019-04-24 11:03:01,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3443252e-01 1.1065544e-03 7.3991605e-04 1.6859039e-08 4.9666339e-12
 1.6996315e-09 6.3751344e-11 4.5775235e-04 2.6326323e-01 9.3145526e-12
 5.2913603e-13], sum to 1.0000
[2019-04-24 11:03:01,484] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6400
[2019-04-24 11:03:01,502] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 67.0, 0.0, 0.0, 19.0, 23.25739165850514, -0.1067643583950473, 0.0, 1.0, 55.0, 48.856105154238406], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3900000.0000, 
sim time next is 3901200.0000, 
raw observation next is [-2.666666666666667, 69.0, 0.0, 0.0, 19.0, 23.23437478183451, -0.2622731153627116, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.38873499538319484, 0.69, 0.0, 0.0, 0.08333333333333333, 0.4361978984862092, 0.4125756282124295, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5134156], dtype=float32), 0.7233311]. 
=============================================
[2019-04-24 11:03:05,712] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.2345400e-01 1.2956640e-03 1.3282906e-03 3.1594404e-08 1.0727523e-11
 2.3468927e-09 1.5075871e-10 5.9468765e-04 2.7332735e-01 1.0541806e-11
 1.5466964e-12], sum to 1.0000
[2019-04-24 11:03:05,719] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4862
[2019-04-24 11:03:05,737] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 71.0, 0.0, 0.0, 19.0, 21.28150275649871, -0.5323328399078223, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4510800.0000, 
sim time next is 4512000.0000, 
raw observation next is [-0.8666666666666667, 71.0, 0.0, 0.0, 19.0, 21.11745821307256, -0.5734051010514725, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.4385964912280702, 0.71, 0.0, 0.0, 0.08333333333333333, 0.2597881844227133, 0.3088649663161758, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2829142], dtype=float32), 0.19454624]. 
=============================================
[2019-04-24 11:03:12,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.12923884e-01 1.06836588e-03 9.01973341e-04 2.65110742e-08
 1.20057209e-12 2.18725427e-10 1.30063425e-11 8.31093756e-04
 2.84274697e-01 1.74699870e-12 6.05181663e-14], sum to 1.0000
[2019-04-24 11:03:12,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6191
[2019-04-24 11:03:12,458] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.3, 57.0, 99.5, 584.0, 22.5, 23.90406274977728, -0.111336626427042, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4352400.0000, 
sim time next is 4353600.0000, 
raw observation next is [7.533333333333333, 52.00000000000001, 104.5, 646.0, 22.5, 23.71637709148466, -0.1249598424483603, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6712834718374886, 0.52, 0.34833333333333333, 0.7138121546961326, 0.375, 0.4763647576237216, 0.4583467191838799, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.48923305], dtype=float32), 0.25623605]. 
=============================================
[2019-04-24 11:03:17,594] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:17,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:18,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:18,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:18,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run13
[2019-04-24 11:03:19,792] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:19,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:20,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:20,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:20,796] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run13
[2019-04-24 11:03:22,291] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.8667521e-01 2.2914531e-04 7.7775406e-04 2.7117379e-08 2.2160902e-12
 1.4248098e-09 6.3818430e-12 1.3864158e-04 2.1217930e-01 1.4264554e-12
 1.1811191e-12], sum to 1.0000
[2019-04-24 11:03:22,293] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0326
[2019-04-24 11:03:22,302] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 19.0, 24.01859622782119, 0.1579344223943346, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4652400.0000, 
sim time next is 4653600.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 23.85248986182452, 0.1276576132733457, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.48770748848537665, 0.5425525377577819, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58387023], dtype=float32), 0.57890576]. 
=============================================
[2019-04-24 11:03:22,737] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:22,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:23,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:23,444] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:23,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:23,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:23,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run13
[2019-04-24 11:03:24,267] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:24,267] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:24,280] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run13
[2019-04-24 11:03:25,323] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.4860283e-01 8.2346011e-04 1.6669717e-04 2.0884237e-08 3.5265694e-12
 5.7206351e-10 1.9948914e-11 2.0664229e-04 1.5020028e-01 1.5308138e-12
 4.2810056e-13], sum to 1.0000
[2019-04-24 11:03:25,325] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7794
[2019-04-24 11:03:25,338] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 19.0, 23.87584678480302, -0.01379901063029839, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4674000.0000, 
sim time next is 4675200.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 19.0, 23.32254183422284, -0.1024587160820497, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.518005540166205, 0.62, 0.0, 0.0, 0.08333333333333333, 0.44354515285190327, 0.4658470946393168, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.62844235], dtype=float32), 0.5054941]. 
=============================================
[2019-04-24 11:03:26,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9754814e-01 3.1005536e-04 3.8887077e-04 1.2692557e-08 8.2520232e-13
 2.1883367e-10 2.7719073e-12 5.1292453e-05 1.0170170e-01 4.3512904e-13
 2.3337024e-13], sum to 1.0000
[2019-04-24 11:03:26,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5145
[2019-04-24 11:03:26,708] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 76.0, 24.16666666666667, 23.33333333333334, 22.5, 22.97211765745537, -0.221352746579346, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4729200.0000, 
sim time next is 4730400.0000, 
raw observation next is [0.0, 78.0, 0.0, 0.0, 22.5, 22.29104328763726, -0.3028393167592574, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.78, 0.0, 0.0, 0.375, 0.3575869406364385, 0.39905356108024753, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6967345], dtype=float32), -0.5148332]. 
=============================================
[2019-04-24 11:03:27,122] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5277832e-01 1.4312011e-03 7.4562174e-04 3.1786300e-08 1.1701385e-11
 6.2180066e-09 1.4936528e-11 1.6655143e-04 1.4487825e-01 6.0476350e-12
 1.2597282e-12], sum to 1.0000
[2019-04-24 11:03:27,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1478
[2019-04-24 11:03:27,181] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 29.0, 0.0, 0.0, 19.0, 24.64474126094402, 0.1926275687843076, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5000400.0000, 
sim time next is 5001600.0000, 
raw observation next is [3.666666666666667, 31.66666666666667, 0.0, 0.0, 19.0, 24.27402182448184, 0.1291017749186038, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.564173591874423, 0.3166666666666667, 0.0, 0.0, 0.08333333333333333, 0.5228351520401532, 0.543033924972868, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2267463], dtype=float32), 0.1144672]. 
=============================================
[2019-04-24 11:03:27,381] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:27,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:28,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6753035e-01 5.7381851e-04 4.0337883e-04 8.6567224e-09 5.6501375e-12
 1.6077840e-09 3.7308621e-11 1.2097891e-04 1.3137156e-01 1.1121966e-11
 2.8735030e-13], sum to 1.0000
[2019-04-24 11:03:28,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9884
[2019-04-24 11:03:28,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:28,376] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:28,389] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run13
[2019-04-24 11:03:28,455] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [8.2, 30.0, 0.0, 0.0, 19.0, 24.506547345901, 0.1764036586644915, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 5096400.0000, 
sim time next is 5097600.0000, 
raw observation next is [8.1, 35.0, 0.0, 0.0, 19.0, 24.66782221180393, 0.3682604807288305, 0.0, 1.0, 55.0, 71.45196100373238], 
processed observation next is [1.0, 0.0, 0.6869806094182825, 0.35, 0.0, 0.0, 0.08333333333333333, 0.5556518509836609, 0.6227534935762769, 0.0, 1.0, 0.8, 0.7145196100373238], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0686737], dtype=float32), -0.46630844]. 
=============================================
[2019-04-24 11:03:28,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:28,717] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:29,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:29,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:29,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run13
[2019-04-24 11:03:30,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:30,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:30,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:30,930] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:31,082] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:31,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:31,378] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:31,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:31,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:31,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:31,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run13
[2019-04-24 11:03:31,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:31,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:31,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run13
[2019-04-24 11:03:32,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:32,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:32,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run13
[2019-04-24 11:03:32,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:32,368] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:32,372] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run13
[2019-04-24 11:03:32,511] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.9661355e-01 1.1648432e-03 4.2324457e-03 7.9613010e-08 1.7103567e-10
 3.1611926e-08 3.5157754e-10 5.9890066e-04 2.9739019e-01 1.9264382e-10
 6.4916829e-11], sum to 1.0000
[2019-04-24 11:03:32,512] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1950
[2019-04-24 11:03:32,561] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 254.0, 381.0, 19.0, 22.57092935295426, -0.324304730051021, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4888800.0000, 
sim time next is 4890000.0000, 
raw observation next is [2.333333333333333, 44.33333333333334, 242.0, 376.3333333333334, 19.0, 22.20924210197519, -0.3994409401858541, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5272391505078486, 0.4433333333333334, 0.8066666666666666, 0.4158379373848988, 0.08333333333333333, 0.3507701751645991, 0.36685301993804864, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.92368], dtype=float32), -1.3555708]. 
=============================================
[2019-04-24 11:03:32,566] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[57.26817 ]
 [57.67232 ]
 [56.97736 ]
 [57.11007 ]
 [57.399017]
 [56.488   ]
 [56.96747 ]
 [56.042145]
 [56.343018]
 [56.48641 ]
 [56.456562]
 [55.251656]
 [53.782143]
 [53.68387 ]
 [53.704212]
 [53.588   ]
 [52.35245 ]
 [50.931232]
 [49.348125]
 [49.59041 ]
 [49.92133 ]
 [50.403107]
 [50.958736]
 [51.463863]
 [52.081806]], R is [[57.22279739]
 [57.65056992]
 [57.07406616]
 [57.50332642]
 [57.92829514]
 [57.34901428]
 [57.77552414]
 [57.19776917]
 [57.62579346]
 [58.04953766]
 [58.46904373]
 [57.88435364]
 [57.30551147]
 [57.73245621]
 [58.15513229]
 [58.5735817 ]
 [57.98784637]
 [57.40796661]
 [56.83388901]
 [57.26555252]
 [57.6928978 ]
 [58.11597061]
 [58.53481293]
 [58.94946671]
 [59.35997391]].
[2019-04-24 11:03:35,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2535576e-01 6.5481979e-03 7.3153847e-03 7.7198570e-07 1.5566849e-09
 4.7347665e-08 2.3068718e-08 2.5973658e-03 4.5818236e-01 8.2518470e-10
 1.3782568e-10], sum to 1.0000
[2019-04-24 11:03:35,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3168
[2019-04-24 11:03:35,205] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 76.66666666666667, 0.0, 0.0, 19.0, 17.75065040380532, -1.456744756032163, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 182400.0000, 
sim time next is 183600.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 17.4259217387231, -1.504022770901242, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, -0.04783985510640824, -0.0013409236337473078, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.7540226], dtype=float32), 1.0489924]. 
=============================================
[2019-04-24 11:03:35,310] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.3552793e-01 1.5649402e-03 1.2461159e-03 6.9355394e-08 1.7577732e-10
 2.6648108e-08 8.4730084e-10 1.5120001e-03 2.6014891e-01 4.7110819e-11
 5.9400484e-12], sum to 1.0000
[2019-04-24 11:03:35,310] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7926
[2019-04-24 11:03:35,400] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.666666666666667, 52.33333333333334, 0.0, 0.0, 19.0, 21.30455170045729, -0.407309821389261, 0.0, 1.0, 55.0, 83.21416154351404], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 5034000.0000, 
sim time next is 5035200.0000, 
raw observation next is [-2.333333333333333, 58.66666666666666, 0.0, 0.0, 19.0, 22.12106237896864, -0.3155135094092748, 0.0, 1.0, 55.0, 52.28287209030201], 
processed observation next is [1.0, 0.2608695652173913, 0.3979686057248385, 0.5866666666666666, 0.0, 0.0, 0.08333333333333333, 0.34342186491405347, 0.39482883019690834, 0.0, 1.0, 0.8, 0.52282872090302], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39309344], dtype=float32), 0.70646054]. 
=============================================
[2019-04-24 11:03:37,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:37,886] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:38,100] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:38,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:38,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8300742e-01 1.7603907e-03 3.3093691e-03 3.7694377e-08 5.0076089e-12
 3.1380945e-09 3.4972369e-11 1.1558149e-04 3.1180725e-01 3.6474409e-12
 1.2355473e-12], sum to 1.0000
[2019-04-24 11:03:38,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1892
[2019-04-24 11:03:38,482] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 35.0, 0.0, 0.0, 19.0, 24.44902182067934, 0.09714053739293949, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5006400.0000, 
sim time next is 5007600.0000, 
raw observation next is [3.0, 34.0, 0.0, 0.0, 19.0, 23.86818489097753, -0.01422287965703348, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.5457063711911359, 0.34, 0.0, 0.0, 0.08333333333333333, 0.48901540758146095, 0.4952590401143222, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.90024364], dtype=float32), -0.32247937]. 
=============================================
[2019-04-24 11:03:38,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:38,573] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:38,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run13
[2019-04-24 11:03:39,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:39,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:39,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run13
[2019-04-24 11:03:39,523] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:39,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:39,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:39,799] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:39,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.04382 ]
 [68.19768 ]
 [68.51609 ]
 [68.89297 ]
 [68.18389 ]
 [68.23004 ]
 [68.021034]
 [68.24779 ]
 [68.62017 ]
 [67.37537 ]
 [67.75445 ]
 [68.335205]
 [68.690956]
 [69.096954]
 [69.7028  ]
 [69.90392 ]
 [70.36718 ]
 [70.867455]
 [71.43081 ]
 [71.9232  ]
 [71.21898 ]
 [71.2791  ]
 [71.205894]], R is [[ 0.        ]
 [ 1.        ]
 [ 1.99      ]
 [ 2.9701    ]
 [ 2.940399  ]
 [ 3.91099501]
 [ 4.87188506]
 [ 5.82316621]
 [ 6.76493455]
 [ 6.6972852 ]
 [ 7.63031235]
 [ 8.55400923]
 [ 9.46846913]
 [10.37378444]
 [11.2700466 ]
 [12.15734613]
 [13.03577267]
 [13.90541494]
 [14.76636079]
 [15.61869719]
 [15.46251021]
 [16.30788511]
 [17.14480626]].
[2019-04-24 11:03:40,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:40,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:40,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:40,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run13
[2019-04-24 11:03:40,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:40,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:40,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run13
[2019-04-24 11:03:40,682] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:41,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9620713e-01 5.2215910e-04 6.6024694e-04 7.0246653e-09 5.1958932e-12
 1.3266598e-09 1.3955521e-11 2.5952517e-04 2.0235094e-01 1.5526095e-12
 1.8231918e-13], sum to 1.0000
[2019-04-24 11:03:41,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3626
[2019-04-24 11:03:41,234] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.2, 30.0, 0.0, 0.0, 19.0, 24.41989529963636, 0.3479899806822652, 0.0, 1.0, 55.0, 72.7022266108637], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5096400.0000, 
sim time next is 5097600.0000, 
raw observation next is [8.1, 35.0, 0.0, 0.0, 19.0, 25.05024212624486, 0.265383019766823, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6869806094182825, 0.35, 0.0, 0.0, 0.08333333333333333, 0.5875201771870717, 0.588461006588941, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3798335], dtype=float32), -0.7548522]. 
=============================================
[2019-04-24 11:03:41,304] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:03:41,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:41,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:41,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run13
[2019-04-24 11:03:41,587] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:03:42,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:03:42,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:03:42,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run13
[2019-04-24 11:03:48,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6096991e-01 8.5678557e-04 1.4120202e-03 9.6866273e-08 5.1719802e-11
 2.7895128e-09 6.0895072e-10 7.8219775e-04 3.3597901e-01 4.0832265e-11
 5.4176845e-12], sum to 1.0000
[2019-04-24 11:03:48,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4669
[2019-04-24 11:03:48,061] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.1, 70.33333333333333, 0.0, 0.0, 19.0, 19.64509334117455, -0.7694202439447321, 0.0, 1.0, 55.0, 84.48971773239694], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 110400.0000, 
sim time next is 111600.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 19.0, 20.18844448810091, -0.8845585640320874, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.08333333333333333, 0.18237037400840914, 0.20514714532263753, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1888075], dtype=float32), 0.29825497]. 
=============================================
[2019-04-24 11:03:54,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.74045 ]
 [67.7559  ]
 [68.208755]
 [68.59983 ]
 [69.13066 ]
 [69.30112 ]
 [69.0723  ]
 [68.03976 ]
 [68.415016]
 [68.4245  ]
 [68.84859 ]
 [69.36872 ]
 [68.42648 ]
 [68.87418 ]
 [69.70353 ]
 [70.34514 ]
 [71.07659 ]
 [71.48308 ]
 [72.03808 ]
 [72.235214]
 [71.46161 ]
 [71.60966 ]
 [71.89255 ]], R is [[ 1.        ]
 [ 0.99      ]
 [ 1.9801    ]
 [ 2.960299  ]
 [ 3.93069601]
 [ 4.89138905]
 [ 5.84247516]
 [ 5.78405041]
 [ 6.7262099 ]
 [ 7.6589478 ]
 [ 8.58235833]
 [ 9.49653474]
 [ 9.4015694 ]
 [10.3075537 ]
 [11.20447816]
 [12.09243338]
 [12.97150905]
 [13.84179396]
 [14.70337602]
 [15.55634226]
 [15.40077884]
 [16.24677105]
 [17.08430334]].
[2019-04-24 11:03:54,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3385695e-01 4.9993850e-04 1.9614587e-03 1.8751081e-08 6.0417255e-11
 1.2676846e-09 2.0423618e-10 3.1982653e-04 3.6336187e-01 5.6012129e-11
 1.5972920e-12], sum to 1.0000
[2019-04-24 11:03:54,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5388
[2019-04-24 11:03:54,896] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.233333333333333, 83.33333333333334, 23.33333333333333, 0.0, 19.0, 21.91029313795373, -0.4078783550835226, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 58800.0000, 
sim time next is 60000.0000, 
raw observation next is [5.866666666666667, 84.66666666666666, 15.0, 0.0, 19.0, 21.57303229215561, -0.4982638778734769, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6251154201292707, 0.8466666666666666, 0.05, 0.0, 0.08333333333333333, 0.2977526910129675, 0.333912040708841, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.14540702], dtype=float32), 0.071156695]. 
=============================================
[2019-04-24 11:03:54,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.796047]
 [64.43159 ]
 [63.657997]
 [64.43426 ]
 [65.19223 ]
 [65.845276]
 [66.56455 ]
 [67.134964]
 [66.619255]
 [66.0523  ]
 [66.76681 ]
 [67.41473 ]
 [68.07626 ]
 [68.48094 ]
 [67.48729 ]
 [67.66299 ]
 [66.58881 ]
 [67.021996]
 [67.55072 ]
 [67.074844]
 [66.41225 ]
 [65.53591 ]
 [64.601875]
 [63.336437]
 [63.508465]], R is [[63.65091324]
 [64.0144043 ]
 [63.37425995]
 [63.74051666]
 [64.10311127]
 [64.46208191]
 [64.81745911]
 [65.16928864]
 [64.51759338]
 [63.87241745]
 [64.23368835]
 [64.59135437]
 [64.9454422 ]
 [65.29598999]
 [64.64302826]
 [64.99659729]
 [64.34663391]
 [64.70317078]
 [65.05613708]
 [64.40557861]
 [63.7615242 ]
 [63.123909  ]
 [62.49267197]
 [61.86774445]
 [62.24906921]].
[2019-04-24 11:03:55,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2423203e-01 1.8129253e-03 4.4127563e-03 5.5959841e-08 3.5953251e-11
 6.8503132e-09 1.0388036e-09 4.2197065e-04 4.6912020e-01 4.2400545e-11
 2.2914863e-11], sum to 1.0000
[2019-04-24 11:03:55,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9921
[2019-04-24 11:03:55,439] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 19.0, 20.34607681535856, -0.9182448484918951, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 255600.0000, 
sim time next is 256800.0000, 
raw observation next is [-4.1, 81.0, 0.0, 0.0, 19.0, 20.20600408065329, -0.7738295079207299, 0.0, 1.0, 55.0, 79.53147881322903], 
processed observation next is [1.0, 1.0, 0.3490304709141275, 0.81, 0.0, 0.0, 0.08333333333333333, 0.1838336733877742, 0.24205683069309003, 0.0, 1.0, 0.8, 0.7953147881322903], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35394055], dtype=float32), -1.2785125]. 
=============================================
[2019-04-24 11:03:57,904] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.8693955e-01 5.8084214e-03 1.1622445e-03 8.5846909e-07 7.9484458e-10
 1.9033267e-07 6.9103447e-09 1.3359865e-03 5.0475276e-01 2.2934046e-10
 1.4170981e-10], sum to 1.0000
[2019-04-24 11:03:57,905] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5162
[2019-04-24 11:03:57,953] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 19.0, 19.64639389445475, -0.9591751684047892, 0.0, 1.0, 55.0, 80.89731931229542], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 352800.0000, 
sim time next is 354000.0000, 
raw observation next is [-15.0, 69.0, 0.0, 0.0, 19.0, 19.91054298391631, -0.9425227340765172, 0.0, 1.0, 55.0, 58.2578538910596], 
processed observation next is [1.0, 0.08695652173913043, 0.04709141274238226, 0.69, 0.0, 0.0, 0.08333333333333333, 0.15921191532635928, 0.1858257553078276, 0.0, 1.0, 0.8, 0.582578538910596], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8184137], dtype=float32), 0.5504321]. 
=============================================
[2019-04-24 11:04:00,804] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2182200e-01 3.1427888e-03 2.6766264e-03 8.0340448e-07 2.7870006e-10
 5.8931022e-08 3.5579799e-09 5.7912909e-04 3.7177849e-01 1.7965628e-10
 5.1042608e-11], sum to 1.0000
[2019-04-24 11:04:00,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8319
[2019-04-24 11:04:00,870] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.4, 68.0, 0.0, 0.0, 19.0, 19.13716937991187, -0.8542825182086671, 0.0, 1.0, 55.0, 98.80576520352972], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 162000.0000, 
sim time next is 163200.0000, 
raw observation next is [-8.4, 69.0, 0.0, 0.0, 19.0, 20.16667377166981, -0.7628182482992432, 0.0, 1.0, 55.0, 61.2252744615578], 
processed observation next is [1.0, 0.9130434782608695, 0.2299168975069252, 0.69, 0.0, 0.0, 0.08333333333333333, 0.18055614763915084, 0.24572725056691894, 0.0, 1.0, 0.8, 0.612252744615578], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8766465], dtype=float32), -0.31229645]. 
=============================================
[2019-04-24 11:04:03,452] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.1059995e-01 4.5983186e-03 2.0666344e-03 2.9820796e-07 1.5026659e-11
 1.1943581e-08 7.8098150e-10 5.8431568e-04 5.8215046e-01 3.7135055e-11
 1.8622848e-11], sum to 1.0000
[2019-04-24 11:04:03,453] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1667
[2019-04-24 11:04:03,556] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 78.0, 56.5, 148.0, 22.5, 20.65048547839546, -0.941895030869316, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 205200.0000, 
sim time next is 206400.0000, 
raw observation next is [-8.033333333333333, 77.0, 71.50000000000001, 49.33333333333332, 22.5, 20.33243137988952, -0.987726464397122, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24007386888273316, 0.77, 0.23833333333333337, 0.05451197053406997, 0.375, 0.19436928165746004, 0.17075784520095935, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6791931], dtype=float32), 1.1401197]. 
=============================================
[2019-04-24 11:04:04,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4632323e-01 5.2851147e-04 1.0688909e-03 5.8429507e-08 1.1600695e-11
 1.9488915e-09 9.5809569e-11 3.3709267e-04 2.5174227e-01 1.7585202e-11
 8.4823945e-12], sum to 1.0000
[2019-04-24 11:04:04,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4744
[2019-04-24 11:04:04,145] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.766666666666667, 63.0, 143.6666666666667, 0.0, 22.5, 20.61973169850878, -0.8759563441406567, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 222000.0000, 
sim time next is 223200.0000, 
raw observation next is [-3.4, 62.0, 133.0, 0.0, 22.5, 20.4201390437556, -0.8756142010740792, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.368421052631579, 0.62, 0.44333333333333336, 0.0, 0.375, 0.20167825364630007, 0.2081285996419736, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0034, 
noisyNet noise sample is [array([1.0819536], dtype=float32), -1.182837]. 
=============================================
[2019-04-24 11:04:12,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4114778e-01 4.3634174e-04 3.0968271e-04 1.6024405e-08 1.4927728e-12
 3.4410760e-10 7.5124672e-12 4.3980759e-05 1.5806222e-01 1.4830811e-12
 1.9375324e-13], sum to 1.0000
[2019-04-24 11:04:12,367] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5121
[2019-04-24 11:04:12,447] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.9666666666666668, 66.66666666666667, 129.8333333333333, 186.5, 22.5, 23.72513148210773, -0.2961804236127474, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 729600.0000, 
sim time next is 730800.0000, 
raw observation next is [-0.6, 66.0, 111.5, 423.5, 22.5, 23.27693063231008, -0.3575525801995216, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.44598337950138506, 0.66, 0.37166666666666665, 0.46795580110497237, 0.375, 0.43974421935917335, 0.38081580660015946, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4919695], dtype=float32), 2.4735203]. 
=============================================
[2019-04-24 11:04:14,109] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.5591660e-01 3.2187558e-03 7.3294068e-04 3.9148009e-07 2.4994881e-10
 1.1947043e-07 7.3880529e-10 3.1995785e-04 2.3981124e-01 1.4341366e-10
 7.3711308e-11], sum to 1.0000
[2019-04-24 11:04:14,110] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4928
[2019-04-24 11:04:14,177] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 22.5, 21.18229393758018, -0.5222565485100211, 1.0, 1.0, 55.0, 108.91366083486753], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 412800.0000, 
sim time next is 414000.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 22.5, 21.82814411474819, -0.6568384744710253, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.1994459833795014, 0.4, 0.0, 0.0, 0.375, 0.31901200956234926, 0.2810538418429916, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.3850, 
noisyNet noise sample is [array([-0.6435766], dtype=float32), 0.2079192]. 
=============================================
[2019-04-24 11:04:15,426] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.9825417e-01 1.6468649e-03 1.6877612e-03 6.6278325e-08 6.6485832e-12
 1.1239614e-09 7.4274253e-11 4.2568558e-04 2.9798540e-01 7.1733145e-12
 3.4266431e-12], sum to 1.0000
[2019-04-24 11:04:15,427] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1678
[2019-04-24 11:04:15,479] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 67.33333333333334, 132.6666666666667, 64.83333333333334, 22.5, 21.72548632961289, -0.698637515756593, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 728400.0000, 
sim time next is 729600.0000, 
raw observation next is [-0.9666666666666668, 66.66666666666667, 129.8333333333333, 186.5, 22.5, 21.54663793184747, -0.7049949832753125, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.43582640812557716, 0.6666666666666667, 0.4327777777777776, 0.20607734806629835, 0.375, 0.29555316098728923, 0.2650016722415625, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01110731], dtype=float32), -1.7504022]. 
=============================================
[2019-04-24 11:04:15,717] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [5.2783298e-01 2.4283638e-03 3.7564652e-03 2.9884254e-07 3.7164730e-10
 1.3121225e-08 2.9764564e-09 7.8035030e-04 4.6520144e-01 5.9813321e-10
 6.8027299e-11], sum to 1.0000
[2019-04-24 11:04:15,717] A3C_AGENT_WORKER-Thread-8 DEBUG:Softmax action selection sampled number: 0.3676
[2019-04-24 11:04:15,765] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 80.0, 136.1666666666667, 573.6666666666667, 19.0, 20.60745642640646, -0.8110240642391626, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 567600.0000, 
sim time next is 568800.0000, 
raw observation next is [-1.2, 80.0, 132.5, 531.0, 19.0, 20.00321713321448, -0.9221238222596173, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.8, 0.44166666666666665, 0.5867403314917127, 0.08333333333333333, 0.16693476110120672, 0.19262539258012756, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9760179], dtype=float32), 0.8589011]. 
=============================================
[2019-04-24 11:04:24,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3936234e-01 1.7508330e-04 3.6869524e-04 2.0994519e-09 1.0519266e-12
 2.0083370e-10 1.2775480e-11 2.3741249e-04 3.5985643e-01 3.5959419e-13
 1.2690780e-13], sum to 1.0000
[2019-04-24 11:04:24,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8311
[2019-04-24 11:04:24,722] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [8.066666666666666, 83.0, 0.0, 0.0, 19.0, 22.50898382734303, -0.3500543102644515, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 966000.0000, 
sim time next is 967200.0000, 
raw observation next is [8.433333333333334, 83.0, 0.0, 0.0, 19.0, 22.45903821092166, -0.2016084845112875, 0.0, 1.0, 55.0, 65.23339763266776], 
processed observation next is [1.0, 0.17391304347826086, 0.6962142197599263, 0.83, 0.0, 0.0, 0.08333333333333333, 0.3715865175768049, 0.43279717182957084, 0.0, 1.0, 0.8, 0.6523339763266776], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38578668], dtype=float32), -0.3501865]. 
=============================================
[2019-04-24 11:04:26,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.55798602e-01 1.09891058e-03 8.50432087e-04 8.34414706e-08
 1.11401955e-11 3.17689874e-09 8.13180495e-11 2.37679866e-04
 1.42014310e-01 6.72152134e-12 5.54630560e-12], sum to 1.0000
[2019-04-24 11:04:26,462] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0063
[2019-04-24 11:04:26,507] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 70.33333333333334, 0.0, 0.0, 22.5, 22.67273989790082, -0.5187754661935156, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 495600.0000, 
sim time next is 496800.0000, 
raw observation next is [0.5, 84.0, 0.0, 0.0, 22.5, 22.0627330218515, -0.6554624289344616, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.84, 0.0, 0.0, 0.375, 0.3385610851542917, 0.2815125236885128, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.3958, 
noisyNet noise sample is [array([-1.6879431], dtype=float32), 0.35176814]. 
=============================================
[2019-04-24 11:04:33,488] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.6217071e-01 1.3855662e-03 3.1832239e-04 4.0065981e-08 1.6293750e-12
 1.8298421e-09 3.1664723e-11 6.9927155e-05 3.3605537e-01 2.9288809e-12
 5.5593090e-13], sum to 1.0000
[2019-04-24 11:04:33,489] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0409
[2019-04-24 11:04:33,507] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 46.66666666666667, 87.5, 763.1666666666667, 22.5, 23.11241117212175, -0.290758497146627, 1.0, 1.0, 55.0, 66.93461995962507], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 740400.0000, 
sim time next is 741600.0000, 
raw observation next is [0.5, 45.0, 84.5, 743.5, 22.5, 23.25241496436987, -0.2692167448261295, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.4764542936288089, 0.45, 0.2816666666666667, 0.8215469613259668, 0.375, 0.4377012470308224, 0.41026108505795683, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6400568], dtype=float32), -0.072349094]. 
=============================================
[2019-04-24 11:04:41,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.67303765e-01 4.84839635e-04 5.63941896e-04 4.72278616e-09
 1.10079198e-12 1.35648859e-09 1.70583860e-11 2.13146617e-04
 2.31434375e-01 1.05059537e-12 1.04551343e-13], sum to 1.0000
[2019-04-24 11:04:41,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9648
[2019-04-24 11:04:41,363] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [10.86666666666667, 75.0, 0.0, 0.0, 19.0, 22.99860647445455, -0.01759111245776317, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1125600.0000, 
sim time next is 1126800.0000, 
raw observation next is [10.5, 77.0, 0.0, 0.0, 19.0, 23.26199335933828, 0.2185458503899975, 0.0, 1.0, 55.0, 75.55962307287533], 
processed observation next is [0.0, 0.043478260869565216, 0.7534626038781165, 0.77, 0.0, 0.0, 0.08333333333333333, 0.43849944661152335, 0.5728486167966659, 0.0, 1.0, 0.8, 0.7555962307287533], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1373804], dtype=float32), -1.2888379]. 
=============================================
[2019-04-24 11:04:41,947] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.91099727e-01 1.08765620e-04 4.84040997e-04 1.78327275e-09
 5.05415913e-13 1.00366174e-10 2.27610877e-12 9.62123377e-05
 2.08211169e-01 4.51711043e-13 1.31029231e-15], sum to 1.0000
[2019-04-24 11:04:41,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1139
[2019-04-24 11:04:41,955] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.3, 96.0, 0.0, 0.0, 19.0, 23.97102435872458, 0.2438804658746815, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1274400.0000, 
sim time next is 1275600.0000, 
raw observation next is [7.933333333333334, 96.0, 0.0, 0.0, 19.0, 23.70969013089151, 0.1997860525808083, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.6823638042474609, 0.96, 0.0, 0.0, 0.08333333333333333, 0.4758075109076258, 0.5665953508602695, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.33089557], dtype=float32), -1.0077165]. 
=============================================
[2019-04-24 11:04:42,953] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.2847900e-01 4.1430013e-04 7.1957853e-04 2.1837743e-09 1.2820471e-13
 1.5097040e-10 7.9638518e-12 2.2853811e-04 3.7015855e-01 3.5655815e-13
 8.1772439e-14], sum to 1.0000
[2019-04-24 11:04:42,954] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3672
[2019-04-24 11:04:42,980] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 19.0, 22.16559515785251, -0.3170695159254641, 0.0, 1.0, 55.0, 50.01914444670841], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 944400.0000, 
sim time next is 945600.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 19.0, 22.21741213737183, -0.4420525729411835, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6011080332409973, 0.96, 0.0, 0.0, 0.08333333333333333, 0.35145101144765256, 0.3526491423529388, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38825315], dtype=float32), 0.41127622]. 
=============================================
[2019-04-24 11:04:44,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.19501674e-01 1.00292766e-03 2.22363058e-04 2.99117042e-09
 4.38436207e-13 2.82764756e-10 1.35572022e-12 1.05221356e-04
 2.79167801e-01 6.53003584e-14 1.60651742e-14], sum to 1.0000
[2019-04-24 11:04:44,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9130
[2019-04-24 11:04:44,412] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [14.2, 77.33333333333333, 0.0, 0.0, 19.0, 24.07531194921968, 0.08846009705880888, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1046400.0000, 
sim time next is 1047600.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 19.0, 24.02612623070484, 0.242102436902087, 0.0, 1.0, 55.0, 62.435869852097284], 
processed observation next is [1.0, 0.13043478260869565, 0.8614958448753465, 0.77, 0.0, 0.0, 0.08333333333333333, 0.5021771858920699, 0.5807008123006957, 0.0, 1.0, 0.8, 0.6243586985209728], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87387824], dtype=float32), 0.44435474]. 
=============================================
[2019-04-24 11:04:48,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6454762e-01 7.4000156e-04 8.9060552e-05 1.4172719e-09 4.5284038e-14
 2.6475436e-10 3.7908777e-13 3.5388090e-05 3.3458790e-01 3.8313645e-14
 6.1613223e-15], sum to 1.0000
[2019-04-24 11:04:48,363] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7064
[2019-04-24 11:04:48,422] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [7.0, 96.33333333333333, 0.0, 0.0, 19.0, 23.98539061843758, 0.1485483671283143, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1650000.0000, 
sim time next is 1651200.0000, 
raw observation next is [6.8, 96.66666666666666, 0.0, 0.0, 19.0, 24.27261035645925, 0.3816387635945425, 0.0, 1.0, 55.0, 73.73110679267708], 
processed observation next is [1.0, 0.08695652173913043, 0.6509695290858727, 0.9666666666666666, 0.0, 0.0, 0.08333333333333333, 0.5227175297049375, 0.6272129211981808, 0.0, 1.0, 0.8, 0.7373110679267708], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2249951], dtype=float32), -0.40277547]. 
=============================================
[2019-04-24 11:04:49,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5771785e-01 1.0298329e-04 4.5993880e-04 1.8962407e-09 1.0197696e-13
 8.4716012e-11 6.7086153e-13 1.0096263e-04 2.4161829e-01 2.1646579e-13
 2.4897376e-14], sum to 1.0000
[2019-04-24 11:04:49,027] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1155
[2019-04-24 11:04:49,042] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.033333333333333, 94.0, 90.0, 706.6666666666666, 22.5, 23.46753898801229, -0.05944179386139692, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1510800.0000, 
sim time next is 1512000.0000, 
raw observation next is [4.4, 93.0, 94.0, 704.0, 22.5, 23.4791000888729, -0.06388479355575367, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5844875346260389, 0.93, 0.31333333333333335, 0.7779005524861878, 0.375, 0.45659167407274176, 0.4787050688147488, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0587271], dtype=float32), 0.725157]. 
=============================================
[2019-04-24 11:04:49,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5767460e-01 7.0608738e-05 1.9815841e-04 4.0258985e-10 6.9614501e-14
 6.9486960e-12 2.0835682e-13 5.3118943e-05 1.4200361e-01 1.3678917e-14
 2.6983105e-15], sum to 1.0000
[2019-04-24 11:04:49,281] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9568
[2019-04-24 11:04:49,329] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.266666666666667, 79.66666666666667, 97.5, 700.1666666666667, 22.5, 24.58731358336933, 0.3466212355850857, 1.0, 1.0, 55.0, 64.39824620358792], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1514400.0000, 
sim time next is 1515600.0000, 
raw observation next is [7.2, 73.0, 92.5, 700.5, 22.5, 25.41870794096421, 0.4552865515231836, 1.0, 1.0, 55.0, 41.5292117024571], 
processed observation next is [1.0, 0.5652173913043478, 0.662049861495845, 0.73, 0.30833333333333335, 0.7740331491712708, 0.375, 0.6182256617470175, 0.6517621838410612, 1.0, 1.0, 0.8, 0.415292117024571], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6636055], dtype=float32), 0.40451476]. 
=============================================
[2019-04-24 11:04:52,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2723075e-01 2.7074409e-04 9.1161972e-05 1.6893174e-09 3.6048957e-14
 6.9954244e-11 1.7850752e-12 2.6846132e-05 1.7238051e-01 3.4826271e-14
 2.1587529e-14], sum to 1.0000
[2019-04-24 11:04:52,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3592
[2019-04-24 11:04:52,505] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 92.0, 92.5, 0.0, 22.5, 24.29450108187459, 0.08178808855023044, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1333200.0000, 
sim time next is 1334400.0000, 
raw observation next is [0.9000000000000001, 92.0, 106.1666666666667, 0.0, 22.5, 24.0774868089353, 0.04833700757303164, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.48753462603878117, 0.92, 0.353888888888889, 0.0, 0.375, 0.5064572340779417, 0.5161123358576772, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6046659], dtype=float32), -1.5902562]. 
=============================================
[2019-04-24 11:04:58,670] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.7893686e-01 2.4845995e-04 1.2446164e-04 3.6971412e-10 4.5885194e-14
 4.9516523e-11 6.9794263e-13 5.6517198e-05 2.2063373e-01 2.6711203e-14
 3.5661938e-15], sum to 1.0000
[2019-04-24 11:04:58,671] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7547
[2019-04-24 11:04:58,702] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 100.0, 32.5, 0.0, 22.5, 24.21308245387812, 0.08766713381022662, 1.0, 1.0, 55.0, 43.99840990040458], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1501200.0000, 
sim time next is 1502400.0000, 
raw observation next is [1.8, 100.0, 42.16666666666667, 0.0, 22.5, 24.20860456900162, -0.002188236883824787, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.5124653739612189, 1.0, 0.14055555555555557, 0.0, 0.375, 0.5173837140834682, 0.49927058770539173, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11148085], dtype=float32), 0.48857057]. 
=============================================
[2019-04-24 11:04:58,834] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2936306e-01 1.0146473e-03 1.0401210e-03 1.4984549e-07 8.1929311e-11
 1.4269687e-08 5.3597238e-09 1.3449632e-03 3.6723691e-01 2.4134897e-10
 2.7481274e-11], sum to 1.0000
[2019-04-24 11:04:58,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6096
[2019-04-24 11:04:58,862] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.9, 84.33333333333334, 58.5, 0.0, 19.0, 20.81329039418836, -0.4988312766971927, 0.0, 1.0, 55.0, 76.15052570918661], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1761600.0000, 
sim time next is 1762800.0000, 
raw observation next is [-2.1, 85.66666666666667, 70.33333333333334, 0.0, 19.0, 21.12137778861277, -0.6111208709567831, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.404432132963989, 0.8566666666666667, 0.23444444444444448, 0.0, 0.08333333333333333, 0.2601148157177307, 0.2962930430144056, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.64806706], dtype=float32), 0.89657235]. 
=============================================
[2019-04-24 11:04:59,844] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.2144572e-01 2.7222829e-03 1.3508098e-02 9.2329884e-07 3.2035314e-09
 7.0551465e-08 2.5073746e-08 1.1711402e-03 3.6115173e-01 5.1052851e-09
 5.1076687e-10], sum to 1.0000
[2019-04-24 11:04:59,845] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8513
[2019-04-24 11:04:59,920] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 19.0, 18.22239080106612, -1.332263136737869, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1897200.0000, 
sim time next is 1898400.0000, 
raw observation next is [-7.300000000000001, 80.0, 0.0, 0.0, 19.0, 18.40280429078014, -1.095405569535457, 0.0, 1.0, 55.0, 89.70026620571397], 
processed observation next is [0.0, 1.0, 0.26038781163434904, 0.8, 0.0, 0.0, 0.08333333333333333, 0.03356702423167827, 0.13486481015484766, 0.0, 1.0, 0.8, 0.8970026620571397], 
reward next is 0.9021, 
noisyNet noise sample is [array([-0.6572959], dtype=float32), -0.8844002]. 
=============================================
[2019-04-24 11:05:00,876] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.8081094e-01 4.0783114e-03 1.3014776e-02 2.7569098e-07 4.5144199e-10
 1.8011853e-08 9.7501385e-09 8.8253221e-04 5.0121313e-01 4.1157297e-10
 1.1919250e-10], sum to 1.0000
[2019-04-24 11:05:00,878] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5911
[2019-04-24 11:05:00,958] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-9.3, 88.0, 0.0, 0.0, 19.0, 17.03643154259631, -1.590531841475435, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1924800.0000, 
sim time next is 1926000.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 19.0, 17.33621389399613, -1.334399823673934, 0.0, 1.0, 55.0, 90.52372877707208], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.08333333333333333, -0.055315508833655734, 0.05520005877535531, 0.0, 1.0, 0.8, 0.9052372877707208], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39931792], dtype=float32), 1.4638289]. 
=============================================
[2019-04-24 11:05:07,617] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.6133953e-01 3.0390215e-03 3.2549573e-03 8.3992049e-08 2.8694647e-11
 3.4193486e-09 9.6813557e-10 4.9964560e-04 5.3186673e-01 2.4373649e-11
 7.2756527e-12], sum to 1.0000
[2019-04-24 11:05:07,627] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0596
[2019-04-24 11:05:07,664] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 80.0, 0.0, 0.0, 19.0, 20.35234136819558, -0.7754537626355167, 0.0, 1.0, 55.0, 55.91513701446844], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2162400.0000, 
sim time next is 2163600.0000, 
raw observation next is [-7.3, 79.0, 0.0, 0.0, 19.0, 20.51700596787319, -0.9269887431592587, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.26038781163434904, 0.79, 0.0, 0.0, 0.08333333333333333, 0.20975049732276574, 0.1910037522802471, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5928775], dtype=float32), 1.789315]. 
=============================================
[2019-04-24 11:05:08,725] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.7005787e-01 5.1424168e-03 1.1436255e-02 2.6551339e-07 5.9364852e-10
 2.6951682e-08 1.2875861e-08 4.9981597e-04 4.1286331e-01 8.9854185e-10
 1.0275571e-10], sum to 1.0000
[2019-04-24 11:05:08,728] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6741
[2019-04-24 11:05:08,780] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 83.33333333333334, 0.0, 0.0, 19.0, 19.94692716885596, -0.9196819991957533, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1809600.0000, 
sim time next is 1810800.0000, 
raw observation next is [-5.0, 82.0, 0.0, 0.0, 19.0, 19.80401669544788, -0.7751657017491224, 0.0, 1.0, 55.0, 78.28438838469458], 
processed observation next is [0.0, 1.0, 0.32409972299168976, 0.82, 0.0, 0.0, 0.08333333333333333, 0.15033472462065678, 0.24161143275029254, 0.0, 1.0, 0.8, 0.7828438838469458], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5080476], dtype=float32), -1.4682628]. 
=============================================
[2019-04-24 11:05:11,744] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6200576e-01 2.2345164e-03 4.9232552e-03 2.9266635e-08 4.0379148e-11
 2.2797877e-08 2.1207676e-09 3.3254179e-04 4.3050388e-01 7.0049598e-11
 7.6985180e-12], sum to 1.0000
[2019-04-24 11:05:11,744] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5355
[2019-04-24 11:05:11,763] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 75.0, 0.0, 0.0, 19.0, 20.29963499827569, -0.9040745993045239, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2250000.0000, 
sim time next is 2251200.0000, 
raw observation next is [-6.9, 77.33333333333334, 0.0, 0.0, 19.0, 19.62183886219466, -1.005565606387825, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.27146814404432135, 0.7733333333333334, 0.0, 0.0, 0.08333333333333333, 0.13515323851622174, 0.16481146453739162, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6758186], dtype=float32), -0.40740395]. 
=============================================
[2019-04-24 11:05:12,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0932832e-01 2.1119073e-03 1.6048588e-03 6.3370742e-08 9.1735343e-12
 3.6410457e-09 7.1395910e-11 2.4985141e-04 1.8670501e-01 1.3537862e-11
 1.9526813e-12], sum to 1.0000
[2019-04-24 11:05:12,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9258
[2019-04-24 11:05:12,530] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [0.0, 44.0, 89.5, 21.0, 22.5, 23.17319524671699, -0.4259092659637041, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2304000.0000, 
sim time next is 2305200.0000, 
raw observation next is [-0.2, 45.66666666666667, 57.16666666666667, 6.999999999999998, 22.5, 22.89619942230974, -0.1790746496008995, 1.0, 1.0, 55.0, 77.84531917194256], 
processed observation next is [1.0, 0.6956521739130435, 0.4570637119113574, 0.4566666666666667, 0.19055555555555556, 0.007734806629834252, 0.375, 0.40801661852581156, 0.4403084501330335, 1.0, 1.0, 0.8, 0.7784531917194256], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43727148], dtype=float32), -0.3018955]. 
=============================================
[2019-04-24 11:05:14,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.4957142e-01 4.7529957e-04 9.6838665e-04 2.1313657e-08 6.2088208e-12
 2.9932856e-09 5.5915904e-11 9.8925084e-05 3.4888595e-01 2.3316900e-12
 1.8975605e-12], sum to 1.0000
[2019-04-24 11:05:14,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0651
[2019-04-24 11:05:14,560] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 19.0, 22.51434480501349, -0.3906711172003139, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2146800.0000, 
sim time next is 2148000.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 21.89262981001689, -0.5103199197512043, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.3243858175014074, 0.3298933600829319, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29560202], dtype=float32), -0.29677716]. 
=============================================
[2019-04-24 11:05:17,286] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6626725e-01 3.3291578e-03 1.5456662e-02 5.3112080e-07 2.5348903e-09
 7.2467884e-08 3.7048711e-08 1.7729331e-03 4.1317338e-01 5.2169753e-09
 6.0683231e-10], sum to 1.0000
[2019-04-24 11:05:17,288] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3106
[2019-04-24 11:05:17,316] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 45.66666666666667, 66.83333333333334, 51.0, 19.0, 21.01516874597031, -0.6178682043077864, 0.0, 1.0, 20.0, 40.253520555678506], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2392800.0000, 
sim time next is 2394000.0000, 
raw observation next is [-0.6, 45.0, 42.5, 37.0, 19.0, 21.0701539702486, -0.7493010608753069, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.44598337950138506, 0.45, 0.14166666666666666, 0.04088397790055249, 0.08333333333333333, 0.25584616418738343, 0.25023297970823105, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.07788], dtype=float32), 1.2537302]. 
=============================================
[2019-04-24 11:05:35,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.16978824e-01 7.99105875e-03 1.19627835e-02 2.43067075e-06
 1.36280924e-08 8.16808381e-07 7.77365159e-08 1.94338092e-03
 3.61120671e-01 1.01332382e-08 1.76766668e-09], sum to 1.0000
[2019-04-24 11:05:35,745] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0600
[2019-04-24 11:05:35,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 35.66666666666667, 0.0, 0.0, 19.0, 19.95394077910883, -0.9605722983844123, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2496000.0000, 
sim time next is 2497200.0000, 
raw observation next is [-1.2, 34.33333333333334, 0.0, 0.0, 19.0, 19.83856326426931, -0.9897492015914753, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.42936288088642666, 0.34333333333333343, 0.0, 0.0, 0.08333333333333333, 0.1532136053557759, 0.17008359946950824, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4898917], dtype=float32), -1.2669296]. 
=============================================
[2019-04-24 11:05:37,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9694016e-01 1.0353171e-03 4.7089863e-03 4.6779551e-08 1.3443894e-11
 2.6727123e-09 2.9914562e-10 2.8898238e-04 3.9702642e-01 1.2578549e-11
 2.6226987e-12], sum to 1.0000
[2019-04-24 11:05:37,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4677
[2019-04-24 11:05:37,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.666666666666667, 71.0, 0.0, 0.0, 19.0, 21.93650611339893, -0.5400504401073629, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2679600.0000, 
sim time next is 2680800.0000, 
raw observation next is [-8.333333333333334, 70.0, 0.0, 0.0, 19.0, 21.02832256943727, -0.6961085306403184, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.23176361957525393, 0.7, 0.0, 0.0, 0.08333333333333333, 0.25236021411977266, 0.26796382311989386, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1715565], dtype=float32), 0.5020239]. 
=============================================
[2019-04-24 11:05:42,294] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2308214e-01 6.4080432e-03 2.0568334e-03 3.3391890e-07 1.9693465e-10
 8.7470575e-08 2.8441753e-09 1.8798326e-03 4.6657276e-01 2.5210437e-10
 2.5037683e-10], sum to 1.0000
[2019-04-24 11:05:42,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1534
[2019-04-24 11:05:42,308] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.1, 54.33333333333334, 0.0, 0.0, 19.0, 20.20228969912947, -0.8276791731365108, 0.0, 1.0, 55.0, 71.65140815473251], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2522400.0000, 
sim time next is 2523600.0000, 
raw observation next is [-2.3, 57.0, 0.0, 0.0, 19.0, 20.57410153867198, -0.9201661082984248, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.57, 0.0, 0.0, 0.08333333333333333, 0.21450846155599823, 0.19327796390052507, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.00802148], dtype=float32), 2.0846589]. 
=============================================
[2019-04-24 11:05:44,488] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-24 11:05:44,489] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 11:05:44,499] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:05:44,517] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 11:05:44,517] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:05:44,521] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run18
[2019-04-24 11:05:44,519] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run18
[2019-04-24 11:05:44,567] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 11:05:44,567] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:05:44,571] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/5/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run18
