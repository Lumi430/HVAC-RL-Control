Using TensorFlow backend.
[2019-04-16 11:56:33,493] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v3', activation='relu', agent_num=5, check_args_only=False, clip_norm=1.0, debug_log_prob=0.001, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Light-Pit-Train-Repeat-v2', eval_act_func='part4_v4', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=50000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_add_time_to_state=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_r_term_zero=True, is_warm_start=False, job_mode='Train', learning_rate=5e-06, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part4_v2', model_dir='None', model_param=[64, 2], model_type='nn', num_threads=16, output='./Part4-Light-Pit-Train-Repeat-v2-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v8', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=0.75, rwd_p_para=10.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=11, test_env=['Part4-Light-Pit-Test-Repeat-v3', 'Part4-Light-Pit-Test-Repeat-v4'], test_mode='Multiple', train_act_func='part4_v4', train_freq=25, v_loss_frac=0.5, violation_penalty_scl=5.0, weight_initer='glorot_uniform', window_len=10)
[2019-04-16 11:56:33,493] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-16 11:56:33.531052: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-16 11:56:49,454] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-16 11:56:49,455] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Light-Pit-Train-Repeat-v2', 'Part4-Light-Pit-Test-Repeat-v3', 'Part4-Light-Pit-Test-Repeat-v4'] ...
[2019-04-16 11:56:49,470] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation worker starts!
[2019-04-16 11:56:49,479] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation worker starts!
[2019-04-16 11:56:49,487] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation worker starts!
[2019-04-16 11:56:49,487] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:49,487] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-16 11:56:49,559] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:49,560] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run1
[2019-04-16 11:56:50,488] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:50,491] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-16 11:56:50,563] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:50,564] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run1
[2019-04-16 11:56:51,492] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:51,493] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-16 11:56:51,568] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:51,569] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run1
[2019-04-16 11:56:52,494] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:52,495] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-16 11:56:52,567] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:52,568] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run1
[2019-04-16 11:56:53,496] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:53,498] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-16 11:56:53,572] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:53,573] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run1
[2019-04-16 11:56:54,499] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:54,500] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2019-04-16 11:56:54,594] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:54,595] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run1
[2019-04-16 11:56:54,814] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-16 11:56:54,815] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 11:56:54,815] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 11:56:54,815] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:54,815] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 11:56:54,815] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:54,816] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:54,819] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run1
[2019-04-16 11:56:54,819] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run1
[2019-04-16 11:56:54,838] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run1
[2019-04-16 11:56:55,500] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:55,501] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-04-16 11:56:55,607] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:55,609] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run1
[2019-04-16 11:56:56,502] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:56,503] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-16 11:56:56,589] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:56,590] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run1
[2019-04-16 11:56:57,504] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:57,505] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-16 11:56:57,681] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:57,683] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run1
[2019-04-16 11:56:58,506] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:58,507] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-16 11:56:58,609] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:58,611] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run1
[2019-04-16 11:56:59,508] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:56:59,508] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-16 11:56:59,714] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:56:59,716] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run1
[2019-04-16 11:57:00,509] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:57:00,510] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-16 11:57:00,613] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:57:00,615] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run1
[2019-04-16 11:57:01,511] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:57:01,512] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-16 11:57:01,615] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:57:01,617] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run1
[2019-04-16 11:57:02,513] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:57:02,514] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-16 11:57:02,626] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:57:02,628] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run1
[2019-04-16 11:57:03,514] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:57:03,515] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-16 11:57:03,611] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:57:03,613] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run1
[2019-04-16 11:57:04,516] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-16 11:57:04,517] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-16 11:57:04,629] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 11:57:04,631] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run1
[2019-04-16 11:57:36,426] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-16 11:57:36,427] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation this: [-3.600111555333333, 66.34074477, 0.0, 0.0, 22.5, 26.03836890966882, 0.5134472158848841, 0.0, 1.0, 35.0, 30.614288072118]
[2019-04-16 11:57:36,427] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation forecast: []
[2019-04-16 11:57:36,428] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Softmax [0.11629244 0.07261528 0.05243263 0.09028329 0.06694704 0.13123795
 0.03711011 0.16960238 0.10730231 0.06973558 0.08644106], sampled 0.9334506892699318
[2019-04-16 11:58:10,081] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 1476.3309 133218.3479 1193.5033
[2019-04-16 11:58:10,102] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 11:58:10,213] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 11:58:17,586] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 1407.0680 145830.4952 684.5318
[2019-04-16 11:58:17,606] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 11:58:17,711] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 11:58:17,881] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1414.2280 143073.8893 916.6258
[2019-04-16 11:58:17,901] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 11:58:18,015] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 11:58:18,903] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 1414.2280119626146, 143073.88934745622, 916.6257774369352, 1476.330893061029, 133218.3479350751, 1193.503349555236, 1407.0679875129113, 145830.49522032004, 684.5317757843476]
[2019-04-16 11:58:22,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.12069343 0.07198342 0.05132513 0.09138655 0.05042548 0.12647311
 0.03299375 0.18082587 0.12012979 0.0700083  0.08375518], sum to 1.0000
[2019-04-16 11:58:22,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4425
[2019-04-16 11:58:22,746] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [0.3666666666666667, 95.33333333333333, 0.0, 0.0, 19.0, 23.3579894999938, 0.0234280032451583, 0.0, 1.0, 50.0, 53.70249158026907], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 81600.0000, 
sim time next is 82800.0000, 
raw observation next is [0.3, 95.0, 0.0, 0.0, 19.0, 23.4250043408083, 0.01451130989635933, 0.0, 1.0, 40.0, 30.00662215767594], 
processed observation next is [0.0, 1.0, 0.47091412742382277, 0.95, 0.0, 0.0, 0.08333333333333333, 0.45208369506735835, 0.5048371032987865, 0.0, 1.0, 0.5, 0.30006622157675944], 
reward next is 0.3249, 
noisyNet noise sample is [array([-1.2952113], dtype=float32), -0.30705178]. 
=============================================
[2019-04-16 11:58:28,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.11854511 0.06736916 0.05834426 0.08926234 0.06336214 0.12521692
 0.03721201 0.19914077 0.08284874 0.07359938 0.08509918], sum to 1.0000
[2019-04-16 11:58:28,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7306
[2019-04-16 11:58:29,112] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 60.0, 66.16666666666667, 0.0, 22.5, 25.46965862484847, 0.3147573121007609, 1.0, 1.0, 65.0, 62.99136099722292], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 228000.0000, 
sim time next is 229200.0000, 
raw observation next is [-3.2, 61.0, 49.66666666666667, 0.0, 22.5, 25.66729846336583, 0.339285385525099, 1.0, 1.0, 50.0, 45.34492250680398], 
processed observation next is [1.0, 0.6521739130434783, 0.37396121883656513, 0.61, 0.16555555555555557, 0.0, 0.375, 0.6389415386138193, 0.6130951285083663, 1.0, 1.0, 0.7, 0.4534492250680398], 
reward next is 0.0216, 
noisyNet noise sample is [array([1.1727256], dtype=float32), -0.935839]. 
=============================================
[2019-04-16 11:58:30,833] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.12174118 0.07634267 0.05396252 0.09764215 0.04600203 0.13436823
 0.03124281 0.16368824 0.11025811 0.08023016 0.08452191], sum to 1.0000
[2019-04-16 11:58:30,834] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0113
[2019-04-16 11:58:31,016] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.1, 81.0, 0.0, 0.0, 19.0, 23.66300229926776, 0.0009462934225424787, 0.0, 1.0, 60.0, 55.62107960055779], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 256800.0000, 
sim time next is 258000.0000, 
raw observation next is [-4.3, 80.0, 0.0, 0.0, 19.0, 23.46877835019762, -0.1876892554891793, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.34349030470914127, 0.8, 0.0, 0.0, 0.08333333333333333, 0.45573152918313503, 0.4374369148369402, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6629225], dtype=float32), 0.99592793]. 
=============================================
[2019-04-16 11:58:34,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.15203932 0.08597407 0.04374691 0.07479616 0.04245268 0.13721314
 0.02496158 0.2144627  0.0925391  0.05588612 0.07592821], sum to 1.0000
[2019-04-16 11:58:34,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5963
[2019-04-16 11:58:34,231] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-12.8, 72.33333333333334, 0.0, 0.0, 19.0, 21.2165666521877, -0.6098936970983839, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 332400.0000, 
sim time next is 333600.0000, 
raw observation next is [-12.8, 74.66666666666666, 0.0, 0.0, 19.0, 20.92927264054428, -0.4886389386282814, 0.0, 1.0, 50.0, 74.03807941532372], 
processed observation next is [1.0, 0.8695652173913043, 0.1080332409972299, 0.7466666666666666, 0.0, 0.0, 0.08333333333333333, 0.24410605337868999, 0.33712035379057287, 0.0, 1.0, 0.7, 0.7403807941532372], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6062627], dtype=float32), -0.50495577]. 
=============================================
[2019-04-16 11:58:36,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.12184613 0.09130034 0.05047651 0.07652643 0.05572978 0.14496003
 0.03631369 0.19236882 0.07970995 0.05639643 0.09437189], sum to 1.0000
[2019-04-16 11:58:36,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4338
[2019-04-16 11:58:36,591] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-13.76666666666667, 62.0, 68.83333333333334, 734.8333333333333, 22.5, 23.67297276988654, -0.07976983458229003, 1.0, 1.0, 60.0, 75.06431869342317], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 384000.0000, 
sim time next is 385200.0000, 
raw observation next is [-13.4, 60.0, 64.5, 746.5, 22.5, 24.16725268547523, -0.02376820060930335, 1.0, 1.0, 40.0, 48.63573242566761], 
processed observation next is [1.0, 0.4782608695652174, 0.09141274238227146, 0.6, 0.215, 0.8248618784530387, 0.375, 0.5139377237896025, 0.49207726646356553, 1.0, 1.0, 0.5, 0.4863573242566761], 
reward next is 0.1386, 
noisyNet noise sample is [array([0.1681298], dtype=float32), 1.6498175]. 
=============================================
[2019-04-16 11:58:39,144] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.12361345 0.08206544 0.05352448 0.08876964 0.05947516 0.11207595
 0.03458211 0.1909505  0.09891967 0.07917952 0.0768441 ], sum to 1.0000
[2019-04-16 11:58:39,144] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4117
[2019-04-16 11:58:39,284] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-10.6, 47.0, 0.0, 0.0, 19.0, 21.34827690787028, -0.5458259404282183, 0.0, 1.0, 20.0, 29.63665620858458], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 421200.0000, 
sim time next is 422400.0000, 
raw observation next is [-10.6, 47.66666666666667, 0.0, 0.0, 19.0, 21.24226186867207, -0.585020014619817, 0.0, 1.0, 40.0, 28.378593144323318], 
processed observation next is [1.0, 0.9130434782608695, 0.1689750692520776, 0.47666666666666674, 0.0, 0.0, 0.08333333333333333, 0.27018848905600584, 0.304993328460061, 0.0, 1.0, 0.5, 0.28378593144323316], 
reward next is 0.3412, 
noisyNet noise sample is [array([-0.4387487], dtype=float32), 0.14727256]. 
=============================================
[2019-04-16 11:58:41,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.10570507 0.08095887 0.05738299 0.08113938 0.06814113 0.13534813
 0.04030579 0.14454773 0.11440266 0.08122225 0.09084608], sum to 1.0000
[2019-04-16 11:58:41,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8780
[2019-04-16 11:58:42,064] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.433333333333334, 84.66666666666667, 0.0, 0.0, 19.0, 23.34032430640979, -0.06593228689289911, 0.0, 1.0, 20.0, 43.744296398082234], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 530400.0000, 
sim time next is 531600.0000, 
raw observation next is [3.066666666666667, 83.33333333333334, 0.0, 0.0, 19.0, 23.49247529840905, -0.0458633524551286, 0.0, 1.0, 60.0, 52.45508458972619], 
processed observation next is [0.0, 0.13043478260869565, 0.5475530932594646, 0.8333333333333335, 0.0, 0.0, 0.08333333333333333, 0.45770627486742094, 0.48471221584829044, 0.0, 1.0, 0.9, 0.5245508458972619], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1446871], dtype=float32), -1.7722929]. 
=============================================
[2019-04-16 11:58:47,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.12164817 0.07992623 0.05856988 0.10896692 0.05133353 0.13055727
 0.03476912 0.15212594 0.09523281 0.08716451 0.07970559], sum to 1.0000
[2019-04-16 11:58:47,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0115
[2019-04-16 11:58:47,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 74.0, 0.0, 0.0, 19.0, 21.42137592859637, -0.5679676603285283, 0.0, 1.0, 20.0, 48.81090041079281], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 697200.0000, 
sim time next is 698400.0000, 
raw observation next is [-3.4, 75.0, 0.0, 0.0, 19.0, 21.28961341992251, -0.6955433510652348, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.368421052631579, 0.75, 0.0, 0.0, 0.08333333333333333, 0.27413445166020917, 0.2681522163115884, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35799417], dtype=float32), -0.90958273]. 
=============================================
[2019-04-16 11:58:48,509] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.11721261 0.08003413 0.0572293  0.09312021 0.07233663 0.13141747
 0.03820661 0.1392549  0.11041243 0.07271145 0.08806429], sum to 1.0000
[2019-04-16 11:58:48,509] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2300
[2019-04-16 11:58:48,631] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 69.0, 115.6666666666667, 42.5, 19.0, 21.82404324350176, -0.3688027391560704, 0.0, 1.0, 60.0, 65.46063734602689], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 638400.0000, 
sim time next is 639600.0000, 
raw observation next is [-3.899999999999999, 67.0, 129.1666666666667, 42.5, 19.0, 22.16089083387717, -0.3362427558445748, 0.0, 1.0, 25.0, 42.33914553335134], 
processed observation next is [0.0, 0.391304347826087, 0.35457063711911363, 0.67, 0.4305555555555557, 0.04696132596685083, 0.08333333333333333, 0.3467409028230974, 0.3879190813851417, 0.0, 1.0, 0.2, 0.4233914553335134], 
reward next is 0.4266, 
noisyNet noise sample is [array([-0.32769212], dtype=float32), 0.16786008]. 
=============================================
[2019-04-16 11:58:50,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.12642051 0.07833922 0.06024076 0.1052339  0.05545591 0.1157785
 0.03685519 0.15518457 0.10152511 0.07456091 0.09040545], sum to 1.0000
[2019-04-16 11:58:50,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8418
[2019-04-16 11:58:50,743] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.9, 71.0, 0.0, 0.0, 19.0, 21.9238109856076, -0.4077066933440107, 0.0, 1.0, 40.0, 60.53366993844065], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 691200.0000, 
sim time next is 692400.0000, 
raw observation next is [-3.733333333333333, 71.33333333333334, 0.0, 0.0, 19.0, 22.1711205540136, -0.3663119478414383, 0.0, 1.0, 60.0, 53.06830028855088], 
processed observation next is [1.0, 0.0, 0.35918744228993543, 0.7133333333333334, 0.0, 0.0, 0.08333333333333333, 0.34759337950113345, 0.3778960173861872, 0.0, 1.0, 0.9, 0.5306830028855088], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7177362], dtype=float32), -0.78383076]. 
=============================================
[2019-04-16 11:58:53,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.10764806 0.07032177 0.05763505 0.09833606 0.0617029  0.13194945
 0.03403383 0.19377342 0.09061203 0.07654332 0.07744408], sum to 1.0000
[2019-04-16 11:58:53,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3467
[2019-04-16 11:58:53,163] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 55.0, 0.0, 0.0, 22.5, 25.51027815391832, 0.3698311472234204, 1.0, 1.0, 20.0, 38.92947654396886], 
current ob forecast is [], 
actual action is [1, 35.0], 
sim time this is 757200.0000, 
sim time next is 758400.0000, 
raw observation next is [-3.899999999999999, 54.0, 0.0, 0.0, 22.5, 25.28559804576788, 0.3303922013190896, 1.0, 1.0, 35.0, 34.87414198087254], 
processed observation next is [1.0, 0.782608695652174, 0.35457063711911363, 0.54, 0.0, 0.0, 0.375, 0.6071331704806567, 0.6101307337730298, 1.0, 1.0, 0.4, 0.34874141980872536], 
reward next is 0.3513, 
noisyNet noise sample is [array([-0.07104962], dtype=float32), 0.2534075]. 
=============================================
[2019-04-16 11:58:55,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.11572923 0.08071274 0.0569514  0.08308226 0.05272671 0.12564094
 0.03424929 0.20950955 0.10166837 0.06278605 0.07694352], sum to 1.0000
[2019-04-16 11:58:55,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4572
[2019-04-16 11:58:55,298] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.300000000000001, 79.0, 92.33333333333334, 0.0, 22.5, 23.88422343030717, -0.006670703424922139, 1.0, 1.0, 50.0, 39.04948090345154], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 825600.0000, 
sim time next is 826800.0000, 
raw observation next is [-4.1, 79.0, 85.66666666666667, 0.0, 22.5, 23.77058613354079, -0.05571725176370141, 1.0, 1.0, 40.0, 33.04782001820362], 
processed observation next is [1.0, 0.5652173913043478, 0.3490304709141275, 0.79, 0.28555555555555556, 0.0, 0.375, 0.48088217779506576, 0.48142758274543285, 1.0, 1.0, 0.5, 0.3304782001820362], 
reward next is 0.2945, 
noisyNet noise sample is [array([0.17145833], dtype=float32), 0.5396689]. 
=============================================
[2019-04-16 11:59:01,934] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.10573218 0.07684039 0.05807894 0.11146914 0.06187766 0.12215113
 0.03976932 0.154033   0.09795337 0.07816572 0.09392913], sum to 1.0000
[2019-04-16 11:59:01,936] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1438
[2019-04-16 11:59:02,041] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 77.66666666666667, 0.0, 0.0, 19.0, 27.55427600524726, 1.006377163593673, 0.0, 1.0, 30.0, 22.32902002498815], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 1045200.0000, 
sim time next is 1046400.0000, 
raw observation next is [14.2, 77.33333333333333, 0.0, 0.0, 19.0, 27.51899974883595, 0.9985588400882777, 0.0, 1.0, 20.0, 25.504542850312717], 
processed observation next is [1.0, 0.08695652173913043, 0.8559556786703602, 0.7733333333333333, 0.0, 0.0, 0.08333333333333333, 0.7932499790696624, 0.8328529466960926, 0.0, 1.0, 0.1, 0.25504542850312717], 
reward next is 0.6700, 
noisyNet noise sample is [array([-1.1496704], dtype=float32), -0.547437]. 
=============================================
[2019-04-16 11:59:04,340] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.10741679 0.06278869 0.05960436 0.11180113 0.05837597 0.11468925
 0.03959991 0.16206278 0.10456947 0.08117057 0.09792117], sum to 1.0000
[2019-04-16 11:59:04,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9116
[2019-04-16 11:59:04,434] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [18.46666666666667, 64.33333333333334, 88.0, 0.0, 19.0, 28.21230056345067, 1.229419345515823, 0.0, 0.0, 40.0, 16.464148822968433], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1178400.0000, 
sim time next is 1179600.0000, 
raw observation next is [18.63333333333333, 63.66666666666667, 71.5, 0.0, 19.0, 28.21341646241634, 1.238139833327313, 0.0, 0.0, 65.0, 31.65041648737244], 
processed observation next is [0.0, 0.6521739130434783, 0.9787626962142197, 0.6366666666666667, 0.23833333333333334, 0.0, 0.08333333333333333, 0.851118038534695, 0.912713277775771, 0.0, 0.0, 1.0, 0.3165041648737244], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0310043], dtype=float32), 1.4112729]. 
=============================================
[2019-04-16 11:59:05,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.11161663 0.07259196 0.05070845 0.10606696 0.04965043 0.11664227
 0.04376176 0.17355138 0.09683676 0.07941474 0.09915863], sum to 1.0000
[2019-04-16 11:59:05,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2691
[2019-04-16 11:59:05,416] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [16.43333333333334, 76.0, 0.0, 0.0, 19.0, 28.10990460273893, 1.214129355511599, 0.0, 0.0, 50.0, 19.58005824155401], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 1207200.0000, 
sim time next is 1208400.0000, 
raw observation next is [16.26666666666667, 77.0, 0.0, 0.0, 19.0, 28.11189501765428, 1.210214346557505, 0.0, 0.0, 30.0, 19.202949284898676], 
processed observation next is [0.0, 1.0, 0.9132040627885505, 0.77, 0.0, 0.0, 0.08333333333333333, 0.8426579181378567, 0.903404782185835, 0.0, 0.0, 0.3, 0.19202949284898677], 
reward next is 0.5830, 
noisyNet noise sample is [array([-0.5075719], dtype=float32), 1.0491116]. 
=============================================
[2019-04-16 11:59:07,012] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.12513262 0.0609198  0.04703114 0.10393761 0.04983905 0.15966766
 0.03316569 0.15597911 0.10833098 0.07199793 0.08399837], sum to 1.0000
[2019-04-16 11:59:07,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3073
[2019-04-16 11:59:07,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.1014512  0.08777405 0.0574142  0.09305962 0.05903183 0.13577648
 0.03515883 0.15441068 0.12454022 0.072754   0.07862891], sum to 1.0000
[2019-04-16 11:59:07,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0004
[2019-04-16 11:59:07,099] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 26.22065951466444, 0.8064676572559405, 0.0, 1.0, 50.0, 50.263197551314555], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1315200.0000, 
sim time next is 1316400.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 26.18452590106498, 0.7228339257572872, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.6820438250887483, 0.7409446419190958, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3218304], dtype=float32), 3.1644423]. 
=============================================
[2019-04-16 11:59:07,156] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [4.200000000000001, 95.0, 0.0, 0.0, 19.0, 27.34199772258076, 1.063099274649185, 0.0, 1.0, 30.0, 30.90209526974445], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 1297200.0000, 
sim time next is 1298400.0000, 
raw observation next is [4.0, 94.0, 0.0, 0.0, 19.0, 27.33200029347131, 1.043467763309478, 0.0, 1.0, 30.0, 26.956251012390837], 
processed observation next is [1.0, 0.0, 0.5734072022160666, 0.94, 0.0, 0.0, 0.08333333333333333, 0.7776666911226092, 0.847822587769826, 0.0, 1.0, 0.3, 0.26956251012390836], 
reward next is 0.5054, 
noisyNet noise sample is [array([0.03761001], dtype=float32), 1.1725048]. 
=============================================
[2019-04-16 11:59:07,733] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.10374638 0.06389216 0.0618531  0.10935304 0.06474631 0.12726744
 0.04258209 0.143129   0.1049548  0.07875148 0.0997242 ], sum to 1.0000
[2019-04-16 11:59:07,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1443
[2019-04-16 11:59:07,861] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 63.66666666666667, 161.8333333333333, 0.0, 19.0, 28.04853207476739, 1.189453979917199, 0.0, 0.0, 65.0, 21.46239294569267], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 1165200.0000, 
sim time next is 1166400.0000, 
raw observation next is [18.8, 63.0, 165.5, 0.0, 19.0, 28.09251074180175, 1.196955965693183, 0.0, 0.0, 20.0, 17.17658601574556], 
processed observation next is [0.0, 0.5217391304347826, 0.9833795013850417, 0.63, 0.5516666666666666, 0.0, 0.08333333333333333, 0.8410425618168125, 0.8989853218977277, 0.0, 0.0, 0.1, 0.1717658601574556], 
reward next is 0.7532, 
noisyNet noise sample is [array([0.9390263], dtype=float32), -0.40088797]. 
=============================================
[2019-04-16 11:59:11,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.12683436 0.06835822 0.0492872  0.10749179 0.04629255 0.15202965
 0.02484158 0.16764733 0.1077142  0.07042039 0.0790827 ], sum to 1.0000
[2019-04-16 11:59:11,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4828
[2019-04-16 11:59:11,968] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 26.17918619903314, 0.6812528148870948, 0.0, 1.0, 50.0, 31.546391630329623], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 1466400.0000, 
sim time next is 1467600.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 26.08225025084682, 0.6521051041496121, 0.0, 1.0, 40.0, 26.45863010779972], 
processed observation next is [1.0, 1.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.673520854237235, 0.7173683680498707, 0.0, 1.0, 0.5, 0.2645863010779972], 
reward next is 0.3604, 
noisyNet noise sample is [array([0.99716234], dtype=float32), 0.45898876]. 
=============================================
[2019-04-16 11:59:15,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.1072938  0.06271798 0.051027   0.0894395  0.06341158 0.13261478
 0.03793672 0.20534763 0.09412952 0.07221733 0.08386419], sum to 1.0000
[2019-04-16 11:59:15,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2128
[2019-04-16 11:59:15,531] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [10.13333333333333, 59.66666666666667, 213.3333333333333, 222.1666666666667, 22.5, 28.47821702738303, 1.168846998489761, 1.0, 1.0, 45.0, 13.27306602150426], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 1596000.0000, 
sim time next is 1597200.0000, 
raw observation next is [10.86666666666667, 58.33333333333334, 204.8333333333333, 228.1666666666667, 22.5, 28.58720874753142, 1.19384730417305, 1.0, 1.0, 25.0, 11.693441807706085], 
processed observation next is [1.0, 0.4782608695652174, 0.7636195752539245, 0.5833333333333335, 0.6827777777777776, 0.2521178637200737, 0.375, 0.8822673956276184, 0.8979491013910167, 1.0, 1.0, 0.2, 0.11693441807706086], 
reward next is 0.7331, 
noisyNet noise sample is [array([0.6569393], dtype=float32), 0.31600493]. 
=============================================
[2019-04-16 11:59:16,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.10824602 0.08781814 0.0553544  0.10387097 0.0599322  0.12450371
 0.03727887 0.1585448  0.11024477 0.06792918 0.08627701], sum to 1.0000
[2019-04-16 11:59:16,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7561
[2019-04-16 11:59:16,994] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 19.0, 27.47011385330246, 1.004199857622716, 0.0, 1.0, 30.0, 27.789951905450415], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1654800.0000, 
sim time next is 1656000.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 19.0, 27.43344009244031, 1.00734215921809, 0.0, 1.0, 55.0, 33.40945199238024], 
processed observation next is [1.0, 0.17391304347826086, 0.6454293628808865, 0.97, 0.0, 0.0, 0.08333333333333333, 0.7861200077033592, 0.8357807197393633, 0.0, 1.0, 0.8, 0.3340945199238024], 
reward next is 0.0659, 
noisyNet noise sample is [array([-0.37030733], dtype=float32), -0.3498048]. 
=============================================
[2019-04-16 11:59:18,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.14359492 0.06564584 0.0521019  0.09003521 0.05129483 0.1291687
 0.02751028 0.17745544 0.11166212 0.08318192 0.06834895], sum to 1.0000
[2019-04-16 11:59:18,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5425
[2019-04-16 11:59:19,029] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.12475792 0.07233583 0.04516712 0.10215941 0.05717727 0.11642429
 0.03012718 0.20124044 0.10756689 0.05819052 0.08485311], sum to 1.0000
[2019-04-16 11:59:19,032] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5669
[2019-04-16 11:59:19,072] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-2.3, 83.0, 122.5, 0.0, 19.0, 23.33195787265986, 0.01764083053267798, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 45.0], 
sim time this is 1771200.0000, 
sim time next is 1772400.0000, 
raw observation next is [-2.466666666666667, 83.0, 124.8333333333333, 0.0, 19.0, 23.50788899587517, 0.2055877537782255, 0.0, 1.0, 45.0, 70.62045043962577], 
processed observation next is [0.0, 0.5217391304347826, 0.39427516158818104, 0.83, 0.416111111111111, 0.0, 0.08333333333333333, 0.4589907496562642, 0.5685292512594086, 0.0, 1.0, 0.6, 0.7062045043962577], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11440302], dtype=float32), 0.75135857]. 
=============================================
[2019-04-16 11:59:19,074] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.1, 88.0, 96.66666666666667, 0.0, 22.5, 26.90372538447225, 1.016678932124649, 1.0, 1.0, 25.0, 63.79508652339885], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1690800.0000, 
sim time next is 1692000.0000, 
raw observation next is [1.1, 88.0, 90.0, 0.0, 22.5, 27.53326670802385, 1.016115345915741, 1.0, 1.0, 50.0, 25.836522498017615], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.88, 0.3, 0.0, 0.375, 0.7944388923353207, 0.838705115305247, 1.0, 1.0, 0.7, 0.25836522498017617], 
reward next is 0.2166, 
noisyNet noise sample is [array([-2.1020548], dtype=float32), 0.86061084]. 
=============================================
[2019-04-16 11:59:19,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.11881839 0.0805961  0.05078213 0.09081884 0.06593215 0.14061269
 0.03692072 0.14916359 0.11172982 0.07411634 0.08050918], sum to 1.0000
[2019-04-16 11:59:19,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0825
[2019-04-16 11:59:19,404] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 83.0, 122.5, 0.0, 19.0, 25.63305984318919, 0.5225896078303287, 0.0, 1.0, 30.0, 36.71453007521809], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1771200.0000, 
sim time next is 1772400.0000, 
raw observation next is [-2.466666666666667, 83.0, 124.8333333333333, 0.0, 19.0, 25.36905753087395, 0.3565709585101636, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.39427516158818104, 0.83, 0.416111111111111, 0.0, 0.08333333333333333, 0.614088127572829, 0.6188569861700546, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.73464906], dtype=float32), -0.54653895]. 
=============================================
[2019-04-16 11:59:23,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.11352536 0.07746081 0.06101048 0.08414508 0.07070071 0.12351376
 0.04364851 0.14093785 0.11798946 0.0739053  0.09316272], sum to 1.0000
[2019-04-16 11:59:23,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0532
[2019-04-16 11:59:23,196] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 19.0, 22.43310962937472, -0.2749759841823992, 0.0, 1.0, 40.0, 35.006098050099716], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1836000.0000, 
sim time next is 1837200.0000, 
raw observation next is [-6.366666666666667, 78.66666666666667, 0.0, 0.0, 19.0, 22.14982505740956, -0.4346467185811709, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.28624192059095105, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.3458187547841301, 0.355117760472943, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.72411484], dtype=float32), -0.8032304]. 
=============================================
[2019-04-16 11:59:25,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.15194723 0.06961687 0.04471046 0.08439406 0.04835971 0.12594803
 0.03087918 0.18258068 0.1178932  0.06905485 0.07461572], sum to 1.0000
[2019-04-16 11:59:25,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6872
[2019-04-16 11:59:25,897] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.3, 81.0, 0.0, 0.0, 19.0, 21.67993672448877, -0.5305791077032531, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1899600.0000, 
sim time next is 1900800.0000, 
raw observation next is [-7.3, 82.0, 0.0, 0.0, 19.0, 21.45351644411036, -0.4336344356652792, 0.0, 1.0, 50.0, 65.30995253745311], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.82, 0.0, 0.0, 0.08333333333333333, 0.2877930370091966, 0.35545518811157356, 0.0, 1.0, 0.7, 0.6530995253745311], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18172812], dtype=float32), 0.51601374]. 
=============================================
[2019-04-16 11:59:26,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.10314544 0.09121127 0.06676286 0.096171   0.05559957 0.13552819
 0.03872862 0.15387772 0.10537984 0.07213847 0.0814571 ], sum to 1.0000
[2019-04-16 11:59:26,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0831
[2019-04-16 11:59:26,547] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 23.42326821605848, -0.08104377202432679, 0.0, 1.0, 65.0, 59.791755548533814], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2006400.0000, 
sim time next is 2007600.0000, 
raw observation next is [-6.199999999999999, 87.0, 0.0, 0.0, 19.0, 23.23533673302079, -0.2900320835160503, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.4362780610850659, 0.4033226388279832, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9846106], dtype=float32), -1.2600104]. 
=============================================
[2019-04-16 11:59:27,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.1222719  0.0805438  0.04714065 0.09257173 0.05256887 0.12089164
 0.03408127 0.19892597 0.10106573 0.0689424  0.08099607], sum to 1.0000
[2019-04-16 11:59:27,279] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7836
[2019-04-16 11:59:27,321] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.9, 75.0, 17.5, 1.0, 22.5, 24.46484470337247, 0.09840882692667656, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 1962000.0000, 
sim time next is 1963200.0000, 
raw observation next is [-4.266666666666667, 76.33333333333334, 9.166666666666666, 1.666666666666667, 22.5, 24.81124671336293, 0.2363308250758429, 1.0, 1.0, 55.0, 63.82069439142574], 
processed observation next is [1.0, 0.7391304347826086, 0.3444136657433057, 0.7633333333333334, 0.030555555555555555, 0.0018416206261510132, 0.375, 0.5676038927802441, 0.5787769416919476, 1.0, 1.0, 0.8, 0.6382069439142574], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1457149], dtype=float32), -0.5640923]. 
=============================================
[2019-04-16 11:59:33,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.12024969 0.07187035 0.05578952 0.07823659 0.059658   0.12520447
 0.03470732 0.2218199  0.09085786 0.05814851 0.08345778], sum to 1.0000
[2019-04-16 11:59:33,218] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5692
[2019-04-16 11:59:33,278] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 75.0, 151.5, 0.0, 22.5, 25.04081562166585, 0.1884127812808104, 1.0, 1.0, 65.0, 67.86627892968386], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2030400.0000, 
sim time next is 2031600.0000, 
raw observation next is [-4.5, 76.33333333333334, 154.5, 0.0, 22.5, 24.79803053731344, 0.2261425768893822, 1.0, 1.0, 50.0, 46.50458971260206], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.7633333333333334, 0.515, 0.0, 0.375, 0.56650254477612, 0.5753808589631274, 1.0, 1.0, 0.7, 0.4650458971260206], 
reward next is 0.0100, 
noisyNet noise sample is [array([1.7963469], dtype=float32), 2.226569]. 
=============================================
[2019-04-16 11:59:34,744] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.11518174 0.0769536  0.06280684 0.10973766 0.04522181 0.13476214
 0.02928857 0.16509473 0.1057859  0.0789668  0.07620025], sum to 1.0000
[2019-04-16 11:59:34,744] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9403
[2019-04-16 11:59:34,784] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-7.3, 82.0, 0.0, 0.0, 19.0, 23.5381983417625, 0.04050254566166862, 0.0, 1.0, 65.0, 69.39620273557827], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2158800.0000, 
sim time next is 2160000.0000, 
raw observation next is [-7.3, 82.0, 0.0, 0.0, 19.0, 23.71171907372462, 0.109445514018158, 0.0, 1.0, 65.0, 66.61164392948817], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.82, 0.0, 0.0, 0.08333333333333333, 0.4759765894770516, 0.5364818380060526, 0.0, 1.0, 1.0, 0.6661164392948816], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0082015], dtype=float32), -1.0312694]. 
=============================================
[2019-04-16 11:59:34,803] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[0.5369142 ]
 [0.5314157 ]
 [0.53214866]
 [0.5201818 ]
 [0.557063  ]
 [0.51697624]
 [0.6072483 ]
 [0.4867955 ]
 [0.46924022]
 [0.54247403]
 [0.4578134 ]
 [0.48023418]
 [0.37835345]
 [0.51459014]
 [0.44546416]
 [0.47874403]
 [0.42213115]
 [0.39008877]
 [0.49008754]
 [0.43222642]
 [0.4486961 ]
 [0.408038  ]
 [0.44405618]
 [0.49066597]
 [0.41466606]], R is [[0.5250597 ]
 [0.51980913]
 [0.60971326]
 [0.69561154]
 [1.13387609]
 [1.12253737]
 [1.45451403]
 [1.75286114]
 [2.08215141]
 [2.06132984]
 [2.47633266]
 [2.9068315 ]
 [2.87776327]
 [3.17311049]
 [3.14137936]
 [4.10996532]
 [4.06886578]
 [5.02817726]
 [4.97789574]
 [4.9281168 ]
 [4.87883568]
 [4.83004713]
 [5.78174686]
 [5.77882671]
 [6.72103834]].
[2019-04-16 11:59:35,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.12419666 0.07796181 0.05887216 0.09175865 0.05706527 0.12908623
 0.0409368  0.1688996  0.09911926 0.0642314  0.08787211], sum to 1.0000
[2019-04-16 11:59:35,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3356
[2019-04-16 11:59:35,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-5.6, 75.0, 51.16666666666667, 293.5, 22.5, 24.41978783441585, 0.1097957763374561, 1.0, 1.0, 50.0, 41.91405633023868], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 2191200.0000, 
sim time next is 2192400.0000, 
raw observation next is [-5.6, 75.0, 71.5, 356.5, 22.5, 24.60415397086187, 0.127908869641387, 1.0, 1.0, 30.0, 35.546126588684544], 
processed observation next is [1.0, 0.391304347826087, 0.30747922437673136, 0.75, 0.23833333333333334, 0.3939226519337017, 0.375, 0.5503461642384891, 0.5426362898804623, 1.0, 1.0, 0.3, 0.35546126588684546], 
reward next is 0.4195, 
noisyNet noise sample is [array([-0.37347358], dtype=float32), 0.7031851]. 
=============================================
[2019-04-16 11:59:40,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.13771908 0.08168599 0.05280545 0.08488198 0.04303388 0.12148374
 0.03322652 0.19412157 0.10326736 0.06337836 0.08439606], sum to 1.0000
[2019-04-16 11:59:40,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1309
[2019-04-16 11:59:40,363] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 55.33333333333334, 0.0, 0.0, 19.0, 24.40774139647124, 0.2328362934003185, 0.0, 1.0, 50.0, 33.44011824282949], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2319600.0000, 
sim time next is 2320800.0000, 
raw observation next is [-1.7, 54.66666666666667, 0.0, 0.0, 19.0, 24.22899620474722, 0.09823276475313951, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4155124653739613, 0.5466666666666667, 0.0, 0.0, 0.08333333333333333, 0.5190830170622682, 0.5327442549177132, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.57980114], dtype=float32), -2.2196584]. 
=============================================
[2019-04-16 11:59:45,777] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.13188623 0.07395778 0.05409409 0.08954666 0.06170661 0.11002824
 0.03838335 0.18891388 0.09157902 0.08041038 0.07949378], sum to 1.0000
[2019-04-16 11:59:45,777] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6539
[2019-04-16 11:59:45,805] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.2, 49.0, 134.5, 39.0, 22.5, 24.7962514078282, 0.08944065189502044, 1.0, 1.0, 30.0, 27.45161722062368], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2541600.0000, 
sim time next is 2542800.0000, 
raw observation next is [-1.0, 48.33333333333334, 133.5, 43.0, 22.5, 24.82207376984824, 0.109123617536753, 1.0, 1.0, 50.0, 35.8510315229415], 
processed observation next is [1.0, 0.43478260869565216, 0.4349030470914128, 0.48333333333333345, 0.445, 0.04751381215469613, 0.375, 0.5685061474873535, 0.5363745391789176, 1.0, 1.0, 0.7, 0.35851031522941496], 
reward next is 0.1165, 
noisyNet noise sample is [array([-1.2415962], dtype=float32), 0.08448724]. 
=============================================
[2019-04-16 11:59:55,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.13595198 0.08006681 0.04644004 0.08879764 0.0493494  0.14037533
 0.02473794 0.18288016 0.10607802 0.07239257 0.07293005], sum to 1.0000
[2019-04-16 11:59:55,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3901
[2019-04-16 11:59:55,144] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 24.44954256732468, 0.06103323392973988, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 35.0], 
sim time this is 2761200.0000, 
sim time next is 2762400.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 23.69594218618109, 0.0895563851966525, 0.0, 1.0, 35.0, 56.13978833435162], 
processed observation next is [1.0, 1.0, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.47466184884842405, 0.5298521283988842, 0.0, 1.0, 0.4, 0.5613978833435163], 
reward next is 0.1386, 
noisyNet noise sample is [array([-0.67919403], dtype=float32), -0.8592303]. 
=============================================
[2019-04-16 12:00:00,153] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 38916: loss 331.9580
[2019-04-16 12:00:00,206] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 38916: learning rate 0.0000
[2019-04-16 12:00:00,360] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 38992: loss 219.2090
[2019-04-16 12:00:00,362] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 38993: learning rate 0.0000
[2019-04-16 12:00:00,571] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39075: loss 366.1175
[2019-04-16 12:00:00,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39075: learning rate 0.0000
[2019-04-16 12:00:01,280] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 39375: loss 315.4356
[2019-04-16 12:00:01,281] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 2500, global step 39375: learning rate 0.0000
[2019-04-16 12:00:01,352] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39403: loss 299.1359
[2019-04-16 12:00:01,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39404: learning rate 0.0000
[2019-04-16 12:00:01,388] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39421: loss 395.6835
[2019-04-16 12:00:01,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39421: learning rate 0.0000
[2019-04-16 12:00:01,971] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39677: loss 500.2836
[2019-04-16 12:00:01,971] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39677: learning rate 0.0000
[2019-04-16 12:00:02,462] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39897: loss 425.7933
[2019-04-16 12:00:02,474] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39901: learning rate 0.0000
[2019-04-16 12:00:02,533] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39931: loss 380.0783
[2019-04-16 12:00:02,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39931: learning rate 0.0000
[2019-04-16 12:00:02,615] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39967: loss 518.2275
[2019-04-16 12:00:02,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39967: learning rate 0.0000
[2019-04-16 12:00:02,778] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 40046: loss 157.7160
[2019-04-16 12:00:02,779] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 40046: learning rate 0.0000
[2019-04-16 12:00:03,547] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40402: loss 363.3026
[2019-04-16 12:00:03,548] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40402: learning rate 0.0000
[2019-04-16 12:00:03,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.13216224 0.08775415 0.05472284 0.08289441 0.06678768 0.12076171
 0.0408109  0.138371   0.11322411 0.07482985 0.08768106], sum to 1.0000
[2019-04-16 12:00:03,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5562
[2019-04-16 12:00:04,015] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 6, 
current raw observation is [-6.0, 68.33333333333333, 14.66666666666666, 118.1666666666667, 19.0, 22.57727692503632, -0.26555444783364, 0.0, 1.0, 50.0, 39.60066693563367], 
current ob forecast is [], 
actual action is [1, 45.0], 
sim time this is 3051600.0000, 
sim time next is 3052800.0000, 
raw observation next is [-6.0, 64.0, 42.0, 214.5, 19.0, 22.56595443050475, -0.2602634919266609, 0.0, 1.0, 45.0, 32.013713028639266], 
processed observation next is [0.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.14, 0.23701657458563535, 0.08333333333333333, 0.38049620254206246, 0.41324550269111304, 0.0, 1.0, 0.6, 0.3201371302863927], 
reward next is 0.2299, 
noisyNet noise sample is [array([-1.1141741], dtype=float32), -0.3892329]. 
=============================================
[2019-04-16 12:00:04,355] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40772: loss 294.4287
[2019-04-16 12:00:04,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40772: learning rate 0.0000
[2019-04-16 12:00:04,786] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.16415454 0.07381223 0.03581817 0.06464266 0.05601345 0.13645612
 0.02353698 0.1892288  0.10536215 0.07228667 0.07868823], sum to 1.0000
[2019-04-16 12:00:04,787] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9542
[2019-04-16 12:00:04,834] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-2.333333333333333, 61.66666666666667, 108.5, 791.8333333333334, 19.0, 24.57103307574331, 0.2836090576392052, 0.0, 1.0, 50.0, 36.618518792976985], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2986800.0000, 
sim time next is 2988000.0000, 
raw observation next is [-2.0, 60.0, 105.5, 775.5, 19.0, 24.58761974827457, 0.3562442477282794, 0.0, 1.0, 65.0, 62.36632095599215], 
processed observation next is [0.0, 0.6086956521739131, 0.40720221606648205, 0.6, 0.3516666666666667, 0.8569060773480663, 0.08333333333333333, 0.5489683123562141, 0.6187480825760932, 0.0, 1.0, 1.0, 0.6236632095599215], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0880343], dtype=float32), 1.2593268]. 
=============================================
[2019-04-16 12:00:05,203] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.15156804 0.07385509 0.03170076 0.0630618  0.03864703 0.12417925
 0.0222602  0.28730378 0.0892143  0.05086766 0.06734221], sum to 1.0000
[2019-04-16 12:00:05,204] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0717
[2019-04-16 12:00:05,222] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 41166: loss 186.6147
[2019-04-16 12:00:05,222] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 41166: learning rate 0.0000
[2019-04-16 12:00:05,230] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.866666666666667, 99.66666666666667, 86.83333333333333, 693.0, 22.5, 28.36632126472985, 1.067212766075875, 1.0, 1.0, 35.0, 40.51301960107792], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3165600.0000, 
sim time next is 3166800.0000, 
raw observation next is [6.733333333333333, 99.33333333333334, 79.66666666666666, 649.0, 22.5, 27.12621107585593, 1.058842439408199, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.649122807017544, 0.9933333333333334, 0.26555555555555554, 0.7171270718232045, 0.375, 0.7605175896546609, 0.852947479802733, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9384633], dtype=float32), -0.35585412]. 
=============================================
[2019-04-16 12:00:05,412] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 41258: loss 271.1997
[2019-04-16 12:00:05,414] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 41258: learning rate 0.0000
[2019-04-16 12:00:07,162] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 42061: loss 438.2553
[2019-04-16 12:00:07,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 42061: learning rate 0.0000
[2019-04-16 12:00:11,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.11544082 0.0910878  0.07422573 0.08990402 0.05989123 0.12249926
 0.03930198 0.1399639  0.11794363 0.07838263 0.07135898], sum to 1.0000
[2019-04-16 12:00:11,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8271
[2019-04-16 12:00:11,189] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-8.3, 77.0, 0.0, 0.0, 19.0, 24.08651672690187, 0.2164579745227328, 0.0, 1.0, 35.0, 44.27368068479797], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3295200.0000, 
sim time next is 3296400.0000, 
raw observation next is [-8.600000000000001, 77.0, 0.0, 0.0, 19.0, 24.1173013362755, 0.2477489166158718, 0.0, 1.0, 55.0, 55.08283967769568], 
processed observation next is [1.0, 0.13043478260869565, 0.22437673130193903, 0.77, 0.0, 0.0, 0.08333333333333333, 0.5097751113562916, 0.5825829722052905, 0.0, 1.0, 0.8, 0.5508283967769568], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6012042], dtype=float32), -0.07546186]. 
=============================================
[2019-04-16 12:00:15,687] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.15114379 0.07343485 0.03884023 0.06806653 0.03722296 0.12158614
 0.01979617 0.27119327 0.09566994 0.06186622 0.06117986], sum to 1.0000
[2019-04-16 12:00:15,688] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3841
[2019-04-16 12:00:15,742] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.333333333333333, 75.0, 0.0, 0.0, 22.5, 25.6862694069042, 0.5783125777883235, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 3436800.0000, 
sim time next is 3438000.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 22.5, 26.1046289729537, 0.7477296482144511, 1.0, 1.0, 40.0, 56.660030409313606], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.79, 0.0, 0.0, 0.375, 0.6753857477461418, 0.7492432160714837, 1.0, 1.0, 0.5, 0.5666003040931361], 
reward next is 0.0584, 
noisyNet noise sample is [array([1.7290012], dtype=float32), 1.0565426]. 
=============================================
[2019-04-16 12:00:16,171] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.15129726 0.06832598 0.04707431 0.09370635 0.03202634 0.13227761
 0.02575637 0.20150495 0.10807469 0.06557842 0.07437778], sum to 1.0000
[2019-04-16 12:00:16,171] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4076
[2019-04-16 12:00:16,217] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 26.10386418674536, 0.6350335727615092, 0.0, 1.0, 50.0, 35.91583225133623], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 3362400.0000, 
sim time next is 3363600.0000, 
raw observation next is [-4.333333333333334, 67.0, 0.0, 0.0, 19.0, 26.10844745536939, 0.5693789482424576, 0.0, 1.0, 40.0, 38.34947231406977], 
processed observation next is [1.0, 0.9565217391304348, 0.3425669436749769, 0.67, 0.0, 0.0, 0.08333333333333333, 0.6757039546141158, 0.6897929827474858, 0.0, 1.0, 0.5, 0.3834947231406977], 
reward next is 0.2415, 
noisyNet noise sample is [array([-1.5654873], dtype=float32), 1.2915009]. 
=============================================
[2019-04-16 12:00:16,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.1495789  0.0765295  0.04831862 0.09955568 0.03916544 0.11750578
 0.02601729 0.19424272 0.1113456  0.06838051 0.06935992], sum to 1.0000
[2019-04-16 12:00:16,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6100
[2019-04-16 12:00:16,487] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 26.43649305709883, 0.6874424211309944, 0.0, 1.0, 55.0, 44.35357514594534], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3451200.0000, 
sim time next is 3452400.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 26.38911506301055, 0.668395660946364, 0.0, 1.0, 50.0, 34.0784962039389], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.6990929219175458, 0.7227985536487881, 0.0, 1.0, 0.7, 0.34078496203938896], 
reward next is 0.1342, 
noisyNet noise sample is [array([-0.6251483], dtype=float32), 1.2114389]. 
=============================================
[2019-04-16 12:00:16,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.17015108 0.08359934 0.04134194 0.08426481 0.03307049 0.11609443
 0.02398674 0.19163574 0.11074328 0.0715936  0.07351844], sum to 1.0000
[2019-04-16 12:00:16,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9322
[2019-04-16 12:00:16,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 19.0, 24.49303904527192, 0.216691838513006, 0.0, 1.0, 20.0, 22.107633690951015], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3366000.0000, 
sim time next is 3367200.0000, 
raw observation next is [-5.333333333333334, 73.0, 0.0, 0.0, 19.0, 24.26026864936127, 0.2185816750002779, 0.0, 1.0, 65.0, 58.34818661267081], 
processed observation next is [1.0, 1.0, 0.31486611265004616, 0.73, 0.0, 0.0, 0.08333333333333333, 0.521689054113439, 0.572860558333426, 0.0, 1.0, 1.0, 0.583481866126708], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37441596], dtype=float32), 0.81010824]. 
=============================================
[2019-04-16 12:00:18,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.1357977  0.08782078 0.04674408 0.0948495  0.03341545 0.11982211
 0.02636496 0.2165445  0.10677069 0.06890124 0.06296901], sum to 1.0000
[2019-04-16 12:00:18,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8041
[2019-04-16 12:00:18,495] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [1.0, 81.33333333333334, 0.0, 0.0, 19.0, 26.6263777475155, 0.7821731659014741, 0.0, 1.0, 55.0, 40.00167574528], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3446400.0000, 
sim time next is 3447600.0000, 
raw observation next is [1.0, 83.66666666666666, 0.0, 0.0, 19.0, 26.67637072083864, 0.7862234465298736, 0.0, 1.0, 55.0, 40.43913340226575], 
processed observation next is [1.0, 0.9130434782608695, 0.4903047091412743, 0.8366666666666666, 0.0, 0.0, 0.08333333333333333, 0.72303089340322, 0.7620744821766245, 0.0, 1.0, 0.8, 0.40439133402265753], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7232764], dtype=float32), -0.3126671]. 
=============================================
[2019-04-16 12:00:19,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.15372606 0.08251487 0.05026652 0.07664278 0.05900032 0.11794219
 0.03461913 0.15519121 0.12486866 0.07176968 0.07345863], sum to 1.0000
[2019-04-16 12:00:19,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9730
[2019-04-16 12:00:19,400] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-6.666666666666666, 70.0, 17.16666666666666, 171.6666666666667, 19.0, 24.46835156015875, 0.2722452412272631, 0.0, 1.0, 50.0, 38.791416676784635], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 3570000.0000, 
sim time next is 3571200.0000, 
raw observation next is [-7.0, 70.0, 45.5, 273.0, 19.0, 24.4649016156881, 0.3464935989157052, 0.0, 1.0, 65.0, 66.04237204517307], 
processed observation next is [0.0, 0.34782608695652173, 0.2686980609418283, 0.7, 0.15166666666666667, 0.30165745856353593, 0.08333333333333333, 0.5387418013073416, 0.6154978663052351, 0.0, 1.0, 1.0, 0.6604237204517307], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9420776], dtype=float32), -0.8552047]. 
=============================================
[2019-04-16 12:00:22,718] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.13262723 0.07738576 0.05351371 0.09411802 0.05889317 0.12675734
 0.02953875 0.15836135 0.08593563 0.10080634 0.08206264], sum to 1.0000
[2019-04-16 12:00:22,718] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7859
[2019-04-16 12:00:22,743] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [8.0, 32.0, 46.5, 262.0, 19.0, 26.81522419348054, 0.6786655350634233, 0.0, 1.0, 60.0, 37.23324790583402], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3657600.0000, 
sim time next is 3658800.0000, 
raw observation next is [9.0, 30.0, 74.83333333333334, 356.0000000000001, 19.0, 26.88731138156649, 0.7018702935782152, 0.0, 1.0, 55.0, 30.149099092307335], 
processed observation next is [0.0, 0.34782608695652173, 0.7119113573407203, 0.3, 0.24944444444444447, 0.3933701657458565, 0.08333333333333333, 0.7406092817972075, 0.7339567645260717, 0.0, 1.0, 0.8, 0.30149099092307335], 
reward next is 0.0985, 
noisyNet noise sample is [array([0.97721744], dtype=float32), -0.07067781]. 
=============================================
[2019-04-16 12:00:23,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.19949019 0.08235353 0.03545528 0.06101846 0.0377221  0.12698264
 0.01710003 0.1964093  0.11277355 0.07795614 0.05273874], sum to 1.0000
[2019-04-16 12:00:23,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0143
[2019-04-16 12:00:23,523] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.333333333333334, 56.0, 55.83333333333334, 462.5, 19.0, 27.79965109245533, 1.00810865763403, 0.0, 1.0, 50.0, 27.88510325631829], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3688800.0000, 
sim time next is 3690000.0000, 
raw observation next is [4.0, 59.0, 39.5, 343.5, 19.0, 27.75223924625711, 0.9231091150642321, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5734072022160666, 0.59, 0.13166666666666665, 0.37955801104972375, 0.08333333333333333, 0.812686603854759, 0.807703038354744, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5619568], dtype=float32), 0.943962]. 
=============================================
[2019-04-16 12:00:23,531] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[0.8935199 ]
 [0.9399129 ]
 [0.84387314]
 [0.86895657]
 [0.86075056]
 [0.85473526]
 [0.8966187 ]
 [0.7589083 ]
 [0.80662143]
 [0.8335625 ]
 [0.8344941 ]
 [0.82636476]
 [0.7333244 ]
 [0.8114979 ]
 [0.82651937]
 [0.8086486 ]
 [0.79298913]
 [0.78620946]
 [0.8403244 ]
 [0.73470855]
 [0.74141467]
 [0.700027  ]
 [0.7220999 ]
 [0.74031365]
 [0.6684884 ]], R is [[ 1.84305847]
 [ 2.02077675]
 [ 2.58348703]
 [ 3.28279114]
 [ 3.6584394 ]
 [ 4.33927393]
 [ 4.76917791]
 [ 5.44007492]
 [ 5.65446472]
 [ 5.59791994]
 [ 6.54194069]
 [ 6.91363049]
 [ 7.33991385]
 [ 7.74775696]
 [ 7.71508837]
 [ 8.63793755]
 [ 9.55155849]
 [ 9.69788361]
 [10.09248829]
 [10.68981266]
 [11.10992336]
 [11.09019661]
 [11.67387962]
 [11.92731285]
 [12.01500416]].
[2019-04-16 12:00:23,886] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.19187817 0.07555355 0.03356346 0.0518221  0.04927768 0.13703825
 0.01534515 0.20132887 0.09817082 0.08729842 0.05872355], sum to 1.0000
[2019-04-16 12:00:23,887] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8962
[2019-04-16 12:00:23,915] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 19.0, 26.71220275577797, 0.707853951552865, 0.0, 1.0, 20.0, 33.98704508401843], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3607200.0000, 
sim time next is 3608400.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 19.0, 26.77458630213287, 0.7051680538420753, 0.0, 1.0, 60.0, 40.29200179777228], 
processed observation next is [0.0, 0.782608695652174, 0.4349030470914128, 0.42, 0.0, 0.0, 0.08333333333333333, 0.7312155251777392, 0.7350560179473584, 0.0, 1.0, 0.9, 0.4029200179777228], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9491764], dtype=float32), 0.20810546]. 
=============================================
[2019-04-16 12:00:25,277] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-16 12:00:25,277] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:00:25,277] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:00:25,277] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:00:25,278] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:00:25,278] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:00:25,278] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:00:25,281] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run2
[2019-04-16 12:00:25,300] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run2
[2019-04-16 12:00:25,322] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run2
[2019-04-16 12:00:48,956] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([0.00335783], dtype=float32), 0.00479652]
[2019-04-16 12:00:48,957] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation this: [17.7, 67.0, 0.0, 0.0, 19.0, 28.20905133992414, 1.228917210550387, 0.0, 0.0, 50.0, 19.014014513607833]
[2019-04-16 12:00:48,957] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-16 12:00:48,958] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Softmax [0.14245576 0.06972516 0.05013444 0.0945318  0.04595751 0.10220622
 0.03622936 0.19160336 0.09629839 0.08450394 0.08635411], sampled 0.731148830707282
[2019-04-16 12:01:32,122] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 1590.1101 130516.3262 1125.5351
[2019-04-16 12:01:32,143] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:01:32,143] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:01:32,252] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:01:32,252] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:01:40,580] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1472.8319 141422.9439 857.4059
[2019-04-16 12:01:40,600] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:01:40,600] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:01:40,712] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:01:40,712] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:01:41,797] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 1449.6381 143789.8787 645.4715
[2019-04-16 12:01:41,816] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:01:41,816] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:01:41,929] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:01:41,929] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:01:42,818] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 50000, evaluation results [50000.0, 1472.8319259256155, 141422.94386193206, 857.4058706257455, 1590.1101208265047, 130516.32616244642, 1125.5350710957357, 1449.6381068430092, 143789.8787403002, 645.4715279195296]
[2019-04-16 12:01:43,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.21855305 0.0722045  0.02750508 0.04649939 0.04244822 0.14822422
 0.0137431  0.19881216 0.09939995 0.08219904 0.05041119], sum to 1.0000
[2019-04-16 12:01:43,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9258
[2019-04-16 12:01:43,863] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [6.0, 47.0, 95.5, 740.5, 19.0, 27.68823856555508, 0.9221494462683185, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3682800.0000, 
sim time next is 3684000.0000, 
raw observation next is [5.666666666666666, 48.0, 89.83333333333333, 716.8333333333333, 19.0, 27.55546469275708, 0.9933759078953991, 0.0, 1.0, 60.0, 41.471238972472285], 
processed observation next is [0.0, 0.6521739130434783, 0.6195752539242845, 0.48, 0.2994444444444444, 0.7920810313075506, 0.08333333333333333, 0.7962887243964234, 0.8311253026317997, 0.0, 1.0, 0.9, 0.41471238972472285], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5563298], dtype=float32), 0.43243954]. 
=============================================
[2019-04-16 12:01:44,850] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.12288324 0.08820547 0.05802128 0.0846837  0.05968526 0.1375226
 0.03473611 0.14841782 0.1287686  0.06665616 0.07041971], sum to 1.0000
[2019-04-16 12:01:44,854] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7831
[2019-04-16 12:01:44,891] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 25.33768497456348, 0.4884064364807994, 0.0, 1.0, 55.0, 47.536712781191156], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3902400.0000, 
sim time next is 3903600.0000, 
raw observation next is [-3.333333333333333, 73.0, 0.0, 0.0, 19.0, 25.70212442568023, 0.5138160795426375, 0.0, 1.0, 55.0, 45.803568854011246], 
processed observation next is [1.0, 0.17391304347826086, 0.37026777469990774, 0.73, 0.0, 0.0, 0.08333333333333333, 0.6418437021400191, 0.6712720265142126, 0.0, 1.0, 0.8, 0.45803568854011245], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0143116], dtype=float32), -1.1641473]. 
=============================================
[2019-04-16 12:01:46,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.1313693  0.09358377 0.05839757 0.08584987 0.05218722 0.14010946
 0.03833222 0.14840902 0.10613234 0.07401145 0.07161778], sum to 1.0000
[2019-04-16 12:01:46,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0714
[2019-04-16 12:01:46,442] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.666666666666666, 62.33333333333333, 0.0, 0.0, 19.0, 25.76137293204594, 0.4751482159489761, 0.0, 1.0, 55.0, 43.468241214885275], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3912000.0000, 
sim time next is 3913200.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 25.34645580853989, 0.2681302033180343, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.6122046507116575, 0.5893767344393447, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.9574339], dtype=float32), 0.076705046]. 
=============================================
[2019-04-16 12:01:49,912] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.15622005 0.08782371 0.04712992 0.10186833 0.03789816 0.11784773
 0.02823095 0.1772315  0.10660771 0.06898435 0.07015756], sum to 1.0000
[2019-04-16 12:01:49,913] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8588
[2019-04-16 12:01:49,959] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 26.51307054158205, 0.6963829736732783, 0.0, 1.0, 55.0, 41.77219215466298], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3892800.0000, 
sim time next is 3894000.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 26.5025622490947, 0.6931879524977291, 0.0, 1.0, 55.0, 42.69747237033138], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.7085468540912251, 0.7310626508325764, 0.0, 1.0, 0.8, 0.42697472370331385], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2343218], dtype=float32), 0.41894394]. 
=============================================
[2019-04-16 12:01:49,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.13761948 0.08558988 0.05385403 0.08197994 0.04586872 0.12866038
 0.03366736 0.16828725 0.10066903 0.08435676 0.07944713], sum to 1.0000
[2019-04-16 12:01:50,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8249
[2019-04-16 12:01:50,033] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-10.66666666666667, 58.0, 0.0, 0.0, 19.0, 25.01894956049315, 0.3594823043097827, 0.0, 1.0, 25.0, 41.04803465490984], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3976800.0000, 
sim time next is 3978000.0000, 
raw observation next is [-11.0, 58.0, 0.0, 0.0, 19.0, 25.08270003019639, 0.345930756901511, 0.0, 1.0, 55.0, 46.40869667146624], 
processed observation next is [1.0, 0.043478260869565216, 0.15789473684210528, 0.58, 0.0, 0.0, 0.08333333333333333, 0.5902250025163657, 0.6153102523005036, 0.0, 1.0, 0.8, 0.4640869667146624], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04901738], dtype=float32), -0.5968198]. 
=============================================
[2019-04-16 12:01:52,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.20236357 0.06968774 0.03231954 0.04187553 0.03830425 0.15675037
 0.01802103 0.22040057 0.09102449 0.05636081 0.07289213], sum to 1.0000
[2019-04-16 12:01:52,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5637
[2019-04-16 12:01:52,767] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.333333333333333, 27.0, 112.3333333333333, 824.0, 22.5, 26.43906935191081, 0.6371315679695414, 1.0, 1.0, 35.0, 30.698001367135383], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4023600.0000, 
sim time next is 4024800.0000, 
raw observation next is [-3.0, 26.0, 109.0, 812.0, 22.5, 26.63656229759316, 0.6619945027492982, 1.0, 1.0, 50.0, 33.4808483692005], 
processed observation next is [1.0, 0.6086956521739131, 0.3795013850415513, 0.26, 0.36333333333333334, 0.8972375690607735, 0.375, 0.7197135247994298, 0.720664834249766, 1.0, 1.0, 0.7, 0.334808483692005], 
reward next is 0.1402, 
noisyNet noise sample is [array([-2.0150626], dtype=float32), 0.1098399]. 
=============================================
[2019-04-16 12:01:58,585] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.19682248 0.06056561 0.03068228 0.0502603  0.04556822 0.14980951
 0.01374724 0.19519603 0.10413547 0.09434114 0.05887168], sum to 1.0000
[2019-04-16 12:01:58,586] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0353
[2019-04-16 12:01:58,605] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 38.0, 83.33333333333333, 548.0, 19.0, 27.19084338435573, 0.8264084152714019, 0.0, 1.0, 60.0, 25.92389586475176], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4206000.0000, 
sim time next is 4207200.0000, 
raw observation next is [2.333333333333333, 39.0, 60.66666666666667, 485.5000000000001, 19.0, 27.16587188000831, 0.7285638167736835, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5272391505078486, 0.39, 0.20222222222222225, 0.5364640883977901, 0.08333333333333333, 0.7638226566673593, 0.7428546055912278, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2301997], dtype=float32), 0.33946148]. 
=============================================
[2019-04-16 12:01:59,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.14659785 0.09436303 0.05399052 0.08037344 0.04762592 0.12833242
 0.03241094 0.16260399 0.11101449 0.07098372 0.07170365], sum to 1.0000
[2019-04-16 12:01:59,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0153
[2019-04-16 12:01:59,786] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.966666666666667, 70.66666666666667, 0.0, 0.0, 19.0, 26.70079398911646, 0.6206140240911117, 0.0, 1.0, 40.0, 26.2705809551382], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4332000.0000, 
sim time next is 4333200.0000, 
raw observation next is [3.933333333333333, 70.33333333333333, 0.0, 0.0, 19.0, 26.25812183659447, 0.4803628230825255, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5715604801477379, 0.7033333333333333, 0.0, 0.0, 0.08333333333333333, 0.6881768197162058, 0.6601209410275085, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.59802336], dtype=float32), -0.29366568]. 
=============================================
[2019-04-16 12:02:01,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.12740324 0.09277173 0.05593622 0.0940287  0.0458874  0.1333138
 0.03301737 0.13880107 0.11892955 0.07721343 0.08269748], sum to 1.0000
[2019-04-16 12:02:01,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8155
[2019-04-16 12:02:01,995] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-0.7333333333333334, 73.0, 0.0, 0.0, 19.0, 25.98440944987905, 0.6372130417420265, 0.0, 1.0, 25.0, 37.89562906157256], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 4501200.0000, 
sim time next is 4502400.0000, 
raw observation next is [-0.8666666666666667, 73.0, 0.0, 0.0, 19.0, 26.04402303137391, 0.661299429661626, 0.0, 1.0, 55.0, 47.3172787582886], 
processed observation next is [1.0, 0.08695652173913043, 0.4385964912280702, 0.73, 0.0, 0.0, 0.08333333333333333, 0.6703352526144926, 0.720433143220542, 0.0, 1.0, 0.8, 0.473172787582886], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0997592], dtype=float32), 0.5835713]. 
=============================================
[2019-04-16 12:02:02,097] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.14653046 0.08394562 0.05920275 0.07997502 0.05111022 0.12459513
 0.03644016 0.1862586  0.09656186 0.07498344 0.06039684], sum to 1.0000
[2019-04-16 12:02:02,098] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4330
[2019-04-16 12:02:02,136] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.8666666666666667, 71.0, 0.0, 0.0, 19.0, 25.75194262122862, 0.5086831529922675, 0.0, 1.0, 25.0, 28.610355938676456], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 4512000.0000, 
sim time next is 4513200.0000, 
raw observation next is [-0.9333333333333333, 71.0, 0.0, 0.0, 19.0, 25.55034981372822, 0.4677540552429576, 0.0, 1.0, 40.0, 24.637278204613978], 
processed observation next is [1.0, 0.21739130434782608, 0.4367497691597415, 0.71, 0.0, 0.0, 0.08333333333333333, 0.6291958178106851, 0.6559180184143192, 0.0, 1.0, 0.5, 0.24637278204613977], 
reward next is 0.3786, 
noisyNet noise sample is [array([0.98449194], dtype=float32), 0.047511056]. 
=============================================
[2019-04-16 12:02:02,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.1823111  0.04830988 0.02894373 0.05588808 0.03959436 0.11483893
 0.01866095 0.28509668 0.0949462  0.06191067 0.06949938], sum to 1.0000
[2019-04-16 12:02:02,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1478
[2019-04-16 12:02:02,846] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 196.5, 73.0, 22.5, 28.18883221226854, 1.091008601136021, 1.0, 1.0, 20.0, 20.425286124264026], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4446000.0000, 
sim time next is 4447200.0000, 
raw observation next is [1.0, 86.0, 160.1666666666667, 24.33333333333333, 22.5, 28.20976777480204, 1.033425351660261, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.86, 0.5338888888888891, 0.026887661141804783, 0.375, 0.8508139812335033, 0.8444751172200871, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5517348], dtype=float32), -0.7875011]. 
=============================================
[2019-04-16 12:02:04,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.14041801 0.08362842 0.06507616 0.08629868 0.04371262 0.13777514
 0.03384008 0.16442814 0.10715064 0.08140785 0.05626434], sum to 1.0000
[2019-04-16 12:02:04,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3452
[2019-04-16 12:02:04,804] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-2.0, 71.0, 0.0, 0.0, 19.0, 26.19477478437062, 0.5838886559307291, 0.0, 1.0, 50.0, 32.12691457008114], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 4597200.0000, 
sim time next is 4598400.0000, 
raw observation next is [-2.2, 72.0, 0.0, 0.0, 19.0, 26.0669761669446, 0.5398901614693582, 0.0, 1.0, 30.0, 25.27940251045689], 
processed observation next is [1.0, 0.21739130434782608, 0.4016620498614959, 0.72, 0.0, 0.0, 0.08333333333333333, 0.6722480139120499, 0.6799633871564527, 0.0, 1.0, 0.3, 0.2527940251045689], 
reward next is 0.5222, 
noisyNet noise sample is [array([0.9264802], dtype=float32), 1.1929423]. 
=============================================
[2019-04-16 12:02:06,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.20481421 0.06922815 0.03462837 0.07890487 0.03008363 0.11544085
 0.01777017 0.21518713 0.09851876 0.07854372 0.0568802 ], sum to 1.0000
[2019-04-16 12:02:06,738] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2748
[2019-04-16 12:02:06,783] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [2.0, 53.66666666666667, 0.0, 0.0, 19.0, 27.17717518292774, 0.8099858451528057, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 4664400.0000, 
sim time next is 4665600.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 26.82937907920353, 0.8758852611829884, 0.0, 1.0, 25.0, 53.99857545883806], 
processed observation next is [1.0, 0.0, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.7357815899336275, 0.7919617537276628, 0.0, 1.0, 0.2, 0.5399857545883806], 
reward next is 0.3100, 
noisyNet noise sample is [array([-1.6588564], dtype=float32), -1.3232708]. 
=============================================
[2019-04-16 12:02:18,171] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:18,349] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:18,497] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:18,510] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:18,661] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:18,695] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:19,170] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:19,172] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:19,179] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run2
[2019-04-16 12:02:19,369] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:19,499] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:19,499] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:19,503] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run2
[2019-04-16 12:02:19,521] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:19,522] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:19,523] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:19,535] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run2
[2019-04-16 12:02:19,746] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:19,922] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:20,331] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:20,373] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:20,373] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:20,375] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run2
[2019-04-16 12:02:20,454] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:20,513] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:20,627] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:20,635] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:20,747] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:20,748] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:20,750] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run2
[2019-04-16 12:02:20,802] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:20,935] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:21,100] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:21,180] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:21,333] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:21,333] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:21,335] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run2
[2019-04-16 12:02:21,352] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:21,456] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:21,469] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:21,456] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:21,471] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run2
[2019-04-16 12:02:21,623] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:21,637] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:21,637] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:21,640] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run2
[2019-04-16 12:02:21,933] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:21,933] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:21,935] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run2
[2019-04-16 12:02:22,181] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:22,181] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:22,183] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run2
[2019-04-16 12:02:22,457] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:22,457] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:22,459] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run2
[2019-04-16 12:02:22,713] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:22,920] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:23,458] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:23,586] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:23,697] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:23,697] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:23,699] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run2
[2019-04-16 12:02:23,755] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:23,843] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:24,459] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:24,459] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:24,461] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run2
[2019-04-16 12:02:24,495] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:24,589] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:24,589] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:24,591] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run2
[2019-04-16 12:02:24,837] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:25,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:25,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:25,498] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run2
[2019-04-16 12:02:26,453] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:02:26,638] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:02:27,454] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:02:27,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:02:27,456] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run2
[2019-04-16 12:02:32,763] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.15614381 0.09302723 0.04713111 0.06504676 0.04896313 0.12016528
 0.03168596 0.16387108 0.12143779 0.07577629 0.07675158], sum to 1.0000
[2019-04-16 12:02:32,763] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6095
[2019-04-16 12:02:32,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 19.0, 21.08671569526715, -0.5235580582793337, 0.0, 1.0, 20.0, 24.52662042825923], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 9600.0000, 
sim time next is 10800.0000, 
raw observation next is [7.2, 96.0, 0.0, 0.0, 19.0, 21.23174408906082, -0.4751423945526134, 0.0, 1.0, 50.0, 41.867458107607035], 
processed observation next is [0.0, 0.13043478260869565, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.26931200742173483, 0.3416192018157955, 0.0, 1.0, 0.7, 0.41867458107607036], 
reward next is 0.0563, 
noisyNet noise sample is [array([0.31610808], dtype=float32), 0.0720624]. 
=============================================
[2019-04-16 12:02:33,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.20180452 0.06429834 0.03784415 0.06235719 0.03860029 0.12084194
 0.02115738 0.23708265 0.08958199 0.07569201 0.05073949], sum to 1.0000
[2019-04-16 12:02:33,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9238
[2019-04-16 12:02:33,736] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [7.7, 86.0, 83.0, 0.0, 19.0, 23.51980911615919, 0.01185471864649363, 0.0, 1.0, 45.0, 28.109089732925565], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 50400.0000, 
sim time next is 51600.0000, 
raw observation next is [7.533333333333333, 86.0, 80.33333333333334, 0.0, 19.0, 23.49913089327789, 0.06050329603094367, 0.0, 1.0, 60.0, 60.929129515230954], 
processed observation next is [0.0, 0.6086956521739131, 0.6712834718374886, 0.86, 0.26777777777777784, 0.0, 0.08333333333333333, 0.4582609077731575, 0.520167765343648, 0.0, 1.0, 0.9, 0.6092912951523095], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1072818], dtype=float32), 1.0420376]. 
=============================================
[2019-04-16 12:02:41,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.1848962  0.07167395 0.03073911 0.06151382 0.03473247 0.09070449
 0.01794281 0.29714602 0.09584837 0.05557545 0.05922737], sum to 1.0000
[2019-04-16 12:02:41,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2893
[2019-04-16 12:02:41,055] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-2.8, 59.0, 86.5, 0.0, 22.5, 23.89054112784768, -0.1551847516746055, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 226800.0000, 
sim time next is 228000.0000, 
raw observation next is [-3.0, 60.0, 66.16666666666667, 0.0, 22.5, 23.68377316377375, -0.07566273287994564, 1.0, 1.0, 30.0, 53.363938928626794], 
processed observation next is [1.0, 0.6521739130434783, 0.3795013850415513, 0.6, 0.22055555555555556, 0.0, 0.375, 0.4736477636478125, 0.4747790890400181, 1.0, 1.0, 0.3, 0.533639389286268], 
reward next is 0.2414, 
noisyNet noise sample is [array([0.33817348], dtype=float32), 0.9453222]. 
=============================================
[2019-04-16 12:02:41,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.22312367 0.05535759 0.03003385 0.05783616 0.0361513  0.12915596
 0.01660392 0.25501287 0.0837073  0.0601543  0.05286302], sum to 1.0000
[2019-04-16 12:02:41,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7310
[2019-04-16 12:02:41,337] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 65.0, 141.0, 0.0, 22.5, 22.97563984360196, -0.2386081740084937, 1.0, 1.0, 50.0, 47.26462162858432], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 216000.0000, 
sim time next is 217200.0000, 
raw observation next is [-4.833333333333334, 65.0, 133.0, 0.0, 22.5, 23.36510827952056, -0.1830749171583691, 1.0, 1.0, 50.0, 44.54486585340254], 
processed observation next is [1.0, 0.5217391304347826, 0.32871652816251157, 0.65, 0.44333333333333336, 0.0, 0.375, 0.44709235662671326, 0.4389750276138769, 1.0, 1.0, 0.7, 0.44544865853402543], 
reward next is 0.0296, 
noisyNet noise sample is [array([0.6725452], dtype=float32), -0.6430313]. 
=============================================
[2019-04-16 12:02:44,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.16109224 0.08185136 0.05319652 0.0768925  0.03610677 0.13461512
 0.02645936 0.17806609 0.10088565 0.0863225  0.06451189], sum to 1.0000
[2019-04-16 12:02:44,908] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2625
[2019-04-16 12:02:44,945] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 20.96505252777221, -0.7212757207327406, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 264000.0000, 
sim time next is 265200.0000, 
raw observation next is [-7.1, 69.66666666666666, 0.0, 0.0, 19.0, 20.57854757055247, -0.6204495625066316, 0.0, 1.0, 25.0, 60.682451269102685], 
processed observation next is [1.0, 0.043478260869565216, 0.2659279778393352, 0.6966666666666665, 0.0, 0.0, 0.08333333333333333, 0.2148789642127058, 0.29318347916445614, 0.0, 1.0, 0.2, 0.6068245126910269], 
reward next is 0.2432, 
noisyNet noise sample is [array([0.41405058], dtype=float32), -0.36812538]. 
=============================================
[2019-04-16 12:02:48,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.2013078  0.07174487 0.03901817 0.06572057 0.04457087 0.10961945
 0.02322955 0.21475169 0.09018558 0.06742794 0.07242348], sum to 1.0000
[2019-04-16 12:02:48,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7094
[2019-04-16 12:02:48,564] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-15.23333333333333, 82.0, 36.66666666666666, 694.5, 22.5, 22.20697800056642, -0.5532026133171087, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 379200.0000, 
sim time next is 380400.0000, 
raw observation next is [-14.86666666666667, 74.0, 44.33333333333333, 736.5, 22.5, 22.06196901830915, -0.414269597853854, 1.0, 1.0, 50.0, 63.88795985028226], 
processed observation next is [1.0, 0.391304347826087, 0.05078485687903958, 0.74, 0.14777777777777776, 0.8138121546961326, 0.375, 0.3384974181924291, 0.36191013404871536, 1.0, 1.0, 0.7, 0.6388795985028226], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0571073], dtype=float32), 1.2394768]. 
=============================================
[2019-04-16 12:02:54,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.19265865 0.07427932 0.03617134 0.06678581 0.02085309 0.12957072
 0.0159994  0.2582583  0.08413316 0.06515363 0.05613659], sum to 1.0000
[2019-04-16 12:02:54,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7349
[2019-04-16 12:02:54,710] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.7, 92.0, 0.0, 0.0, 19.0, 22.61781101592535, -0.2830050475704547, 0.0, 1.0, 40.0, 30.289714334088472], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 511200.0000, 
sim time next is 512400.0000, 
raw observation next is [2.9, 93.33333333333334, 0.0, 0.0, 19.0, 22.54972478421058, -0.2864068654514006, 0.0, 1.0, 50.0, 38.49669445937488], 
processed observation next is [1.0, 0.9565217391304348, 0.5429362880886427, 0.9333333333333335, 0.0, 0.0, 0.08333333333333333, 0.3791437320175482, 0.4045310448495331, 0.0, 1.0, 0.7, 0.3849669445937488], 
reward next is 0.0900, 
noisyNet noise sample is [array([0.0806288], dtype=float32), 0.8679609]. 
=============================================
[2019-04-16 12:03:00,670] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.2320292  0.05098834 0.02857042 0.05280767 0.03194056 0.10491668
 0.01278274 0.30456713 0.06572326 0.06401971 0.05165435], sum to 1.0000
[2019-04-16 12:03:00,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2978
[2019-04-16 12:03:00,704] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-4.266666666666667, 54.66666666666667, 0.0, 0.0, 22.5, 24.85413552829652, 0.2381167774071567, 1.0, 1.0, 50.0, 39.04474391820871], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 760800.0000, 
sim time next is 762000.0000, 
raw observation next is [-4.633333333333333, 56.33333333333333, 0.0, 0.0, 22.5, 24.56256644510827, 0.1833342977922168, 1.0, 1.0, 25.0, 30.42434025027704], 
processed observation next is [1.0, 0.8260869565217391, 0.3342566943674977, 0.5633333333333332, 0.0, 0.0, 0.375, 0.5468805370923558, 0.5611114325974056, 1.0, 1.0, 0.2, 0.30424340250277043], 
reward next is 0.5458, 
noisyNet noise sample is [array([-0.66031945], dtype=float32), -0.7680997]. 
=============================================
[2019-04-16 12:03:02,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.23097324 0.06664023 0.02582043 0.05379133 0.03273729 0.12630509
 0.0158514  0.21166588 0.09965838 0.07408012 0.06247666], sum to 1.0000
[2019-04-16 12:03:02,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2367
[2019-04-16 12:03:02,688] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-1.2, 81.0, 128.8333333333333, 488.3333333333333, 19.0, 22.73816319576073, -0.2282539640827453, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 570000.0000, 
sim time next is 571200.0000, 
raw observation next is [-1.2, 82.0, 122.5, 401.3333333333334, 19.0, 22.80138792269934, -0.03648112023674883, 0.0, 1.0, 20.0, 68.92448281026397], 
processed observation next is [0.0, 0.6086956521739131, 0.42936288088642666, 0.82, 0.4083333333333333, 0.443462246777164, 0.08333333333333333, 0.4001156602249451, 0.48783962658775043, 0.0, 1.0, 0.1, 0.6892448281026397], 
reward next is 0.2358, 
noisyNet noise sample is [array([-0.08470836], dtype=float32), -0.15123953]. 
=============================================
[2019-04-16 12:03:05,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.20258981 0.0601812  0.02962878 0.05655982 0.02953122 0.10084163
 0.01743011 0.26836488 0.10653974 0.06864575 0.05968711], sum to 1.0000
[2019-04-16 12:03:05,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7657
[2019-04-16 12:03:06,022] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 19.0, 20.49119083629705, -0.718698155878671, 0.0, 1.0, 50.0, 58.41715746637192], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 684000.0000, 
sim time next is 685200.0000, 
raw observation next is [-3.566666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 20.76861638859727, -0.656228005092239, 0.0, 1.0, 55.0, 53.02922319491032], 
processed observation next is [0.0, 0.9565217391304348, 0.3638042474607572, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.23071803238310581, 0.2812573316359203, 0.0, 1.0, 0.8, 0.5302922319491032], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7867804], dtype=float32), 0.080985226]. 
=============================================
[2019-04-16 12:03:09,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.24938987 0.04982377 0.02802592 0.04449164 0.01916217 0.12579069
 0.01138725 0.32296443 0.06060368 0.05117714 0.03718341], sum to 1.0000
[2019-04-16 12:03:09,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0020
[2019-04-16 12:03:09,630] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 22.5, 26.73031182279743, 0.8383759569176688, 0.0, 1.0, 60.0, 50.41947232655684], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1022400.0000, 
sim time next is 1023600.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 19.0, 26.72912170609894, 0.7312471667035547, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.8614958448753465, 0.77, 0.0, 0.0, 0.08333333333333333, 0.7274268088415784, 0.7437490555678515, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47551984], dtype=float32), 0.22999464]. 
=============================================
[2019-04-16 12:03:10,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.16848044 0.07805408 0.04500892 0.07082277 0.03628989 0.1206851
 0.02038057 0.2551249  0.08259152 0.07219634 0.0503655 ], sum to 1.0000
[2019-04-16 12:03:10,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2219
[2019-04-16 12:03:10,496] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 80.0, 0.0, 0.0, 19.0, 26.90296324060572, 0.8808286992356117, 0.0, 1.0, 50.0, 31.22892369889962], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 1058400.0000, 
sim time next is 1059600.0000, 
raw observation next is [13.3, 80.0, 0.0, 0.0, 19.0, 26.922117655619, 0.8753646660935294, 0.0, 1.0, 20.0, 24.235815766931353], 
processed observation next is [1.0, 0.2608695652173913, 0.8310249307479226, 0.8, 0.0, 0.0, 0.08333333333333333, 0.7435098046349168, 0.7917882220311765, 0.0, 1.0, 0.1, 0.24235815766931354], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.10724299], dtype=float32), 0.77628285]. 
=============================================
[2019-04-16 12:03:11,874] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.1687455  0.09862928 0.05246715 0.07688928 0.03100694 0.11429435
 0.02345557 0.20185658 0.09376141 0.08567504 0.05321892], sum to 1.0000
[2019-04-16 12:03:11,874] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8314
[2019-04-16 12:03:11,900] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 19.0, 23.98770594069387, 0.1456807724529016, 0.0, 1.0, 25.0, 39.98540679679383], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 968400.0000, 
sim time next is 969600.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 19.0, 24.17576117882959, 0.2086057766723914, 0.0, 1.0, 55.0, 46.82829863917661], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.08333333333333333, 0.5146467649024657, 0.5695352588907971, 0.0, 1.0, 0.8, 0.4682829863917661], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.93204814], dtype=float32), -1.0971065]. 
=============================================
[2019-04-16 12:03:14,070] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.19365674 0.04187742 0.03235787 0.05471021 0.02783633 0.10046311
 0.0178194  0.36937076 0.04847921 0.06341897 0.0500099 ], sum to 1.0000
[2019-04-16 12:03:14,071] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0462
[2019-04-16 12:03:14,091] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 49.0, 116.0, 0.0, 22.5, 28.61227606511784, 1.315307260865982, 1.0, 0.0, 30.0, 8.616158675730876], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1090800.0000, 
sim time next is 1092000.0000, 
raw observation next is [19.4, 49.0, 100.0, 0.0, 22.5, 28.89965288588859, 1.341254537595288, 1.0, 0.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.49, 0.3333333333333333, 0.0, 0.375, 0.9083044071573824, 0.947084845865096, 1.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19635321], dtype=float32), 1.4621489]. 
=============================================
[2019-04-16 12:03:20,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.1779122  0.05961896 0.05019454 0.06693083 0.03771713 0.12793222
 0.02863703 0.2290778  0.09293358 0.07290354 0.05614228], sum to 1.0000
[2019-04-16 12:03:20,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1815
[2019-04-16 12:03:20,227] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 27.96140705210506, 1.18163353279972, 0.0, 0.0, 60.0, 26.225070692818946], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 1233600.0000, 
sim time next is 1234800.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 27.94630626266854, 1.182388824410636, 0.0, 0.0, 20.0, 20.720063142047675], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.8288588552223782, 0.8941296081368787, 0.0, 0.0, 0.1, 0.20720063142047673], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.65907043], dtype=float32), -0.8959202]. 
=============================================
[2019-04-16 12:03:20,600] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.30321282 0.05367419 0.02363003 0.0413449  0.02385847 0.08405504
 0.0100584  0.26252773 0.10030731 0.06536996 0.03196122], sum to 1.0000
[2019-04-16 12:03:20,601] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6024
[2019-04-16 12:03:20,626] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [6.466666666666667, 96.0, 0.0, 0.0, 19.0, 27.19042978386409, 1.113269324389417, 0.0, 1.0, 25.0, 51.513024127671386], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1280400.0000, 
sim time next is 1281600.0000, 
raw observation next is [6.1, 96.0, 0.0, 0.0, 19.0, 27.40228013354806, 1.120383257011539, 0.0, 1.0, 50.0, 29.285927558964815], 
processed observation next is [0.0, 0.8695652173913043, 0.6315789473684211, 0.96, 0.0, 0.0, 0.08333333333333333, 0.7835233444623384, 0.8734610856705131, 0.0, 1.0, 0.7, 0.29285927558964814], 
reward next is 0.1821, 
noisyNet noise sample is [array([-0.13228473], dtype=float32), -1.3345648]. 
=============================================
[2019-04-16 12:03:20,870] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.2803176  0.04027559 0.02693476 0.03400551 0.02361541 0.11612876
 0.00783816 0.32187077 0.05597883 0.05558357 0.03745108], sum to 1.0000
[2019-04-16 12:03:20,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5466
[2019-04-16 12:03:20,905] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.5, 96.0, 9.0, 0.0, 22.5, 27.43646470246276, 0.9313906997953203, 1.0, 1.0, 50.0, 31.13397225460585], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1357200.0000, 
sim time next is 1358400.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 27.6243214572782, 0.9311786174924749, 1.0, 1.0, 50.0, 37.627669433879525], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.8020267881065166, 0.8103928724974917, 1.0, 1.0, 0.7, 0.37627669433879524], 
reward next is 0.0987, 
noisyNet noise sample is [array([-0.7807678], dtype=float32), -0.19022246]. 
=============================================
[2019-04-16 12:03:23,521] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.27826378 0.05052596 0.02241086 0.03612886 0.0207815  0.10048161
 0.00976774 0.32279652 0.06631923 0.05819143 0.03433257], sum to 1.0000
[2019-04-16 12:03:23,522] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4882
[2019-04-16 12:03:23,588] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.1, 92.0, 59.0, 0.0, 22.5, 27.16778402696161, 0.7760513008155924, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 1436400.0000, 
sim time next is 1437600.0000, 
raw observation next is [1.1, 92.0, 50.33333333333333, 0.0, 22.5, 26.37365741767819, 0.7556800905232661, 1.0, 1.0, 40.0, 40.96114504146399], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.16777777777777778, 0.0, 0.375, 0.6978047848065158, 0.7518933635077554, 1.0, 1.0, 0.5, 0.4096114504146399], 
reward next is 0.2154, 
noisyNet noise sample is [array([-0.08968574], dtype=float32), -0.42685506]. 
=============================================
[2019-04-16 12:03:23,675] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.2302174  0.06218854 0.03200798 0.05420972 0.02803157 0.12977824
 0.01326849 0.2554102  0.08826827 0.0651839  0.0414357 ], sum to 1.0000
[2019-04-16 12:03:23,676] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4689
[2019-04-16 12:03:23,697] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 25.89922558438838, 0.619277939018385, 0.0, 1.0, 50.0, 46.63131629231724], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 1472400.0000, 
sim time next is 1473600.0000, 
raw observation next is [1.8, 92.0, 0.0, 0.0, 19.0, 25.97733426363766, 0.6178420578088959, 0.0, 1.0, 40.0, 26.52604544367487], 
processed observation next is [1.0, 0.043478260869565216, 0.5124653739612189, 0.92, 0.0, 0.0, 0.08333333333333333, 0.6647778553031382, 0.7059473526029653, 0.0, 1.0, 0.5, 0.2652604544367487], 
reward next is 0.3597, 
noisyNet noise sample is [array([2.882902], dtype=float32), -0.56068665]. 
=============================================
[2019-04-16 12:03:25,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.22180781 0.06417671 0.05322293 0.06348085 0.03094405 0.14243217
 0.01993001 0.19884628 0.08857407 0.07495258 0.04163243], sum to 1.0000
[2019-04-16 12:03:25,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5122
[2019-04-16 12:03:25,946] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [6.233333333333333, 97.0, 0.0, 0.0, 19.0, 27.45048115479672, 0.9502191493112702, 0.0, 1.0, 55.0, 33.30183583010094], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 1660800.0000, 
sim time next is 1662000.0000, 
raw observation next is [5.866666666666667, 97.0, 0.0, 0.0, 19.0, 27.31870193680986, 0.9438292308292033, 0.0, 1.0, 40.0, 31.06296783857364], 
processed observation next is [1.0, 0.21739130434782608, 0.6251154201292707, 0.97, 0.0, 0.0, 0.08333333333333333, 0.776558494734155, 0.8146097436097345, 0.0, 1.0, 0.5, 0.3106296783857364], 
reward next is 0.3144, 
noisyNet noise sample is [array([0.47752142], dtype=float32), -2.2265494]. 
=============================================
[2019-04-16 12:03:29,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.22996286 0.05844947 0.03915687 0.06093298 0.02580199 0.1131965
 0.01822932 0.25951132 0.07284541 0.08290403 0.03900927], sum to 1.0000
[2019-04-16 12:03:29,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3293
[2019-04-16 12:03:29,139] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [1.433333333333333, 100.0, 22.83333333333333, 0.0, 22.5, 26.20223015683161, 0.6281258646634562, 1.0, 1.0, 50.0, 32.877984000180135], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 1500000.0000, 
sim time next is 1501200.0000, 
raw observation next is [1.6, 100.0, 32.5, 0.0, 22.5, 26.35180250486748, 0.6493214610674929, 1.0, 1.0, 30.0, 25.910091766985317], 
processed observation next is [1.0, 0.391304347826087, 0.5069252077562327, 1.0, 0.10833333333333334, 0.0, 0.375, 0.6959835420722899, 0.7164404870224977, 1.0, 1.0, 0.3, 0.25910091766985316], 
reward next is 0.5159, 
noisyNet noise sample is [array([0.7843984], dtype=float32), 0.2312401]. 
=============================================
[2019-04-16 12:03:31,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.2959944  0.04675263 0.02401163 0.03234394 0.01480103 0.08981683
 0.00812455 0.35640255 0.06072124 0.04714846 0.02388274], sum to 1.0000
[2019-04-16 12:03:31,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2926
[2019-04-16 12:03:31,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.366666666666667, 75.33333333333333, 0.0, 0.0, 19.0, 27.6631986232342, 1.094290946249159, 0.0, 1.0, 40.0, 24.339567065593165], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1629600.0000, 
sim time next is 1630800.0000, 
raw observation next is [7.2, 76.0, 0.0, 0.0, 19.0, 27.55866172733933, 1.018827907344645, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.662049861495845, 0.76, 0.0, 0.0, 0.08333333333333333, 0.7965551439449442, 0.8396093024482149, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36919308], dtype=float32), -1.1764177]. 
=============================================
[2019-04-16 12:03:40,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.17991866 0.07809373 0.05451605 0.0688481  0.03242753 0.1597975
 0.01903655 0.211883   0.07464805 0.0703873  0.0504435 ], sum to 1.0000
[2019-04-16 12:03:40,606] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9533
[2019-04-16 12:03:40,658] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-5.2, 87.66666666666667, 0.0, 0.0, 19.0, 22.35583877895775, -0.1928872187017179, 0.0, 1.0, 65.0, 72.42034027072847], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2085600.0000, 
sim time next is 2086800.0000, 
raw observation next is [-5.4, 89.33333333333334, 0.0, 0.0, 19.0, 22.97307038276141, -0.1314376749727907, 0.0, 1.0, 65.0, 65.25345296761077], 
processed observation next is [1.0, 0.13043478260869565, 0.31301939058171746, 0.8933333333333334, 0.0, 0.0, 0.08333333333333333, 0.4144225318967842, 0.4561874416757364, 0.0, 1.0, 1.0, 0.6525345296761077], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1197392], dtype=float32), -0.7413795]. 
=============================================
[2019-04-16 12:03:40,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.25324985 0.05376173 0.03050372 0.04650088 0.03264236 0.13482355
 0.01621589 0.26615065 0.0592091  0.06701348 0.03992872], sum to 1.0000
[2019-04-16 12:03:40,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1071
[2019-04-16 12:03:41,029] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.633333333333333, 81.0, 89.0, 50.5, 22.5, 23.88298154538732, -0.1837313855289191, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2104800.0000, 
sim time next is 2106000.0000, 
raw observation next is [-7.8, 82.0, 123.0, 77.5, 22.5, 23.27304915821489, -0.247738698928733, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.82, 0.41, 0.0856353591160221, 0.375, 0.43942076318457407, 0.41742043369042237, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3605007], dtype=float32), -0.92289406]. 
=============================================
[2019-04-16 12:03:42,087] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.18782209 0.08243022 0.05555398 0.07434095 0.03520275 0.1299921
 0.02329968 0.20273039 0.08773164 0.07293863 0.04795762], sum to 1.0000
[2019-04-16 12:03:42,088] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5516
[2019-04-16 12:03:42,118] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 23.02686663039061, -0.1315788119899436, 0.0, 1.0, 30.0, 44.520373892816835], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 2012400.0000, 
sim time next is 2013600.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 22.5, 23.39517340928202, -0.1359445772395925, 1.0, 1.0, 40.0, 35.808096422008155], 
processed observation next is [1.0, 0.30434782608695654, 0.2908587257617729, 0.87, 0.0, 0.0, 0.375, 0.449597784106835, 0.45468514092013584, 1.0, 1.0, 0.5, 0.35808096422008157], 
reward next is 0.2669, 
noisyNet noise sample is [array([-1.6580628], dtype=float32), 0.19706522]. 
=============================================
[2019-04-16 12:03:47,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.26693532 0.0454554  0.02862144 0.04203229 0.03007978 0.10011242
 0.01159464 0.32746994 0.05874468 0.05742322 0.03153086], sum to 1.0000
[2019-04-16 12:03:47,479] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9976
[2019-04-16 12:03:47,514] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.5, 71.0, 19.0, 0.0, 22.5, 24.19917888785412, 0.03935745818541109, 1.0, 1.0, 20.0, 31.587733190316875], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2221200.0000, 
sim time next is 2222400.0000, 
raw observation next is [-4.5, 70.0, 8.333333333333332, 0.0, 22.5, 24.2742185007853, 0.07993541334701725, 1.0, 1.0, 65.0, 66.63292856784403], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.7, 0.027777777777777773, 0.0, 0.375, 0.5228515417321082, 0.526645137782339, 1.0, 1.0, 1.0, 0.6663292856784403], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5646434], dtype=float32), -0.95412546]. 
=============================================
[2019-04-16 12:03:47,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.22092731 0.06118538 0.04729598 0.06898701 0.02441265 0.13871014
 0.01262917 0.24575624 0.0703349  0.07495692 0.03480438], sum to 1.0000
[2019-04-16 12:03:47,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9108
[2019-04-16 12:03:47,598] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 19.0, 22.67839333172317, -0.3493529541612981, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2076000.0000, 
sim time next is 2077200.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 19.0, 22.24758158626071, -0.2221045101273782, 0.0, 1.0, 60.0, 77.69237639203645], 
processed observation next is [1.0, 0.043478260869565216, 0.3379501385041552, 0.91, 0.0, 0.0, 0.08333333333333333, 0.3539651321883926, 0.4259651632908739, 0.0, 1.0, 0.9, 0.7769237639203646], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6869543], dtype=float32), 0.31411666]. 
=============================================
[2019-04-16 12:03:49,907] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.2069335  0.0643041  0.053239   0.05776211 0.02490448 0.14569281
 0.01217839 0.2147088  0.06423776 0.10992934 0.04610969], sum to 1.0000
[2019-04-16 12:03:49,907] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8369
[2019-04-16 12:03:49,954] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 19.0, 21.37073924081977, -0.3955693809681811, 0.0, 1.0, 55.0, 58.49982256758322], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2246400.0000, 
sim time next is 2247600.0000, 
raw observation next is [-6.700000000000001, 77.0, 0.0, 0.0, 19.0, 21.67312799137406, -0.3404850476769374, 0.0, 1.0, 55.0, 54.32765451589139], 
processed observation next is [1.0, 0.0, 0.2770083102493075, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3060939992811716, 0.3865049841076875, 0.0, 1.0, 0.8, 0.5432765451589139], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02250043], dtype=float32), 0.733365]. 
=============================================
[2019-04-16 12:03:50,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.3198005  0.03462873 0.02483807 0.03377741 0.01568487 0.08048791
 0.00743122 0.36508197 0.03740477 0.05359291 0.02727164], sum to 1.0000
[2019-04-16 12:03:50,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8569
[2019-04-16 12:03:50,824] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.2, 52.66666666666667, 0.0, 0.0, 22.5, 25.00587202618415, 0.2892851635754959, 1.0, 1.0, 55.0, 43.10081811989876], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2312400.0000, 
sim time next is 2313600.0000, 
raw observation next is [-1.2, 53.33333333333334, 0.0, 0.0, 22.5, 25.01898266938693, 0.2956482736863118, 1.0, 1.0, 50.0, 32.48496230797964], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.5333333333333334, 0.0, 0.0, 0.375, 0.5849152224489108, 0.5985494245621039, 1.0, 1.0, 0.7, 0.3248496230797964], 
reward next is 0.1502, 
noisyNet noise sample is [array([-1.2205374], dtype=float32), 0.03769186]. 
=============================================
[2019-04-16 12:03:52,789] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.27148443 0.05057828 0.02925917 0.03859629 0.01773101 0.14878665
 0.00986745 0.25744712 0.07176244 0.0755577  0.02892941], sum to 1.0000
[2019-04-16 12:03:52,792] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9723
[2019-04-16 12:03:52,838] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-1.7, 54.66666666666667, 0.0, 0.0, 19.0, 23.7895534153442, -0.03770804131056746, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 2323200.0000, 
sim time next is 2324400.0000, 
raw observation next is [-1.7, 55.33333333333333, 0.0, 0.0, 19.0, 23.50010033586434, 0.1069282698475121, 0.0, 1.0, 65.0, 79.44652813245905], 
processed observation next is [1.0, 0.9130434782608695, 0.4155124653739613, 0.5533333333333332, 0.0, 0.0, 0.08333333333333333, 0.45834169465536156, 0.5356427566158374, 0.0, 1.0, 1.0, 0.7944652813245905], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.199437], dtype=float32), 0.010679322]. 
=============================================
[2019-04-16 12:03:54,873] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-16 12:03:54,874] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:03:54,874] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:03:54,876] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run3
[2019-04-16 12:03:54,892] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:03:54,893] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:03:54,895] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run3
[2019-04-16 12:03:54,909] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:03:54,912] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:03:54,914] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run3
[2019-04-16 12:04:04,350] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:NoisyNet noise sample: [array([0.01223424], dtype=float32), 0.014501117]
[2019-04-16 12:04:04,351] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation this: [-2.917287857333334, 61.79776901333334, 0.0, 0.0, 19.0, 24.31855881491376, 0.04725347700654309, 0.0, 1.0, 55.0, 54.94972897679635]
[2019-04-16 12:04:04,351] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation forecast: []
[2019-04-16 12:04:04,352] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Softmax [0.26367086 0.04453884 0.02764487 0.04599947 0.01955545 0.11313697
 0.0104133  0.3148983  0.06855185 0.05537754 0.03621258], sampled 0.5967481476606092
[2019-04-16 12:04:32,222] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:NoisyNet noise sample: [array([0.01223424], dtype=float32), 0.014501117]
[2019-04-16 12:04:32,222] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation this: [-5.884685443, 87.23589258, 0.0, 0.0, 19.0, 22.47717858764636, -0.246531677585813, 0.0, 1.0, 65.0, 72.22848772858072]
[2019-04-16 12:04:32,223] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation forecast: []
[2019-04-16 12:04:32,223] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Softmax [0.25377685 0.05778962 0.03067208 0.04464581 0.02154935 0.1109395
 0.01035685 0.28083178 0.08271224 0.06504942 0.04167651], sampled 0.2967539208340927
[2019-04-16 12:05:03,257] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 1731.0686 125518.7071 1030.6472
[2019-04-16 12:05:03,278] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:03,278] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:03,278] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:03,391] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:03,391] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:03,391] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:11,033] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1653.8872 134236.6243 687.8378
[2019-04-16 12:05:11,054] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:11,054] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:11,054] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:11,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:11,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:11,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:11,836] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 1622.3989 137457.8929 504.0755
[2019-04-16 12:05:11,857] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:11,857] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:11,857] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:05:11,960] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:11,960] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:11,960] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:05:12,859] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 100000, evaluation results [100000.0, 1653.8871751147642, 134236.62431405284, 687.837785385503, 1731.0686087271897, 125518.70705933233, 1030.647247705355, 1622.3989020234076, 137457.8929195073, 504.07551678685576]
[2019-04-16 12:05:13,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.23055974 0.06658798 0.04304606 0.05351353 0.03478189 0.11767478
 0.01795249 0.22294618 0.09001362 0.07842004 0.04450376], sum to 1.0000
[2019-04-16 12:05:13,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8345
[2019-04-16 12:05:13,744] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-6.566666666666666, 49.66666666666666, 0.0, 0.0, 19.0, 21.51123195604695, -0.4647072333312272, 0.0, 1.0, 50.0, 72.5044171724057], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2424000.0000, 
sim time next is 2425200.0000, 
raw observation next is [-6.933333333333334, 51.33333333333333, 0.0, 0.0, 19.0, 21.95472494611727, -0.4434500383499794, 0.0, 1.0, 55.0, 49.50431283545067], 
processed observation next is [0.0, 0.043478260869565216, 0.270544783010157, 0.5133333333333333, 0.0, 0.0, 0.08333333333333333, 0.3295604121764392, 0.35218332055000684, 0.0, 1.0, 0.8, 0.4950431283545067], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04813222], dtype=float32), 0.17074183]. 
=============================================
[2019-04-16 12:05:14,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.25918996 0.05824963 0.03766822 0.05658622 0.03034596 0.09565009
 0.01375174 0.23734872 0.08715201 0.07699019 0.0470673 ], sum to 1.0000
[2019-04-16 12:05:14,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5227
[2019-04-16 12:05:14,728] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 35.66666666666667, 0.0, 0.0, 19.0, 22.7559276372564, -0.4227663748932528, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 2496000.0000, 
sim time next is 2497200.0000, 
raw observation next is [-1.2, 34.33333333333334, 0.0, 0.0, 19.0, 22.42369531867452, -0.36056903489217, 0.0, 1.0, 40.0, 49.361930147326746], 
processed observation next is [0.0, 0.9130434782608695, 0.42936288088642666, 0.34333333333333343, 0.0, 0.0, 0.08333333333333333, 0.3686412765562099, 0.37981032170261003, 0.0, 1.0, 0.5, 0.49361930147326744], 
reward next is 0.1314, 
noisyNet noise sample is [array([2.176325], dtype=float32), 1.0761918]. 
=============================================
[2019-04-16 12:05:21,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.30215657 0.035151   0.02593161 0.03072292 0.01897956 0.10519891
 0.00970228 0.33420026 0.05101141 0.05893997 0.02800547], sum to 1.0000
[2019-04-16 12:05:21,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5054
[2019-04-16 12:05:21,383] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [1.833333333333333, 33.0, 210.1666666666667, 98.66666666666666, 22.5, 26.93081584836098, 0.4839051431633205, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 2551200.0000, 
sim time next is 2552400.0000, 
raw observation next is [2.2, 30.0, 194.5, 252.0, 22.5, 26.67061838181751, 0.5490427728980699, 1.0, 1.0, 40.0, 49.0094924282938], 
processed observation next is [1.0, 0.5652173913043478, 0.5235457063711911, 0.3, 0.6483333333333333, 0.27845303867403315, 0.375, 0.7225515318181257, 0.68301425763269, 1.0, 1.0, 0.5, 0.490094924282938], 
reward next is 0.1349, 
noisyNet noise sample is [array([-1.5615176], dtype=float32), 0.81015444]. 
=============================================
[2019-04-16 12:05:23,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.28166962 0.05380885 0.03187886 0.0470706  0.02643993 0.0913718
 0.01396646 0.290505   0.06798723 0.05308259 0.04221916], sum to 1.0000
[2019-04-16 12:05:23,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4819
[2019-04-16 12:05:23,341] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-4.633333333333334, 64.0, 142.1666666666667, 244.3333333333333, 22.5, 23.63788686997894, -0.1657887941886638, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 2629200.0000, 
sim time next is 2630400.0000, 
raw observation next is [-4.266666666666667, 63.0, 164.0, 257.6666666666667, 22.5, 23.7168529531218, -0.02263156824655524, 1.0, 1.0, 40.0, 52.93377451642087], 
processed observation next is [1.0, 0.43478260869565216, 0.3444136657433057, 0.63, 0.5466666666666666, 0.2847145488029466, 0.375, 0.4764044127601501, 0.49245614391781495, 1.0, 1.0, 0.5, 0.5293377451642087], 
reward next is 0.0957, 
noisyNet noise sample is [array([-0.17899442], dtype=float32), -0.0035120843]. 
=============================================
[2019-04-16 12:05:27,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.2645847  0.04529619 0.02094647 0.03471908 0.01775468 0.13384122
 0.00907738 0.33761483 0.05655617 0.04747805 0.03213122], sum to 1.0000
[2019-04-16 12:05:27,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9079
[2019-04-16 12:05:27,227] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-4.533333333333333, 55.33333333333334, 103.1666666666667, 742.1666666666667, 22.5, 25.02992444427977, 0.2416373483504491, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2730000.0000, 
sim time next is 2731200.0000, 
raw observation next is [-4.266666666666667, 54.66666666666667, 99.33333333333333, 713.1666666666667, 22.5, 25.18325443350804, 0.3999339687541419, 1.0, 1.0, 55.0, 58.43443167686573], 
processed observation next is [1.0, 0.6086956521739131, 0.3444136657433057, 0.5466666666666667, 0.3311111111111111, 0.7880294659300185, 0.375, 0.59860453612567, 0.6333113229180473, 1.0, 1.0, 0.8, 0.5843443167686573], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0242308], dtype=float32), -1.272939]. 
=============================================
[2019-04-16 12:05:31,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.2607367  0.05204643 0.03041122 0.03906121 0.02115035 0.1314172
 0.00922036 0.2985929  0.06401054 0.07301319 0.02033992], sum to 1.0000
[2019-04-16 12:05:31,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4723
[2019-04-16 12:05:31,498] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-1.666666666666667, 58.33333333333334, 0.0, 0.0, 19.0, 23.79667474657956, -0.04691398312799888, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 3001200.0000, 
sim time next is 3002400.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 19.0, 23.56615680866151, 0.007707919612190935, 0.0, 1.0, 40.0, 51.28278119900581], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6, 0.0, 0.0, 0.08333333333333333, 0.46384640072179256, 0.502569306537397, 0.0, 1.0, 0.5, 0.5128278119900581], 
reward next is 0.1122, 
noisyNet noise sample is [array([-1.4845815], dtype=float32), -1.0561554]. 
=============================================
[2019-04-16 12:05:35,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.2820525  0.05136415 0.03261926 0.03683616 0.01907401 0.10053428
 0.01061719 0.3013007  0.07146518 0.06413255 0.03000411], sum to 1.0000
[2019-04-16 12:05:35,912] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3806
[2019-04-16 12:05:35,951] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 92.0, 0.0, 0.0, 19.0, 23.277581267802, -0.08090264835456647, 0.0, 1.0, 25.0, 30.497647280716265], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 3096000.0000, 
sim time next is 3097200.0000, 
raw observation next is [-1.0, 94.66666666666667, 0.0, 0.0, 19.0, 23.31895898398115, -0.09703568823673576, 0.0, 1.0, 30.0, 27.34620319260346], 
processed observation next is [0.0, 0.8695652173913043, 0.4349030470914128, 0.9466666666666668, 0.0, 0.0, 0.08333333333333333, 0.44324658199842926, 0.46765477058775473, 0.0, 1.0, 0.3, 0.27346203192603463], 
reward next is 0.5015, 
noisyNet noise sample is [array([0.11917242], dtype=float32), 0.360915]. 
=============================================
[2019-04-16 12:05:37,441] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.33902067 0.04498399 0.02201822 0.0290154  0.01793563 0.12397016
 0.0055901  0.2691126  0.04877234 0.08087497 0.01870593], sum to 1.0000
[2019-04-16 12:05:37,442] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2965
[2019-04-16 12:05:37,471] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 82.0, 0.0, 0.0, 19.0, 24.06807251938562, 0.09126244987698383, 0.0, 1.0, 20.0, 36.201749132468414], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3088800.0000, 
sim time next is 3090000.0000, 
raw observation next is [-0.7333333333333334, 85.33333333333334, 0.0, 0.0, 19.0, 23.90316067082572, -0.01118497972464859, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.44228993536472766, 0.8533333333333334, 0.0, 0.0, 0.08333333333333333, 0.49193005590214334, 0.49627167342511713, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4570457], dtype=float32), 0.88693374]. 
=============================================
[2019-04-16 12:05:37,481] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[2.657712 ]
 [2.622206 ]
 [2.5626569]
 [2.6217647]
 [2.4550471]
 [2.4310384]
 [2.4549623]
 [2.442163 ]
 [2.5180452]
 [2.4906485]
 [2.5008335]
 [2.4753902]
 [2.4375653]
 [2.3317528]
 [2.4543772]
 [2.3960595]
 [2.2985163]
 [2.3954792]
 [2.2024112]
 [2.323354 ]
 [2.2617352]
 [2.1527615]
 [2.1674275]
 [2.2238972]
 [2.199891 ]], R is [[ 3.64544964]
 [ 4.17197752]
 [ 5.13025761]
 [ 5.66312075]
 [ 5.73242903]
 [ 6.0228796 ]
 [ 6.10998583]
 [ 6.18682146]
 [ 6.41452503]
 [ 7.35037994]
 [ 8.27687645]
 [ 8.19410801]
 [ 8.37060261]
 [ 9.28689671]
 [ 9.54153252]
 [ 9.61418438]
 [10.10182476]
 [10.06918812]
 [ 9.96849632]
 [10.15852642]
 [10.05694103]
 [10.95637131]
 [11.34206676]
 [11.61531067]
 [11.99211407]].
[2019-04-16 12:05:40,390] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.36370194 0.02724837 0.01835939 0.0174799  0.01046392 0.104022
 0.00269861 0.36833963 0.03913544 0.03474308 0.01380776], sum to 1.0000
[2019-04-16 12:05:40,390] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0042
[2019-04-16 12:05:40,411] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 69.0, 0.0, 0.0, 22.5, 25.54585521187738, 0.52524885385248, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3260400.0000, 
sim time next is 3261600.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 22.5, 25.3983294094888, 0.5002157595335549, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.65, 0.0, 0.0, 0.375, 0.6165274507907332, 0.666738586511185, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13944656], dtype=float32), 0.107392445]. 
=============================================
[2019-04-16 12:05:42,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.22527024 0.0699973  0.05427547 0.05638383 0.02524841 0.14719668
 0.013708   0.22883888 0.06901619 0.06942345 0.04064162], sum to 1.0000
[2019-04-16 12:05:42,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6187
[2019-04-16 12:05:42,643] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.666666666666666, 75.0, 0.0, 0.0, 19.0, 23.36294710042106, -0.1201928857304551, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3385200.0000, 
sim time next is 3386400.0000, 
raw observation next is [-5.333333333333333, 73.0, 0.0, 0.0, 19.0, 23.24010496154973, -0.04679222796449561, 0.0, 1.0, 50.0, 56.29682886450266], 
processed observation next is [1.0, 0.17391304347826086, 0.3148661126500462, 0.73, 0.0, 0.0, 0.08333333333333333, 0.43667541346247746, 0.48440259067850144, 0.0, 1.0, 0.7, 0.5629682886450266], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87980443], dtype=float32), 0.44269145]. 
=============================================
[2019-04-16 12:05:43,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.30230266 0.02524557 0.01849972 0.01677002 0.01115764 0.13295113
 0.00281471 0.4085464  0.03047876 0.03882568 0.01240766], sum to 1.0000
[2019-04-16 12:05:43,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3672
[2019-04-16 12:05:43,176] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 22.5, 26.87092711793531, 0.832052173715347, 1.0, 1.0, 50.0, 50.29656191452473], 
current ob forecast is [], 
actual action is [1, 35.0], 
sim time this is 3262800.0000, 
sim time next is 3264000.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 22.5, 26.94376640133584, 0.8244161725742059, 1.0, 1.0, 35.0, 31.615891232040546], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.65, 0.0, 0.0, 0.375, 0.7453138667779866, 0.7748053908580687, 1.0, 1.0, 0.4, 0.31615891232040544], 
reward next is 0.3838, 
noisyNet noise sample is [array([0.49082828], dtype=float32), -0.10451936]. 
=============================================
[2019-04-16 12:05:48,931] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.28634018 0.05276139 0.03116893 0.04313863 0.02130613 0.09826371
 0.01060195 0.28148648 0.07309208 0.07278996 0.02905056], sum to 1.0000
[2019-04-16 12:05:48,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1789
[2019-04-16 12:05:48,948] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.333333333333334, 66.66666666666667, 0.0, 0.0, 19.0, 24.964084442897, 0.3119380873670258, 0.0, 1.0, 50.0, 34.16112135802915], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3561600.0000, 
sim time next is 3562800.0000, 
raw observation next is [-5.666666666666667, 68.33333333333333, 0.0, 0.0, 19.0, 24.69967437952838, 0.1517553794322187, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.30563250230840255, 0.6833333333333332, 0.0, 0.0, 0.08333333333333333, 0.5583061982940315, 0.5505851264774062, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.43117183], dtype=float32), 0.18563241]. 
=============================================
[2019-04-16 12:05:52,082] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.27400702 0.05584977 0.02070546 0.04059753 0.02150066 0.13270694
 0.00587127 0.26715457 0.07057285 0.08203112 0.02900277], sum to 1.0000
[2019-04-16 12:05:52,083] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1323
[2019-04-16 12:05:52,095] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 99.33333333333333, 773.1666666666667, 19.0, 23.67020076875433, 0.0978977499557262, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3595200.0000, 
sim time next is 3596400.0000, 
raw observation next is [-1.0, 42.0, 94.0, 743.5, 19.0, 23.57707876232811, 0.0797840309810229, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4349030470914128, 0.42, 0.31333333333333335, 0.8215469613259668, 0.08333333333333333, 0.4647565635273425, 0.5265946769936743, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4340396], dtype=float32), 1.2160645]. 
=============================================
[2019-04-16 12:05:57,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.35969013 0.01461695 0.01243339 0.01709866 0.00756668 0.07739615
 0.00344931 0.42310405 0.02786212 0.04386473 0.01291787], sum to 1.0000
[2019-04-16 12:05:57,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9780
[2019-04-16 12:05:57,461] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.666666666666667, 49.0, 0.0, 0.0, 22.5, 27.58334184603277, 0.8977755452871058, 1.0, 1.0, 50.0, 29.61726649159881], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3867600.0000, 
sim time next is 3868800.0000, 
raw observation next is [1.333333333333333, 50.0, 0.0, 0.0, 22.5, 27.33768246514484, 0.8880861875240603, 1.0, 1.0, 60.0, 39.406880921997015], 
processed observation next is [1.0, 0.782608695652174, 0.4995383194829178, 0.5, 0.0, 0.0, 0.375, 0.7781402054287367, 0.7960287291746867, 1.0, 1.0, 0.9, 0.3940688092199702], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24213645], dtype=float32), 2.0820057]. 
=============================================
[2019-04-16 12:05:57,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.34910002 0.02994078 0.0130263  0.01880701 0.01229488 0.14620996
 0.00392743 0.32381967 0.04285897 0.0420772  0.01793786], sum to 1.0000
[2019-04-16 12:05:57,662] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8218
[2019-04-16 12:05:57,731] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.666666666666667, 46.0, 83.16666666666666, 689.3333333333333, 22.5, 27.66008427962318, 0.6472918250181454, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3858000.0000, 
sim time next is 3859200.0000, 
raw observation next is [3.0, 45.0, 75.5, 634.0, 22.5, 27.11272040661864, 0.9147585778714992, 1.0, 1.0, 50.0, 38.28925065813016], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.25166666666666665, 0.7005524861878453, 0.375, 0.7593933672182199, 0.8049195259571663, 1.0, 1.0, 0.7, 0.3828925065813016], 
reward next is 0.0921, 
noisyNet noise sample is [array([-1.8680279], dtype=float32), 0.40105018]. 
=============================================
[2019-04-16 12:05:57,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.24252793 0.06154472 0.03793271 0.04502198 0.01828402 0.13537577
 0.00886309 0.3091681  0.04263478 0.07022943 0.02841743], sum to 1.0000
[2019-04-16 12:05:57,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8646
[2019-04-16 12:05:57,760] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 25.64191740072084, 0.4470439887051287, 0.0, 1.0, 35.0, 48.87491964463258], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 3729600.0000, 
sim time next is 3730800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 25.66087530089755, 0.4684974401675762, 0.0, 1.0, 55.0, 45.26930392722612], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.638406275074796, 0.6561658133891921, 0.0, 1.0, 0.8, 0.4526930392722612], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6652556], dtype=float32), -0.16790374]. 
=============================================
[2019-04-16 12:06:03,447] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.220821   0.05533022 0.0465003  0.04769075 0.02586104 0.14419223
 0.01156768 0.29025805 0.0521545  0.0758679  0.02975629], sum to 1.0000
[2019-04-16 12:06:03,448] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7149
[2019-04-16 12:06:03,482] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.333333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 24.328924629748, 0.2455354159136693, 0.0, 1.0, 60.0, 60.218765156948265], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3910800.0000, 
sim time next is 3912000.0000, 
raw observation next is [-6.666666666666666, 62.33333333333333, 0.0, 0.0, 19.0, 24.78488811797854, 0.2638496344118746, 0.0, 1.0, 50.0, 41.59207746336579], 
processed observation next is [1.0, 0.2608695652173913, 0.2779316712834719, 0.6233333333333333, 0.0, 0.0, 0.08333333333333333, 0.5654073431648783, 0.5879498781372915, 0.0, 1.0, 0.7, 0.4159207746336579], 
reward next is 0.0591, 
noisyNet noise sample is [array([-0.18584448], dtype=float32), 0.41801956]. 
=============================================
[2019-04-16 12:06:03,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.2904778  0.03774409 0.02480436 0.03601709 0.0090161  0.16073556
 0.00424593 0.33071017 0.04882742 0.03884809 0.01857332], sum to 1.0000
[2019-04-16 12:06:03,856] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6617
[2019-04-16 12:06:03,904] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.333333333333333, 22.0, 101.5, 780.3333333333334, 22.5, 26.1748394909929, 0.5023121792495083, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4027200.0000, 
sim time next is 4028400.0000, 
raw observation next is [-2.0, 20.0, 96.5, 753.0, 22.5, 26.32759522332361, 0.6289036853762987, 1.0, 1.0, 50.0, 46.64585815927464], 
processed observation next is [1.0, 0.6521739130434783, 0.40720221606648205, 0.2, 0.32166666666666666, 0.8320441988950277, 0.375, 0.6939662686103008, 0.7096345617920995, 1.0, 1.0, 0.7, 0.4664585815927464], 
reward next is 0.0085, 
noisyNet noise sample is [array([-0.78891534], dtype=float32), 0.7208117]. 
=============================================
[2019-04-16 12:06:05,273] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.23247266 0.06041034 0.04388101 0.04967916 0.02900574 0.14929582
 0.01209479 0.25755453 0.05404078 0.07861517 0.03295005], sum to 1.0000
[2019-04-16 12:06:05,273] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1677
[2019-04-16 12:06:05,300] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 38.66666666666667, 0.0, 0.0, 19.0, 23.44738015666288, -0.02014087584830388, 0.0, 1.0, 55.0, 48.45505396129998], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4076400.0000, 
sim time next is 4077600.0000, 
raw observation next is [-4.333333333333334, 36.33333333333333, 0.0, 0.0, 19.0, 23.42012624137124, -0.1704099480670273, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.3425669436749769, 0.3633333333333333, 0.0, 0.0, 0.08333333333333333, 0.4516771867809366, 0.44319668397765755, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.19459414], dtype=float32), -0.78275675]. 
=============================================
[2019-04-16 12:06:05,649] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.27714002 0.03437798 0.0175055  0.02369197 0.01639188 0.11684732
 0.00528252 0.38062704 0.06248459 0.0473608  0.01829041], sum to 1.0000
[2019-04-16 12:06:05,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2045
[2019-04-16 12:06:05,686] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 26.0, 109.0, 812.0, 22.5, 26.41302429829321, 0.5377494072364309, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4024800.0000, 
sim time next is 4026000.0000, 
raw observation next is [-2.666666666666667, 24.0, 105.6666666666667, 800.0, 22.5, 26.33971355748622, 0.5154301024540747, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.38873499538319484, 0.24, 0.3522222222222223, 0.8839779005524862, 0.375, 0.6949761297905184, 0.6718100341513583, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15958975], dtype=float32), 1.4142635]. 
=============================================
[2019-04-16 12:06:07,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.22758612 0.06595824 0.05745137 0.04476819 0.02676916 0.17180857
 0.01349155 0.20961282 0.05962833 0.09072228 0.03220336], sum to 1.0000
[2019-04-16 12:06:07,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9768
[2019-04-16 12:06:07,614] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-4.0, 34.0, 0.0, 0.0, 19.0, 24.19004780875488, 0.07921280990987221, 0.0, 1.0, 50.0, 41.097918919445135], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 4078800.0000, 
sim time next is 4080000.0000, 
raw observation next is [-4.0, 35.33333333333334, 0.0, 0.0, 19.0, 24.31039380024793, 0.1221479163819826, 0.0, 1.0, 65.0, 70.27428996537665], 
processed observation next is [1.0, 0.21739130434782608, 0.3518005540166205, 0.35333333333333344, 0.0, 0.0, 0.08333333333333333, 0.5258661500206608, 0.5407159721273275, 0.0, 1.0, 1.0, 0.7027428996537666], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5079927], dtype=float32), 1.6576443]. 
=============================================
[2019-04-16 12:06:07,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[2.839012 ]
 [2.9364183]
 [2.9744222]
 [2.7642379]
 [2.9220073]
 [2.6659386]
 [2.780758 ]
 [2.5332987]
 [2.6636684]
 [2.958322 ]
 [3.0703204]
 [3.2453961]
 [3.0229933]
 [3.3418157]
 [3.4514081]
 [3.5016694]
 [3.667464 ]
 [3.6803734]
 [3.7053742]
 [3.7766016]
 [3.766739 ]
 [4.0223775]
 [3.925815 ]
 [3.9180052]
 [3.8712661]], R is [[ 2.99508023]
 [ 3.02915025]
 [ 2.99885869]
 [ 3.24018478]
 [ 3.40961695]
 [ 3.37552071]
 [ 4.3417654 ]
 [ 4.29834795]
 [ 5.25536442]
 [ 6.20281076]
 [ 6.45091343]
 [ 6.45209217]
 [ 6.38757133]
 [ 7.32369566]
 [ 7.25045872]
 [ 8.17795372]
 [ 9.09617424]
 [10.00521278]
 [10.54683399]
 [10.55704308]
 [10.57127953]
 [10.58428001]
 [10.61749744]
 [10.88249779]
 [10.77367306]].
[2019-04-16 12:06:07,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.38220775 0.04407221 0.02479913 0.02550024 0.01330369 0.10234945
 0.0044472  0.2656508  0.04541729 0.06595083 0.02630133], sum to 1.0000
[2019-04-16 12:06:07,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2055
[2019-04-16 12:06:07,818] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.333333333333334, 29.66666666666667, 0.0, 0.0, 19.0, 24.98199522682004, 0.3243424714605207, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4051200.0000, 
sim time next is 4052400.0000, 
raw observation next is [-4.666666666666666, 30.33333333333333, 0.0, 0.0, 19.0, 24.64511563917056, 0.262306722925546, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.33333333333333337, 0.3033333333333333, 0.0, 0.0, 0.08333333333333333, 0.5537596365975466, 0.5874355743085153, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.44667956], dtype=float32), 0.024421982]. 
=============================================
[2019-04-16 12:06:13,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.26009545 0.06708665 0.04153512 0.04464449 0.01960061 0.10125455
 0.00589539 0.30858558 0.04202149 0.0829855  0.02629512], sum to 1.0000
[2019-04-16 12:06:13,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8471
[2019-04-16 12:06:13,307] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 68.0, 0.0, 0.0, 19.0, 26.08759070206677, 0.6989091396657079, 0.0, 1.0, 40.0, 25.098193542867016], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4428000.0000, 
sim time next is 4429200.0000, 
raw observation next is [2.666666666666667, 72.0, 0.0, 0.0, 19.0, 26.15179896537501, 0.7152193764403988, 0.0, 1.0, 50.0, 38.87181098644295], 
processed observation next is [1.0, 0.2608695652173913, 0.5364727608494922, 0.72, 0.0, 0.0, 0.08333333333333333, 0.6793165804479177, 0.7384064588134662, 0.0, 1.0, 0.7, 0.3887181098644295], 
reward next is 0.0863, 
noisyNet noise sample is [array([-0.38605785], dtype=float32), 0.077758096]. 
=============================================
[2019-04-16 12:06:20,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.27416292 0.03777471 0.02686255 0.04459156 0.01352445 0.11406152
 0.00430719 0.35371107 0.04495336 0.06393231 0.02211832], sum to 1.0000
[2019-04-16 12:06:20,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5781
[2019-04-16 12:06:20,357] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 58.66666666666666, 0.0, 0.0, 19.0, 26.09002417962816, 0.661920307533563, 0.0, 1.0, 50.0, 35.74673823658712], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4671600.0000, 
sim time next is 4672800.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 19.0, 26.18048882329254, 0.6621871483649042, 0.0, 1.0, 50.0, 35.120734030703446], 
processed observation next is [1.0, 0.08695652173913043, 0.518005540166205, 0.62, 0.0, 0.0, 0.08333333333333333, 0.6817074019410448, 0.7207290494549681, 0.0, 1.0, 0.7, 0.35120734030703443], 
reward next is 0.1238, 
noisyNet noise sample is [array([-0.24373639], dtype=float32), -0.924938]. 
=============================================
[2019-04-16 12:06:27,715] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:27,853] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:27,887] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:28,022] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:28,121] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:28,289] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:28,716] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:28,716] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:28,718] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run3
[2019-04-16 12:06:28,855] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:28,855] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:28,858] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run3
[2019-04-16 12:06:29,118] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:29,118] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:29,124] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run3
[2019-04-16 12:06:30,025] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:30,162] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:30,193] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:30,313] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.31760308 0.01569056 0.01264985 0.01180831 0.00812263 0.11356676
 0.00149837 0.4424083  0.03094022 0.03211104 0.01360094], sum to 1.0000
[2019-04-16 12:06:30,314] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5858
[2019-04-16 12:06:30,337] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:30,364] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [8.333333333333334, 25.66666666666667, 94.83333333333334, 781.5, 22.5, 27.36634128835734, 0.9336745725860128, 1.0, 1.0, 50.0, 29.48800720592256], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4980000.0000, 
sim time next is 4981200.0000, 
raw observation next is [8.666666666666668, 25.33333333333333, 88.66666666666667, 751.8333333333333, 22.5, 27.76259776356056, 0.9662905309274956, 1.0, 1.0, 50.0, 7.976070546436601], 
processed observation next is [1.0, 0.6521739130434783, 0.7026777469990768, 0.2533333333333333, 0.29555555555555557, 0.8307550644567219, 0.375, 0.8135498136300466, 0.8220968436424986, 1.0, 1.0, 0.7, 0.079760705464366], 
reward next is 0.3952, 
noisyNet noise sample is [array([0.33807445], dtype=float32), -0.906758]. 
=============================================
[2019-04-16 12:06:30,666] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.2887721  0.04467408 0.03250929 0.03985532 0.01333776 0.10401057
 0.00657957 0.32535928 0.04070744 0.07909292 0.02510172], sum to 1.0000
[2019-04-16 12:06:30,666] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0898
[2019-04-16 12:06:30,677] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 46.0, 46.5, 280.0, 22.5, 23.79741508091338, -0.07806008356630524, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4953600.0000, 
sim time next is 4954800.0000, 
raw observation next is [-1.666666666666667, 43.66666666666667, 77.5, 466.6666666666667, 22.5, 23.24721118308047, -0.1284618867308886, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4164358264081256, 0.4366666666666667, 0.25833333333333336, 0.5156537753222836, 0.375, 0.43726759859003916, 0.4571793710897038, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4279506], dtype=float32), 0.07709749]. 
=============================================
[2019-04-16 12:06:30,967] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:31,031] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:31,031] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:31,033] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run3
[2019-04-16 12:06:31,137] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:31,163] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:31,163] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:31,168] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run3
[2019-04-16 12:06:31,261] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:31,298] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:31,453] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:31,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:31,564] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:31,707] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.40127644 0.01872401 0.01600113 0.02660647 0.00883904 0.06286977
 0.00290543 0.35505012 0.03497494 0.05614888 0.01660382], sum to 1.0000
[2019-04-16 12:06:31,707] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6738
[2019-04-16 12:06:31,728] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:31,740] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [8.7, 19.0, 0.0, 0.0, 19.0, 27.47393111810524, 0.9088534552264481, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 5090400.0000, 
sim time next is 5091600.0000, 
raw observation next is [8.6, 19.33333333333334, 0.0, 0.0, 19.0, 27.49987147316826, 0.9517024333538009, 0.0, 1.0, 50.0, 48.27782102150811], 
processed observation next is [1.0, 0.9565217391304348, 0.700831024930748, 0.19333333333333338, 0.0, 0.0, 0.08333333333333333, 0.791655956097355, 0.817234144451267, 0.0, 1.0, 0.7, 0.4827782102150811], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0555497], dtype=float32), -0.48223096]. 
=============================================
[2019-04-16 12:06:31,852] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:31,869] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:31,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:31,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:31,963] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run3
[2019-04-16 12:06:32,023] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:32,023] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:32,257] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:32,257] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:32,259] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run3
[2019-04-16 12:06:32,297] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:32,297] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:32,301] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run3
[2019-04-16 12:06:32,558] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:32,558] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:32,560] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run3
[2019-04-16 12:06:32,851] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:32,853] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:32,853] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:32,855] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run3
[2019-04-16 12:06:32,884] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:32,885] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:32,890] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run3
[2019-04-16 12:06:33,096] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:33,852] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:33,852] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:33,854] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run3
[2019-04-16 12:06:34,624] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:34,811] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:34,976] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:35,229] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:35,621] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:35,621] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:35,623] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run3
[2019-04-16 12:06:35,977] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:35,977] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:35,980] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run3
[2019-04-16 12:06:36,037] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:36,274] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:36,587] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:06:36,953] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-16 12:06:37,038] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:37,038] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:37,040] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run3
[2019-04-16 12:06:37,588] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:06:37,588] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:06:37,590] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run3
[2019-04-16 12:06:45,889] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.25210994 0.04195813 0.02989812 0.03933228 0.01955411 0.15424079
 0.00524688 0.33197305 0.03343371 0.06858488 0.02366809], sum to 1.0000
[2019-04-16 12:06:45,889] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1280
[2019-04-16 12:06:45,950] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 22.5, 21.52347326117848, -0.5404641947978074, 1.0, 1.0, 55.0, 67.88413609860547], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 200400.0000, 
sim time next is 201600.0000, 
raw observation next is [-8.9, 78.0, 17.0, 157.0, 22.5, 21.69107172598044, -0.6441664908486512, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.21606648199445982, 0.78, 0.056666666666666664, 0.1734806629834254, 0.375, 0.30758931049836996, 0.28527783638378296, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.4804, 
noisyNet noise sample is [array([-1.2426522], dtype=float32), -1.1858954]. 
=============================================
[2019-04-16 12:06:48,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.293365   0.04048588 0.02513828 0.02554151 0.01145554 0.11183586
 0.00409347 0.35691735 0.04010725 0.07213151 0.0189283 ], sum to 1.0000
[2019-04-16 12:06:48,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2304
[2019-04-16 12:06:48,846] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 67.5, 0.0, 19.0, 23.17042625392556, 0.0004718428412253672, 0.0, 1.0, 60.0, 60.37005928505374], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 39600.0000, 
sim time next is 40800.0000, 
raw observation next is [7.7, 93.0, 72.5, 0.0, 19.0, 23.41751017890763, -0.1202882049600316, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.6759002770083103, 0.93, 0.24166666666666667, 0.0, 0.08333333333333333, 0.45145918157563586, 0.4599039316799895, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15216634], dtype=float32), 0.05642352]. 
=============================================
[2019-04-16 12:06:52,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.29547343 0.02829498 0.01790502 0.01508391 0.00835433 0.0782747
 0.00284391 0.48181465 0.02241916 0.03420691 0.01532898], sum to 1.0000
[2019-04-16 12:06:52,436] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2924
[2019-04-16 12:06:52,456] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 65.0, 139.0, 0.0, 22.5, 23.01301168646686, -0.09489454168036456, 1.0, 1.0, 65.0, 91.51180130413184], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 219600.0000, 
sim time next is 220800.0000, 
raw observation next is [-4.133333333333334, 64.0, 145.6666666666667, 0.0, 22.5, 23.39808912720279, -0.1783694557215443, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.34810710987996313, 0.64, 0.48555555555555574, 0.0, 0.375, 0.4498407606002326, 0.4405435147594852, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2528147], dtype=float32), 0.22548479]. 
=============================================
[2019-04-16 12:06:57,655] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.24248852 0.07107323 0.05278243 0.04040912 0.01837311 0.13984813
 0.00934202 0.28271398 0.04494452 0.0672585  0.03076649], sum to 1.0000
[2019-04-16 12:06:57,655] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8216
[2019-04-16 12:06:57,667] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.22194368 0.07202135 0.04419647 0.05260177 0.02264162 0.12000877
 0.00920259 0.27704626 0.05422567 0.09162623 0.03448571], sum to 1.0000
[2019-04-16 12:06:57,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0860
[2019-04-16 12:06:57,684] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.3, 69.0, 0.0, 0.0, 19.0, 21.39997924919732, -0.5338223278601311, 0.0, 1.0, 35.0, 48.1452700190993], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 272400.0000, 
sim time next is 273600.0000, 
raw observation next is [-9.5, 70.0, 0.0, 0.0, 19.0, 21.31906842589516, -0.73384922230224, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.1994459833795014, 0.7, 0.0, 0.0, 0.08333333333333333, 0.2765890354912634, 0.25538359256591997, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.78832036], dtype=float32), 0.24760899]. 
=============================================
[2019-04-16 12:06:57,698] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 19.0, 19.27112136775888, -1.00039867126298, 0.0, 1.0, 50.0, 50.118050738400605], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 362400.0000, 
sim time next is 363600.0000, 
raw observation next is [-15.6, 73.0, 0.0, 0.0, 19.0, 19.5688631714943, -0.9741386758822852, 0.0, 1.0, 50.0, 49.366843456893065], 
processed observation next is [1.0, 0.21739130434782608, 0.030470914127423816, 0.73, 0.0, 0.0, 0.08333333333333333, 0.130738597624525, 0.17528710803923828, 0.0, 1.0, 0.7, 0.49366843456893067], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.2643156], dtype=float32), -0.6126616]. 
=============================================
[2019-04-16 12:07:06,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.31371406 0.03249946 0.02218103 0.02991731 0.00848348 0.10376578
 0.00268923 0.38080007 0.02850239 0.06492212 0.01252515], sum to 1.0000
[2019-04-16 12:07:06,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1676
[2019-04-16 12:07:06,543] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 54.0, 0.0, 0.0, 19.0, 20.69751251256162, -0.6236803669208025, 0.0, 1.0, 60.0, 84.18027716182903], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 430800.0000, 
sim time next is 432000.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 19.0, 20.95097460154764, -0.7790177208185604, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.08333333333333333, 0.2459145501289699, 0.24032742639381321, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9157312], dtype=float32), -0.16184239]. 
=============================================
[2019-04-16 12:07:07,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.40836513 0.02673526 0.01686447 0.01802933 0.00804811 0.05601209
 0.00324559 0.38832936 0.02569062 0.0343685  0.01431146], sum to 1.0000
[2019-04-16 12:07:07,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0862
[2019-04-16 12:07:07,287] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.833333333333332, 41.33333333333334, 0.0, 0.0, 22.5, 21.40085943275818, -0.6602267090427213, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 416400.0000, 
sim time next is 417600.0000, 
raw observation next is [-10.0, 42.0, 0.0, 0.0, 22.5, 20.79492168661348, -0.7659430687752095, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.18559556786703602, 0.42, 0.0, 0.0, 0.375, 0.23291014055112344, 0.24468564374159685, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4747846], dtype=float32), 1.0267528]. 
=============================================
[2019-04-16 12:07:08,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.2740756  0.04828875 0.02218751 0.02821521 0.01514379 0.0986585
 0.00664558 0.36787865 0.04144182 0.07433405 0.02313057], sum to 1.0000
[2019-04-16 12:07:08,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5292
[2019-04-16 12:07:08,870] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-0.4, 88.33333333333334, 132.8333333333333, 109.3333333333333, 19.0, 21.87840894284875, -0.3859660949239892, 0.0, 1.0, 20.0, 40.904449465401605], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 553200.0000, 
sim time next is 554400.0000, 
raw observation next is [-0.6, 87.0, 110.5, 122.0, 19.0, 22.05635730709656, -0.3845867626608075, 0.0, 1.0, 50.0, 36.340085591851775], 
processed observation next is [0.0, 0.43478260869565216, 0.44598337950138506, 0.87, 0.36833333333333335, 0.13480662983425415, 0.08333333333333333, 0.33802977559138014, 0.3718044124463975, 0.0, 1.0, 0.7, 0.36340085591851773], 
reward next is 0.1116, 
noisyNet noise sample is [array([-1.4787943], dtype=float32), -1.1224784]. 
=============================================
[2019-04-16 12:07:13,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.2538074  0.03903659 0.02949428 0.02960492 0.01545887 0.13948461
 0.00607412 0.36972502 0.03837783 0.05438743 0.02454893], sum to 1.0000
[2019-04-16 12:07:13,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7486
[2019-04-16 12:07:13,255] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.28140584 0.05045684 0.03203306 0.0382922  0.01487936 0.0921458
 0.00625601 0.33038312 0.05392798 0.07724807 0.0229717 ], sum to 1.0000
[2019-04-16 12:07:13,255] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7689
[2019-04-16 12:07:13,294] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.533333333333334, 75.0, 26.66666666666667, 0.0, 22.5, 21.95302053405133, -0.5583492824138104, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 807600.0000, 
sim time next is 808800.0000, 
raw observation next is [-6.366666666666667, 75.0, 36.83333333333333, 0.0, 22.5, 22.34369412397955, -0.3795728452256812, 1.0, 1.0, 50.0, 61.59705105780333], 
processed observation next is [1.0, 0.34782608695652173, 0.28624192059095105, 0.75, 0.12277777777777776, 0.0, 0.375, 0.36197451033162914, 0.37347571825810627, 1.0, 1.0, 0.7, 0.6159705105780333], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6043992], dtype=float32), -0.89457005]. 
=============================================
[2019-04-16 12:07:13,326] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 19.0, 20.32741672947072, -0.6458506257434705, 0.0, 1.0, 55.0, 76.50641958266615], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 612000.0000, 
sim time next is 613200.0000, 
raw observation next is [-3.9, 82.33333333333334, 0.0, 0.0, 19.0, 20.89985303505741, -0.6016371874027583, 0.0, 1.0, 50.0, 44.03181802812499], 
processed observation next is [0.0, 0.08695652173913043, 0.3545706371191136, 0.8233333333333335, 0.0, 0.0, 0.08333333333333333, 0.24165441958811762, 0.2994542708657472, 0.0, 1.0, 0.7, 0.44031818028124986], 
reward next is 0.0347, 
noisyNet noise sample is [array([0.64603287], dtype=float32), 0.020231212]. 
=============================================
[2019-04-16 12:07:21,471] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [0.2786595  0.05884203 0.03353736 0.0330023  0.01082149 0.1452683
 0.00476375 0.30765885 0.03342612 0.07611346 0.01790682], sum to 1.0000
[2019-04-16 12:07:21,471] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8823
[2019-04-16 12:07:21,499] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-1.2, 76.0, 0.0, 0.0, 19.0, 21.99923309159664, -0.434901437785997, 0.0, 1.0, 25.0, 33.73710514754999], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 878400.0000, 
sim time next is 879600.0000, 
raw observation next is [-1.0, 74.66666666666667, 0.0, 0.0, 19.0, 22.0471307974727, -0.4328533702886308, 0.0, 1.0, 55.0, 46.09734471054863], 
processed observation next is [1.0, 0.17391304347826086, 0.4349030470914128, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.3372608997893917, 0.35571554323712307, 0.0, 1.0, 0.8, 0.4609734471054863], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19812724], dtype=float32), -0.83826816]. 
=============================================
[2019-04-16 12:07:25,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.35245097 0.02044484 0.0164952  0.01570065 0.00931216 0.06177824
 0.00222039 0.44712973 0.02335329 0.03747835 0.01363615], sum to 1.0000
[2019-04-16 12:07:25,294] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7690
[2019-04-16 12:07:25,334] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [12.56666666666667, 82.0, 87.00000000000001, 206.5, 22.5, 26.04786079113993, 0.6016194838330293, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1070400.0000, 
sim time next is 1071600.0000, 
raw observation next is [12.93333333333333, 81.0, 102.3333333333333, 195.0, 22.5, 26.23856204250556, 0.764779418731021, 1.0, 1.0, 50.0, 48.997619939503075], 
processed observation next is [1.0, 0.391304347826087, 0.8208679593721145, 0.81, 0.341111111111111, 0.2154696132596685, 0.375, 0.6865468368754634, 0.7549264729103403, 1.0, 1.0, 0.7, 0.48997619939503073], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5145485], dtype=float32), 0.04142777]. 
=============================================
[2019-04-16 12:07:25,365] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-16 12:07:25,370] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:07:25,371] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:07:25,371] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:07:25,371] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:07:25,371] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:07:25,371] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:07:25,375] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run4
[2019-04-16 12:07:25,387] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run4
[2019-04-16 12:07:25,387] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run4
[2019-04-16 12:08:34,048] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 1932.5956 117543.5184 816.6871
[2019-04-16 12:08:34,069] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:34,069] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:34,069] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:34,069] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:34,186] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:34,186] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:34,186] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:34,186] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:42,463] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 1884.0571 124664.7704 446.6500
[2019-04-16 12:08:42,482] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:42,482] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:42,482] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:42,482] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:42,595] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:42,595] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:42,595] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:42,595] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:44,099] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 1841.0956 128153.6957 235.8203
[2019-04-16 12:08:44,117] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:44,117] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:44,117] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:44,117] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:08:44,223] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:44,223] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:44,223] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:44,223] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:08:45,120] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 150000, evaluation results [150000.0, 1884.0571470240538, 124664.77038348812, 446.65004707576054, 1932.5955823352651, 117543.51836881712, 816.6870889216884, 1841.0956041950635, 128153.69574258407, 235.82029521964205]
[2019-04-16 12:08:48,643] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.31565037 0.02537195 0.02242266 0.01962095 0.00868236 0.06278528
 0.00369228 0.41773075 0.02591738 0.08210585 0.01602016], sum to 1.0000
[2019-04-16 12:08:48,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2853
[2019-04-16 12:08:48,658] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 19.0, 27.84441961998344, 1.132885161253841, 0.0, 0.0, 50.0, 25.264138198364865], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1192800.0000, 
sim time next is 1194000.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 19.0, 27.78613371465761, 1.066129997224675, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.9529085872576178, 0.67, 0.0, 0.0, 0.08333333333333333, 0.8155111428881341, 0.8553766657415584, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3890467], dtype=float32), 0.47919306]. 
=============================================
[2019-04-16 12:08:49,045] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.40477562 0.01775935 0.01272909 0.01521086 0.00550959 0.05904181
 0.00237843 0.39620736 0.02611595 0.04925971 0.01101221], sum to 1.0000
[2019-04-16 12:08:49,046] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7791
[2019-04-16 12:08:49,063] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [14.4, 96.0, 98.0, 0.0, 19.0, 27.8264089926445, 1.179997021215223, 0.0, 1.0, 50.0, 24.302688862089852], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1252800.0000, 
sim time next is 1254000.0000, 
raw observation next is [14.2, 97.33333333333333, 100.0, 0.0, 19.0, 27.8467219228498, 1.185249569572183, 0.0, 1.0, 50.0, 24.051258225696525], 
processed observation next is [0.0, 0.5217391304347826, 0.8559556786703602, 0.9733333333333333, 0.3333333333333333, 0.0, 0.08333333333333333, 0.8205601602374832, 0.8950831898573943, 0.0, 1.0, 0.7, 0.24051258225696526], 
reward next is 0.2345, 
noisyNet noise sample is [array([-1.0325866], dtype=float32), -1.6975971]. 
=============================================
[2019-04-16 12:08:50,359] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.35436758 0.02967222 0.01377937 0.02141492 0.00398913 0.07500488
 0.00111837 0.4380116  0.01202624 0.04230157 0.00831405], sum to 1.0000
[2019-04-16 12:08:50,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6484
[2019-04-16 12:08:50,392] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [11.8, 69.33333333333333, 0.0, 0.0, 19.0, 27.34325179715197, 1.030769979407952, 0.0, 1.0, 50.0, 26.056883987586822], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1122000.0000, 
sim time next is 1123200.0000, 
raw observation next is [11.6, 71.0, 0.0, 0.0, 19.0, 27.43857454713246, 1.03447385813158, 0.0, 1.0, 50.0, 27.457781219083387], 
processed observation next is [0.0, 0.0, 0.7839335180055402, 0.71, 0.0, 0.0, 0.08333333333333333, 0.7865478789277051, 0.8448246193771934, 0.0, 1.0, 0.7, 0.2745778121908339], 
reward next is 0.2004, 
noisyNet noise sample is [array([-1.2933632], dtype=float32), -0.0024160864]. 
=============================================
[2019-04-16 12:08:52,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5781174e-01 9.5596062e-03 5.8126943e-03 9.2720473e-03 1.8877501e-03
 4.5360543e-02 5.3382677e-04 3.3022818e-01 1.8117579e-02 1.6805304e-02
 4.6107392e-03], sum to 1.0000
[2019-04-16 12:08:52,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3118
[2019-04-16 12:08:52,173] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 22.5, 26.55809569909504, 0.8306084432639174, 0.0, 1.0, 50.0, 38.822009381096635], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1365600.0000, 
sim time next is 1366800.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 26.3161978342387, 0.6876941157919355, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.6930164861865583, 0.7292313719306452, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4118289], dtype=float32), -0.11539445]. 
=============================================
[2019-04-16 12:08:53,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.3804956  0.0436392  0.02814685 0.03105537 0.01516847 0.07758613
 0.00762039 0.28979334 0.03866602 0.05869263 0.02913587], sum to 1.0000
[2019-04-16 12:08:53,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8597
[2019-04-16 12:08:53,254] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [15.5, 93.0, 0.0, 0.0, 19.0, 27.45515190638243, 1.013725055580101, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1222800.0000, 
sim time next is 1224000.0000, 
raw observation next is [15.5, 93.0, 0.0, 0.0, 19.0, 27.39591511202086, 1.090549085073126, 0.0, 0.0, 50.0, 44.167038809968545], 
processed observation next is [0.0, 0.17391304347826086, 0.8919667590027703, 0.93, 0.0, 0.0, 0.08333333333333333, 0.7829929260017382, 0.8635163616910421, 0.0, 0.0, 0.7, 0.44167038809968545], 
reward next is 0.0333, 
noisyNet noise sample is [array([-1.2035269], dtype=float32), -0.19055393]. 
=============================================
[2019-04-16 12:08:53,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.3076407  0.03989929 0.02363114 0.02024981 0.00884888 0.11323833
 0.00180702 0.40681696 0.02613936 0.03961141 0.01211713], sum to 1.0000
[2019-04-16 12:08:53,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3905
[2019-04-16 12:08:53,923] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 19.0, 24.66892520234661, 0.3718601282133974, 0.0, 1.0, 50.0, 51.15648794849578], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 1399200.0000, 
sim time next is 1400400.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 24.79420529186616, 0.358090741552225, 0.0, 1.0, 30.0, 29.788441504033813], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5661837743221799, 0.6193635805174084, 0.0, 1.0, 0.3, 0.29788441504033814], 
reward next is 0.4771, 
noisyNet noise sample is [array([-0.26549754], dtype=float32), 0.092350505]. 
=============================================
[2019-04-16 12:08:54,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.54133373 0.01590516 0.00811114 0.00768266 0.00348542 0.05159436
 0.00087043 0.3135894  0.02266715 0.03000644 0.00475408], sum to 1.0000
[2019-04-16 12:08:54,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4042
[2019-04-16 12:08:54,022] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.9, 98.66666666666667, 0.0, 0.0, 19.0, 27.55756201799263, 1.147591035153618, 0.0, 1.0, 50.0, 29.12034058738012], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1272000.0000, 
sim time next is 1273200.0000, 
raw observation next is [9.600000000000001, 97.33333333333334, 0.0, 0.0, 19.0, 27.53066007411798, 1.069395124360053, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.7285318559556788, 0.9733333333333334, 0.0, 0.0, 0.08333333333333333, 0.7942216728431649, 0.856465041453351, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42706868], dtype=float32), -0.25070506]. 
=============================================
[2019-04-16 12:08:56,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.33507442 0.02404656 0.01818161 0.01657197 0.00645218 0.10516296
 0.00188954 0.40438202 0.01775026 0.0606992  0.0097893 ], sum to 1.0000
[2019-04-16 12:08:56,426] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9619
[2019-04-16 12:08:56,473] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [6.6, 97.0, 0.0, 0.0, 19.0, 26.01630640043193, 0.6201126946846124, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1659600.0000, 
sim time next is 1660800.0000, 
raw observation next is [6.233333333333333, 97.0, 0.0, 0.0, 19.0, 26.17605468734156, 0.7935302728779311, 0.0, 1.0, 60.0, 71.21038364156345], 
processed observation next is [1.0, 0.21739130434782608, 0.6352723915050786, 0.97, 0.0, 0.0, 0.08333333333333333, 0.6813378906117965, 0.7645100909593103, 0.0, 1.0, 0.9, 0.7121038364156346], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2245736], dtype=float32), 0.1872945]. 
=============================================
[2019-04-16 12:08:57,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.3640143  0.04736767 0.02480562 0.02364033 0.00627419 0.09858497
 0.00206542 0.33599776 0.02652943 0.06018072 0.01053965], sum to 1.0000
[2019-04-16 12:08:57,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5283
[2019-04-16 12:08:57,244] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 19.0, 23.84331647809211, 0.0641729627630133, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 1402800.0000, 
sim time next is 1404000.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 23.42664889541564, 0.1245814316496814, 0.0, 1.0, 40.0, 44.28466385119733], 
processed observation next is [1.0, 0.2608695652173913, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4522207412846366, 0.5415271438832271, 0.0, 1.0, 0.5, 0.4428466385119733], 
reward next is 0.1822, 
noisyNet noise sample is [array([-0.08736543], dtype=float32), 0.8729768]. 
=============================================
[2019-04-16 12:08:59,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.34057692 0.04564434 0.02183811 0.0243888  0.01222075 0.09551401
 0.00526879 0.34449467 0.03775715 0.05736459 0.01493184], sum to 1.0000
[2019-04-16 12:08:59,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0225
[2019-04-16 12:08:59,214] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 21.39501625418812, -0.5156681815080257, 0.0, 1.0, 50.0, 46.11473619560612], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1842000.0000, 
sim time next is 1843200.0000, 
raw observation next is [-6.7, 78.0, 14.0, 0.0, 19.0, 21.20591095309721, -0.6738274219817719, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.2770083102493075, 0.78, 0.04666666666666667, 0.0, 0.08333333333333333, 0.2671592460914341, 0.2753908593394094, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5909624], dtype=float32), -0.8505543]. 
=============================================
[2019-04-16 12:09:01,432] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.42121017 0.03583145 0.02210192 0.01680899 0.00975419 0.07756346
 0.00300431 0.31701595 0.0325354  0.04953717 0.01463686], sum to 1.0000
[2019-04-16 12:09:01,432] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3128
[2019-04-16 12:09:01,442] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 87.0, 13.5, 0.0, 19.0, 24.32550009596693, 0.08525146097383555, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1756800.0000, 
sim time next is 1758000.0000, 
raw observation next is [-1.7, 85.66666666666667, 21.83333333333334, 0.0, 19.0, 23.48194676788174, -0.05008326934707019, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.4155124653739613, 0.8566666666666667, 0.0727777777777778, 0.0, 0.08333333333333333, 0.4568288973234784, 0.4833055768843099, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26726872], dtype=float32), -0.80298734]. 
=============================================
[2019-04-16 12:09:02,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.41041654 0.01915819 0.02095458 0.01717668 0.00595835 0.04733383
 0.00220649 0.3954053  0.02500744 0.0490106  0.00737214], sum to 1.0000
[2019-04-16 12:09:02,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3199
[2019-04-16 12:09:02,042] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 81.0, 0.0, 0.0, 19.0, 22.44596527729916, -0.3087045134243783, 0.0, 1.0, 25.0, 40.66256117074323], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1812000.0000, 
sim time next is 1813200.0000, 
raw observation next is [-5.0, 80.0, 0.0, 0.0, 19.0, 22.15874245195679, -0.492228298772042, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.32409972299168976, 0.8, 0.0, 0.0, 0.08333333333333333, 0.3465618709963992, 0.3359239004093193, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.59623426], dtype=float32), -0.079934664]. 
=============================================
[2019-04-16 12:09:08,232] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.30556974 0.03118197 0.0294907  0.02694777 0.0127812  0.11856227
 0.00345426 0.3727609  0.02845246 0.05285322 0.01794551], sum to 1.0000
[2019-04-16 12:09:08,232] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9979
[2019-04-16 12:09:08,435] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 10, 
current raw observation is [-9.3, 89.33333333333334, 27.83333333333333, 17.66666666666667, 22.5, 20.00772656756726, -0.8105833926783643, 1.0, 1.0, 50.0, 61.564193536852756], 
current ob forecast is [], 
actual action is [1, 65.0], 
sim time this is 1930800.0000, 
sim time next is 1932000.0000, 
raw observation next is [-9.100000000000001, 87.66666666666666, 41.66666666666666, 109.0, 22.5, 21.12437531079969, -0.5997543095995458, 1.0, 1.0, 65.0, 87.09239160264946], 
processed observation next is [1.0, 0.34782608695652173, 0.21052631578947364, 0.8766666666666666, 0.13888888888888887, 0.12044198895027625, 0.375, 0.2603646092333074, 0.3000818968001514, 1.0, 1.0, 1.0, 0.8709239160264945], 
reward next is 0.4988, 
noisyNet noise sample is [array([0.44397748], dtype=float32), -0.13154556]. 
=============================================
[2019-04-16 12:09:15,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.28206092 0.04586592 0.02009745 0.02309156 0.011009   0.06300186
 0.00299933 0.44750327 0.02031252 0.06936966 0.01468852], sum to 1.0000
[2019-04-16 12:09:15,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4031
[2019-04-16 12:09:15,823] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 91.0, 9.999999999999998, 19.33333333333334, 22.5, 19.23436008796866, -1.072518040375831, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 2274000.0000, 
sim time next is 2275200.0000, 
raw observation next is [-9.5, 91.0, 24.0, 18.0, 22.5, 19.87204684533249, -0.7578971431013916, 1.0, 1.0, 40.0, 91.91517816900117], 
processed observation next is [1.0, 0.34782608695652173, 0.1994459833795014, 0.91, 0.08, 0.019889502762430938, 0.375, 0.1560039037777076, 0.24736761896620282, 1.0, 1.0, 0.5, 0.9191517816900117], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34957147], dtype=float32), -1.6064603]. 
=============================================
[2019-04-16 12:09:16,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.34101808 0.01553665 0.01061813 0.01075435 0.00552374 0.08344
 0.00089996 0.4680211  0.01929298 0.0379107  0.0069843 ], sum to 1.0000
[2019-04-16 12:09:16,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5005
[2019-04-16 12:09:16,486] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 22.5, 22.48911119099555, -0.2067774091364385, 0.0, 1.0, 50.0, 45.919766186044555], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2145600.0000, 
sim time next is 2146800.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 22.58129932041336, -0.2017403012114214, 0.0, 1.0, 50.0, 42.37743982940337], 
processed observation next is [1.0, 0.8695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.3817749433677801, 0.4327532329295262, 0.0, 1.0, 0.7, 0.42377439829403374], 
reward next is 0.0512, 
noisyNet noise sample is [array([0.376379], dtype=float32), -0.012564599]. 
=============================================
[2019-04-16 12:09:21,583] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.40576655 0.0157776  0.0128327  0.01185607 0.00559204 0.06445325
 0.00201554 0.42082906 0.01607868 0.03568939 0.00910905], sum to 1.0000
[2019-04-16 12:09:21,584] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2786
[2019-04-16 12:09:21,618] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.100000000000001, 71.33333333333334, 278.8333333333334, 94.16666666666667, 22.5, 23.24545121830418, -0.3710484508794373, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2114400.0000, 
sim time next is 2115600.0000, 
raw observation next is [-6.9, 67.66666666666667, 269.3333333333334, 106.5, 22.5, 22.69538721924129, -0.3596054411140983, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.27146814404432135, 0.6766666666666667, 0.8977777777777781, 0.11767955801104972, 0.375, 0.39128226827010754, 0.3801315196286339, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2569902], dtype=float32), -0.35935098]. 
=============================================
[2019-04-16 12:09:23,744] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.3222762  0.03458751 0.02170128 0.02874611 0.01220055 0.11901163
 0.00243441 0.37084794 0.03083089 0.04057792 0.01678554], sum to 1.0000
[2019-04-16 12:09:23,744] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3097
[2019-04-16 12:09:23,773] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 75.0, 0.0, 0.0, 19.0, 21.45913434794982, -0.6966616955616917, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2178000.0000, 
sim time next is 2179200.0000, 
raw observation next is [-6.2, 76.33333333333334, 0.0, 0.0, 19.0, 20.48432599745724, -0.8681810974995057, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.7633333333333334, 0.0, 0.0, 0.08333333333333333, 0.20702716645477004, 0.2106063008334981, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7871633], dtype=float32), 0.028338106]. 
=============================================
[2019-04-16 12:09:24,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.31319165 0.05668483 0.02678004 0.03234782 0.00940771 0.08646854
 0.00627719 0.34489956 0.04009263 0.06129277 0.02255718], sum to 1.0000
[2019-04-16 12:09:24,601] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0086
[2019-04-16 12:09:24,609] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 19.0, 21.26216558570421, -0.6366256272654606, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2341200.0000, 
sim time next is 2342400.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 19.0, 20.64749482374584, -0.7308394924210305, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.3988919667590028, 0.62, 0.0, 0.0, 0.08333333333333333, 0.22062456864548677, 0.2563868358596565, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39189982], dtype=float32), 0.50154483]. 
=============================================
[2019-04-16 12:09:26,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.35253397 0.03631332 0.01893    0.01735138 0.00701992 0.06277262
 0.00198718 0.38451543 0.0201151  0.09167048 0.00679061], sum to 1.0000
[2019-04-16 12:09:26,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5414
[2019-04-16 12:09:26,634] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.3666666666666668, 29.33333333333334, 0.0, 0.0, 19.0, 21.9698241726893, -0.4672076899285453, 0.0, 1.0, 50.0, 39.33913342932854], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2486400.0000, 
sim time next is 2487600.0000, 
raw observation next is [0.0, 30.0, 0.0, 0.0, 19.0, 22.04787434275643, -0.4669839604542601, 0.0, 1.0, 50.0, 38.54334099808048], 
processed observation next is [0.0, 0.8260869565217391, 0.46260387811634357, 0.3, 0.0, 0.0, 0.08333333333333333, 0.3373228618963691, 0.34433867984857996, 0.0, 1.0, 0.7, 0.38543340998080483], 
reward next is 0.0896, 
noisyNet noise sample is [array([-0.14729017], dtype=float32), -0.8170996]. 
=============================================
[2019-04-16 12:09:29,257] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.30827636 0.07598719 0.03545092 0.03782578 0.0124575  0.10397263
 0.00573448 0.30228502 0.03550531 0.06361652 0.01888826], sum to 1.0000
[2019-04-16 12:09:29,259] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1099
[2019-04-16 12:09:29,272] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 19.0, 21.28911727825957, -0.6475983013013289, 0.0, 1.0, 20.0, 30.275114940413225], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2526000.0000, 
sim time next is 2527200.0000, 
raw observation next is [-2.3, 57.0, 0.0, 0.0, 19.0, 21.17718308202417, -0.77322235773102, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.3988919667590028, 0.57, 0.0, 0.0, 0.08333333333333333, 0.26476525683534763, 0.24225921408966, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09735305], dtype=float32), -0.18506147]. 
=============================================
[2019-04-16 12:09:30,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.36918035 0.04690743 0.02438562 0.03016635 0.0102451  0.09123652
 0.00296702 0.3370253  0.02188098 0.04978586 0.01621945], sum to 1.0000
[2019-04-16 12:09:30,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7442
[2019-04-16 12:09:30,939] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-15.0, 83.0, 0.0, 0.0, 22.5, 19.62223462342186, -0.6739905172960435, 0.0, 1.0, 60.0, 101.63962739413509], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2704800.0000, 
sim time next is 2706000.0000, 
raw observation next is [-15.0, 83.0, 13.33333333333333, 54.99999999999999, 22.5, 21.74763616677936, -0.4883028908356863, 1.0, 1.0, 50.0, 54.94706388810193], 
processed observation next is [1.0, 0.30434782608695654, 0.04709141274238226, 0.83, 0.04444444444444443, 0.060773480662983416, 0.375, 0.31230301389827986, 0.3372323697214379, 1.0, 1.0, 0.7, 0.5494706388810193], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34891334], dtype=float32), 0.49668413]. 
=============================================
[2019-04-16 12:09:31,388] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.5125172  0.023491   0.01465577 0.01355236 0.00812647 0.0620886
 0.00292607 0.30056    0.01206579 0.03549924 0.01451743], sum to 1.0000
[2019-04-16 12:09:31,389] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4236
[2019-04-16 12:09:31,460] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.266666666666667, 53.66666666666667, 121.8333333333333, 30.5, 22.5, 22.46268344801118, -0.3501074331667066, 1.0, 1.0, 40.0, 66.73307214641841], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2539200.0000, 
sim time next is 2540400.0000, 
raw observation next is [-1.733333333333333, 51.33333333333333, 135.5, 35.0, 22.5, 23.18488022499267, -0.3552579877942552, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.41458910433979695, 0.5133333333333333, 0.45166666666666666, 0.03867403314917127, 0.375, 0.43207335208272263, 0.38158067073524826, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4373289], dtype=float32), -0.5011564]. 
=============================================
[2019-04-16 12:09:33,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.4553411  0.0185187  0.00973652 0.01367504 0.00325051 0.03011226
 0.00065552 0.40510666 0.0067112  0.05135883 0.00553364], sum to 1.0000
[2019-04-16 12:09:33,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0696
[2019-04-16 12:09:33,068] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.533333333333333, 58.0, 0.0, 0.0, 19.0, 22.17401565303155, -0.3173637468687278, 0.0, 1.0, 50.0, 57.70253715106457], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2587200.0000, 
sim time next is 2588400.0000, 
raw observation next is [-3.9, 59.0, 0.0, 0.0, 19.0, 22.03380317800335, -0.4582374175749416, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.3545706371191136, 0.59, 0.0, 0.0, 0.08333333333333333, 0.3361502648336125, 0.3472541941416862, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1472433], dtype=float32), 1.6430922]. 
=============================================
[2019-04-16 12:09:34,464] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.39000693 0.02314861 0.01282297 0.01251225 0.00726431 0.06195131
 0.00207426 0.4223234  0.02054268 0.03468621 0.01266713], sum to 1.0000
[2019-04-16 12:09:34,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7565
[2019-04-16 12:09:34,602] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-13.33333333333333, 86.0, 94.16666666666667, 565.0, 22.5, 21.98424249376137, -0.300296948765652, 1.0, 1.0, 60.0, 102.74895852140699], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2712000.0000, 
sim time next is 2713200.0000, 
raw observation next is [-12.66666666666667, 81.0, 100.3333333333333, 622.3333333333333, 22.5, 23.41853520659731, -0.1513182047250445, 1.0, 1.0, 50.0, 49.834405760236514], 
processed observation next is [1.0, 0.391304347826087, 0.11172668513388727, 0.81, 0.3344444444444443, 0.6876611418047881, 0.375, 0.4515446005497757, 0.44956059842498514, 1.0, 1.0, 0.7, 0.49834405760236516], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7209908], dtype=float32), -0.35551143]. 
=============================================
[2019-04-16 12:09:34,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.38229635 0.01297981 0.00857229 0.00862784 0.00306681 0.0503557
 0.00084678 0.4965799  0.00920491 0.01936724 0.00810237], sum to 1.0000
[2019-04-16 12:09:34,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1181
[2019-04-16 12:09:34,947] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 54.0, 234.5, 159.0, 22.5, 24.04543685506391, -0.00902165948694487, 1.0, 1.0, 50.0, 42.945307446333736], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2635200.0000, 
sim time next is 2636400.0000, 
raw observation next is [-1.733333333333333, 51.66666666666667, 241.5, 151.0, 22.5, 24.18339229178714, -0.157648032014772, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.41458910433979695, 0.5166666666666667, 0.805, 0.16685082872928178, 0.375, 0.5152826909822616, 0.447450655995076, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8144531], dtype=float32), 0.5731483]. 
=============================================
[2019-04-16 12:09:35,354] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.41359475 0.03514025 0.02066538 0.01973028 0.00699037 0.08651818
 0.00264565 0.32305348 0.03651031 0.04471613 0.0104353 ], sum to 1.0000
[2019-04-16 12:09:35,354] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2581
[2019-04-16 12:09:35,424] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 0.0, 0.0, 22.5, 21.23862835200791, -0.5677673076053038, 0.0, 1.0, 40.0, 48.80305471231058], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2704800.0000, 
sim time next is 2706000.0000, 
raw observation next is [-15.0, 83.0, 13.33333333333333, 54.99999999999999, 22.5, 21.25412381948893, -0.7124491071860307, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.04709141274238226, 0.83, 0.04444444444444443, 0.060773480662983416, 0.375, 0.271176984957411, 0.2625169642713231, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4699417], dtype=float32), 0.09494983]. 
=============================================
[2019-04-16 12:09:35,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.37827578 0.05528678 0.02278852 0.02827504 0.01187458 0.11071377
 0.00329573 0.2845043  0.02600007 0.05989464 0.01909089], sum to 1.0000
[2019-04-16 12:09:35,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5101
[2019-04-16 12:09:35,894] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [-15.33333333333333, 83.0, 0.0, 0.0, 19.0, 19.77788048578352, -0.9693913492052803, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 2702400.0000, 
sim time next is 2703600.0000, 
raw observation next is [-15.0, 83.0, 0.0, 0.0, 19.0, 19.40215164810814, -0.9180866376580664, 0.0, 1.0, 40.0, 52.44725907315495], 
processed observation next is [1.0, 0.30434782608695654, 0.04709141274238226, 0.83, 0.0, 0.0, 0.08333333333333333, 0.11684597067567844, 0.19397112078064452, 0.0, 1.0, 0.5, 0.5244725907315495], 
reward next is 0.1005, 
noisyNet noise sample is [array([0.0950544], dtype=float32), -0.84456605]. 
=============================================
[2019-04-16 12:09:41,026] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.9289984e-01 1.5627645e-02 5.1339511e-03 2.8421907e-03 2.2268659e-03
 7.9861104e-02 4.0017124e-04 4.7170141e-01 6.6409092e-03 1.9005746e-02
 3.6601019e-03], sum to 1.0000
[2019-04-16 12:09:41,026] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7555
[2019-04-16 12:09:41,067] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.666666666666667, 52.66666666666667, 0.0, 0.0, 22.5, 23.97522681313609, 0.06002082883598734, 1.0, 1.0, 50.0, 58.325011766580474], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2742000.0000, 
sim time next is 2743200.0000, 
raw observation next is [-4.0, 54.0, 0.0, 0.0, 22.5, 24.16070947158199, 0.1041279833934781, 1.0, 1.0, 50.0, 56.28451633236], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.54, 0.0, 0.0, 0.375, 0.5133924559651657, 0.534709327797826, 1.0, 1.0, 0.7, 0.5628451633236], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39380336], dtype=float32), 0.057713058]. 
=============================================
[2019-04-16 12:09:43,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.3784007  0.02798142 0.01126151 0.01560066 0.00635596 0.05031347
 0.00198952 0.39226153 0.02415926 0.08161052 0.01006545], sum to 1.0000
[2019-04-16 12:09:43,282] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8854
[2019-04-16 12:09:43,322] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 8, 
current raw observation is [-2.666666666666667, 63.33333333333334, 121.8333333333333, 781.8333333333334, 19.0, 20.35428984379195, -0.6656023005491208, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 55.0], 
sim time this is 2985600.0000, 
sim time next is 2986800.0000, 
raw observation next is [-2.333333333333333, 61.66666666666667, 108.5, 791.8333333333334, 19.0, 20.74773152059293, -0.400427821190993, 0.0, 1.0, 55.0, 79.34725428801994], 
processed observation next is [0.0, 0.5652173913043478, 0.3979686057248385, 0.6166666666666667, 0.3616666666666667, 0.8749539594843463, 0.08333333333333333, 0.22897762671607738, 0.36652405960300233, 0.0, 1.0, 0.8, 0.7934725428801994], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17262785], dtype=float32), -0.8253003]. 
=============================================
[2019-04-16 12:09:47,338] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.4271107  0.02844844 0.0153532  0.01892996 0.00669919 0.0545535
 0.00181114 0.36057824 0.01912075 0.05824573 0.00914901], sum to 1.0000
[2019-04-16 12:09:47,338] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4318
[2019-04-16 12:09:47,379] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 20.86364017163436, -0.531438771128859, 0.0, 1.0, 50.0, 65.03915446712314], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 3020400.0000, 
sim time next is 3021600.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 21.43167322393711, -0.4874958817092168, 0.0, 1.0, 20.0, 31.885512928559233], 
processed observation next is [0.0, 1.0, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.2859727686614259, 0.33750137276359443, 0.0, 1.0, 0.1, 0.31885512928559234], 
reward next is 0.6061, 
noisyNet noise sample is [array([-0.71538466], dtype=float32), 2.2986312]. 
=============================================
[2019-04-16 12:09:47,497] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.7348359e-01 5.9025721e-03 3.5030947e-03 3.6184920e-03 1.3212140e-03
 2.5854185e-02 1.7506120e-04 3.6875013e-01 4.4597927e-03 1.0769101e-02
 2.1627806e-03], sum to 1.0000
[2019-04-16 12:09:47,498] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6622
[2019-04-16 12:09:47,567] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 93.0, 38.5, 47.5, 22.5, 24.67855346198193, 0.09842832273457047, 1.0, 1.0, 40.0, 38.868318600469394], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2912400.0000, 
sim time next is 2913600.0000, 
raw observation next is [1.666666666666667, 93.0, 16.83333333333333, 43.16666666666667, 22.5, 23.96086539766394, 0.1311307050381585, 1.0, 1.0, 50.0, 47.00878982366379], 
processed observation next is [1.0, 0.7391304347826086, 0.5087719298245615, 0.93, 0.0561111111111111, 0.04769797421731124, 0.375, 0.49673878313866177, 0.5437102350127195, 1.0, 1.0, 0.7, 0.4700878982366379], 
reward next is 0.0049, 
noisyNet noise sample is [array([0.39733377], dtype=float32), -2.1102679]. 
=============================================
[2019-04-16 12:09:51,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5270344e-01 5.7139453e-03 2.8175937e-03 3.9873682e-03 8.9583389e-04
 3.3564512e-02 1.5650725e-04 3.8080823e-01 4.1466751e-03 1.3952392e-02
 1.2535473e-03], sum to 1.0000
[2019-04-16 12:09:51,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0624
[2019-04-16 12:09:51,254] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 22.5, 25.87770781798885, 0.5736629956270807, 1.0, 1.0, 50.0, 40.06893425475471], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3262800.0000, 
sim time next is 3264000.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 22.5, 25.63093882262564, 0.4206166788838746, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3518005540166205, 0.65, 0.0, 0.0, 0.375, 0.6359115685521367, 0.6402055596279582, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1734211], dtype=float32), -0.9190967]. 
=============================================
[2019-04-16 12:09:51,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6930861e-01 1.6743515e-02 4.9770847e-03 7.1871933e-03 1.3115966e-03
 4.5304481e-02 2.6083365e-04 4.2402887e-01 7.3025236e-03 1.9883718e-02
 3.6915033e-03], sum to 1.0000
[2019-04-16 12:09:51,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5479
[2019-04-16 12:09:51,537] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.666666666666667, 100.0, 0.0, 0.0, 19.0, 25.49245108740683, 0.6211087351337582, 0.0, 1.0, 50.0, 35.3483311342234], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3187200.0000, 
sim time next is 3188400.0000, 
raw observation next is [2.333333333333333, 100.0, 0.0, 0.0, 19.0, 25.60266724296776, 0.6315465907550796, 0.0, 1.0, 50.0, 35.08285672249225], 
processed observation next is [1.0, 0.9130434782608695, 0.5272391505078486, 1.0, 0.0, 0.0, 0.08333333333333333, 0.6335556035806468, 0.7105155302516932, 0.0, 1.0, 0.7, 0.3508285672249225], 
reward next is 0.1242, 
noisyNet noise sample is [array([-1.51894], dtype=float32), 0.22015744]. 
=============================================
[2019-04-16 12:09:56,813] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5556036e-01 6.6261133e-03 4.5020031e-03 3.6396130e-03 1.4607209e-03
 3.1160012e-02 1.0551625e-04 4.7236663e-01 6.0789329e-03 1.6140165e-02
 2.3598676e-03], sum to 1.0000
[2019-04-16 12:09:56,813] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9398
[2019-04-16 12:09:56,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.4273274  0.01464255 0.00795996 0.0075842  0.00146967 0.04107685
 0.0004986  0.4588182  0.00525686 0.03101742 0.00434822], sum to 1.0000
[2019-04-16 12:09:56,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5345
[2019-04-16 12:09:56,869] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 23.44741270569332, 0.1066443289567454, 0.0, 1.0, 50.0, 57.053751523396514], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3453600.0000, 
sim time next is 3454800.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 23.83766102483818, 0.1382257388218995, 0.0, 1.0, 50.0, 41.50573360443961], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.48647175206984833, 0.5460752462739665, 0.0, 1.0, 0.7, 0.4150573360443961], 
reward next is 0.0599, 
noisyNet noise sample is [array([-0.6149767], dtype=float32), -0.87727785]. 
=============================================
[2019-04-16 12:09:56,890] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 55.0, 99.83333333333334, 763.1666666666667, 22.5, 25.70999034837791, 0.3807075825491368, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3422400.0000, 
sim time next is 3423600.0000, 
raw observation next is [3.0, 58.0, 93.5, 739.5, 22.5, 25.53795126212174, 0.5033154963798809, 1.0, 1.0, 50.0, 60.53485275888154], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.58, 0.31166666666666665, 0.8171270718232044, 0.375, 0.6281626051768118, 0.6677718321266269, 1.0, 1.0, 0.7, 0.6053485275888154], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98973536], dtype=float32), 1.5549028]. 
=============================================
[2019-04-16 12:09:57,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2772349e-01 1.5854046e-02 7.3618889e-03 1.0361275e-02 1.7501133e-03
 3.5768002e-02 4.5541438e-04 3.5917085e-01 8.2573453e-03 2.7810929e-02
 5.4866341e-03], sum to 1.0000
[2019-04-16 12:09:57,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7025
[2019-04-16 12:09:57,672] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 19.0, 24.79169464816348, 0.4160951868061675, 0.0, 1.0, 50.0, 38.197717534809236], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3200400.0000, 
sim time next is 3201600.0000, 
raw observation next is [0.6666666666666667, 100.0, 0.0, 0.0, 19.0, 25.03708435823024, 0.4303825026866168, 0.0, 1.0, 50.0, 37.67241203759545], 
processed observation next is [1.0, 0.043478260869565216, 0.4810710987996307, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5864236965191866, 0.6434608342288722, 0.0, 1.0, 0.7, 0.3767241203759545], 
reward next is 0.0983, 
noisyNet noise sample is [array([-1.1318582], dtype=float32), -0.0483142]. 
=============================================
[2019-04-16 12:09:58,791] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.28895062 0.02678837 0.01799942 0.01868715 0.00634451 0.08096761
 0.00125265 0.47620684 0.01737714 0.05438735 0.01103836], sum to 1.0000
[2019-04-16 12:09:58,794] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0965
[2019-04-16 12:09:58,812] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.333333333333333, 73.0, 0.0, 0.0, 19.0, 22.57000341053257, -0.3340766305990235, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3386400.0000, 
sim time next is 3387600.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 19.0, 21.9843485666553, -0.402894138397057, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.32409972299168976, 0.71, 0.0, 0.0, 0.08333333333333333, 0.33202904722127496, 0.36570195386764764, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2705933], dtype=float32), 0.116841845]. 
=============================================
[2019-04-16 12:09:59,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6195725e-01 5.3988793e-03 2.4955021e-03 4.7686282e-03 1.0256020e-03
 4.0060166e-02 2.4856380e-04 4.6850461e-01 3.6708610e-03 1.0127360e-02
 1.7425402e-03], sum to 1.0000
[2019-04-16 12:09:59,389] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9787
[2019-04-16 12:09:59,448] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 49.0, 113.6666666666667, 807.8333333333334, 22.5, 26.11550738431134, 0.5041193736345528, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3417600.0000, 
sim time next is 3418800.0000, 
raw observation next is [3.0, 49.0, 111.3333333333333, 800.8333333333334, 22.5, 26.27527096900304, 0.6667965867456654, 1.0, 1.0, 50.0, 70.08147533958208], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.371111111111111, 0.8848987108655617, 0.375, 0.6896059140835865, 0.7222655289152219, 1.0, 1.0, 0.7, 0.7008147533958209], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.96178776], dtype=float32), -0.90632033]. 
=============================================
[2019-04-16 12:09:59,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3567193e-01 8.6104823e-03 3.2300043e-03 3.0595169e-03 1.3295069e-03
 2.4516398e-02 9.8915632e-05 4.9740708e-01 4.6098325e-03 2.0495333e-02
 9.7096700e-04], sum to 1.0000
[2019-04-16 12:09:59,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7576
[2019-04-16 12:09:59,809] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 49.0, 115.0, 811.5, 22.5, 24.6545847221704, 0.3428801911257404, 1.0, 1.0, 40.0, 55.882708593136655], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3416400.0000, 
sim time next is 3417600.0000, 
raw observation next is [3.0, 49.0, 113.6666666666667, 807.8333333333334, 22.5, 25.30207136431527, 0.480557143446749, 1.0, 1.0, 50.0, 52.42247165297093], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.378888888888889, 0.892633517495396, 0.375, 0.6085059470262726, 0.6601857144822497, 1.0, 1.0, 0.7, 0.5242247165297093], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2553614], dtype=float32), 0.91294944]. 
=============================================
[2019-04-16 12:10:01,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.3855804  0.02553646 0.01710914 0.01808052 0.00554851 0.07174347
 0.00131889 0.38917604 0.02240858 0.05280658 0.01069143], sum to 1.0000
[2019-04-16 12:10:01,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6885
[2019-04-16 12:10:01,392] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 19.0, 22.30510129246598, -0.3005770960210687, 0.0, 1.0, 50.0, 40.70173425409992], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3308400.0000, 
sim time next is 3309600.0000, 
raw observation next is [-11.0, 78.66666666666667, 0.0, 0.0, 22.5, 22.24524536097356, -0.3327077839502704, 1.0, 1.0, 50.0, 44.05562964991506], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.7866666666666667, 0.0, 0.0, 0.375, 0.3537704467477966, 0.3890974053499099, 1.0, 1.0, 0.7, 0.4405562964991506], 
reward next is 0.0344, 
noisyNet noise sample is [array([-1.4650471], dtype=float32), -0.8346425]. 
=============================================
[2019-04-16 12:10:04,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.41626224 0.02291555 0.01313144 0.01242882 0.00438208 0.04381436
 0.00146627 0.41493616 0.01453558 0.04796639 0.00816111], sum to 1.0000
[2019-04-16 12:10:04,462] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2969
[2019-04-16 12:10:04,477] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.066666666666666, 28.33333333333334, 0.0, 0.0, 19.0, 24.02696587068368, 0.036473120051183, 0.0, 1.0, 50.0, 49.47049360033255], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3642000.0000, 
sim time next is 3643200.0000, 
raw observation next is [8.0, 29.0, 0.0, 0.0, 19.0, 24.04822692715602, -0.05653083730043725, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.6842105263157896, 0.29, 0.0, 0.0, 0.08333333333333333, 0.504018910596335, 0.48115638756652096, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.57076675], dtype=float32), -0.6661499]. 
=============================================
[2019-04-16 12:10:06,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.49975228 0.01752891 0.01334817 0.01075324 0.0050248  0.04979613
 0.00101592 0.3422006  0.01769126 0.03419349 0.0086951 ], sum to 1.0000
[2019-04-16 12:10:06,296] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8985
[2019-04-16 12:10:06,338] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 24.05377976398568, 0.0303720510234093, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3715200.0000, 
sim time next is 3716400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 23.81396711123711, 0.1038067335756953, 0.0, 1.0, 50.0, 58.552258205514484], 
processed observation next is [1.0, 0.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.484497259269759, 0.5346022445252318, 0.0, 1.0, 0.7, 0.5855225820551448], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5702162], dtype=float32), 0.24703963]. 
=============================================
[2019-04-16 12:10:06,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6227145e-01 9.9870469e-03 3.6014148e-03 3.5713071e-03 7.0705236e-04
 2.9088205e-02 2.4000493e-04 4.6762624e-01 4.8002223e-03 1.6731540e-02
 1.3754512e-03], sum to 1.0000
[2019-04-16 12:10:06,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4007
[2019-04-16 12:10:06,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 26.36925551409292, 0.6183628280737391, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3528000.0000, 
sim time next is 3529200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 25.64888241943407, 0.5009382415623298, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.6374068682861725, 0.66697941385411, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4659886], dtype=float32), -0.43232903]. 
=============================================
[2019-04-16 12:10:07,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.5217431  0.00975686 0.00434679 0.00396961 0.00240203 0.03755624
 0.0005233  0.3938905  0.00652938 0.01471684 0.00456523], sum to 1.0000
[2019-04-16 12:10:07,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4371
[2019-04-16 12:10:07,330] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 77.0, 105.5, 722.0, 22.5, 25.44098309042663, 0.3756261123989996, 1.0, 1.0, 50.0, 40.10348645866528], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3751200.0000, 
sim time next is 3752400.0000, 
raw observation next is [-3.0, 75.0, 109.1666666666667, 753.3333333333334, 22.5, 25.70643098976247, 0.3272790498699349, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.75, 0.363888888888889, 0.8324125230202579, 0.375, 0.6422025824802059, 0.6090930166233116, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3809671], dtype=float32), 0.6098286]. 
=============================================
[2019-04-16 12:10:09,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3070126e-01 4.0382929e-03 1.5094425e-03 1.5348644e-03 4.7832704e-04
 2.4990683e-02 6.8909707e-05 5.2176261e-01 4.5365384e-03 9.3602967e-03
 1.0187017e-03], sum to 1.0000
[2019-04-16 12:10:09,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7714
[2019-04-16 12:10:09,309] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 60.0, 56.16666666666667, 473.6666666666667, 22.5, 26.10861915031317, 0.4111734147367895, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3775200.0000, 
sim time next is 3776400.0000, 
raw observation next is [0.0, 60.0, 40.5, 343.0, 22.5, 26.1419064155859, 0.700925553788688, 1.0, 1.0, 50.0, 56.68855389110355], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.6, 0.135, 0.37900552486187844, 0.375, 0.678492201298825, 0.733641851262896, 1.0, 1.0, 0.7, 0.5668855389110355], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9272233], dtype=float32), -0.64195114]. 
=============================================
[2019-04-16 12:10:11,089] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.5169605  0.03474814 0.01301465 0.02039015 0.00488638 0.06177377
 0.00112678 0.2927991  0.01401949 0.03185139 0.00842966], sum to 1.0000
[2019-04-16 12:10:11,090] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5733
[2019-04-16 12:10:11,144] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 19.0, 22.4487014433405, -0.07076360670162186, 0.0, 1.0, 50.0, 74.45014681612973], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 3813600.0000, 
sim time next is 3814800.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 19.0, 23.11272116193378, -0.04807251625651959, 0.0, 1.0, 30.0, 36.89664474308975], 
processed observation next is [1.0, 0.13043478260869565, 0.3518005540166205, 0.71, 0.0, 0.0, 0.08333333333333333, 0.42606009682781504, 0.48397582791449345, 0.0, 1.0, 0.3, 0.3689664474308975], 
reward next is 0.4060, 
noisyNet noise sample is [array([1.6595949], dtype=float32), -1.8203552]. 
=============================================
[2019-04-16 12:10:11,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7782397e-01 3.4169990e-03 2.7716071e-03 1.8081010e-03 3.5439216e-04
 5.4931965e-02 7.4289383e-05 4.4792125e-01 2.0550932e-03 7.7164439e-03
 1.1258909e-03], sum to 1.0000
[2019-04-16 12:10:11,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4818
[2019-04-16 12:10:11,368] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [3.0, 41.0, 41.0, 365.0, 22.5, 27.28010866747579, 0.547801944213565, 1.0, 1.0, 40.0, 28.802989215885656], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 3862800.0000, 
sim time next is 3864000.0000, 
raw observation next is [2.666666666666667, 43.33333333333334, 25.66666666666666, 241.0, 22.5, 26.81947011291623, 0.6866420040701459, 1.0, 1.0, 25.0, 25.471157596527334], 
processed observation next is [1.0, 0.7391304347826086, 0.5364727608494922, 0.4333333333333334, 0.08555555555555554, 0.2662983425414365, 0.375, 0.7349558427430191, 0.728880668023382, 1.0, 1.0, 0.2, 0.25471157596527333], 
reward next is 0.5953, 
noisyNet noise sample is [array([0.34953523], dtype=float32), -1.1036798]. 
=============================================
[2019-04-16 12:10:13,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.5530739  0.02234485 0.01399384 0.01338153 0.00372437 0.04672009
 0.00166786 0.28032464 0.01281883 0.03917472 0.01277538], sum to 1.0000
[2019-04-16 12:10:13,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2982
[2019-04-16 12:10:13,907] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 36.66666666666666, 94.0, 504.0, 22.5, 24.68874455401943, 0.09782094738339668, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4092000.0000, 
sim time next is 4093200.0000, 
raw observation next is [-3.0, 38.0, 98.0, 574.0, 22.5, 24.54855200980499, 0.04055414204124674, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.38, 0.32666666666666666, 0.6342541436464089, 0.375, 0.5457126674837491, 0.5135180473470823, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4687302], dtype=float32), -0.8573858]. 
=============================================
[2019-04-16 12:10:17,319] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.2900410e-01 6.3880491e-03 1.6230149e-03 1.4548834e-03 8.7237282e-04
 2.2738397e-02 1.0176797e-04 4.2625535e-01 3.2347147e-03 7.1975808e-03
 1.1297254e-03], sum to 1.0000
[2019-04-16 12:10:17,319] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5023
[2019-04-16 12:10:17,354] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 24.0, 43.5, 370.5, 22.5, 26.10044474110305, 0.4651355679010208, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4035600.0000, 
sim time next is 4036800.0000, 
raw observation next is [-2.333333333333333, 24.66666666666666, 27.83333333333333, 252.1666666666667, 22.5, 25.92167182453329, 0.3458066841576266, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3979686057248385, 0.24666666666666662, 0.09277777777777776, 0.2786372007366483, 0.375, 0.6601393187111076, 0.6152688947192089, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4729577], dtype=float32), 1.658294]. 
=============================================
[2019-04-16 12:10:23,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.4600945  0.02230457 0.007366   0.00678206 0.00371879 0.03691379
 0.0006709  0.40597117 0.0108044  0.03969841 0.00567542], sum to 1.0000
[2019-04-16 12:10:23,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4075
[2019-04-16 12:10:23,979] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.666666666666666, 54.66666666666667, 190.1666666666667, 640.3333333333334, 19.0, 24.03767094194117, 0.0275934945406113, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4272000.0000, 
sim time next is 4273200.0000, 
raw observation next is [5.0, 55.0, 162.5, 713.0, 19.0, 23.68089831608039, -0.0351728778592177, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.6011080332409973, 0.55, 0.5416666666666666, 0.7878453038674034, 0.08333333333333333, 0.4734081930066993, 0.48827570738026077, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07446057], dtype=float32), -0.2055246]. 
=============================================
[2019-04-16 12:10:24,588] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0742888e-01 7.0255082e-03 2.4303959e-03 3.6300223e-03 8.8806346e-04
 1.6499694e-02 6.7829380e-05 4.2463827e-01 1.4167825e-03 3.4563076e-02
 1.4115040e-03], sum to 1.0000
[2019-04-16 12:10:24,589] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6079
[2019-04-16 12:10:24,650] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [7.9, 62.66666666666667, 0.0, 0.0, 19.0, 26.57231280707846, 0.7989411588227698, 0.0, 1.0, 50.0, 35.9909189160146], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4405200.0000, 
sim time next is 4406400.0000, 
raw observation next is [7.6, 63.0, 0.0, 0.0, 19.0, 26.67192011328432, 0.8069474567107561, 0.0, 1.0, 50.0, 35.56803183621767], 
processed observation next is [1.0, 0.0, 0.6731301939058172, 0.63, 0.0, 0.0, 0.08333333333333333, 0.7226600094403599, 0.768982485570252, 0.0, 1.0, 0.7, 0.35568031836217673], 
reward next is 0.1193, 
noisyNet noise sample is [array([0.32365158], dtype=float32), 0.907583]. 
=============================================
[2019-04-16 12:10:25,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1033151e-01 2.4183928e-03 1.0095524e-03 1.4352272e-03 4.7143624e-04
 1.8924523e-02 4.7785459e-05 4.5588264e-01 2.2623211e-03 5.8790972e-03
 1.3375977e-03], sum to 1.0000
[2019-04-16 12:10:25,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4894
[2019-04-16 12:10:25,514] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.73333333333333, 28.66666666666666, 117.5, 851.1666666666667, 22.5, 27.77420728997021, 0.8301794976787873, 1.0, 1.0, 50.0, 37.10983547210549], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4365600.0000, 
sim time next is 4366800.0000, 
raw observation next is [14.6, 29.0, 116.5, 847.5, 22.5, 27.48410467455388, 0.9183572417956577, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8670360110803325, 0.29, 0.3883333333333333, 0.93646408839779, 0.375, 0.7903420562128233, 0.8061190805985525, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7416473], dtype=float32), -0.4932597]. 
=============================================
[2019-04-16 12:10:26,068] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.5547695e-01 1.9602806e-03 7.7669101e-04 7.9785794e-04 2.7830841e-04
 2.6483087e-02 2.8827506e-05 7.0419753e-01 2.1039229e-03 6.7674359e-03
 1.1291438e-03], sum to 1.0000
[2019-04-16 12:10:26,069] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2839
[2019-04-16 12:10:26,103] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 5, 
current raw observation is [14.6, 29.0, 116.5, 847.5, 22.5, 27.75228048403716, 1.01119330852681, 1.0, 1.0, 50.0, 11.406302005090147], 
current ob forecast is [], 
actual action is [1, 40.0], 
sim time this is 4366800.0000, 
sim time next is 4368000.0000, 
raw observation next is [14.56666666666667, 29.66666666666667, 115.5, 843.8333333333334, 22.5, 28.11530355457501, 1.070144737521878, 1.0, 1.0, 40.0, 9.682826816912495], 
processed observation next is [1.0, 0.5652173913043478, 0.8661126500461682, 0.2966666666666667, 0.385, 0.9324125230202579, 0.375, 0.8429419628812509, 0.8567149125072927, 1.0, 1.0, 0.5, 0.09682826816912496], 
reward next is 0.5282, 
noisyNet noise sample is [array([-0.05006664], dtype=float32), 0.65868783]. 
=============================================
[2019-04-16 12:10:27,146] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.5492747e-01 1.4715168e-02 9.0226047e-03 8.6037414e-03 1.4156203e-03
 6.2036328e-02 4.1206268e-04 3.0486146e-01 8.8597815e-03 3.0727493e-02
 4.4183899e-03], sum to 1.0000
[2019-04-16 12:10:27,149] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9216
[2019-04-16 12:10:27,189] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.9, 75.0, 0.0, 0.0, 19.0, 24.431010782963, 0.1510639345655471, 0.0, 1.0, 50.0, 39.686528601677864], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4345200.0000, 
sim time next is 4346400.0000, 
raw observation next is [2.933333333333334, 74.66666666666667, 0.0, 0.0, 22.5, 24.59470580526217, 0.164405732797889, 0.0, 1.0, 50.0, 39.14277268674755], 
processed observation next is [1.0, 0.30434782608695654, 0.543859649122807, 0.7466666666666667, 0.0, 0.0, 0.375, 0.5495588171051807, 0.5548019109326296, 0.0, 1.0, 0.7, 0.3914277268674755], 
reward next is 0.0836, 
noisyNet noise sample is [array([1.6293129], dtype=float32), 0.14481595]. 
=============================================
[2019-04-16 12:10:28,782] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4458157e-01 7.5389948e-03 7.2982511e-03 4.2779306e-03 1.6810104e-03
 4.9302772e-02 2.5386360e-04 4.5145923e-01 5.2664275e-03 2.4854973e-02
 3.4850135e-03], sum to 1.0000
[2019-04-16 12:10:28,786] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1208
[2019-04-16 12:10:28,803] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.199999999999999, 62.66666666666667, 94.5, 522.0, 22.5, 26.02108585981102, 0.509331399886861, 1.0, 1.0, 40.0, 37.20653736537924], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4351200.0000, 
sim time next is 4352400.0000, 
raw observation next is [6.3, 57.0, 99.5, 584.0, 22.5, 26.23915616669158, 0.4493739756640591, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6371191135734073, 0.57, 0.33166666666666667, 0.6453038674033149, 0.375, 0.6865963472242983, 0.6497913252213531, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4626218], dtype=float32), 0.5943306]. 
=============================================
[2019-04-16 12:10:30,621] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.49646997e-01 7.33412197e-03 3.28060705e-03 2.57562636e-03
 5.79068146e-04 1.45828305e-02 6.07909824e-05 3.09769511e-01
 2.30158563e-03 8.68300814e-03 1.18583196e-03], sum to 1.0000
[2019-04-16 12:10:30,621] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1167
[2019-04-16 12:10:30,633] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.333333333333333, 51.66666666666666, 0.0, 0.0, 22.5, 27.18247358453907, 0.8732426414345779, 1.0, 1.0, 50.0, 27.391669238764624], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4646400.0000, 
sim time next is 4647600.0000, 
raw observation next is [3.0, 53.0, 0.0, 0.0, 22.5, 27.0405935873589, 0.7643507936975068, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5457063711911359, 0.53, 0.0, 0.0, 0.375, 0.7533827989465749, 0.7547835978991689, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.11038999], dtype=float32), -0.3878192]. 
=============================================
[2019-04-16 12:10:31,592] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [0.42020285 0.03035375 0.01310799 0.01461433 0.00263517 0.0578775
 0.00091334 0.392976   0.01336266 0.04574155 0.00821487], sum to 1.0000
[2019-04-16 12:10:31,592] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2086
[2019-04-16 12:10:31,605] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 71.0, 0.0, 0.0, 19.0, 23.69473649036884, -0.03427966733767054, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4597200.0000, 
sim time next is 4598400.0000, 
raw observation next is [-2.2, 72.0, 0.0, 0.0, 19.0, 23.18131984286413, -0.1562632406636822, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.4016620498614959, 0.72, 0.0, 0.0, 0.08333333333333333, 0.4317766535720109, 0.447912253112106, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8610395], dtype=float32), 0.2292337]. 
=============================================
[2019-04-16 12:10:33,742] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.5977168e-01 2.0272311e-02 7.4424166e-03 9.0427250e-03 2.7791241e-03
 3.6905881e-02 2.4766024e-04 2.3383656e-01 6.3141133e-03 2.0243833e-02
 3.1436705e-03], sum to 1.0000
[2019-04-16 12:10:33,743] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1320
[2019-04-16 12:10:33,771] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 24.49994365856473, 0.1715553321169927, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4686000.0000, 
sim time next is 4687200.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 19.0, 24.13674281588315, 0.07418812536336467, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5113952346569292, 0.5247293751211216, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.43944514], dtype=float32), -1.3319137]. 
=============================================
[2019-04-16 12:10:33,970] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [0.45530695 0.03002423 0.01300986 0.01281601 0.0033364  0.03915903
 0.00109081 0.37843707 0.0102626  0.04958535 0.00697167], sum to 1.0000
[2019-04-16 12:10:33,970] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7756
[2019-04-16 12:10:33,994] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 92.0, 62.0, 209.5, 19.0, 22.03375949873543, -0.2208649841425202, 0.0, 1.0, 50.0, 44.28167766852882], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4780800.0000, 
sim time next is 4782000.0000, 
raw observation next is [-5.666666666666666, 87.0, 103.3333333333333, 349.1666666666667, 19.0, 22.55950223872777, -0.1639518710207592, 0.0, 1.0, 50.0, 42.71732893622695], 
processed observation next is [0.0, 0.34782608695652173, 0.3056325023084026, 0.87, 0.34444444444444433, 0.3858195211786372, 0.08333333333333333, 0.37995851989398083, 0.4453493763264136, 0.0, 1.0, 0.7, 0.4271732893622695], 
reward next is 0.0478, 
noisyNet noise sample is [array([1.3182609], dtype=float32), 0.512722]. 
=============================================
[2019-04-16 12:10:35,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.3808085  0.0152664  0.00718285 0.01197645 0.00376069 0.03967807
 0.00067703 0.47157764 0.01532818 0.04805378 0.00569033], sum to 1.0000
[2019-04-16 12:10:35,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0982
[2019-04-16 12:10:35,516] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666667, 41.0, 0.0, 0.0, 19.0, 21.95869982717361, -0.4585360299620052, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4926000.0000, 
sim time next is 4927200.0000, 
raw observation next is [0.3333333333333334, 42.0, 0.0, 0.0, 19.0, 21.80696043108526, -0.4774651799431039, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4718374884579871, 0.42, 0.0, 0.0, 0.08333333333333333, 0.3172467025904382, 0.3408449400189653, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6617461], dtype=float32), -0.8997014]. 
=============================================
[2019-04-16 12:10:36,573] A3C_AGENT_WORKER-Thread-4 INFO:Evaluating...
[2019-04-16 12:10:36,582] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:10:36,583] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:10:36,583] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:10:36,583] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:10:36,583] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:10:36,583] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:10:36,586] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run5
[2019-04-16 12:10:36,599] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run5
[2019-04-16 12:10:36,610] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run5
[2019-04-16 12:11:45,312] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:NoisyNet noise sample: [array([0.02679791], dtype=float32), 0.033793043]
[2019-04-16 12:11:45,312] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:Observation this: [3.8, 86.0, 0.0, 0.0, 19.0, 24.10958289801912, 0.177005113917112, 0.0, 1.0, 15.0, 0.0]
[2019-04-16 12:11:45,313] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:Observation forecast: []
[2019-04-16 12:11:45,313] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Softmax [0.5171641  0.01783733 0.0079332  0.00727376 0.00262441 0.03895335
 0.00057961 0.35574675 0.01106317 0.03665111 0.00417323], sampled 0.10938731743731711
[2019-04-16 12:11:45,909] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2308.5088 104121.5166 485.4978
[2019-04-16 12:11:45,929] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:45,929] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:45,929] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:45,929] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:45,929] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:46,037] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:46,037] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:46,037] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:46,037] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:46,037] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:53,824] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2193.3228 111816.5983 120.1778
[2019-04-16 12:11:53,844] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:53,844] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:53,844] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:53,844] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:53,844] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:53,953] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:53,953] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:53,953] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:53,953] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:53,953] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:58,774] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2190.5417 111742.3470 -123.6514
[2019-04-16 12:11:58,794] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:58,794] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:58,794] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:58,794] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:58,794] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:11:58,909] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:58,909] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:58,909] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:58,909] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:58,909] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:11:59,797] A3C_AGENT_WORKER-Thread-4 INFO:Global step: 200000, evaluation results [200000.0, 2193.3227989158136, 111816.59830296933, 120.17779868570967, 2308.508776205166, 104121.51658420681, 485.49776092689524, 2190.5417122162676, 111742.34702606643, -123.65142476842644]
[2019-04-16 12:12:01,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.4265701  0.02398396 0.0123618  0.0144945  0.00388348 0.04185124
 0.00123228 0.4045687  0.01310127 0.05133787 0.00661487], sum to 1.0000
[2019-04-16 12:12:01,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8099
[2019-04-16 12:12:01,303] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 22.58768264868582, -0.3893320674852784, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4854000.0000, 
sim time next is 4855200.0000, 
raw observation next is [-3.666666666666667, 67.33333333333333, 0.0, 0.0, 19.0, 22.25957606048459, -0.3166668041375879, 0.0, 1.0, 50.0, 56.6237496499143], 
processed observation next is [0.0, 0.17391304347826086, 0.3610341643582641, 0.6733333333333333, 0.0, 0.0, 0.08333333333333333, 0.3549646717070492, 0.394444398620804, 0.0, 1.0, 0.7, 0.566237496499143], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30459726], dtype=float32), 1.1555418]. 
=============================================
[2019-04-16 12:12:02,557] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:02,727] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:03,438] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:03,563] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:03,564] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:03,568] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run4
[2019-04-16 12:12:03,603] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:04,177] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:04,335] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:04,416] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0531709e-01 1.4767135e-02 3.3917716e-03 3.5401478e-03 1.9119059e-03
 4.6464734e-02 3.5818559e-04 3.7447166e-01 8.1638740e-03 3.9471321e-02
 2.1421248e-03], sum to 1.0000
[2019-04-16 12:12:04,417] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4862
[2019-04-16 12:12:04,428] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 139.5, 739.5, 19.0, 23.3900350032994, -0.0465990347563684, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4804800.0000, 
sim time next is 4806000.0000, 
raw observation next is [3.0, 37.0, 122.5, 734.5, 19.0, 23.0866572109327, -0.07982566378519508, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.37, 0.4083333333333333, 0.8116022099447514, 0.08333333333333333, 0.4238881009110583, 0.473391445404935, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.31312132], dtype=float32), 1.969128]. 
=============================================
[2019-04-16 12:12:04,436] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:04,436] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:04,439] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run4
[2019-04-16 12:12:05,098] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:05,176] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:05,176] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:05,178] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run4
[2019-04-16 12:12:05,270] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:05,501] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:05,671] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:06,094] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:06,094] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:06,096] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run4
[2019-04-16 12:12:06,131] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.53643823e-01 4.34866361e-03 1.26038189e-03 2.96079763e-03
 4.27041930e-04 2.30433531e-02 1.05241415e-04 3.90098602e-01
 3.78509075e-03 1.89653430e-02 1.36170769e-03], sum to 1.0000
[2019-04-16 12:12:06,131] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4643
[2019-04-16 12:12:06,170] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 18.33333333333333, 0.0, 0.0, 22.5, 27.67403200519592, 0.9504745464319622, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5082000.0000, 
sim time next is 5083200.0000, 
raw observation next is [10.0, 19.0, 0.0, 0.0, 22.5, 27.42623480696734, 0.8923824066930691, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.739612188365651, 0.19, 0.0, 0.0, 0.375, 0.7855195672472783, 0.797460802231023, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.285218], dtype=float32), -0.9550008]. 
=============================================
[2019-04-16 12:12:06,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:06,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:06,498] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run4
[2019-04-16 12:12:06,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6845909e-01 1.8097587e-03 1.2216506e-03 1.2832315e-03 2.2557516e-04
 1.3411995e-02 4.4474207e-05 4.0288448e-01 1.5075902e-03 8.3550662e-03
 7.9704943e-04], sum to 1.0000
[2019-04-16 12:12:06,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1003
[2019-04-16 12:12:06,596] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:06,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8408461e-01 5.1341192e-03 1.5145709e-03 1.8454525e-03 4.1252485e-04
 1.8108916e-02 3.5705834e-05 4.7596538e-01 1.1009595e-03 1.1163093e-02
 6.3470774e-04], sum to 1.0000
[2019-04-16 12:12:06,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4701
[2019-04-16 12:12:06,619] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 18.33333333333333, 0.0, 0.0, 22.5, 27.28621515761638, 0.8592126679773635, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5082000.0000, 
sim time next is 5083200.0000, 
raw observation next is [10.0, 19.0, 0.0, 0.0, 22.5, 27.02944476429722, 0.8167949071648525, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.739612188365651, 0.19, 0.0, 0.0, 0.375, 0.7524537303581017, 0.7722649690549508, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.04474382], dtype=float32), 0.34177253]. 
=============================================
[2019-04-16 12:12:06,631] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:06,666] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 25.0, 122.5, 855.0, 22.5, 26.11808991177237, 0.5068716876978331, 1.0, 1.0, 50.0, 31.241854403273166], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4968000.0000, 
sim time next is 4969200.0000, 
raw observation next is [6.333333333333333, 24.66666666666667, 122.8333333333333, 861.6666666666667, 22.5, 26.25643672378187, 0.2800638705396173, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6380424746075716, 0.2466666666666667, 0.40944444444444433, 0.9521178637200738, 0.375, 0.6880363936484892, 0.5933546235132058, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7591889], dtype=float32), 0.46155143]. 
=============================================
[2019-04-16 12:12:06,769] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:06,880] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:06,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1585522e-01 7.4814665e-03 3.8929423e-03 2.8125595e-03 1.1971500e-03
 3.4564331e-02 5.8426387e-05 3.2221898e-01 3.5119497e-03 6.9920835e-03
 1.4148225e-03], sum to 1.0000
[2019-04-16 12:12:06,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5327
[2019-04-16 12:12:06,945] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 27.66666666666667, 121.1666666666667, 838.0, 22.5, 25.50231012750308, 0.2562200594919143, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4965600.0000, 
sim time next is 4966800.0000, 
raw observation next is [5.0, 26.33333333333333, 122.1666666666667, 848.3333333333334, 22.5, 25.33635366582397, 0.2325138790909862, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6011080332409973, 0.2633333333333333, 0.4072222222222223, 0.9373848987108656, 0.375, 0.611362805485331, 0.5775046263636621, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.45301443], dtype=float32), 0.0073308884]. 
=============================================
[2019-04-16 12:12:07,009] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:07,175] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:07,225] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:07,313] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:07,382] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:07,382] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:07,489] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:07,553] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:07,597] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:07,597] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:07,599] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run4
[2019-04-16 12:12:07,631] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:07,632] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:07,634] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run4
[2019-04-16 12:12:08,008] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:08,008] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:08,010] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run4
[2019-04-16 12:12:08,221] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:08,221] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:08,224] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run4
[2019-04-16 12:12:08,313] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:08,313] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:08,315] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run4
[2019-04-16 12:12:08,377] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:08,377] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:08,379] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run4
[2019-04-16 12:12:09,297] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:09,511] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:09,869] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:10,090] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:10,229] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:10,298] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:10,298] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:10,300] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run4
[2019-04-16 12:12:10,441] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:10,538] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:10,759] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:10,870] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:10,870] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:10,872] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run4
[2019-04-16 12:12:11,230] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:11,230] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:11,232] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run4
[2019-04-16 12:12:11,442] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:11,442] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:11,444] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run4
[2019-04-16 12:12:12,727] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:12:13,055] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-16 12:12:13,728] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:12:13,729] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:12:13,730] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run4
[2019-04-16 12:12:20,662] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.0985732e-01 9.6636647e-03 5.5135833e-03 3.0807171e-03 1.1065971e-03
 1.8268533e-02 2.1821840e-04 3.1708282e-01 3.9986074e-03 2.9595003e-02
 1.6149934e-03], sum to 1.0000
[2019-04-16 12:12:20,663] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4262
[2019-04-16 12:12:20,696] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 87.0, 0.0, 0.0, 19.0, 22.17820669844461, -0.2287210133860468, 0.0, 1.0, 50.0, 56.258887760642054], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 67200.0000, 
sim time next is 68400.0000, 
raw observation next is [3.8, 86.0, 0.0, 0.0, 19.0, 22.2773438624649, -0.3281850068153859, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.5678670360110805, 0.86, 0.0, 0.0, 0.08333333333333333, 0.35644532187207495, 0.3906049977282047, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0929089], dtype=float32), 0.96435016]. 
=============================================
[2019-04-16 12:12:24,921] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [0.4594082  0.0375873  0.01956364 0.01208724 0.0041868  0.07144487
 0.00076292 0.34104025 0.01186693 0.03353599 0.00851592], sum to 1.0000
[2019-04-16 12:12:24,921] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6496
[2019-04-16 12:12:24,962] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.900000000000002, 78.0, 0.0, 0.0, 19.0, 20.52140551555157, -0.7633338369640423, 0.0, 1.0, 50.0, 47.64000108272866], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 184800.0000, 
sim time next is 186000.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 20.52103261954859, -0.773724349491744, 0.0, 1.0, 50.0, 47.07245861214652], 
processed observation next is [1.0, 0.13043478260869565, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.21008605162904903, 0.24209188350275201, 0.0, 1.0, 0.7, 0.47072458612146517], 
reward next is 0.0043, 
noisyNet noise sample is [array([-0.5946704], dtype=float32), -0.15786587]. 
=============================================
[2019-04-16 12:12:35,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.3652678  0.0398802  0.01890378 0.01540472 0.00551016 0.06654172
 0.00103167 0.40805393 0.01679052 0.05410445 0.00851096], sum to 1.0000
[2019-04-16 12:12:35,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4376
[2019-04-16 12:12:35,923] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [-12.1, 68.0, 0.0, 0.0, 19.0, 19.46318096824495, -1.08437608189377, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 30.0], 
sim time this is 283200.0000, 
sim time next is 284400.0000, 
raw observation next is [-12.3, 67.0, 0.0, 0.0, 19.0, 19.2255454348845, -1.007273701779754, 0.0, 1.0, 30.0, 56.71472132077464], 
processed observation next is [1.0, 0.30434782608695654, 0.12188365650969527, 0.67, 0.0, 0.0, 0.08333333333333333, 0.10212878624037487, 0.1642420994067487, 0.0, 1.0, 0.3, 0.5671472132077464], 
reward next is 0.2079, 
noisyNet noise sample is [array([0.5333421], dtype=float32), -0.55495083]. 
=============================================
[2019-04-16 12:12:37,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.44312626 0.01527963 0.01257307 0.01271197 0.0033285  0.0501537
 0.00063456 0.41142222 0.00855209 0.03140521 0.01081285], sum to 1.0000
[2019-04-16 12:12:37,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4632
[2019-04-16 12:12:37,623] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [-5.066666666666666, 32.33333333333334, 68.0, 0.0, 22.5, 21.3990239466543, -0.7262260468026126, 1.0, 1.0, 50.0, 59.711528459391715], 
current ob forecast is [], 
actual action is [1, 25.0], 
sim time this is 466800.0000, 
sim time next is 468000.0000, 
raw observation next is [-4.5, 32.0, 80.0, 0.0, 22.5, 21.92039113906496, -0.6690182963244805, 1.0, 1.0, 25.0, 42.538441273495806], 
processed observation next is [1.0, 0.43478260869565216, 0.3379501385041552, 0.32, 0.26666666666666666, 0.0, 0.375, 0.32669926158874674, 0.27699390122517314, 1.0, 1.0, 0.2, 0.4253844127349581], 
reward next is 0.6801, 
noisyNet noise sample is [array([-0.47612646], dtype=float32), -0.058375504]. 
=============================================
[2019-04-16 12:12:44,492] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0555789e-01 8.2980413e-03 4.2409846e-03 2.5764683e-03 2.3598345e-03
 3.3697013e-02 1.6378591e-04 4.0962923e-01 6.1383466e-03 2.4519395e-02
 2.8190615e-03], sum to 1.0000
[2019-04-16 12:12:44,492] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0312
[2019-04-16 12:12:44,501] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.066666666666667, 80.33333333333333, 131.3333333333333, 429.1666666666666, 19.0, 20.58906520421776, -0.7520907925979509, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 564000.0000, 
sim time next is 565200.0000, 
raw observation next is [-1.2, 80.0, 134.0, 495.5, 19.0, 20.22758191676674, -0.8094119466992699, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.42936288088642666, 0.8, 0.44666666666666666, 0.5475138121546961, 0.08333333333333333, 0.18563182639722844, 0.23019601776691004, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1052656], dtype=float32), 0.71505517]. 
=============================================
[2019-04-16 12:12:47,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.46761990e-01 1.02900695e-02 2.07008957e-03 1.75916159e-03
 6.01598178e-04 3.53980176e-02 4.66755482e-05 3.85670930e-01
 3.39400931e-03 1.28435288e-02 1.16396125e-03], sum to 1.0000
[2019-04-16 12:12:47,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3013
[2019-04-16 12:12:47,021] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 45.66666666666667, 81.5, 723.8333333333333, 22.5, 23.24415263612144, -0.2594345760962695, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 742800.0000, 
sim time next is 744000.0000, 
raw observation next is [0.1666666666666667, 46.33333333333334, 80.83333333333334, 600.1666666666666, 22.5, 23.26117448800707, -0.2830865572558425, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.4672206832871654, 0.46333333333333343, 0.2694444444444445, 0.6631675874769797, 0.375, 0.43843120733392266, 0.4056378142480525, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.576375], dtype=float32), 1.2140552]. 
=============================================
[2019-04-16 12:12:48,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5460644e-01 1.5052619e-02 8.1621446e-03 6.6244425e-03 2.8897300e-03
 2.3056362e-02 3.4414581e-04 4.1577235e-01 1.1955333e-02 5.7850149e-02
 3.6861768e-03], sum to 1.0000
[2019-04-16 12:12:48,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2646
[2019-04-16 12:12:48,554] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.7, 61.0, 100.5, 69.0, 19.0, 19.28177559706325, -0.9453658417042726, 0.0, 1.0, 50.0, 75.16759233177284], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 648000.0000, 
sim time next is 649200.0000, 
raw observation next is [-2.566666666666667, 60.33333333333334, 108.1666666666667, 89.66666666666667, 19.0, 19.75170885892384, -1.040252408759304, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.39150507848568794, 0.6033333333333334, 0.3605555555555557, 0.0990791896869245, 0.08333333333333333, 0.14597573824365342, 0.15324919708023202, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3217047], dtype=float32), -1.1007111]. 
=============================================
[2019-04-16 12:13:03,027] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.9267070e-01 1.4623840e-03 6.0681108e-04 6.8598893e-04 5.7709345e-05
 5.6850743e-03 1.4055330e-05 2.9218975e-01 1.4328761e-03 4.7215950e-03
 4.7306652e-04], sum to 1.0000
[2019-04-16 12:13:03,027] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8616
[2019-04-16 12:13:03,067] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 22.5, 23.66752542534527, -0.002364417170067459, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1015200.0000, 
sim time next is 1016400.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 22.5, 23.96839216361236, 0.170760275786617, 1.0, 1.0, 50.0, 60.33646515383113], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.375, 0.4973660136343634, 0.5569200919288724, 1.0, 1.0, 0.7, 0.6033646515383113], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6243169], dtype=float32), -0.8282319]. 
=============================================
[2019-04-16 12:13:07,221] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1364785e-01 1.1770153e-02 6.6595618e-03 6.0371989e-03 1.5665449e-03
 4.9571522e-02 2.1128125e-04 3.6507943e-01 5.2763904e-03 3.5929386e-02
 4.2506377e-03], sum to 1.0000
[2019-04-16 12:13:07,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3467
[2019-04-16 12:13:07,234] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 98.33333333333333, 0.0, 0.0, 19.0, 23.53983563163773, -0.04280278965723098, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1395600.0000, 
sim time next is 1396800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 22.89626857031003, -0.1571443077905036, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.40802238085916925, 0.4476185640698322, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03491801], dtype=float32), -1.2880981]. 
=============================================
[2019-04-16 12:13:12,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3449070e-01 1.1112838e-03 2.7480139e-04 5.6479609e-04 8.2042534e-05
 5.4695965e-03 6.8230856e-06 4.5394853e-01 2.9803778e-04 3.4830705e-03
 2.7028919e-04], sum to 1.0000
[2019-04-16 12:13:12,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0684
[2019-04-16 12:13:12,876] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1666666666666667, 94.0, 95.0, 0.0, 22.5, 25.01082240116131, 0.3239582830858925, 1.0, 1.0, 50.0, 40.68511490999133], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1426800.0000, 
sim time next is 1428000.0000, 
raw observation next is [0.3333333333333333, 93.0, 95.0, 0.0, 22.5, 25.06738376814483, 0.2126107894711722, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4718374884579871, 0.93, 0.31666666666666665, 0.0, 0.375, 0.5889486473454024, 0.5708702631570574, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7920556], dtype=float32), 1.2837735]. 
=============================================
[2019-04-16 12:13:13,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9509122e-01 1.4669456e-03 3.4041022e-04 2.3833346e-04 3.8675415e-05
 3.8722269e-03 1.7597295e-06 3.9386448e-01 2.1976911e-04 4.7524394e-03
 1.1376848e-04], sum to 1.0000
[2019-04-16 12:13:13,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7425
[2019-04-16 12:13:13,152] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [13.8, 49.0, 133.8333333333333, 0.0, 22.5, 27.39659285214356, 0.6476657074992175, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1608000.0000, 
sim time next is 1609200.0000, 
raw observation next is [13.8, 49.0, 111.5, 0.0, 22.5, 27.05687151720654, 0.8541876503130831, 1.0, 1.0, 50.0, 40.00366345174569], 
processed observation next is [1.0, 0.6521739130434783, 0.844875346260388, 0.49, 0.37166666666666665, 0.0, 0.375, 0.7547392931005451, 0.7847292167710277, 1.0, 1.0, 0.7, 0.40003663451745686], 
reward next is 0.0750, 
noisyNet noise sample is [array([-0.8917726], dtype=float32), 0.92680234]. 
=============================================
[2019-04-16 12:13:16,157] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9652928e-01 1.0513533e-02 5.2621742e-03 6.3052936e-03 1.6830134e-03
 2.1690480e-02 4.3501589e-04 4.1539922e-01 8.0124252e-03 3.0531364e-02
 3.6381704e-03], sum to 1.0000
[2019-04-16 12:13:16,157] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0596
[2019-04-16 12:13:16,165] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 84.33333333333333, 120.1666666666667, 0.0, 19.0, 20.29926134376125, -0.6783942738367421, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1770000.0000, 
sim time next is 1771200.0000, 
raw observation next is [-2.3, 83.0, 122.5, 0.0, 19.0, 20.17984984890957, -0.7054018804667007, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3988919667590028, 0.83, 0.4083333333333333, 0.0, 0.08333333333333333, 0.18165415407579744, 0.2648660398444331, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0773491], dtype=float32), 0.49598405]. 
=============================================
[2019-04-16 12:13:17,226] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1723590e-01 4.2140246e-03 3.9269400e-04 7.6517562e-04 1.2809552e-04
 8.6796731e-03 8.1290909e-06 3.4638333e-01 1.0683166e-03 2.0867951e-02
 2.5679145e-04], sum to 1.0000
[2019-04-16 12:13:17,227] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5984
[2019-04-16 12:13:17,244] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1666666666666667, 94.0, 0.0, 0.0, 19.0, 23.15578695096198, -0.09304834174790312, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1725600.0000, 
sim time next is 1726800.0000, 
raw observation next is [0.3333333333333333, 93.0, 0.0, 0.0, 19.0, 22.47928722075391, -0.1890062642152099, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4718374884579871, 0.93, 0.0, 0.0, 0.08333333333333333, 0.37327393506282586, 0.43699791192826337, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1826121], dtype=float32), 0.44307983]. 
=============================================
[2019-04-16 12:13:18,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8484286e-01 1.9504142e-03 4.8619427e-04 4.6612194e-04 4.6875943e-05
 5.2435850e-03 4.2521137e-06 4.0410954e-01 4.0392115e-04 2.1841677e-03
 2.6199888e-04], sum to 1.0000
[2019-04-16 12:13:18,285] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3193
[2019-04-16 12:13:18,322] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.833333333333334, 63.33333333333333, 202.6666666666667, 114.8333333333333, 22.5, 26.47078286461046, 0.6132000022460354, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1593600.0000, 
sim time next is 1594800.0000, 
raw observation next is [9.4, 61.0, 208.0, 168.5, 22.5, 26.28868827075282, 0.5847251590533218, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7229916897506927, 0.61, 0.6933333333333334, 0.1861878453038674, 0.375, 0.6907240225627351, 0.6949083863511073, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7383288], dtype=float32), 0.52336854]. 
=============================================
[2019-04-16 12:13:20,382] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.02674210e-01 6.57606462e-04 1.27670559e-04 1.36595612e-04
 3.00877437e-05 2.24095210e-03 1.17014940e-06 2.92987883e-01
 1.28689077e-04 9.09989409e-04 1.05181316e-04], sum to 1.0000
[2019-04-16 12:13:20,382] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1570
[2019-04-16 12:13:20,422] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.600000000000001, 60.66666666666667, 0.0, 0.0, 22.5, 26.34453868292275, 0.7652424573847361, 1.0, 1.0, 50.0, 44.63852119108539], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1536000.0000, 
sim time next is 1537200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 22.5, 26.47853957883697, 0.6804687898585762, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7229916897506927, 0.61, 0.0, 0.0, 0.375, 0.7065449649030807, 0.7268229299528587, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7455833], dtype=float32), -0.33935916]. 
=============================================
[2019-04-16 12:13:20,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3765655e-01 1.1504519e-02 3.1424654e-03 4.9166526e-03 1.2264227e-03
 1.9095721e-02 1.9634001e-04 3.8309368e-01 6.0637277e-03 3.1030383e-02
 2.0735178e-03], sum to 1.0000
[2019-04-16 12:13:20,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4306
[2019-04-16 12:13:20,607] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.833333333333333, 85.0, 0.0, 0.0, 19.0, 20.40992800973402, -0.8116613047531535, 0.0, 1.0, 50.0, 46.778005546266485], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1878000.0000, 
sim time next is 1879200.0000, 
raw observation next is [-5.0, 86.0, 0.0, 0.0, 19.0, 20.29312639597038, -0.9576210175208923, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.32409972299168976, 0.86, 0.0, 0.0, 0.08333333333333333, 0.19109386633086492, 0.18079299415970254, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7138832], dtype=float32), -1.0327654]. 
=============================================
[2019-04-16 12:13:21,137] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.78685343e-01 1.72868837e-02 5.84172504e-03 6.01080246e-03
 9.40167811e-04 4.14950587e-02 1.13121416e-04 3.23191434e-01
 4.99023031e-03 1.89013388e-02 2.54386361e-03], sum to 1.0000
[2019-04-16 12:13:21,138] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4851
[2019-04-16 12:13:21,144] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.6, 85.0, 0.0, 0.0, 19.0, 23.4585257943215, 0.04549026647306293, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1569600.0000, 
sim time next is 1570800.0000, 
raw observation next is [4.633333333333334, 84.66666666666667, 0.0, 0.0, 19.0, 23.34075018516497, 0.008079849736525646, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5909510618651893, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.44506251543041425, 0.5026932832455085, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8501785], dtype=float32), -1.7875774]. 
=============================================
[2019-04-16 12:13:24,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5610468e-01 3.1328013e-03 1.5064955e-03 7.6090416e-04 2.4016836e-04
 1.2218562e-02 1.2836321e-05 3.1475481e-01 9.2598452e-04 9.8455874e-03
 4.9714802e-04], sum to 1.0000
[2019-04-16 12:13:24,056] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4533
[2019-04-16 12:13:24,126] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 65.0, 182.0, 2.0, 22.5, 21.44053114844237, -0.786581537560914, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1947600.0000, 
sim time next is 1948800.0000, 
raw observation next is [-3.733333333333333, 64.0, 152.0, 0.6666666666666665, 22.5, 20.80092093481342, -0.8650054755934061, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.35918744228993543, 0.64, 0.5066666666666667, 0.000736648250460405, 0.375, 0.23341007790111826, 0.21166484146886463, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.69845635], dtype=float32), -1.405043]. 
=============================================
[2019-04-16 12:13:34,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8954778e-01 1.0067825e-03 5.8066432e-04 5.2241376e-04 4.8764465e-05
 9.0506533e-03 9.4128236e-06 2.9267356e-01 6.5582816e-04 5.5865832e-03
 3.1749791e-04], sum to 1.0000
[2019-04-16 12:13:34,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4659
[2019-04-16 12:13:34,294] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 22.5, 22.00120355697246, -0.3067956312870159, 1.0, 1.0, 50.0, 87.69844099740865], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2055600.0000, 
sim time next is 2056800.0000, 
raw observation next is [-3.9, 83.33333333333334, 0.0, 0.0, 22.5, 22.64227669632119, -0.3881774079762315, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3545706371191136, 0.8333333333333335, 0.0, 0.0, 0.375, 0.38685639136009914, 0.3706075306745895, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4133562], dtype=float32), -1.2122571]. 
=============================================
[2019-04-16 12:13:37,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3234726e-01 1.0922045e-02 4.9754437e-03 5.7201288e-03 6.2808470e-04
 2.6978778e-02 7.1939940e-05 3.9099315e-01 4.7188862e-03 2.0273866e-02
 2.3703622e-03], sum to 1.0000
[2019-04-16 12:13:37,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1030
[2019-04-16 12:13:37,250] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 78.33333333333334, 0.0, 0.0, 22.5, 20.46156365065725, -0.7296702403571665, 1.0, 1.0, 50.0, 63.20331162704565], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2100000.0000, 
sim time next is 2101200.0000, 
raw observation next is [-7.1, 78.66666666666667, 0.0, 0.0, 22.5, 20.83367400790279, -0.8728098838581205, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.2659279778393352, 0.7866666666666667, 0.0, 0.0, 0.375, 0.23613950065856582, 0.20906337204729317, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9510717], dtype=float32), -0.34063327]. 
=============================================
[2019-04-16 12:13:37,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3758868e-01 1.5952102e-03 1.3350394e-03 1.3806770e-03 1.3905379e-04
 7.4822204e-03 2.2475901e-05 3.4485027e-01 8.8087597e-04 3.8350071e-03
 8.9060527e-04], sum to 1.0000
[2019-04-16 12:13:37,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7503
[2019-04-16 12:13:38,200] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.2, 53.33333333333334, 255.1666666666667, 73.16666666666667, 22.5, 20.27869145973722, -0.9673846622941465, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2292000.0000, 
sim time next is 2293200.0000, 
raw observation next is [-1.7, 51.0, 241.5, 71.5, 22.5, 20.77024702218102, -0.7391317280477638, 1.0, 1.0, 50.0, 90.67919768070661], 
processed observation next is [1.0, 0.5652173913043478, 0.4155124653739613, 0.51, 0.805, 0.07900552486187845, 0.375, 0.23085391851508508, 0.2536227573174121, 1.0, 1.0, 0.7, 0.906791976807066], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.73316747], dtype=float32), -0.32826564]. 
=============================================
[2019-04-16 12:13:42,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.31832600e-01 4.36540879e-03 1.37044222e-03 1.02254236e-03
 2.52196100e-04 1.39801493e-02 1.21908652e-05 3.32813650e-01
 2.05426500e-03 1.10534625e-02 1.24314986e-03], sum to 1.0000
[2019-04-16 12:13:42,562] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4006
[2019-04-16 12:13:42,616] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 67.66666666666667, 269.3333333333334, 106.5, 22.5, 22.17688947901508, -0.3981139639051716, 1.0, 1.0, 50.0, 68.75832178563796], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2115600.0000, 
sim time next is 2116800.0000, 
raw observation next is [-6.7, 64.0, 222.0, 117.5, 22.5, 22.40480609797377, -0.4834580268908381, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.2770083102493075, 0.64, 0.74, 0.1298342541436464, 0.375, 0.36706717483114737, 0.3388473243697206, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15805195], dtype=float32), -1.9170043]. 
=============================================
[2019-04-16 12:13:43,613] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8563722e-01 1.6590668e-02 5.7565337e-03 7.5324308e-03 2.1461172e-03
 3.2338593e-02 2.9854951e-04 3.9735821e-01 8.5527347e-03 4.0113837e-02
 3.6750366e-03], sum to 1.0000
[2019-04-16 12:13:43,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5897
[2019-04-16 12:13:43,662] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.8, 65.0, 0.0, 0.0, 19.0, 20.43194785550905, -0.7364105641261305, 0.0, 1.0, 50.0, 61.87217315880572], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2347200.0000, 
sim time next is 2348400.0000, 
raw observation next is [-3.0, 66.33333333333334, 0.0, 0.0, 19.0, 20.77225119764167, -0.7101181857242649, 0.0, 1.0, 50.0, 44.25917541334336], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.6633333333333334, 0.0, 0.0, 0.08333333333333333, 0.23102093313680575, 0.2632939380919117, 0.0, 1.0, 0.7, 0.44259175413343355], 
reward next is 0.0324, 
noisyNet noise sample is [array([-1.1731311], dtype=float32), -1.637876]. 
=============================================
[2019-04-16 12:13:47,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8500952e-01 1.0334119e-02 2.3787373e-03 3.2251617e-03 3.9871299e-04
 1.3748464e-02 6.3976484e-05 3.7021250e-01 2.1613576e-03 1.0563907e-02
 1.9034863e-03], sum to 1.0000
[2019-04-16 12:13:47,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9401
[2019-04-16 12:13:47,676] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.8, 54.0, 28.5, 9.0, 22.5, 20.55190670283314, -0.9415046906598397, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2534400.0000, 
sim time next is 2535600.0000, 
raw observation next is [-2.8, 54.66666666666667, 43.5, 15.0, 22.5, 20.5152091301517, -0.7164429994999272, 1.0, 1.0, 50.0, 72.8994771338032], 
processed observation next is [1.0, 0.34782608695652173, 0.38504155124653744, 0.5466666666666667, 0.145, 0.016574585635359115, 0.375, 0.20960076084597498, 0.2611856668333576, 1.0, 1.0, 0.7, 0.728994771338032], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0621474], dtype=float32), 0.1575882]. 
=============================================
[2019-04-16 12:13:49,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.5462065  0.01399498 0.01139674 0.01128865 0.00250158 0.04515414
 0.00075943 0.29956436 0.01197325 0.05323302 0.00392732], sum to 1.0000
[2019-04-16 12:13:49,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4226
[2019-04-16 12:13:49,102] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.566666666666666, 49.66666666666666, 0.0, 0.0, 19.0, 19.182044292023, -1.161562395758344, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2424000.0000, 
sim time next is 2425200.0000, 
raw observation next is [-6.933333333333334, 51.33333333333333, 0.0, 0.0, 19.0, 18.6620200109365, -1.286704202443354, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.270544783010157, 0.5133333333333333, 0.0, 0.0, 0.08333333333333333, 0.05516833424470846, 0.07109859918554869, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.5431, 
noisyNet noise sample is [array([0.47215053], dtype=float32), -0.09196964]. 
=============================================
[2019-04-16 12:13:50,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.52261734 0.03106742 0.00988805 0.01189376 0.00241428 0.05730142
 0.00078552 0.30918792 0.00745117 0.04341665 0.00397643], sum to 1.0000
[2019-04-16 12:13:50,616] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1798
[2019-04-16 12:13:50,641] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.2, 59.0, 0.0, 0.0, 19.0, 19.31876980093008, -1.100847362058616, 0.0, 1.0, 50.0, 41.59330940827193], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2432400.0000, 
sim time next is 2433600.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 19.0, 19.0674949141278, -1.276524984856152, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2299168975069252, 0.61, 0.0, 0.0, 0.08333333333333333, 0.08895790951064993, 0.07449167171461601, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9212183], dtype=float32), -0.24026375]. 
=============================================
[2019-04-16 12:13:50,929] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5427054e-01 1.4321888e-02 1.0487415e-02 6.7883921e-03 1.7769176e-03
 4.5226395e-02 3.0711974e-04 4.1913429e-01 5.1883380e-03 3.8962666e-02
 3.5360744e-03], sum to 1.0000
[2019-04-16 12:13:50,929] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3621
[2019-04-16 12:13:50,941] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.466666666666667, 56.00000000000001, 0.0, 0.0, 19.0, 19.99336614845068, -0.9619581713807396, 0.0, 1.0, 25.0, 32.84299512581586], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2528400.0000, 
sim time next is 2529600.0000, 
raw observation next is [-2.633333333333333, 55.0, 0.0, 0.0, 19.0, 19.87200032828686, -1.062813808586968, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.38965835641735924, 0.55, 0.0, 0.0, 0.08333333333333333, 0.15600002735723825, 0.14572873047101065, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29854453], dtype=float32), -0.009145627]. 
=============================================
[2019-04-16 12:13:52,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4389483e-01 6.1953701e-03 3.0649232e-03 5.1251450e-03 8.6792588e-04
 1.5683979e-02 1.6782242e-04 4.0022972e-01 3.2972186e-03 1.9402115e-02
 2.0709869e-03], sum to 1.0000
[2019-04-16 12:13:52,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2130
[2019-04-16 12:13:52,835] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 38.66666666666667, 0.0, 0.0, 19.0, 19.38573769955651, -0.8994052263659519, 0.0, 1.0, 50.0, 70.36215688423688], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2506800.0000, 
sim time next is 2508000.0000, 
raw observation next is [-1.7, 39.33333333333333, 0.0, 0.0, 19.0, 20.12131637733309, -0.9884484433181856, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.3933333333333333, 0.0, 0.0, 0.08333333333333333, 0.1767763647777576, 0.1705171855606048, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.23826392], dtype=float32), -0.27394265]. 
=============================================
[2019-04-16 12:13:53,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9137064e-01 1.1126469e-02 6.0405773e-03 7.3560351e-03 7.9345232e-04
 3.7980787e-02 7.6085926e-05 3.2130745e-01 2.4216671e-03 1.5985467e-02
 5.5413665e-03], sum to 1.0000
[2019-04-16 12:13:53,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0914
[2019-04-16 12:13:53,518] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 79.0, 42.0, 4.0, 22.5, 20.49933693042104, -0.8248851707675308, 1.0, 1.0, 50.0, 59.04045353812671], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2620800.0000, 
sim time next is 2622000.0000, 
raw observation next is [-7.100000000000001, 77.66666666666667, 65.33333333333334, 1.333333333333333, 22.5, 20.50757753081774, -0.9338385375113697, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.26592797783933514, 0.7766666666666667, 0.21777777777777782, 0.00147329650092081, 0.375, 0.20896479423481176, 0.1887204874962101, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42858133], dtype=float32), 0.89786386]. 
=============================================
[2019-04-16 12:13:53,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3023895e-01 7.4010580e-03 4.2071179e-03 5.2235043e-03 6.5343792e-04
 3.4238178e-02 5.7255769e-05 2.9819822e-01 1.3632083e-03 1.4232204e-02
 4.1869129e-03], sum to 1.0000
[2019-04-16 12:13:53,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4017
[2019-04-16 12:13:53,778] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 75.0, 85.0, 45.5, 22.5, 21.48776413515348, -0.787432121259546, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2624400.0000, 
sim time next is 2625600.0000, 
raw observation next is [-6.133333333333335, 71.66666666666667, 90.33333333333333, 75.83333333333334, 22.5, 21.03857266177855, -0.8446010219220453, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.29270544783010155, 0.7166666666666667, 0.3011111111111111, 0.0837937384898711, 0.375, 0.2532143884815457, 0.2184663260259849, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42858133], dtype=float32), 0.89786386]. 
=============================================
[2019-04-16 12:13:53,840] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.5605435e-01 7.9636707e-04 2.2055574e-04 5.8968441e-04 8.5218526e-05
 4.9010753e-03 1.9303814e-06 4.3197691e-01 3.0373261e-04 4.7283052e-03
 3.4185630e-04], sum to 1.0000
[2019-04-16 12:13:53,840] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0061
[2019-04-16 12:13:53,868] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 36.0, 0.0, 0.0, 22.5, 23.41310575748782, -0.04197498352687504, 1.0, 1.0, 50.0, 53.782635639908904], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2574000.0000, 
sim time next is 2575200.0000, 
raw observation next is [-0.9666666666666667, 38.66666666666667, 0.0, 0.0, 22.5, 23.54482682558587, -0.1523216104976001, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.43582640812557716, 0.3866666666666667, 0.0, 0.0, 0.375, 0.46206890213215573, 0.4492261298341333, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3055468], dtype=float32), -0.21265697]. 
=============================================
[2019-04-16 12:13:54,810] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.5310525e-01 9.9554602e-03 3.1868366e-03 4.3768384e-03 2.2951865e-03
 4.2348597e-02 2.7206136e-04 5.5145264e-01 6.8594380e-03 2.3589434e-02
 2.5583468e-03], sum to 1.0000
[2019-04-16 12:13:54,810] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2892
[2019-04-16 12:13:54,838] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 36.0, 81.0, 803.0, 19.0, 19.9423511577134, -0.8990915618001983, 0.0, 1.0, 50.0, 43.493300015637644], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2458800.0000, 
sim time next is 2460000.0000, 
raw observation next is [-1.733333333333333, 34.33333333333334, 84.33333333333334, 820.3333333333334, 19.0, 20.0196959117192, -0.9945664916361309, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.41458910433979695, 0.34333333333333343, 0.28111111111111114, 0.9064456721915286, 0.08333333333333333, 0.16830799264326668, 0.16847783612128972, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10352224], dtype=float32), -0.17223582]. 
=============================================
[2019-04-16 12:13:54,859] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[8.544062 ]
 [7.9880333]
 [7.4836354]
 [6.9087276]
 [7.285758 ]
 [7.328986 ]
 [7.365982 ]
 [6.804185 ]
 [6.951354 ]
 [7.2490416]
 [7.1655655]
 [7.0541935]
 [7.153132 ]
 [7.4724174]
 [7.5285406]
 [7.342078 ]
 [7.0812683]
 [7.652418 ]
 [7.208075 ]
 [7.3615966]
 [6.9512415]
 [7.081864 ]
 [7.0995336]
 [7.5176563]
 [6.923327 ]], R is [[ 9.22412205]
 [ 9.17194748]
 [ 9.10392094]
 [ 9.19407368]
 [10.07131004]
 [10.97059727]
 [10.86089134]
 [11.75228214]
 [11.6347599 ]
 [12.51841259]
 [13.23746109]
 [13.10508633]
 [12.97403526]
 [12.8442955 ]
 [13.56657314]
 [14.21074677]
 [14.06863976]
 [13.92795372]
 [14.73910713]
 [15.59171581]
 [15.43579865]
 [15.28144073]
 [15.96235275]
 [16.07525635]
 [16.04367065]].
[2019-04-16 12:13:55,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1987058e-01 1.3320831e-02 7.7299280e-03 7.7564828e-03 9.9326100e-04
 3.4082729e-02 1.4803308e-04 3.8755056e-01 5.8086528e-03 1.9348700e-02
 3.3903553e-03], sum to 1.0000
[2019-04-16 12:13:55,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8552
[2019-04-16 12:13:55,362] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.3, 79.0, 0.0, 0.0, 19.0, 19.77165700210613, -1.02295221036848, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2617200.0000, 
sim time next is 2618400.0000, 
raw observation next is [-7.300000000000001, 79.0, 0.0, 0.0, 22.5, 19.54480280363668, -0.8668179017887669, 1.0, 1.0, 50.0, 81.91350015693261], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.79, 0.0, 0.0, 0.375, 0.12873356696972346, 0.21106069940374436, 1.0, 1.0, 0.7, 0.8191350015693262], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8229425], dtype=float32), 1.056411]. 
=============================================
[2019-04-16 12:14:08,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1466068e-01 1.8207213e-02 4.0191449e-03 5.2377330e-03 9.9888130e-04
 2.1938922e-02 1.7464289e-04 3.0368328e-01 8.6765783e-03 1.9236464e-02
 3.1664439e-03], sum to 1.0000
[2019-04-16 12:14:08,919] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0852
[2019-04-16 12:14:08,940] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 20.38275036954428, -0.7523155360584178, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2949600.0000, 
sim time next is 2950800.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 19.98544331833675, -0.8585629841810835, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.16545360986139576, 0.21381233860630552, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9293197], dtype=float32), 0.9111686]. 
=============================================
[2019-04-16 12:14:10,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2892307e-01 7.0522954e-03 2.5171335e-03 3.2886546e-03 8.8944327e-04
 1.7745154e-02 1.2310616e-04 5.1133138e-01 4.5925668e-03 2.2118293e-02
 1.4188086e-03], sum to 1.0000
[2019-04-16 12:14:10,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3917
[2019-04-16 12:14:10,036] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 77.0, 0.0, 0.0, 19.0, 19.11948761908959, -0.8552002252654588, 0.0, 1.0, 50.0, 93.65915588481757], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2964000.0000, 
sim time next is 2965200.0000, 
raw observation next is [-4.0, 77.0, 14.0, 15.66666666666666, 19.0, 19.56093062870554, -0.9727133592966419, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.3518005540166205, 0.77, 0.04666666666666667, 0.017311233885819514, 0.08333333333333333, 0.13007755239212818, 0.175762213567786, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.360962], dtype=float32), 0.78611875]. 
=============================================
[2019-04-16 12:14:11,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2221758e-01 1.4529379e-02 4.7028479e-03 6.0484544e-03 1.2280003e-03
 4.6434067e-02 3.0535061e-04 4.6822575e-01 8.4810527e-03 2.3048751e-02
 4.7787474e-03], sum to 1.0000
[2019-04-16 12:14:11,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6145
[2019-04-16 12:14:11,698] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.666666666666666, 55.66666666666667, 100.1666666666667, 655.6666666666667, 19.0, 18.82062587935688, -1.125235091005413, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3058800.0000, 
sim time next is 3060000.0000, 
raw observation next is [-4.0, 54.0, 102.5, 697.0, 19.0, 18.94777691641287, -0.9235368421360213, 0.0, 1.0, 50.0, 63.12584904899401], 
processed observation next is [0.0, 0.43478260869565216, 0.3518005540166205, 0.54, 0.3416666666666667, 0.7701657458563536, 0.08333333333333333, 0.07898140970107252, 0.19215438595465958, 0.0, 1.0, 0.7, 0.6312584904899401], 
reward next is 0.1044, 
noisyNet noise sample is [array([0.52133715], dtype=float32), 0.14415808]. 
=============================================
[2019-04-16 12:14:11,703] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[8.935155 ]
 [9.103845 ]
 [9.319958 ]
 [9.899785 ]
 [9.520027 ]
 [9.801355 ]
 [9.2235985]
 [9.383878 ]
 [9.220847 ]
 [8.766786 ]
 [9.063765 ]
 [8.927787 ]
 [8.573031 ]
 [8.327678 ]
 [8.391003 ]
 [7.6495867]
 [8.107867 ]
 [7.986101 ]
 [8.048721 ]
 [8.1553755]
 [8.250402 ]
 [8.192473 ]
 [8.873845 ]
 [9.258473 ]
 [9.498942 ]], R is [[ 9.44067001]
 [10.21756268]
 [11.11538696]
 [12.00423336]
 [11.9391098 ]
 [11.86296749]
 [11.74433804]
 [12.62689495]
 [12.53738785]
 [12.41201401]
 [13.28789425]
 [13.19445038]
 [13.09762192]
 [12.99777889]
 [12.87718201]
 [12.99815369]
 [13.86817265]
 [14.01302719]
 [14.76192474]
 [15.6143055 ]
 [15.49153137]
 [16.33661652]
 [17.1732502 ]
 [17.09046364]
 [17.91955948]].
[2019-04-16 12:14:11,798] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5754609e-01 1.3897511e-02 3.4561474e-03 7.8800116e-03 1.9389244e-03
 2.8840220e-02 2.1642161e-04 4.4904533e-01 6.9757728e-03 2.7151268e-02
 3.0522770e-03], sum to 1.0000
[2019-04-16 12:14:11,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1241
[2019-04-16 12:14:11,820] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 19.0, 19.64178864527729, -1.028104530791207, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3030000.0000, 
sim time next is 3031200.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 19.0, 19.13662768034403, -1.131327249436233, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.32409972299168976, 0.71, 0.0, 0.0, 0.08333333333333333, 0.09471897336200256, 0.12289091685458901, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.70374787], dtype=float32), -0.22420147]. 
=============================================
[2019-04-16 12:14:15,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2539846e-01 7.3524909e-03 1.5370501e-03 1.8688948e-03 4.6970235e-04
 1.4562012e-02 5.5848443e-05 3.2281026e-01 5.6287013e-03 1.8755758e-02
 1.5607749e-03], sum to 1.0000
[2019-04-16 12:14:15,279] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4099
[2019-04-16 12:14:15,290] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 19.15732340230611, -1.039417932623935, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3016800.0000, 
sim time next is 3018000.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 19.05520105576046, -1.066833232829886, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.08793342131337163, 0.144388922390038, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.66092014], dtype=float32), -0.61426914]. 
=============================================
[2019-04-16 12:14:16,676] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.7750595e-01 2.9454443e-03 6.1907963e-04 1.4914684e-03 7.2132429e-04
 2.7147869e-02 1.6082760e-05 4.7087356e-01 2.6552759e-03 1.5382413e-02
 6.4157625e-04], sum to 1.0000
[2019-04-16 12:14:16,676] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1073
[2019-04-16 12:14:16,689] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 51.66666666666666, 113.1666666666667, 815.1666666666667, 19.0, 21.37368897732227, -0.5293024659021146, 0.0, 1.0, 50.0, 39.1556052702597], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3069600.0000, 
sim time next is 3070800.0000, 
raw observation next is [-2.0, 50.0, 111.5, 811.5, 19.0, 21.43636457660686, -0.6320889969530482, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.40720221606648205, 0.5, 0.37166666666666665, 0.8966850828729281, 0.08333333333333333, 0.28636371471723826, 0.28930366768231724, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.068075], dtype=float32), 0.4549662]. 
=============================================
[2019-04-16 12:14:18,887] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.7921853e-01 3.3517189e-03 4.7799834e-04 2.8394608e-04 7.9168829e-05
 2.4707487e-03 2.5271790e-06 3.0909112e-01 4.4690500e-04 4.3989564e-03
 1.7827500e-04], sum to 1.0000
[2019-04-16 12:14:18,889] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7096
[2019-04-16 12:14:18,924] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 23.58517058680319, 0.06070214642981673, 0.0, 1.0, 50.0, 41.439193786305054], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3358800.0000, 
sim time next is 3360000.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 23.69058197260628, 0.06768924294160561, 0.0, 1.0, 50.0, 40.94800447400242], 
processed observation next is [1.0, 0.9130434782608695, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.4742151643838568, 0.5225630809805352, 0.0, 1.0, 0.7, 0.4094800447400242], 
reward next is 0.0655, 
noisyNet noise sample is [array([0.5832441], dtype=float32), 1.90669]. 
=============================================
[2019-04-16 12:14:18,925] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4540002e-01 3.9692661e-03 2.4294767e-03 2.0261304e-03 1.1353113e-04
 1.3331870e-02 1.1473075e-05 4.1931343e-01 1.0609721e-03 1.1491582e-02
 8.5226994e-04], sum to 1.0000
[2019-04-16 12:14:18,925] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3327
[2019-04-16 12:14:18,930] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[14.899763 ]
 [15.376543 ]
 [15.307095 ]
 [15.134886 ]
 [15.755698 ]
 [15.2667885]
 [16.047647 ]
 [15.871635 ]
 [16.459929 ]
 [16.26229  ]
 [16.336643 ]
 [16.461306 ]
 [16.775534 ]
 [16.883224 ]
 [16.38794  ]
 [16.681374 ]
 [16.426304 ]
 [16.007866 ]
 [15.42935  ]
 [16.033867 ]
 [15.704317 ]
 [16.153646 ]
 [15.910015 ]
 [16.177528 ]
 [16.315836 ]], R is [[15.4912281 ]
 [15.39692402]
 [15.24295521]
 [16.09052658]
 [15.98582649]
 [15.82596874]
 [16.66770935]
 [16.50103188]
 [17.33602142]
 [18.1626606 ]
 [18.98103333]
 [19.79122353]
 [20.59331131]
 [21.38737869]
 [21.17350578]
 [21.96177101]
 [21.83499336]
 [21.69947624]
 [21.482481  ]
 [22.26765633]
 [23.0449791 ]
 [23.81452942]
 [23.57638359]
 [24.34062004]
 [25.09721375]].
[2019-04-16 12:14:18,974] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 19.0, 22.14372060291693, -0.2243872987382887, 0.0, 1.0, 50.0, 62.492079344027296], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3290400.0000, 
sim time next is 3291600.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 22.2386444301742, -0.3533661987589192, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.35322036918118344, 0.3822112670803603, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.42912772], dtype=float32), -0.12825267]. 
=============================================
[2019-04-16 12:14:19,155] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.8597684e-01 1.5331531e-04 4.7930593e-05 3.8815822e-05 6.8066961e-06
 1.1476496e-03 1.7475199e-07 4.1148174e-01 1.1369568e-04 1.0152748e-03
 1.7801489e-05], sum to 1.0000
[2019-04-16 12:14:19,156] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6341
[2019-04-16 12:14:19,200] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.0, 47.33333333333334, 64.5, 529.8333333333333, 22.5, 25.12741103357331, 0.06601897245013666, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3342000.0000, 
sim time next is 3343200.0000, 
raw observation next is [-2.0, 48.66666666666666, 51.83333333333334, 439.6666666666667, 22.5, 24.69355633349093, 0.2915580720147159, 1.0, 1.0, 50.0, 56.490147250084874], 
processed observation next is [1.0, 0.6956521739130435, 0.40720221606648205, 0.4866666666666666, 0.1727777777777778, 0.48581952117863725, 0.375, 0.557796361124244, 0.5971860240049053, 1.0, 1.0, 0.7, 0.5649014725008488], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9099399], dtype=float32), 0.54090863]. 
=============================================
[2019-04-16 12:14:22,401] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4145505e-01 9.8152435e-04 2.9850533e-04 2.1673193e-04 2.8139855e-05
 3.3321213e-03 1.9365884e-06 3.5229144e-01 1.9738372e-04 1.0618266e-03
 1.3531859e-04], sum to 1.0000
[2019-04-16 12:14:22,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8159
[2019-04-16 12:14:22,452] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.666666666666667, 48.66666666666666, 110.0, 770.6666666666667, 22.5, 23.39535122064984, -0.1749232629654357, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3408000.0000, 
sim time next is 3409200.0000, 
raw observation next is [3.0, 49.0, 112.0, 784.0, 22.5, 23.77257333466385, 0.008904876147877763, 1.0, 1.0, 50.0, 73.93818093096066], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.49, 0.37333333333333335, 0.8662983425414365, 0.375, 0.48104777788865416, 0.5029682920492926, 1.0, 1.0, 0.7, 0.7393818093096065], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3666017], dtype=float32), 0.44758815]. 
=============================================
[2019-04-16 12:14:22,707] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-16 12:14:22,708] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:14:22,708] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:14:22,708] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:14:22,709] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:14:22,710] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run6
[2019-04-16 12:14:22,710] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:14:22,711] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:14:22,727] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run6
[2019-04-16 12:14:22,738] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run6
[2019-04-16 12:15:19,503] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([0.02927048], dtype=float32), 0.04330881]
[2019-04-16 12:15:19,503] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation this: [-0.3333333333333334, 100.0, 0.0, 0.0, 19.0, 19.43305360006864, -1.049024156389632, 0.0, 1.0, 15.0, 0.0]
[2019-04-16 12:15:19,504] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-16 12:15:19,505] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Softmax [6.5315390e-01 3.7490823e-03 9.4390573e-04 1.1187500e-03 1.9056621e-04
 7.0976503e-03 1.9575096e-05 3.2047707e-01 1.6071437e-03 1.1019365e-02
 6.2310469e-04], sampled 0.6364164879007697
[2019-04-16 12:15:32,598] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2600.9198 89891.9588 206.1827
[2019-04-16 12:15:32,618] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:32,618] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:32,618] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:32,618] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:32,618] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:32,618] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:32,733] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:32,733] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:32,733] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:32,733] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:32,733] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:32,733] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:43,375] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2436.9174 93765.2710 -332.0218
[2019-04-16 12:15:43,394] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:43,394] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:43,394] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:43,394] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:43,394] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:43,394] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:43,507] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:43,507] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:43,507] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:43,507] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:43,507] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:43,507] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:46,414] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2400.1404 97065.2796 -462.1806
[2019-04-16 12:15:46,434] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:46,434] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:46,434] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:46,434] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:46,434] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:46,434] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:15:46,542] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:46,542] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:46,542] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:46,542] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:46,542] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:46,542] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:15:47,437] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 250000, evaluation results [250000.0, 2436.9173976677494, 93765.27103526022, -332.02184032480227, 2600.91981056622, 89891.95881265291, 206.1826647958262, 2400.1404209717034, 97065.2795624476, -462.1806452222962]
[2019-04-16 12:15:50,110] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6704130e-01 4.7239857e-03 1.4730651e-03 5.7373551e-04 1.4336692e-04
 7.2802040e-03 1.3561384e-05 2.9951054e-01 1.7961256e-03 1.6187400e-02
 1.2567122e-03], sum to 1.0000
[2019-04-16 12:15:50,110] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1166
[2019-04-16 12:15:50,125] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 20.93866104232361, -0.6488648098433333, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3375600.0000, 
sim time next is 3376800.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 20.64160731330237, -0.7090226898068996, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.22013394277519746, 0.2636591033977001, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7963469], dtype=float32), -0.48009297]. 
=============================================
[2019-04-16 12:15:55,952] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.9218544e-01 3.7722773e-04 6.3516796e-05 4.6826488e-05 6.1872270e-06
 2.8787032e-03 1.8556874e-07 5.0345695e-01 1.1216391e-04 8.2572200e-04
 4.7086800e-05], sum to 1.0000
[2019-04-16 12:15:55,952] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5038
[2019-04-16 12:15:56,026] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 60.0, 83.16666666666666, 682.3333333333333, 22.5, 24.85031801347116, 0.2492722509457553, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3771600.0000, 
sim time next is 3772800.0000, 
raw observation next is [0.0, 60.0, 75.5, 625.0, 22.5, 25.12259503326485, 0.46416071334401, 1.0, 1.0, 50.0, 61.29661919096534], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.6, 0.25166666666666665, 0.6906077348066298, 0.375, 0.5935495861054042, 0.6547202377813367, 1.0, 1.0, 0.7, 0.6129661919096534], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3877103], dtype=float32), 0.46895525]. 
=============================================
[2019-04-16 12:15:56,267] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.4376346e-01 2.5278871e-04 3.4623714e-05 2.8119419e-05 2.1532549e-06
 1.6932535e-03 6.6631380e-08 4.5357138e-01 5.2794407e-05 5.7772605e-04
 2.3576760e-05], sum to 1.0000
[2019-04-16 12:15:56,268] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9014
[2019-04-16 12:15:56,299] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.333333333333333, 67.33333333333333, 14.16666666666667, 122.5, 22.5, 25.37244048743215, 0.487023466574531, 1.0, 1.0, 50.0, 53.074929439864974], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3778800.0000, 
sim time next is 3780000.0000, 
raw observation next is [-2.0, 71.0, 0.0, 0.0, 22.5, 25.72050210517656, 0.5210476949217829, 1.0, 1.0, 50.0, 38.696017542721165], 
processed observation next is [1.0, 0.782608695652174, 0.40720221606648205, 0.71, 0.0, 0.0, 0.375, 0.64337517543138, 0.6736825649739276, 1.0, 1.0, 0.7, 0.3869601754272117], 
reward next is 0.0880, 
noisyNet noise sample is [array([1.3877103], dtype=float32), 0.46895525]. 
=============================================
[2019-04-16 12:15:56,312] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[19.17308  ]
 [18.574108 ]
 [18.663038 ]
 [18.633854 ]
 [18.394115 ]
 [18.017078 ]
 [17.68661  ]
 [18.335932 ]
 [17.991669 ]
 [17.96017  ]
 [17.9147   ]
 [17.838438 ]
 [18.084297 ]
 [17.879116 ]
 [17.949047 ]
 [17.560661 ]
 [17.259544 ]
 [17.240177 ]
 [17.1427   ]
 [17.172726 ]
 [15.893928 ]
 [15.619984 ]
 [15.2330675]
 [13.854239 ]
 [13.668156 ]], R is [[18.64997292]
 [18.46347427]
 [19.27883911]
 [19.18262291]
 [19.08464622]
 [18.97902679]
 [18.78923607]
 [19.60134315]
 [20.40533066]
 [21.20127678]
 [20.98926353]
 [21.77937126]
 [22.56157684]
 [22.33596039]
 [23.11260033]
 [23.88147545]
 [23.72418404]
 [23.48694229]
 [24.25207329]
 [25.009552  ]
 [24.75945663]
 [25.5118618 ]
 [25.3089447 ]
 [25.0558548 ]
 [25.80529594]].
[2019-04-16 12:16:00,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.71714747e-01 9.23340209e-04 1.39270633e-04 1.02901126e-04
 2.62623544e-05 2.25751451e-03 6.73018633e-07 2.23633870e-01
 1.49361716e-04 8.80832551e-04 1.71301057e-04], sum to 1.0000
[2019-04-16 12:16:00,769] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4467
[2019-04-16 12:16:00,784] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.666666666666667, 49.0, 110.8333333333333, 761.1666666666667, 22.5, 23.21632187081615, -0.1779155012709108, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3925200.0000, 
sim time next is 3926400.0000, 
raw observation next is [-6.333333333333334, 49.0, 114.1666666666667, 780.8333333333334, 22.5, 23.24645732256701, -0.173426290673094, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.28716528162511545, 0.49, 0.38055555555555565, 0.8627992633517496, 0.375, 0.43720477688058423, 0.44219123644230196, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2260149], dtype=float32), -1.3962848]. 
=============================================
[2019-04-16 12:16:04,461] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6473997e-01 4.1228868e-03 9.8795060e-04 2.3316403e-03 2.9025812e-04
 1.1957225e-02 1.4820588e-05 3.0209655e-01 1.6175209e-03 1.1060223e-02
 7.8097224e-04], sum to 1.0000
[2019-04-16 12:16:04,466] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6226
[2019-04-16 12:16:04,482] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.333333333333334, 65.0, 0.0, 0.0, 19.0, 21.24085542351804, -0.571162099837844, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3908400.0000, 
sim time next is 3909600.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 20.86749026619561, -0.6318555829011889, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.23895752218296748, 0.2893814723662704, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3093069], dtype=float32), 0.84555304]. 
=============================================
[2019-04-16 12:16:06,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8420070e-01 3.7488635e-03 6.3288835e-04 1.1706912e-03 2.3256532e-04
 1.4020843e-02 6.2390964e-06 2.7701059e-01 6.8818039e-04 1.7936515e-02
 3.5193661e-04], sum to 1.0000
[2019-04-16 12:16:06,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3018
[2019-04-16 12:16:06,427] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 173.5, 313.5, 19.0, 21.75513288189547, -0.2422131079530834, 0.0, 1.0, 50.0, 64.66357203648288], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4201200.0000, 
sim time next is 4202400.0000, 
raw observation next is [2.333333333333333, 41.66666666666667, 164.5, 463.1666666666667, 19.0, 22.50039640120778, -0.254473654055319, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5272391505078486, 0.41666666666666674, 0.5483333333333333, 0.5117863720073665, 0.08333333333333333, 0.3750330334339817, 0.41517544864822703, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3637689], dtype=float32), 0.6577508]. 
=============================================
[2019-04-16 12:16:06,570] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.0281661e-01 6.9839880e-03 9.7506319e-04 2.1215826e-03 2.9107789e-04
 9.1225468e-03 5.5481789e-05 2.6112032e-01 2.4989413e-03 1.2668578e-02
 1.3458445e-03], sum to 1.0000
[2019-04-16 12:16:06,572] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4989
[2019-04-16 12:16:06,584] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.333333333333334, 49.66666666666667, 0.0, 0.0, 19.0, 22.45697435654366, -0.2296889926828133, 0.0, 1.0, 50.0, 42.53429524386563], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4170000.0000, 
sim time next is 4171200.0000, 
raw observation next is [-4.666666666666666, 49.33333333333333, 0.0, 0.0, 19.0, 22.43122690723029, -0.3689923763690385, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.33333333333333337, 0.4933333333333333, 0.0, 0.0, 0.08333333333333333, 0.36926890893585745, 0.37700254121032045, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0747252], dtype=float32), 0.098168135]. 
=============================================
[2019-04-16 12:16:06,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5839031e-01 1.9491306e-03 5.2401237e-04 7.3876698e-04 1.2975252e-04
 8.0424193e-03 4.3461541e-06 2.1607381e-01 4.8427691e-04 1.3451580e-02
 2.1164484e-04], sum to 1.0000
[2019-04-16 12:16:06,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2663
[2019-04-16 12:16:06,713] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.5, 41.66666666666667, 0.0, 0.0, 19.0, 22.08394542802517, -0.410588723329499, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4214400.0000, 
sim time next is 4215600.0000, 
raw observation next is [1.4, 42.0, 0.0, 0.0, 19.0, 21.90262323458381, -0.4455532687926556, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.5013850415512465, 0.42, 0.0, 0.0, 0.08333333333333333, 0.3252186028819842, 0.35148224373578146, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3637689], dtype=float32), 0.6577508]. 
=============================================
[2019-04-16 12:16:07,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1103814e-01 1.8646868e-03 6.6242043e-05 9.7092889e-05 1.4318183e-05
 3.5540501e-03 2.4494062e-07 1.7975859e-01 1.2708947e-04 3.4424455e-03
 3.7079619e-05], sum to 1.0000
[2019-04-16 12:16:07,687] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7045
[2019-04-16 12:16:07,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.666666666666668, 60.33333333333333, 0.0, 0.0, 19.0, 25.61487470001166, 0.5114984663175902, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4398000.0000, 
sim time next is 4399200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 19.0, 25.34431416806471, 0.4451350521474697, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.7229916897506927, 0.61, 0.0, 0.0, 0.08333333333333333, 0.6120261806720592, 0.6483783507158233, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8565518], dtype=float32), 0.35552567]. 
=============================================
[2019-04-16 12:16:09,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.3746935e-01 1.7682707e-03 2.3453253e-04 2.2609216e-04 3.1449879e-05
 5.8472957e-03 1.2438846e-06 3.5092819e-01 5.9295748e-04 2.6911518e-03
 2.0943016e-04], sum to 1.0000
[2019-04-16 12:16:09,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8158
[2019-04-16 12:16:09,943] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [11.73333333333333, 36.66666666666666, 115.8333333333333, 788.0, 22.5, 24.82555333940763, 0.2392244515904927, 1.0, 1.0, 50.0, 38.937729599369106], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4358400.0000, 
sim time next is 4359600.0000, 
raw observation next is [12.6, 34.0, 117.5, 804.0, 22.5, 25.3784398532961, 0.3291064803155987, 1.0, 1.0, 50.0, 36.60204821669254], 
processed observation next is [1.0, 0.4782608695652174, 0.8116343490304709, 0.34, 0.39166666666666666, 0.8883977900552487, 0.375, 0.614869987774675, 0.6097021601051996, 1.0, 1.0, 0.7, 0.3660204821669254], 
reward next is 0.1090, 
noisyNet noise sample is [array([1.4664458], dtype=float32), -0.97280747]. 
=============================================
[2019-04-16 12:16:11,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0011649e-01 2.4765774e-04 6.1180152e-05 1.5120161e-05 6.1754886e-06
 9.8038430e-04 7.2364010e-08 3.9804843e-01 1.7538472e-05 4.7084951e-04
 3.6110821e-05], sum to 1.0000
[2019-04-16 12:16:11,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9890
[2019-04-16 12:16:12,025] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 86.0, 196.5, 73.0, 22.5, 25.99014658407848, 0.4340080162167664, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4446000.0000, 
sim time next is 4447200.0000, 
raw observation next is [1.0, 86.0, 160.1666666666667, 24.33333333333333, 22.5, 25.8803936541119, 0.3691374365744228, 1.0, 1.0, 50.0, 55.117637285959134], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.86, 0.5338888888888891, 0.026887661141804783, 0.375, 0.6566994711759916, 0.6230458121914743, 1.0, 1.0, 0.7, 0.5511763728595913], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49894267], dtype=float32), 0.6821717]. 
=============================================
[2019-04-16 12:16:14,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1340230e-01 2.7176598e-04 1.3030735e-04 9.6006137e-05 1.0872111e-05
 2.6665027e-03 3.7235469e-07 1.8202795e-01 1.6624099e-04 1.0056469e-03
 2.2198564e-04], sum to 1.0000
[2019-04-16 12:16:14,906] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6542
[2019-04-16 12:16:14,915] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 22.51631253490778, -0.238264217177514, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4562400.0000, 
sim time next is 4563600.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 22.26372560023258, -0.2786340350489492, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.35531046668604827, 0.40712198831701696, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.304324], dtype=float32), 0.185507]. 
=============================================
[2019-04-16 12:16:16,760] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1317941e-01 3.2117643e-04 4.0363513e-05 4.2271848e-05 7.6757915e-06
 1.3339767e-03 4.6490054e-08 2.8339937e-01 7.1069502e-05 1.5661871e-03
 3.8516897e-05], sum to 1.0000
[2019-04-16 12:16:16,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5378
[2019-04-16 12:16:16,777] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.800000000000001, 49.33333333333334, 192.3333333333333, 634.6666666666666, 22.5, 24.70919425513874, 0.2161005382743081, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4630800.0000, 
sim time next is 4632000.0000, 
raw observation next is [4.9, 49.66666666666666, 201.6666666666667, 520.6666666666666, 22.5, 24.8662506293508, 0.2435164931852987, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5983379501385043, 0.4966666666666666, 0.6722222222222224, 0.5753222836095764, 0.375, 0.5721875524459001, 0.5811721643950996, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30509982], dtype=float32), -0.9664038]. 
=============================================
[2019-04-16 12:16:17,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8843361e-01 2.3615614e-03 7.1116665e-04 6.3570682e-04 1.5184806e-04
 8.5304808e-03 7.8734956e-06 1.8540207e-01 8.9913781e-04 1.2538546e-02
 3.2798495e-04], sum to 1.0000
[2019-04-16 12:16:17,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6872
[2019-04-16 12:16:17,795] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.133333333333333, 92.66666666666667, 0.0, 0.0, 19.0, 20.07812734612813, -0.8690916621281389, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4776000.0000, 
sim time next is 4777200.0000, 
raw observation next is [-6.2, 93.0, 0.0, 0.0, 19.0, 19.46730655997649, -0.9551447659638607, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.2908587257617729, 0.93, 0.0, 0.0, 0.08333333333333333, 0.12227554666470741, 0.1816184113453798, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8732729], dtype=float32), 0.6159892]. 
=============================================
[2019-04-16 12:16:18,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6442540e-01 1.7166083e-03 2.7441146e-04 4.3995745e-04 1.5489994e-05
 9.5339399e-04 5.7620952e-07 2.2712281e-01 2.3968332e-04 4.6496005e-03
 1.6192332e-04], sum to 1.0000
[2019-04-16 12:16:18,947] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9009
[2019-04-16 12:16:18,999] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 57.0, 0.0, 0.0, 19.0, 23.59547285494562, 0.05415357638510435, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4662000.0000, 
sim time next is 4663200.0000, 
raw observation next is [2.0, 55.33333333333334, 0.0, 0.0, 19.0, 23.77813045027798, 0.2305694723839905, 0.0, 1.0, 50.0, 62.57727910925894], 
processed observation next is [1.0, 1.0, 0.518005540166205, 0.5533333333333335, 0.0, 0.0, 0.08333333333333333, 0.4815108708564984, 0.5768564907946635, 0.0, 1.0, 0.7, 0.6257727910925894], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2342975], dtype=float32), -0.30352217]. 
=============================================
[2019-04-16 12:16:19,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2952272e-01 1.8925178e-03 2.0383566e-04 2.3641811e-04 7.8805620e-05
 5.1529277e-03 2.6860851e-06 4.5039606e-01 7.2174350e-04 1.1562910e-02
 2.2936730e-04], sum to 1.0000
[2019-04-16 12:16:19,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4200
[2019-04-16 12:16:19,144] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 152.8333333333333, 404.5, 19.0, 21.10145513468325, -0.5136741808178715, 0.0, 1.0, 50.0, 56.6086854507834], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4894800.0000, 
sim time next is 4896000.0000, 
raw observation next is [3.0, 45.0, 132.5, 369.5, 19.0, 21.53037715088969, -0.5625391262074795, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.44166666666666665, 0.40828729281767956, 0.08333333333333333, 0.2941980959074743, 0.3124869579308402, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16900803], dtype=float32), -0.58079916]. 
=============================================
[2019-04-16 12:16:20,509] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6365794e-01 1.8814888e-02 5.6886999e-03 7.0830071e-03 2.2844425e-03
 2.7948566e-02 2.9191919e-04 3.1901768e-01 6.5208795e-03 4.4594690e-02
 4.0972820e-03], sum to 1.0000
[2019-04-16 12:16:20,510] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9159
[2019-04-16 12:16:20,544] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 19.0, 18.27594399145369, -1.271115675628501, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4860000.0000, 
sim time next is 4861200.0000, 
raw observation next is [-3.333333333333333, 61.66666666666667, 0.0, 0.0, 19.0, 18.56654729532211, -1.03501515711564, 0.0, 1.0, 50.0, 81.79453429015416], 
processed observation next is [0.0, 0.2608695652173913, 0.37026777469990774, 0.6166666666666667, 0.0, 0.0, 0.08333333333333333, 0.04721227461017582, 0.15499494762811997, 0.0, 1.0, 0.7, 0.8179453429015416], 
reward next is 0.8669, 
noisyNet noise sample is [array([-0.5084004], dtype=float32), 1.7863622]. 
=============================================
[2019-04-16 12:16:21,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.82700026e-01 1.84140546e-04 7.77228706e-05 1.77991642e-05
 4.44578654e-06 5.95426303e-04 1.07925473e-07 1.15770414e-01
 3.42833737e-05 5.66117989e-04 4.95727145e-05], sum to 1.0000
[2019-04-16 12:16:21,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4027
[2019-04-16 12:16:21,404] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 22.5, 22.62663790904623, -0.1660232729888743, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4734000.0000, 
sim time next is 4735200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 22.5, 22.50818362020977, -0.2009880690174228, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.78, 0.0, 0.0, 0.375, 0.3756819683508142, 0.4330039769941924, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6952343], dtype=float32), 0.8013909]. 
=============================================
[2019-04-16 12:16:22,756] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.1751256e-01 3.3088219e-03 1.8902590e-03 1.9102995e-03 5.5193336e-04
 1.3050815e-02 2.8833563e-05 4.2433375e-01 2.7202161e-03 3.3268481e-02
 1.4241369e-03], sum to 1.0000
[2019-04-16 12:16:22,758] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5449
[2019-04-16 12:16:22,806] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.666666666666667, 67.33333333333334, 0.0, 0.0, 19.0, 20.38642424258361, -0.8252900343418076, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4857600.0000, 
sim time next is 4858800.0000, 
raw observation next is [-3.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 20.37366711094262, -0.6727659690535712, 0.0, 1.0, 50.0, 67.97466723260422], 
processed observation next is [0.0, 0.21739130434782608, 0.37026777469990774, 0.6366666666666667, 0.0, 0.0, 0.08333333333333333, 0.19780559257855165, 0.27574467698214294, 0.0, 1.0, 0.7, 0.6797466723260421], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5449993], dtype=float32), -1.4399526]. 
=============================================
[2019-04-16 12:16:23,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7630076e-01 1.0234421e-02 9.0553641e-04 2.5259019e-03 3.0639497e-04
 1.6602250e-02 2.8088174e-05 2.7194238e-01 2.0856585e-03 1.7921049e-02
 1.1476335e-03], sum to 1.0000
[2019-04-16 12:16:23,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2770
[2019-04-16 12:16:23,569] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 50.0, 0.0, 0.0, 19.0, 19.19043765200509, -1.121960743829352, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4939200.0000, 
sim time next is 4940400.0000, 
raw observation next is [-2.0, 48.66666666666667, 0.0, 0.0, 19.0, 18.96675674438122, -1.153926159143901, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.40720221606648205, 0.4866666666666667, 0.0, 0.0, 0.08333333333333333, 0.08056306203176848, 0.11535794695203301, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9956, 
noisyNet noise sample is [array([0.35215527], dtype=float32), 0.78012854]. 
=============================================
[2019-04-16 12:16:24,290] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:24,442] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:24,557] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:24,715] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:25,269] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:25,286] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:25,287] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:25,288] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run5
[2019-04-16 12:16:25,448] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:25,546] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:25,546] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:25,551] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run5
[2019-04-16 12:16:26,285] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:26,285] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:26,291] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run5
[2019-04-16 12:16:26,515] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:26,694] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:27,489] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:27,513] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:27,513] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:27,515] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run5
[2019-04-16 12:16:27,544] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:27,651] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:27,715] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:27,838] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:27,874] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.7287155e-01 2.1399723e-04 2.0081881e-05 5.8202801e-05 5.5160485e-06
 1.5487045e-03 1.9026129e-07 2.2480147e-01 7.4946001e-05 3.7195621e-04
 3.3361150e-05], sum to 1.0000
[2019-04-16 12:16:27,875] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0867
[2019-04-16 12:16:27,886] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.666666666666667, 39.33333333333334, 115.3333333333333, 790.5, 22.5, 25.35911325069385, 0.4294233086986356, 1.0, 1.0, 50.0, 58.83133573465276], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5048400.0000, 
sim time next is 5049600.0000, 
raw observation next is [4.333333333333333, 37.66666666666667, 117.1666666666667, 815.0, 22.5, 25.92547782220706, 0.2206968743835625, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.58264081255771, 0.3766666666666667, 0.39055555555555566, 0.9005524861878453, 0.375, 0.6604564851839217, 0.5735656247945208, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1845907], dtype=float32), -0.018215666]. 
=============================================
[2019-04-16 12:16:27,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0419977e-01 6.2318295e-03 1.7724907e-03 2.4948150e-03 6.0972333e-04
 9.9200737e-03 3.8439932e-05 3.5083973e-01 2.6214833e-03 2.0061316e-02
 1.2102886e-03], sum to 1.0000
[2019-04-16 12:16:27,892] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3364
[2019-04-16 12:16:27,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 19.73455759167438, -0.8556644957136778, 0.0, 1.0, 20.0, 59.218059287058914], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4843200.0000, 
sim time next is 4844400.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 19.0, 19.95844564105563, -0.9350208594100206, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.6, 0.0, 0.0, 0.08333333333333333, 0.16320380342130245, 0.18832638019665981, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4767637], dtype=float32), 1.0341107]. 
=============================================
[2019-04-16 12:16:28,005] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:28,489] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:28,490] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:28,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run5
[2019-04-16 12:16:28,553] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:28,553] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:28,555] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run5
[2019-04-16 12:16:28,828] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:28,837] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:28,837] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:28,839] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run5
[2019-04-16 12:16:29,033] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:29,111] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:29,345] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:29,382] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:29,560] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:29,781] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:29,829] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:29,829] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:29,831] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run5
[2019-04-16 12:16:29,945] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:30,104] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:30,104] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:30,105] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run5
[2019-04-16 12:16:30,131] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:30,249] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:30,283] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:30,382] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:30,382] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:30,384] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run5
[2019-04-16 12:16:30,440] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:30,782] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:30,782] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:30,784] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run5
[2019-04-16 12:16:31,104] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:31,105] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:31,106] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run5
[2019-04-16 12:16:31,253] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:31,253] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:31,255] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run5
[2019-04-16 12:16:34,757] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:34,775] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:35,054] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:35,094] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:35,745] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:35,745] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:35,747] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run5
[2019-04-16 12:16:35,783] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:35,783] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:35,785] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run5
[2019-04-16 12:16:35,889] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:16:36,246] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-16 12:16:36,878] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:16:36,878] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:16:36,880] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run5
[2019-04-16 12:16:43,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1890650e-01 2.5036279e-03 4.0524884e-04 6.3780887e-04 5.1095074e-05
 5.8267163e-03 4.5141219e-06 3.6454526e-01 5.6993525e-04 6.2743244e-03
 2.7485384e-04], sum to 1.0000
[2019-04-16 12:16:43,118] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9154
[2019-04-16 12:16:43,171] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [7.699999999999999, 93.0, 78.5, 0.0, 19.0, 21.24708531519956, -0.5754919827536485, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 42000.0000, 
sim time next is 43200.0000, 
raw observation next is [7.7, 93.0, 85.5, 0.0, 19.0, 21.20387492452378, -0.4223065517631719, 0.0, 1.0, 50.0, 62.99536305682299], 
processed observation next is [0.0, 0.5217391304347826, 0.6759002770083103, 0.93, 0.285, 0.0, 0.08333333333333333, 0.2669895770436484, 0.359231149412276, 0.0, 1.0, 0.7, 0.6299536305682298], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5204982], dtype=float32), -0.13675775]. 
=============================================
[2019-04-16 12:16:44,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1744205e-01 5.6618894e-03 6.9921406e-04 7.2567590e-04 1.4837518e-04
 9.4743064e-03 5.6002559e-06 5.6013757e-01 1.0364210e-03 4.2480091e-03
 4.2083533e-04], sum to 1.0000
[2019-04-16 12:16:44,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2265
[2019-04-16 12:16:44,722] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 87.0, 0.0, 0.0, 19.0, 20.13821010487754, -0.7441430172472426, 0.0, 1.0, 50.0, 65.74114778788905], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 97200.0000, 
sim time next is 98400.0000, 
raw observation next is [-3.0, 84.33333333333334, 0.0, 0.0, 19.0, 20.31606714837945, -0.846472493527567, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.8433333333333334, 0.0, 0.0, 0.08333333333333333, 0.19300559569828746, 0.21784250215747766, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0236652], dtype=float32), -2.158022]. 
=============================================
[2019-04-16 12:16:47,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7076262e-01 7.9982344e-04 2.7002502e-04 2.9031929e-04 3.0284873e-05
 3.2077823e-03 1.1263285e-06 2.1828425e-01 5.6947191e-04 5.5864775e-03
 1.9776073e-04], sum to 1.0000
[2019-04-16 12:16:47,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2075
[2019-04-16 12:16:47,558] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 87.66666666666667, 0.0, 0.0, 19.0, 20.7257258208477, -0.6406999353763568, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 73200.0000, 
sim time next is 74400.0000, 
raw observation next is [1.966666666666667, 86.33333333333334, 0.0, 0.0, 19.0, 20.45055932254573, -0.6893138669912161, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.5170821791320407, 0.8633333333333334, 0.0, 0.0, 0.08333333333333333, 0.20421327687881075, 0.27022871100292795, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3856239], dtype=float32), -0.22931704]. 
=============================================
[2019-04-16 12:16:49,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1406491e-01 5.2333861e-03 1.1383318e-03 2.2797217e-03 1.2119762e-04
 8.8824192e-03 1.8933670e-05 5.5039811e-01 2.1957222e-03 1.4659250e-02
 1.0079677e-03], sum to 1.0000
[2019-04-16 12:16:49,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3870
[2019-04-16 12:16:49,680] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 18.97418189311664, -1.044523227177741, 0.0, 1.0, 50.0, 50.44364956688719], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 190800.0000, 
sim time next is 192000.0000, 
raw observation next is [-8.900000000000002, 78.0, 0.0, 0.0, 19.0, 19.12222675885614, -1.174295107435386, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2160664819944598, 0.78, 0.0, 0.0, 0.08333333333333333, 0.093518896571345, 0.108568297521538, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03228571], dtype=float32), -1.3909727]. 
=============================================
[2019-04-16 12:16:52,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6607168e-01 6.8112399e-04 1.5853342e-04 1.3575933e-04 1.8681058e-05
 2.6741116e-03 8.7553889e-07 2.2830404e-01 3.4022712e-04 1.4669813e-03
 1.4787879e-04], sum to 1.0000
[2019-04-16 12:16:52,452] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7712
[2019-04-16 12:16:52,576] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.4, 63.0, 24.33333333333333, 0.0, 22.5, 21.07527267825602, -0.6203351891213725, 1.0, 1.0, 50.0, 99.29369836620702], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 231600.0000, 
sim time next is 232800.0000, 
raw observation next is [-3.4, 64.0, 15.0, 0.0, 22.5, 22.39518884634157, -0.5682652298361098, 1.0, 1.0, 50.0, 60.53657871026087], 
processed observation next is [1.0, 0.6956521739130435, 0.368421052631579, 0.64, 0.05, 0.0, 0.375, 0.3662657371951307, 0.31057825672129674, 1.0, 1.0, 0.7, 0.6053657871026087], 
reward next is 0.3413, 
noisyNet noise sample is [array([-2.0239875], dtype=float32), 0.36476347]. 
=============================================
[2019-04-16 12:17:07,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2335461e-01 5.4504671e-03 1.6947612e-03 1.9772616e-03 1.9631481e-04
 1.3447452e-02 2.6014046e-05 3.3855185e-01 1.7746435e-03 1.2613566e-02
 9.1300433e-04], sum to 1.0000
[2019-04-16 12:17:07,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3948
[2019-04-16 12:17:07,908] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 67.0, 0.0, 0.0, 19.0, 17.20697282768302, -1.413436101611923, 0.0, 1.0, 50.0, 75.35175500248836], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 624000.0000, 
sim time next is 625200.0000, 
raw observation next is [-4.5, 66.0, 0.0, 0.0, 19.0, 17.65169298398927, -1.515868540075253, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.3379501385041552, 0.66, 0.0, 0.0, 0.08333333333333333, -0.02902558466756074, -0.005289513358417652, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6011319], dtype=float32), 0.6267138]. 
=============================================
[2019-04-16 12:17:08,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.30838704e-01 2.96755740e-03 1.19038695e-03 2.28839344e-03
 1.05802785e-04 1.29874740e-02 8.50422839e-06 5.40900826e-01
 1.95835624e-03 6.08185912e-03 6.72106340e-04], sum to 1.0000
[2019-04-16 12:17:08,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3706
[2019-04-16 12:17:08,917] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 19.0, 17.47911894411389, -1.588069637786172, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 716400.0000, 
sim time next is 717600.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 22.5, 16.96565606284415, -1.645200075548026, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.3988919667590028, 0.76, 0.0, 0.0, 0.375, -0.0861953280963208, -0.04840002518267535, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27445114], dtype=float32), 2.1180792]. 
=============================================
[2019-04-16 12:17:13,180] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2903497e-01 9.3069933e-03 9.4522675e-04 1.8289812e-03 1.6867476e-04
 2.3430116e-02 1.7446851e-05 4.2557871e-01 1.2320265e-03 7.5510298e-03
 9.0573868e-04], sum to 1.0000
[2019-04-16 12:17:13,181] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7693
[2019-04-16 12:17:13,242] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.466666666666667, 75.66666666666667, 0.0, 0.0, 19.0, 18.13241805662446, -1.324962707114752, 0.0, 1.0, 50.0, 67.52973235905654], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 708000.0000, 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 19.0, 18.66583024568352, -1.261585370993906, 0.0, 1.0, 50.0, 47.963056077348945], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.76, 0.0, 0.0, 0.08333333333333333, 0.05548585380695995, 0.07947154300203134, 0.0, 1.0, 0.7, 0.4796305607734894], 
reward next is 0.6683, 
noisyNet noise sample is [array([-0.37340522], dtype=float32), -0.39726543]. 
=============================================
[2019-04-16 12:17:14,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4269876e-01 1.3204997e-03 2.4845480e-04 5.9598481e-04 3.5742585e-05
 2.8526220e-03 3.6393756e-06 3.4850416e-01 4.0803646e-04 2.9588356e-03
 3.7321323e-04], sum to 1.0000
[2019-04-16 12:17:14,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5835
[2019-04-16 12:17:14,926] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 19.0, 18.47348377401067, -1.182229346719534, 0.0, 1.0, 50.0, 73.79199306298582], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 715200.0000, 
sim time next is 716400.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 19.0, 18.93031664589643, -1.286962765987872, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.3988919667590028, 0.76, 0.0, 0.0, 0.08333333333333333, 0.07752638715803577, 0.07101241133737601, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.678717], dtype=float32), -0.37643066]. 
=============================================
[2019-04-16 12:17:18,224] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7320635e-01 1.3216380e-04 6.3347907e-05 2.1936256e-05 1.3054670e-06
 4.2171445e-04 4.1673751e-08 2.2560720e-01 4.0797677e-05 4.6592433e-04
 3.9213195e-05], sum to 1.0000
[2019-04-16 12:17:18,225] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1565
[2019-04-16 12:17:18,306] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 19.0, 22.01874397477879, -0.4566921371145381, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 937200.0000, 
sim time next is 938400.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 19.0, 21.57290267654342, -0.5554343551294328, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 1.0, 0.0, 0.0, 0.08333333333333333, 0.29774188971195176, 0.3148552149568557, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.81605756], dtype=float32), 0.4121276]. 
=============================================
[2019-04-16 12:17:19,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5310587e-01 3.8983519e-04 5.9555830e-05 4.7042497e-05 9.6898984e-06
 2.0782468e-03 6.1061627e-08 5.4276806e-01 9.3732364e-05 1.3788091e-03
 6.9075359e-05], sum to 1.0000
[2019-04-16 12:17:19,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4511
[2019-04-16 12:17:19,375] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 48.0, 70.83333333333334, 7.666666666666665, 22.5, 22.73533277726111, -0.5764762151534731, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 750000.0000, 
sim time next is 751200.0000, 
raw observation next is [-2.066666666666666, 51.0, 56.66666666666667, 2.833333333333333, 22.5, 22.18491598879485, -0.558332678237848, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.40535549399815335, 0.51, 0.1888888888888889, 0.0031307550644567215, 0.375, 0.3487429990662374, 0.31388910725405067, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9679, 
noisyNet noise sample is [array([-0.3588529], dtype=float32), -0.25470278]. 
=============================================
[2019-04-16 12:17:22,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.6436378e-01 1.5962316e-03 3.2028282e-04 3.6399908e-04 1.5392325e-05
 2.6389505e-03 1.2455107e-06 4.2702079e-01 2.6584446e-04 3.3191016e-03
 9.4447721e-05], sum to 1.0000
[2019-04-16 12:17:22,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1914
[2019-04-16 12:17:22,258] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 80.0, 38.5, 0.0, 22.5, 21.36194926611398, -0.8045328039409801, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 896400.0000, 
sim time next is 897600.0000, 
raw observation next is [1.1, 81.33333333333334, 44.83333333333333, 0.0, 22.5, 21.11626202832787, -0.8686014634913907, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8133333333333335, 0.14944444444444444, 0.0, 0.375, 0.2596885023606559, 0.2104661788362031, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0881832], dtype=float32), 1.1487142]. 
=============================================
[2019-04-16 12:17:23,973] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6289008e-01 2.3239334e-04 4.0591485e-06 3.1069474e-05 3.6982783e-07
 1.2373968e-04 2.7490688e-09 3.3589101e-01 2.7721604e-05 7.9079886e-04
 8.7467060e-06], sum to 1.0000
[2019-04-16 12:17:23,974] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9101
[2019-04-16 12:17:24,021] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 19.0, 23.81821159531347, 0.04294028168746708, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1024800.0000, 
sim time next is 1026000.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 19.0, 23.7624186510366, 0.1736573900920353, 0.0, 1.0, 50.0, 54.97871162488668], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.77, 0.0, 0.0, 0.08333333333333333, 0.48020155425305006, 0.5578857966973451, 0.0, 1.0, 0.7, 0.5497871162488668], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.65617675], dtype=float32), -0.6141476]. 
=============================================
[2019-04-16 12:17:24,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0334693e-01 7.4824266e-04 1.9999221e-04 2.0326448e-04 7.5965218e-06
 1.7716909e-03 3.4431025e-07 1.9140600e-01 8.7393877e-05 2.0581875e-03
 1.7046196e-04], sum to 1.0000
[2019-04-16 12:17:24,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4193
[2019-04-16 12:17:24,559] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.2, 77.33333333333334, 0.0, 0.0, 19.0, 22.29509726445843, -0.159784991683711, 0.0, 1.0, 50.0, 64.53646927582373], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1052400.0000, 
sim time next is 1053600.0000, 
raw observation next is [14.0, 77.66666666666667, 0.0, 0.0, 19.0, 22.76880156442832, -0.2123833051606544, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.8504155124653741, 0.7766666666666667, 0.0, 0.0, 0.08333333333333333, 0.3974001303690266, 0.4292055649464485, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6833312], dtype=float32), 1.6189609]. 
=============================================
[2019-04-16 12:17:25,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0024077e-01 1.3157841e-03 2.1409437e-04 1.7835686e-04 1.7513537e-05
 5.9514297e-03 6.9424976e-07 3.8926476e-01 6.4629850e-05 2.5793491e-03
 1.7253193e-04], sum to 1.0000
[2019-04-16 12:17:25,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6861
[2019-04-16 12:17:25,534] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 19.0, 21.57946614783325, -0.5368044562187317, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 972000.0000, 
sim time next is 973200.0000, 
raw observation next is [9.200000000000001, 83.0, 0.0, 0.0, 19.0, 21.76454568123989, -0.3880681462275939, 0.0, 1.0, 50.0, 62.93244089331502], 
processed observation next is [1.0, 0.2608695652173913, 0.7174515235457064, 0.83, 0.0, 0.0, 0.08333333333333333, 0.31371214010332427, 0.3706439512574687, 0.0, 1.0, 0.7, 0.6293244089331502], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38128188], dtype=float32), 0.016064776]. 
=============================================
[2019-04-16 12:17:25,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.0720422e-01 4.3344544e-03 5.3421682e-04 1.0160995e-03 1.2974160e-04
 4.6426556e-03 1.0499898e-05 2.7114853e-01 8.7463536e-04 9.2758993e-03
 8.2910038e-04], sum to 1.0000
[2019-04-16 12:17:25,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7438
[2019-04-16 12:17:25,674] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [16.1, 80.0, 0.0, 0.0, 19.0, 24.36402307192594, 0.3189730150537451, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1213200.0000, 
sim time next is 1214400.0000, 
raw observation next is [16.1, 81.0, 0.0, 0.0, 19.0, 24.54608514382427, 0.4988708564052565, 0.0, 0.0, 50.0, 59.830848872047895], 
processed observation next is [0.0, 0.043478260869565216, 0.9085872576177286, 0.81, 0.0, 0.0, 0.08333333333333333, 0.5455070953186892, 0.6662902854684188, 0.0, 0.0, 0.7, 0.5983084887204789], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71745455], dtype=float32), 0.014212224]. 
=============================================
[2019-04-16 12:17:26,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.42339152e-01 1.08157816e-04 1.03305501e-05 1.27363228e-05
 7.21320305e-07 3.98543576e-04 8.91979024e-09 5.56448340e-01
 6.09670451e-06 6.69693283e-04 6.13683824e-06], sum to 1.0000
[2019-04-16 12:17:26,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8850
[2019-04-16 12:17:26,271] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [12.36666666666667, 86.0, 126.6666666666667, 0.0, 22.5, 24.5898039548485, 0.02250089746456747, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 994800.0000, 
sim time next is 996000.0000, 
raw observation next is [12.53333333333333, 86.0, 126.5, 0.0, 22.5, 23.54982733519421, 0.155543778983353, 1.0, 1.0, 50.0, 56.83544634714522], 
processed observation next is [1.0, 0.5217391304347826, 0.8097876269621421, 0.86, 0.4216666666666667, 0.0, 0.375, 0.4624856112661841, 0.5518479263277843, 1.0, 1.0, 0.7, 0.5683544634714522], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3079612], dtype=float32), 1.144992]. 
=============================================
[2019-04-16 12:17:30,673] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.85692739e-01 1.50659017e-03 3.10188130e-04 1.65236561e-04
 1.18601693e-05 1.30388560e-03 1.28470549e-06 5.07036567e-01
 1.14459515e-04 3.77497496e-03 8.21943395e-05], sum to 1.0000
[2019-04-16 12:17:30,674] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5660
[2019-04-16 12:17:30,712] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [7.333333333333333, 80.66666666666666, 0.0, 0.0, 19.0, 20.39537106468995, -0.7987937705999953, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 960000.0000, 
sim time next is 961200.0000, 
raw observation next is [7.7, 80.0, 0.0, 0.0, 19.0, 20.54283930436477, -0.5977936094294728, 0.0, 1.0, 50.0, 68.94346974370103], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.8, 0.0, 0.0, 0.08333333333333333, 0.21190327536373074, 0.30073546352350905, 0.0, 1.0, 0.7, 0.6894346974370102], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29284945], dtype=float32), 0.6857514]. 
=============================================
[2019-04-16 12:17:32,053] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3632088e-01 1.0266389e-04 1.5189599e-05 1.5019795e-05 1.1083995e-06
 5.6980882e-04 2.4124530e-08 1.6266909e-01 1.3443386e-05 2.8511495e-04
 7.5818994e-06], sum to 1.0000
[2019-04-16 12:17:32,074] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4631
[2019-04-16 12:17:32,089] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.4, 93.0, 94.0, 704.0, 22.5, 22.83103705479605, -0.2123386245971276, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1512000.0000, 
sim time next is 1513200.0000, 
raw observation next is [5.333333333333334, 86.33333333333334, 98.0, 701.3333333333334, 22.5, 22.82900245295705, -0.2877476728120927, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6103416435826409, 0.8633333333333334, 0.32666666666666666, 0.7749539594843463, 0.375, 0.40241687107975405, 0.40408410906263575, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5325478], dtype=float32), -0.7107373]. 
=============================================
[2019-04-16 12:17:32,484] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.51693869e-01 6.65141852e-05 1.28117954e-05 2.08292586e-05
 6.77692185e-07 5.33023383e-04 2.14721041e-08 1.47463873e-01
 1.27903095e-05 1.75775815e-04 1.98619455e-05], sum to 1.0000
[2019-04-16 12:17:32,484] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1941
[2019-04-16 12:17:32,513] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 22.5, 21.34317064752521, -0.4830899885103752, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1450800.0000, 
sim time next is 1452000.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 21.17826352133746, -0.5133186111718763, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.2648552934447883, 0.32889379627604126, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9956, 
noisyNet noise sample is [array([0.6795908], dtype=float32), -0.43998918]. 
=============================================
[2019-04-16 12:17:34,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6667118e-01 1.1561533e-03 2.1385746e-04 5.6675693e-04 2.8171833e-05
 1.2386366e-03 3.4035183e-06 2.2525187e-01 4.4189871e-04 3.9165351e-03
 5.1158050e-04], sum to 1.0000
[2019-04-16 12:17:34,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2958
[2019-04-16 12:17:34,206] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 100.0, 76.0, 0.0, 19.0, 25.26353164862731, 0.5109416527960695, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1245600.0000, 
sim time next is 1246800.0000, 
raw observation next is [14.8, 100.0, 77.33333333333333, 0.0, 19.0, 25.0307966265398, 0.4772108306438311, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.8725761772853187, 1.0, 0.2577777777777778, 0.0, 0.08333333333333333, 0.5858997188783167, 0.659070276881277, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02538016], dtype=float32), -0.8843883]. 
=============================================
[2019-04-16 12:17:35,855] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.2393390e-01 1.3952467e-03 1.8501033e-04 2.5741465e-04 2.8368058e-05
 2.3213297e-03 2.2874917e-06 1.6456647e-01 1.4431874e-04 7.0329467e-03
 1.3270677e-04], sum to 1.0000
[2019-04-16 12:17:35,858] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9429
[2019-04-16 12:17:35,893] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [16.43333333333334, 76.0, 0.0, 0.0, 19.0, 24.38672488746739, 0.2903935969884862, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1207200.0000, 
sim time next is 1208400.0000, 
raw observation next is [16.26666666666667, 77.0, 0.0, 0.0, 19.0, 24.51240155747633, 0.4531985427611531, 0.0, 0.0, 50.0, 58.23694749181169], 
processed observation next is [0.0, 1.0, 0.9132040627885505, 0.77, 0.0, 0.0, 0.08333333333333333, 0.5427001297896942, 0.6510661809203844, 0.0, 0.0, 0.7, 0.5823694749181169], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13132279], dtype=float32), 0.89231956]. 
=============================================
[2019-04-16 12:17:38,385] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.6868170e-01 4.3188230e-04 1.2554248e-05 1.4734792e-05 4.6956529e-07
 4.2381824e-04 1.4805707e-08 2.3017222e-01 2.0265114e-05 2.3584932e-04
 6.4891760e-06], sum to 1.0000
[2019-04-16 12:17:38,386] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2570
[2019-04-16 12:17:38,401] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 23.19003647972759, -0.08705332994487835, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1705200.0000, 
sim time next is 1706400.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 22.79985291154704, -0.1250321271581455, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.39998774262891984, 0.4583226242806182, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4851926], dtype=float32), 0.049104422]. 
=============================================
[2019-04-16 12:17:41,661] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.1980181e-01 6.6301487e-05 3.0087718e-05 1.0359149e-05 1.3070998e-07
 3.5153152e-04 2.0025446e-09 1.7946617e-01 1.4476115e-05 2.5360609e-04
 5.5317328e-06], sum to 1.0000
[2019-04-16 12:17:41,662] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0290
[2019-04-16 12:17:41,672] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.2, 82.0, 0.0, 0.0, 19.0, 24.63184992667498, 0.3066406722242751, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1638000.0000, 
sim time next is 1639200.0000, 
raw observation next is [7.200000000000001, 83.33333333333334, 0.0, 0.0, 19.0, 24.35104865919475, 0.2632412318347909, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.662049861495845, 0.8333333333333335, 0.0, 0.0, 0.08333333333333333, 0.5292540549328958, 0.5877470772782637, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.97280085], dtype=float32), 0.43874958]. 
=============================================
[2019-04-16 12:17:41,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.67823040e-01 4.89783415e-04 5.76266357e-05 1.04772844e-04
 5.23067456e-06 1.40613259e-03 1.30177753e-07 2.28128165e-01
 8.04699157e-05 1.86668290e-03 3.79940830e-05], sum to 1.0000
[2019-04-16 12:17:41,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8301
[2019-04-16 12:17:41,878] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-0.4, 98.33333333333334, 41.33333333333334, 0.0, 22.5, 21.64189346904414, -0.5551834852158414, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1416000.0000, 
sim time next is 1417200.0000, 
raw observation next is [-0.2, 96.66666666666666, 50.33333333333333, 0.0, 22.5, 22.43052610749318, -0.2291935109480686, 1.0, 1.0, 50.0, 89.37603608354384], 
processed observation next is [1.0, 0.391304347826087, 0.4570637119113574, 0.9666666666666666, 0.16777777777777778, 0.0, 0.375, 0.3692105089577649, 0.4236021630173104, 1.0, 1.0, 0.7, 0.8937603608354384], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6750662], dtype=float32), 0.009549449]. 
=============================================
[2019-04-16 12:17:42,393] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.4870006e-01 5.3274544e-04 3.2749784e-05 1.7892708e-04 2.3881037e-06
 7.5510499e-04 7.8585010e-08 3.4745204e-01 5.4296986e-05 2.2530290e-03
 3.8624243e-05], sum to 1.0000
[2019-04-16 12:17:42,393] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2510
[2019-04-16 12:17:42,398] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 93.0, 0.0, 0.0, 19.0, 23.10575404170018, -0.01381856357716665, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1645200.0000, 
sim time next is 1646400.0000, 
raw observation next is [6.800000000000001, 94.0, 0.0, 0.0, 19.0, 22.96840170242406, -0.04455664933806357, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6509695290858727, 0.94, 0.0, 0.0, 0.08333333333333333, 0.414033475202005, 0.4851477835539788, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09408151], dtype=float32), 0.06562642]. 
=============================================
[2019-04-16 12:17:42,969] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.50358039e-01 1.11557332e-04 8.21994581e-06 1.19478555e-05
 3.68704150e-07 4.76377114e-04 1.91308107e-08 6.48867786e-01
 2.19793874e-05 1.37755706e-04 5.96979589e-06], sum to 1.0000
[2019-04-16 12:17:42,971] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2901
[2019-04-16 12:17:43,029] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.266666666666667, 100.0, 15.0, 0.0, 22.5, 22.59172116213801, -0.1566643539504315, 1.0, 1.0, 50.0, 53.632480501668674], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1498800.0000, 
sim time next is 1500000.0000, 
raw observation next is [1.433333333333333, 100.0, 22.83333333333333, 0.0, 22.5, 23.29219235823817, -0.2024697484672408, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.502308402585411, 1.0, 0.0761111111111111, 0.0, 0.375, 0.44101602985318095, 0.43251008384425305, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6604934], dtype=float32), 0.6130843]. 
=============================================
[2019-04-16 12:17:43,034] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[22.270157]
 [21.862328]
 [21.907894]
 [20.820019]
 [20.829927]
 [21.375471]
 [21.012733]
 [20.731247]
 [20.779537]
 [20.954914]
 [20.499794]
 [20.730663]
 [19.945982]
 [20.306122]
 [20.45955 ]
 [19.729147]
 [19.446102]
 [19.036446]
 [19.312416]
 [19.738876]
 [20.065163]
 [19.461008]
 [19.350464]
 [19.707302]
 [19.324217]], R is [[22.51490593]
 [22.28975677]
 [23.0668602 ]
 [22.83619118]
 [23.60783005]
 [24.37175179]
 [24.22387886]
 [24.07522392]
 [23.92631149]
 [23.77836227]
 [23.6244278 ]
 [23.4702816 ]
 [23.23557854]
 [24.00322342]
 [23.8447628 ]
 [23.60631561]
 [24.37025261]
 [24.20673561]
 [24.03888893]
 [23.8645649 ]
 [23.6808815 ]
 [23.44407272]
 [24.20963287]
 [23.99556923]
 [23.75561333]].
[2019-04-16 12:17:45,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0737318e-01 1.5745761e-03 2.4219128e-04 2.2520855e-04 1.2211484e-05
 3.6132284e-03 7.7730220e-07 3.8440725e-01 1.2186710e-04 2.2195990e-03
 2.0985820e-04], sum to 1.0000
[2019-04-16 12:17:45,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7197
[2019-04-16 12:17:45,983] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-9.100000000000001, 87.66666666666666, 41.66666666666666, 109.0, 22.5, 19.04529269636636, -1.154602189640764, 1.0, 1.0, 50.0, 65.06514684933315], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1932000.0000, 
sim time next is 1933200.0000, 
raw observation next is [-8.9, 86.0, 59.0, 285.0, 22.5, 19.98065419830557, -1.010832983601239, 1.0, 1.0, 50.0, 60.912049563842686], 
processed observation next is [1.0, 0.391304347826087, 0.21606648199445982, 0.86, 0.19666666666666666, 0.3149171270718232, 0.375, 0.16505451652546407, 0.1630556721329203, 1.0, 1.0, 0.7, 0.6091204956384269], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.903211], dtype=float32), 0.061453518]. 
=============================================
[2019-04-16 12:17:47,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7932990e-01 1.5669291e-04 2.5780280e-05 4.8565646e-05 2.3870928e-06
 6.6203054e-04 6.4339666e-08 2.1910429e-01 4.8006979e-05 5.9914065e-04
 2.3141250e-05], sum to 1.0000
[2019-04-16 12:17:47,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2750
[2019-04-16 12:17:47,453] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.2, 62.0, 116.1666666666667, 0.0, 22.5, 20.99664016440758, -0.8489045559977276, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1952400.0000, 
sim time next is 1953600.0000, 
raw observation next is [-3.0, 62.0, 105.6666666666667, 0.0, 22.5, 20.82079255857551, -0.8649038312066235, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3795013850415513, 0.62, 0.3522222222222223, 0.0, 0.375, 0.23506604654795904, 0.2116987229311255, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8408704], dtype=float32), 1.1828874]. 
=============================================
[2019-04-16 12:17:47,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.8823391e-01 1.0031766e-05 1.6645946e-06 2.1851904e-06 2.9459656e-08
 9.6748234e-05 2.1404575e-10 3.1154785e-01 1.7960631e-06 1.0537868e-04
 4.3513458e-07], sum to 1.0000
[2019-04-16 12:17:47,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2079
[2019-04-16 12:17:47,885] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.266666666666666, 71.33333333333333, 0.0, 0.0, 22.5, 25.48236191266223, 0.4802927832989397, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1626000.0000, 
sim time next is 1627200.0000, 
raw observation next is [7.7, 74.0, 0.0, 0.0, 22.5, 25.16492551547857, 0.4056955162661839, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6759002770083103, 0.74, 0.0, 0.0, 0.375, 0.5970771262898807, 0.6352318387553947, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06326177], dtype=float32), 0.98576653]. 
=============================================
[2019-04-16 12:17:49,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1290605e-01 2.5047632e-03 3.8477435e-04 5.2923860e-04 4.2038799e-05
 3.3483284e-03 1.1335806e-06 5.7677644e-01 2.9462593e-04 3.0488912e-03
 1.6371893e-04], sum to 1.0000
[2019-04-16 12:17:49,127] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4356
[2019-04-16 12:17:49,163] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 19.0, 18.01648672799639, -1.471592627088095, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1912800.0000, 
sim time next is 1914000.0000, 
raw observation next is [-8.4, 78.0, 0.0, 0.0, 19.0, 17.7758098091487, -1.324301827075964, 0.0, 1.0, 50.0, 75.59014964957674], 
processed observation next is [1.0, 0.13043478260869565, 0.2299168975069252, 0.78, 0.0, 0.0, 0.08333333333333333, -0.018682515904274943, 0.058566057641345294, 0.0, 1.0, 0.7, 0.7559014964957674], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06716274], dtype=float32), -1.4115779]. 
=============================================
[2019-04-16 12:17:59,657] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-16 12:17:59,657] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:17:59,657] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:17:59,659] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run7
[2019-04-16 12:17:59,677] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:17:59,687] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:17:59,689] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run7
[2019-04-16 12:17:59,706] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:17:59,710] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:17:59,712] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run7
[2019-04-16 12:18:52,373] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([0.03037507], dtype=float32), 0.052428238]
[2019-04-16 12:18:52,373] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation this: [-6.0, 64.0, 54.0, 103.5, 22.5, 18.26654349322428, -1.311966121988976, 1.0, 1.0, 15.0, 0.0]
[2019-04-16 12:18:52,373] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-16 12:18:52,374] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Softmax [6.4627838e-01 1.6441880e-03 4.9196958e-04 5.3618912e-04 7.5879936e-05
 3.9813868e-03 5.7894758e-06 3.4019202e-01 7.9410430e-04 5.5336533e-03
 4.6645559e-04], sampled 0.49558432064331825
[2019-04-16 12:19:10,857] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2745.8639 79946.0038 -4.3185
[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,878] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:10,994] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,644] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2513.0194 86924.5268 -477.4290
[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,664] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:19,779] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:24,898] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2426.7623 90253.5788 -602.8846
[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:24,916] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:19:25,919] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 300000, evaluation results [300000.0, 2513.0193821300195, 86924.52677620272, -477.4289917407075, 2745.863873229261, 79946.00375021843, -4.318523589271729, 2426.7622791179338, 90253.57881390779, -602.884604916653]
[2019-04-16 12:19:27,961] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.1559420e-01 9.8838340e-05 1.2269016e-05 1.2549394e-05 7.4294405e-07
 3.5439301e-04 1.2963984e-08 1.8327686e-01 1.8606223e-05 6.1852607e-04
 1.3008812e-05], sum to 1.0000
[2019-04-16 12:19:27,961] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7958
[2019-04-16 12:19:28,034] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.3, 70.0, 29.66666666666667, 0.0, 22.5, 22.21071170060812, -0.5862936724046944, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2220000.0000, 
sim time next is 2221200.0000, 
raw observation next is [-4.5, 71.0, 19.0, 0.0, 22.5, 21.84080073090298, -0.7328849162977208, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.71, 0.06333333333333334, 0.0, 0.375, 0.3200667275752484, 0.2557050279007597, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0528657], dtype=float32), 0.83793175]. 
=============================================
[2019-04-16 12:19:29,470] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.7716212e-01 2.3103645e-04 1.5442877e-04 5.8229554e-05 4.4835997e-06
 3.0184302e-03 5.0114856e-08 5.1859838e-01 6.6542110e-05 6.5252243e-04
 5.3779731e-05], sum to 1.0000
[2019-04-16 12:19:29,470] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3909
[2019-04-16 12:19:29,552] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.300000000000001, 70.0, 138.6666666666667, 0.0, 22.5, 20.38081827596221, -1.042559632634305, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2200800.0000, 
sim time next is 2202000.0000, 
raw observation next is [-4.1, 69.0, 140.5, 0.0, 22.5, 20.09347978803978, -1.099716273263419, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3490304709141275, 0.69, 0.4683333333333333, 0.0, 0.375, 0.17445664900331495, 0.1334279089121937, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11781365], dtype=float32), -0.46207374]. 
=============================================
[2019-04-16 12:19:29,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9027893e-01 5.4143486e-05 4.6293867e-06 1.3222125e-05 3.4541134e-07
 4.8519447e-04 1.7420509e-09 5.0835657e-01 4.7142625e-05 7.5327948e-04
 6.5836707e-06], sum to 1.0000
[2019-04-16 12:19:29,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0572
[2019-04-16 12:19:29,677] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 70.0, 124.0, 0.0, 22.5, 22.33594620727249, -0.4722434206988396, 1.0, 1.0, 50.0, 55.656633681721516], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2211600.0000, 
sim time next is 2212800.0000, 
raw observation next is [-3.899999999999999, 69.0, 126.1666666666667, 47.49999999999999, 22.5, 22.62504192570623, -0.6429555905888654, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.35457063711911363, 0.69, 0.4205555555555557, 0.05248618784530386, 0.375, 0.38542016047551925, 0.2856814698037115, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.4891, 
noisyNet noise sample is [array([0.0123685], dtype=float32), -0.4079676]. 
=============================================
[2019-04-16 12:19:32,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2394215e-01 9.1433048e-04 2.8359924e-05 1.3423487e-04 7.2765365e-06
 4.3021288e-04 1.6023156e-07 5.7289064e-01 9.7477809e-05 1.4975618e-03
 5.7560141e-05], sum to 1.0000
[2019-04-16 12:19:32,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9909
[2019-04-16 12:19:32,253] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.199999999999999, 72.33333333333333, 104.5, 375.8333333333334, 22.5, 20.97867800492828, -0.8620048299957483, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2194800.0000, 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 109.5, 225.5, 22.5, 21.25405910339848, -0.6300666337513451, 1.0, 1.0, 50.0, 83.49319121600584], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.71, 0.365, 0.24917127071823206, 0.375, 0.2711715919498732, 0.28997778874955166, 1.0, 1.0, 0.7, 0.8349319121600584], 
reward next is 0.6503, 
noisyNet noise sample is [array([-0.20287429], dtype=float32), -0.2738417]. 
=============================================
[2019-04-16 12:19:37,947] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.0996455e-01 4.6869980e-05 6.1359310e-06 1.3599456e-05 9.3023949e-08
 1.5326493e-04 2.8720719e-09 3.8951081e-01 3.0682040e-06 2.9960778e-04
 1.9787724e-06], sum to 1.0000
[2019-04-16 12:19:37,948] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3096
[2019-04-16 12:19:38,015] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 65.0, 136.0, 0.0, 22.5, 21.64023647329285, -0.5006370632736722, 1.0, 1.0, 50.0, 83.70376231142257], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2206800.0000, 
sim time next is 2208000.0000, 
raw observation next is [-3.566666666666667, 67.0, 141.3333333333333, 0.0, 22.5, 21.98481093369517, -0.5997218014901161, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3638042474607572, 0.67, 0.471111111111111, 0.0, 0.375, 0.3320675778079307, 0.30009273283662796, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7514, 
noisyNet noise sample is [array([-2.0509486], dtype=float32), 0.6374762]. 
=============================================
[2019-04-16 12:19:38,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0458335e-01 3.0772218e-03 3.5768931e-04 6.2084181e-04 4.9826915e-05
 3.8780309e-03 5.0575172e-06 2.7532372e-01 6.3268276e-04 1.1056130e-02
 4.1552639e-04], sum to 1.0000
[2019-04-16 12:19:38,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8023
[2019-04-16 12:19:38,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 41.0, 0.0, 0.0, 19.0, 18.99774720449486, -1.250452742430308, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2415600.0000, 
sim time next is 2416800.0000, 
raw observation next is [-5.2, 41.66666666666667, 0.0, 0.0, 19.0, 18.65539021108501, -1.146239276718697, 0.0, 1.0, 50.0, 68.1894842966359], 
processed observation next is [0.0, 1.0, 0.31855955678670367, 0.41666666666666674, 0.0, 0.0, 0.08333333333333333, 0.0546158509237508, 0.11792024109376764, 0.0, 1.0, 0.7, 0.6818948429663589], 
reward next is 0.2142, 
noisyNet noise sample is [array([1.1545674], dtype=float32), 0.46290067]. 
=============================================
[2019-04-16 12:19:41,143] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.5526394e-01 1.0543319e-03 7.9198631e-05 2.2400248e-04 8.8513152e-06
 1.9275915e-03 3.1732591e-07 4.3522567e-01 7.9173937e-05 5.9758639e-03
 1.6109931e-04], sum to 1.0000
[2019-04-16 12:19:41,143] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8874
[2019-04-16 12:19:41,167] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.1, 54.33333333333334, 0.0, 0.0, 19.0, 20.05793587398646, -0.9252313261689261, 0.0, 1.0, 20.0, 33.804952294159364], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2522400.0000, 
sim time next is 2523600.0000, 
raw observation next is [-2.3, 57.0, 0.0, 0.0, 19.0, 20.21738206992702, -0.8986367551751461, 0.0, 1.0, 50.0, 41.69295580796721], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.57, 0.0, 0.0, 0.08333333333333333, 0.18478183916058497, 0.20045441494161798, 0.0, 1.0, 0.7, 0.4169295580796721], 
reward next is 0.0581, 
noisyNet noise sample is [array([-0.8928383], dtype=float32), 0.6366756]. 
=============================================
[2019-04-16 12:19:41,179] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.15191698e-01 1.12176710e-03 1.34512520e-04 2.15241482e-04
 1.41841683e-05 2.19684420e-03 7.31640910e-07 3.76502842e-01
 2.08875208e-04 4.30178642e-03 1.11512774e-04], sum to 1.0000
[2019-04-16 12:19:41,182] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8571
[2019-04-16 12:19:41,224] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.3, 25.66666666666667, 50.33333333333333, 345.8333333333333, 19.0, 19.89001966096259, -1.007481794720285, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2478000.0000, 
sim time next is 2479200.0000, 
raw observation next is [3.3, 25.33333333333333, 41.0, 239.6666666666667, 19.0, 20.04917357026571, -0.8326783450188148, 0.0, 1.0, 50.0, 63.49064115998472], 
processed observation next is [0.0, 0.6956521739130435, 0.554016620498615, 0.2533333333333333, 0.13666666666666666, 0.2648250460405157, 0.08333333333333333, 0.1707644641888093, 0.22244055166039509, 0.0, 1.0, 0.7, 0.6349064115998472], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67262703], dtype=float32), -2.7001905]. 
=============================================
[2019-04-16 12:19:42,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.3817251e-01 2.2176704e-03 2.1320854e-04 3.7342051e-04 2.8781367e-05
 2.2328652e-03 3.5469798e-06 3.5066551e-01 3.4043539e-04 5.3401636e-03
 4.1185401e-04], sum to 1.0000
[2019-04-16 12:19:42,667] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1162
[2019-04-16 12:19:42,692] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 44.66666666666667, 0.0, 0.0, 19.0, 18.51725128210088, -1.312876441501613, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2420400.0000, 
sim time next is 2421600.0000, 
raw observation next is [-6.0, 46.33333333333334, 0.0, 0.0, 19.0, 18.12814455914289, -1.392721271222613, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.296398891966759, 0.46333333333333343, 0.0, 0.0, 0.08333333333333333, 0.010678713261907427, 0.03575957625912903, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35738686], dtype=float32), -0.3400316]. 
=============================================
[2019-04-16 12:19:43,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7852730e-01 5.3312001e-04 4.0351595e-05 7.2709241e-05 5.9357271e-06
 1.2110900e-03 9.2589680e-08 3.1717718e-01 4.2499716e-05 2.3421147e-03
 4.7658970e-05], sum to 1.0000
[2019-04-16 12:19:43,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7764
[2019-04-16 12:19:43,726] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 62.0, 0.0, 0.0, 19.0, 19.65004651561356, -0.9578527989714792, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2592000.0000, 
sim time next is 2593200.0000, 
raw observation next is [-4.666666666666667, 64.0, 0.0, 0.0, 19.0, 19.82780483913297, -0.7535363088422545, 0.0, 1.0, 50.0, 78.70923247900723], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 0.64, 0.0, 0.0, 0.08333333333333333, 0.1523170699277475, 0.24882123038591517, 0.0, 1.0, 0.7, 0.7870923247900723], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5054708], dtype=float32), 1.2606224]. 
=============================================
[2019-04-16 12:19:49,972] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4433930e-01 2.8833908e-03 6.3354278e-04 1.0533887e-03 5.4054784e-05
 6.0931314e-03 4.4613912e-06 4.3457758e-01 7.1744289e-04 9.2111873e-03
 4.3246572e-04], sum to 1.0000
[2019-04-16 12:19:49,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5144
[2019-04-16 12:19:50,007] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.66666666666667, 83.0, 0.0, 0.0, 19.0, 17.33817628470807, -1.509862556638979, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2698800.0000, 
sim time next is 2700000.0000, 
raw observation next is [-16.0, 83.0, 0.0, 0.0, 19.0, 17.08903338992009, -1.559076823306396, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.01939058171745151, 0.83, 0.0, 0.0, 0.08333333333333333, -0.07591388417332585, -0.019692274435465357, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1391361], dtype=float32), -1.1869062]. 
=============================================
[2019-04-16 12:19:50,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[15.566625]
 [15.940452]
 [15.999452]
 [15.917532]
 [16.879877]
 [16.713942]
 [16.610346]
 [17.190557]
 [17.367222]
 [17.04507 ]
 [16.700197]
 [17.513113]
 [18.651926]
 [19.718164]
 [19.66923 ]
 [18.974724]
 [19.996881]
 [19.758947]
 [20.841005]
 [21.740356]
 [21.843832]
 [22.223577]
 [21.757668]
 [21.687737]
 [21.767572]], R is [[14.95228767]
 [14.80276489]
 [14.65473747]
 [14.50819016]
 [15.36310863]
 [15.81166267]
 [15.65354633]
 [15.49701118]
 [16.34204102]
 [16.17862129]
 [16.01683617]
 [16.14957047]
 [16.98504639]
 [17.81519699]
 [17.63704491]
 [17.46067429]
 [18.28606796]
 [18.10320663]
 [18.92217445]
 [19.73295212]
 [20.53562355]
 [21.33026695]
 [21.11696434]
 [20.90579414]
 [21.69673729]].
[2019-04-16 12:19:50,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.52231055e-01 1.53513145e-04 8.90705996e-06 1.36313565e-05
 1.03737159e-06 4.21813282e-04 2.31865549e-08 6.46698356e-01
 1.40170769e-05 4.45730780e-04 1.18673906e-05], sum to 1.0000
[2019-04-16 12:19:50,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4782
[2019-04-16 12:19:50,351] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-12.66666666666667, 81.0, 100.3333333333333, 622.3333333333333, 22.5, 20.87322104217765, -0.7307987447012082, 1.0, 1.0, 50.0, 74.5345396630624], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2713200.0000, 
sim time next is 2714400.0000, 
raw observation next is [-12.0, 76.0, 107.0, 643.0, 22.5, 21.6049134864821, -0.6102575901570014, 1.0, 1.0, 50.0, 53.5256840173327], 
processed observation next is [1.0, 0.43478260869565216, 0.13019390581717452, 0.76, 0.3566666666666667, 0.7104972375690608, 0.375, 0.3004094572068417, 0.2965808032809995, 1.0, 1.0, 0.7, 0.535256840173327], 
reward next is 0.5513, 
noisyNet noise sample is [array([-0.47003403], dtype=float32), -0.60764396]. 
=============================================
[2019-04-16 12:19:51,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.73088872e-01 1.01795194e-04 6.46693979e-06 1.02764898e-05
 8.57079669e-07 3.13153520e-04 6.68881484e-09 2.26128951e-01
 4.12145746e-05 3.01258639e-04 7.14685802e-06], sum to 1.0000
[2019-04-16 12:19:51,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1538
[2019-04-16 12:19:51,303] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 52.66666666666667, 88.66666666666667, 633.8333333333334, 22.5, 22.28015778852477, -0.4052521640928506, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2733600.0000, 
sim time next is 2734800.0000, 
raw observation next is [-3.333333333333333, 51.33333333333333, 80.66666666666667, 587.3333333333334, 22.5, 22.42088859773781, -0.3903536973872501, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.37026777469990774, 0.5133333333333333, 0.2688888888888889, 0.648987108655617, 0.375, 0.3684073831448176, 0.3698821008709166, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21899205], dtype=float32), -1.597037]. 
=============================================
[2019-04-16 12:19:52,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3003600e-01 4.8741966e-04 2.0712321e-05 2.3231612e-05 1.9200529e-06
 5.2904466e-04 2.1795906e-08 3.6685979e-01 4.8630878e-05 1.9616503e-03
 3.1565534e-05], sum to 1.0000
[2019-04-16 12:19:52,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3496
[2019-04-16 12:19:52,155] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.466666666666667, 36.0, 220.3333333333333, 30.16666666666666, 22.5, 21.86285916818552, -0.7613588632304588, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2550000.0000, 
sim time next is 2551200.0000, 
raw observation next is [1.833333333333333, 33.0, 210.1666666666667, 98.66666666666666, 22.5, 21.30818199180371, -0.8458000757476841, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5133887349953832, 0.33, 0.7005555555555557, 0.10902394106813995, 0.375, 0.2756818326503092, 0.21806664141743862, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39024076], dtype=float32), 0.91030145]. 
=============================================
[2019-04-16 12:19:55,042] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9699466e-01 2.5709154e-04 3.8818092e-05 9.5189040e-05 1.7205564e-06
 2.1952773e-03 5.8092763e-08 2.9853863e-01 9.5136493e-05 1.7391795e-03
 4.4213175e-05], sum to 1.0000
[2019-04-16 12:19:55,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8323
[2019-04-16 12:19:55,198] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.3, 79.0, 42.0, 4.0, 22.5, 20.44692404704113, -0.8359230281866474, 1.0, 1.0, 50.0, 59.17953442916597], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2620800.0000, 
sim time next is 2622000.0000, 
raw observation next is [-7.100000000000001, 77.66666666666667, 65.33333333333334, 1.333333333333333, 22.5, 20.75530321341227, -0.7547874355473199, 1.0, 1.0, 50.0, 57.03763152335996], 
processed observation next is [1.0, 0.34782608695652173, 0.26592797783933514, 0.7766666666666667, 0.21777777777777782, 0.00147329650092081, 0.375, 0.22960860111768908, 0.24840418815089338, 1.0, 1.0, 0.7, 0.5703763152335997], 
reward next is 0.8114, 
noisyNet noise sample is [array([2.483985], dtype=float32), 1.5789078]. 
=============================================
[2019-04-16 12:20:04,460] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.4478936e-01 1.8044953e-03 3.2432243e-04 6.2263076e-04 5.6558598e-05
 8.6697470e-03 4.4090598e-06 2.3691109e-01 4.8471414e-04 5.8743982e-03
 4.5823323e-04], sum to 1.0000
[2019-04-16 12:20:04,460] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6305
[2019-04-16 12:20:04,490] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 166.0, 78.0, 19.0, 19.5180809252643, -1.02540727527706, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2973600.0000, 
sim time next is 2974800.0000, 
raw observation next is [-3.666666666666667, 69.0, 174.0, 42.0, 19.0, 19.01745526115132, -1.135064967450672, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3610341643582641, 0.69, 0.58, 0.04640883977900553, 0.08333333333333333, 0.08478793842927661, 0.12164501084977597, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.94113785], dtype=float32), 0.43282956]. 
=============================================
[2019-04-16 12:20:10,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0558026e-01 2.4322297e-05 1.3012748e-06 1.4805826e-06 4.2872358e-08
 5.7279987e-05 1.2779551e-09 1.9424827e-01 4.6803807e-06 8.0823353e-05
 1.5221411e-06], sum to 1.0000
[2019-04-16 12:20:10,820] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5983
[2019-04-16 12:20:10,848] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 51.66666666666667, 19.16666666666666, 194.3333333333333, 22.5, 23.09848596370066, -0.3861447782699189, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3345600.0000, 
sim time next is 3346800.0000, 
raw observation next is [-2.666666666666667, 53.33333333333333, 9.166666666666668, 110.8333333333333, 22.5, 22.08759793253196, -0.4102474806529811, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.38873499538319484, 0.5333333333333333, 0.030555555555555558, 0.12246777163904232, 0.375, 0.34063316104433, 0.3632508397823397, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.93317187], dtype=float32), 0.94838244]. 
=============================================
[2019-04-16 12:20:12,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.06101739e-01 5.97293139e-04 4.98510562e-05 7.70099869e-05
 2.96699682e-06 1.11650792e-03 6.33368629e-08 1.89036623e-01
 1.12934904e-04 2.86904071e-03 3.60428421e-05], sum to 1.0000
[2019-04-16 12:20:12,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6170
[2019-04-16 12:20:12,237] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 75.33333333333334, 15.33333333333333, 154.3333333333333, 19.0, 21.07131608959117, -0.7523299314345943, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3086400.0000, 
sim time next is 3087600.0000, 
raw observation next is [-0.4, 78.66666666666667, 0.0, 0.0, 19.0, 20.48006844815833, -0.882122943405637, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.45152354570637127, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.2066723706798609, 0.20595901886478765, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80637646], dtype=float32), 0.5457828]. 
=============================================
[2019-04-16 12:20:12,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9042772e-01 1.4185278e-05 2.4168003e-06 1.0406432e-06 3.2134839e-08
 9.2118185e-05 1.7408985e-10 3.0922601e-01 1.6382860e-06 2.3400642e-04
 8.2529249e-07], sum to 1.0000
[2019-04-16 12:20:12,974] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4339
[2019-04-16 12:20:12,987] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 22.5, 24.33126635814941, 0.1243915836621667, 1.0, 1.0, 50.0, 40.53626993994828], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3349200.0000, 
sim time next is 3350400.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 22.5, 24.0579364149359, -0.02356138017847688, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3795013850415513, 0.55, 0.0, 0.0, 0.375, 0.5048280345779915, 0.4921462066071744, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1156418], dtype=float32), -1.4349687]. 
=============================================
[2019-04-16 12:20:14,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1073425e-01 3.6428179e-04 2.8993582e-05 6.6687877e-05 7.7912619e-06
 1.1934707e-03 2.8364570e-07 2.8552982e-01 9.4166047e-05 1.9405809e-03
 3.9640414e-05], sum to 1.0000
[2019-04-16 12:20:14,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5437
[2019-04-16 12:20:14,580] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 43.0, 74.5, 607.0, 19.0, 21.00956097019521, -0.5546689107553849, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3600000.0000, 
sim time next is 3601200.0000, 
raw observation next is [0.0, 41.66666666666667, 66.83333333333333, 545.6666666666666, 19.0, 20.95276807084705, -0.5692500641568766, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.46260387811634357, 0.41666666666666674, 0.22277777777777777, 0.6029465930018416, 0.08333333333333333, 0.24606400590392083, 0.3102499786143745, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05638923], dtype=float32), -0.29266283]. 
=============================================
[2019-04-16 12:20:18,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9754994e-01 1.7138080e-04 9.4838679e-06 1.3026249e-05 7.3371768e-07
 9.6260454e-04 4.8447237e-09 3.0045000e-01 1.0658820e-05 8.2763017e-04
 4.4637545e-06], sum to 1.0000
[2019-04-16 12:20:18,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9279
[2019-04-16 12:20:18,301] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [4.333333333333334, 56.0, 55.83333333333334, 462.5, 19.0, 23.45175765432092, -0.07745049731103565, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3688800.0000, 
sim time next is 3690000.0000, 
raw observation next is [4.0, 59.0, 39.5, 343.5, 19.0, 23.47886699519271, 0.06407070035014517, 0.0, 1.0, 50.0, 57.317949027526524], 
processed observation next is [0.0, 0.7391304347826086, 0.5734072022160666, 0.59, 0.13166666666666665, 0.37955801104972375, 0.08333333333333333, 0.4565722495993925, 0.521356900116715, 0.0, 1.0, 0.7, 0.5731794902752653], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2103739], dtype=float32), 0.7188472]. 
=============================================
[2019-04-16 12:20:18,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[21.594763]
 [22.102516]
 [22.882605]
 [22.970387]
 [22.984623]
 [22.73123 ]
 [22.59749 ]
 [22.198868]
 [21.146103]
 [21.80998 ]
 [21.805452]
 [21.570942]
 [21.496836]
 [20.511904]
 [20.215725]
 [19.14144 ]
 [19.153536]
 [18.477503]
 [18.397158]
 [17.24819 ]
 [17.512224]
 [16.795368]
 [15.734974]
 [15.91835 ]
 [16.578325]], R is [[22.43870163]
 [23.21431541]
 [23.98217201]
 [24.74234962]
 [25.49492645]
 [25.23997688]
 [25.98757744]
 [25.85622025]
 [25.59765816]
 [26.34168243]
 [27.07826614]
 [26.93988991]
 [26.79976273]
 [26.53176498]
 [27.26644707]
 [26.99378204]
 [27.72384453]
 [28.44660568]
 [29.16213989]
 [28.87051964]
 [29.58181381]
 [29.3863678 ]
 [29.0925045 ]
 [29.80158043]
 [30.50356483]].
[2019-04-16 12:20:21,452] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.6782417e-01 6.8759204e-05 8.5393140e-06 9.4116194e-06 3.2735505e-07
 8.8822440e-04 9.5917700e-09 2.3064852e-01 2.0391370e-05 5.2138889e-04
 1.0281693e-05], sum to 1.0000
[2019-04-16 12:20:21,453] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7335
[2019-04-16 12:20:21,501] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 63.66666666666667, 102.5, 695.8333333333334, 22.5, 22.59758528178722, -0.4231341380080007, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3836400.0000, 
sim time next is 3837600.0000, 
raw observation next is [-2.0, 60.0, 105.5, 727.5, 22.5, 22.4665325667765, -0.4381423422277553, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.40720221606648205, 0.6, 0.3516666666666667, 0.8038674033149171, 0.375, 0.37221104723137505, 0.35395255259074826, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8461148], dtype=float32), -0.43719864]. 
=============================================
[2019-04-16 12:20:22,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9592872e-01 4.1496169e-05 4.6234013e-06 1.1809230e-05 7.5615766e-08
 1.2197530e-04 1.6417240e-09 2.0319895e-01 7.0150513e-06 6.8266108e-04
 2.6198761e-06], sum to 1.0000
[2019-04-16 12:20:22,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7623
[2019-04-16 12:20:22,904] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 22.48662793896226, -0.3049502626058254, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3451200.0000, 
sim time next is 3452400.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 21.99777985625278, -0.4088974868584707, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.33314832135439837, 0.3637008377138431, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7804013], dtype=float32), 0.08800198]. 
=============================================
[2019-04-16 12:20:23,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.62827277e-01 7.86259887e-04 2.48087861e-04 1.76806003e-04
 1.62587148e-05 2.48770183e-03 7.93629340e-07 2.30830207e-01
 2.05347300e-04 2.31333217e-03 1.07790715e-04], sum to 1.0000
[2019-04-16 12:20:23,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9897
[2019-04-16 12:20:23,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1267886e-01 1.0456407e-05 2.4805266e-07 4.4434071e-07 2.7085008e-08
 4.3608772e-05 6.9835429e-11 4.8720539e-01 2.2478193e-06 5.8577512e-05
 1.8167870e-07], sum to 1.0000
[2019-04-16 12:20:23,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2120
[2019-04-16 12:20:23,736] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.666666666666666, 62.33333333333333, 0.0, 0.0, 19.0, 19.00677134217647, -1.093211229929162, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3912000.0000, 
sim time next is 3913200.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.14334001202382, -0.8852988608707517, 0.0, 1.0, 50.0, 82.03310844435748], 
processed observation next is [1.0, 0.30434782608695654, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.09527833433531836, 0.20490037970974942, 0.0, 1.0, 0.7, 0.8203310844435748], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6442048], dtype=float32), -0.035653826]. 
=============================================
[2019-04-16 12:20:23,754] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 60.0, 117.0, 828.5, 22.5, 24.1280422227215, 0.1060809787437658, 1.0, 1.0, 50.0, 53.951795331815966], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3844800.0000, 
sim time next is 3846000.0000, 
raw observation next is [-0.3333333333333334, 57.00000000000001, 117.0, 832.8333333333334, 22.5, 24.50745738824366, 0.03313621321695163, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4533702677747, 0.5700000000000001, 0.39, 0.9202578268876612, 0.375, 0.5422881156869718, 0.5110454044056506, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.71203387], dtype=float32), -0.7920145]. 
=============================================
[2019-04-16 12:20:24,387] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.44085443e-01 9.00474086e-04 6.13139273e-05 9.54420684e-05
 9.07442154e-06 1.55147165e-03 1.04456404e-07 4.51857030e-01
 1.16132549e-04 1.26848067e-03 5.49489705e-05], sum to 1.0000
[2019-04-16 12:20:24,387] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7579
[2019-04-16 12:20:24,424] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 54.0, 112.5, 787.0, 19.0, 21.07176529014461, -0.5172630139630467, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3582000.0000, 
sim time next is 3583200.0000, 
raw observation next is [-3.666666666666667, 54.33333333333334, 113.5, 806.3333333333333, 19.0, 21.28348049662431, -0.3138695433509642, 0.0, 1.0, 50.0, 66.09637783207543], 
processed observation next is [0.0, 0.4782608695652174, 0.3610341643582641, 0.5433333333333334, 0.37833333333333335, 0.8909760589318599, 0.08333333333333333, 0.2736233747186925, 0.39537681888301196, 0.0, 1.0, 0.7, 0.6609637783207544], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1212859], dtype=float32), -0.22183268]. 
=============================================
[2019-04-16 12:20:26,213] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7463158e-01 5.7630840e-04 8.3063191e-05 7.4022442e-05 1.1718017e-05
 1.1652458e-03 7.6419298e-07 5.2229321e-01 2.3408604e-04 8.8413904e-04
 4.5865643e-05], sum to 1.0000
[2019-04-16 12:20:26,213] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3849
[2019-04-16 12:20:26,236] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.0, 63.0, 46.5, 222.0, 22.5, 17.48847880987027, -1.456069562604131, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4003200.0000, 
sim time next is 4004400.0000, 
raw observation next is [-12.33333333333333, 59.66666666666667, 77.5, 370.0, 22.5, 17.40264305184592, -1.426572392178339, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.12096029547553101, 0.5966666666666667, 0.25833333333333336, 0.4088397790055249, 0.375, -0.049779745679506604, 0.02447586927388697, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.2950, 
noisyNet noise sample is [array([0.8467914], dtype=float32), -1.6401889]. 
=============================================
[2019-04-16 12:20:26,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2281221e-01 1.5150292e-05 1.3941385e-06 1.4719506e-06 4.2519773e-08
 1.0838960e-04 3.2562588e-11 3.7696889e-01 2.0007074e-06 8.9535315e-05
 7.8810757e-07], sum to 1.0000
[2019-04-16 12:20:26,811] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7876
[2019-04-16 12:20:26,856] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 45.0, 75.5, 634.0, 22.5, 25.04014393895604, 0.3788354981075401, 1.0, 1.0, 50.0, 58.49933022339022], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3859200.0000, 
sim time next is 3860400.0000, 
raw observation next is [3.0, 43.66666666666667, 67.83333333333333, 578.6666666666666, 22.5, 25.44577940265343, 0.4392908039135469, 1.0, 1.0, 50.0, 37.8375474218268], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.4366666666666667, 0.2261111111111111, 0.6394106813996316, 0.375, 0.6204816168877857, 0.6464302679711823, 1.0, 1.0, 0.7, 0.378375474218268], 
reward next is 0.0966, 
noisyNet noise sample is [array([1.8367555], dtype=float32), -0.71192676]. 
=============================================
[2019-04-16 12:20:26,860] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.69021261e-01 6.18169579e-05 3.51092740e-06 1.42182125e-05
 2.37699339e-07 3.27745103e-04 2.36122988e-09 5.30435443e-01
 1.26006753e-05 1.18520649e-04 4.63853212e-06], sum to 1.0000
[2019-04-16 12:20:26,861] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2805
[2019-04-16 12:20:26,893] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 40.0, 115.5, 798.5, 22.5, 22.93929815694553, -0.3876147860080748, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4014000.0000, 
sim time next is 4015200.0000, 
raw observation next is [-7.333333333333334, 39.0, 117.8333333333333, 810.1666666666666, 22.5, 22.46629563653845, -0.4766961416502176, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.2594644506001847, 0.39, 0.39277777777777767, 0.8952117863720074, 0.375, 0.3721913030448709, 0.3411012861165941, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44216612], dtype=float32), -0.14798129]. 
=============================================
[2019-04-16 12:20:28,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8292779e-01 2.5307082e-04 9.2932069e-06 1.5789836e-05 9.0247698e-07
 8.7451388e-04 9.5218349e-09 3.1559339e-01 5.7216646e-05 2.5937357e-04
 8.7202661e-06], sum to 1.0000
[2019-04-16 12:20:28,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8164
[2019-04-16 12:20:28,499] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.666666666666667, 51.66666666666667, 98.5, 654.3333333333334, 22.5, 22.90869046430504, -0.1119950889253797, 1.0, 1.0, 50.0, 64.57188839350235], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3921600.0000, 
sim time next is 3922800.0000, 
raw observation next is [-7.333333333333333, 50.33333333333333, 102.1666666666667, 705.8333333333334, 22.5, 23.70062063327908, -0.00145819656659651, 1.0, 1.0, 50.0, 44.902129792832056], 
processed observation next is [1.0, 0.391304347826087, 0.25946445060018475, 0.5033333333333333, 0.34055555555555567, 0.779926335174954, 0.375, 0.4750517194399233, 0.4995139344778012, 1.0, 1.0, 0.7, 0.4490212979283206], 
reward next is 0.0260, 
noisyNet noise sample is [array([0.99836445], dtype=float32), 0.5575502]. 
=============================================
[2019-04-16 12:20:34,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.10352254e-01 7.59148691e-07 2.40297560e-08 4.96090422e-08
 5.55484159e-10 7.04114382e-06 1.93415488e-12 4.89627540e-01
 1.18505326e-07 1.21772418e-05 1.11328212e-07], sum to 1.0000
[2019-04-16 12:20:34,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9326
[2019-04-16 12:20:34,192] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [13.0, 35.0, 71.0, 0.0, 22.5, 27.39589792207275, 0.8457094288576243, 1.0, 1.0, 60.0, 34.71346968665598], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4377600.0000, 
sim time next is 4378800.0000, 
raw observation next is [13.0, 36.0, 49.66666666666666, 0.0, 22.5, 27.91017199878189, 0.8975992871654294, 1.0, 1.0, 50.0, 18.61268274663494], 
processed observation next is [1.0, 0.6956521739130435, 0.8227146814404434, 0.36, 0.1655555555555555, 0.0, 0.375, 0.8258476665651576, 0.7991997623884765, 1.0, 1.0, 0.7, 0.18612682746634937], 
reward next is 0.2889, 
noisyNet noise sample is [array([-1.2674694], dtype=float32), 0.2064737]. 
=============================================
[2019-04-16 12:20:35,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4033991e-01 3.3535573e-04 3.8446102e-05 8.0105179e-05 3.1288446e-06
 5.8355427e-04 7.3924433e-08 3.5598621e-01 1.8121873e-04 2.4208131e-03
 3.1139709e-05], sum to 1.0000
[2019-04-16 12:20:35,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9502
[2019-04-16 12:20:35,050] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 38.33333333333334, 0.0, 0.0, 19.0, 20.55249698181699, -0.7718362172048789, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4062000.0000, 
sim time next is 4063200.0000, 
raw observation next is [-6.0, 39.66666666666666, 0.0, 0.0, 19.0, 20.68529455814506, -0.5903777825318594, 0.0, 1.0, 50.0, 73.07063182875429], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.39666666666666656, 0.0, 0.0, 0.08333333333333333, 0.2237745465120883, 0.30320740582271355, 0.0, 1.0, 0.7, 0.7307063182875428], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6472989], dtype=float32), 0.14693335]. 
=============================================
[2019-04-16 12:20:35,905] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.3210959e-01 1.2029111e-06 9.6299772e-08 1.4051170e-07 8.0726714e-10
 2.1091475e-05 1.2670902e-11 6.7863591e-02 1.0909530e-07 4.1272683e-06
 2.6780887e-08], sum to 1.0000
[2019-04-16 12:20:35,905] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6557
[2019-04-16 12:20:35,951] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.56666666666667, 29.66666666666667, 115.5, 843.8333333333334, 22.5, 24.64534140569294, 0.1041647704432814, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4368000.0000, 
sim time next is 4369200.0000, 
raw observation next is [14.53333333333333, 30.33333333333333, 128.3333333333333, 806.5, 22.5, 24.51754425870957, 0.1951442088362553, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8651892890120036, 0.3033333333333333, 0.42777777777777765, 0.8911602209944751, 0.375, 0.5431286882257975, 0.5650480696120851, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6432631], dtype=float32), -0.7475827]. 
=============================================
[2019-04-16 12:20:36,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5348103e-01 2.6161634e-04 8.1276276e-06 2.5020989e-05 7.7063231e-07
 4.8411125e-04 2.3902222e-08 2.4383259e-01 3.0554373e-05 1.8680197e-03
 8.2055021e-06], sum to 1.0000
[2019-04-16 12:20:36,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5332
[2019-04-16 12:20:36,439] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 39.0, 60.66666666666667, 485.5000000000001, 19.0, 22.31962980681435, -0.3370897513480927, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4207200.0000, 
sim time next is 4208400.0000, 
raw observation next is [2.0, 40.0, 46.0, 356.5, 19.0, 22.08967757762284, -0.381892352062003, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.518005540166205, 0.4, 0.15333333333333332, 0.3939226519337017, 0.08333333333333333, 0.34080646480190335, 0.37270254931266567, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9334685], dtype=float32), 0.3914796]. 
=============================================
[2019-04-16 12:20:38,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5541196e-01 9.2771770e-05 2.7930403e-06 1.6221220e-05 3.1896832e-07
 6.0569344e-04 3.6489527e-09 3.4359869e-01 1.0122220e-05 2.5473619e-04
 6.6506518e-06], sum to 1.0000
[2019-04-16 12:20:38,324] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5691
[2019-04-16 12:20:38,335] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.866666666666667, 58.66666666666667, 134.8333333333333, 610.0, 19.0, 22.94838325003238, -0.1267677780701254, 0.0, 1.0, 50.0, 37.41969269982318], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4288800.0000, 
sim time next is 4290000.0000, 
raw observation next is [6.933333333333334, 57.33333333333333, 108.3333333333333, 638.5, 19.0, 23.10711072684131, -0.1902345802902911, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.6546629732225301, 0.5733333333333333, 0.361111111111111, 0.7055248618784531, 0.08333333333333333, 0.42559256057010914, 0.43658847323656963, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.67565954], dtype=float32), -0.1219794]. 
=============================================
[2019-04-16 12:20:38,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[24.81373 ]
 [24.503042]
 [23.376947]
 [23.652784]
 [23.731737]
 [22.416655]
 [22.875223]
 [22.597815]
 [21.945185]
 [21.351248]
 [21.148142]
 [20.779512]
 [20.50572 ]
 [19.421087]
 [19.702322]
 [19.205698]
 [18.278967]
 [16.670313]
 [16.686916]
 [16.23702 ]
 [16.093714]
 [16.15217 ]
 [16.49256 ]
 [17.387253]
 [16.288904]], R is [[25.95979118]
 [25.80099678]
 [25.54298782]
 [26.2875576 ]
 [27.024683  ]
 [26.75443649]
 [27.4868927 ]
 [27.21202469]
 [27.93990517]
 [28.6605072 ]
 [29.37390327]
 [30.08016396]
 [30.77936172]
 [30.47156906]
 [31.16685295]
 [31.85518456]
 [31.56751251]
 [31.25183678]
 [31.93931961]
 [32.61992645]
 [33.29372787]
 [33.96079254]
 [34.6211853 ]
 [35.27497482]
 [34.92222595]].
[2019-04-16 12:20:38,464] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.71187520e-01 3.62249602e-06 1.05161426e-07 2.42891929e-07
 2.38074938e-09 7.74830733e-06 5.28215006e-11 3.28718066e-01
 3.65225304e-07 8.20601927e-05 3.71491581e-07], sum to 1.0000
[2019-04-16 12:20:38,465] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0432
[2019-04-16 12:20:38,474] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.933333333333334, 59.66666666666667, 0.0, 0.0, 19.0, 25.50414446366261, 0.5993097238785007, 0.0, 1.0, 50.0, 58.259965325507075], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4396800.0000, 
sim time next is 4398000.0000, 
raw observation next is [9.666666666666668, 60.33333333333333, 0.0, 0.0, 19.0, 25.81721626329794, 0.5313979468604583, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7303785780240075, 0.6033333333333333, 0.0, 0.0, 0.08333333333333333, 0.6514346886081617, 0.677132648953486, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5161238], dtype=float32), 0.12751606]. 
=============================================
[2019-04-16 12:20:42,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3015527e-01 1.0691531e-04 2.8653881e-06 4.4026315e-06 8.9329760e-08
 1.3961391e-04 1.1614442e-09 3.6945108e-01 2.7684709e-06 1.3489762e-04
 2.1639150e-06], sum to 1.0000
[2019-04-16 12:20:42,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1645
[2019-04-16 12:20:42,378] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 92.0, 0.0, 0.0, 19.0, 23.99031231182897, 0.0158802884570306, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4680000.0000, 
sim time next is 4681200.0000, 
raw observation next is [-0.3333333333333333, 94.66666666666667, 0.0, 0.0, 19.0, 23.61569541570171, -0.0889918368268935, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4533702677747, 0.9466666666666668, 0.0, 0.0, 0.08333333333333333, 0.46797461797514234, 0.4703360543910355, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58110976], dtype=float32), -0.34194455]. 
=============================================
[2019-04-16 12:20:42,943] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.9393915e-01 1.5940891e-04 1.9000789e-05 2.5726706e-05 1.5891135e-06
 4.9472356e-04 1.5477029e-08 3.0359933e-01 3.8427588e-05 1.7194914e-03
 3.0953631e-06], sum to 1.0000
[2019-04-16 12:20:42,944] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2178
[2019-04-16 12:20:42,958] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.5, 69.0, 0.0, 0.0, 19.0, 22.17689953415443, -0.3979298123535414, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4593600.0000, 
sim time next is 4594800.0000, 
raw observation next is [-1.666666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 21.78600479846036, -0.4604467555726173, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4164358264081256, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.31550039987169676, 0.3465177481424609, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5381217], dtype=float32), -1.0608515]. 
=============================================
[2019-04-16 12:20:43,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6745832e-01 8.5411773e-07 9.2921752e-08 7.1138373e-08 6.3577654e-10
 7.2073576e-06 7.8765781e-13 2.3252620e-01 1.5056116e-07 7.1349550e-06
 3.4942929e-08], sum to 1.0000
[2019-04-16 12:20:43,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4346
[2019-04-16 12:20:43,460] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.7, 49.0, 171.0, 706.0, 22.5, 25.48000670671739, 0.3644361454031412, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4629600.0000, 
sim time next is 4630800.0000, 
raw observation next is [4.800000000000001, 49.33333333333334, 192.3333333333333, 634.6666666666666, 22.5, 25.569548987117, 0.3675122628525169, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5955678670360112, 0.4933333333333334, 0.641111111111111, 0.7012891344383057, 0.375, 0.6307957489264165, 0.6225040876175056, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1600521], dtype=float32), -0.069835074]. 
=============================================
[2019-04-16 12:20:46,733] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6030275e-01 3.1850647e-04 7.1637041e-06 4.4957735e-05 5.4574446e-07
 3.2420328e-04 3.7114543e-08 1.3730931e-01 2.7300301e-05 1.6516503e-03
 1.3645081e-05], sum to 1.0000
[2019-04-16 12:20:46,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4134
[2019-04-16 12:20:46,751] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 19.0, 22.38717231668014, -0.13299887363092, 0.0, 1.0, 50.0, 67.93384671560737], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4674000.0000, 
sim time next is 4675200.0000, 
raw observation next is [2.0, 62.0, 0.0, 0.0, 19.0, 22.95272998095188, -0.2092071379181558, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.518005540166205, 0.62, 0.0, 0.0, 0.08333333333333333, 0.4127274984126566, 0.4302642873606148, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4737576], dtype=float32), -0.48813626]. 
=============================================
[2019-04-16 12:20:50,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8677753e-01 3.5297128e-04 2.2417460e-05 3.5391709e-05 5.6516778e-06
 4.5788503e-04 6.6077256e-08 3.1004205e-01 5.3858250e-05 2.2386624e-03
 1.3438468e-05], sum to 1.0000
[2019-04-16 12:20:50,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7724
[2019-04-16 12:20:50,057] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.6666666666666667, 37.0, 0.0, 0.0, 19.0, 20.77626258535349, -0.7615205520631733, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4918800.0000, 
sim time next is 4920000.0000, 
raw observation next is [0.3333333333333334, 38.0, 0.0, 0.0, 19.0, 20.78768351391838, -0.6181811607816515, 0.0, 1.0, 50.0, 66.04546783121414], 
processed observation next is [0.0, 0.9565217391304348, 0.4718374884579871, 0.38, 0.0, 0.0, 0.08333333333333333, 0.23230695949319843, 0.2939396130727828, 0.0, 1.0, 0.7, 0.6604546783121414], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.69407326], dtype=float32), -0.04416871]. 
=============================================
[2019-04-16 12:20:50,077] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[21.023985]
 [20.916164]
 [21.885061]
 [21.423008]
 [21.829788]
 [22.321297]
 [23.30028 ]
 [23.798351]
 [23.45263 ]
 [24.094791]
 [23.695858]
 [24.531162]
 [24.366741]
 [23.681898]
 [23.739122]
 [23.824942]
 [23.576368]
 [24.360497]
 [25.203949]
 [25.512365]
 [26.548635]
 [25.541016]
 [25.427948]
 [26.243452]
 [26.302021]], R is [[20.89282036]
 [21.6838932 ]
 [22.46705437]
 [22.24238396]
 [23.0199604 ]
 [23.78976059]
 [24.55186272]
 [25.30634499]
 [26.05328178]
 [26.7927494 ]
 [26.52482224]
 [27.25957489]
 [27.08178329]
 [26.81096649]
 [27.54285622]
 [27.36040688]
 [27.08680344]
 [27.81593513]
 [28.53777695]
 [29.25239944]
 [29.95987511]
 [29.66027641]
 [30.36367416]
 [31.06003761]
 [31.74943733]].
[2019-04-16 12:20:50,875] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:51,057] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:51,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9423678e-01 7.5867873e-05 2.7961676e-05 3.3314587e-05 1.0378546e-06
 1.9482076e-04 2.7010133e-08 2.0365937e-01 3.3167242e-05 1.7258286e-03
 1.1829899e-05], sum to 1.0000
[2019-04-16 12:20:51,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4110
[2019-04-16 12:20:51,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 19.0, 21.18748475963211, -0.6630107227773258, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4832400.0000, 
sim time next is 4833600.0000, 
raw observation next is [-1.0, 55.0, 0.0, 0.0, 19.0, 20.73712289931784, -0.7668044306196294, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.55, 0.0, 0.0, 0.08333333333333333, 0.22809357494315327, 0.2443985231267902, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16562095], dtype=float32), 2.774741]. 
=============================================
[2019-04-16 12:20:51,893] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:51,893] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:51,898] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run6
[2019-04-16 12:20:51,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7286086e-01 4.2213788e-04 2.8262422e-05 3.6324851e-05 2.9937953e-06
 2.7207498e-04 2.3598605e-07 3.2409260e-01 3.9728595e-05 2.2274863e-03
 1.7373857e-05], sum to 1.0000
[2019-04-16 12:20:51,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2731
[2019-04-16 12:20:51,957] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 39.0, 0.0, 0.0, 19.0, 19.70384867658535, -1.001885078746475, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4921200.0000, 
sim time next is 4922400.0000, 
raw observation next is [0.3333333333333333, 39.33333333333334, 0.0, 0.0, 19.0, 19.54535216457401, -1.032739242001842, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.4718374884579871, 0.3933333333333334, 0.0, 0.0, 0.08333333333333333, 0.1287793470478341, 0.15575358599938602, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2647411], dtype=float32), -0.23686825]. 
=============================================
[2019-04-16 12:20:52,149] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:52,319] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:53,148] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:53,148] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:53,152] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run6
[2019-04-16 12:20:53,393] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:53,578] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:53,853] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:54,019] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:54,313] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:54,396] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:54,396] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:54,400] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run6
[2019-04-16 12:20:54,477] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:54,865] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:54,866] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:54,878] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run6
[2019-04-16 12:20:54,915] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:55,125] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:55,273] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:55,313] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:55,313] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:55,317] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run6
[2019-04-16 12:20:55,424] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:55,909] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:55,909] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:55,930] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run6
[2019-04-16 12:20:56,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6370385e-01 2.9524963e-06 2.3494518e-08 5.1926133e-07 5.1543418e-09
 2.0629357e-05 6.0583301e-12 1.3622515e-01 1.5186261e-07 4.6708683e-05
 1.2973402e-07], sum to 1.0000
[2019-04-16 12:20:56,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6545
[2019-04-16 12:20:56,034] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.666666666666668, 25.33333333333333, 123.0, 864.1666666666667, 22.5, 25.31483676421166, 0.2937335955785964, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5056800.0000, 
sim time next is 5058000.0000, 
raw observation next is [9.0, 25.0, 121.0, 862.5, 22.5, 25.34709101420018, 0.2955408995241648, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.7119113573407203, 0.25, 0.4033333333333333, 0.9530386740331491, 0.375, 0.6122575845166818, 0.5985136331747216, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46507818], dtype=float32), 0.8521384]. 
=============================================
[2019-04-16 12:20:56,270] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:56,270] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:56,274] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run6
[2019-04-16 12:20:56,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:56,859] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:56,971] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:57,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:57,204] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:57,462] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:57,512] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:57,556] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:57,556] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:57,560] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run6
[2019-04-16 12:20:57,697] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:57,972] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:57,976] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:57,979] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run6
[2019-04-16 12:20:58,205] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:58,205] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:58,227] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run6
[2019-04-16 12:20:58,381] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2145504e-01 2.2196800e-05 4.6484445e-08 5.0427332e-07 4.2877559e-09
 1.8394407e-05 3.1418707e-12 2.7847254e-01 2.3596168e-07 3.0784307e-05
 2.0020062e-07], sum to 1.0000
[2019-04-16 12:20:58,382] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4175
[2019-04-16 12:20:58,395] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 25.0, 17.0, 152.0, 22.5, 24.78977962872182, 0.213239269070954, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4989600.0000, 
sim time next is 4990800.0000, 
raw observation next is [6.0, 24.33333333333334, 0.0, 0.0, 22.5, 24.80103408958282, 0.1113706243785896, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.2433333333333334, 0.0, 0.0, 0.375, 0.5667528407985684, 0.5371235414595299, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2285872], dtype=float32), 2.612864]. 
=============================================
[2019-04-16 12:20:58,513] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:58,513] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:58,523] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run6
[2019-04-16 12:20:58,625] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:58,931] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:59,435] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:20:59,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5460126e-01 2.6146829e-04 1.2117435e-05 1.8506122e-05 2.5551394e-06
 3.0729765e-04 2.2261998e-08 1.4342292e-01 4.5960085e-05 1.3076302e-03
 2.0354986e-05], sum to 1.0000
[2019-04-16 12:20:59,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6851
[2019-04-16 12:20:59,461] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 16.5, 93.5, 19.0, 20.37816689856742, -0.6541159550593331, 0.0, 1.0, 50.0, 66.59642204114611], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4903200.0000, 
sim time next is 4904400.0000, 
raw observation next is [1.666666666666667, 45.0, 0.0, 0.0, 19.0, 20.94055008189278, -0.722812498584824, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5087719298245615, 0.45, 0.0, 0.0, 0.08333333333333333, 0.2450458401577317, 0.25906250047172535, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.56914467], dtype=float32), 0.98160046]. 
=============================================
[2019-04-16 12:20:59,617] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:20:59,617] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:20:59,620] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run6
[2019-04-16 12:20:59,660] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:20:59,999] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:21:00,179] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:21:00,436] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:21:00,436] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:00,439] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run6
[2019-04-16 12:21:01,000] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:21:01,001] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:01,004] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run6
[2019-04-16 12:21:01,813] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:21:02,130] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:21:02,802] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:21:02,802] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:02,818] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run6
[2019-04-16 12:21:04,732] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:21:04,935] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-16 12:21:05,730] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:21:05,730] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:05,734] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run6
[2019-04-16 12:21:15,621] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.7604909e-01 1.4012089e-04 9.0196145e-06 1.0813230e-05 3.5429460e-07
 2.1299765e-04 5.1228111e-09 4.2316705e-01 3.6344816e-05 3.6878846e-04
 5.4293423e-06], sum to 1.0000
[2019-04-16 12:21:15,627] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2689
[2019-04-16 12:21:15,684] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.9, 64.33333333333334, 93.66666666666667, 404.5, 22.5, 19.84001821805369, -1.140662515530394, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 294000.0000, 
sim time next is 295200.0000, 
raw observation next is [-11.7, 63.0, 91.0, 447.5, 22.5, 19.5248360365392, -1.18364131000784, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.13850415512465375, 0.63, 0.30333333333333334, 0.494475138121547, 0.375, 0.12706966971159991, 0.10545289666405333, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7387786], dtype=float32), -1.039469]. 
=============================================
[2019-04-16 12:21:21,580] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.8350965e-01 1.7947557e-04 6.8787876e-06 5.5323344e-06 6.4821535e-07
 2.5047536e-04 3.7248340e-09 3.1532896e-01 1.8001339e-05 6.9243205e-04
 7.9579422e-06], sum to 1.0000
[2019-04-16 12:21:21,580] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2716
[2019-04-16 12:21:21,609] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.0, 78.66666666666667, 0.0, 0.0, 19.0, 17.54843991125393, -1.512034975970031, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 336000.0000, 
sim time next is 337200.0000, 
raw observation next is [-13.2, 80.33333333333333, 0.0, 0.0, 19.0, 17.33290383524383, -1.559795953838262, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.09695290858725764, 0.8033333333333332, 0.0, 0.0, 0.08333333333333333, -0.0555913470630142, -0.01993198461275399, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16720837], dtype=float32), 0.16225857]. 
=============================================
[2019-04-16 12:21:21,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6709167e-01 8.8376073e-06 3.1682751e-07 9.3644348e-07 2.9930060e-08
 4.5592893e-05 1.2919085e-10 3.3279932e-01 3.3561630e-06 4.9651062e-05
 2.5318900e-07], sum to 1.0000
[2019-04-16 12:21:21,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4756
[2019-04-16 12:21:21,931] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 68.0, 0.0, 0.0, 19.0, 18.92400355322433, -1.140469755008703, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 162000.0000, 
sim time next is 163200.0000, 
raw observation next is [-8.4, 69.0, 0.0, 0.0, 19.0, 18.67708073116088, -1.186910254520585, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.2299168975069252, 0.69, 0.0, 0.0, 0.08333333333333333, 0.05642339426340678, 0.10436324849313834, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.5829, 
noisyNet noise sample is [array([1.1549038], dtype=float32), -0.9401258]. 
=============================================
[2019-04-16 12:21:26,975] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5436890e-01 1.1493035e-04 1.1098855e-05 1.1862518e-05 1.7200918e-07
 1.8666874e-04 1.1607747e-08 2.4487829e-01 3.2495409e-05 3.7801318e-04
 1.7448299e-05], sum to 1.0000
[2019-04-16 12:21:26,975] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5433
[2019-04-16 12:21:27,018] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-14.86666666666667, 74.0, 44.33333333333333, 736.5, 22.5, 18.22336202344524, -1.423969003033561, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 380400.0000, 
sim time next is 381600.0000, 
raw observation next is [-14.5, 66.0, 55.0, 733.5, 22.5, 18.14888788032783, -1.437458073070775, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.06094182825484763, 0.66, 0.18333333333333332, 0.8104972375690608, 0.375, 0.012407323360652533, 0.020847308976408296, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6346739], dtype=float32), -1.5360034]. 
=============================================
[2019-04-16 12:21:36,642] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.4228457e-01 6.8417628e-04 6.2622596e-05 1.3176484e-04 3.4407594e-06
 1.5507833e-03 1.1972139e-07 3.5406736e-01 8.5222950e-05 1.0895078e-03
 4.0376006e-05], sum to 1.0000
[2019-04-16 12:21:36,643] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4712
[2019-04-16 12:21:36,653] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 22.5, 17.87148406315173, -1.504755043562585, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 717600.0000, 
sim time next is 718800.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 22.5, 17.6053462094473, -1.57063115195168, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.3988919667590028, 0.76, 0.0, 0.0, 0.375, -0.03288781587939157, -0.02354371731722667, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3747895], dtype=float32), -0.14607136]. 
=============================================
[2019-04-16 12:21:39,602] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.6281275e-01 5.3222856e-04 4.5650777e-05 8.0241800e-05 4.1525823e-06
 2.6242640e-03 1.1566433e-07 5.3012681e-01 5.4681972e-05 3.6740846e-03
 4.5058689e-05], sum to 1.0000
[2019-04-16 12:21:39,602] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0434
[2019-04-16 12:21:39,616] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.966666666666667, 84.0, 0.0, 0.0, 19.0, 19.42811575504746, -1.011914574232859, 0.0, 1.0, 50.0, 60.295207319245165], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 535200.0000, 
sim time next is 536400.0000, 
raw observation next is [1.6, 85.0, 0.0, 0.0, 19.0, 19.52140134587306, -1.116901334761509, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.5069252077562327, 0.85, 0.0, 0.0, 0.08333333333333333, 0.12678344548942158, 0.12769955507949696, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17667706], dtype=float32), 1.330648]. 
=============================================
[2019-04-16 12:21:43,382] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-16 12:21:43,397] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:21:43,397] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:21:43,397] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:43,398] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:43,398] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:21:43,398] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:21:43,401] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run8
[2019-04-16 12:21:43,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run8
[2019-04-16 12:21:43,426] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run8
[2019-04-16 12:22:54,388] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2822.3504 74650.3553 -89.0896
[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,422] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:22:54,537] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,774] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2577.9454 81846.8443 -595.9535
[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,794] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:04,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:07,913] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2372.0775 81668.6580 -820.4290
[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:07,934] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:23:08,937] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 350000, evaluation results [350000.0, 2577.945383606686, 81846.84432513313, -595.953482443269, 2822.3504175387284, 74650.35527220448, -89.08959440568432, 2372.0775378670633, 81668.65803855231, -820.4289707990343]
[2019-04-16 12:23:19,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5390557e-01 1.5086909e-04 7.4607983e-06 1.4007901e-05 5.2469721e-07
 2.9984664e-04 1.5065369e-08 3.4487662e-01 2.4743355e-05 7.1350281e-04
 6.8180439e-06], sum to 1.0000
[2019-04-16 12:23:19,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9367
[2019-04-16 12:23:19,386] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [14.4, 100.0, 86.5, 0.0, 19.0, 24.33967179398663, 0.371761216092836, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1249200.0000, 
sim time next is 1250400.0000, 
raw observation next is [14.4, 98.66666666666667, 92.16666666666667, 0.0, 19.0, 24.56425560233602, 0.556439669724309, 0.0, 1.0, 50.0, 58.018632386052], 
processed observation next is [0.0, 0.4782608695652174, 0.8614958448753465, 0.9866666666666667, 0.30722222222222223, 0.0, 0.08333333333333333, 0.5470213001946682, 0.685479889908103, 0.0, 1.0, 0.7, 0.5801863238605199], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3116575], dtype=float32), 0.77721417]. 
=============================================
[2019-04-16 12:23:23,586] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5859156e-01 9.1535576e-06 1.0788227e-06 1.1353355e-06 1.1620740e-08
 5.9693419e-05 2.7463026e-10 6.4129341e-01 1.6786772e-06 4.0954408e-05
 1.2155655e-06], sum to 1.0000
[2019-04-16 12:23:23,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0990
[2019-04-16 12:23:23,593] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.56666666666667, 82.0, 0.0, 0.0, 22.5, 23.43202973030292, -0.03907568567252234, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1064400.0000, 
sim time next is 1065600.0000, 
raw observation next is [12.2, 83.0, 11.5, 38.0, 22.5, 23.24221853424183, -0.05773210983538574, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.8005540166204987, 0.83, 0.03833333333333333, 0.041988950276243095, 0.375, 0.4368515445201524, 0.48075596338820475, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10723691], dtype=float32), -1.1850904]. 
=============================================
[2019-04-16 12:23:25,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.01373219e-01 1.89351954e-06 1.44411260e-07 2.79174426e-08
 6.23280927e-10 9.74049453e-06 1.48268409e-12 2.98603445e-01
 6.36455439e-08 1.14695795e-05 2.03854125e-08], sum to 1.0000
[2019-04-16 12:23:25,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2926
[2019-04-16 12:23:25,734] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 66.5, 0.0, 22.5, 24.16780513974051, 0.02268776631730386, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1348800.0000, 
sim time next is 1350000.0000, 
raw observation next is [1.1, 92.0, 57.5, 0.0, 22.5, 22.69840020101331, -0.08392574371933374, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19166666666666668, 0.0, 0.375, 0.3915333500844425, 0.47202475209355543, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04521027], dtype=float32), 0.6123448]. 
=============================================
[2019-04-16 12:23:25,738] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[34.407413]
 [34.406544]
 [35.205757]
 [35.97382 ]
 [34.860714]
 [34.705112]
 [35.05674 ]
 [35.998417]
 [35.238792]
 [34.823708]
 [34.47175 ]
 [34.126118]
 [33.5071  ]
 [32.17288 ]
 [31.961924]
 [32.12363 ]
 [31.303232]
 [30.719145]
 [29.372458]
 [28.931967]
 [28.949034]
 [29.26652 ]
 [28.54155 ]
 [28.287788]
 [27.419014]], R is [[34.95449829]
 [35.60495377]
 [36.24890518]
 [36.88641739]
 [36.51755524]
 [37.1523819 ]
 [37.78085709]
 [38.40304947]
 [38.01902008]
 [38.63883209]
 [39.25244522]
 [39.8599205 ]
 [39.51678848]
 [39.12162018]
 [39.7304039 ]
 [40.33309937]
 [39.976017  ]
 [39.60319138]
 [39.20716095]
 [39.81509018]
 [40.41693878]
 [41.01277161]
 [41.60264587]
 [42.1866188 ]
 [41.80854034]].
[2019-04-16 12:23:26,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.91423225e-01 6.93482298e-06 2.45016992e-07 8.01329122e-07
 3.53092240e-08 4.95376298e-05 2.98696103e-11 1.08254895e-01
 7.81094514e-07 2.63272959e-04 3.27773961e-07], sum to 1.0000
[2019-04-16 12:23:26,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0958
[2019-04-16 12:23:26,504] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.933333333333334, 96.0, 0.0, 0.0, 19.0, 24.34798654443878, 0.36283644149703, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1275600.0000, 
sim time next is 1276800.0000, 
raw observation next is [7.566666666666666, 96.0, 0.0, 0.0, 19.0, 24.13608508685644, 0.3242478025099098, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.672206832871653, 0.96, 0.0, 0.0, 0.08333333333333333, 0.5113404239047034, 0.6080826008366366, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05011937], dtype=float32), -0.7103788]. 
=============================================
[2019-04-16 12:23:26,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2330197e-01 3.9569436e-06 1.5061428e-07 6.0765490e-07 1.7564481e-09
 1.8289726e-05 5.3082113e-12 1.7652681e-01 2.8809387e-07 1.4760517e-04
 2.7976566e-07], sum to 1.0000
[2019-04-16 12:23:26,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1989
[2019-04-16 12:23:26,770] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.5, 82.0, 0.0, 0.0, 19.0, 23.5884441037112, 0.0219215729342121, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1551600.0000, 
sim time next is 1552800.0000, 
raw observation next is [5.333333333333334, 82.0, 0.0, 0.0, 19.0, 23.33597663244275, -0.03852958534439314, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.6103416435826409, 0.82, 0.0, 0.0, 0.08333333333333333, 0.4446647193702293, 0.48715680488520224, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0922722], dtype=float32), -0.4351781]. 
=============================================
[2019-04-16 12:23:26,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.5553223e-01 4.7911089e-06 1.7908641e-07 6.2993405e-07 1.4564107e-09
 1.4659842e-05 6.8993140e-12 1.4429219e-01 3.3801456e-07 1.5475885e-04
 2.6415009e-07], sum to 1.0000
[2019-04-16 12:23:26,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1369
[2019-04-16 12:23:26,804] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.166666666666666, 82.0, 0.0, 0.0, 19.0, 22.97362996677154, -0.09615936108758327, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1554000.0000, 
sim time next is 1555200.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 19.0, 22.72020772850705, -0.1412751727090582, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6011080332409973, 0.82, 0.0, 0.0, 0.08333333333333333, 0.39335064404225406, 0.4529082757636473, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0922722], dtype=float32), -0.4351781]. 
=============================================
[2019-04-16 12:23:29,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5583615e-01 7.2888274e-06 5.6755379e-08 6.2799593e-08 8.9841118e-10
 9.0262884e-06 1.3632394e-11 1.4414158e-01 9.8155070e-08 5.5454811e-06
 1.7176306e-07], sum to 1.0000
[2019-04-16 12:23:29,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3226
[2019-04-16 12:23:29,957] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.566666666666667, 98.66666666666667, 68.66666666666667, 0.0, 22.5, 22.43933340758419, -0.3890000496392135, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1506000.0000, 
sim time next is 1507200.0000, 
raw observation next is [2.933333333333333, 97.33333333333334, 75.5, 118.0, 22.5, 22.42528826383062, -0.3848469873287064, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.543859649122807, 0.9733333333333334, 0.25166666666666665, 0.13038674033149172, 0.375, 0.368774021985885, 0.37171767089043123, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12171964], dtype=float32), 0.17585267]. 
=============================================
[2019-04-16 12:23:30,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8647804e-01 5.5772425e-06 3.7752194e-08 5.3991776e-08 1.0643130e-09
 1.4159080e-05 9.5176202e-12 2.1349646e-01 8.6231395e-08 5.4103061e-06
 1.8413741e-07], sum to 1.0000
[2019-04-16 12:23:30,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3406
[2019-04-16 12:23:30,164] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.133333333333333, 69.66666666666667, 87.5, 700.8333333333334, 22.5, 22.59936522946449, -0.2186994685928609, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1516800.0000, 
sim time next is 1518000.0000, 
raw observation next is [9.066666666666666, 66.33333333333334, 83.33333333333334, 694.6666666666667, 22.5, 22.99071601757738, -0.162405445351462, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.713758079409049, 0.6633333333333334, 0.2777777777777778, 0.7675874769797423, 0.375, 0.4158930014647817, 0.44586485154951266, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12171964], dtype=float32), 0.17585267]. 
=============================================
[2019-04-16 12:23:34,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5722473e-01 3.6717603e-07 3.8219827e-09 1.7529119e-08 2.5718152e-11
 7.9334609e-07 3.8132861e-14 4.2770706e-02 2.6665626e-08 3.3642898e-06
 8.3495060e-09], sum to 1.0000
[2019-04-16 12:23:34,745] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1580
[2019-04-16 12:23:34,753] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.266666666666666, 71.33333333333333, 0.0, 0.0, 22.5, 25.1081853006121, 0.4507332243404099, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1626000.0000, 
sim time next is 1627200.0000, 
raw observation next is [7.7, 74.0, 0.0, 0.0, 22.5, 24.97255618784654, 0.4199786531575753, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6759002770083103, 0.74, 0.0, 0.0, 0.375, 0.5810463489872116, 0.6399928843858584, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7712833], dtype=float32), -0.052737605]. 
=============================================
[2019-04-16 12:23:38,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9322287e-01 5.9101929e-08 4.5223216e-09 1.2110482e-09 1.4563890e-11
 7.6212109e-07 3.1960207e-14 7.0677602e-01 8.4437017e-09 2.5432044e-07
 2.4119278e-09], sum to 1.0000
[2019-04-16 12:23:38,220] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4395
[2019-04-16 12:23:38,247] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 25.03370593341027, 0.4366795286353245, 1.0, 1.0, 50.0, 55.09737484446492], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1708800.0000, 
sim time next is 1710000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 25.02210019631513, 0.4448622127372627, 1.0, 1.0, 50.0, 40.343027596799836], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.5851750163595941, 0.6482874042457542, 1.0, 1.0, 0.7, 0.40343027596799835], 
reward next is 0.0716, 
noisyNet noise sample is [array([-0.1765771], dtype=float32), -0.91000694]. 
=============================================
[2019-04-16 12:23:38,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[40.534286]
 [40.01136 ]
 [40.78916 ]
 [41.108242]
 [40.63278 ]
 [41.650696]
 [41.247814]
 [42.08156 ]
 [42.10798 ]
 [42.05704 ]
 [42.145515]
 [41.379257]
 [40.61384 ]
 [40.561523]
 [40.783443]
 [40.54647 ]
 [39.654007]
 [38.973396]
 [37.954685]
 [37.577103]
 [37.098106]
 [36.913025]
 [36.99432 ]
 [35.787914]
 [35.40042 ]], R is [[39.74977493]
 [39.35227585]
 [39.95875168]
 [39.63220978]
 [39.23588943]
 [39.84353256]
 [39.44509888]
 [40.05064774]
 [39.74141312]
 [39.43523407]
 [39.12610245]
 [38.81268311]
 [38.50989532]
 [38.20806122]
 [37.90631104]
 [37.60548019]
 [37.29820251]
 [36.98247147]
 [36.67037582]
 [36.34555435]
 [35.98209763]
 [36.62227631]
 [37.25605392]
 [36.91994858]
 [36.57102203]].
[2019-04-16 12:23:41,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2940705e-01 4.8700086e-04 3.4221765e-05 7.4328731e-05 1.4877099e-06
 8.1301341e-04 5.5478925e-08 3.6751628e-01 4.7739675e-05 1.5614576e-03
 5.7333684e-05], sum to 1.0000
[2019-04-16 12:23:41,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6733
[2019-04-16 12:23:41,409] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.8, 78.0, 0.0, 0.0, 19.0, 17.36876834109419, -1.616344929484332, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1908000.0000, 
sim time next is 1909200.0000, 
raw observation next is [-8.0, 78.0, 0.0, 0.0, 19.0, 17.22059236700639, -1.497770725340877, 0.0, 1.0, 50.0, 71.65548431715362], 
processed observation next is [1.0, 0.08695652173913043, 0.24099722991689754, 0.78, 0.0, 0.0, 0.08333333333333333, -0.06495063608280087, 0.0007430915530410124, 0.0, 1.0, 0.7, 0.7165548431715362], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4084843], dtype=float32), 1.0102456]. 
=============================================
[2019-04-16 12:23:41,827] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.8959520e-01 5.9598673e-04 2.7205708e-05 8.3426145e-05 5.3931481e-06
 4.9133890e-04 2.6357989e-07 4.0543410e-01 1.8173976e-04 3.5424239e-03
 4.2933083e-05], sum to 1.0000
[2019-04-16 12:23:41,828] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1664
[2019-04-16 12:23:41,917] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 71.0, 145.0, 20.0, 19.0, 16.29287836948313, -1.521586077465637, 0.0, 1.0, 50.0, 108.65482293611174], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1861200.0000, 
sim time next is 1862400.0000, 
raw observation next is [-4.5, 71.0, 161.6666666666667, 33.33333333333334, 19.0, 17.45529919698129, -1.563998886258905, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.3379501385041552, 0.71, 0.5388888888888891, 0.03683241252302027, 0.08333333333333333, -0.04539173358489249, -0.021332962086301643, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7852229], dtype=float32), 0.12169902]. 
=============================================
[2019-04-16 12:23:44,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7681037e-01 1.5592262e-07 3.8193120e-09 2.1946828e-08 1.3780010e-10
 3.6288188e-06 4.9566042e-13 5.2318352e-01 1.6287652e-07 2.1135086e-06
 2.2275099e-08], sum to 1.0000
[2019-04-16 12:23:44,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4853
[2019-04-16 12:23:44,543] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 83.33333333333334, 0.0, 0.0, 22.5, 21.90364511748302, -0.4631194736548307, 1.0, 1.0, 50.0, 74.88992398661053], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2056800.0000, 
sim time next is 2058000.0000, 
raw observation next is [-3.899999999999999, 84.66666666666666, 0.0, 0.0, 22.5, 22.16743767206075, -0.4294502844363781, 0.0, 1.0, 50.0, 54.16944615600221], 
processed observation next is [1.0, 0.8260869565217391, 0.35457063711911363, 0.8466666666666666, 0.0, 0.0, 0.375, 0.34728647267172913, 0.35684990518787396, 0.0, 1.0, 0.7, 0.5416944615600221], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8809247], dtype=float32), -0.0002571537]. 
=============================================
[2019-04-16 12:23:47,816] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1127250e-01 9.7813157e-05 5.9829486e-06 4.4454291e-06 3.3740614e-07
 1.3248668e-04 4.0005999e-09 1.8794201e-01 7.7919622e-06 5.3050293e-04
 6.1435030e-06], sum to 1.0000
[2019-04-16 12:23:47,816] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8547
[2019-04-16 12:23:47,890] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.6, 83.0, 0.0, 0.0, 19.0, 17.07770322369247, -1.546061562912194, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1984800.0000, 
sim time next is 1986000.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 17.39638707048167, -1.288450770665638, 0.0, 1.0, 50.0, 88.75473078538639], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, -0.0503010774598609, 0.07051640977812064, 0.0, 1.0, 0.7, 0.8875473078538638], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2126526], dtype=float32), 0.5077875]. 
=============================================
[2019-04-16 12:23:54,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2696626e-01 1.8354432e-06 1.0581220e-07 1.6101953e-07 7.4530010e-10
 1.5336222e-05 5.8534010e-13 6.7298406e-01 1.9566822e-07 3.2049596e-05
 2.5908962e-08], sum to 1.0000
[2019-04-16 12:23:54,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1636
[2019-04-16 12:23:54,265] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 84.66666666666666, 0.0, 0.0, 22.5, 22.92106294054385, -0.2336217785740341, 0.0, 1.0, 50.0, 52.89991893729429], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2058000.0000, 
sim time next is 2059200.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 22.5, 22.73449892600838, -0.376473403097087, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.3545706371191136, 0.86, 0.0, 0.0, 0.375, 0.3945415771673651, 0.3745088656343043, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0788288], dtype=float32), 1.0893508]. 
=============================================
[2019-04-16 12:24:00,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0449988e-01 3.6739567e-04 2.0980440e-05 7.8809157e-05 4.4649660e-06
 8.1506599e-04 2.5383332e-07 3.9100641e-01 6.6144967e-05 3.0943027e-03
 4.6226858e-05], sum to 1.0000
[2019-04-16 12:24:00,326] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7593
[2019-04-16 12:24:00,411] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.633333333333333, 64.0, 136.0, 435.0, 19.0, 19.5711423506804, -0.9011009675275465, 0.0, 1.0, 50.0, 65.62717673279418], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2370000.0000, 
sim time next is 2371200.0000, 
raw observation next is [-2.466666666666667, 63.0, 143.6666666666667, 426.0, 19.0, 20.06206021128072, -0.8379002125976801, 0.0, 1.0, 50.0, 45.74749660147427], 
processed observation next is [0.0, 0.43478260869565216, 0.39427516158818104, 0.63, 0.47888888888888903, 0.4707182320441989, 0.08333333333333333, 0.17183835094005998, 0.22069992913410663, 0.0, 1.0, 0.7, 0.4574749660147427], 
reward next is 0.0175, 
noisyNet noise sample is [array([1.5773529], dtype=float32), 1.8333281]. 
=============================================
[2019-04-16 12:24:03,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8411577e-01 1.4383241e-04 4.5264028e-06 1.5776281e-05 1.4315610e-06
 4.1156774e-04 2.5470442e-08 3.1470254e-01 1.6187150e-05 5.7644263e-04
 1.1825594e-05], sum to 1.0000
[2019-04-16 12:24:03,828] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2364
[2019-04-16 12:24:03,844] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 45.66666666666667, 66.83333333333334, 51.0, 19.0, 19.19718768185377, -1.101198896413182, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2392800.0000, 
sim time next is 2394000.0000, 
raw observation next is [-0.6, 45.0, 42.5, 37.0, 19.0, 18.91320173739867, -1.152848742248757, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.44598337950138506, 0.45, 0.14166666666666666, 0.04088397790055249, 0.08333333333333333, 0.07610014478322243, 0.115717085917081, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9699, 
noisyNet noise sample is [array([0.40149194], dtype=float32), -0.33483976]. 
=============================================
[2019-04-16 12:24:05,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7718492e-01 5.4269226e-04 1.3742479e-04 2.3103980e-04 1.9729332e-05
 8.5284538e-04 6.8012946e-07 4.1773331e-01 2.1574672e-04 2.9714233e-03
 1.1008776e-04], sum to 1.0000
[2019-04-16 12:24:05,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1130
[2019-04-16 12:24:05,983] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.166666666666666, 45.33333333333333, 63.5, 683.6666666666667, 19.0, 17.99453808967193, -1.476367146740238, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2454000.0000, 
sim time next is 2455200.0000, 
raw observation next is [-5.6, 43.0, 68.5, 721.0, 19.0, 17.45408404836689, -1.538914044359939, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.43, 0.22833333333333333, 0.7966850828729282, 0.08333333333333333, -0.04549299596942576, -0.01297134811997965, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8041651], dtype=float32), 2.2577128]. 
=============================================
[2019-04-16 12:24:08,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7407422e-01 1.4089409e-04 3.8119410e-06 4.6613568e-06 3.6062224e-07
 3.8134959e-04 4.7211026e-09 6.2406707e-01 5.6241065e-06 1.3195525e-03
 2.3905507e-06], sum to 1.0000
[2019-04-16 12:24:08,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5385
[2019-04-16 12:24:08,288] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.3, 25.66666666666667, 50.33333333333333, 345.8333333333333, 19.0, 20.50752000125516, -0.9177179177992958, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2478000.0000, 
sim time next is 2479200.0000, 
raw observation next is [3.3, 25.33333333333333, 41.0, 239.6666666666667, 19.0, 20.46308934470703, -0.8190305575116961, 0.0, 1.0, 50.0, 53.59425299330732], 
processed observation next is [0.0, 0.6956521739130435, 0.554016620498615, 0.2533333333333333, 0.13666666666666666, 0.2648250460405157, 0.08333333333333333, 0.20525744539225244, 0.22698981416276798, 0.0, 1.0, 0.7, 0.5359425299330732], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3638917], dtype=float32), 0.62927413]. 
=============================================
[2019-04-16 12:24:09,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3115469e-01 2.8452603e-04 4.9129371e-06 3.9551906e-05 3.9900948e-07
 4.8337950e-04 1.1639072e-08 4.6738181e-01 1.9089170e-05 6.1740039e-04
 1.4280272e-05], sum to 1.0000
[2019-04-16 12:24:09,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1242
[2019-04-16 12:24:09,422] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 19.0, 19.51664439922464, -1.076703093612928, 0.0, 1.0, 50.0, 43.36621109571195], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2523600.0000, 
sim time next is 2524800.0000, 
raw observation next is [-2.3, 57.00000000000001, 0.0, 0.0, 19.0, 19.51793443759367, -1.188478726601104, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.5700000000000001, 0.0, 0.0, 0.08333333333333333, 0.12649453646613917, 0.10384042446629864, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07661758], dtype=float32), 1.1136209]. 
=============================================
[2019-04-16 12:24:10,504] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.6862252e-01 5.3066542e-05 3.1816369e-06 8.0989648e-06 7.3269369e-08
 1.8912701e-04 2.8021228e-09 2.3040420e-01 8.5676093e-06 7.0970162e-04
 1.3739677e-06], sum to 1.0000
[2019-04-16 12:24:10,520] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8184
[2019-04-16 12:24:10,558] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.333333333333334, 70.0, 0.0, 0.0, 19.0, 20.34524260194146, -0.7514254127508493, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2680800.0000, 
sim time next is 2682000.0000, 
raw observation next is [-9.0, 69.0, 0.0, 0.0, 19.0, 20.46348891622963, -0.5583379300352299, 0.0, 1.0, 50.0, 77.43434795796527], 
processed observation next is [1.0, 0.043478260869565216, 0.21329639889196678, 0.69, 0.0, 0.0, 0.08333333333333333, 0.20529074301913575, 0.31388735665492334, 0.0, 1.0, 0.7, 0.7743434795796528], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1873683], dtype=float32), 0.018435279]. 
=============================================
[2019-04-16 12:24:13,173] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5719092e-01 2.7621759e-06 6.6203732e-08 1.3460222e-07 5.1272320e-10
 1.9115934e-05 8.2287074e-13 3.4276471e-01 2.0170145e-07 2.1945012e-05
 7.5278955e-08], sum to 1.0000
[2019-04-16 12:24:13,173] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4458
[2019-04-16 12:24:13,198] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.266666666666667, 27.33333333333334, 169.0, 447.5, 22.5, 23.40901764294518, -0.1471312654631626, 1.0, 1.0, 50.0, 40.57871177778607], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2554800.0000, 
sim time next is 2556000.0000, 
raw observation next is [3.8, 26.0, 165.0, 378.5, 22.5, 23.62831074062336, -0.3472959496204975, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5678670360110805, 0.26, 0.55, 0.41823204419889504, 0.375, 0.4690258950519466, 0.3842346834598342, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.41975886], dtype=float32), -0.099192865]. 
=============================================
[2019-04-16 12:24:14,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0780426e-01 4.1131701e-04 3.3827575e-05 2.8338867e-05 3.8015869e-06
 7.0629612e-04 2.3348584e-07 2.8947827e-01 9.7478667e-05 1.4026103e-03
 3.3560198e-05], sum to 1.0000
[2019-04-16 12:24:14,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3297
[2019-04-16 12:24:14,202] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.566666666666666, 60.66666666666667, 0.0, 0.0, 19.0, 17.87044334937828, -1.471939477748985, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2438400.0000, 
sim time next is 2439600.0000, 
raw observation next is [-8.733333333333334, 60.33333333333334, 0.0, 0.0, 19.0, 17.29600202620685, -1.558741507115476, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.22068328716528163, 0.6033333333333334, 0.0, 0.0, 0.08333333333333333, -0.05866649781609586, -0.01958050237182533, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45944053], dtype=float32), -0.6627203]. 
=============================================
[2019-04-16 12:24:19,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8986386e-01 1.0585009e-04 6.0805150e-06 1.8073810e-05 5.1603131e-08
 1.7041042e-04 3.1977845e-09 3.0940369e-01 6.7773299e-06 4.1885412e-04
 6.2529953e-06], sum to 1.0000
[2019-04-16 12:24:19,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5054
[2019-04-16 12:24:19,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 93.0, 0.0, 0.0, 19.0, 20.32577478563893, -0.8869177616775926, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2868000.0000, 
sim time next is 2869200.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 19.0, 19.82872504736903, -1.002409937854602, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.4903047091412743, 0.93, 0.0, 0.0, 0.08333333333333333, 0.15239375394741916, 0.16586335404846597, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8191041], dtype=float32), 0.9301408]. 
=============================================
[2019-04-16 12:24:26,742] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5267353e-01 1.2687065e-05 7.9229110e-08 1.4586847e-06 9.3960955e-09
 1.3872783e-05 3.8645837e-11 1.4727622e-01 2.2072984e-06 1.9796524e-05
 1.4441834e-07], sum to 1.0000
[2019-04-16 12:24:26,742] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5897
[2019-04-16 12:24:26,762] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 19.0, 21.20049990063503, -0.5759838397770016, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2840400.0000, 
sim time next is 2841600.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 19.0, 20.96210928994415, -0.6508880531827101, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.44, 0.0, 0.0, 0.08333333333333333, 0.24684244082867904, 0.2830373156057633, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46830928], dtype=float32), -0.67784]. 
=============================================
[2019-04-16 12:24:27,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6098614e-01 4.6544494e-05 4.6214600e-06 8.0274967e-06 6.0256309e-07
 1.0826151e-04 3.4589454e-09 5.3823936e-01 9.2093305e-06 5.9515593e-04
 2.0279897e-06], sum to 1.0000
[2019-04-16 12:24:27,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2544
[2019-04-16 12:24:27,746] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 19.85956426644177, -1.017935048611086, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3024000.0000, 
sim time next is 3025200.0000, 
raw observation next is [-4.333333333333334, 67.0, 0.0, 0.0, 19.0, 19.2482842511481, -1.103288186371442, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.3425669436749769, 0.67, 0.0, 0.0, 0.08333333333333333, 0.10402368759567497, 0.1322372712095193, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.6777225], dtype=float32), -0.9580192]. 
=============================================
[2019-04-16 12:24:30,726] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5582916e-01 2.1934259e-06 1.5382373e-07 8.4491381e-07 2.5575710e-09
 3.3462084e-06 1.2926507e-12 7.4414575e-01 1.6554755e-07 1.8331015e-05
 2.9060359e-08], sum to 1.0000
[2019-04-16 12:24:30,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8054
[2019-04-16 12:24:30,775] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.6666666666666667, 100.0, 0.0, 0.0, 19.0, 24.41773416181356, 0.2347886536026735, 0.0, 1.0, 50.0, 37.16091230902944], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3201600.0000, 
sim time next is 3202800.0000, 
raw observation next is [0.3333333333333334, 100.0, 0.0, 0.0, 19.0, 24.41056059470549, 0.214312357765008, 0.0, 1.0, 50.0, 37.18279001060483], 
processed observation next is [1.0, 0.043478260869565216, 0.4718374884579871, 1.0, 0.0, 0.0, 0.08333333333333333, 0.5342133828921242, 0.571437452588336, 0.0, 1.0, 0.7, 0.3718279001060483], 
reward next is 0.1032, 
noisyNet noise sample is [array([-0.8332037], dtype=float32), -0.79211247]. 
=============================================
[2019-04-16 12:24:32,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5914170e-01 2.3210567e-04 1.4896660e-05 4.1346637e-05 1.8018094e-06
 5.1498844e-04 4.1197477e-08 5.3894824e-01 5.5896289e-05 1.0197082e-03
 2.9274619e-05], sum to 1.0000
[2019-04-16 12:24:32,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9853
[2019-04-16 12:24:32,282] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 74.66666666666666, 0.0, 0.0, 19.0, 18.59460574440241, -1.303793561620034, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3048000.0000, 
sim time next is 3049200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 18.36302947737453, -1.176615686029895, 0.0, 1.0, 50.0, 68.50987476213078], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.030252456447877368, 0.1077947713233683, 0.0, 1.0, 0.7, 0.6850987476213077], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18048853], dtype=float32), 1.4983464]. 
=============================================
[2019-04-16 12:24:39,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5560026e-01 2.4111830e-06 6.2500540e-08 2.2093237e-08 2.9159597e-10
 5.9819117e-06 1.3250222e-12 4.4378594e-02 1.5002556e-07 1.2481878e-05
 1.0607308e-08], sum to 1.0000
[2019-04-16 12:24:39,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8672
[2019-04-16 12:24:39,927] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666667, 88.33333333333333, 0.0, 0.0, 19.0, 23.22632235251478, -0.02786596659980277, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3274800.0000, 
sim time next is 3276000.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 22.81924762621111, -0.1007951802906854, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.4016039688509257, 0.46640160656977153, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22357875], dtype=float32), -3.343087]. 
=============================================
[2019-04-16 12:24:40,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3288896e-01 3.8279433e-04 2.3890467e-05 1.3684031e-05 8.3313193e-07
 6.3970772e-04 1.5759394e-08 1.6533232e-01 3.9628732e-05 6.6910399e-04
 9.0003314e-06], sum to 1.0000
[2019-04-16 12:24:40,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7989
[2019-04-16 12:24:40,291] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.600000000000001, 77.0, 0.0, 0.0, 19.0, 19.70397864486676, -0.8608680467693572, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3296400.0000, 
sim time next is 3297600.0000, 
raw observation next is [-8.9, 77.0, 0.0, 0.0, 19.0, 19.59905484573241, -0.9080265031098249, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.77, 0.0, 0.0, 0.08333333333333333, 0.13325457047770092, 0.1973244989633917, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22357875], dtype=float32), -3.343087]. 
=============================================
[2019-04-16 12:24:40,294] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.6714240e-01 5.1866849e-05 3.0659851e-06 5.4875827e-06 3.2301381e-07
 1.8375106e-04 3.6156478e-09 5.3236127e-01 5.6513018e-06 2.4252482e-04
 3.5749545e-06], sum to 1.0000
[2019-04-16 12:24:40,294] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8392
[2019-04-16 12:24:40,319] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 19.0, 20.9744114861891, -0.6308351185058436, 0.0, 1.0, 50.0, 58.6478916131243], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3630000.0000, 
sim time next is 3631200.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 19.0, 21.49414721724694, -0.5730659203658577, 0.0, 1.0, 50.0, 41.24201920732972], 
processed observation next is [0.0, 0.0, 0.7119113573407203, 0.25, 0.0, 0.0, 0.08333333333333333, 0.2911789347705784, 0.3089780265447141, 0.0, 1.0, 0.7, 0.41242019207329716], 
reward next is 0.0626, 
noisyNet noise sample is [array([-0.3233786], dtype=float32), 0.14163962]. 
=============================================
[2019-04-16 12:24:44,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0919807e-01 1.4427783e-07 9.9492237e-10 3.4504250e-08 1.3483314e-10
 2.2903848e-06 1.7160959e-14 4.9079108e-01 8.2010914e-09 8.3381528e-06
 1.3187546e-09], sum to 1.0000
[2019-04-16 12:24:44,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1610
[2019-04-16 12:24:44,359] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 66.33333333333334, 552.0, 22.5, 26.2327838693765, 0.5304498062828441, 1.0, 1.0, 50.0, 36.824347954503665], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3514800.0000, 
sim time next is 3516000.0000, 
raw observation next is [3.0, 49.0, 53.83333333333334, 462.6666666666667, 22.5, 25.69860001958651, 0.3569588301399899, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.49, 0.1794444444444445, 0.5112338858195212, 0.375, 0.6415500016322092, 0.61898627671333, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5375734], dtype=float32), 0.4619552]. 
=============================================
[2019-04-16 12:24:45,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6702936e-01 1.4942259e-04 1.0154060e-05 3.5863777e-05 5.2525542e-07
 4.1984845e-04 2.0549836e-08 5.3112227e-01 3.5951442e-05 1.1813403e-03
 1.5230684e-05], sum to 1.0000
[2019-04-16 12:24:45,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0245
[2019-04-16 12:24:45,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.333333333333334, 26.33333333333334, 0.0, 0.0, 19.0, 22.25407914446972, -0.4297799737286211, 0.0, 1.0, 50.0, 38.64998037562801], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3652800.0000, 
sim time next is 3654000.0000, 
raw observation next is [9.0, 27.0, 0.0, 0.0, 19.0, 22.20477330339713, -0.534013803022079, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.7119113573407203, 0.27, 0.0, 0.0, 0.08333333333333333, 0.35039777528309407, 0.32199539899264035, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3782228], dtype=float32), -1.2852992]. 
=============================================
[2019-04-16 12:24:46,789] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.87696201e-01 1.55561327e-04 1.24576645e-05 2.24894593e-05
 1.11970780e-06 1.18526060e-03 1.14887753e-08 5.10641575e-01
 2.40826103e-05 2.51207821e-04 1.00599327e-05], sum to 1.0000
[2019-04-16 12:24:46,789] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8278
[2019-04-16 12:24:46,818] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 70.0, 0.0, 0.0, 19.0, 20.99255332005379, -0.5616848685587095, 0.0, 1.0, 50.0, 43.975104772950374], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3566400.0000, 
sim time next is 3567600.0000, 
raw observation next is [-6.0, 70.0, 0.0, 0.0, 19.0, 21.13920362347395, -0.5501127365837555, 0.0, 1.0, 50.0, 43.57364404097197], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.7, 0.0, 0.0, 0.08333333333333333, 0.2616003019561625, 0.3166290878054148, 0.0, 1.0, 0.7, 0.4357364404097197], 
reward next is 0.0393, 
noisyNet noise sample is [array([-1.7138925], dtype=float32), -0.48434433]. 
=============================================
[2019-04-16 12:24:47,378] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.9516903e-01 4.8826609e-05 2.9949310e-06 3.2273508e-06 6.7009900e-08
 1.0590623e-04 4.0808429e-10 3.0446434e-01 3.1377660e-06 2.0006731e-04
 2.4092549e-06], sum to 1.0000
[2019-04-16 12:24:47,379] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4023
[2019-04-16 12:24:47,396] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 22.4406039044422, -0.1957138001613326, 0.0, 1.0, 50.0, 44.36390436684445], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3896400.0000, 
sim time next is 3897600.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 22.75947173047616, -0.3288173549845499, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.39662264420634674, 0.39039421500515004, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1336585], dtype=float32), -0.17206083]. 
=============================================
[2019-04-16 12:24:47,661] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.9995563e-01 6.2395549e-07 3.8299699e-08 1.2386955e-07 2.3189056e-10
 1.3994779e-06 2.4685481e-13 1.0003875e-01 2.4635074e-08 3.4241382e-06
 6.0121028e-09], sum to 1.0000
[2019-04-16 12:24:47,661] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3346
[2019-04-16 12:24:47,676] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 75.0, 109.1666666666667, 753.3333333333334, 22.5, 23.11001615881769, -0.240557891815823, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3752400.0000, 
sim time next is 3753600.0000, 
raw observation next is [-3.0, 73.0, 111.6666666666667, 777.8333333333334, 22.5, 23.16604785318871, -0.2242059491795494, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.73, 0.37222222222222234, 0.8594843462246777, 0.375, 0.43050398776572596, 0.42526468360681685, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2350768], dtype=float32), -0.37379095]. 
=============================================
[2019-04-16 12:24:55,700] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2585723e-01 2.1837122e-06 7.2800823e-08 1.3529328e-07 8.8048430e-10
 1.0365537e-06 9.3052050e-12 3.7411654e-01 1.3697256e-07 2.2572343e-05
 5.4860887e-08], sum to 1.0000
[2019-04-16 12:24:55,700] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3630
[2019-04-16 12:24:55,719] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 22.77309609729874, -0.05677268991133742, 0.0, 1.0, 50.0, 64.31704786444999], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3890400.0000, 
sim time next is 3891600.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 23.08197653736261, -0.1393038251696362, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.4234980447802175, 0.45356539161012127, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6488131], dtype=float32), 0.79430616]. 
=============================================
[2019-04-16 12:24:56,384] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.3444436e-01 1.1871113e-06 1.2253076e-07 5.7386313e-08 8.1728474e-10
 5.1643178e-06 3.7102014e-12 3.6553562e-01 2.1704408e-07 1.3195674e-05
 5.4828213e-08], sum to 1.0000
[2019-04-16 12:24:56,385] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2949
[2019-04-16 12:24:56,455] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.0, 105.5, 727.5, 22.5, 23.53762441422548, -0.1945004405428346, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3837600.0000, 
sim time next is 3838800.0000, 
raw observation next is [-1.666666666666667, 60.00000000000001, 108.5, 759.1666666666667, 22.5, 23.40948840453205, -0.2013861057330326, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4164358264081256, 0.6000000000000001, 0.3616666666666667, 0.8388581952117865, 0.375, 0.4507907003776707, 0.4328712980889891, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0099193], dtype=float32), -0.55943555]. 
=============================================
[2019-04-16 12:24:59,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0439485e-01 6.0690269e-05 9.6783288e-07 3.5910484e-06 2.6111282e-08
 1.3324554e-04 5.5306637e-10 3.9508867e-01 2.0608170e-06 3.1453717e-04
 1.4478710e-06], sum to 1.0000
[2019-04-16 12:24:59,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1247
[2019-04-16 12:24:59,045] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 60.0, 47.0, 392.0, 19.0, 23.07363858587241, -0.1910220522452029, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4294800.0000, 
sim time next is 4296000.0000, 
raw observation next is [6.466666666666667, 61.33333333333334, 31.66666666666666, 282.6666666666666, 19.0, 22.8573521282634, -0.2668696482548057, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.6417359187442291, 0.6133333333333334, 0.10555555555555554, 0.3123388581952117, 0.08333333333333333, 0.40477934402195004, 0.4110434505817315, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9920753], dtype=float32), -0.18081509]. 
=============================================
[2019-04-16 12:25:02,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2576550e-01 2.4985607e-07 2.9424185e-09 5.6012337e-09 9.5272228e-12
 2.4362621e-06 2.0346567e-14 8.7423033e-01 3.6853509e-09 1.4606892e-06
 8.8623031e-10], sum to 1.0000
[2019-04-16 12:25:02,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7008
[2019-04-16 12:25:02,778] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0121096e-01 5.0374166e-07 4.0913428e-09 2.6858526e-08 8.5577948e-11
 1.5759572e-06 3.2461439e-13 9.8784819e-02 1.1939012e-08 1.9693905e-06
 1.0139718e-08], sum to 1.0000
[2019-04-16 12:25:02,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0293
[2019-04-16 12:25:02,795] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 45.0, 0.0, 0.0, 19.0, 22.85241039765117, -0.136077609932692, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3961200.0000, 
sim time next is 3962400.0000, 
raw observation next is [-7.0, 45.0, 0.0, 0.0, 19.0, 22.5623026385754, -0.1908850661248549, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.2686980609418283, 0.45, 0.0, 0.0, 0.08333333333333333, 0.38019188654794994, 0.43637164462504835, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5143383], dtype=float32), -1.1402855]. 
=============================================
[2019-04-16 12:25:02,821] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [12.6, 34.0, 117.5, 804.0, 22.5, 26.03471674356693, 0.4434841059910823, 1.0, 1.0, 50.0, 42.68896692655135], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4359600.0000, 
sim time next is 4360800.0000, 
raw observation next is [13.4, 32.0, 119.1666666666667, 820.0, 22.5, 26.29321445021931, 0.532777622944644, 1.0, 1.0, 50.0, 41.035023209766806], 
processed observation next is [1.0, 0.4782608695652174, 0.8337950138504157, 0.32, 0.3972222222222223, 0.9060773480662984, 0.375, 0.6911012041849425, 0.6775925409815481, 1.0, 1.0, 0.7, 0.4103502320976681], 
reward next is 0.0646, 
noisyNet noise sample is [array([-0.6893366], dtype=float32), 0.96820563]. 
=============================================
[2019-04-16 12:25:03,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3287866e-01 2.9894383e-05 3.9989791e-07 1.1683937e-06 6.9040532e-08
 2.2284092e-05 2.2202812e-10 3.6685380e-01 2.0927052e-06 2.1113564e-04
 5.0073265e-07], sum to 1.0000
[2019-04-16 12:25:03,175] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3824
[2019-04-16 12:25:03,185] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 19.0, 21.60896407681165, -0.3988204326201095, 0.0, 1.0, 50.0, 67.09700739369026], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4228800.0000, 
sim time next is 4230000.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 19.0, 22.10943797923477, -0.4687465717462688, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.4903047091412743, 0.47, 0.0, 0.0, 0.08333333333333333, 0.3424531649362308, 0.3437511427512437, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6374867], dtype=float32), -0.7205013]. 
=============================================
[2019-04-16 12:25:03,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[28.182888]
 [26.939466]
 [27.670418]
 [27.918814]
 [27.65618 ]
 [28.506159]
 [28.228998]
 [28.164764]
 [27.645666]
 [27.222706]
 [27.10092 ]
 [28.878157]
 [27.982914]
 [28.008835]
 [28.307175]
 [27.421701]
 [28.450459]
 [27.509726]
 [27.901613]
 [27.83904 ]
 [28.733492]
 [27.496744]
 [27.466694]
 [28.302095]
 [27.861952]], R is [[28.65626144]
 [28.36969948]
 [29.08600235]
 [29.79514313]
 [30.49719238]
 [31.19222069]
 [30.95568466]
 [30.71692276]
 [30.47188377]
 [30.16716576]
 [30.86549377]
 [31.55683899]
 [31.24127007]
 [31.9288578 ]
 [32.60956955]
 [32.28347397]
 [32.96063995]
 [32.63103485]
 [33.30472565]
 [33.97167969]
 [34.63196182]
 [34.28564072]
 [34.94278336]
 [35.59335709]
 [36.23742294]].
[2019-04-16 12:25:04,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5688536e-01 2.0858596e-07 1.5724418e-10 1.8220658e-09 3.4819318e-11
 1.7481344e-07 2.9716789e-14 4.4311297e-01 1.2093283e-08 1.3003048e-06
 1.7050644e-09], sum to 1.0000
[2019-04-16 12:25:04,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6934
[2019-04-16 12:25:04,564] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 37.0, 58.0, 247.0, 22.5, 25.15311038468732, 0.2695770655707733, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4122000.0000, 
sim time next is 4123200.0000, 
raw observation next is [3.0, 36.0, 34.66666666666666, 120.3333333333333, 22.5, 25.66856186302812, 0.2705727328530762, 1.0, 1.0, 50.0, 53.521132862812465], 
processed observation next is [1.0, 0.7391304347826086, 0.5457063711911359, 0.36, 0.11555555555555552, 0.13296500920810309, 0.375, 0.6390468219190101, 0.5901909109510254, 1.0, 1.0, 0.7, 0.5352113286281246], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4511453], dtype=float32), 1.6115036]. 
=============================================
[2019-04-16 12:25:05,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0834603e-01 3.2204246e-06 3.0577258e-08 1.3770945e-07 2.1313808e-09
 1.1025238e-05 3.5877003e-11 1.9158784e-01 3.5858946e-07 5.1370323e-05
 5.5165444e-08], sum to 1.0000
[2019-04-16 12:25:05,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9125
[2019-04-16 12:25:05,123] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [6.866666666666667, 59.0, 210.1666666666667, 430.0, 19.0, 21.86316894453046, -0.3946086375440334, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4286400.0000, 
sim time next is 4287600.0000, 
raw observation next is [6.8, 60.0, 172.5, 520.0, 19.0, 22.21247945601193, -0.17837271843942, 0.0, 1.0, 50.0, 61.48275710820734], 
processed observation next is [0.0, 0.6521739130434783, 0.6509695290858727, 0.6, 0.575, 0.574585635359116, 0.08333333333333333, 0.35103995466766086, 0.44054242718686004, 0.0, 1.0, 0.7, 0.6148275710820734], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4067755], dtype=float32), -1.244684]. 
=============================================
[2019-04-16 12:25:07,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3089468e-01 3.3432269e-05 4.6558239e-07 4.2362353e-06 3.5959971e-08
 6.1374405e-05 2.4056906e-10 2.6891679e-01 3.6479996e-06 8.4528358e-05
 8.9662848e-07], sum to 1.0000
[2019-04-16 12:25:07,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3027
[2019-04-16 12:25:07,953] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.6, 69.0, 0.0, 0.0, 19.0, 22.10362183057689, -0.4621523670170657, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4338000.0000, 
sim time next is 4339200.0000, 
raw observation next is [3.5, 69.66666666666667, 0.0, 0.0, 19.0, 21.73112428312359, -0.5418868597278904, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5595567867036012, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.3109270235936326, 0.3193710467573699, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07858318], dtype=float32), 1.6651906]. 
=============================================
[2019-04-16 12:25:09,598] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-16 12:25:09,598] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:25:09,599] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:25:09,600] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:25:09,601] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:25:09,602] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run9
[2019-04-16 12:25:09,620] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:25:09,623] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:25:09,624] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run9
[2019-04-16 12:25:09,643] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run9
[2019-04-16 12:26:20,305] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2806.3269 74890.0418 -124.8874
[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,325] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:20,441] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,026] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2468.1990 81430.6792 -597.1341
[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:29,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,486] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2422.7330 84554.8324 -712.6929
[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,504] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:34,611] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:26:35,507] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 400000, evaluation results [400000.0, 2468.1989571455442, 81430.67922349667, -597.1340591035846, 2806.326860633392, 74890.04181356775, -124.88735041211152, 2422.733014618909, 84554.83240225932, -712.6928964710179]
[2019-04-16 12:26:35,840] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.14036417e-01 1.43127504e-03 5.33244420e-05 8.39562708e-05
 1.74162378e-05 1.18809496e-03 2.06933805e-07 4.79802221e-01
 3.37156845e-04 2.94429553e-03 1.05617146e-04], sum to 1.0000
[2019-04-16 12:26:35,841] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8747
[2019-04-16 12:26:35,882] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 18.63960798369851, -1.117559409006287, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4770000.0000, 
sim time next is 4771200.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 18.93692865707656, -0.86774048155662, 0.0, 1.0, 50.0, 84.14738030569653], 
processed observation next is [0.0, 0.21739130434782608, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.07807738808971336, 0.21075317281446002, 0.0, 1.0, 0.7, 0.8414738030569653], 
reward next is 0.1261, 
noisyNet noise sample is [array([0.10932347], dtype=float32), 0.04554068]. 
=============================================
[2019-04-16 12:26:37,161] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.4099604e-01 1.3591934e-05 2.9679813e-07 9.5870121e-07 1.2774060e-08
 2.1505637e-05 2.8740552e-11 3.5892722e-01 3.4850842e-07 3.9725226e-05
 3.6689335e-07], sum to 1.0000
[2019-04-16 12:26:37,162] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7245
[2019-04-16 12:26:37,200] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.266666666666667, 68.0, 0.0, 0.0, 19.0, 23.346167287347, -0.07955400635757238, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4426800.0000, 
sim time next is 4428000.0000, 
raw observation next is [3.0, 68.0, 0.0, 0.0, 19.0, 23.26394902296687, 0.07671133224236613, 0.0, 1.0, 50.0, 65.81665800973504], 
processed observation next is [1.0, 0.2608695652173913, 0.5457063711911359, 0.68, 0.0, 0.0, 0.08333333333333333, 0.4386624185805725, 0.5255704440807887, 0.0, 1.0, 0.7, 0.6581665800973504], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0986665], dtype=float32), -0.7282516]. 
=============================================
[2019-04-16 12:26:38,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6796390e-01 1.5371342e-07 2.2064861e-09 6.9438286e-09 4.0166145e-11
 8.4474522e-07 1.0538825e-13 4.3203306e-01 3.3046753e-08 2.0666193e-06
 2.7183504e-09], sum to 1.0000
[2019-04-16 12:26:38,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0823
[2019-04-16 12:26:38,199] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 23.55715756501558, -0.102604288111989, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4473600.0000, 
sim time next is 4474800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 22.84982993710658, -0.2143606899340733, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.4041524947588817, 0.42854643668864223, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.40491185], dtype=float32), -0.009181766]. 
=============================================
[2019-04-16 12:26:39,810] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4614280e-01 4.8289912e-05 1.2775415e-06 4.4858693e-06 1.6609688e-08
 4.2201875e-05 1.5869689e-10 2.5340298e-01 2.0147986e-06 3.5457665e-04
 1.4554739e-06], sum to 1.0000
[2019-04-16 12:26:39,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6763
[2019-04-16 12:26:39,833] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 38.0, 0.0, 0.0, 19.0, 21.69342947651562, -0.4926368710300786, 0.0, 1.0, 50.0, 54.57174130551316], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4920000.0000, 
sim time next is 4921200.0000, 
raw observation next is [0.0, 39.0, 0.0, 0.0, 19.0, 21.75256892200434, -0.5922734894051465, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.46260387811634357, 0.39, 0.0, 0.0, 0.08333333333333333, 0.31271407683369495, 0.30257550353161783, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.87537557], dtype=float32), 1.4487519]. 
=============================================
[2019-04-16 12:26:42,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5533470e-01 9.6695130e-06 3.0814957e-07 1.1235968e-06 1.6106373e-08
 1.8622677e-05 4.6749493e-11 1.4456655e-01 6.4391190e-07 6.7922178e-05
 4.2887726e-07], sum to 1.0000
[2019-04-16 12:26:42,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7176
[2019-04-16 12:26:42,303] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 132.5, 369.5, 19.0, 21.4919275577941, -0.5909416972786377, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4896000.0000, 
sim time next is 4897200.0000, 
raw observation next is [3.0, 45.0, 112.1666666666667, 334.5, 19.0, 21.24063360036495, -0.6253501048831365, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.373888888888889, 0.3696132596685083, 0.08333333333333333, 0.2700528000304126, 0.29154996503895453, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23896417], dtype=float32), -0.82934314]. 
=============================================
[2019-04-16 12:26:42,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2422148e-01 1.0570881e-05 1.1016555e-07 3.6389997e-07 5.7659291e-09
 9.4417419e-06 2.7498800e-11 4.7572899e-01 6.1803610e-07 2.8187620e-05
 1.7642860e-07], sum to 1.0000
[2019-04-16 12:26:42,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5734
[2019-04-16 12:26:42,981] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-0.9333333333333333, 71.0, 0.0, 0.0, 19.0, 22.41506370439034, -0.2088092804941446, 0.0, 1.0, 50.0, 44.090585171571945], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4513200.0000, 
sim time next is 4514400.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 19.0, 22.71819796144271, -0.1782310287210416, 0.0, 1.0, 50.0, 43.15279925457298], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.71, 0.0, 0.0, 0.08333333333333333, 0.393183163453559, 0.44058965709298614, 0.0, 1.0, 0.7, 0.4315279925457298], 
reward next is 0.0435, 
noisyNet noise sample is [array([-0.29834917], dtype=float32), -0.6122478]. 
=============================================
[2019-04-16 12:26:43,325] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:43,496] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:43,512] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.52757806e-01 3.74092670e-05 2.27203009e-06 1.05569625e-05
 9.31221322e-08 1.13545459e-04 5.98775118e-09 5.46800077e-01
 3.73690978e-06 2.72376725e-04 2.16831290e-06], sum to 1.0000
[2019-04-16 12:26:43,512] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7498
[2019-04-16 12:26:43,554] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 21.26211413226584, -0.469613913440766, 0.0, 1.0, 50.0, 43.85899116331913], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4767600.0000, 
sim time next is 4768800.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 21.55108477176597, -0.4396172272304069, 0.0, 1.0, 50.0, 43.155340228693106], 
processed observation next is [0.0, 0.17391304347826086, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.2959237309804976, 0.35346092425653103, 0.0, 1.0, 0.7, 0.43155340228693106], 
reward next is 0.0434, 
noisyNet noise sample is [array([0.7300401], dtype=float32), 0.5071415]. 
=============================================
[2019-04-16 12:26:43,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6617359e-01 8.7716217e-06 3.6979384e-07 3.0902397e-06 7.4180285e-08
 5.6571418e-05 4.1938331e-10 5.3365266e-01 9.6311544e-07 1.0305246e-04
 7.9784638e-07], sum to 1.0000
[2019-04-16 12:26:43,685] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2384
[2019-04-16 12:26:43,706] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.133333333333333, 46.33333333333334, 281.3333333333334, 376.3333333333333, 19.0, 20.06832832448584, -0.8517580153616766, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4882800.0000, 
sim time next is 4884000.0000, 
raw observation next is [1.266666666666667, 45.66666666666667, 279.5, 389.6666666666666, 19.0, 19.99185286715495, -0.8646664430012424, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4976915974145891, 0.4566666666666667, 0.9316666666666666, 0.4305709023941067, 0.08333333333333333, 0.1659877389295792, 0.2117778523329192, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21057436], dtype=float32), -1.7028652]. 
=============================================
[2019-04-16 12:26:43,930] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:44,104] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:44,255] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.8500313e-01 9.0635190e-08 1.3326416e-10 1.5159688e-09 2.1803744e-12
 1.6219316e-07 1.1585767e-14 2.1499652e-01 4.6883758e-10 6.6676527e-08
 1.0932116e-09], sum to 1.0000
[2019-04-16 12:26:44,255] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9278
[2019-04-16 12:26:44,293] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 86.0, 121.5, 0.0, 22.5, 23.32261619175051, -0.1475369937226829, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4712400.0000, 
sim time next is 4713600.0000, 
raw observation next is [1.333333333333333, 81.66666666666667, 130.5, 0.0, 22.5, 23.42967566332522, 0.08631940911834063, 1.0, 1.0, 50.0, 81.55951989537769], 
processed observation next is [1.0, 0.5652173913043478, 0.4995383194829178, 0.8166666666666668, 0.435, 0.0, 0.375, 0.45247297194376834, 0.5287731363727802, 1.0, 1.0, 0.7, 0.8155951989537769], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49077004], dtype=float32), 2.3248994]. 
=============================================
[2019-04-16 12:26:44,326] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:44,326] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:44,332] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run7
[2019-04-16 12:26:44,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.91506970e-01 7.83133055e-06 9.27241786e-08 1.01817982e-07
 3.59765973e-09 6.59376065e-06 3.78574637e-11 1.08453915e-01
 3.21439302e-07 2.39172241e-05 2.10343543e-07], sum to 1.0000
[2019-04-16 12:26:44,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8094
[2019-04-16 12:26:44,626] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 19.0, 22.0683416652977, -0.3008546512551954, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4579200.0000, 
sim time next is 4580400.0000, 
raw observation next is [0.8, 61.66666666666667, 0.0, 0.0, 19.0, 21.91986228970571, -0.3325669183908236, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4847645429362882, 0.6166666666666667, 0.0, 0.0, 0.08333333333333333, 0.32665519080880906, 0.3891443605363922, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4539621], dtype=float32), -0.10841714]. 
=============================================
[2019-04-16 12:26:44,932] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:44,932] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:44,943] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run7
[2019-04-16 12:26:45,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8039458e-01 4.9135135e-05 3.2147962e-06 6.9380085e-06 3.0316592e-08
 1.1723711e-04 1.4271482e-09 7.1909821e-01 2.9712246e-06 3.2395005e-04
 3.7257055e-06], sum to 1.0000
[2019-04-16 12:26:45,633] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6183
[2019-04-16 12:26:45,664] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 50.0, 0.0, 0.0, 19.0, 21.51536726933644, -0.5927202605828629, 0.0, 1.0, 50.0, 42.36090801979496], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4934400.0000, 
sim time next is 4935600.0000, 
raw observation next is [-1.0, 50.0, 0.0, 0.0, 19.0, 21.59138337749628, -0.5812623794433867, 0.0, 1.0, 50.0, 41.78128011422106], 
processed observation next is [1.0, 0.13043478260869565, 0.4349030470914128, 0.5, 0.0, 0.0, 0.08333333333333333, 0.29928194812468983, 0.3062458735188711, 0.0, 1.0, 0.7, 0.41781280114221064], 
reward next is 0.0572, 
noisyNet noise sample is [array([-1.028886], dtype=float32), 1.1858761]. 
=============================================
[2019-04-16 12:26:46,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5696868e-01 3.6670157e-05 8.6949660e-07 7.5962439e-06 5.1802076e-08
 3.9855696e-04 7.8587864e-10 2.4227029e-01 6.0821899e-06 3.0717603e-04
 3.9287925e-06], sum to 1.0000
[2019-04-16 12:26:46,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2744
[2019-04-16 12:26:46,196] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333334, 36.0, 105.5, 690.8333333333333, 22.5, 20.68074448410082, -0.8251421030201017, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4958400.0000, 
sim time next is 4959600.0000, 
raw observation next is [0.3333333333333333, 33.0, 109.5, 731.3333333333333, 22.5, 20.86801994422603, -0.7764498646700496, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4718374884579871, 0.33, 0.365, 0.8081031307550643, 0.375, 0.2390016620188359, 0.2411833784433168, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.4869, 
noisyNet noise sample is [array([0.05285466], dtype=float32), -1.0071455]. 
=============================================
[2019-04-16 12:26:46,203] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:46,381] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:47,184] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:47,209] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:47,209] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:47,217] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run7
[2019-04-16 12:26:47,339] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:47,385] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:47,569] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:48,186] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:48,186] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:48,192] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run7
[2019-04-16 12:26:48,387] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:48,387] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:48,391] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run7
[2019-04-16 12:26:48,910] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:48,965] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:49,077] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:49,099] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:49,173] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:49,246] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:49,533] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:49,596] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:49,716] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:49,767] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:49,911] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:49,912] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:49,915] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run7
[2019-04-16 12:26:49,969] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:49,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:49,974] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run7
[2019-04-16 12:26:50,081] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:50,081] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:50,098] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run7
[2019-04-16 12:26:50,534] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:50,534] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:50,537] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run7
[2019-04-16 12:26:50,601] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:50,601] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:50,604] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run7
[2019-04-16 12:26:51,690] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:51,750] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.5793453e-01 9.2560640e-06 1.0309270e-06 1.3141469e-06 3.4195349e-08
 4.4803284e-05 2.3998772e-10 5.4173684e-01 1.0005590e-06 2.7053471e-04
 6.9042426e-07], sum to 1.0000
[2019-04-16 12:26:51,751] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7292
[2019-04-16 12:26:51,798] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 19.0, 22.76194556776659, -0.3139763116707622, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 5017200.0000, 
sim time next is 5018400.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 19.0, 22.53752914861497, -0.2262408067241765, 0.0, 1.0, 50.0, 59.226093111524406], 
processed observation next is [1.0, 0.08695652173913043, 0.4903047091412743, 0.4, 0.0, 0.0, 0.08333333333333333, 0.37812742905124735, 0.4245863977586078, 0.0, 1.0, 0.7, 0.592260931115244], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1930273], dtype=float32), -0.2297707]. 
=============================================
[2019-04-16 12:26:51,969] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:52,001] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:52,034] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:52,172] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:52,271] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:52,690] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:52,691] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:52,694] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run7
[2019-04-16 12:26:52,973] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:52,973] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:52,977] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run7
[2019-04-16 12:26:53,062] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:53,062] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:53,105] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run7
[2019-04-16 12:26:54,001] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:54,297] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:54,721] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:54,933] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:55,001] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:55,001] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:55,014] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run7
[2019-04-16 12:26:55,709] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:55,709] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:55,712] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run7
[2019-04-16 12:26:58,913] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:26:59,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-16 12:26:59,914] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:26:59,914] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:26:59,918] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run7
[2019-04-16 12:27:01,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.73126900e-01 1.45886734e-04 5.72791350e-06 1.16561605e-05
 2.94011102e-07 1.87949307e-04 3.28642447e-09 2.25713030e-01
 1.60643758e-05 7.84524833e-04 7.99158897e-06], sum to 1.0000
[2019-04-16 12:27:01,636] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1518
[2019-04-16 12:27:01,648] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.8, 86.0, 0.0, 0.0, 19.0, 18.49957559369204, -1.109431539576309, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 68400.0000, 
sim time next is 69600.0000, 
raw observation next is [3.433333333333334, 87.0, 0.0, 0.0, 19.0, 18.42683544309666, -1.127295124014755, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.5577100646352725, 0.87, 0.0, 0.0, 0.08333333333333333, 0.035569620258055025, 0.12423495866174832, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1670074], dtype=float32), -0.40163088]. 
=============================================
[2019-04-16 12:27:16,479] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9086329e-01 2.6690823e-05 2.6971085e-07 6.6265738e-07 1.9955007e-08
 2.0851860e-05 4.7342491e-11 4.0895930e-01 6.5206973e-07 1.2718710e-04
 1.1269311e-06], sum to 1.0000
[2019-04-16 12:27:16,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2954
[2019-04-16 12:27:16,534] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 63.0, 91.0, 447.5, 22.5, 20.10852276445514, -1.023322575867456, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 295200.0000, 
sim time next is 296400.0000, 
raw observation next is [-11.33333333333333, 62.00000000000001, 88.33333333333333, 490.5, 22.5, 19.94103094365192, -1.0413689453916, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.14866112650046176, 0.6200000000000001, 0.29444444444444445, 0.541988950276243, 0.375, 0.16175257863766004, 0.1528770182028, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17926332], dtype=float32), -0.58873385]. 
=============================================
[2019-04-16 12:27:26,267] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.9825628e-01 3.9465704e-05 1.9049882e-06 2.8501636e-06 5.2242012e-08
 6.6321183e-05 1.0967864e-09 2.0077895e-01 2.6855314e-06 8.4805943e-04
 3.3152398e-06], sum to 1.0000
[2019-04-16 12:27:26,267] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8638
[2019-04-16 12:27:26,319] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [4.766666666666667, 88.66666666666667, 0.0, 0.0, 19.0, 19.21428200682233, -0.941149622940847, 0.0, 1.0, 50.0, 78.11339494075986], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 523200.0000, 
sim time next is 524400.0000, 
raw observation next is [4.533333333333333, 88.33333333333334, 0.0, 0.0, 19.0, 20.12523484782297, -0.8602558246627628, 0.0, 1.0, 50.0, 48.17470246649785], 
processed observation next is [0.0, 0.043478260869565216, 0.5881809787626964, 0.8833333333333334, 0.0, 0.0, 0.08333333333333333, 0.1771029039852475, 0.2132480584457457, 0.0, 1.0, 0.7, 0.4817470246649785], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7238896], dtype=float32), -0.25844824]. 
=============================================
[2019-04-16 12:27:28,380] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0082170e-01 2.0891146e-04 3.5548492e-06 4.9403920e-06 1.2361332e-07
 1.1047774e-04 4.0867567e-09 2.9859266e-01 1.3118987e-05 2.4033937e-04
 4.1877893e-06], sum to 1.0000
[2019-04-16 12:27:28,380] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6176
[2019-04-16 12:27:28,392] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.466666666666667, 75.66666666666667, 0.0, 0.0, 19.0, 17.42515503224019, -1.601862461770183, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 708000.0000, 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 19.0, 17.10884925194834, -1.648995646183218, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.76, 0.0, 0.0, 0.08333333333333333, -0.07426256233763844, -0.04966521539440601, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09208237], dtype=float32), 0.23335014]. 
=============================================
[2019-04-16 12:27:34,987] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.0471363e-01 8.3078070e-05 2.0655966e-06 1.3236009e-05 4.4059878e-08
 4.3373053e-05 8.5429241e-10 5.9448242e-01 2.6582497e-06 6.5759785e-04
 1.9274366e-06], sum to 1.0000
[2019-04-16 12:27:34,988] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5038
[2019-04-16 12:27:35,030] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.2, 75.0, 0.0, 0.0, 19.0, 18.73817757575163, -1.21258640416228, 0.0, 1.0, 50.0, 46.82232946702266], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 703200.0000, 
sim time next is 704400.0000, 
raw observation next is [-3.0, 75.0, 0.0, 0.0, 19.0, 19.10358046938853, -1.187613223157442, 0.0, 1.0, 50.0, 45.48673959834866], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.75, 0.0, 0.0, 0.08333333333333333, 0.09196503911571074, 0.10412892561418596, 0.0, 1.0, 0.7, 0.45486739598348663], 
reward next is 0.0201, 
noisyNet noise sample is [array([0.12028836], dtype=float32), 0.21116862]. 
=============================================
[2019-04-16 12:27:36,296] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.7152685e-01 1.7353017e-06 3.1167612e-08 3.6594670e-07 4.2707204e-10
 8.0557202e-06 7.9554826e-12 3.2841256e-01 6.6748925e-08 5.0321705e-05
 7.9047382e-08], sum to 1.0000
[2019-04-16 12:27:36,296] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5386
[2019-04-16 12:27:36,332] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 19.90607427956518, -0.7594437067994758, 0.0, 1.0, 50.0, 73.93265552889662], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 775200.0000, 
sim time next is 776400.0000, 
raw observation next is [-7.1, 69.66666666666666, 0.0, 0.0, 19.0, 20.38277011008094, -0.8571964620038844, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.2659279778393352, 0.6966666666666665, 0.0, 0.0, 0.08333333333333333, 0.19856417584007838, 0.2142678459987052, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05928306], dtype=float32), 0.4580265]. 
=============================================
[2019-04-16 12:27:38,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6913152e-01 3.4080265e-05 5.1620027e-06 9.7610127e-06 4.9130392e-08
 1.6853002e-04 3.4519565e-09 3.3045170e-01 9.8425335e-06 1.8599576e-04
 3.3061713e-06], sum to 1.0000
[2019-04-16 12:27:38,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0276
[2019-04-16 12:27:38,868] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.533333333333334, 75.0, 26.66666666666667, 0.0, 22.5, 16.86992004995854, -1.606200683099567, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 807600.0000, 
sim time next is 808800.0000, 
raw observation next is [-6.366666666666667, 75.0, 36.83333333333333, 0.0, 22.5, 17.33759443724731, -1.546780857885824, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.28624192059095105, 0.75, 0.12277777777777776, 0.0, 0.375, -0.055200463562724046, -0.01559361929527466, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.5942, 
noisyNet noise sample is [array([0.60325646], dtype=float32), 0.09508245]. 
=============================================
[2019-04-16 12:27:39,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9428406e-01 5.4234391e-08 1.0687653e-09 5.6120553e-09 3.3953320e-12
 2.3607474e-06 5.1647487e-15 4.0571278e-01 2.5392968e-09 7.6422856e-07
 4.8821751e-09], sum to 1.0000
[2019-04-16 12:27:39,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4475
[2019-04-16 12:27:39,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.8, 100.0, 0.0, 0.0, 22.5, 21.49292649726952, -0.4238058076276445, 0.0, 1.0, 50.0, 82.17389810577225], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 934800.0000, 
sim time next is 936000.0000, 
raw observation next is [5.0, 100.0, 0.0, 0.0, 22.5, 21.98034904853097, -0.4976858979591972, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.6011080332409973, 1.0, 0.0, 0.0, 0.375, 0.3316957540442476, 0.3341047006802676, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.1170003], dtype=float32), 0.68733454]. 
=============================================
[2019-04-16 12:27:41,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9812942e-01 1.8231976e-06 1.5080095e-08 4.9021182e-08 2.8904190e-10
 3.4038271e-06 1.5094108e-12 3.0185202e-01 4.5359240e-08 1.3273985e-05
 2.2908816e-08], sum to 1.0000
[2019-04-16 12:27:41,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0426
[2019-04-16 12:27:41,135] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.733333333333333, 85.0, 0.0, 0.0, 22.5, 19.51651242552922, -1.028572887375819, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 847200.0000, 
sim time next is 848400.0000, 
raw observation next is [-3.566666666666666, 84.0, 0.0, 0.0, 22.5, 19.16750552571543, -1.084126495484694, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3638042474607572, 0.84, 0.0, 0.0, 0.375, 0.09729212714295254, 0.13862450150510197, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23460792], dtype=float32), 0.3810508]. 
=============================================
[2019-04-16 12:27:41,481] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6757464e-01 1.3902141e-05 2.3713787e-07 1.5133629e-06 1.5114084e-08
 2.3074743e-05 3.4751851e-11 3.3230659e-01 5.2635926e-07 7.8295627e-05
 1.2743867e-06], sum to 1.0000
[2019-04-16 12:27:41,486] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4969
[2019-04-16 12:27:41,513] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.8, 83.0, 0.0, 0.0, 19.0, 21.32471965221008, -0.579671042327525, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 969600.0000, 
sim time next is 970800.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 19.0, 21.07400023216689, -0.619276475503407, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.08333333333333333, 0.25616668601390735, 0.293574508165531, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3722874], dtype=float32), 0.8022735]. 
=============================================
[2019-04-16 12:27:44,242] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2458053e-01 1.3477226e-06 1.1901529e-08 2.3860617e-08 2.8069196e-11
 9.6278916e-07 1.7938416e-13 2.7541214e-01 3.7422478e-09 4.9808491e-06
 1.6319795e-08], sum to 1.0000
[2019-04-16 12:27:44,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0699
[2019-04-16 12:27:44,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 60.0, 0.0, 0.0, 22.5, 25.7523370074871, 0.6525823572424655, 0.0, 1.0, 50.0, 34.1372950159502], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1108800.0000, 
sim time next is 1110000.0000, 
raw observation next is [13.63333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 25.75513911709923, 0.5563984221246342, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.840258541089566, 0.6066666666666667, 0.0, 0.0, 0.08333333333333333, 0.6462615930916025, 0.6854661407082113, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.37634], dtype=float32), 1.2609729]. 
=============================================
[2019-04-16 12:27:44,267] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[40.984314]
 [40.086502]
 [38.512794]
 [38.028187]
 [38.674164]
 [37.727646]
 [37.942627]
 [38.374207]
 [38.540253]
 [39.854706]
 [38.89296 ]
 [38.998665]
 [39.061176]
 [39.575253]
 [39.675304]
 [40.684334]
 [41.653645]
 [43.104885]
 [44.519375]
 [44.33618 ]
 [44.940228]
 [46.461063]
 [48.058613]
 [48.49874 ]
 [50.064297]], R is [[41.65637207]
 [41.37343597]
 [40.95970154]
 [41.55010605]
 [42.13460541]
 [41.71326065]
 [42.29612732]
 [42.87316513]
 [43.44443512]
 [44.00999069]
 [43.56989288]
 [44.13419342]
 [44.69285202]
 [45.24592209]
 [45.79346466]
 [46.33552933]
 [46.87217331]
 [47.40345383]
 [47.92942047]
 [47.47001648]
 [47.99531555]
 [48.51536179]
 [49.03020859]
 [49.53990555]
 [50.04450607]].
[2019-04-16 12:27:52,294] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3922400e-01 3.6824913e-06 3.3053632e-07 2.7943312e-07 7.8455775e-09
 6.1119695e-06 2.0647586e-10 6.0669579e-02 4.9558372e-07 9.5068222e-05
 3.6637525e-07], sum to 1.0000
[2019-04-16 12:27:52,295] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2253
[2019-04-16 12:27:52,311] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.6, 75.0, 0.0, 0.0, 19.0, 25.00120062168619, 0.591447467461169, 0.0, 0.0, 50.0, 58.293224987706104], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1206000.0000, 
sim time next is 1207200.0000, 
raw observation next is [16.43333333333334, 76.0, 0.0, 0.0, 19.0, 25.46203170578592, 0.5457832715312775, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.9178208679593725, 0.76, 0.0, 0.0, 0.08333333333333333, 0.6218359754821599, 0.6819277571770925, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21478207], dtype=float32), -1.747638]. 
=============================================
[2019-04-16 12:27:54,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7867353e-01 1.6351421e-05 1.9125491e-06 7.8710042e-07 2.4689470e-08
 7.7463454e-05 5.9469030e-10 2.2115321e-01 1.3290714e-06 7.4018353e-05
 1.3391954e-06], sum to 1.0000
[2019-04-16 12:27:54,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8687
[2019-04-16 12:27:54,752] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [16.1, 79.33333333333333, 0.0, 0.0, 19.0, 24.73893585858604, 0.4129106282253889, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1212000.0000, 
sim time next is 1213200.0000, 
raw observation next is [16.1, 80.0, 0.0, 0.0, 19.0, 24.94550983018641, 0.583843416165538, 0.0, 0.0, 50.0, 58.62121100509043], 
processed observation next is [0.0, 0.043478260869565216, 0.9085872576177286, 0.8, 0.0, 0.0, 0.08333333333333333, 0.5787924858488674, 0.6946144720551793, 0.0, 0.0, 0.7, 0.5862121100509043], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4247903], dtype=float32), -0.63633615]. 
=============================================
[2019-04-16 12:27:57,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3394279e-01 1.5368512e-05 2.3913069e-07 2.1941773e-07 6.5625643e-09
 1.2374884e-05 2.1850724e-11 6.5995574e-02 1.1189721e-06 3.1663028e-05
 5.6517678e-07], sum to 1.0000
[2019-04-16 12:27:57,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2540
[2019-04-16 12:27:57,391] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 19.0, 19.89311549515238, -0.8215569586318893, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1489200.0000, 
sim time next is 1490400.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 19.77119572260504, -0.8455970227923459, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.14759964355041996, 0.21813432573588468, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6314672], dtype=float32), 0.36056936]. 
=============================================
[2019-04-16 12:27:58,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8630146e-01 1.6171830e-07 3.2884029e-10 5.9014353e-09 6.3084363e-13
 1.0990349e-07 1.0900587e-15 6.1369681e-01 6.8448019e-10 1.4088954e-06
 3.9230597e-10], sum to 1.0000
[2019-04-16 12:27:58,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9181
[2019-04-16 12:27:58,818] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [10.53333333333333, 59.33333333333334, 76.66666666666666, 669.3333333333333, 22.5, 24.73954564642555, 0.3698740141541899, 1.0, 1.0, 50.0, 52.69975157248497], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1520400.0000, 
sim time next is 1521600.0000, 
raw observation next is [11.06666666666667, 55.66666666666667, 75.33333333333333, 632.1666666666666, 22.5, 25.65857338539596, 0.4948516897148446, 1.0, 1.0, 50.0, 33.868091389842235], 
processed observation next is [1.0, 0.6086956521739131, 0.7691597414589106, 0.5566666666666668, 0.2511111111111111, 0.6985267034990792, 0.375, 0.6382144487829967, 0.6649505632382815, 1.0, 1.0, 0.7, 0.33868091389842236], 
reward next is 0.1363, 
noisyNet noise sample is [array([-0.75468624], dtype=float32), -0.4696339]. 
=============================================
[2019-04-16 12:27:59,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8264136e-01 1.1429205e-05 1.7800474e-07 8.0714108e-07 1.8366380e-09
 1.9806554e-05 1.2577059e-10 4.1727433e-01 7.3598619e-07 5.1138970e-05
 2.3370117e-07], sum to 1.0000
[2019-04-16 12:27:59,744] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8416
[2019-04-16 12:27:59,780] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [18.3, 63.66666666666667, 0.0, 0.0, 19.0, 26.64818757143867, 0.768470536588194, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1186800.0000, 
sim time next is 1188000.0000, 
raw observation next is [18.3, 63.0, 0.0, 0.0, 19.0, 26.52385113054952, 0.8421979789204919, 0.0, 0.0, 50.0, 44.01991906843428], 
processed observation next is [0.0, 0.782608695652174, 0.9695290858725764, 0.63, 0.0, 0.0, 0.08333333333333333, 0.7103209275457933, 0.7807326596401639, 0.0, 0.0, 0.7, 0.44019919068434277], 
reward next is 0.0348, 
noisyNet noise sample is [array([0.12964857], dtype=float32), -0.020032944]. 
=============================================
[2019-04-16 12:28:00,393] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3560777e-01 4.1282991e-08 1.2592583e-10 1.1625134e-09 9.3601316e-12
 2.8774380e-07 1.9094884e-15 1.6439097e-01 6.1578005e-09 8.5129091e-07
 1.0425713e-09], sum to 1.0000
[2019-04-16 12:28:00,394] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2140
[2019-04-16 12:28:00,402] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 90.66666666666666, 0.0, 0.0, 19.0, 23.13724628219522, -0.006873093796566587, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1716000.0000, 
sim time next is 1717200.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 22.87097240839826, -0.05477405879408478, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.4059143673665216, 0.48174198040197175, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24488334], dtype=float32), -1.0728495]. 
=============================================
[2019-04-16 12:28:10,988] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.9301738e-01 1.9937849e-07 1.6836715e-09 4.7419473e-09 9.3477196e-12
 9.8808334e-07 1.3535357e-14 5.0698060e-01 6.8996764e-09 8.3131278e-07
 7.0492732e-09], sum to 1.0000
[2019-04-16 12:28:10,988] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9960
[2019-04-16 12:28:11,096] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.666666666666667, 69.0, 5.999999999999999, 0.0, 22.5, 22.53285646676516, -0.5655710980596961, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2136000.0000, 
sim time next is 2137200.0000, 
raw observation next is [-4.833333333333333, 70.0, 0.0, 0.0, 22.5, 21.86023924429234, -0.4006126022739376, 1.0, 1.0, 50.0, 79.08079677983933], 
processed observation next is [1.0, 0.7391304347826086, 0.3287165281625116, 0.7, 0.0, 0.0, 0.375, 0.3216866036910284, 0.3664624659086875, 1.0, 1.0, 0.7, 0.7908079677983934], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42835462], dtype=float32), 0.8950049]. 
=============================================
[2019-04-16 12:28:12,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8697065e-01 2.8349348e-07 2.9613370e-09 5.7524350e-09 3.8949323e-11
 8.4560810e-07 4.0435215e-14 3.1302521e-01 4.3691685e-08 2.9504631e-06
 8.1715719e-09], sum to 1.0000
[2019-04-16 12:28:12,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9971
[2019-04-16 12:28:12,708] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 22.5, 20.99655283710464, -0.7928904441302302, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2059200.0000, 
sim time next is 2060400.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 19.0, 20.62437366600965, -0.7053513855948307, 0.0, 1.0, 50.0, 67.03752579931162], 
processed observation next is [1.0, 0.8695652173913043, 0.3545706371191136, 0.86, 0.0, 0.0, 0.08333333333333333, 0.21869780550080412, 0.2648828714683898, 0.0, 1.0, 0.7, 0.6703752579931163], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3628082], dtype=float32), 0.21741123]. 
=============================================
[2019-04-16 12:28:14,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8630292e-01 5.1354056e-07 3.3183143e-09 6.6166619e-09 2.1146647e-11
 5.8278738e-07 9.4973596e-14 2.1369494e-01 1.4422900e-08 1.0543118e-06
 2.6025238e-09], sum to 1.0000
[2019-04-16 12:28:14,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5063
[2019-04-16 12:28:14,342] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.633333333333334, 65.0, 227.8333333333333, 5.0, 22.5, 20.97837164304911, -0.9207118828986217, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1945200.0000, 
sim time next is 1946400.0000, 
raw observation next is [-4.266666666666667, 65.0, 212.0, 3.333333333333333, 22.5, 20.39037653793952, -0.9859018737497478, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3444136657433057, 0.65, 0.7066666666666667, 0.0036832412523020255, 0.375, 0.19919804482829337, 0.1713660420834174, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21609558], dtype=float32), -1.607931]. 
=============================================
[2019-04-16 12:28:21,822] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6660249e-01 1.5583741e-05 1.5364114e-07 5.6949375e-07 6.9151929e-09
 6.3635157e-06 7.7164447e-12 3.3334574e-01 4.8826678e-07 2.8410606e-05
 1.5959704e-07], sum to 1.0000
[2019-04-16 12:28:21,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2970
[2019-04-16 12:28:21,847] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 80.0, 0.0, 0.0, 19.0, 19.94294288831702, -0.9971385651379814, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2162400.0000, 
sim time next is 2163600.0000, 
raw observation next is [-7.3, 79.0, 0.0, 0.0, 19.0, 19.50073889378107, -1.081981057777221, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.26038781163434904, 0.79, 0.0, 0.0, 0.08333333333333333, 0.12506157448175573, 0.13933964740759297, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5775849], dtype=float32), -0.07860576]. 
=============================================
[2019-04-16 12:28:27,047] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1795571e-01 1.4020137e-04 6.1844057e-06 3.0254558e-05 7.2139068e-07
 2.3007338e-04 1.8869052e-08 2.8103259e-01 3.9699029e-05 5.4235215e-04
 2.2275446e-05], sum to 1.0000
[2019-04-16 12:28:27,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2761
[2019-04-16 12:28:27,070] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.466666666666667, 63.0, 0.0, 0.0, 19.0, 19.54546961068505, -0.8155989686746904, 0.0, 1.0, 50.0, 77.30987136296912], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2344800.0000, 
sim time next is 2346000.0000, 
raw observation next is [-2.633333333333333, 64.0, 0.0, 0.0, 19.0, 20.09444187190804, -0.9097042912550058, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.38965835641735924, 0.64, 0.0, 0.0, 0.08333333333333333, 0.17453682265900325, 0.1967652362483314, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29177386], dtype=float32), 0.38776326]. 
=============================================
[2019-04-16 12:28:28,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1061422e-01 3.1500356e-05 2.0030920e-07 3.4381395e-07 1.1755995e-08
 1.9501034e-05 4.4836780e-11 4.8923877e-01 1.5841722e-06 9.3654613e-05
 2.6841630e-07], sum to 1.0000
[2019-04-16 12:28:28,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7185
[2019-04-16 12:28:28,173] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 49.33333333333334, 237.8333333333333, 404.3333333333334, 19.0, 20.56866001131836, -0.6806490991591115, 0.0, 1.0, 50.0, 42.38948747259325], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2377200.0000, 
sim time next is 2378400.0000, 
raw observation next is [-0.8, 51.66666666666667, 241.8333333333333, 353.3333333333334, 19.0, 20.96445221308851, -0.6261989831311372, 0.0, 1.0, 50.0, 41.09347423002079], 
processed observation next is [0.0, 0.5217391304347826, 0.4404432132963989, 0.5166666666666667, 0.806111111111111, 0.39042357274401485, 0.08333333333333333, 0.2470376844240425, 0.29126700562295427, 0.0, 1.0, 0.7, 0.4109347423002079], 
reward next is 0.0641, 
noisyNet noise sample is [array([-0.44396362], dtype=float32), -0.18857229]. 
=============================================
[2019-04-16 12:28:30,889] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1128066e-01 9.1819937e-05 3.1637767e-06 8.8290026e-06 2.0893674e-07
 3.3548978e-04 1.1581086e-08 4.8737192e-01 9.2580376e-06 8.9322252e-04
 5.4428569e-06], sum to 1.0000
[2019-04-16 12:28:30,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4566
[2019-04-16 12:28:30,942] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.166666666666667, 32.66666666666666, 86.66666666666667, 831.6666666666667, 19.0, 17.90170576639805, -1.396957485967872, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2461200.0000, 
sim time next is 2462400.0000, 
raw observation next is [-0.6, 31.0, 88.0, 837.0, 19.0, 17.86661877992256, -1.412929371997657, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.44598337950138506, 0.31, 0.29333333333333333, 0.9248618784530387, 0.08333333333333333, -0.01111510167311991, 0.029023542667447666, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88695484], dtype=float32), -1.043977]. 
=============================================
[2019-04-16 12:28:34,327] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.9002481e-01 3.2203932e-06 6.4231543e-08 7.0418913e-08 3.2430718e-09
 1.8107035e-05 1.6821610e-11 5.0994039e-01 1.9072185e-07 1.3030658e-05
 1.2393498e-07], sum to 1.0000
[2019-04-16 12:28:34,331] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2344
[2019-04-16 12:28:34,351] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 48.66666666666667, 147.6666666666667, 56.83333333333332, 19.0, 21.7341618220706, -0.5526381147443847, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2385600.0000, 
sim time next is 2386800.0000, 
raw observation next is [0.0, 47.0, 123.0, 170.5, 19.0, 21.12731448472802, -0.6509368234143738, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.41, 0.18839779005524862, 0.08333333333333333, 0.2606095403940018, 0.2830210588618754, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.07357865], dtype=float32), -0.20944256]. 
=============================================
[2019-04-16 12:28:34,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1495215e-01 2.4720584e-04 4.1950647e-05 3.8744765e-05 1.1822532e-06
 1.2914934e-03 1.2776630e-07 3.8143483e-01 7.8397374e-05 1.8801927e-03
 3.3801454e-05], sum to 1.0000
[2019-04-16 12:28:34,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7492
[2019-04-16 12:28:35,038] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.2, 35.66666666666667, 0.0, 0.0, 19.0, 18.93151997362438, -1.243926187195716, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2496000.0000, 
sim time next is 2497200.0000, 
raw observation next is [-1.2, 34.33333333333334, 0.0, 0.0, 19.0, 19.00646998349089, -1.107619079619035, 0.0, 1.0, 50.0, 66.68982703827292], 
processed observation next is [0.0, 0.9130434782608695, 0.42936288088642666, 0.34333333333333343, 0.0, 0.0, 0.08333333333333333, 0.08387249862424095, 0.13079364012698833, 0.0, 1.0, 0.7, 0.6668982703827292], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25906974], dtype=float32), 0.8743521]. 
=============================================
[2019-04-16 12:28:37,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5108347e-01 1.5667722e-07 6.1221123e-10 1.9266921e-09 6.9541998e-12
 9.7334784e-08 6.8648341e-16 3.4891590e-01 1.8971400e-09 3.9631419e-07
 2.1008348e-10], sum to 1.0000
[2019-04-16 12:28:37,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5729
[2019-04-16 12:28:37,972] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.9, 29.0, 59.5, 135.8333333333333, 22.5, 24.12942667482465, -0.2853280568506137, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2565600.0000, 
sim time next is 2566800.0000, 
raw observation next is [2.7, 29.0, 38.5, 83.5, 22.5, 23.38712870873042, -0.2929502728679213, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5373961218836566, 0.29, 0.12833333333333333, 0.09226519337016574, 0.375, 0.4489273923942016, 0.4023499090440262, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.96477854], dtype=float32), -0.09229409]. 
=============================================
[2019-04-16 12:28:41,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2031019e-01 8.0444792e-08 4.2929427e-10 1.1660638e-09 2.8468751e-12
 5.3966840e-08 6.9304193e-15 3.7968954e-01 1.6222175e-09 9.5219029e-08
 5.3646587e-10], sum to 1.0000
[2019-04-16 12:28:41,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9769
[2019-04-16 12:28:42,000] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 58.0, 0.0, 0.0, 22.5, 22.85415696746595, -0.3416695030643376, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2659200.0000, 
sim time next is 2660400.0000, 
raw observation next is [-1.2, 60.0, 0.0, 0.0, 22.5, 22.56639522046934, -0.2449264047815733, 1.0, 1.0, 50.0, 62.29496766337365], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.6, 0.0, 0.0, 0.375, 0.38053293503911156, 0.41835786507280887, 1.0, 1.0, 0.7, 0.6229496766337365], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5325128], dtype=float32), 0.38087553]. 
=============================================
[2019-04-16 12:28:46,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3650940e-01 1.4576045e-08 2.1585533e-10 6.2276140e-10 2.4998103e-13
 1.6359658e-07 8.0615514e-16 5.6348944e-01 1.8155540e-09 9.8239707e-07
 5.8923527e-10], sum to 1.0000
[2019-04-16 12:28:46,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6296
[2019-04-16 12:28:46,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 50.0, 70.0, 534.0, 22.5, 24.51067600685758, 0.07009146965295536, 1.0, 1.0, 50.0, 64.99049086395081], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2736000.0000, 
sim time next is 2737200.0000, 
raw observation next is [-3.0, 50.0, 59.33333333333333, 480.6666666666667, 22.5, 24.53316294939173, 0.09764310036544076, 1.0, 1.0, 50.0, 57.48707624990834], 
processed observation next is [1.0, 0.6956521739130435, 0.3795013850415513, 0.5, 0.19777777777777777, 0.5311233885819522, 0.375, 0.5444302457826442, 0.5325477001218136, 1.0, 1.0, 0.7, 0.5748707624990834], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48017535], dtype=float32), 0.64665127]. 
=============================================
[2019-04-16 12:28:46,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4532787e-01 1.0364756e-07 6.5669146e-09 4.9154942e-09 1.0919345e-11
 2.1455546e-06 4.1740928e-15 3.5466927e-01 1.2531407e-09 6.2802650e-07
 2.3474709e-09], sum to 1.0000
[2019-04-16 12:28:46,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7235
[2019-04-16 12:28:47,191] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.333333333333334, 55.66666666666667, 0.0, 0.0, 22.5, 22.6466013883683, -0.526591336874664, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2744400.0000, 
sim time next is 2745600.0000, 
raw observation next is [-4.666666666666666, 57.33333333333333, 0.0, 0.0, 22.5, 21.76418001751678, -0.287412552849636, 1.0, 1.0, 50.0, 106.84556248676026], 
processed observation next is [1.0, 0.782608695652174, 0.33333333333333337, 0.5733333333333333, 0.0, 0.0, 0.375, 0.31368166812639825, 0.404195815716788, 1.0, 1.0, 0.7, 1.0684556248676025], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9761581], dtype=float32), -0.43277115]. 
=============================================
[2019-04-16 12:28:48,285] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.4399976e-01 1.4316740e-06 7.8394740e-09 7.0379535e-08 3.4437805e-10
 2.9405558e-06 6.4173757e-12 3.5596737e-01 6.0855456e-08 2.8332595e-05
 9.8815791e-09], sum to 1.0000
[2019-04-16 12:28:48,285] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5869
[2019-04-16 12:28:48,306] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 0.0, 0.0, 19.0, 21.47990411689203, -0.4169169497612666, 0.0, 1.0, 50.0, 75.55893264716175], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2842800.0000, 
sim time next is 2844000.0000, 
raw observation next is [2.0, 44.0, 0.0, 0.0, 19.0, 21.86045308011421, -0.5018150084061158, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.44, 0.0, 0.0, 0.08333333333333333, 0.3217044233428507, 0.33272833053129475, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6836796], dtype=float32), -1.0784676]. 
=============================================
[2019-04-16 12:28:50,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.24223650e-01 8.95998440e-08 4.15663920e-10 2.01648676e-09
 1.38248935e-11 5.77405729e-07 5.53344390e-15 8.75775158e-01
 6.88172319e-09 5.56493319e-07 9.54406776e-10], sum to 1.0000
[2019-04-16 12:28:50,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1938
[2019-04-16 12:28:50,978] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.366666666666667, 59.33333333333334, 212.0, 188.3333333333333, 22.5, 24.07952617111885, -0.03225939690031739, 1.0, 1.0, 50.0, 42.401924956668026], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2632800.0000, 
sim time next is 2634000.0000, 
raw observation next is [-2.833333333333333, 56.66666666666667, 227.5, 167.0, 22.5, 24.18627085222476, -0.008182328378115444, 1.0, 1.0, 50.0, 41.95731590408538], 
processed observation next is [1.0, 0.4782608695652174, 0.3841181902123731, 0.5666666666666668, 0.7583333333333333, 0.18453038674033148, 0.375, 0.5155225710187299, 0.49727255720729485, 1.0, 1.0, 0.7, 0.4195731590408538], 
reward next is 0.0554, 
noisyNet noise sample is [array([-0.83324134], dtype=float32), -0.24246609]. 
=============================================
[2019-04-16 12:28:51,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8028970e-01 8.8072493e-06 1.8226085e-07 1.5906500e-06 7.4478570e-09
 4.2348238e-05 7.8755794e-11 6.1945450e-01 7.9193092e-07 2.0165351e-04
 3.4988227e-07], sum to 1.0000
[2019-04-16 12:28:51,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5276
[2019-04-16 12:28:51,404] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 19.0, 20.95657607319838, -0.695071376887911, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3002400.0000, 
sim time next is 3003600.0000, 
raw observation next is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 20.73935308526979, -0.6128517995369959, 0.0, 1.0, 50.0, 58.09624337144862], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6000000000000001, 0.0, 0.0, 0.08333333333333333, 0.22827942377248256, 0.2957160668210014, 0.0, 1.0, 0.7, 0.5809624337144862], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09814199], dtype=float32), 0.13864915]. 
=============================================
[2019-04-16 12:28:58,303] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5810711e-01 2.5571881e-05 1.1829900e-06 1.4881554e-06 5.7651331e-08
 4.9576687e-05 1.6863756e-09 5.4143113e-01 3.4561338e-06 3.7971584e-04
 7.3808690e-07], sum to 1.0000
[2019-04-16 12:28:58,305] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3164
[2019-04-16 12:28:58,325] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 20.39218772383424, -0.6202871988108677, 0.0, 1.0, 50.0, 64.39903752932155], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2955600.0000, 
sim time next is 2956800.0000, 
raw observation next is [-3.333333333333333, 81.66666666666667, 0.0, 0.0, 19.0, 20.57704112819825, -0.7311118726037832, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.37026777469990774, 0.8166666666666668, 0.0, 0.0, 0.08333333333333333, 0.21475342734985414, 0.2562960424654056, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26791304], dtype=float32), -0.1831887]. 
=============================================
[2019-04-16 12:28:58,827] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-16 12:28:58,833] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:28:58,833] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:28:58,835] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run10
[2019-04-16 12:28:58,848] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:28:58,849] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:28:58,851] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run10
[2019-04-16 12:28:58,866] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:28:58,867] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:28:58,872] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run10
[2019-04-16 12:30:09,269] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2519.0966 91090.2652 264.1808
[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,289] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:09,399] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,795] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2394.8106 98813.1698 -212.7508
[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:17,927] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,048] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2296.8733 100602.7310 -372.5485
[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,067] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:22,179] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:30:23,070] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 450000, evaluation results [450000.0, 2394.8105666644765, 98813.1698374209, -212.75076594347408, 2519.0965590917035, 91090.26522925269, 264.18075708092323, 2296.873292671811, 100602.7310037433, -372.54846436820156]
[2019-04-16 12:30:25,854] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.0958385e-01 9.0143786e-08 1.8152594e-12 2.3156689e-10 3.0239076e-14
 7.6042795e-08 1.0666204e-17 3.9041576e-01 8.4013831e-11 1.2261589e-07
 1.0558014e-10], sum to 1.0000
[2019-04-16 12:30:25,854] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0071
[2019-04-16 12:30:25,873] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 106.5, 784.5, 22.5, 26.66520195731688, 0.6367528359019545, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3160800.0000, 
sim time next is 3162000.0000, 
raw observation next is [7.0, 100.0, 102.8333333333333, 770.1666666666667, 22.5, 25.87436601324014, 0.4974480349373192, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.6565096952908588, 1.0, 0.3427777777777777, 0.8510128913443832, 0.375, 0.6561971677700118, 0.6658160116457731, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.4393687], dtype=float32), 0.58600336]. 
=============================================
[2019-04-16 12:30:29,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7644225e-01 5.4996640e-06 1.5638518e-08 3.9974744e-08 4.1289133e-10
 2.4506646e-06 2.7359321e-12 6.2354469e-01 3.2321083e-08 5.0399117e-06
 1.4199220e-08], sum to 1.0000
[2019-04-16 12:30:29,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6286
[2019-04-16 12:30:29,923] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.666666666666666, 75.0, 0.0, 0.0, 19.0, 22.30291833184062, -0.3558273917538211, 0.0, 1.0, 50.0, 41.33888903584449], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3385200.0000, 
sim time next is 3386400.0000, 
raw observation next is [-5.333333333333333, 73.0, 0.0, 0.0, 19.0, 22.31143262260434, -0.3686713566747133, 0.0, 1.0, 50.0, 41.58050080073434], 
processed observation next is [1.0, 0.17391304347826086, 0.3148661126500462, 0.73, 0.0, 0.0, 0.08333333333333333, 0.35928605188369495, 0.3771095477750956, 0.0, 1.0, 0.7, 0.41580500800734344], 
reward next is 0.0592, 
noisyNet noise sample is [array([0.63510793], dtype=float32), -0.5698469]. 
=============================================
[2019-04-16 12:30:31,286] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9270492e-01 4.8553972e-07 3.4355527e-09 1.1358835e-08 1.0080125e-11
 9.4858211e-07 2.9209756e-13 3.0729303e-01 1.2158506e-08 6.8298920e-07
 4.4130961e-09], sum to 1.0000
[2019-04-16 12:30:31,287] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9440
[2019-04-16 12:30:31,332] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 22.5, 22.15246690984264, -0.2816688004058892, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3355200.0000, 
sim time next is 3356400.0000, 
raw observation next is [-3.333333333333333, 58.33333333333334, 0.0, 0.0, 19.0, 22.36108690641871, -0.08080118290504153, 0.0, 1.0, 50.0, 72.836130840566], 
processed observation next is [1.0, 0.8695652173913043, 0.37026777469990774, 0.5833333333333335, 0.0, 0.0, 0.08333333333333333, 0.3634239088682258, 0.47306627236498616, 0.0, 1.0, 0.7, 0.72836130840566], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2451969], dtype=float32), -0.6342879]. 
=============================================
[2019-04-16 12:30:32,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0584084e-01 4.9934597e-06 8.9155414e-08 2.4559128e-07 2.8753739e-09
 4.4025648e-05 1.5151418e-11 4.9404767e-01 1.2513889e-06 6.0844162e-05
 6.7974220e-08], sum to 1.0000
[2019-04-16 12:30:32,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8133
[2019-04-16 12:30:32,257] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.333333333333334, 67.33333333333334, 0.0, 0.0, 19.0, 21.69354096562406, -0.5967628493712084, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3388800.0000, 
sim time next is 3390000.0000, 
raw observation next is [-3.666666666666667, 63.66666666666667, 0.0, 0.0, 19.0, 21.35969811543495, -0.4931107092919503, 0.0, 1.0, 50.0, 62.79611595257452], 
processed observation next is [1.0, 0.21739130434782608, 0.3610341643582641, 0.6366666666666667, 0.0, 0.0, 0.08333333333333333, 0.27997484295291236, 0.3356297635693499, 0.0, 1.0, 0.7, 0.6279611595257452], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.62609446], dtype=float32), 0.642505]. 
=============================================
[2019-04-16 12:30:32,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[33.738743]
 [33.92319 ]
 [33.486187]
 [31.603405]
 [33.42336 ]
 [31.93148 ]
 [32.880917]
 [33.047066]
 [32.036205]
 [32.86034 ]
 [32.60117 ]
 [34.056316]
 [34.949627]
 [36.637444]
 [36.95168 ]
 [37.644993]
 [37.5116  ]
 [36.992115]
 [38.213352]
 [38.881554]
 [39.388668]
 [39.267597]
 [39.383213]
 [38.566963]
 [37.71845 ]], R is [[34.09659195]
 [34.75562668]
 [34.42590714]
 [34.08164978]
 [34.74083328]
 [34.39342499]
 [35.04949188]
 [34.72101593]
 [34.373806  ]
 [35.03006744]
 [34.67976761]
 [35.33296967]
 [35.97964096]
 [36.61984634]
 [36.25364685]
 [36.89110947]
 [36.53531265]
 [36.16996002]
 [36.80826187]
 [37.44017792]
 [38.06577682]
 [38.68511963]
 [38.32941818]
 [37.96260834]
 [37.58298111]].
[2019-04-16 12:30:33,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2229433e-01 1.4944334e-06 8.3457428e-09 6.0971153e-08 8.4009016e-10
 8.7300805e-07 1.2560337e-12 2.7766180e-01 4.4569436e-08 4.1338037e-05
 3.2038542e-08], sum to 1.0000
[2019-04-16 12:30:33,845] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3139
[2019-04-16 12:30:33,854] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 23.34172570464603, -0.03070372199092806, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3211200.0000, 
sim time next is 3212400.0000, 
raw observation next is [-1.333333333333333, 100.0, 0.0, 0.0, 19.0, 22.87945302547749, -0.1086895678655995, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.42566943674976926, 1.0, 0.0, 0.0, 0.08333333333333333, 0.40662108545645737, 0.46377014404480016, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.18737184], dtype=float32), 1.444992]. 
=============================================
[2019-04-16 12:30:41,265] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.3540968e-01 2.8698747e-07 3.2916081e-09 1.0424340e-08 5.9967101e-12
 4.7402457e-07 1.6097116e-14 8.6458915e-01 1.6956097e-09 4.2709618e-07
 1.1590991e-08], sum to 1.0000
[2019-04-16 12:30:41,266] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1530
[2019-04-16 12:30:41,328] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 71.0, 96.0, 563.5, 22.5, 24.29086371453995, 0.1405810565995076, 1.0, 1.0, 50.0, 40.20283005587008], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3834000.0000, 
sim time next is 3835200.0000, 
raw observation next is [-3.333333333333333, 67.33333333333334, 99.33333333333333, 641.1666666666667, 22.5, 24.58489454758778, 0.204762667151762, 1.0, 1.0, 50.0, 39.33485032266166], 
processed observation next is [1.0, 0.391304347826087, 0.37026777469990774, 0.6733333333333335, 0.3311111111111111, 0.7084714548802947, 0.375, 0.5487412122989817, 0.5682542223839206, 1.0, 1.0, 0.7, 0.3933485032266166], 
reward next is 0.0817, 
noisyNet noise sample is [array([2.3939145], dtype=float32), 0.35993978]. 
=============================================
[2019-04-16 12:30:42,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7432485e-01 2.7388946e-06 4.5827777e-09 4.2057962e-08 1.4895016e-10
 1.2064239e-06 5.0233656e-13 4.2563623e-01 2.4773328e-07 3.4716097e-05
 3.8843286e-08], sum to 1.0000
[2019-04-16 12:30:42,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9797
[2019-04-16 12:30:42,555] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-7.0, 45.0, 0.0, 0.0, 19.0, 22.77906253488769, -0.1416274971928167, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3963600.0000, 
sim time next is 3964800.0000, 
raw observation next is [-7.333333333333334, 46.33333333333334, 0.0, 0.0, 19.0, 22.81385146030777, 0.01423330841962067, 0.0, 1.0, 50.0, 70.19428909890604], 
processed observation next is [1.0, 0.9130434782608695, 0.2594644506001847, 0.46333333333333343, 0.0, 0.0, 0.08333333333333333, 0.40115428835898087, 0.5047444361398735, 0.0, 1.0, 0.7, 0.7019428909890604], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13233867], dtype=float32), -0.33474934]. 
=============================================
[2019-04-16 12:30:43,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5956711e-01 2.9617404e-09 8.5337459e-11 3.2426375e-10 7.0611106e-14
 5.4256393e-08 5.1000267e-16 7.4043214e-01 2.5184277e-10 6.7515282e-07
 3.2996753e-10], sum to 1.0000
[2019-04-16 12:30:43,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6851
[2019-04-16 12:30:43,465] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 48.0, 96.5, 749.5, 22.5, 25.03652787455637, 0.5064102309141834, 1.0, 1.0, 50.0, 49.347838490061605], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3855600.0000, 
sim time next is 3856800.0000, 
raw observation next is [2.333333333333333, 47.0, 90.16666666666666, 727.8333333333333, 22.5, 26.26944358625032, 0.6200773350466203, 1.0, 1.0, 50.0, 35.67666324176016], 
processed observation next is [1.0, 0.6521739130434783, 0.5272391505078486, 0.47, 0.3005555555555555, 0.8042357274401473, 0.375, 0.6891202988541932, 0.7066924450155402, 1.0, 1.0, 0.7, 0.3567666324176016], 
reward next is 0.1182, 
noisyNet noise sample is [array([-0.10799035], dtype=float32), 0.18630938]. 
=============================================
[2019-04-16 12:30:47,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2855003e-01 3.0288702e-06 1.5867420e-07 7.2894130e-07 1.6180947e-09
 1.9601499e-05 4.4399703e-11 4.7139776e-01 1.2574927e-07 2.8385884e-05
 1.2792532e-07], sum to 1.0000
[2019-04-16 12:30:47,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8016
[2019-04-16 12:30:47,211] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 19.0, 22.16306749603019, -0.4044968113951175, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3984000.0000, 
sim time next is 3985200.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 19.0, 21.87927006205989, -0.3048256093566942, 0.0, 1.0, 50.0, 62.44326223661986], 
processed observation next is [1.0, 0.13043478260869565, 0.13019390581717452, 0.63, 0.0, 0.0, 0.08333333333333333, 0.3232725051716576, 0.3983914635477686, 0.0, 1.0, 0.7, 0.6244326223661986], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30216032], dtype=float32), -0.3761845]. 
=============================================
[2019-04-16 12:30:49,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8855023e-01 2.1792350e-05 3.4237896e-06 6.6239422e-06 1.5931752e-07
 6.7746092e-05 8.1256308e-09 3.1082770e-01 8.4887870e-06 5.1231717e-04
 1.5124192e-06], sum to 1.0000
[2019-04-16 12:30:49,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5262
[2019-04-16 12:30:49,993] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 47.66666666666666, 0.0, 0.0, 19.0, 20.97527500829609, -0.5423861365275855, 0.0, 1.0, 50.0, 72.02524691355336], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4254000.0000, 
sim time next is 4255200.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 19.0, 21.48755766518984, -0.6215786324897499, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.08333333333333333, 0.2906298054324867, 0.29280712250341673, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9756761], dtype=float32), -1.7050141]. 
=============================================
[2019-04-16 12:30:51,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0497670e-01 2.8782601e-08 3.2975411e-10 1.0495006e-09 2.0536908e-12
 9.1472664e-08 1.2047566e-15 5.9502292e-01 4.1023535e-10 2.9208149e-07
 1.0226578e-09], sum to 1.0000
[2019-04-16 12:30:51,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8959
[2019-04-16 12:30:52,006] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.666666666666667, 60.00000000000001, 108.5, 759.1666666666667, 22.5, 24.69558280383104, 0.09941002756947152, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3838800.0000, 
sim time next is 3840000.0000, 
raw observation next is [-1.333333333333333, 60.0, 111.1666666666667, 782.8333333333334, 22.5, 24.73670109010212, 0.2338465339799111, 1.0, 1.0, 50.0, 54.262740367121246], 
processed observation next is [1.0, 0.43478260869565216, 0.42566943674976926, 0.6, 0.3705555555555557, 0.8650092081031308, 0.375, 0.56139175750851, 0.5779488446599704, 1.0, 1.0, 0.7, 0.5426274036712124], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45290166], dtype=float32), -1.1107975]. 
=============================================
[2019-04-16 12:30:52,011] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[46.210217]
 [46.001614]
 [44.155018]
 [43.245636]
 [40.90593 ]
 [41.02377 ]
 [40.755936]
 [40.188114]
 [37.943584]
 [37.519268]
 [36.167896]
 [36.62926 ]
 [34.93007 ]
 [34.69451 ]
 [35.133152]
 [33.89389 ]
 [34.27756 ]
 [33.889126]
 [35.208385]
 [35.06919 ]
 [35.085953]
 [33.786144]
 [34.748295]
 [35.955154]
 [37.211575]], R is [[47.27150345]
 [47.79878998]
 [47.32080078]
 [47.8475914 ]
 [47.36911774]
 [47.8954277 ]
 [48.41647339]
 [47.9323082 ]
 [47.45298386]
 [46.97845459]
 [46.50867081]
 [46.05554581]
 [45.59498978]
 [46.1390419 ]
 [46.67765045]
 [46.21087265]
 [46.74876404]
 [46.2812767 ]
 [46.81846619]
 [46.35715485]
 [45.89358521]
 [45.43465042]
 [45.98030472]
 [46.520504  ]
 [47.05529785]].
[2019-04-16 12:30:52,813] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1953285e-01 7.0971088e-05 6.3909346e-07 3.0085041e-06 7.1614707e-08
 4.5147863e-05 6.3520789e-10 2.8012118e-01 3.7398261e-06 2.2128702e-04
 1.1989988e-06], sum to 1.0000
[2019-04-16 12:30:52,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3878
[2019-04-16 12:30:52,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1319711e-01 6.6644810e-09 4.9085014e-11 3.2381656e-10 1.7197174e-14
 3.4503412e-08 3.5125551e-18 6.8680274e-01 2.0894880e-11 7.9582449e-08
 7.3904303e-12], sum to 1.0000
[2019-04-16 12:30:52,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0144
[2019-04-16 12:30:52,827] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 50.0, 0.0, 0.0, 19.0, 22.9916093118247, -0.1635420621408862, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4158000.0000, 
sim time next is 4159200.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 19.0, 22.71819820717931, -0.2142088780503574, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.5, 0.0, 0.0, 0.08333333333333333, 0.3931831839316091, 0.42859704064988086, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8929126], dtype=float32), -1.0890402]. 
=============================================
[2019-04-16 12:30:52,840] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 43.33333333333334, 25.66666666666666, 241.0, 22.5, 27.03450623954372, 0.7520139804480498, 1.0, 1.0, 50.0, 33.597300264245035], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3864000.0000, 
sim time next is 3865200.0000, 
raw observation next is [2.333333333333333, 45.66666666666667, 15.0, 149.1666666666667, 22.5, 26.83795838011783, 0.6621964968176226, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5272391505078486, 0.4566666666666667, 0.05, 0.1648250460405157, 0.375, 0.7364965316764858, 0.7207321656058742, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6637855], dtype=float32), 1.5951885]. 
=============================================
[2019-04-16 12:30:53,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4159766e-01 8.1300641e-05 8.5901011e-06 3.9136485e-06 1.9878122e-07
 6.0196078e-05 3.9592845e-09 4.5801625e-01 2.6305470e-05 2.0271730e-04
 2.8718407e-06], sum to 1.0000
[2019-04-16 12:30:53,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6597
[2019-04-16 12:30:53,649] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 49.0, 0.0, 0.0, 19.0, 20.44964627679116, -0.77670104384618, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4172400.0000, 
sim time next is 4173600.0000, 
raw observation next is [-5.0, 50.66666666666667, 0.0, 0.0, 19.0, 20.70685567245565, -0.5884613750243303, 0.0, 1.0, 50.0, 70.27786779922312], 
processed observation next is [0.0, 0.30434782608695654, 0.32409972299168976, 0.5066666666666667, 0.0, 0.0, 0.08333333333333333, 0.2255713060379708, 0.30384620832522324, 0.0, 1.0, 0.7, 0.7027786779922311], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3054115], dtype=float32), -0.10639996]. 
=============================================
[2019-04-16 12:30:59,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6409570e-01 5.5956512e-08 3.6408834e-11 5.0671090e-10 6.6519197e-13
 7.3764333e-08 2.4251798e-15 3.3590376e-01 1.9333397e-09 4.1106202e-07
 8.3745111e-10], sum to 1.0000
[2019-04-16 12:30:59,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7001
[2019-04-16 12:30:59,830] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 24.41717521238798, 0.05545991771175764, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4473600.0000, 
sim time next is 4474800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 23.7750712374501, 0.2694933403915113, 1.0, 1.0, 50.0, 70.44547539308512], 
processed observation next is [1.0, 0.8260869565217391, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.4812559364541749, 0.5898311134638371, 1.0, 1.0, 0.7, 0.7044547539308512], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28114283], dtype=float32), 0.802225]. 
=============================================
[2019-04-16 12:31:00,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.1114324e-01 9.3017753e-09 2.9700717e-10 4.1443049e-10 5.9641402e-12
 8.9859981e-08 1.8958444e-15 8.8856220e-02 2.3563462e-10 3.8247626e-07
 1.4593714e-09], sum to 1.0000
[2019-04-16 12:31:00,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7315
[2019-04-16 12:31:00,076] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 50.66666666666666, 147.0, 7.999999999999998, 22.5, 23.96756239733477, -0.09954253250880994, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4538400.0000, 
sim time next is 4539600.0000, 
raw observation next is [2.0, 52.0, 187.0, 24.0, 22.5, 22.43667624727349, -0.1832212496685242, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.518005540166205, 0.52, 0.6233333333333333, 0.026519337016574586, 0.375, 0.3697230206061241, 0.43892625011049197, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6660848], dtype=float32), -0.13503338]. 
=============================================
[2019-04-16 12:31:00,911] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2025415e-01 1.8020359e-07 1.0621046e-09 2.6226192e-09 4.6425250e-13
 7.5370615e-08 4.2599883e-15 1.7974262e-01 1.1298134e-09 2.9190282e-06
 2.2335620e-09], sum to 1.0000
[2019-04-16 12:31:00,911] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9525
[2019-04-16 12:31:00,963] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 19.0, 25.09055997655492, 0.4147816924136506, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4653600.0000, 
sim time next is 4654800.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 25.15401387431108, 0.5605692807601909, 0.0, 1.0, 50.0, 58.51835034669432], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.5961678228592566, 0.6868564269200635, 0.0, 1.0, 0.7, 0.5851835034669431], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25094208], dtype=float32), -0.20078056]. 
=============================================
[2019-04-16 12:31:01,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1934565e-01 8.1403719e-08 1.7320575e-09 1.0419437e-08 9.3678659e-12
 1.2975208e-07 4.4538941e-14 1.8064773e-01 8.8006109e-09 6.4231826e-06
 1.8745767e-09], sum to 1.0000
[2019-04-16 12:31:01,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2619
[2019-04-16 12:31:01,259] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 23.21679420980605, -0.1650624210366796, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4558800.0000, 
sim time next is 4560000.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 22.85269572519307, -0.2471581753428642, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.4043913104327557, 0.4176139415523786, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5559156], dtype=float32), -1.259135]. 
=============================================
[2019-04-16 12:31:01,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[43.044853]
 [43.14002 ]
 [43.865467]
 [42.91931 ]
 [44.30994 ]
 [44.45753 ]
 [44.496033]
 [44.288048]
 [44.52772 ]
 [45.123623]
 [45.979523]
 [45.74727 ]
 [45.098225]
 [45.18262 ]
 [44.87875 ]
 [44.42446 ]
 [44.3367  ]
 [43.882683]
 [44.263763]
 [43.18909 ]
 [41.699905]
 [41.5963  ]
 [41.009075]
 [40.863483]
 [38.848907]], R is [[43.19234467]
 [43.76042175]
 [44.32281876]
 [43.8795929 ]
 [44.4407959 ]
 [44.99638748]
 [45.54642487]
 [46.09096146]
 [46.63005066]
 [47.16374969]
 [47.69211197]
 [48.21519089]
 [48.73303986]
 [49.24570847]
 [48.75325012]
 [49.26571655]
 [49.77305984]
 [50.27532959]
 [50.77257538]
 [50.2942543 ]
 [49.79131317]
 [50.29339981]
 [50.79046631]
 [51.28256226]
 [50.76973724]].
[2019-04-16 12:31:05,026] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:05,190] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:05,548] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.1198248e-01 5.0423055e-06 3.0806330e-08 2.0483539e-07 5.2464415e-09
 2.5175309e-06 8.9988208e-12 8.7990053e-02 9.9391151e-08 1.9521554e-05
 5.4082783e-08], sum to 1.0000
[2019-04-16 12:31:05,551] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5657
[2019-04-16 12:31:05,579] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 35.0, 73.83333333333334, 488.3333333333333, 19.0, 21.4774563254763, -0.3072587235186878, 0.0, 1.0, 50.0, 63.74830364625138], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4812000.0000, 
sim time next is 4813200.0000, 
raw observation next is [3.0, 34.0, 57.5, 367.0, 19.0, 22.18898703816776, -0.3588425595399274, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5457063711911359, 0.34, 0.19166666666666668, 0.40552486187845305, 0.08333333333333333, 0.3490822531806466, 0.38038581348669087, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05373193], dtype=float32), 0.97356516]. 
=============================================
[2019-04-16 12:31:06,033] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:06,033] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:06,045] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run8
[2019-04-16 12:31:07,318] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6701343e-01 1.3418730e-06 7.5955349e-09 4.6262553e-08 7.5877699e-10
 2.9614644e-06 1.2313846e-12 2.3294145e-01 8.1949608e-08 4.0671799e-05
 2.1829846e-08], sum to 1.0000
[2019-04-16 12:31:07,319] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9246
[2019-04-16 12:31:07,362] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 45.0, 175.1666666666667, 414.0, 19.0, 22.27589163579367, -0.3806550349141605, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4893600.0000, 
sim time next is 4894800.0000, 
raw observation next is [3.0, 45.0, 152.8333333333333, 404.5, 19.0, 22.23217352902187, -0.2828825081497151, 0.0, 1.0, 50.0, 49.634458877100045], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.45, 0.5094444444444443, 0.44696132596685084, 0.08333333333333333, 0.3526811274184893, 0.40570583061676163, 0.0, 1.0, 0.7, 0.49634458877100046], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16421211], dtype=float32), 1.3390224]. 
=============================================
[2019-04-16 12:31:09,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7720618e-01 1.7329759e-05 1.0990434e-06 1.1010062e-06 3.0462029e-08
 9.1062728e-05 1.7470682e-10 2.2233166e-01 3.3403937e-06 3.4784438e-04
 3.6764081e-07], sum to 1.0000
[2019-04-16 12:31:09,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0100
[2019-04-16 12:31:09,598] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 44.66666666666667, 0.0, 0.0, 19.0, 21.51615485463662, -0.6060797145349329, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4908000.0000, 
sim time next is 4909200.0000, 
raw observation next is [1.0, 42.33333333333333, 0.0, 0.0, 19.0, 21.02533378094622, -0.6851516214967285, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.4903047091412743, 0.4233333333333333, 0.0, 0.0, 0.08333333333333333, 0.25211114841218496, 0.27161612616775715, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42110443], dtype=float32), -0.2935024]. 
=============================================
[2019-04-16 12:31:10,437] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:10,619] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:10,901] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:10,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6010704e-01 1.0761512e-07 3.0237612e-09 8.8548600e-09 7.4098443e-11
 5.9211862e-07 3.0530896e-14 2.3989101e-01 7.6383326e-09 1.2255115e-06
 3.4175986e-09], sum to 1.0000
[2019-04-16 12:31:10,940] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7423
[2019-04-16 12:31:10,970] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 41.0, 114.0, 753.5, 22.5, 25.20344462697843, 0.2366792785412558, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5047200.0000, 
sim time next is 5048400.0000, 
raw observation next is [3.666666666666667, 39.33333333333334, 115.3333333333333, 790.5, 22.5, 25.22332849947962, 0.2424348603390611, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.564173591874423, 0.3933333333333334, 0.3844444444444443, 0.8734806629834254, 0.375, 0.6019440416233017, 0.5808116201130203, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.791926], dtype=float32), -0.87280697]. 
=============================================
[2019-04-16 12:31:11,076] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:11,437] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:11,437] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:11,443] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run8
[2019-04-16 12:31:11,909] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:11,909] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:11,931] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run8
[2019-04-16 12:31:11,993] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:12,167] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:12,195] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:12,381] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:12,646] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:12,820] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:13,002] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:13,002] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:13,009] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run8
[2019-04-16 12:31:13,189] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:13,189] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:13,198] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run8
[2019-04-16 12:31:13,477] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:13,513] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:13,643] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:13,649] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:13,649] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:13,653] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run8
[2019-04-16 12:31:13,693] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:14,344] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:14,466] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:14,466] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:14,470] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run8
[2019-04-16 12:31:14,514] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:14,514] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:14,520] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:14,526] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run8
[2019-04-16 12:31:14,644] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:14,845] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:14,934] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.3993177e-01 2.6600126e-06 6.3115166e-08 3.0109183e-07 1.2164106e-09
 2.0904990e-05 4.0558524e-12 4.6001118e-01 8.5033224e-07 3.2162148e-05
 8.8319887e-08], sum to 1.0000
[2019-04-16 12:31:14,934] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3448
[2019-04-16 12:31:14,947] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 22.28302126011826, -0.2805423686517006, 0.0, 1.0, 50.0, 38.89218592921394], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 24000.0000, 
sim time next is 25200.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 22.20003151767933, -0.3946678640628585, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.3500026264732776, 0.3684440453123805, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2152591], dtype=float32), 0.92643625]. 
=============================================
[2019-04-16 12:31:15,173] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:15,345] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:15,345] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:15,348] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run8
[2019-04-16 12:31:15,376] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:15,653] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:15,653] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:15,656] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run8
[2019-04-16 12:31:15,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:16,169] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:16,169] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:16,174] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run8
[2019-04-16 12:31:16,192] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:16,378] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:16,601] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:16,945] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:16,945] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:16,948] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run8
[2019-04-16 12:31:17,127] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:17,338] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:17,379] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:17,379] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:17,383] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run8
[2019-04-16 12:31:18,128] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:18,128] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:18,132] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run8
[2019-04-16 12:31:19,449] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:19,687] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:20,449] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:20,449] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:20,453] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run8
[2019-04-16 12:31:25,549] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:31:26,002] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-16 12:31:26,534] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:31:26,535] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:31:26,575] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run8
[2019-04-16 12:31:28,376] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.8909032e-01 1.2137068e-07 3.0155389e-10 2.6749386e-10 4.0958689e-13
 8.9971742e-08 9.5740286e-17 5.1090932e-01 8.6251950e-10 1.7533034e-07
 3.9655826e-10], sum to 1.0000
[2019-04-16 12:31:28,376] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4127
[2019-04-16 12:31:28,390] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.866666666666667, 44.33333333333334, 31.66666666666666, 279.5, 22.5, 22.81563216377291, -0.388267382021512, 1.0, 1.0, 50.0, 46.36444620963415], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 318000.0000, 
sim time next is 319200.0000, 
raw observation next is [-10.23333333333333, 46.66666666666666, 20.0, 201.0, 22.5, 22.62447759849394, -0.5416339323672692, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.1791320406278856, 0.46666666666666656, 0.06666666666666667, 0.22209944751381216, 0.375, 0.3853731332078283, 0.31945535587757695, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9567, 
noisyNet noise sample is [array([0.19883855], dtype=float32), -1.4084494]. 
=============================================
[2019-04-16 12:31:31,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0750899e-01 3.8297568e-07 8.9361521e-08 8.7961425e-08 5.7544908e-10
 1.5920018e-06 4.5250422e-12 4.9247992e-01 2.6404425e-07 8.5713955e-06
 4.6463853e-08], sum to 1.0000
[2019-04-16 12:31:31,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6251
[2019-04-16 12:31:31,308] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.733333333333334, 73.0, 0.0, 0.0, 19.0, 19.78681566152918, -0.9940680653111821, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 175200.0000, 
sim time next is 176400.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 19.0, 19.72662882372607, -0.8303526231468444, 0.0, 1.0, 50.0, 74.03464337549292], 
processed observation next is [1.0, 0.043478260869565216, 0.21606648199445982, 0.74, 0.0, 0.0, 0.08333333333333333, 0.14388573531050586, 0.22321579228438518, 0.0, 1.0, 0.7, 0.7403464337549291], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5070499], dtype=float32), 0.9888749]. 
=============================================
[2019-04-16 12:31:32,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3762587e-01 2.7599456e-06 3.5621202e-08 1.8015101e-07 2.0239665e-09
 1.3791348e-05 1.1098024e-12 3.6234149e-01 1.1166996e-07 1.5774851e-05
 3.1757658e-08], sum to 1.0000
[2019-04-16 12:31:32,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7760
[2019-04-16 12:31:32,972] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-9.866666666666667, 69.0, 0.0, 0.0, 19.0, 20.35321343119143, -0.8083699078556982, 0.0, 1.0, 50.0, 48.202585919923905], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 274800.0000, 
sim time next is 276000.0000, 
raw observation next is [-10.23333333333333, 68.0, 0.0, 0.0, 19.0, 20.3781172607409, -0.8120950846449512, 0.0, 1.0, 50.0, 48.163435017562804], 
processed observation next is [1.0, 0.17391304347826086, 0.1791320406278856, 0.68, 0.0, 0.0, 0.08333333333333333, 0.19817643839507504, 0.22930163845168294, 0.0, 1.0, 0.7, 0.48163435017562806], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43043157], dtype=float32), -1.0035475]. 
=============================================
[2019-04-16 12:31:38,219] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.26798499e-01 5.13855457e-06 3.36795090e-08 4.06817691e-08
 1.61868588e-10 7.20065009e-06 1.98860936e-12 1.73187345e-01
 1.13055265e-07 1.63187019e-06 3.03037098e-08], sum to 1.0000
[2019-04-16 12:31:38,219] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6599
[2019-04-16 12:31:38,273] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 42.66666666666667, 80.0, 598.6666666666667, 22.5, 20.02731857858907, -0.9625012709477004, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 312000.0000, 
sim time next is 313200.0000, 
raw observation next is [-9.5, 42.0, 76.0, 550.0, 22.5, 19.67027861452094, -1.019026625118649, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.1994459833795014, 0.42, 0.25333333333333335, 0.6077348066298343, 0.375, 0.13918988454341155, 0.16032445829378364, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80126894], dtype=float32), -0.019497195]. 
=============================================
[2019-04-16 12:31:38,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3294721e-01 6.2711506e-06 1.0420243e-07 4.3553431e-08 1.5215782e-09
 9.8130186e-06 1.6706567e-11 3.6702266e-01 2.1427287e-07 1.3646289e-05
 1.3284244e-07], sum to 1.0000
[2019-04-16 12:31:38,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0742
[2019-04-16 12:31:38,545] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.133333333333334, 74.66666666666667, 0.0, 0.0, 19.0, 19.95736089933096, -0.7443451785732181, 0.0, 1.0, 50.0, 65.3659386064228], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 106800.0000, 
sim time next is 108000.0000, 
raw observation next is [-6.7, 75.0, 0.0, 0.0, 19.0, 20.04435383118896, -0.867594470977814, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2770083102493075, 0.75, 0.0, 0.0, 0.08333333333333333, 0.1703628192657467, 0.21080184300739535, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.65706766], dtype=float32), -0.3430733]. 
=============================================
[2019-04-16 12:31:41,840] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2632108e-01 7.2750190e-05 5.7881789e-06 1.4853193e-05 2.4094905e-07
 2.0439227e-04 2.7976206e-09 3.7292993e-01 2.3583327e-05 4.1600279e-04
 1.1397932e-05], sum to 1.0000
[2019-04-16 12:31:41,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7340
[2019-04-16 12:31:41,920] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.766666666666666, 43.33333333333333, 0.0, 0.0, 19.0, 15.15208326810336, -2.078155984037422, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 456000.0000, 
sim time next is 457200.0000, 
raw observation next is [-8.4, 43.0, 0.0, 0.0, 19.0, 15.33630671872614, -1.851885978122676, 0.0, 1.0, 50.0, 83.73360670806898], 
processed observation next is [1.0, 0.30434782608695654, 0.2299168975069252, 0.43, 0.0, 0.0, 0.08333333333333333, -0.22197444010615497, -0.11729532604089199, 0.0, 1.0, 0.7, 0.8373360670806897], 
reward next is 0.9211, 
noisyNet noise sample is [array([0.8983507], dtype=float32), 1.4594252]. 
=============================================
[2019-04-16 12:31:46,198] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.2266704e-01 3.6328998e-07 7.2263235e-09 1.1274954e-07 2.8269706e-10
 5.4897805e-07 1.2127092e-12 2.7731457e-01 1.2618634e-07 1.7200175e-05
 1.7800888e-08], sum to 1.0000
[2019-04-16 12:31:46,198] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6367
[2019-04-16 12:31:46,244] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.6, 47.66666666666667, 0.0, 0.0, 19.0, 18.60784300401426, -1.157793930988666, 0.0, 1.0, 50.0, 80.07908278127739], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 422400.0000, 
sim time next is 423600.0000, 
raw observation next is [-10.6, 48.33333333333333, 0.0, 0.0, 19.0, 18.98440283667052, -1.275906741719981, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.1689750692520776, 0.4833333333333333, 0.0, 0.0, 0.08333333333333333, 0.08203356972254323, 0.07469775276000634, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.83270824], dtype=float32), 1.5617913]. 
=============================================
[2019-04-16 12:31:46,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7117959e-01 1.2230538e-05 5.7852503e-07 1.0523779e-06 5.8390315e-09
 1.5040964e-05 2.0543807e-10 3.2871699e-01 4.4968172e-07 7.3199059e-05
 8.6290777e-07], sum to 1.0000
[2019-04-16 12:31:46,532] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2029
[2019-04-16 12:31:46,548] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 54.00000000000001, 0.0, 0.0, 19.0, 17.75306136668818, -1.551785641828043, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 429600.0000, 
sim time next is 430800.0000, 
raw observation next is [-11.7, 54.0, 0.0, 0.0, 19.0, 17.00864913425534, -1.681955637547285, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.13850415512465375, 0.54, 0.0, 0.0, 0.08333333333333333, -0.08261257214538838, -0.06065187918242835, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.73782456], dtype=float32), -1.4883821]. 
=============================================
[2019-04-16 12:31:46,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9099039e-01 3.0553572e-05 4.7657531e-07 2.6887053e-06 6.8610864e-09
 4.4613433e-05 4.2887333e-11 3.0884853e-01 3.9284032e-06 7.8113451e-05
 6.6022278e-07], sum to 1.0000
[2019-04-16 12:31:46,590] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0467
[2019-04-16 12:31:46,600] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.533333333333333, 88.33333333333334, 0.0, 0.0, 19.0, 19.50308904623634, -1.089131539654634, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 524400.0000, 
sim time next is 525600.0000, 
raw observation next is [4.3, 88.0, 0.0, 0.0, 19.0, 19.2558537570419, -1.130548140517797, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.5817174515235458, 0.88, 0.0, 0.0, 0.08333333333333333, 0.10465447975349178, 0.12315061982740098, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8022471], dtype=float32), 0.1742456]. 
=============================================
[2019-04-16 12:31:53,660] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4817420e-01 2.1351073e-06 2.2780732e-07 1.6474137e-07 3.8857055e-09
 4.3984164e-06 2.9455220e-11 4.5180425e-01 2.3406344e-07 1.4363997e-05
 4.7251529e-08], sum to 1.0000
[2019-04-16 12:31:53,660] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8096
[2019-04-16 12:31:53,704] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.466666666666667, 87.0, 0.0, 0.0, 19.0, 19.84291783837499, -0.9671857118755162, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 584400.0000, 
sim time next is 585600.0000, 
raw observation next is [-2.633333333333333, 87.0, 0.0, 0.0, 19.0, 19.58805025852934, -0.8371624506322605, 0.0, 1.0, 50.0, 69.39759178164982], 
processed observation next is [0.0, 0.782608695652174, 0.38965835641735924, 0.87, 0.0, 0.0, 0.08333333333333333, 0.1323375215441116, 0.2209458497892465, 0.0, 1.0, 0.7, 0.6939759178164983], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1390202], dtype=float32), 0.72273916]. 
=============================================
[2019-04-16 12:31:56,534] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9632695e-01 8.3722589e-05 5.7246857e-06 1.2173069e-05 2.0714651e-07
 1.3991522e-04 1.4145490e-08 4.0288976e-01 1.7256762e-05 5.1780016e-04
 6.4775963e-06], sum to 1.0000
[2019-04-16 12:31:56,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3235
[2019-04-16 12:31:56,549] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 69.0, 115.6666666666667, 42.5, 19.0, 16.68303453879378, -1.616219184731019, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 638400.0000, 
sim time next is 639600.0000, 
raw observation next is [-3.899999999999999, 67.0, 129.1666666666667, 42.5, 19.0, 16.56125931973737, -1.638915009803185, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.35457063711911363, 0.67, 0.4305555555555557, 0.04696132596685083, 0.08333333333333333, -0.11989505668855245, -0.04630500326772835, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.49414], dtype=float32), -0.8721332]. 
=============================================
[2019-04-16 12:31:58,927] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6076528e-01 3.9401937e-05 8.3186768e-07 1.0409221e-06 7.3402788e-08
 7.0658505e-05 4.0285403e-10 1.3910435e-01 3.0853330e-06 1.3237437e-05
 2.0303967e-06], sum to 1.0000
[2019-04-16 12:31:58,927] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4185
[2019-04-16 12:31:58,950] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 19.0, 18.17207451811424, -1.317826673253392, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 795600.0000, 
sim time next is 796800.0000, 
raw observation next is [-7.300000000000001, 71.0, 0.0, 0.0, 19.0, 17.94496289060461, -1.365159622290993, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.26038781163434904, 0.71, 0.0, 0.0, 0.08333333333333333, -0.0045864257829490995, 0.04494679256966901, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.98272085], dtype=float32), 0.9061364]. 
=============================================
[2019-04-16 12:32:00,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0021231e-01 5.2958267e-08 2.1313644e-09 3.8673238e-09 7.5873644e-13
 1.5110381e-07 6.4013803e-15 4.9978650e-01 3.1388692e-09 1.0852388e-06
 2.1064410e-09], sum to 1.0000
[2019-04-16 12:32:00,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1059
[2019-04-16 12:32:00,482] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.9000000000000001, 92.0, 0.0, 0.0, 22.5, 21.05911935793744, -0.799630519558224, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 499200.0000, 
sim time next is 500400.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 22.5, 20.56953418631274, -0.9024384187750042, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.96, 0.0, 0.0, 0.375, 0.21412784885939504, 0.19918719374166527, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.423141], dtype=float32), -0.14599976]. 
=============================================
[2019-04-16 12:32:02,052] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6856433e-01 7.4128156e-06 4.8270209e-08 3.7814388e-07 1.8534893e-09
 5.0419039e-06 7.0172076e-12 5.3139770e-01 1.4767994e-07 2.4837129e-05
 8.6367642e-08], sum to 1.0000
[2019-04-16 12:32:02,053] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0445
[2019-04-16 12:32:02,107] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.700000000000001, 69.66666666666667, 0.0, 0.0, 22.5, 19.54222300553272, -0.9761213740398395, 1.0, 1.0, 50.0, 59.615233597496854], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 804000.0000, 
sim time next is 805200.0000, 
raw observation next is [-6.700000000000001, 72.33333333333334, 0.0, 0.0, 22.5, 19.77076333852758, -1.098191461712131, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.2770083102493075, 0.7233333333333334, 0.0, 0.0, 0.375, 0.147563611543965, 0.1339361794292897, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00075369], dtype=float32), 0.90371954]. 
=============================================
[2019-04-16 12:32:10,298] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.23311274e-01 3.50825369e-09 1.13162136e-11 2.16245875e-11
 1.89739848e-15 1.54695492e-08 7.30803070e-18 8.76688600e-01
 1.64244070e-11 1.28120973e-07 2.69237735e-12], sum to 1.0000
[2019-04-16 12:32:10,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3202
[2019-04-16 12:32:10,435] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.8, 93.0, 93.0, 0.0, 22.5, 24.48684301958519, 0.01506871830224246, 1.0, 1.0, 50.0, 46.52831402771214], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 914400.0000, 
sim time next is 915600.0000, 
raw observation next is [4.0, 93.0, 91.0, 0.0, 22.5, 24.45185529569548, 0.0811085957601148, 1.0, 1.0, 50.0, 46.51862769238258], 
processed observation next is [1.0, 0.6086956521739131, 0.5734072022160666, 0.93, 0.30333333333333334, 0.0, 0.375, 0.5376546079746234, 0.5270361985867049, 1.0, 1.0, 0.7, 0.4651862769238258], 
reward next is 0.0098, 
noisyNet noise sample is [array([-0.16095303], dtype=float32), 0.54907125]. 
=============================================
[2019-04-16 12:32:11,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6122487e-01 6.8459345e-09 2.5023766e-12 2.7509833e-11 1.2235952e-14
 5.1228100e-10 2.9264027e-18 7.3877501e-01 1.7410436e-11 6.6872623e-08
 1.1939759e-12], sum to 1.0000
[2019-04-16 12:32:11,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2496
[2019-04-16 12:32:11,655] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 19.0, 24.96127806741948, 0.3487686083675916, 0.0, 1.0, 50.0, 33.34276268714008], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1024800.0000, 
sim time next is 1026000.0000, 
raw observation next is [14.4, 77.0, 0.0, 0.0, 19.0, 24.85023015127334, 0.2473322338923753, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.77, 0.0, 0.0, 0.08333333333333333, 0.5708525126061117, 0.5824440779641251, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4380392], dtype=float32), 0.23077376]. 
=============================================
[2019-04-16 12:32:13,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.4026006e-01 2.2165891e-06 1.0471964e-08 3.9209336e-08 2.0067827e-10
 2.1644039e-06 1.2756506e-12 2.5972217e-01 4.7876178e-08 1.3284059e-05
 1.8100524e-08], sum to 1.0000
[2019-04-16 12:32:13,152] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1434
[2019-04-16 12:32:13,174] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.2, 67.0, 106.5, 0.0, 19.0, 24.55687185998066, 0.434499209374388, 0.0, 0.0, 50.0, 58.08187739324839], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1159200.0000, 
sim time next is 1160400.0000, 
raw observation next is [17.56666666666667, 66.33333333333334, 122.1666666666667, 0.0, 19.0, 24.96702708996285, 0.3874872680708943, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.9492151431209604, 0.6633333333333334, 0.4072222222222223, 0.0, 0.08333333333333333, 0.5805855908302376, 0.6291624226902981, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.53341544], dtype=float32), 0.6405423]. 
=============================================
[2019-04-16 12:32:16,993] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.8312570e-01 9.7248960e-07 1.1460700e-09 4.9801248e-09 1.6205252e-11
 8.4275530e-07 1.4818240e-13 7.1685094e-01 1.2271692e-08 2.1645710e-05
 4.5385566e-09], sum to 1.0000
[2019-04-16 12:32:16,993] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3618
[2019-04-16 12:32:17,036] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.67099662103221, -0.3226781124885886, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1382400.0000, 
sim time next is 1383600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 21.89644850766771, -0.08491711399485032, 0.0, 1.0, 50.0, 75.09989395431197], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.3247040423056425, 0.47169429533504986, 0.0, 1.0, 0.7, 0.7509989395431197], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5122017], dtype=float32), -0.38140762]. 
=============================================
[2019-04-16 12:32:18,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0850685e-01 5.4573626e-09 1.4892717e-11 4.4287005e-11 2.9057547e-14
 2.7380135e-08 7.0571625e-18 1.9149294e-01 1.0465098e-10 1.8422861e-07
 2.4218411e-10], sum to 1.0000
[2019-04-16 12:32:18,024] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5501
[2019-04-16 12:32:18,091] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.6, 86.0, 108.0, 0.0, 22.5, 25.34083667057816, 0.3029181958678931, 1.0, 1.0, 50.0, 44.536034754802195], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 990000.0000, 
sim time next is 991200.0000, 
raw observation next is [11.8, 86.0, 116.0, 0.0, 22.5, 25.35091316789059, 0.2308320898364367, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7894736842105264, 0.86, 0.38666666666666666, 0.0, 0.375, 0.6125760973242157, 0.5769440299454789, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1543943], dtype=float32), 1.0564584]. 
=============================================
[2019-04-16 12:32:23,133] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.4918242e-01 5.2166224e-06 1.2050056e-07 2.9494527e-06 7.3765358e-09
 1.1087331e-05 1.3219466e-10 4.5074204e-01 4.6056795e-07 5.5339569e-05
 4.3027245e-07], sum to 1.0000
[2019-04-16 12:32:23,134] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3289
[2019-04-16 12:32:23,199] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 77.0, 124.6666666666667, 58.16666666666666, 19.0, 20.16524620633808, -0.7880730697860977, 0.0, 1.0, 50.0, 67.3916789991208], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1851600.0000, 
sim time next is 1852800.0000, 
raw observation next is [-5.6, 76.0, 130.6666666666667, 56.0, 19.0, 20.24632754017205, -0.9167138974687047, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.76, 0.4355555555555557, 0.061878453038674036, 0.08333333333333333, 0.1871939616810042, 0.1944287008437651, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.783781], dtype=float32), -0.4422186]. 
=============================================
[2019-04-16 12:32:24,136] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.7128320e-01 6.2083693e-08 2.9986488e-10 3.7303699e-10 4.1675905e-13
 9.3883592e-08 1.2637127e-15 5.2871644e-01 2.8908434e-10 2.0162170e-07
 2.1851009e-10], sum to 1.0000
[2019-04-16 12:32:24,137] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6636
[2019-04-16 12:32:24,175] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [7.7, 74.0, 0.0, 0.0, 19.0, 25.81530985566265, 0.6111039602986083, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1544400.0000, 
sim time next is 1545600.0000, 
raw observation next is [7.333333333333334, 74.66666666666667, 0.0, 0.0, 19.0, 25.85026060912366, 0.6813248350009276, 0.0, 1.0, 50.0, 48.395854676566145], 
processed observation next is [1.0, 0.9130434782608695, 0.6657433056325024, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.6541883840936382, 0.7271082783336426, 0.0, 1.0, 0.7, 0.48395854676566147], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9380953], dtype=float32), 0.07041902]. 
=============================================
[2019-04-16 12:32:27,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3421898e-01 1.7738868e-08 4.4729037e-10 9.5759145e-10 1.6822168e-12
 2.2741649e-08 7.0273246e-15 1.6578096e-01 2.4283726e-09 1.0960252e-07
 1.4855270e-10], sum to 1.0000
[2019-04-16 12:32:27,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1465
[2019-04-16 12:32:27,236] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.800000000000001, 94.0, 0.0, 0.0, 19.0, 24.93557995859182, 0.3545738766214048, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1646400.0000, 
sim time next is 1647600.0000, 
raw observation next is [7.0, 95.0, 0.0, 0.0, 19.0, 24.70712683271675, 0.3089782677915699, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6565096952908588, 0.95, 0.0, 0.0, 0.08333333333333333, 0.5589272360597292, 0.6029927559305234, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.125702], dtype=float32), 0.30910432]. 
=============================================
[2019-04-16 12:32:29,986] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-16 12:32:29,987] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:32:29,990] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:32:29,990] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:32:29,991] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:32:29,991] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:32:29,991] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:32:29,993] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run11
[2019-04-16 12:32:29,994] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run11
[2019-04-16 12:32:30,022] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run11
[2019-04-16 12:33:15,679] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([0.03099142], dtype=float32), 0.07394782]
[2019-04-16 12:33:15,680] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation this: [-1.7, 39.33333333333334, 0.0, 0.0, 19.0, 19.69249534547446, -1.114488165715165, 0.0, 1.0, 15.0, 0.0]
[2019-04-16 12:33:15,680] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-16 12:33:15,681] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Softmax [5.3345615e-01 4.0363804e-05 2.2607187e-06 4.9977893e-06 1.2766952e-07
 6.1411425e-05 2.5741886e-09 4.6605659e-01 8.8322504e-06 3.6591943e-04
 3.3098961e-06], sampled 0.3842844899644544
[2019-04-16 12:33:40,835] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2536.6754 91153.5688 249.1892
[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,856] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:40,961] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,435] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2354.3747 99522.7113 -189.3968
[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,455] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:48,571] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,000] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2319.9872 100790.8675 -357.9537
[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,021] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:53,136] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:33:54,024] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 500000, evaluation results [500000.0, 2354.3747472381774, 99522.71127314556, -189.39675065151974, 2536.675435942713, 91153.56880035288, 249.18920797237578, 2319.9871930991576, 100790.86751690986, -357.95368008196095]
[2019-04-16 12:33:54,682] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.87055910e-01 4.81563529e-06 1.14804884e-07 2.93982907e-07
 6.52437304e-09 1.05752033e-05 2.79589095e-11 2.12890789e-01
 4.86721490e-07 3.69362278e-05 8.91366767e-08], sum to 1.0000
[2019-04-16 12:33:54,687] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3224
[2019-04-16 12:33:54,700] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 86.0, 0.0, 0.0, 19.0, 18.91269308803933, -1.22409693728984, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1886400.0000, 
sim time next is 1887600.0000, 
raw observation next is [-5.6, 85.0, 0.0, 0.0, 19.0, 18.48708388913128, -1.316569306893052, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.30747922437673136, 0.85, 0.0, 0.0, 0.08333333333333333, 0.0405903240942734, 0.06114356436898268, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2624245], dtype=float32), 0.31901222]. 
=============================================
[2019-04-16 12:33:56,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4580408e-01 9.4926918e-07 5.5253196e-08 4.8571206e-07 5.9239338e-09
 1.1434892e-05 1.1134149e-11 4.5412678e-01 7.9655472e-08 5.5945653e-05
 1.4359142e-07], sum to 1.0000
[2019-04-16 12:33:56,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3432
[2019-04-16 12:33:56,072] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.4, 78.33333333333334, 0.0, 0.0, 19.0, 20.01094146066104, -0.8415740455219533, 0.0, 1.0, 50.0, 48.971051859626314], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1816800.0000, 
sim time next is 1818000.0000, 
raw observation next is [-5.6, 78.0, 0.0, 0.0, 19.0, 19.92462744799672, -0.993691535846548, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.30747922437673136, 0.78, 0.0, 0.0, 0.08333333333333333, 0.1603856206663933, 0.16876948805115066, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2064732], dtype=float32), -1.2462076]. 
=============================================
[2019-04-16 12:34:13,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7632107e-01 3.3785932e-06 4.2533859e-08 3.9001293e-07 7.5440859e-10
 6.0018469e-06 6.8792797e-12 4.2365319e-01 9.7541317e-07 1.4980361e-05
 7.5276574e-08], sum to 1.0000
[2019-04-16 12:34:13,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9287
[2019-04-16 12:34:13,114] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 20.50927586210213, -0.6754683410627811, 0.0, 1.0, 50.0, 62.973876988463516], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2169600.0000, 
sim time next is 2170800.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 19.0, 20.99009589717662, -0.6353543038025323, 0.0, 1.0, 50.0, 45.05431712298825], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.24917465809805162, 0.28821523206582256, 0.0, 1.0, 0.7, 0.4505431712298825], 
reward next is 0.0245, 
noisyNet noise sample is [array([-1.7971224], dtype=float32), 0.5865097]. 
=============================================
[2019-04-16 12:34:13,239] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9986258e-01 1.4731460e-05 4.6430009e-07 2.0340497e-06 5.7145133e-09
 3.7028705e-05 9.1188598e-11 3.9986527e-01 1.0371170e-06 2.1631771e-04
 5.4524889e-07], sum to 1.0000
[2019-04-16 12:34:13,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4730
[2019-04-16 12:34:13,277] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.2, 86.66666666666667, 0.0, 0.0, 19.0, 19.87394555043498, -1.013127937296544, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2259600.0000, 
sim time next is 2260800.0000, 
raw observation next is [-8.4, 87.0, 0.0, 0.0, 19.0, 19.35249838748803, -1.099775078124052, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.2299168975069252, 0.87, 0.0, 0.0, 0.08333333333333333, 0.11270819895733582, 0.13340830729198264, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1640487], dtype=float32), -0.21525687]. 
=============================================
[2019-04-16 12:34:15,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8903652e-01 2.1731568e-05 6.6134243e-07 3.3038593e-06 1.1957407e-07
 4.0890332e-05 1.9011344e-09 4.1057247e-01 4.3712625e-06 3.1830455e-04
 1.5605910e-06], sum to 1.0000
[2019-04-16 12:34:15,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2845
[2019-04-16 12:34:15,219] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 42.0, 0.0, 0.0, 19.0, 18.67646180988065, -1.217547169148067, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2407200.0000, 
sim time next is 2408400.0000, 
raw observation next is [-3.4, 42.0, 0.0, 0.0, 19.0, 18.49042171173458, -1.24564143436092, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.368421052631579, 0.42, 0.0, 0.0, 0.08333333333333333, 0.04086847597788168, 0.08478618854636004, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13539414], dtype=float32), 1.1001513]. 
=============================================
[2019-04-16 12:34:16,159] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.3827887e-01 1.5108884e-07 5.3517768e-10 9.8950252e-09 3.6110323e-11
 5.4799477e-07 2.5241890e-14 2.6171997e-01 1.5166448e-08 4.3949970e-07
 8.9965582e-09], sum to 1.0000
[2019-04-16 12:34:16,159] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6810
[2019-04-16 12:34:16,239] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 51.0, 0.0, 0.0, 22.5, 22.14511994090745, -0.5849610030235953, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2310000.0000, 
sim time next is 2311200.0000, 
raw observation next is [-1.2, 52.0, 0.0, 0.0, 22.5, 21.67359581225012, -0.6610339360438509, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.52, 0.0, 0.0, 0.375, 0.3061329843541767, 0.2796553546520497, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.3517, 
noisyNet noise sample is [array([-0.43717802], dtype=float32), 0.31598887]. 
=============================================
[2019-04-16 12:34:19,939] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.5043622e-01 5.5901975e-08 2.7433808e-10 1.7732551e-09 2.0002804e-12
 1.5998528e-07 3.3886226e-15 3.4956208e-01 6.3822791e-09 1.5283479e-06
 1.8233920e-09], sum to 1.0000
[2019-04-16 12:34:19,939] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7350
[2019-04-16 12:34:20,004] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.5, 50.0, 63.66666666666666, 117.0, 22.5, 24.2112478175544, -0.05605349520687964, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2652000.0000, 
sim time next is 2653200.0000, 
raw observation next is [0.5, 50.0, 41.0, 103.0, 22.5, 24.17760087037825, -0.05470497816091927, 1.0, 1.0, 50.0, 60.32563251720593], 
processed observation next is [1.0, 0.7391304347826086, 0.4764542936288089, 0.5, 0.13666666666666666, 0.1138121546961326, 0.375, 0.5148000725315208, 0.48176500727969357, 1.0, 1.0, 0.7, 0.6032563251720593], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1409917], dtype=float32), 0.04920111]. 
=============================================
[2019-04-16 12:34:21,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5454748e-01 8.2585774e-07 9.6326023e-09 4.3851919e-08 4.4711037e-11
 1.0569321e-06 7.6285218e-13 8.4543693e-01 1.9999057e-08 1.3574079e-05
 7.8675413e-09], sum to 1.0000
[2019-04-16 12:34:21,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2694
[2019-04-16 12:34:21,479] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.3, 27.0, 70.0, 732.0, 19.0, 21.89431093573603, -0.4786813137087993, 0.0, 1.0, 50.0, 51.21743667568986], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2473200.0000, 
sim time next is 2474400.0000, 
raw observation next is [3.3, 26.66666666666667, 64.66666666666667, 697.3333333333334, 19.0, 22.23142546091064, -0.4279094091022133, 0.0, 1.0, 50.0, 36.83915704412155], 
processed observation next is [0.0, 0.6521739130434783, 0.554016620498615, 0.2666666666666667, 0.21555555555555558, 0.7705340699815838, 0.08333333333333333, 0.35261878840921995, 0.3573635302992622, 0.0, 1.0, 0.7, 0.3683915704412155], 
reward next is 0.1066, 
noisyNet noise sample is [array([0.4435632], dtype=float32), 0.3547703]. 
=============================================
[2019-04-16 12:34:22,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6761958e-01 5.5823079e-05 1.2811409e-05 4.1511816e-05 3.7263260e-07
 3.8296037e-04 1.2606129e-08 7.3148894e-01 1.2787923e-05 3.7536561e-04
 9.7794027e-06], sum to 1.0000
[2019-04-16 12:34:22,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7958
[2019-04-16 12:34:22,274] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 19.0, 18.11407128499318, -1.282235522964723, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2340000.0000, 
sim time next is 2341200.0000, 
raw observation next is [-2.3, 62.0, 0.0, 0.0, 19.0, 18.59442669943067, -1.015963089284533, 0.0, 1.0, 50.0, 82.78977961103949], 
processed observation next is [0.0, 0.08695652173913043, 0.3988919667590028, 0.62, 0.0, 0.0, 0.08333333333333333, 0.04953555828588918, 0.16134563690515566, 0.0, 1.0, 0.7, 0.8278977961103949], 
reward next is 0.8111, 
noisyNet noise sample is [array([-1.429769], dtype=float32), -1.099768]. 
=============================================
[2019-04-16 12:34:22,638] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.4105497e-01 1.9401956e-08 1.7666640e-10 3.9349235e-10 1.8548958e-12
 6.8104377e-08 1.2702413e-15 5.5894482e-01 4.4163379e-10 1.6353509e-07
 3.2788777e-10], sum to 1.0000
[2019-04-16 12:34:22,638] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4849
[2019-04-16 12:34:22,661] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.1, 39.0, 225.0, 46.5, 22.5, 23.68083946678937, -0.1687765068705989, 1.0, 1.0, 50.0, 38.531704674591765], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2548800.0000, 
sim time next is 2550000.0000, 
raw observation next is [1.466666666666667, 36.0, 220.3333333333333, 30.16666666666666, 22.5, 23.87593831351968, -0.1370416816841207, 1.0, 1.0, 50.0, 37.87091842370759], 
processed observation next is [1.0, 0.5217391304347826, 0.5032317636195753, 0.36, 0.7344444444444442, 0.033333333333333326, 0.375, 0.48966152612663993, 0.45431943943862646, 1.0, 1.0, 0.7, 0.37870918423707595], 
reward next is 0.0963, 
noisyNet noise sample is [array([-0.38227278], dtype=float32), 1.677385]. 
=============================================
[2019-04-16 12:34:22,666] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[48.76778 ]
 [48.76582 ]
 [47.38874 ]
 [48.029507]
 [47.09592 ]
 [47.556652]
 [45.27712 ]
 [43.785828]
 [42.577473]
 [42.934845]
 [40.861416]
 [39.420544]
 [38.007534]
 [36.98186 ]
 [36.21423 ]
 [34.702168]
 [35.894936]
 [34.34743 ]
 [35.558247]
 [34.840252]
 [35.02334 ]
 [35.32929 ]
 [36.44887 ]
 [35.54436 ]
 [33.892742]], R is [[48.7382431 ]
 [48.34054565]
 [47.85713959]
 [48.37856674]
 [47.89478302]
 [48.41583633]
 [48.00803757]
 [47.52795792]
 [47.94552612]
 [48.46253967]
 [47.9779129 ]
 [47.66785812]
 [47.84631348]
 [47.83806992]
 [48.35968781]
 [48.876091  ]
 [49.3873291 ]
 [48.89345551]
 [49.40452194]
 [48.91047668]
 [49.42137146]
 [49.92715836]
 [50.42788696]
 [49.98338699]
 [49.53871155]].
[2019-04-16 12:34:28,985] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.0656627e-01 1.2865746e-07 1.7759301e-09 5.6834204e-09 9.6987080e-12
 6.4180043e-08 6.0966606e-14 2.9343209e-01 3.0025822e-09 1.4580962e-06
 1.5826179e-09], sum to 1.0000
[2019-04-16 12:34:28,985] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8459
[2019-04-16 12:34:29,026] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.666666666666667, 70.0, 0.0, 0.0, 19.0, 21.32127752748455, -0.5641976987070217, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2676000.0000, 
sim time next is 2677200.0000, 
raw observation next is [-6.333333333333333, 71.0, 0.0, 0.0, 19.0, 21.30497914479889, -0.422426227222629, 0.0, 1.0, 50.0, 70.08438824454672], 
processed observation next is [1.0, 1.0, 0.28716528162511545, 0.71, 0.0, 0.0, 0.08333333333333333, 0.27541492873324075, 0.359191257592457, 0.0, 1.0, 0.7, 0.7008438824454671], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7742729], dtype=float32), -0.18138652]. 
=============================================
[2019-04-16 12:34:30,729] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5020308e-01 1.1509155e-06 2.3922620e-08 1.0189834e-07 3.1714181e-10
 2.7864787e-06 5.7694100e-13 4.4978571e-01 3.4802163e-08 7.0828896e-06
 2.4503246e-08], sum to 1.0000
[2019-04-16 12:34:30,729] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7200
[2019-04-16 12:34:30,782] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.333333333333334, 70.0, 0.0, 0.0, 19.0, 20.95977899344511, -0.679344588554084, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2680800.0000, 
sim time next is 2682000.0000, 
raw observation next is [-9.0, 69.0, 0.0, 0.0, 19.0, 20.7698358217308, -0.534935544213562, 0.0, 1.0, 50.0, 73.27216720006064], 
processed observation next is [1.0, 0.043478260869565216, 0.21329639889196678, 0.69, 0.0, 0.0, 0.08333333333333333, 0.2308196518109001, 0.32168815192881267, 0.0, 1.0, 0.7, 0.7327216720006063], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4675362], dtype=float32), -0.61976403]. 
=============================================
[2019-04-16 12:34:30,871] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5199599e-01 2.1735282e-06 3.1340647e-08 1.5909431e-07 3.4111030e-09
 5.7729494e-06 2.2496676e-11 4.4793963e-01 4.7796919e-07 5.5698303e-05
 8.6698684e-08], sum to 1.0000
[2019-04-16 12:34:30,872] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9511
[2019-04-16 12:34:30,923] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.566666666666667, 27.0, 79.5, 792.0, 19.0, 20.96104348149808, -0.7621786025055227, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2470800.0000, 
sim time next is 2472000.0000, 
raw observation next is [2.933333333333333, 27.0, 75.33333333333333, 766.6666666666667, 19.0, 20.86628430720386, -0.6577384136958107, 0.0, 1.0, 50.0, 54.485698720777194], 
processed observation next is [0.0, 0.6086956521739131, 0.543859649122807, 0.27, 0.2511111111111111, 0.847145488029466, 0.08333333333333333, 0.2388570256003216, 0.28075386210139647, 0.0, 1.0, 0.7, 0.544856987207772], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5703845], dtype=float32), -1.4745057]. 
=============================================
[2019-04-16 12:34:37,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.33788550e-01 7.58017313e-06 2.08205222e-08 1.05783144e-07
 3.22437455e-09 8.55657800e-06 1.25573614e-11 2.66153485e-01
 3.09195997e-07 4.12873742e-05 9.60470672e-08], sum to 1.0000
[2019-04-16 12:34:37,303] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0529
[2019-04-16 12:34:37,319] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.0, 0.0, 0.0, 19.0, 20.75073663625649, -0.6182514194676679, 0.0, 1.0, 50.0, 64.32952760204057], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3002400.0000, 
sim time next is 3003600.0000, 
raw observation next is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 20.94278642910923, -0.7136884016290392, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6000000000000001, 0.0, 0.0, 0.08333333333333333, 0.24523220242576915, 0.2621038661236536, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.18312293], dtype=float32), 1.4855449]. 
=============================================
[2019-04-16 12:34:39,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9340292e-01 1.7197424e-08 5.6255989e-10 6.8681696e-09 2.4781060e-12
 1.5815212e-07 5.1884262e-15 4.0659672e-01 5.9319678e-09 1.8684486e-07
 3.1852834e-09], sum to 1.0000
[2019-04-16 12:34:39,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6687
[2019-04-16 12:34:39,166] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.110223024625157e-16, 48.0, 133.1666666666667, 720.5, 22.5, 23.74747242848675, -0.2730048817148697, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2805600.0000, 
sim time next is 2806800.0000, 
raw observation next is [0.9999999999999999, 46.0, 133.8333333333333, 750.0, 22.5, 23.50992636411689, -0.0561035683587652, 1.0, 1.0, 50.0, 72.46265695252369], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.46, 0.44611111111111096, 0.8287292817679558, 0.375, 0.45916053034307414, 0.4812988105470783, 1.0, 1.0, 0.7, 0.7246265695252369], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5100734], dtype=float32), -0.18129511]. 
=============================================
[2019-04-16 12:34:40,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7575011e-01 9.6167298e-08 1.0969324e-09 1.0130909e-09 7.0544673e-12
 5.5645825e-07 1.2886301e-13 4.2423767e-01 1.3275574e-08 1.1598543e-05
 1.9549054e-08], sum to 1.0000
[2019-04-16 12:34:40,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9307
[2019-04-16 12:34:40,656] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 72.0, 0.0, 0.0, 19.0, 22.69098758253429, -0.3111409069695136, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2851200.0000, 
sim time next is 2852400.0000, 
raw observation next is [1.0, 72.0, 0.0, 0.0, 19.0, 22.31016149060242, -0.2013388812299454, 0.0, 1.0, 50.0, 74.43408543713846], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.72, 0.0, 0.0, 0.08333333333333333, 0.35918012421686846, 0.4328870395900182, 0.0, 1.0, 0.7, 0.7443408543713846], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0476589], dtype=float32), -0.8069045]. 
=============================================
[2019-04-16 12:34:41,316] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0079238e-01 1.0264215e-07 8.7551122e-09 6.1490773e-08 2.7466101e-11
 6.9613913e-07 4.1023033e-13 4.9919879e-01 3.1212569e-08 7.8968442e-06
 1.7195907e-08], sum to 1.0000
[2019-04-16 12:34:41,316] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4632
[2019-04-16 12:34:41,330] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.7725077122325, -0.3071071031184034, 0.0, 1.0, 50.0, 61.56526978304757], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2940000.0000, 
sim time next is 2941200.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.89420045006659, -0.4152912845175199, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.32451670417221595, 0.3615695718274934, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1137896], dtype=float32), -1.8805239]. 
=============================================
[2019-04-16 12:34:45,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8238577e-01 2.0098184e-07 6.3633867e-09 6.2588432e-09 2.6803495e-11
 9.5412952e-07 1.7390260e-13 7.1761161e-01 2.1233655e-08 1.3067000e-06
 3.9543058e-09], sum to 1.0000
[2019-04-16 12:34:45,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6232
[2019-04-16 12:34:45,534] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 19.0, 21.37939128692033, -0.5730284239839348, 0.0, 1.0, 50.0, 41.5388717024731], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3109200.0000, 
sim time next is 3110400.0000, 
raw observation next is [0.0, 100.0, 0.0, 0.0, 19.0, 21.47812727614246, -0.5593629797747569, 0.0, 1.0, 50.0, 41.09362320496477], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 1.0, 0.0, 0.0, 0.08333333333333333, 0.2898439396785382, 0.3135456734084144, 0.0, 1.0, 0.7, 0.4109362320496477], 
reward next is 0.0641, 
noisyNet noise sample is [array([-1.4840223], dtype=float32), -0.6377742]. 
=============================================
[2019-04-16 12:34:46,739] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [1.3987850e-01 6.4305899e-10 8.5415556e-13 3.5837013e-12 1.1554838e-14
 3.9421508e-10 1.3352225e-18 8.6012143e-01 1.9139385e-11 8.6117344e-09
 2.3216537e-12], sum to 1.0000
[2019-04-16 12:34:46,740] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8896
[2019-04-16 12:34:46,788] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.133333333333333, 74.0, 113.3333333333333, 813.0, 22.5, 26.03364573051004, 0.5858869696161199, 1.0, 1.0, 50.0, 36.209585783771885], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3238800.0000, 
sim time next is 3240000.0000, 
raw observation next is [-2.0, 71.0, 114.0, 817.0, 22.5, 25.87949719735389, 0.5950108053634698, 1.0, 1.0, 50.0, 35.34296122651429], 
processed observation next is [1.0, 0.5217391304347826, 0.40720221606648205, 0.71, 0.38, 0.9027624309392265, 0.375, 0.6566247664461574, 0.6983369351211567, 1.0, 1.0, 0.7, 0.3534296122651429], 
reward next is 0.1216, 
noisyNet noise sample is [array([0.48119482], dtype=float32), 1.5027637]. 
=============================================
[2019-04-16 12:34:46,806] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[56.392357]
 [55.918205]
 [55.350372]
 [54.65396 ]
 [53.899044]
 [52.38643 ]
 [51.16533 ]
 [50.142006]
 [48.26194 ]
 [47.65297 ]
 [46.934383]
 [46.14922 ]
 [44.70739 ]
 [44.34781 ]
 [43.19013 ]
 [41.919834]
 [41.49612 ]
 [41.43069 ]
 [42.371037]
 [41.788544]
 [40.37013 ]
 [41.59846 ]
 [41.208145]
 [39.608974]
 [39.614716]], R is [[56.31915283]
 [55.86886597]
 [55.43137741]
 [54.99023819]
 [54.54976654]
 [54.11010742]
 [53.67078781]
 [53.23147964]
 [52.79006577]
 [52.34959412]
 [51.90641403]
 [51.45658493]
 [51.00776672]
 [50.56033707]
 [50.10709   ]
 [49.65984726]
 [49.21332932]
 [48.72119522]
 [49.23398209]
 [48.7908783 ]
 [48.30297089]
 [48.81994247]
 [48.37556839]
 [47.89181137]
 [48.4128952 ]].
[2019-04-16 12:34:47,505] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.2415291e-01 1.1811949e-10 8.2332958e-14 1.0211739e-12 5.7118920e-16
 2.1570341e-09 2.7993382e-20 5.7584703e-01 1.8695481e-12 1.0748346e-09
 4.1136985e-12], sum to 1.0000
[2019-04-16 12:34:47,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5753
[2019-04-16 12:34:47,537] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [6.866666666666667, 99.66666666666667, 86.83333333333333, 693.0, 22.5, 26.00406009590699, 0.745592325444974, 1.0, 1.0, 50.0, 27.741551826198048], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3165600.0000, 
sim time next is 3166800.0000, 
raw observation next is [6.733333333333333, 99.33333333333334, 79.66666666666666, 649.0, 22.5, 26.97310465399509, 0.8297125862056736, 1.0, 1.0, 50.0, 27.754637979225897], 
processed observation next is [1.0, 0.6521739130434783, 0.649122807017544, 0.9933333333333334, 0.26555555555555554, 0.7171270718232045, 0.375, 0.7477587211662575, 0.7765708620685579, 1.0, 1.0, 0.7, 0.277546379792259], 
reward next is 0.1975, 
noisyNet noise sample is [array([1.5568517], dtype=float32), 1.0276402]. 
=============================================
[2019-04-16 12:34:50,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2819348e-01 1.8432936e-09 9.4264494e-13 3.0555274e-12 4.1275670e-15
 1.9142295e-10 6.8731066e-18 5.7180655e-01 1.2053285e-11 2.5198647e-08
 1.5957588e-12], sum to 1.0000
[2019-04-16 12:34:50,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9159
[2019-04-16 12:34:50,966] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 19.0, 25.02158533032255, 0.5475234654991973, 0.0, 1.0, 50.0, 51.881026076146675], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3184800.0000, 
sim time next is 3186000.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 19.0, 25.31858047642795, 0.5758361221258327, 0.0, 1.0, 50.0, 34.59655436576675], 
processed observation next is [1.0, 0.9130434782608695, 0.5457063711911359, 1.0, 0.0, 0.0, 0.08333333333333333, 0.6098817063689959, 0.6919453740419442, 0.0, 1.0, 0.7, 0.3459655436576675], 
reward next is 0.1290, 
noisyNet noise sample is [array([0.9541597], dtype=float32), -0.2236694]. 
=============================================
[2019-04-16 12:34:52,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7077118e-01 4.1406309e-10 4.0716610e-12 1.1026454e-11 2.8908076e-14
 8.3470804e-09 2.6921720e-17 8.2922882e-01 7.0008013e-11 1.1562323e-08
 9.9770114e-12], sum to 1.0000
[2019-04-16 12:34:52,850] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5225
[2019-04-16 12:34:52,886] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 47.66666666666666, 116.3333333333333, 815.1666666666667, 22.5, 25.13276091631047, 0.3656233618489703, 1.0, 1.0, 50.0, 45.29739158523353], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3415200.0000, 
sim time next is 3416400.0000, 
raw observation next is [3.0, 49.0, 115.0, 811.5, 22.5, 25.53395163039906, 0.3999531238091121, 1.0, 1.0, 50.0, 50.21909155125586], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.38333333333333336, 0.8966850828729281, 0.375, 0.627829302533255, 0.6333177079363707, 1.0, 1.0, 0.7, 0.5021909155125586], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.56930923], dtype=float32), -1.0559506]. 
=============================================
[2019-04-16 12:34:53,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9846759e-01 1.9710919e-08 2.8583075e-10 7.2966055e-10 1.2593206e-12
 1.3922943e-07 9.3384603e-15 4.0153012e-01 7.4919448e-09 2.1994722e-06
 1.1643475e-09], sum to 1.0000
[2019-04-16 12:34:53,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2056
[2019-04-16 12:34:53,384] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 79.33333333333334, 0.0, 0.0, 19.0, 22.3226407406135, -0.1378362832577306, 0.0, 1.0, 50.0, 61.197661626060615], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3284400.0000, 
sim time next is 3285600.0000, 
raw observation next is [-7.0, 74.66666666666667, 0.0, 0.0, 19.0, 22.39981570062719, -0.241407458011903, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.3666513083855992, 0.4195308473293657, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06636802], dtype=float32), 2.1816587]. 
=============================================
[2019-04-16 12:34:56,351] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.90127206e-01 2.97515794e-06 2.02626623e-07 3.50355577e-07
 1.65965663e-09 2.66083998e-06 4.69071240e-11 5.09777069e-01
 3.50159468e-07 8.90072988e-05 1.00564336e-07], sum to 1.0000
[2019-04-16 12:34:56,354] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7789
[2019-04-16 12:34:56,391] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 19.0, 21.61211861887769, -0.355906001788834, 0.0, 1.0, 50.0, 67.0416870695294], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3628800.0000, 
sim time next is 3630000.0000, 
raw observation next is [9.0, 25.0, 0.0, 0.0, 19.0, 22.49746720242895, -0.2632153563026664, 0.0, 1.0, 50.0, 42.40394679164045], 
processed observation next is [0.0, 0.0, 0.7119113573407203, 0.25, 0.0, 0.0, 0.08333333333333333, 0.3747889335357459, 0.4122615478991112, 0.0, 1.0, 0.7, 0.4240394679164045], 
reward next is 0.0510, 
noisyNet noise sample is [array([0.34788692], dtype=float32), -1.2565441]. 
=============================================
[2019-04-16 12:34:56,400] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[33.092606]
 [32.18649 ]
 [32.258823]
 [32.210457]
 [32.287186]
 [32.408596]
 [31.01894 ]
 [31.846918]
 [32.5621  ]
 [33.77786 ]
 [33.580822]
 [33.892826]
 [35.240215]
 [36.52152 ]
 [37.982807]
 [37.75343 ]
 [39.339226]
 [38.76472 ]
 [39.078438]
 [38.965893]
 [40.296165]
 [40.274616]
 [39.482296]
 [38.64227 ]
 [37.873505]], R is [[32.91384888]
 [32.58470917]
 [33.25886154]
 [33.92627335]
 [34.58700943]
 [34.28806686]
 [33.94518661]
 [34.60573578]
 [35.25967789]
 [35.9070816 ]
 [36.54801178]
 [37.18253326]
 [37.81070709]
 [38.43260193]
 [39.04827499]
 [38.65779114]
 [39.27121353]
 [38.98613358]
 [38.70071793]
 [38.31370926]
 [38.93057251]
 [39.5412674 ]
 [39.26205444]
 [38.98112488]
 [38.69622803]].
[2019-04-16 12:35:00,280] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6934454e-01 3.0185316e-05 6.6541429e-07 4.3185759e-07 1.7998648e-08
 1.5941654e-05 3.1367875e-10 3.3053404e-01 2.6562002e-06 7.0030728e-05
 1.5544539e-06], sum to 1.0000
[2019-04-16 12:35:00,281] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4431
[2019-04-16 12:35:00,295] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.33333333333333, 65.0, 0.0, 0.0, 19.0, 20.00648397691047, -0.6594665847736533, 0.0, 1.0, 50.0, 84.83536887855246], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3990000.0000, 
sim time next is 3991200.0000, 
raw observation next is [-12.66666666666667, 67.0, 0.0, 0.0, 19.0, 20.48193012410176, -0.7781999344735735, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.11172668513388727, 0.67, 0.0, 0.0, 0.08333333333333333, 0.2068275103418132, 0.24060002184214216, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46301734], dtype=float32), 0.0903797]. 
=============================================
[2019-04-16 12:35:03,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.35764515e-01 9.87065629e-09 6.84557411e-11 1.01438066e-10
 1.10396643e-13 3.06629744e-08 2.67544594e-16 4.64235425e-01
 3.45339785e-10 8.32675795e-08 1.34194059e-10], sum to 1.0000
[2019-04-16 12:35:03,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8432
[2019-04-16 12:35:03,540] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.666666666666667, 40.0, 15.83333333333333, 140.8333333333333, 22.5, 25.34500897780386, 0.3557980321603081, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3951600.0000, 
sim time next is 3952800.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 22.5, 25.10961408250186, 0.4093357032548133, 1.0, 1.0, 50.0, 52.50194223556986], 
processed observation next is [1.0, 0.782608695652174, 0.296398891966759, 0.41, 0.0, 0.0, 0.375, 0.5924678402084883, 0.636445234418271, 1.0, 1.0, 0.7, 0.5250194223556985], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57878596], dtype=float32), 0.08110807]. 
=============================================
[2019-04-16 12:35:04,181] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9799389e-01 1.3807112e-07 5.7242117e-10 2.9618377e-09 2.3992243e-12
 1.4090985e-07 2.7784347e-15 5.0200504e-01 2.9526999e-09 7.8791925e-07
 6.4599937e-11], sum to 1.0000
[2019-04-16 12:35:04,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0205
[2019-04-16 12:35:04,195] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 56.66666666666667, 0.0, 0.0, 19.0, 23.97005029732821, 0.08313619266413863, 0.0, 1.0, 50.0, 40.56221686459827], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3882000.0000, 
sim time next is 3883200.0000, 
raw observation next is [-1.0, 58.33333333333334, 0.0, 0.0, 19.0, 23.76595315988736, -0.06780618463964438, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.5833333333333335, 0.0, 0.0, 0.08333333333333333, 0.48049609665728, 0.47739793845345185, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.70899165], dtype=float32), 0.9099506]. 
=============================================
[2019-04-16 12:35:06,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9648858e-01 2.7260745e-05 2.2258941e-06 3.7000807e-06 1.6631120e-07
 1.0569212e-04 1.6734740e-09 2.0317043e-01 1.8258511e-06 1.9902141e-04
 1.0648369e-06], sum to 1.0000
[2019-04-16 12:35:06,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2929
[2019-04-16 12:35:06,299] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 45.0, 100.0, 574.0, 19.0, 20.79788283272189, -0.5968340678017251, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4179600.0000, 
sim time next is 4180800.0000, 
raw observation next is [-3.333333333333333, 41.66666666666667, 105.3333333333333, 631.3333333333333, 19.0, 20.73821127490595, -0.5939002655140807, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.37026777469990774, 0.41666666666666674, 0.351111111111111, 0.6976058931860036, 0.08333333333333333, 0.22818427290882917, 0.30203324482863975, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9053416], dtype=float32), 0.05575128]. 
=============================================
[2019-04-16 12:35:06,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5286801e-01 1.5500316e-06 1.3333529e-08 1.5276473e-08 3.8528269e-10
 1.3391116e-06 1.8518160e-12 4.4712195e-01 8.4612260e-08 7.0536389e-06
 3.0914702e-08], sum to 1.0000
[2019-04-16 12:35:06,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8479
[2019-04-16 12:35:06,866] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.666666666666667, 39.33333333333333, 144.6666666666667, 540.0, 19.0, 22.84138922856706, -0.07852766834816412, 0.0, 1.0, 50.0, 55.654550191231706], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4203600.0000, 
sim time next is 4204800.0000, 
raw observation next is [3.0, 37.0, 114.0, 544.0, 19.0, 23.37280125808954, -0.005685021353759099, 0.0, 1.0, 50.0, 38.81660299697854], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.37, 0.38, 0.6011049723756906, 0.08333333333333333, 0.4477334381741285, 0.49810499288208027, 0.0, 1.0, 0.7, 0.3881660299697854], 
reward next is 0.0868, 
noisyNet noise sample is [array([-1.5990882], dtype=float32), -0.45105028]. 
=============================================
[2019-04-16 12:35:07,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.8407926e-02 7.8738172e-10 4.4638848e-13 4.9605064e-12 2.5923115e-15
 8.7593719e-09 9.1527028e-19 9.1159207e-01 4.8087152e-11 6.4579062e-09
 2.7044083e-12], sum to 1.0000
[2019-04-16 12:35:07,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0140
[2019-04-16 12:35:07,405] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 75.5, 634.0, 22.5, 26.39656789237522, 0.7315898755798749, 1.0, 1.0, 50.0, 45.78367298020926], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3859200.0000, 
sim time next is 3860400.0000, 
raw observation next is [3.0, 43.66666666666667, 67.83333333333333, 578.6666666666666, 22.5, 26.95459245452772, 0.7060789334856966, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.4366666666666667, 0.2261111111111111, 0.6394106813996316, 0.375, 0.7462160378773101, 0.7353596444952322, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32559782], dtype=float32), 0.76585996]. 
=============================================
[2019-04-16 12:35:07,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9257106e-01 2.0683075e-05 5.4647569e-07 7.7667931e-07 6.6719345e-08
 2.7430899e-05 5.9927469e-10 5.0732708e-01 1.2791338e-06 4.9831408e-05
 1.2244451e-06], sum to 1.0000
[2019-04-16 12:35:07,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7656
[2019-04-16 12:35:07,487] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [9.0, 27.0, 0.0, 0.0, 19.0, 22.38725595156284, -0.2196926861702625, 0.0, 1.0, 50.0, 64.03434075179847], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3646800.0000, 
sim time next is 3648000.0000, 
raw observation next is [9.333333333333334, 26.33333333333334, 0.0, 0.0, 19.0, 23.12256000238587, -0.1463503009885478, 0.0, 1.0, 50.0, 40.04609282181142], 
processed observation next is [0.0, 0.21739130434782608, 0.7211449676823639, 0.2633333333333334, 0.0, 0.0, 0.08333333333333333, 0.4268800001988226, 0.45121656633715074, 0.0, 1.0, 0.7, 0.4004609282181142], 
reward next is 0.0745, 
noisyNet noise sample is [array([0.3564477], dtype=float32), -0.83360964]. 
=============================================
[2019-04-16 12:35:08,669] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3075620e-01 3.2414103e-08 9.4447165e-11 8.7178453e-10 1.0402661e-12
 1.0177364e-07 1.4926895e-16 3.6924306e-01 5.9512367e-10 5.1663721e-07
 5.3340138e-10], sum to 1.0000
[2019-04-16 12:35:08,669] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2109
[2019-04-16 12:35:08,700] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333334, 57.00000000000001, 117.0, 832.8333333333334, 22.5, 25.01414759475698, 0.2496767800442481, 1.0, 1.0, 50.0, 40.026716932768], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3846000.0000, 
sim time next is 3847200.0000, 
raw observation next is [0.3333333333333333, 54.0, 116.3333333333333, 833.1666666666667, 22.5, 24.48135361197852, 0.09176920231945983, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4718374884579871, 0.54, 0.38777777777777767, 0.9206261510128915, 0.375, 0.54011280099821, 0.5305897341064866, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8595708], dtype=float32), 0.8907339]. 
=============================================
[2019-04-16 12:35:11,498] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.6847025e-01 9.0617974e-08 1.8758546e-09 5.9064140e-09 5.8199418e-11
 1.1203948e-06 2.8277228e-14 6.3152784e-01 3.0100875e-08 7.0191595e-07
 1.2551237e-08], sum to 1.0000
[2019-04-16 12:35:11,499] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7096
[2019-04-16 12:35:11,524] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [6.1, 66.0, 0.0, 0.0, 19.0, 24.70805956072738, 0.3309795704901227, 0.0, 1.0, 50.0, 39.7206446679944], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4413600.0000, 
sim time next is 4414800.0000, 
raw observation next is [5.733333333333334, 66.33333333333334, 0.0, 0.0, 19.0, 24.99621666427329, 0.3585836092619191, 0.0, 1.0, 50.0, 38.86971811198106], 
processed observation next is [1.0, 0.08695652173913043, 0.6214219759926132, 0.6633333333333334, 0.0, 0.0, 0.08333333333333333, 0.5830180553561076, 0.619527869753973, 0.0, 1.0, 0.7, 0.38869718111981055], 
reward next is 0.0863, 
noisyNet noise sample is [array([1.0634062], dtype=float32), 0.625922]. 
=============================================
[2019-04-16 12:35:12,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6664658e-01 3.5563158e-07 1.7373286e-09 3.2159456e-08 1.9728678e-10
 7.1286200e-07 1.1348745e-12 4.3334490e-01 4.1170168e-08 7.3873593e-06
 1.6101726e-08], sum to 1.0000
[2019-04-16 12:35:12,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2511
[2019-04-16 12:35:12,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 19.0, 23.54521666194471, -0.04828550045566941, 0.0, 1.0, 50.0, 38.83006722845387], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4219200.0000, 
sim time next is 4220400.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 19.0, 23.49643923480767, -0.1726135449616287, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.08333333333333333, 0.45803660290063924, 0.4424621516794571, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8472213], dtype=float32), -0.7049943]. 
=============================================
[2019-04-16 12:35:13,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0524902e-01 2.3324271e-08 2.5944352e-10 1.1854653e-10 3.5653061e-13
 9.3954826e-09 2.6115662e-16 4.9475089e-01 1.6137301e-09 5.2852993e-08
 4.3595027e-11], sum to 1.0000
[2019-04-16 12:35:13,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2135
[2019-04-16 12:35:13,938] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 41.0, 0.0, 0.0, 22.5, 26.9223831955894, 0.8056003210611565, 0.0, 1.0, 50.0, 33.98571256089971], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4131600.0000, 
sim time next is 4132800.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 22.5, 26.81102878188849, 0.6987087153007447, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.375, 0.7342523984907073, 0.7329029051002482, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8099034], dtype=float32), 0.50851285]. 
=============================================
[2019-04-16 12:35:14,706] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.0349251e-01 6.9898317e-07 1.5183944e-07 5.3774112e-08 2.6914992e-09
 3.4977372e-06 6.9476660e-12 5.9648651e-01 2.7076234e-07 1.6238004e-05
 2.8555947e-08], sum to 1.0000
[2019-04-16 12:35:14,707] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5756
[2019-04-16 12:35:14,740] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 49.0, 0.0, 0.0, 19.0, 22.92107877866469, -0.1761517397128218, 0.0, 1.0, 50.0, 55.35542970308256], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4256400.0000, 
sim time next is 4257600.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 19.0, 23.14716606571352, -0.146397545429925, 0.0, 1.0, 50.0, 39.83636588640626], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.08333333333333333, 0.4289305054761267, 0.45120081819002494, 0.0, 1.0, 0.7, 0.3983636588640626], 
reward next is 0.0766, 
noisyNet noise sample is [array([0.20677166], dtype=float32), -0.21008825]. 
=============================================
[2019-04-16 12:35:15,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3906717e-01 3.5913104e-06 1.5339202e-07 1.2043024e-07 2.9298604e-09
 1.4565087e-05 1.0447347e-11 3.6086676e-01 1.5762348e-07 4.7393391e-05
 5.0168627e-08], sum to 1.0000
[2019-04-16 12:35:15,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0386
[2019-04-16 12:35:15,986] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 19.0, 23.64161629598132, -0.05865276115622788, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4219200.0000, 
sim time next is 4220400.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 19.0, 23.353988182535, -0.1498198878913879, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.08333333333333333, 0.4461656818779168, 0.45006003736953737, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27850112], dtype=float32), -1.8777401]. 
=============================================
[2019-04-16 12:35:16,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7570351e-01 1.2291527e-09 2.5153568e-12 8.9647838e-12 1.9998919e-14
 8.0007901e-08 2.3736950e-17 6.2429637e-01 4.3888504e-11 7.6098488e-09
 1.5736447e-11], sum to 1.0000
[2019-04-16 12:35:16,565] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6643
[2019-04-16 12:35:16,618] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 78.0, 60.0, 0.0, 22.5, 26.51741987326837, 0.7889320021047405, 1.0, 1.0, 50.0, 39.86750228463667], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4464000.0000, 
sim time next is 4465200.0000, 
raw observation next is [0.0, 78.0, 52.66666666666666, 0.0, 22.5, 27.03212090236289, 0.8126649918824415, 1.0, 1.0, 50.0, 41.80646400092933], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.78, 0.17555555555555552, 0.0, 0.375, 0.7526767418635743, 0.7708883306274804, 1.0, 1.0, 0.7, 0.41806464000929333], 
reward next is 0.0569, 
noisyNet noise sample is [array([-1.6465677], dtype=float32), -0.38662943]. 
=============================================
[2019-04-16 12:35:18,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2680947e-01 3.2505554e-08 5.1569482e-12 4.0803246e-11 3.2138417e-13
 2.4854513e-08 4.8260311e-16 1.7319022e-01 1.8859170e-10 3.3434799e-07
 9.6409228e-11], sum to 1.0000
[2019-04-16 12:35:18,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2905
[2019-04-16 12:35:18,914] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 208.5, 62.5, 22.5, 25.55599713520291, 0.3636415534863595, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4546800.0000, 
sim time next is 4548000.0000, 
raw observation next is [2.666666666666667, 46.0, 171.5, 28.83333333333333, 22.5, 25.03521525703404, 0.2723543863368329, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5364727608494922, 0.46, 0.5716666666666667, 0.031860036832412515, 0.375, 0.58626793808617, 0.590784795445611, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0906764], dtype=float32), -0.99726206]. 
=============================================
[2019-04-16 12:35:20,776] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5509756e-01 2.1320429e-07 4.3347764e-10 3.9454009e-09 2.3215744e-11
 3.5201464e-07 6.8019836e-14 5.4489917e-01 4.5329617e-08 2.6151488e-06
 2.3787083e-09], sum to 1.0000
[2019-04-16 12:35:20,776] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6706
[2019-04-16 12:35:20,819] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [6.0, 69.0, 0.0, 0.0, 19.0, 24.37213117735313, 0.103670467024198, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4302000.0000, 
sim time next is 4303200.0000, 
raw observation next is [5.8, 70.33333333333334, 0.0, 0.0, 19.0, 24.36561336252775, 0.2334967119068523, 0.0, 1.0, 50.0, 57.82893733183146], 
processed observation next is [0.0, 0.8260869565217391, 0.6232686980609419, 0.7033333333333335, 0.0, 0.0, 0.08333333333333333, 0.5304677802106458, 0.5778322373022841, 0.0, 1.0, 0.7, 0.5782893733183146], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.56222147], dtype=float32), 0.24604847]. 
=============================================
[2019-04-16 12:35:23,246] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7576758e-01 3.7973123e-06 5.4991094e-08 6.5897872e-08 4.0460393e-10
 3.7392676e-06 2.1993969e-12 4.2421332e-01 2.2251288e-07 1.1078535e-05
 9.5249071e-08], sum to 1.0000
[2019-04-16 12:35:23,246] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5944
[2019-04-16 12:35:23,294] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.333333333333333, 72.0, 0.0, 0.0, 19.0, 23.39691354191564, -0.09998281059202425, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4677600.0000, 
sim time next is 4678800.0000, 
raw observation next is [0.6666666666666667, 82.0, 0.0, 0.0, 19.0, 23.18650178806177, 0.03626861143409606, 0.0, 1.0, 50.0, 62.84210456786721], 
processed observation next is [1.0, 0.13043478260869565, 0.4810710987996307, 0.82, 0.0, 0.0, 0.08333333333333333, 0.4322084823384807, 0.5120895371446986, 0.0, 1.0, 0.7, 0.6284210456786721], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7271583], dtype=float32), -0.05718135]. 
=============================================
[2019-04-16 12:35:23,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.95492148e-01 7.15768010e-06 1.20139703e-07 1.28874558e-06
 5.27790078e-09 5.96504697e-06 1.14815504e-10 3.04457158e-01
 1.23235941e-06 3.47672249e-05 2.66031407e-07], sum to 1.0000
[2019-04-16 12:35:23,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3832
[2019-04-16 12:35:23,879] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 20.57406319867108, -0.7215673122922359, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4767600.0000, 
sim time next is 4768800.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 20.14563884497156, -0.7846854828227849, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.17880323708096343, 0.23843817239240503, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.03143], dtype=float32), -1.790758]. 
=============================================
[2019-04-16 12:35:24,892] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9491284e-01 1.3619863e-06 3.5738651e-08 7.2799850e-08 2.1308735e-10
 1.3589191e-06 4.0487232e-12 7.0508218e-01 6.2167310e-08 2.0807440e-06
 5.5486399e-08], sum to 1.0000
[2019-04-16 12:35:24,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4058
[2019-04-16 12:35:24,936] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-0.9333333333333333, 71.0, 0.0, 0.0, 19.0, 21.98944366919165, -0.1949076590934348, 0.0, 1.0, 50.0, 70.39098583508516], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4513200.0000, 
sim time next is 4514400.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 19.0, 22.6494294557304, -0.1265159783524191, 0.0, 1.0, 50.0, 44.553212770513085], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.71, 0.0, 0.0, 0.08333333333333333, 0.3874524546441999, 0.4578280072158603, 0.0, 1.0, 0.7, 0.44553212770513084], 
reward next is 0.0295, 
noisyNet noise sample is [array([-0.7254319], dtype=float32), -1.9005735]. 
=============================================
[2019-04-16 12:35:26,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7429298e-01 2.0446311e-08 4.3809648e-10 2.3749540e-09 3.5363516e-12
 2.1944144e-08 2.0529512e-15 3.2570657e-01 7.1422163e-10 4.1343179e-07
 4.3704174e-09], sum to 1.0000
[2019-04-16 12:35:26,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8613
[2019-04-16 12:35:26,856] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 19.0, 23.19973442566954, 0.05443070286408665, 0.0, 1.0, 50.0, 63.08126746112419], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4576800.0000, 
sim time next is 4578000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 19.0, 23.63293939772084, 0.1011063970613045, 0.0, 1.0, 50.0, 39.82158622027138], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.61, 0.0, 0.0, 0.08333333333333333, 0.4694116164767366, 0.5337021323537682, 0.0, 1.0, 0.7, 0.39821586220271377], 
reward next is 0.0768, 
noisyNet noise sample is [array([0.11465245], dtype=float32), 0.86193895]. 
=============================================
[2019-04-16 12:35:28,803] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:28,966] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:28,991] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:29,162] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:29,805] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:29,805] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:29,817] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run9
[2019-04-16 12:35:29,993] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:29,994] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:30,012] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run9
[2019-04-16 12:35:30,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6787211e-01 1.0172625e-05 1.4001078e-07 3.3153435e-07 2.9038437e-08
 1.1899948e-05 1.8371672e-10 5.3205073e-01 1.6867947e-06 5.2325875e-05
 5.7779056e-07], sum to 1.0000
[2019-04-16 12:35:30,246] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7706
[2019-04-16 12:35:30,281] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 71.0, 70.5, 156.5, 19.0, 20.8001869101373, -0.6748840533911986, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4867200.0000, 
sim time next is 4868400.0000, 
raw observation next is [-3.666666666666667, 69.0, 117.5, 260.8333333333334, 19.0, 20.9875771729721, -0.4603708880556469, 0.0, 1.0, 50.0, 67.49778154782305], 
processed observation next is [0.0, 0.34782608695652173, 0.3610341643582641, 0.69, 0.39166666666666666, 0.2882136279926336, 0.08333333333333333, 0.24896476441434157, 0.34654303731478436, 0.0, 1.0, 0.7, 0.6749778154782305], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8386518], dtype=float32), -0.5043815]. 
=============================================
[2019-04-16 12:35:31,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7497000e-01 2.4821569e-09 1.9092701e-12 2.8064493e-11 4.5826305e-14
 9.6193116e-09 5.2745035e-18 7.2503000e-01 3.0644438e-11 2.5070474e-08
 1.1604813e-11], sum to 1.0000
[2019-04-16 12:35:31,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4475
[2019-04-16 12:35:31,180] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [10.33333333333333, 21.66666666666666, 116.8333333333333, 853.1666666666667, 22.5, 26.52102661747661, 0.7583541387432181, 1.0, 1.0, 50.0, 32.25010907409086], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 5060400.0000, 
sim time next is 5061600.0000, 
raw observation next is [11.0, 20.0, 114.5, 839.5, 22.5, 27.42417469773912, 0.8524023740808331, 1.0, 1.0, 50.0, 20.76479618602524], 
processed observation next is [1.0, 0.6086956521739131, 0.7673130193905818, 0.2, 0.38166666666666665, 0.9276243093922651, 0.375, 0.7853478914782599, 0.784134124693611, 1.0, 1.0, 0.7, 0.2076479618602524], 
reward next is 0.2674, 
noisyNet noise sample is [array([0.01954931], dtype=float32), 0.053470135]. 
=============================================
[2019-04-16 12:35:31,977] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:32,101] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:32,152] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:32,288] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:32,981] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:32,982] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:32,986] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run9
[2019-04-16 12:35:33,090] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:33,091] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:33,096] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run9
[2019-04-16 12:35:33,874] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:34,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:34,789] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:34,868] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:34,868] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:34,872] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run9
[2019-04-16 12:35:34,944] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:35,786] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:35,787] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:35,790] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run9
[2019-04-16 12:35:36,152] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:36,345] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:36,761] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:36,955] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:37,153] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:37,153] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:37,161] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run9
[2019-04-16 12:35:37,184] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:37,184] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:37,411] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:37,518] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:37,765] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:37,765] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:37,772] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run9
[2019-04-16 12:35:37,861] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:38,059] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:38,157] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:38,184] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:38,193] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:38,185] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:38,196] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:38,201] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run9
[2019-04-16 12:35:38,231] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run9
[2019-04-16 12:35:38,352] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:38,867] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:38,867] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:38,871] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run9
[2019-04-16 12:35:39,168] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:39,169] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:39,172] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run9
[2019-04-16 12:35:40,966] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:41,255] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:41,458] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:41,532] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:41,767] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:41,786] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:41,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:41,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:41,964] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run9
[2019-04-16 12:35:42,459] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:42,460] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:42,463] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run9
[2019-04-16 12:35:42,549] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:42,549] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:42,552] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run9
[2019-04-16 12:35:45,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3329985e-01 1.1309465e-05 1.0812943e-07 5.5707443e-07 1.8004040e-09
 5.7840211e-06 1.9197130e-10 2.6665524e-01 5.6809318e-07 2.6315867e-05
 3.0293765e-07], sum to 1.0000
[2019-04-16 12:35:45,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1827
[2019-04-16 12:35:45,215] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:35:45,244] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 68.0, 0.0, 0.0, 22.5, 17.38473664595385, -1.170617653642467, 1.0, 1.0, 50.0, 100.94341237240732], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 112800.0000, 
sim time next is 114000.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 22.5, 18.58807160249385, -1.226689144089557, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.375, 0.049005966874487626, 0.09110361863681431, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34063858], dtype=float32), -0.3002427]. 
=============================================
[2019-04-16 12:35:45,502] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-16 12:35:46,216] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:35:46,216] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:35:46,220] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run9
[2019-04-16 12:35:52,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1046814e-01 1.6355793e-08 3.0337449e-10 1.8871986e-09 2.1203180e-12
 5.9387474e-08 6.7063435e-15 8.8953090e-01 8.2233897e-10 8.7260185e-07
 5.0259463e-10], sum to 1.0000
[2019-04-16 12:35:52,054] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1105
[2019-04-16 12:35:52,122] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.233333333333334, 88.66666666666667, 0.0, 0.0, 19.0, 21.45106750498902, -0.438901549970609, 0.0, 1.0, 50.0, 41.05910298092512], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 76800.0000, 
sim time next is 78000.0000, 
raw observation next is [0.8666666666666667, 92.33333333333334, 0.0, 0.0, 19.0, 21.57564269278131, -0.4254913323233705, 0.0, 1.0, 50.0, 40.66445725052534], 
processed observation next is [0.0, 0.9130434782608695, 0.4866112650046169, 0.9233333333333335, 0.0, 0.0, 0.08333333333333333, 0.2979702243984426, 0.35816955589220983, 0.0, 1.0, 0.7, 0.4066445725052534], 
reward next is 0.0684, 
noisyNet noise sample is [array([0.20530115], dtype=float32), 0.3133303]. 
=============================================
[2019-04-16 12:35:58,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.6107231e-01 2.7416258e-08 4.1293294e-10 1.2610119e-09 1.1681225e-12
 8.3024837e-08 8.6534800e-15 3.3892733e-01 2.6300748e-09 1.9992743e-07
 3.7025469e-09], sum to 1.0000
[2019-04-16 12:35:58,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2028
[2019-04-16 12:35:58,743] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 22.5, 22.12857916822025, -0.6605762405892386, 1.0, 1.0, 50.0, 58.66673801629695], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 235200.0000, 
sim time next is 236400.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 22.5, 21.69986277333044, -0.7862365838371633, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.368421052631579, 0.65, 0.0, 0.0, 0.375, 0.30832189777753677, 0.23792113872094556, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14710602], dtype=float32), 2.407086]. 
=============================================
[2019-04-16 12:36:07,725] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.45421720e-01 1.22300025e-05 7.45817999e-07 1.75252285e-06
 1.80055668e-08 3.79528356e-05 1.85911064e-10 4.54351902e-01
 4.11980591e-06 1.67205057e-04 2.42798183e-06], sum to 1.0000
[2019-04-16 12:36:07,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6809
[2019-04-16 12:36:07,872] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-16.33333333333334, 84.0, 20.83333333333334, 405.8333333333333, 22.5, 16.67280944349275, -1.732278080503436, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 375600.0000, 
sim time next is 376800.0000, 
raw observation next is [-15.96666666666667, 87.0, 27.33333333333334, 520.5, 22.5, 17.41968991419151, -1.366303051520614, 1.0, 1.0, 50.0, 99.7814398038533], 
processed observation next is [1.0, 0.34782608695652173, 0.020313942751615764, 0.87, 0.09111111111111113, 0.5751381215469613, 0.375, -0.04835917381737431, 0.044565649493128655, 1.0, 1.0, 0.7, 0.997814398038533], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.68191266], dtype=float32), 2.4290888]. 
=============================================
[2019-04-16 12:36:10,246] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-16 12:36:10,247] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:36:10,247] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:36:10,249] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run12
[2019-04-16 12:36:10,265] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:36:10,266] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:36:10,267] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:36:10,268] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:36:10,270] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run12
[2019-04-16 12:36:10,285] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run12
[2019-04-16 12:37:19,906] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2468.9596 94682.8237 308.3637
[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:19,927] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:20,043] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:27,943] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2313.1292 103466.1042 -119.5091
[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:27,970] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:28,075] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,829] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2265.3853 103896.8478 -241.4866
[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,849] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:34,951] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:37:35,851] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 550000, evaluation results [550000.0, 2313.1292351675884, 103466.10419972881, -119.50906983295387, 2468.959625612063, 94682.82366974239, 308.3637056409651, 2265.3852548595873, 103896.84784760546, -241.48655071567347]
[2019-04-16 12:37:39,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3170396e-01 2.1303783e-09 5.7431143e-11 1.2545623e-10 1.8199199e-13
 7.9118934e-08 1.5861857e-16 6.6829586e-01 1.7843819e-10 5.6065968e-08
 1.3460386e-10], sum to 1.0000
[2019-04-16 12:37:39,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9404
[2019-04-16 12:37:39,800] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-0.6, 57.0, 107.5, 614.0, 22.5, 23.30978711399031, -0.3227247733050586, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 734400.0000, 
sim time next is 735600.0000, 
raw observation next is [-0.2333333333333334, 54.66666666666667, 123.1666666666667, 504.0, 22.5, 23.113041111216, -0.2401760765965011, 1.0, 1.0, 50.0, 53.177465113515346], 
processed observation next is [1.0, 0.5217391304347826, 0.456140350877193, 0.5466666666666667, 0.4105555555555557, 0.5569060773480663, 0.375, 0.42608675926799994, 0.4199413078011663, 1.0, 1.0, 0.7, 0.5317746511351534], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40604576], dtype=float32), 0.5423667]. 
=============================================
[2019-04-16 12:37:45,033] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3694457e-01 1.8800600e-06 3.7677889e-08 8.7517876e-08 1.2351028e-09
 3.0293434e-06 7.3023419e-12 4.6302393e-01 3.8176472e-07 2.5890142e-05
 8.3935390e-08], sum to 1.0000
[2019-04-16 12:37:45,033] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4352
[2019-04-16 12:37:45,054] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 87.0, 0.0, 0.0, 19.0, 19.27998252002017, -0.9458949632735855, 0.0, 1.0, 50.0, 64.01888665506938], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 583200.0000, 
sim time next is 584400.0000, 
raw observation next is [-2.466666666666667, 87.0, 0.0, 0.0, 19.0, 19.49931164080656, -1.044555420238689, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.39427516158818104, 0.87, 0.0, 0.0, 0.08333333333333333, 0.12494263673388002, 0.15181485992043697, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6336669], dtype=float32), -0.6072754]. 
=============================================
[2019-04-16 12:37:48,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.98168063e-01 3.75038253e-05 6.89019203e-07 8.71801262e-07
 2.78476389e-08 1.34736065e-05 7.95090549e-10 2.01710939e-01
 1.01040769e-06 6.61972736e-05 1.27147791e-06], sum to 1.0000
[2019-04-16 12:37:48,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9393
[2019-04-16 12:37:48,365] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.4, 65.0, 94.5, 19.0, 19.0, 18.13966089796295, -1.431420123811298, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 644400.0000, 
sim time next is 645600.0000, 
raw observation next is [-3.166666666666667, 63.66666666666667, 90.83333333333334, 31.66666666666667, 19.0, 18.23074061555429, -1.192212824538769, 0.0, 1.0, 50.0, 92.86690632468563], 
processed observation next is [0.0, 0.4782608695652174, 0.3748845798707295, 0.6366666666666667, 0.3027777777777778, 0.03499079189686925, 0.08333333333333333, 0.019228384629524104, 0.10259572515374364, 0.0, 1.0, 0.7, 0.9286690632468563], 
reward next is 0.4554, 
noisyNet noise sample is [array([0.33787936], dtype=float32), -0.38724434]. 
=============================================
[2019-04-16 12:37:50,405] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.6290440e-01 1.4773290e-09 3.2063976e-12 3.8177122e-12 2.7532022e-15
 3.0580245e-09 1.6335190e-19 6.3709563e-01 6.2006400e-11 7.5435773e-09
 3.4910963e-12], sum to 1.0000
[2019-04-16 12:37:50,405] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7832
[2019-04-16 12:37:50,449] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [14.4, 81.0, 106.5, 0.0, 22.5, 25.35371685183031, 0.419710657987826, 1.0, 1.0, 50.0, 35.32320387671387], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1000800.0000, 
sim time next is 1002000.0000, 
raw observation next is [14.4, 81.0, 98.16666666666667, 0.0, 22.5, 25.7340188152877, 0.4866021882578522, 1.0, 1.0, 50.0, 34.19893510307895], 
processed observation next is [1.0, 0.6086956521739131, 0.8614958448753465, 0.81, 0.32722222222222225, 0.0, 0.375, 0.6445015679406417, 0.6622007294192841, 1.0, 1.0, 0.7, 0.34198935103078953], 
reward next is 0.1330, 
noisyNet noise sample is [array([0.09382197], dtype=float32), 1.2309211]. 
=============================================
[2019-04-16 12:37:50,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8931268e-01 4.1883322e-06 4.5278614e-07 7.7058837e-07 1.2115971e-08
 1.7295657e-05 9.5488763e-11 6.1061263e-01 1.2126052e-06 5.0234663e-05
 5.1573920e-07], sum to 1.0000
[2019-04-16 12:37:50,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8974
[2019-04-16 12:37:51,062] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.4, 65.0, 94.5, 19.0, 19.0, 19.1273690721319, -1.181093431607265, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 644400.0000, 
sim time next is 645600.0000, 
raw observation next is [-3.166666666666667, 63.66666666666667, 90.83333333333334, 31.66666666666667, 19.0, 19.01200206725477, -1.062430379151912, 0.0, 1.0, 50.0, 67.91304208033834], 
processed observation next is [0.0, 0.4782608695652174, 0.3748845798707295, 0.6366666666666667, 0.3027777777777778, 0.03499079189686925, 0.08333333333333333, 0.08433350560456414, 0.14585654028269598, 0.0, 1.0, 0.7, 0.6791304208033835], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17299944], dtype=float32), 0.6252435]. 
=============================================
[2019-04-16 12:37:56,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2706863e-01 1.8614436e-08 1.0947194e-10 2.7161468e-10 1.7440000e-13
 1.2106870e-08 5.1103912e-16 1.7293137e-01 1.9196439e-10 3.9743263e-08
 1.6982232e-11], sum to 1.0000
[2019-04-16 12:37:56,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1891
[2019-04-16 12:37:56,635] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.3, 62.0, 0.0, 0.0, 19.0, 25.63530030672165, 0.5968775312558253, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1112400.0000, 
sim time next is 1113600.0000, 
raw observation next is [13.1, 62.66666666666667, 0.0, 0.0, 19.0, 25.42400192517218, 0.5585969512467716, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8254847645429363, 0.6266666666666667, 0.0, 0.0, 0.08333333333333333, 0.6186668270976817, 0.6861989837489239, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3447368], dtype=float32), -0.25649115]. 
=============================================
[2019-04-16 12:37:58,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2332703e-01 1.0564907e-07 4.3722177e-09 1.2360122e-09 4.1793118e-12
 9.7510764e-08 1.4333117e-14 8.7667191e-01 2.0320023e-09 8.5599299e-07
 1.4446809e-09], sum to 1.0000
[2019-04-16 12:37:58,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5131
[2019-04-16 12:37:58,115] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [8.433333333333334, 83.0, 0.0, 0.0, 19.0, 22.89378642196233, -0.1968313464186987, 0.0, 1.0, 50.0, 38.88690761486525], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 967200.0000, 
sim time next is 968400.0000, 
raw observation next is [8.8, 83.0, 0.0, 0.0, 19.0, 22.96984242613292, -0.1831683446428407, 0.0, 1.0, 50.0, 38.41308448266068], 
processed observation next is [1.0, 0.21739130434782608, 0.7063711911357342, 0.83, 0.0, 0.0, 0.08333333333333333, 0.41415353551107675, 0.4389438851190531, 0.0, 1.0, 0.7, 0.3841308448266068], 
reward next is 0.0909, 
noisyNet noise sample is [array([1.1642919], dtype=float32), -0.055659812]. 
=============================================
[2019-04-16 12:37:58,331] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.2299322e-01 1.4953930e-08 1.5955238e-09 1.3755167e-09 1.5352030e-12
 2.6162135e-07 2.0620867e-15 1.7700636e-01 3.7711845e-10 1.1777285e-07
 9.4698416e-10], sum to 1.0000
[2019-04-16 12:37:58,332] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0896
[2019-04-16 12:37:58,348] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.8, 86.0, 116.0, 0.0, 22.5, 22.9729000841729, -0.2114759858198419, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 991200.0000, 
sim time next is 992400.0000, 
raw observation next is [12.0, 86.0, 121.3333333333333, 0.0, 22.5, 22.99820765177114, -0.2037635631752024, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7950138504155125, 0.86, 0.40444444444444433, 0.0, 0.375, 0.4165173043142616, 0.43207881227493256, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8066525], dtype=float32), 0.25677848]. 
=============================================
[2019-04-16 12:37:59,834] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3871668e-01 1.9923471e-08 1.6682170e-10 2.6086533e-10 4.1819090e-13
 7.2851001e-09 5.1357302e-16 5.6128293e-01 5.3254395e-10 3.8548416e-07
 2.1607612e-10], sum to 1.0000
[2019-04-16 12:37:59,836] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5005
[2019-04-16 12:37:59,875] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [12.2, 83.0, 11.5, 38.0, 22.5, 24.28026279918498, 0.2134657484541205, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1065600.0000, 
sim time next is 1066800.0000, 
raw observation next is [12.2, 83.0, 18.5, 58.66666666666666, 22.5, 24.492192139499, 0.4331718110085563, 1.0, 1.0, 50.0, 57.29208470805162], 
processed observation next is [1.0, 0.34782608695652173, 0.8005540166204987, 0.83, 0.06166666666666667, 0.06482504604051564, 0.375, 0.5410160116249166, 0.6443906036695187, 1.0, 1.0, 0.7, 0.5729208470805162], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0025125], dtype=float32), -0.94537276]. 
=============================================
[2019-04-16 12:38:00,430] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.2779037e-01 7.8232283e-09 6.8896548e-11 2.4907647e-11 3.2273275e-13
 6.6689104e-08 1.0642824e-16 7.7220941e-01 4.0315137e-11 2.1224884e-07
 7.5719743e-11], sum to 1.0000
[2019-04-16 12:38:00,430] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4141
[2019-04-16 12:38:00,459] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [14.6, 58.00000000000001, 0.0, 0.0, 22.5, 27.61159362884953, 1.032136184828949, 0.0, 1.0, 50.0, 28.702824045539472], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1106400.0000, 
sim time next is 1107600.0000, 
raw observation next is [14.2, 59.0, 0.0, 0.0, 22.5, 27.44684540560932, 1.019429573124845, 1.0, 1.0, 50.0, 29.89970880632316], 
processed observation next is [1.0, 0.8260869565217391, 0.8559556786703602, 0.59, 0.0, 0.0, 0.375, 0.78723711713411, 0.8398098577082816, 1.0, 1.0, 0.7, 0.2989970880632316], 
reward next is 0.1760, 
noisyNet noise sample is [array([-0.16941923], dtype=float32), -1.0114409]. 
=============================================
[2019-04-16 12:38:01,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6182967e-01 3.1980267e-08 2.5723518e-10 1.8489298e-10 5.7370189e-12
 1.0781952e-07 7.9092443e-16 2.3816828e-01 1.0035087e-09 1.9326737e-06
 3.6504764e-09], sum to 1.0000
[2019-04-16 12:38:01,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2037
[2019-04-16 12:38:01,252] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 89.0, 0.0, 0.0, 19.0, 22.61251794699804, -0.1782859562719274, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1458000.0000, 
sim time next is 1459200.0000, 
raw observation next is [1.433333333333334, 90.0, 0.0, 0.0, 19.0, 22.28487541350203, -0.2303189534460808, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.502308402585411, 0.9, 0.0, 0.0, 0.08333333333333333, 0.35707295112516907, 0.4232270155179731, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.904325], dtype=float32), 1.3962238]. 
=============================================
[2019-04-16 12:38:03,212] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9915658e-01 6.2384249e-09 3.6392396e-11 1.2846850e-10 7.1188627e-14
 1.5653065e-08 3.6349434e-16 7.0084345e-01 3.4536443e-10 2.5297808e-08
 1.4877416e-10], sum to 1.0000
[2019-04-16 12:38:03,213] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7222
[2019-04-16 12:38:03,247] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [19.4, 49.0, 82.5, 0.0, 22.5, 27.18698211934074, 1.032169067953306, 1.0, 0.0, 50.0, 23.821531348571977], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1093200.0000, 
sim time next is 1094400.0000, 
raw observation next is [19.4, 49.0, 63.5, 0.0, 22.5, 28.24200042346443, 1.104396826756745, 1.0, 0.0, 50.0, 11.822827703985126], 
processed observation next is [1.0, 0.6956521739130435, 1.0, 0.49, 0.21166666666666667, 0.0, 0.375, 0.8535000352887024, 0.8681322755855817, 1.0, 0.0, 0.7, 0.11822827703985127], 
reward next is 0.3568, 
noisyNet noise sample is [array([0.3373239], dtype=float32), -0.88793534]. 
=============================================
[2019-04-16 12:38:05,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5181057e-01 5.1205600e-09 6.6688009e-11 2.1186373e-10 1.6668545e-12
 4.5588155e-08 5.3221446e-16 6.4818913e-01 4.1270590e-10 3.1317691e-07
 2.3175885e-10], sum to 1.0000
[2019-04-16 12:38:05,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8767
[2019-04-16 12:38:05,098] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-0.6, 100.0, 0.0, 0.0, 22.5, 24.05109091583996, 0.1668047027842946, 1.0, 1.0, 50.0, 39.937811284300224], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1410000.0000, 
sim time next is 1411200.0000, 
raw observation next is [-0.6, 100.0, 9.0, 0.0, 22.5, 24.09283355261787, 0.1770043301971107, 1.0, 1.0, 50.0, 39.46772129270736], 
processed observation next is [1.0, 0.34782608695652173, 0.44598337950138506, 1.0, 0.03, 0.0, 0.375, 0.5077361293848224, 0.5590014433990369, 1.0, 1.0, 0.7, 0.3946772129270736], 
reward next is 0.0803, 
noisyNet noise sample is [array([1.8696233], dtype=float32), 1.9057921]. 
=============================================
[2019-04-16 12:38:05,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3556089e-01 8.8452433e-11 6.0594851e-13 2.1991393e-12 8.1891916e-15
 1.1882688e-09 7.2715824e-19 6.6443914e-01 6.2980597e-12 1.0751821e-08
 2.5504236e-12], sum to 1.0000
[2019-04-16 12:38:05,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1834
[2019-04-16 12:38:05,693] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 67.66666666666667, 0.0, 22.5, 24.18896644381244, 0.3553241247617238, 1.0, 1.0, 50.0, 58.480979353235995], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1435200.0000, 
sim time next is 1436400.0000, 
raw observation next is [1.1, 92.0, 59.0, 0.0, 22.5, 25.27579914548779, 0.3442398205472258, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.92, 0.19666666666666666, 0.0, 0.375, 0.606316595457316, 0.6147466068490752, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8696233], dtype=float32), 1.9057921]. 
=============================================
[2019-04-16 12:38:07,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3921492e-01 3.7414143e-09 8.7076721e-11 1.2662606e-10 3.4126049e-13
 8.9790042e-09 1.4659280e-16 1.6078480e-01 3.5528602e-10 1.9658192e-07
 1.5467393e-10], sum to 1.0000
[2019-04-16 12:38:07,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4874
[2019-04-16 12:38:07,883] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.23333333333333, 73.0, 0.0, 0.0, 19.0, 26.24324462754077, 0.7058374771365529, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1124400.0000, 
sim time next is 1125600.0000, 
raw observation next is [10.86666666666667, 75.0, 0.0, 0.0, 19.0, 25.91619085628945, 0.6212912124081461, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.7636195752539245, 0.75, 0.0, 0.0, 0.08333333333333333, 0.6596825713574542, 0.7070970708027153, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.72756374], dtype=float32), 0.21230938]. 
=============================================
[2019-04-16 12:38:10,808] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.1915361e-01 4.7486428e-09 1.0051615e-11 2.1045937e-10 5.6817086e-14
 1.7012657e-07 8.5818361e-17 1.8084615e-01 6.4186968e-11 9.0304610e-08
 3.5266477e-11], sum to 1.0000
[2019-04-16 12:38:10,808] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3067
[2019-04-16 12:38:10,818] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.600000000000001, 60.66666666666667, 0.0, 0.0, 22.5, 23.98387530703559, 0.220145734112923, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1536000.0000, 
sim time next is 1537200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 22.5, 24.23405382288147, 0.2197412171146333, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7229916897506927, 0.61, 0.0, 0.0, 0.375, 0.5195044852401226, 0.5732470723715445, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.601524], dtype=float32), 0.41235426]. 
=============================================
[2019-04-16 12:38:12,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5604131e-01 7.3985049e-09 7.4512887e-12 3.8477312e-11 2.5309868e-14
 2.0400710e-08 2.4931606e-17 1.4395872e-01 4.2829371e-10 2.5254009e-08
 5.3457655e-11], sum to 1.0000
[2019-04-16 12:38:12,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5023
[2019-04-16 12:38:12,048] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 75.0, 0.0, 22.5, 23.22020387210485, -0.04873631237440296, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1434000.0000, 
sim time next is 1435200.0000, 
raw observation next is [1.1, 92.0, 67.66666666666667, 0.0, 22.5, 23.58512452941596, -0.01907538095662178, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.22555555555555556, 0.0, 0.375, 0.4654270441179967, 0.49364153968112606, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7660091], dtype=float32), 0.47410554]. 
=============================================
[2019-04-16 12:38:14,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4898268e-01 8.0318294e-08 3.8864176e-10 1.5814326e-10 2.4056416e-13
 9.4264003e-08 7.7384328e-17 7.5101703e-01 3.6451689e-10 5.2253746e-08
 1.7288555e-10], sum to 1.0000
[2019-04-16 12:38:14,669] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0485
[2019-04-16 12:38:14,705] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 89.33333333333334, 80.16666666666667, 0.0, 22.5, 25.67529702377305, 0.51441294241942, 1.0, 1.0, 50.0, 44.781039944726636], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1682400.0000, 
sim time next is 1683600.0000, 
raw observation next is [1.1, 86.66666666666667, 87.0, 0.0, 22.5, 25.7431830399635, 0.4206740057715719, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.49307479224376743, 0.8666666666666667, 0.29, 0.0, 0.375, 0.6452652533302917, 0.640224668590524, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47944605], dtype=float32), -0.33582756]. 
=============================================
[2019-04-16 12:38:15,945] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5768753e-01 1.8672631e-06 2.6802640e-08 1.2809807e-07 1.2863156e-09
 2.0092505e-06 5.5439568e-12 1.4230232e-01 5.7893675e-07 5.4330690e-06
 1.4151458e-07], sum to 1.0000
[2019-04-16 12:38:15,947] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1568
[2019-04-16 12:38:16,000] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 71.0, 128.3333333333333, 6.666666666666665, 19.0, 19.38688340632302, -0.906677772796643, 0.0, 1.0, 50.0, 73.00581353949728], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1860000.0000, 
sim time next is 1861200.0000, 
raw observation next is [-4.5, 71.0, 145.0, 20.0, 19.0, 19.73001553846711, -0.9959811844663293, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.3379501385041552, 0.71, 0.48333333333333334, 0.022099447513812154, 0.08333333333333333, 0.1441679615389259, 0.16800627184455688, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0677567], dtype=float32), 0.006942107]. 
=============================================
[2019-04-16 12:38:16,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5886537e-01 8.3557015e-06 4.4636874e-07 4.0566400e-07 8.7724006e-09
 1.5077228e-05 2.0182871e-11 5.4108536e-01 1.6917779e-06 2.2905682e-05
 4.4223245e-07], sum to 1.0000
[2019-04-16 12:38:16,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1688
[2019-04-16 12:38:16,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 79.66666666666667, 0.0, 0.0, 19.0, 18.83302295512393, -1.137915327972863, 0.0, 1.0, 50.0, 50.23769216541683], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1902000.0000, 
sim time next is 1903200.0000, 
raw observation next is [-7.3, 77.33333333333334, 0.0, 0.0, 19.0, 18.85023988679259, -1.282207132718342, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.7733333333333334, 0.0, 0.0, 0.08333333333333333, 0.07085332389938248, 0.07259762242721934, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9361, 
noisyNet noise sample is [array([1.811346], dtype=float32), 0.4969105]. 
=============================================
[2019-04-16 12:38:18,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2262774e-01 5.4237010e-08 2.3641587e-11 3.9489034e-11 2.5389974e-13
 3.0929794e-08 1.3445405e-16 3.7737209e-01 3.1115677e-10 7.2384147e-08
 1.8859765e-10], sum to 1.0000
[2019-04-16 12:38:18,350] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9530
[2019-04-16 12:38:18,384] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 23.23650443271531, 0.137785342886847, 1.0, 1.0, 50.0, 74.51007839054364], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1707600.0000, 
sim time next is 1708800.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 23.8910776548483, 0.1882676965853571, 1.0, 1.0, 50.0, 46.09764503380281], 
processed observation next is [1.0, 0.782608695652174, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.4909231379040249, 0.5627558988617857, 1.0, 1.0, 0.7, 0.46097645033802814], 
reward next is 0.0140, 
noisyNet noise sample is [array([1.7484931], dtype=float32), 1.019796]. 
=============================================
[2019-04-16 12:38:19,675] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.72000962e-01 1.63020957e-08 4.21230578e-10 9.28551347e-10
 3.29107103e-13 6.69271483e-09 1.43402540e-15 6.27998650e-01
 1.06735606e-10 3.68244514e-07 5.42586032e-10], sum to 1.0000
[2019-04-16 12:38:19,676] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6483
[2019-04-16 12:38:19,708] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [5.333333333333334, 95.33333333333334, 0.0, 0.0, 19.0, 24.29199892683282, 0.2950832177910305, 0.0, 1.0, 50.0, 53.701181805662756], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1664400.0000, 
sim time next is 1665600.0000, 
raw observation next is [5.166666666666666, 93.66666666666666, 0.0, 0.0, 19.0, 24.63051802409952, 0.3245530529439679, 0.0, 1.0, 50.0, 38.49291386788963], 
processed observation next is [1.0, 0.2608695652173913, 0.6057248384118191, 0.9366666666666665, 0.0, 0.0, 0.08333333333333333, 0.5525431686749599, 0.6081843509813226, 0.0, 1.0, 0.7, 0.3849291386788963], 
reward next is 0.0901, 
noisyNet noise sample is [array([-0.2094934], dtype=float32), -0.7823041]. 
=============================================
[2019-04-16 12:38:22,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2508159e-02 5.9563461e-09 6.3443465e-12 3.6272298e-11 8.0228894e-14
 4.5966477e-08 3.1213760e-17 9.5749182e-01 3.2002626e-11 1.1105804e-08
 3.2780108e-11], sum to 1.0000
[2019-04-16 12:38:22,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8708
[2019-04-16 12:38:22,621] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 86.0, 0.0, 0.0, 19.0, 22.58333546154489, -0.2546576899955328, 0.0, 1.0, 50.0, 41.00558078709099], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2062800.0000, 
sim time next is 2064000.0000, 
raw observation next is [-3.9, 84.66666666666667, 0.0, 0.0, 19.0, 22.55290608112789, -0.2583908724106515, 0.0, 1.0, 50.0, 40.83554095854731], 
processed observation next is [1.0, 0.9130434782608695, 0.3545706371191136, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.37940884009399084, 0.41386970919644944, 0.0, 1.0, 0.7, 0.4083554095854731], 
reward next is 0.0666, 
noisyNet noise sample is [array([-0.8017785], dtype=float32), -1.7375275]. 
=============================================
[2019-04-16 12:38:24,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.13011920e-01 4.14679818e-07 1.40852094e-08 1.47630942e-07
 3.23717830e-10 7.07797824e-07 8.09385545e-13 2.86974519e-01
 2.09830674e-07 1.20465875e-05 4.55757956e-08], sum to 1.0000
[2019-04-16 12:38:24,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2134
[2019-04-16 12:38:24,216] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 84.33333333333333, 0.0, 0.0, 19.0, 19.56452877105458, -0.9616936981641998, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1993200.0000, 
sim time next is 1994400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 19.35240559840084, -1.006118998145528, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.11270046653340327, 0.1646270006181573, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.205113], dtype=float32), 0.56085753]. 
=============================================
[2019-04-16 12:38:24,254] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4793603e-01 5.7895454e-07 1.0723783e-08 3.1382420e-08 3.7517267e-10
 1.6105138e-06 1.5046279e-12 5.5205315e-01 1.2781291e-07 8.5130714e-06
 2.2383471e-08], sum to 1.0000
[2019-04-16 12:38:24,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3873
[2019-04-16 12:38:24,269] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 86.0, 0.0, 0.0, 19.0, 21.16519376084459, -0.7258367637822895, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2082000.0000, 
sim time next is 2083200.0000, 
raw observation next is [-4.833333333333333, 86.0, 0.0, 0.0, 19.0, 20.40042953151499, -0.8703287778277811, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.3287165281625116, 0.86, 0.0, 0.0, 0.08333333333333333, 0.20003579429291593, 0.20989040739073964, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38447985], dtype=float32), 2.0770826]. 
=============================================
[2019-04-16 12:38:28,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4084518e-01 1.3803655e-06 8.2536566e-08 1.2429736e-07 1.8077655e-09
 2.5506265e-06 7.2779508e-12 3.5914370e-01 5.2434405e-07 6.3639218e-06
 1.7168385e-07], sum to 1.0000
[2019-04-16 12:38:28,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4729
[2019-04-16 12:38:28,463] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 85.66666666666667, 0.0, 0.0, 19.0, 20.8589704592786, -0.7775406883454742, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2004000.0000, 
sim time next is 2005200.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 19.0, 20.41359402193316, -0.8683307481229942, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.20113283516109673, 0.2105564172923353, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.68765986], dtype=float32), -0.6313646]. 
=============================================
[2019-04-16 12:38:28,731] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.2945199e-01 6.3617989e-08 2.9820890e-09 3.9174552e-08 9.6831336e-12
 4.7172955e-07 9.9414131e-15 3.7054318e-01 1.3084418e-08 4.2808811e-06
 5.2262679e-09], sum to 1.0000
[2019-04-16 12:38:28,731] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3032
[2019-04-16 12:38:28,762] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 91.0, 0.0, 0.0, 19.0, 20.16946418574291, -0.8054396912176317, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2073600.0000, 
sim time next is 2074800.0000, 
raw observation next is [-4.5, 91.0, 0.0, 0.0, 19.0, 19.88688843601642, -0.8500357272984616, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.91, 0.0, 0.0, 0.08333333333333333, 0.15724070300136836, 0.21665475756717947, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0165699], dtype=float32), 2.0428767]. 
=============================================
[2019-04-16 12:38:35,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3084607e-01 4.4636107e-07 7.4499185e-09 7.4099833e-09 2.7732767e-11
 1.4515780e-06 9.7827576e-14 5.6914979e-01 6.7278449e-08 2.0625771e-06
 1.3824093e-08], sum to 1.0000
[2019-04-16 12:38:35,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5473
[2019-04-16 12:38:35,540] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.4, 73.66666666666667, 91.83333333333333, 419.5, 22.5, 21.70544652565108, -0.5402387579149145, 1.0, 1.0, 50.0, 56.7575496197362], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2193600.0000, 
sim time next is 2194800.0000, 
raw observation next is [-5.199999999999999, 72.33333333333333, 104.5, 375.8333333333334, 22.5, 22.34889111251938, -0.4422047862120844, 1.0, 1.0, 50.0, 54.64646785126], 
processed observation next is [1.0, 0.391304347826087, 0.31855955678670367, 0.7233333333333333, 0.34833333333333333, 0.4152854511970535, 0.375, 0.3624075927099482, 0.35259840459597186, 1.0, 1.0, 0.7, 0.5464646785125999], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3458836], dtype=float32), 0.5906659]. 
=============================================
[2019-04-16 12:38:37,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6431910e-01 8.7028837e-08 7.4413659e-10 2.5519622e-09 1.7041629e-11
 2.3230011e-07 3.3845017e-14 8.3567822e-01 6.9150069e-10 2.4168696e-06
 7.0650036e-10], sum to 1.0000
[2019-04-16 12:38:37,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2901
[2019-04-16 12:38:38,148] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.8, 61.33333333333333, 177.8333333333333, 104.0, 22.5, 20.97531406519394, -0.6915190811807858, 1.0, 1.0, 50.0, 85.9104650833946], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2288400.0000, 
sim time next is 2289600.0000, 
raw observation next is [-3.2, 58.0, 211.5, 92.0, 22.5, 21.76134608588264, -0.5806429221020162, 1.0, 1.0, 50.0, 55.73907385653001], 
processed observation next is [1.0, 0.5217391304347826, 0.37396121883656513, 0.58, 0.705, 0.10165745856353592, 0.375, 0.3134455071568866, 0.30645235929932796, 1.0, 1.0, 0.7, 0.5573907385653001], 
reward next is 0.4032, 
noisyNet noise sample is [array([0.54954785], dtype=float32), -0.89183146]. 
=============================================
[2019-04-16 12:38:39,133] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8256108e-01 2.5773175e-05 1.3849207e-07 6.7678803e-07 1.5603497e-08
 1.8420540e-05 2.8399860e-10 4.1731036e-01 1.1731581e-06 8.1736092e-05
 7.3517072e-07], sum to 1.0000
[2019-04-16 12:38:39,133] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6382
[2019-04-16 12:38:39,183] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 66.33333333333334, 0.0, 0.0, 19.0, 20.21821903463806, -0.6768479889731459, 0.0, 1.0, 50.0, 70.66635525617293], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2348400.0000, 
sim time next is 2349600.0000, 
raw observation next is [-3.2, 67.66666666666667, 0.0, 0.0, 19.0, 20.72768740008546, -0.6257886330038568, 0.0, 1.0, 50.0, 45.35473308311626], 
processed observation next is [0.0, 0.17391304347826086, 0.37396121883656513, 0.6766666666666667, 0.0, 0.0, 0.08333333333333333, 0.2273072833404551, 0.2914037889987144, 0.0, 1.0, 0.7, 0.4535473308311626], 
reward next is 0.0215, 
noisyNet noise sample is [array([1.9234972], dtype=float32), 1.1401403]. 
=============================================
[2019-04-16 12:38:49,213] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8698241e-01 1.4467927e-08 8.4328844e-10 1.1364386e-09 2.0644573e-12
 2.4633422e-07 5.6242090e-15 5.1301658e-01 1.2625338e-08 6.8820805e-07
 1.6191368e-10], sum to 1.0000
[2019-04-16 12:38:49,213] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4922
[2019-04-16 12:38:49,299] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-10.0, 68.0, 116.1666666666667, 691.8333333333334, 22.5, 22.62987801258419, -0.4271886996018428, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2716800.0000, 
sim time next is 2718000.0000, 
raw observation next is [-9.0, 64.0, 114.5, 727.5, 22.5, 22.74238783513492, -0.3812059857874791, 1.0, 1.0, 50.0, 61.41110207000679], 
processed observation next is [1.0, 0.4782608695652174, 0.21329639889196678, 0.64, 0.38166666666666665, 0.8038674033149171, 0.375, 0.39519898626124333, 0.3729313380708403, 1.0, 1.0, 0.7, 0.614111020700068], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.026232], dtype=float32), -0.6577004]. 
=============================================
[2019-04-16 12:38:58,055] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0963247e-01 3.4301186e-07 7.4170270e-10 1.4067475e-09 6.5616713e-12
 6.5360751e-07 7.6948098e-14 4.9036634e-01 1.2465476e-08 1.5015307e-07
 2.5549105e-09], sum to 1.0000
[2019-04-16 12:38:58,055] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3918
[2019-04-16 12:38:58,135] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 72.0, 113.6666666666667, 663.6666666666667, 22.5, 21.8420545731132, -0.4844334355472968, 1.0, 1.0, 50.0, 76.23747333219637], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2715600.0000, 
sim time next is 2716800.0000, 
raw observation next is [-10.0, 68.0, 116.1666666666667, 691.8333333333334, 22.5, 22.29986959685078, -0.5282453211018973, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.18559556786703602, 0.68, 0.38722222222222236, 0.7644567219152855, 0.375, 0.35832246640423165, 0.32391822629936756, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9801, 
noisyNet noise sample is [array([-1.1212637], dtype=float32), 0.5168944]. 
=============================================
[2019-04-16 12:38:58,234] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3139807e-01 9.6541527e-08 2.1074090e-10 2.1532985e-10 2.9301602e-13
 2.5245259e-07 1.4502868e-15 1.6860138e-01 6.5036199e-10 2.0340637e-07
 3.5598785e-10], sum to 1.0000
[2019-04-16 12:38:58,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6805
[2019-04-16 12:38:58,308] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 95.33333333333334, 85.5, 0.0, 22.5, 23.30751309518082, -0.1911533809018581, 1.0, 1.0, 50.0, 59.957494237609836], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2892000.0000, 
sim time next is 2893200.0000, 
raw observation next is [1.0, 97.66666666666666, 101.6666666666667, 0.0, 22.5, 23.51437052615574, -0.2737778497294503, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.9766666666666666, 0.338888888888889, 0.0, 0.375, 0.4595308771796451, 0.4087407167568499, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0905172], dtype=float32), -1.0096575]. 
=============================================
[2019-04-16 12:38:58,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.70911145e-01 8.80718289e-08 3.31305161e-09 1.19456498e-08
 3.79365740e-11 3.29023663e-07 3.56582656e-13 5.29085100e-01
 1.42715688e-08 3.34492483e-06 1.09218945e-08], sum to 1.0000
[2019-04-16 12:38:58,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8324
[2019-04-16 12:38:58,563] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 65.0, 145.5, 745.5, 19.0, 20.0396017408646, -0.8036897587040334, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2984400.0000, 
sim time next is 2985600.0000, 
raw observation next is [-2.666666666666667, 63.33333333333334, 121.8333333333333, 781.8333333333334, 19.0, 20.18185486389146, -0.59852117675922, 0.0, 1.0, 50.0, 67.88499921884562], 
processed observation next is [0.0, 0.5652173913043478, 0.38873499538319484, 0.6333333333333334, 0.406111111111111, 0.8639042357274402, 0.08333333333333333, 0.1818212386576216, 0.30049294108026, 0.0, 1.0, 0.7, 0.6788499921884562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7796178], dtype=float32), 0.7483351]. 
=============================================
[2019-04-16 12:39:02,820] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.9117830e-01 3.4602635e-05 1.6792249e-06 1.1964917e-06 2.2846452e-08
 7.4703996e-05 4.7570659e-10 4.0864113e-01 5.2879914e-06 6.1080340e-05
 2.0145299e-06], sum to 1.0000
[2019-04-16 12:39:02,821] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1921
[2019-04-16 12:39:02,837] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 72.33333333333333, 0.0, 0.0, 19.0, 17.45783693945438, -1.315141080950812, 0.0, 1.0, 50.0, 75.17963443148867], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3044400.0000, 
sim time next is 3045600.0000, 
raw observation next is [-6.0, 70.0, 0.0, 0.0, 19.0, 17.9607226532496, -1.402345870129416, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.296398891966759, 0.7, 0.0, 0.0, 0.08333333333333333, -0.0032731122291999406, 0.03255137662352799, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.213243], dtype=float32), -2.4258764]. 
=============================================
[2019-04-16 12:39:03,076] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8305609e-01 3.2636431e-09 3.9530419e-12 3.2799648e-11 3.3909907e-14
 7.0410472e-10 7.4624016e-18 4.1694382e-01 1.3668867e-10 3.4408423e-08
 2.6379310e-10], sum to 1.0000
[2019-04-16 12:39:03,077] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3182
[2019-04-16 12:39:03,090] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 97.66666666666667, 0.0, 0.0, 19.0, 24.13412941930068, 0.2176991686901351, 0.0, 1.0, 50.0, 52.45668070281166], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3190800.0000, 
sim time next is 3192000.0000, 
raw observation next is [2.0, 95.33333333333334, 0.0, 0.0, 19.0, 23.99459041924364, 0.08871320644870288, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.49954920160363664, 0.5295710688162343, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.403995], dtype=float32), 0.9874653]. 
=============================================
[2019-04-16 12:39:04,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0574207e-01 3.1414707e-08 1.4408084e-10 2.4514084e-09 1.6219803e-12
 1.4625681e-07 2.2002735e-15 4.9425748e-01 5.8801608e-10 2.9603805e-07
 6.8620282e-10], sum to 1.0000
[2019-04-16 12:39:04,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0141
[2019-04-16 12:39:04,153] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 102.3333333333333, 669.5, 22.5, 22.61584998881249, -0.05711479446118344, 1.0, 1.0, 50.0, 93.48657845652181], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3231600.0000, 
sim time next is 3232800.0000, 
raw observation next is [-3.0, 92.0, 105.0, 702.5, 22.5, 23.67795135222654, -0.06096270358817483, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3795013850415513, 0.92, 0.35, 0.7762430939226519, 0.375, 0.473162612685545, 0.4796790988039417, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09677681], dtype=float32), 1.7323271]. 
=============================================
[2019-04-16 12:39:04,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7988294e-01 3.2851000e-11 1.5048023e-12 1.2435290e-12 1.1174238e-15
 6.0992411e-10 1.0548228e-18 3.2011706e-01 2.4668154e-12 3.8861918e-09
 7.3269102e-14], sum to 1.0000
[2019-04-16 12:39:04,448] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6944
[2019-04-16 12:39:04,492] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.333333333333333, 100.0, 0.0, 0.0, 22.5, 26.34600621309673, 0.7345786551799695, 0.0, 1.0, 50.0, 32.09490629079871], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3181200.0000, 
sim time next is 3182400.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 22.5, 26.24990647313519, 0.7287576019793057, 1.0, 1.0, 50.0, 32.18667490281998], 
processed observation next is [1.0, 0.8695652173913043, 0.5457063711911359, 1.0, 0.0, 0.0, 0.375, 0.6874922060945993, 0.7429192006597686, 1.0, 1.0, 0.7, 0.3218667490281998], 
reward next is 0.1531, 
noisyNet noise sample is [array([1.49331], dtype=float32), 1.6485627]. 
=============================================
[2019-04-16 12:39:09,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.61945796e-01 1.45999347e-05 6.10432608e-07 1.21489131e-06
 1.12302665e-07 1.29400323e-05 2.17912424e-10 4.37931716e-01
 5.14356316e-06 8.61923399e-05 1.71730198e-06], sum to 1.0000
[2019-04-16 12:39:09,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1332
[2019-04-16 12:39:09,701] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 158.0, 114.0, 19.0, 18.54440236693992, -0.909093303267067, 0.0, 1.0, 50.0, 111.39471050963444], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2972400.0000, 
sim time next is 2973600.0000, 
raw observation next is [-4.0, 71.0, 166.0, 78.0, 19.0, 19.68715627449476, -0.9640353311073913, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3518005540166205, 0.71, 0.5533333333333333, 0.0861878453038674, 0.08333333333333333, 0.14059635620789676, 0.1786548896308696, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03521447], dtype=float32), -0.5515895]. 
=============================================
[2019-04-16 12:39:11,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5123543e-02 7.0612113e-11 3.9825136e-13 4.0347646e-13 2.8644031e-16
 7.7908835e-10 1.0178202e-20 9.3487644e-01 2.9792168e-13 1.8614437e-09
 2.1222833e-12], sum to 1.0000
[2019-04-16 12:39:11,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6557
[2019-04-16 12:39:11,792] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 67.0, 10.0, 100.8333333333333, 22.5, 26.50781839716237, 0.6903852059092085, 1.0, 1.0, 50.0, 36.677029669636894], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3433200.0000, 
sim time next is 3434400.0000, 
raw observation next is [2.0, 67.0, 0.0, 0.0, 22.5, 26.67604431097005, 0.6903053843608462, 1.0, 1.0, 50.0, 37.777156450708134], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.67, 0.0, 0.0, 0.375, 0.7230036925808374, 0.7301017947869487, 1.0, 1.0, 0.7, 0.3777715645070813], 
reward next is 0.0972, 
noisyNet noise sample is [array([1.463367], dtype=float32), -1.7088493]. 
=============================================
[2019-04-16 12:39:16,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6589782e-01 2.3728013e-08 4.8041876e-10 2.9910794e-09 1.2189138e-12
 6.3138835e-08 3.4684714e-15 8.3410192e-01 6.6109602e-09 2.3059549e-07
 2.8639330e-10], sum to 1.0000
[2019-04-16 12:39:16,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1263
[2019-04-16 12:39:16,174] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 23.95058279057658, 0.1638973225761724, 0.0, 1.0, 50.0, 53.2811144557713], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3211200.0000, 
sim time next is 3212400.0000, 
raw observation next is [-1.333333333333333, 100.0, 0.0, 0.0, 19.0, 23.77691481240278, 0.0220380727013869, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.42566943674976926, 1.0, 0.0, 0.0, 0.08333333333333333, 0.48140956770023163, 0.5073460242337956, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5924293], dtype=float32), 0.81250983]. 
=============================================
[2019-04-16 12:39:20,558] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.8883526e-01 6.1468356e-08 3.9136738e-10 1.1624454e-09 4.2974235e-12
 3.2349394e-07 5.1311253e-15 7.1116406e-01 1.9031794e-09 3.4172658e-07
 1.8264478e-09], sum to 1.0000
[2019-04-16 12:39:20,558] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1637
[2019-04-16 12:39:20,581] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.666666666666667, 42.66666666666666, 111.5, 811.0, 19.0, 24.56086592347109, 0.251698724493626, 0.0, 1.0, 50.0, 32.69711902419348], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3678000.0000, 
sim time next is 3679200.0000, 
raw observation next is [6.0, 43.0, 108.5, 797.0, 19.0, 24.64106357797316, 0.1950373033933773, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6288088642659281, 0.43, 0.3616666666666667, 0.8806629834254144, 0.08333333333333333, 0.5534219648310966, 0.565012434464459, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06490786], dtype=float32), -1.2827628]. 
=============================================
[2019-04-16 12:39:21,372] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.2077408e-01 1.1295355e-06 1.7336587e-08 5.6070885e-08 3.9461742e-10
 3.5976072e-06 1.6364285e-11 1.7921311e-01 5.2603948e-08 7.9461797e-06
 4.9981708e-08], sum to 1.0000
[2019-04-16 12:39:21,372] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9010
[2019-04-16 12:39:21,404] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 22.20574200727938, -0.3611093741608769, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3715200.0000, 
sim time next is 3716400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 22.33742409730777, -0.1825121806651834, 0.0, 1.0, 50.0, 71.58152153961733], 
processed observation next is [1.0, 0.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.3614520081089809, 0.4391626064449388, 0.0, 1.0, 0.7, 0.7158152153961733], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4062483], dtype=float32), -0.04288088]. 
=============================================
[2019-04-16 12:39:21,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.3480150e-01 4.5066119e-07 5.4759299e-09 1.6788864e-08 5.5285870e-11
 1.5654078e-06 2.5087434e-12 1.6519448e-01 1.6375976e-08 1.9584850e-06
 1.6368512e-08], sum to 1.0000
[2019-04-16 12:39:21,475] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2440
[2019-04-16 12:39:21,511] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 23.40353568774569, -0.07040951722251027, 0.0, 1.0, 50.0, 43.46039350034344], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3718800.0000, 
sim time next is 3720000.0000, 
raw observation next is [-3.0, 69.0, 0.0, 0.0, 19.0, 23.39182743111405, -0.1916993684043382, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.69, 0.0, 0.0, 0.08333333333333333, 0.4493189525928374, 0.43610021053188724, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4062483], dtype=float32), -0.04288088]. 
=============================================
[2019-04-16 12:39:21,533] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[39.755222]
 [38.263596]
 [38.204433]
 [36.22762 ]
 [37.74342 ]
 [38.044525]
 [38.11535 ]
 [38.43547 ]
 [37.43559 ]
 [37.453526]
 [38.482426]
 [39.543316]
 [40.373585]
 [40.714443]
 [40.452305]
 [41.63611 ]
 [43.053677]
 [43.203423]
 [43.64986 ]
 [45.131542]
 [45.60803 ]
 [45.77039 ]
 [45.380474]
 [46.815563]
 [46.018192]], R is [[40.59885025]
 [40.23326111]
 [39.85543823]
 [39.45688248]
 [40.06231308]
 [40.66168976]
 [41.25507355]
 [41.84252167]
 [41.42409515]
 [42.00985336]
 [42.58975601]
 [43.16386032]
 [43.73222351]
 [44.2949028 ]
 [43.85195541]
 [44.41343689]
 [44.96930313]
 [45.51961136]
 [46.06441498]
 [46.60377121]
 [46.26299667]
 [45.9269371 ]
 [45.46767807]
 [46.01300049]
 [45.69298553]].
[2019-04-16 12:39:22,418] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.6169546e-01 4.2496161e-08 5.0557950e-11 1.7596212e-10 1.5157126e-12
 2.3158634e-08 3.0563458e-15 4.3830323e-01 1.4781542e-09 1.2245013e-06
 3.8844375e-10], sum to 1.0000
[2019-04-16 12:39:22,419] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2615
[2019-04-16 12:39:22,447] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 60.0, 0.0, 0.0, 19.0, 23.72283221402937, -0.009422231035758177, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3884400.0000, 
sim time next is 3885600.0000, 
raw observation next is [-1.333333333333333, 61.66666666666667, 0.0, 0.0, 19.0, 23.23930301672619, -0.1139546823637751, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.42566943674976926, 0.6166666666666667, 0.0, 0.0, 0.08333333333333333, 0.4366085847271825, 0.4620151058787416, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5287378], dtype=float32), 0.63424075]. 
=============================================
[2019-04-16 12:39:25,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5579846e-01 5.9776767e-07 4.9396580e-09 3.8654655e-08 1.4906007e-10
 3.4234472e-06 1.3368223e-12 2.4418806e-01 1.6241503e-07 9.1456968e-06
 2.5697005e-08], sum to 1.0000
[2019-04-16 12:39:25,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6487
[2019-04-16 12:39:25,861] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.0, 24.0, 113.5, 789.5, 19.0, 24.32723644365567, 0.0943253788917466, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3668400.0000, 
sim time next is 3669600.0000, 
raw observation next is [9.333333333333334, 31.0, 115.1666666666667, 807.1666666666666, 19.0, 24.08158435616149, 0.04631480079346503, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.7211449676823639, 0.31, 0.383888888888889, 0.8918968692449355, 0.08333333333333333, 0.5067986963467908, 0.515438266931155, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7228294], dtype=float32), 0.63711727]. 
=============================================
[2019-04-16 12:39:31,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1719602e-01 6.6646377e-09 8.9479604e-11 8.4138994e-11 2.5196371e-14
 5.2296503e-08 1.2494399e-17 3.8280383e-01 1.2804532e-10 4.1817458e-08
 1.0120394e-10], sum to 1.0000
[2019-04-16 12:39:31,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3376
[2019-04-16 12:39:31,196] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 46.0, 83.16666666666666, 689.3333333333333, 22.5, 26.36046024341441, 0.5665993522850699, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3858000.0000, 
sim time next is 3859200.0000, 
raw observation next is [3.0, 45.0, 75.5, 634.0, 22.5, 26.20126869780715, 0.4387046955437863, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.25166666666666665, 0.7005524861878453, 0.375, 0.6834390581505959, 0.6462348985145955, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6396767], dtype=float32), -0.42993337]. 
=============================================
[2019-04-16 12:39:37,206] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.5945808e-01 1.4770642e-07 2.2764872e-09 5.2032831e-09 3.4681740e-11
 8.6598953e-07 6.3990818e-14 5.4053819e-01 3.0052341e-08 2.6452972e-06
 5.5262142e-09], sum to 1.0000
[2019-04-16 12:39:37,208] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1530
[2019-04-16 12:39:37,229] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.333333333333333, 62.66666666666667, 20.0, 190.0, 19.0, 24.39780590809247, 0.05256622955703291, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4297200.0000, 
sim time next is 4298400.0000, 
raw observation next is [6.2, 64.0, 0.0, 0.0, 19.0, 23.87939350482472, -0.0650714001355936, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.6343490304709142, 0.64, 0.0, 0.0, 0.08333333333333333, 0.48994945873539325, 0.47830953328813547, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1238198], dtype=float32), -0.4917491]. 
=============================================
[2019-04-16 12:39:37,380] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-16 12:39:37,381] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:39:37,381] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:39:37,382] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:39:37,382] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:39:37,382] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:39:37,383] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:39:37,387] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run13
[2019-04-16 12:39:37,387] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run13
[2019-04-16 12:39:37,419] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run13
[2019-04-16 12:39:47,085] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:NoisyNet noise sample: [array([0.03100499], dtype=float32), 0.07868877]
[2019-04-16 12:39:47,085] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:Observation this: [-6.666666666666668, 60.00000000000001, 36.0, 164.0, 22.5, 20.08650887212719, -0.9306601796471985, 1.0, 1.0, 15.0, 0.0]
[2019-04-16 12:39:47,085] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:Observation forecast: []
[2019-04-16 12:39:47,085] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Softmax [5.58403194e-01 6.56153452e-06 3.05823590e-07 6.49934577e-07
 1.00650395e-08 8.94332334e-06 1.17491350e-10 4.41539764e-01
 1.22801532e-06 3.88629960e-05 4.78097320e-07], sampled 0.46767574586880845
[2019-04-16 12:40:15,502] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([0.03100499], dtype=float32), 0.07868877]
[2019-04-16 12:40:15,502] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation this: [-4.300000000000001, 79.0, 149.3333333333333, 0.0, 22.5, 22.18176622751104, -0.5538350225555139, 1.0, 1.0, 15.0, 0.0]
[2019-04-16 12:40:15,502] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-16 12:40:15,503] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Softmax [6.1302352e-01 6.2983830e-08 5.9839994e-10 2.4734015e-09 8.5985134e-12
 1.1881304e-07 1.9099870e-14 3.8697582e-01 4.4056496e-09 4.2857849e-07
 1.7441132e-09], sampled 0.4288446215348555
[2019-04-16 12:40:18,912] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:NoisyNet noise sample: [array([0.03100499], dtype=float32), 0.07868877]
[2019-04-16 12:40:18,912] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation this: [-8.083088882, 67.57153615333334, 114.27900187, 12.00450568333333, 22.5, 21.96263853024725, -0.4517231886964704, 1.0, 1.0, 50.0, 59.06345423254588]
[2019-04-16 12:40:18,913] A3C_EVAL-Part4-Light-Pit-Test-v6 DEBUG:Observation forecast: []
[2019-04-16 12:40:18,913] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Softmax [6.0860825e-01 2.5532325e-08 2.0026392e-10 7.7819257e-10 2.3625971e-12
 5.9805160e-08 3.8296706e-15 3.9139155e-01 1.5239352e-09 1.7396601e-07
 5.6234867e-10], sampled 0.9308762158034694
[2019-04-16 12:40:46,292] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2517.1560 92641.8092 277.4256
[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,316] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:46,432] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,199] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2359.6921 100018.8159 -182.5581
[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,219] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:40:56,336] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,022] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2303.8585 102868.8111 -273.1181
[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,041] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:01,153] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:41:02,044] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 600000, evaluation results [600000.0, 2359.6921273800167, 100018.81590379, -182.55809295533246, 2517.155992729433, 92641.80915454135, 277.4255575660898, 2303.858503165067, 102868.81106719276, -273.1181102994619]
[2019-04-16 12:41:02,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7291054e-01 1.1339077e-09 2.8319970e-12 1.2002419e-11 1.5367299e-14
 5.2899840e-10 1.0380542e-17 2.2708948e-01 6.1532231e-11 6.4110259e-09
 1.8849449e-12], sum to 1.0000
[2019-04-16 12:41:02,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2916
[2019-04-16 12:41:02,095] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 78.0, 45.0, 9.166666666666664, 22.5, 25.72271888212241, 0.4515084653466654, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4466400.0000, 
sim time next is 4467600.0000, 
raw observation next is [0.0, 78.0, 37.0, 27.5, 22.5, 25.67147718441713, 0.3218289483229537, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.78, 0.12333333333333334, 0.03038674033149171, 0.375, 0.6392897653680943, 0.6072763161076512, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00179856], dtype=float32), 0.4643149]. 
=============================================
[2019-04-16 12:41:04,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9332139e-01 2.7712153e-06 2.8997762e-09 1.2420608e-08 1.5020982e-10
 1.5441180e-06 3.9568465e-13 5.0666904e-01 1.2740182e-08 5.1994298e-06
 2.8750119e-08], sum to 1.0000
[2019-04-16 12:41:05,000] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3664
[2019-04-16 12:41:05,006] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8666666666666667, 72.33333333333334, 0.0, 0.0, 19.0, 22.24758305836579, -0.2843191566915677, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4508400.0000, 
sim time next is 4509600.0000, 
raw observation next is [-0.8333333333333334, 71.66666666666666, 0.0, 0.0, 19.0, 22.04648437178698, -0.3089804852360791, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.43951985226223456, 0.7166666666666666, 0.0, 0.0, 0.08333333333333333, 0.3372070309822484, 0.39700650492130696, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5869195], dtype=float32), 0.51647663]. 
=============================================
[2019-04-16 12:41:06,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5305960e-01 9.0429761e-09 1.0069665e-10 1.9630794e-10 2.7136144e-13
 2.1149511e-08 1.3099762e-15 7.4694026e-01 6.2234173e-10 1.4328221e-07
 2.7910033e-10], sum to 1.0000
[2019-04-16 12:41:06,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1603
[2019-04-16 12:41:06,584] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 19.0, 24.8422620228845, 0.446333849312597, 0.0, 1.0, 50.0, 39.73063993188949], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4653600.0000, 
sim time next is 4654800.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 25.05070724034078, 0.3647589474429916, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.5875589366950651, 0.6215863158143305, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3530561], dtype=float32), -1.598178]. 
=============================================
[2019-04-16 12:41:09,196] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7512732e-01 1.9172013e-07 5.9103678e-10 3.5748251e-09 3.6779555e-12
 3.4112858e-08 4.9893558e-14 1.2487230e-01 1.6436513e-08 2.3332062e-07
 1.6620040e-09], sum to 1.0000
[2019-04-16 12:41:09,196] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3275
[2019-04-16 12:41:09,217] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 19.0, 24.55301398841787, 0.2195280348705813, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4668000.0000, 
sim time next is 4669200.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 24.31146077655436, 0.1787549261059509, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.5259550647128632, 0.5595849753686503, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6327612], dtype=float32), 0.3824284]. 
=============================================
[2019-04-16 12:41:11,044] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.24237502e-01 5.25213650e-08 6.77819745e-10 1.00583653e-09
 3.99121735e-13 1.21570105e-08 7.74759755e-16 7.75762320e-01
 2.07595097e-09 6.08445561e-08 2.18233445e-10], sum to 1.0000
[2019-04-16 12:41:11,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5366
[2019-04-16 12:41:11,069] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 68.0, 0.0, 0.0, 19.0, 26.24844509068563, 0.6648582049656779, 0.0, 1.0, 50.0, 37.416880919931096], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4428000.0000, 
sim time next is 4429200.0000, 
raw observation next is [2.666666666666667, 72.0, 0.0, 0.0, 19.0, 26.28633835584134, 0.6582406079223592, 0.0, 1.0, 50.0, 37.39724383683249], 
processed observation next is [1.0, 0.2608695652173913, 0.5364727608494922, 0.72, 0.0, 0.0, 0.08333333333333333, 0.6905281963201118, 0.7194135359741197, 0.0, 1.0, 0.7, 0.3739724383683249], 
reward next is 0.1010, 
noisyNet noise sample is [array([0.78731555], dtype=float32), 0.14585918]. 
=============================================
[2019-04-16 12:41:12,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3031144e-01 4.0974935e-10 3.1909593e-11 3.7919969e-11 4.9764510e-14
 8.6583647e-09 5.2148904e-17 6.9688566e-02 1.8930318e-10 4.6475211e-08
 1.2413195e-10], sum to 1.0000
[2019-04-16 12:41:12,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2496
[2019-04-16 12:41:12,128] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 23.74490860746287, 0.08734785131069212, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4485600.0000, 
sim time next is 4486800.0000, 
raw observation next is [-0.09999999999999999, 72.0, 0.0, 0.0, 19.0, 23.3098456811134, -0.07640266040091721, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4598337950138504, 0.72, 0.0, 0.0, 0.08333333333333333, 0.44248714009278345, 0.4745324465330276, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3642278], dtype=float32), -0.924578]. 
=============================================
[2019-04-16 12:41:13,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.54123795e-01 1.53537694e-09 2.10645338e-11 4.50711066e-11
 7.35565580e-14 9.99064564e-09 9.81687446e-18 4.58761901e-02
 1.08431396e-10 1.42182985e-08 2.63190442e-11], sum to 1.0000
[2019-04-16 12:41:13,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2371
[2019-04-16 12:41:13,507] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.2, 46.0, 78.5, 146.0, 22.5, 25.30186104465388, 0.3219193749025738, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4640400.0000, 
sim time next is 4641600.0000, 
raw observation next is [4.800000000000001, 47.0, 52.83333333333333, 145.3333333333333, 22.5, 25.35879787660702, 0.295647980730631, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5955678670360112, 0.47, 0.1761111111111111, 0.16058931860036826, 0.375, 0.6132331563839184, 0.5985493269102103, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5786696], dtype=float32), 0.5498916]. 
=============================================
[2019-04-16 12:41:14,124] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.0606523e-01 7.2945167e-10 8.6915067e-12 8.5620139e-12 7.5136015e-15
 1.2792806e-09 5.8573486e-19 5.9393477e-01 1.2021315e-11 3.1761815e-09
 9.4080944e-11], sum to 1.0000
[2019-04-16 12:41:14,124] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9549
[2019-04-16 12:41:14,152] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.0, 78.0, 0.0, 0.0, 22.5, 25.62213750068758, 0.4801784944783639, 1.0, 1.0, 50.0, 38.65478555413043], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4730400.0000, 
sim time next is 4731600.0000, 
raw observation next is [-0.3333333333333333, 78.0, 0.0, 0.0, 22.5, 25.68504841380631, 0.4685367004557621, 1.0, 1.0, 50.0, 38.86047559963521], 
processed observation next is [1.0, 0.782608695652174, 0.4533702677747, 0.78, 0.0, 0.0, 0.375, 0.6404207011505259, 0.6561789001519207, 1.0, 1.0, 0.7, 0.3886047559963521], 
reward next is 0.0864, 
noisyNet noise sample is [array([-1.2345368], dtype=float32), -0.94882786]. 
=============================================
[2019-04-16 12:41:14,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7086977e-01 1.4999397e-08 3.5791023e-10 1.3238430e-09 2.0395452e-13
 4.1053912e-08 4.2644218e-16 3.2913008e-01 4.7153498e-10 1.1288862e-07
 8.3102060e-11], sum to 1.0000
[2019-04-16 12:41:14,825] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4193
[2019-04-16 12:41:14,847] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 25.4321908575432, 0.5416627918940992, 0.0, 1.0, 50.0, 41.38286920192567], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4485600.0000, 
sim time next is 4486800.0000, 
raw observation next is [-0.09999999999999999, 72.0, 0.0, 0.0, 19.0, 25.27998842041306, 0.3376178339326785, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4598337950138504, 0.72, 0.0, 0.0, 0.08333333333333333, 0.6066657017010882, 0.6125392779775595, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5600442], dtype=float32), -0.33365497]. 
=============================================
[2019-04-16 12:41:15,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.18577397e-01 2.57005382e-07 5.54373480e-09 2.88147799e-08
 1.15192904e-10 4.75606981e-07 5.78385592e-13 4.81417179e-01
 2.62638942e-08 4.50651532e-06 1.82882829e-08], sum to 1.0000
[2019-04-16 12:41:15,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1470
[2019-04-16 12:41:15,510] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 43.0, 0.0, 0.0, 19.0, 22.51581099882734, -0.4339213560234726, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4928400.0000, 
sim time next is 4929600.0000, 
raw observation next is [-0.3333333333333333, 45.33333333333334, 0.0, 0.0, 19.0, 21.85519144850434, -0.5340266346880355, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4533702677747, 0.4533333333333334, 0.0, 0.0, 0.08333333333333333, 0.32126595404202823, 0.32199112177065486, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44371387], dtype=float32), 0.6494668]. 
=============================================
[2019-04-16 12:41:17,421] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:17,588] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:17,950] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:18,103] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:18,179] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:18,338] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:18,422] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:18,422] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:18,430] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run10
[2019-04-16 12:41:18,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.9494917e-01 3.7783687e-07 3.9241169e-08 3.4500264e-08 1.3226469e-10
 4.8050820e-06 2.4583532e-12 2.0503807e-01 3.7353875e-08 7.4944419e-06
 4.1020982e-08], sum to 1.0000
[2019-04-16 12:41:18,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3371
[2019-04-16 12:41:18,826] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 132.5, 369.5, 19.0, 22.2694756470812, -0.3595272157840594, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4896000.0000, 
sim time next is 4897200.0000, 
raw observation next is [3.0, 45.0, 112.1666666666667, 334.5, 19.0, 22.04698036314301, -0.391250442722607, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.45, 0.373888888888889, 0.3696132596685083, 0.08333333333333333, 0.33724836359525084, 0.369583185759131, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15549192], dtype=float32), 0.40084258]. 
=============================================
[2019-04-16 12:41:18,954] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:18,955] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:18,973] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run10
[2019-04-16 12:41:19,183] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:19,184] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:19,189] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run10
[2019-04-16 12:41:21,369] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:21,487] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:21,546] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:21,659] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:21,955] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:22,141] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:22,366] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:22,370] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:22,376] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run10
[2019-04-16 12:41:22,485] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:22,485] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:22,489] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run10
[2019-04-16 12:41:22,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:22,961] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:22,965] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run10
[2019-04-16 12:41:23,740] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:23,948] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:24,165] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:24,258] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:24,351] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:24,441] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:24,749] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:24,749] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:24,753] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run10
[2019-04-16 12:41:24,776] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:24,931] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:25,166] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:25,166] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:25,174] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run10
[2019-04-16 12:41:25,261] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:25,261] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:25,264] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run10
[2019-04-16 12:41:25,776] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:25,776] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:25,780] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run10
[2019-04-16 12:41:26,979] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:26,988] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:27,185] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:27,236] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:27,980] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:27,980] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:27,989] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:27,989] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:27,995] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run10
[2019-04-16 12:41:28,025] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run10
[2019-04-16 12:41:28,745] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:28,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3197179e-01 5.7839546e-09 2.5216685e-11 7.9736739e-10 1.2113354e-13
 1.0671365e-08 1.3771479e-15 5.6802690e-01 4.0673764e-10 1.3114518e-06
 3.2262737e-10], sum to 1.0000
[2019-04-16 12:41:28,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1171
[2019-04-16 12:41:28,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.6, 19.33333333333334, 0.0, 0.0, 19.0, 27.0092198112909, 0.7174415228851952, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5091600.0000, 
sim time next is 5092800.0000, 
raw observation next is [8.5, 19.66666666666666, 0.0, 0.0, 19.0, 26.38406159448993, 0.6333289845522275, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.698060941828255, 0.1966666666666666, 0.0, 0.0, 0.08333333333333333, 0.6986717995408274, 0.7111096615174092, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5773584], dtype=float32), 0.08182842]. 
=============================================
[2019-04-16 12:41:29,054] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:29,067] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:29,322] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:29,748] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:29,748] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:29,752] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run10
[2019-04-16 12:41:30,055] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:30,055] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:30,074] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run10
[2019-04-16 12:41:31,901] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:32,099] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:32,297] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:41:32,512] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-16 12:41:32,902] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:32,902] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:32,906] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run10
[2019-04-16 12:41:33,298] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:41:33,298] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:41:33,314] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run10
[2019-04-16 12:41:35,151] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.8291280e-01 7.7854111e-06 3.6968780e-07 2.5091836e-07 2.1532851e-09
 4.9083060e-06 5.7118633e-11 4.1706362e-01 3.4780294e-07 9.2850423e-06
 6.7032403e-07], sum to 1.0000
[2019-04-16 12:41:35,151] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1744
[2019-04-16 12:41:35,181] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.900000000000002, 78.0, 0.0, 0.0, 19.0, 16.81938837658268, -1.667338922769057, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 192000.0000, 
sim time next is 193200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 16.56682821094923, -1.723295597652316, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, -0.1194309824208976, -0.07443186588410537, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5991809], dtype=float32), 0.26348254]. 
=============================================
[2019-04-16 12:41:35,882] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1002221e-01 2.3274422e-08 1.5491204e-10 2.1410700e-09 2.5548166e-11
 6.7022057e-08 1.6387580e-14 2.8997761e-01 9.6243280e-10 4.4133994e-08
 1.1432943e-09], sum to 1.0000
[2019-04-16 12:41:35,882] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7148
[2019-04-16 12:41:35,916] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-2.433333333333333, 88.33333333333334, 0.0, 0.0, 19.0, 22.27008289207198, -0.4128793091816618, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 96000.0000, 
sim time next is 97200.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 19.0, 21.87791677900292, -0.3359406552632764, 0.0, 1.0, 50.0, 59.52428039236085], 
processed observation next is [1.0, 0.13043478260869565, 0.38504155124653744, 0.87, 0.0, 0.0, 0.08333333333333333, 0.32315973158357664, 0.3880197815789079, 0.0, 1.0, 0.7, 0.5952428039236085], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.543287], dtype=float32), -0.12645686]. 
=============================================
[2019-04-16 12:41:44,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5119777e-01 3.1887232e-06 2.3417934e-08 2.6890680e-07 1.7459841e-09
 2.4958974e-06 1.1231639e-11 4.4878137e-01 2.0440852e-07 1.4360023e-05
 3.5040031e-07], sum to 1.0000
[2019-04-16 12:41:44,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8895
[2019-04-16 12:41:44,865] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 19.0, 18.50380400138742, -1.230626246897302, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 104400.0000, 
sim time next is 105600.0000, 
raw observation next is [-5.566666666666667, 74.33333333333334, 0.0, 0.0, 19.0, 18.25631747191479, -1.131191190307262, 0.0, 1.0, 50.0, 70.82049314434386], 
processed observation next is [1.0, 0.21739130434782608, 0.3084025854108957, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.021359789326232576, 0.12293626989757933, 0.0, 1.0, 0.7, 0.7082049314434385], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28186622], dtype=float32), 1.6604451]. 
=============================================
[2019-04-16 12:41:53,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8924637e-01 1.4101726e-06 4.5167155e-08 8.7964445e-09 6.2162400e-11
 6.1926437e-07 1.6834029e-13 5.1074976e-01 1.2895738e-08 1.7779630e-06
 1.5945164e-09], sum to 1.0000
[2019-04-16 12:41:53,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7075
[2019-04-16 12:41:53,309] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-10.6, 48.33333333333333, 0.0, 0.0, 19.0, 17.94774923636217, -1.339646472976041, 0.0, 1.0, 50.0, 76.78565570546563], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 423600.0000, 
sim time next is 424800.0000, 
raw observation next is [-10.6, 49.0, 0.0, 0.0, 19.0, 18.43432045433505, -1.293221784774253, 0.0, 1.0, 50.0, 50.423864556131846], 
processed observation next is [1.0, 0.9565217391304348, 0.1689750692520776, 0.49, 0.0, 0.0, 0.08333333333333333, 0.03619337119458758, 0.06892607174191563, 0.0, 1.0, 0.7, 0.5042386455613185], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3655024], dtype=float32), 0.15178956]. 
=============================================
[2019-04-16 12:41:56,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2649921e-01 5.0552762e-06 1.1691046e-06 4.9579734e-07 1.0706648e-08
 1.1021602e-05 1.4237929e-10 4.7346896e-01 4.4128299e-07 1.2933141e-05
 6.6038479e-07], sum to 1.0000
[2019-04-16 12:41:56,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2221
[2019-04-16 12:41:56,667] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.0, 0.0, 0.0, 19.0, 17.7361718727814, -1.472564969515859, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 622800.0000, 
sim time next is 624000.0000, 
raw observation next is [-4.5, 67.0, 0.0, 0.0, 19.0, 17.30440082073913, -1.571164759547216, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.3379501385041552, 0.67, 0.0, 0.0, 0.08333333333333333, -0.05796659827173922, -0.023721586515738673, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6668504], dtype=float32), -0.551449]. 
=============================================
[2019-04-16 12:41:57,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5270983e-01 2.5713180e-06 1.7105000e-08 4.8183966e-07 3.2777159e-10
 1.6741877e-06 2.2651410e-12 6.4727175e-01 4.6771615e-07 1.3268802e-05
 2.5070674e-08], sum to 1.0000
[2019-04-16 12:41:57,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7342
[2019-04-16 12:41:57,692] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-10.8, 51.0, 0.0, 0.0, 19.0, 19.54651124870118, -1.205701615224507, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 441600.0000, 
sim time next is 442800.0000, 
raw observation next is [-10.6, 49.0, 0.0, 0.0, 19.0, 19.08451073759251, -1.121541480827059, 0.0, 1.0, 50.0, 67.12301790048438], 
processed observation next is [1.0, 0.13043478260869565, 0.1689750692520776, 0.49, 0.0, 0.0, 0.08333333333333333, 0.0903758947993758, 0.12615283972431368, 0.0, 1.0, 0.7, 0.6712301790048438], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08250579], dtype=float32), 0.07238393]. 
=============================================
[2019-04-16 12:42:09,390] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0708839e-01 3.4247648e-08 1.2538302e-09 2.5079627e-09 2.2166795e-12
 3.9872358e-08 8.9815037e-15 3.9291146e-01 2.2607307e-09 5.2244143e-08
 1.1980160e-09], sum to 1.0000
[2019-04-16 12:42:09,390] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4927
[2019-04-16 12:42:09,457] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.1, 73.33333333333334, 89.0, 40.83333333333334, 22.5, 21.26581600105836, -0.6507764858920023, 1.0, 1.0, 50.0, 80.26891000130308], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 724800.0000, 
sim time next is 726000.0000, 
raw observation next is [-1.9, 70.66666666666666, 107.3333333333333, 52.16666666666666, 22.5, 21.96042458005535, -0.6878837593160502, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4099722991689751, 0.7066666666666666, 0.3577777777777777, 0.05764272559852669, 0.375, 0.3300353816712791, 0.2707054135613166, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.1175, 
noisyNet noise sample is [array([1.141353], dtype=float32), -1.0202794]. 
=============================================
[2019-04-16 12:42:10,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.04900885e-01 1.02168705e-07 6.32340069e-10 1.14859189e-09
 5.26313671e-12 8.76012507e-09 2.99131125e-15 1.95098907e-01
 1.35130074e-09 6.72340477e-08 1.09232734e-09], sum to 1.0000
[2019-04-16 12:42:10,732] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6539
[2019-04-16 12:42:10,785] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 45.66666666666667, 82.16666666666667, 26.33333333333334, 22.5, 22.17659588369217, -0.5909859058682335, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 747600.0000, 
sim time next is 748800.0000, 
raw observation next is [-0.6, 45.0, 76.5, 17.0, 22.5, 22.00951349259854, -0.6386327199062378, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.44598337950138506, 0.45, 0.255, 0.01878453038674033, 0.375, 0.33412612438321165, 0.2871224266979207, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.5195, 
noisyNet noise sample is [array([-0.722397], dtype=float32), 0.69845736]. 
=============================================
[2019-04-16 12:42:21,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1542358e-01 4.2638215e-10 8.1367881e-12 1.1845732e-11 7.5566706e-15
 1.1084795e-08 2.9411676e-18 2.8457639e-01 6.9781896e-11 1.2670732e-08
 8.9536475e-11], sum to 1.0000
[2019-04-16 12:42:21,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0689
[2019-04-16 12:42:21,740] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 81.0, 0.0, 0.0, 22.5, 21.31623025584912, -0.2443657759675263, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1017600.0000, 
sim time next is 1018800.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 22.5, 22.70704297696723, -0.1371279591477959, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.8614958448753465, 0.81, 0.0, 0.0, 0.375, 0.39225358141393585, 0.45429068028406805, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.55977607], dtype=float32), 0.23954394]. 
=============================================
[2019-04-16 12:42:22,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8385299e-01 1.1730776e-10 1.8671950e-12 2.2251825e-12 1.4454049e-15
 2.2476088e-10 1.0792249e-18 2.1614708e-01 6.3299539e-12 2.0108937e-09
 2.0277259e-12], sum to 1.0000
[2019-04-16 12:42:22,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7136
[2019-04-16 12:42:22,402] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.9000000000000001, 94.0, 22.33333333333333, 0.0, 22.5, 25.59538756612454, 0.5483563165338722, 1.0, 1.0, 50.0, 57.43378225688349], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1354800.0000, 
sim time next is 1356000.0000, 
raw observation next is [0.7000000000000001, 95.0, 15.0, 0.0, 22.5, 25.50417803803709, 0.4094641006913554, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4819944598337951, 0.95, 0.05, 0.0, 0.375, 0.6253481698364242, 0.6364880335637851, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32621464], dtype=float32), 0.061370116]. 
=============================================
[2019-04-16 12:42:33,505] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8904980e-01 7.1365192e-10 9.5217302e-13 1.8090942e-11 9.4182593e-15
 2.8498395e-09 9.7449784e-18 2.1095023e-01 3.3791497e-11 2.5272557e-09
 1.0568628e-11], sum to 1.0000
[2019-04-16 12:42:33,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4517
[2019-04-16 12:42:33,526] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.3, 51.0, 64.0, 18.5, 22.5, 27.00496373548458, 0.7632645603284466, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1612800.0000, 
sim time next is 1614000.0000, 
raw observation next is [12.93333333333334, 52.00000000000001, 54.66666666666667, 30.83333333333334, 22.5, 26.47144312609939, 0.6747019555596796, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8208679593721148, 0.52, 0.18222222222222223, 0.03406998158379374, 0.375, 0.7059535938416159, 0.7249006518532265, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.876058], dtype=float32), 1.8170092]. 
=============================================
[2019-04-16 12:42:33,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8575988e-01 8.1993912e-10 9.0861333e-14 1.8994728e-12 1.1176743e-15
 2.2408662e-10 4.6384572e-19 4.1424012e-01 6.3841142e-12 2.2789437e-10
 4.2412181e-12], sum to 1.0000
[2019-04-16 12:42:33,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1034
[2019-04-16 12:42:33,990] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.86666666666667, 58.33333333333334, 204.8333333333333, 228.1666666666667, 22.5, 26.68842519841724, 0.8007261528670183, 1.0, 1.0, 50.0, 47.166071109705086], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1597200.0000, 
sim time next is 1598400.0000, 
raw observation next is [11.6, 57.0, 182.5, 186.5, 22.5, 26.85435423069381, 0.7212692877837834, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.7839335180055402, 0.57, 0.6083333333333333, 0.20607734806629835, 0.375, 0.7378628525578176, 0.7404230959279278, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5416112], dtype=float32), 0.14120427]. 
=============================================
[2019-04-16 12:42:35,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.14635503e-01 1.18868797e-06 7.59640884e-09 2.68926996e-08
 3.95305316e-10 2.04394632e-06 5.38911841e-12 4.85359550e-01
 1.16428396e-07 1.45323509e-06 7.22466851e-08], sum to 1.0000
[2019-04-16 12:42:35,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2704
[2019-04-16 12:42:35,472] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 86.0, 0.0, 0.0, 19.0, 19.09010869772959, -1.026545804667802, 0.0, 1.0, 50.0, 66.13312686976252], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1879200.0000, 
sim time next is 1880400.0000, 
raw observation next is [-4.833333333333334, 85.0, 0.0, 0.0, 19.0, 19.2373078259907, -1.134452199356945, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.32871652816251157, 0.85, 0.0, 0.0, 0.08333333333333333, 0.10310898549922509, 0.12184926688101834, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.80337393], dtype=float32), 1.5293939]. 
=============================================
[2019-04-16 12:42:36,176] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.45689535e-01 2.93039034e-06 3.88002661e-08 1.63748908e-07
 1.36345668e-09 2.66725783e-06 3.06634128e-11 6.54291511e-01
 1.31837709e-07 1.29955515e-05 6.46543157e-08], sum to 1.0000
[2019-04-16 12:42:36,177] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2770
[2019-04-16 12:42:36,188] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.533333333333333, 78.33333333333334, 0.0, 0.0, 19.0, 20.42527415321299, -0.8257566258826817, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1838400.0000, 
sim time next is 1839600.0000, 
raw observation next is [-6.7, 78.0, 0.0, 0.0, 19.0, 19.79025278194488, -0.944892151664876, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.14918773182873993, 0.18503594944504134, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2811261], dtype=float32), 2.179651]. 
=============================================
[2019-04-16 12:42:36,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2034764e-01 5.8130458e-06 7.4192002e-07 2.8301881e-07 8.2002130e-09
 5.0771528e-06 2.7327409e-11 2.7960068e-01 8.0424286e-07 3.8139668e-05
 8.4834221e-07], sum to 1.0000
[2019-04-16 12:42:36,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5474
[2019-04-16 12:42:36,607] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 82.0, 0.0, 0.0, 19.0, 16.98772538441459, -1.652356226430615, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1921200.0000, 
sim time next is 1922400.0000, 
raw observation next is [-8.9, 82.0, 0.0, 0.0, 19.0, 16.55038389744021, -1.719687903155697, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.21606648199445982, 0.82, 0.0, 0.0, 0.08333333333333333, -0.12080134187998255, -0.07322930105189902, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1882006], dtype=float32), -0.8087968]. 
=============================================
[2019-04-16 12:42:37,832] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.3392022e-01 2.6354824e-06 1.8316173e-08 1.0161023e-07 1.6546708e-09
 9.5785290e-06 3.7263643e-12 2.6605734e-01 7.1289797e-08 9.9792996e-06
 5.8350743e-08], sum to 1.0000
[2019-04-16 12:42:37,832] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7237
[2019-04-16 12:42:37,853] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 82.0, 0.0, 0.0, 19.0, 20.59538039220427, -0.7185260181306813, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1791600.0000, 
sim time next is 1792800.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 19.0, 20.15114361335441, -0.8173436289416413, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.08333333333333333, 0.17926196777953418, 0.22755212368611957, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08982763], dtype=float32), -1.4368001]. 
=============================================
[2019-04-16 12:42:42,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8695174e-01 6.6975967e-06 1.7551997e-07 9.2920658e-07 4.4777613e-09
 6.2963541e-06 4.5392232e-11 8.1300771e-01 1.0283349e-06 2.5054520e-05
 4.1928701e-07], sum to 1.0000
[2019-04-16 12:42:42,792] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5589
[2019-04-16 12:42:42,829] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 19.0, 19.15698142384243, -0.9688093574655916, 0.0, 1.0, 50.0, 51.97941266543893], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 1832400.0000, 
sim time next is 1833600.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 19.0, 19.4828289120484, -0.9171061801496007, 0.0, 1.0, 50.0, 51.08228996558865], 
processed observation next is [0.0, 0.21739130434782608, 0.2908587257617729, 0.79, 0.0, 0.0, 0.08333333333333333, 0.1235690760040334, 0.19429793995013311, 0.0, 1.0, 0.7, 0.5108228996558865], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6702749], dtype=float32), -0.13046099]. 
=============================================
[2019-04-16 12:42:49,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0629411e-01 4.9824447e-09 2.0489947e-10 4.5262971e-10 2.1630731e-13
 2.5985820e-08 2.8578633e-15 5.9370589e-01 1.8719375e-09 2.8266586e-08
 4.3764070e-10], sum to 1.0000
[2019-04-16 12:42:49,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9374
[2019-04-16 12:42:50,045] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 71.0, 130.0, 0.0, 22.5, 22.60953615163803, -0.4244746238774977, 1.0, 1.0, 50.0, 55.85205829671938], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2199600.0000, 
sim time next is 2200800.0000, 
raw observation next is [-4.300000000000001, 70.0, 138.6666666666667, 0.0, 22.5, 22.77983922016771, -0.3784927474338126, 1.0, 1.0, 50.0, 54.68163593628229], 
processed observation next is [1.0, 0.4782608695652174, 0.34349030470914127, 0.7, 0.46222222222222237, 0.0, 0.375, 0.3983199350139757, 0.3738357508553958, 1.0, 1.0, 0.7, 0.5468163593628229], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11267281], dtype=float32), 0.092401884]. 
=============================================
[2019-04-16 12:42:56,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2313724e-01 6.0356314e-10 5.9661850e-12 4.6901729e-11 3.2811027e-14
 7.7936491e-10 6.1543793e-18 8.7686270e-01 1.0160099e-10 2.1400428e-08
 1.2593512e-11], sum to 1.0000
[2019-04-16 12:42:56,009] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5608
[2019-04-16 12:42:56,060] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 22.5, 23.08582136821117, -0.1654329619318412, 1.0, 1.0, 50.0, 42.926940593575274], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2052000.0000, 
sim time next is 2053200.0000, 
raw observation next is [-3.9, 82.0, 0.0, 0.0, 22.5, 23.34840174407341, -0.168089982393482, 1.0, 1.0, 50.0, 42.82483012527693], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.82, 0.0, 0.0, 0.375, 0.44570014533945085, 0.44397000586883933, 1.0, 1.0, 0.7, 0.4282483012527693], 
reward next is 0.0468, 
noisyNet noise sample is [array([-0.6755409], dtype=float32), -1.0765294]. 
=============================================
[2019-04-16 12:42:57,612] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4362637e-01 2.1783646e-07 1.3025042e-10 1.4634794e-09 2.3882693e-12
 7.3519281e-08 3.6852438e-15 4.5637307e-01 1.8799551e-09 2.5519572e-07
 5.2112368e-09], sum to 1.0000
[2019-04-16 12:42:57,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9356
[2019-04-16 12:42:57,697] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.199999999999999, 72.33333333333333, 104.5, 375.8333333333334, 22.5, 22.05183327365074, -0.4864545594914795, 1.0, 1.0, 50.0, 58.46748369369523], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2194800.0000, 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 109.5, 225.5, 22.5, 22.44847769208713, -0.4326881310165731, 1.0, 1.0, 50.0, 42.41092080960351], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.71, 0.365, 0.24917127071823206, 0.375, 0.3707064743405943, 0.35577062299447565, 1.0, 1.0, 0.7, 0.4241092080960351], 
reward next is 0.0509, 
noisyNet noise sample is [array([-1.2922891], dtype=float32), 0.14754203]. 
=============================================
[2019-04-16 12:42:58,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5357134e-01 9.4327646e-08 7.8486696e-11 4.9758825e-10 1.2589341e-12
 5.2410094e-08 1.3126578e-15 4.4642833e-01 1.2090824e-09 1.8789120e-07
 1.8222210e-09], sum to 1.0000
[2019-04-16 12:42:58,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9449
[2019-04-16 12:42:58,702] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.899999999999999, 69.0, 126.1666666666667, 47.49999999999999, 22.5, 22.55991294564542, -0.4771100811852543, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2212800.0000, 
sim time next is 2214000.0000, 
raw observation next is [-3.9, 68.0, 138.5, 142.5, 22.5, 22.58585008781282, -0.3138321573447648, 1.0, 1.0, 50.0, 70.44438043738184], 
processed observation next is [1.0, 0.6521739130434783, 0.3545706371191136, 0.68, 0.46166666666666667, 0.1574585635359116, 0.375, 0.3821541739844016, 0.39538928088507835, 1.0, 1.0, 0.7, 0.7044438043738184], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2922891], dtype=float32), 0.14754203]. 
=============================================
[2019-04-16 12:42:59,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6137879e-01 1.6915097e-09 3.5957674e-11 5.8037030e-11 7.0808302e-14
 1.1865241e-09 1.3533694e-16 7.3862118e-01 2.4959573e-10 2.0047876e-08
 3.0557303e-11], sum to 1.0000
[2019-04-16 12:42:59,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7898
[2019-04-16 12:42:59,807] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 70.0, 0.0, 0.0, 19.0, 22.42035293936676, -0.3172978051046641, 0.0, 1.0, 50.0, 44.782043162672565], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2233200.0000, 
sim time next is 2234400.0000, 
raw observation next is [-5.0, 69.0, 0.0, 0.0, 19.0, 22.38015931172403, -0.3219913178578381, 0.0, 1.0, 50.0, 44.737971511897115], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.69, 0.0, 0.0, 0.08333333333333333, 0.3650132759770024, 0.392669560714054, 0.0, 1.0, 0.7, 0.4473797151189711], 
reward next is 0.0276, 
noisyNet noise sample is [array([0.9265606], dtype=float32), -0.05368044]. 
=============================================
[2019-04-16 12:42:59,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0433336e-01 5.5805476e-09 4.5123533e-11 4.4650426e-11 2.3276717e-13
 1.4061805e-08 1.1341375e-17 6.9566667e-01 2.2686377e-11 4.8070641e-09
 4.8695527e-11], sum to 1.0000
[2019-04-16 12:42:59,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0467
[2019-04-16 12:42:59,928] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.4, 68.0, 129.0, 0.0, 22.5, 23.81820301462249, -0.07244994258894889, 1.0, 1.0, 50.0, 39.9993740760539], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2125200.0000, 
sim time next is 2126400.0000, 
raw observation next is [-5.199999999999999, 68.0, 118.5, 0.0, 22.5, 23.7158094153846, -0.2990128363641771, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.31855955678670367, 0.68, 0.395, 0.0, 0.375, 0.4763174512820501, 0.4003290545452743, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9638689], dtype=float32), -2.1411934]. 
=============================================
[2019-04-16 12:43:03,494] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.6787912e-02 1.6002652e-10 2.9046183e-13 1.3181053e-11 4.4524376e-15
 7.5474051e-11 7.7834340e-19 9.6321207e-01 3.4860174e-11 4.8445714e-09
 2.2134544e-13], sum to 1.0000
[2019-04-16 12:43:03,494] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9586
[2019-04-16 12:43:03,533] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.7, 29.0, 38.5, 83.5, 22.5, 25.76329668510168, 0.3594702917911648, 1.0, 1.0, 50.0, 33.81725921665442], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2566800.0000, 
sim time next is 2568000.0000, 
raw observation next is [1.966666666666667, 31.0, 17.5, 31.16666666666666, 22.5, 25.84425568848026, 0.3317065205008596, 1.0, 1.0, 50.0, 34.500572586592654], 
processed observation next is [1.0, 0.7391304347826086, 0.5170821791320407, 0.31, 0.058333333333333334, 0.03443830570902393, 0.375, 0.6536879740400217, 0.6105688401669532, 1.0, 1.0, 0.7, 0.34500572586592654], 
reward next is 0.1300, 
noisyNet noise sample is [array([0.61739737], dtype=float32), 1.1656789]. 
=============================================
[2019-04-16 12:43:03,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7779553e-01 6.5296865e-07 3.9692331e-08 5.2729224e-08 2.5866817e-10
 1.8434794e-06 4.5236235e-13 3.2219934e-01 2.5016837e-08 2.4938661e-06
 7.4386222e-08], sum to 1.0000
[2019-04-16 12:43:03,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2832
[2019-04-16 12:43:03,638] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 87.0, 73.0, 27.5, 22.5, 20.57446826599201, -0.8101569446813696, 1.0, 1.0, 50.0, 64.17879693356281], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2278800.0000, 
sim time next is 2280000.0000, 
raw observation next is [-7.833333333333334, 84.0, 91.66666666666667, 35.16666666666666, 22.5, 20.92329876091081, -0.9055679881328528, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2456140350877193, 0.84, 0.3055555555555556, 0.038858195211786364, 0.375, 0.2436082300759009, 0.19814400395571574, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09621442], dtype=float32), 1.1328281]. 
=============================================
[2019-04-16 12:43:03,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[37.726337]
 [36.33107 ]
 [33.84248 ]
 [35.03925 ]
 [34.251343]
 [33.724094]
 [32.90214 ]
 [33.3836  ]
 [33.237682]
 [33.45686 ]
 [33.714214]
 [34.63194 ]
 [35.18221 ]
 [33.424717]
 [33.33303 ]
 [34.68552 ]
 [35.559273]
 [35.640724]
 [35.58064 ]
 [35.74074 ]
 [37.24966 ]
 [37.424503]
 [38.642517]
 [39.9486  ]
 [40.330227]], R is [[37.98214722]
 [38.60232544]
 [39.21630096]
 [38.96672058]
 [38.57705307]
 [38.19128418]
 [37.80937195]
 [37.43127823]
 [37.05696487]
 [36.68639374]
 [36.41003418]
 [37.04235458]
 [37.67193222]
 [37.52719498]
 [37.82835007]
 [38.40671158]
 [39.02264404]
 [39.63241959]
 [40.23609543]
 [40.83373642]
 [41.42539978]
 [41.01114655]
 [41.60103607]
 [42.18502426]
 [42.76317596]].
[2019-04-16 12:43:05,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8709924e-01 1.2216445e-06 1.8813330e-08 8.4428628e-08 5.3543758e-10
 2.9784151e-06 3.9875551e-12 2.1288668e-01 6.8716196e-07 9.0403082e-06
 3.8488491e-08], sum to 1.0000
[2019-04-16 12:43:05,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1068
[2019-04-16 12:43:05,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 51.66666666666667, 241.8333333333333, 353.3333333333334, 19.0, 19.6877372284216, -0.9305065820341446, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2378400.0000, 
sim time next is 2379600.0000, 
raw observation next is [-0.6, 54.0, 221.5, 212.0, 19.0, 19.49234558496589, -0.9697360834911598, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.44598337950138506, 0.54, 0.7383333333333333, 0.23425414364640884, 0.08333333333333333, 0.12436213208049078, 0.17675463883628006, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.168843], dtype=float32), 1.9159441]. 
=============================================
[2019-04-16 12:43:15,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4569059e-02 4.8315058e-10 7.2647894e-13 3.0012347e-12 4.2722114e-15
 4.6846066e-10 4.7907220e-19 9.6543092e-01 1.2541428e-11 2.8945386e-09
 3.5777852e-12], sum to 1.0000
[2019-04-16 12:43:15,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2875
[2019-04-16 12:43:15,632] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [4.666666666666667, 33.33333333333334, 237.1666666666667, 258.3333333333333, 22.5, 24.85678683241441, 0.2555144276536689, 1.0, 1.0, 50.0, 54.007579871808765], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2812800.0000, 
sim time next is 2814000.0000, 
raw observation next is [5.333333333333334, 31.66666666666667, 227.1666666666667, 144.1666666666667, 22.5, 25.41228007394763, 0.1583900813959318, 1.0, 1.0, 50.0, 53.43202102153801], 
processed observation next is [1.0, 0.5652173913043478, 0.6103416435826409, 0.3166666666666667, 0.7572222222222224, 0.15930018416206268, 0.375, 0.6176900061623026, 0.5527966937986439, 1.0, 1.0, 0.7, 0.5343202102153801], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8542145], dtype=float32), -0.28073934]. 
=============================================
[2019-04-16 12:43:16,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3988194e-01 2.4916278e-07 3.0258411e-09 2.4204028e-09 1.8309281e-11
 2.0082021e-07 1.7462125e-13 4.6011680e-01 4.5330065e-08 7.3479686e-07
 1.7765702e-08], sum to 1.0000
[2019-04-16 12:43:16,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4929
[2019-04-16 12:43:16,181] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 56.0, 0.0, 0.0, 19.0, 21.0863899149649, -0.5213933765536284, 0.0, 1.0, 50.0, 64.51584966281891], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2584800.0000, 
sim time next is 2586000.0000, 
raw observation next is [-3.166666666666667, 57.0, 0.0, 0.0, 19.0, 21.3228727916575, -0.6919971318790772, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.3748845798707295, 0.57, 0.0, 0.0, 0.08333333333333333, 0.2769060659714582, 0.26933428937364096, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13818735], dtype=float32), -0.36659858]. 
=============================================
[2019-04-16 12:43:16,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8504945e-01 1.9515541e-08 1.7926288e-10 9.4423469e-11 5.2635983e-13
 2.5320873e-08 8.1543935e-17 4.1495043e-01 4.8545118e-10 5.6479571e-08
 1.1891479e-10], sum to 1.0000
[2019-04-16 12:43:16,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8808
[2019-04-16 12:43:16,300] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 50.0, 28.5, 253.5, 22.5, 23.10661509839664, -0.1641977135510599, 1.0, 1.0, 50.0, 58.93389378870604], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2739600.0000, 
sim time next is 2740800.0000, 
raw observation next is [-3.333333333333333, 51.33333333333334, 11.5, 119.8333333333333, 22.5, 23.80019735062062, -0.1386978919875625, 1.0, 1.0, 50.0, 58.5430410959828], 
processed observation next is [1.0, 0.7391304347826086, 0.37026777469990774, 0.5133333333333334, 0.03833333333333333, 0.1324125230202578, 0.375, 0.4833497792183851, 0.45376736933747913, 1.0, 1.0, 0.7, 0.5854304109598281], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2455181], dtype=float32), -3.0487494]. 
=============================================
[2019-04-16 12:43:17,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7048066e-01 1.4377167e-08 2.1818575e-11 2.5536062e-10 7.2344203e-14
 2.5727145e-08 8.0050929e-16 1.2951910e-01 6.2578574e-11 1.6789394e-07
 2.5156283e-10], sum to 1.0000
[2019-04-16 12:43:17,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4115
[2019-04-16 12:43:17,955] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.266666666666667, 54.66666666666667, 99.33333333333333, 713.1666666666667, 22.5, 23.90317207960581, -0.1996914834592466, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2731200.0000, 
sim time next is 2732400.0000, 
raw observation next is [-4.0, 54.0, 94.0, 673.5, 22.5, 23.45992177428091, -0.1619610934864039, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3518005540166205, 0.54, 0.31333333333333335, 0.7441988950276243, 0.375, 0.45499348119007593, 0.44601296883786534, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3497767], dtype=float32), -0.25241393]. 
=============================================
[2019-04-16 12:43:21,800] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-16 12:43:21,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2444322e-01 1.2566057e-06 3.1513325e-09 1.9934289e-08 4.1172874e-11
 7.3738454e-07 4.2481581e-13 6.7555380e-01 4.2654630e-08 9.0491102e-07
 5.7601518e-08], sum to 1.0000
[2019-04-16 12:43:21,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8880
[2019-04-16 12:43:21,802] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation job starts!
[2019-04-16 12:43:21,802] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:43:21,804] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation job starts!
[2019-04-16 12:43:21,804] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation job starts!
[2019-04-16 12:43:21,805] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:43:21,806] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-16 12:43:21,807] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res1/Eplus-env-sub_run14
[2019-04-16 12:43:21,824] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v5-res1/Eplus-env-sub_run14
[2019-04-16 12:43:21,854] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 22.4661887647291, -0.2605019479706677, 0.0, 1.0, 50.0, 58.4178204935371], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 2773200.0000, 
sim time next is 2774400.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 22.61634913019143, -0.2389243890668732, 0.0, 1.0, 50.0, 41.796836692977124], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.38469576084928586, 0.4203585369777089, 0.0, 1.0, 0.7, 0.41796836692977124], 
reward next is 0.0570, 
noisyNet noise sample is [array([-0.08278494], dtype=float32), -2.8847475]. 
=============================================
[2019-04-16 12:43:21,857] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Test-v6-res1/Eplus-env-sub_run14
[2019-04-16 12:44:16,096] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:NoisyNet noise sample: [array([0.03101189], dtype=float32), 0.080692254]
[2019-04-16 12:44:16,096] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation this: [-2.333333333333333, 100.0, 0.0, 0.0, 19.0, 23.57261725418498, 0.1344393647672469, 0.0, 1.0, 50.0, 56.36850473403665]
[2019-04-16 12:44:16,096] A3C_EVAL-Part4-Light-Pit-Train-v3 DEBUG:Observation forecast: []
[2019-04-16 12:44:16,096] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Softmax [5.8431035e-01 1.5088396e-07 1.2994673e-09 5.2652482e-09 1.7149780e-11
 1.7981887e-07 4.5989230e-14 4.1568851e-01 8.3677341e-09 8.5145570e-07
 3.0949194e-09], sampled 0.6429791727210102
[2019-04-16 12:44:21,134] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:NoisyNet noise sample: [array([0.03101189], dtype=float32), 0.080692254]
[2019-04-16 12:44:21,134] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:Observation this: [-2.5, 57.33333333333334, 36.33333333333333, 252.3333333333333, 22.5, 25.21381754246276, 0.2813090710912132, 1.0, 1.0, 15.0, 0.0]
[2019-04-16 12:44:21,135] A3C_EVAL-Part4-Light-Pit-Test-v5 DEBUG:Observation forecast: []
[2019-04-16 12:44:21,135] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Softmax [4.8289007e-01 6.5664452e-09 6.0953249e-11 2.2466654e-10 5.9046198e-13
 2.3530060e-08 4.8106437e-16 5.1710981e-01 5.5369498e-10 6.1074722e-08
 1.9608776e-10], sampled 0.07051599419172094
[2019-04-16 12:44:30,626] A3C_EVAL-Part4-Light-Pit-Test-v5 INFO:Evaluation: average rewards by now are 2299.9306 101675.4018 469.1474
[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,646] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:30,764] EPLUS_ENV_Part4-Light-Pit-Test-v5_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,393] A3C_EVAL-Part4-Light-Pit-Train-v3 INFO:Evaluation: average rewards by now are 2161.5389 109820.5021 50.9562
[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,413] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:38,530] EPLUS_ENV_Part4-Light-Pit-Train-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,086] A3C_EVAL-Part4-Light-Pit-Test-v6 INFO:Evaluation: average rewards by now are 2129.4601 110120.3463 -156.1184
[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,106] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:43,221] EPLUS_ENV_Part4-Light-Pit-Test-v6_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-16 12:44:44,109] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 650000, evaluation results [650000.0, 2161.538901750725, 109820.50209324528, 50.956181302784145, 2299.930597880675, 101675.40182508506, 469.1473952541078, 2129.4600699501125, 110120.34632997884, -156.11838675086696]
[2019-04-16 12:44:52,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1442609e-01 1.8148808e-07 1.6118239e-09 1.0840490e-08 2.6936059e-11
 9.4662205e-08 5.9080955e-14 5.8557314e-01 8.9384296e-09 5.0947034e-07
 2.7690916e-09], sum to 1.0000
[2019-04-16 12:44:52,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3714
[2019-04-16 12:44:52,487] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 94.66666666666667, 0.0, 0.0, 19.0, 21.95913152888732, -0.4496774042512199, 0.0, 1.0, 50.0, 41.54995209784026], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3097200.0000, 
sim time next is 3098400.0000, 
raw observation next is [-1.0, 97.33333333333333, 0.0, 0.0, 19.0, 21.8273301224013, -0.5828593064146167, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4349030470914128, 0.9733333333333333, 0.0, 0.0, 0.08333333333333333, 0.31894417686677495, 0.3057135645284611, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.06184756], dtype=float32), -1.3673458]. 
=============================================
[2019-04-16 12:44:52,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.1048337e-01 1.1827424e-11 4.8241413e-13 2.8138269e-13 1.0075187e-15
 2.2946525e-09 2.8147082e-20 2.8951666e-01 1.3764080e-12 1.0950573e-09
 2.3640630e-13], sum to 1.0000
[2019-04-16 12:44:52,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3671
[2019-04-16 12:44:52,685] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 100.0, 16.33333333333333, 179.8333333333333, 22.5, 25.96491977725311, 0.595673424554347, 1.0, 1.0, 50.0, 53.563305699439624], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3172800.0000, 
sim time next is 3174000.0000, 
raw observation next is [6.0, 100.0, 0.0, 0.0, 22.5, 26.151945047634, 0.5642576055534189, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.6288088642659281, 1.0, 0.0, 0.0, 0.375, 0.6793287539695001, 0.6880858685178063, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1864489], dtype=float32), -0.23205073]. 
=============================================
[2019-04-16 12:44:52,694] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3852237e-01 1.8278019e-08 3.8340930e-10 2.3994118e-09 4.8202220e-11
 1.7557169e-07 1.4811604e-14 5.6147647e-01 1.8960609e-09 1.0170805e-06
 1.9636952e-09], sum to 1.0000
[2019-04-16 12:44:52,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3506
[2019-04-16 12:44:52,722] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 19.0, 21.95673143314229, -0.465879988502108, 0.0, 1.0, 50.0, 41.14497356817125], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3106800.0000, 
sim time next is 3108000.0000, 
raw observation next is [0.0, 100.0, 0.0, 0.0, 19.0, 21.79298608719489, -0.6052400536745521, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.46260387811634357, 1.0, 0.0, 0.0, 0.08333333333333333, 0.31608217393290755, 0.29825331544181594, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36810365], dtype=float32), 0.68017083]. 
=============================================
[2019-04-16 12:44:54,055] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1039751e-01 2.1922597e-07 7.7466824e-09 4.2470831e-09 1.2854804e-11
 4.1001254e-08 4.8373191e-14 1.8960112e-01 3.1969591e-08 1.0083683e-06
 2.1275541e-09], sum to 1.0000
[2019-04-16 12:44:54,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5363
[2019-04-16 12:44:54,065] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 79.33333333333334, 0.0, 0.0, 19.0, 21.09730559488317, -0.4873790450928472, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3284400.0000, 
sim time next is 3285600.0000, 
raw observation next is [-7.0, 74.66666666666667, 0.0, 0.0, 19.0, 20.9372688709812, -0.5193079976643654, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.2686980609418283, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.24477240591509997, 0.3268973341118782, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8291612], dtype=float32), -0.3271031]. 
=============================================
[2019-04-16 12:44:59,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0637891e-01 2.0490143e-08 9.1566965e-10 5.4121845e-09 1.8515502e-12
 8.3747139e-08 2.2448639e-15 3.9362025e-01 2.5518632e-09 7.1418566e-07
 6.6935624e-10], sum to 1.0000
[2019-04-16 12:44:59,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0063
[2019-04-16 12:44:59,768] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 24.79246354864997, 0.3054016259754128, 0.0, 1.0, 50.0, 38.90388297359392], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3547200.0000, 
sim time next is 3548400.0000, 
raw observation next is [-2.666666666666667, 67.33333333333333, 0.0, 0.0, 19.0, 24.54460097376246, 0.1567697648445251, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.38873499538319484, 0.6733333333333333, 0.0, 0.0, 0.08333333333333333, 0.545383414480205, 0.5522565882815084, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.01081149], dtype=float32), -0.94872564]. 
=============================================
[2019-04-16 12:44:59,902] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.5582895e-01 3.1348439e-08 6.7627054e-10 1.1383831e-09 8.4087407e-12
 2.0571312e-07 1.6053336e-14 7.4417067e-01 1.9025825e-09 1.0183461e-07
 5.2031374e-10], sum to 1.0000
[2019-04-16 12:44:59,903] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5015
[2019-04-16 12:44:59,932] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.333333333333334, 67.0, 0.0, 0.0, 19.0, 23.33888497496429, -0.1442598667037885, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3363600.0000, 
sim time next is 3364800.0000, 
raw observation next is [-4.666666666666666, 69.0, 0.0, 0.0, 19.0, 22.90647126882301, -0.09252763765986165, 0.0, 1.0, 50.0, 60.04867497459135], 
processed observation next is [1.0, 0.9565217391304348, 0.33333333333333337, 0.69, 0.0, 0.0, 0.08333333333333333, 0.40887260573525097, 0.46915745411337945, 0.0, 1.0, 0.7, 0.6004867497459135], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18324317], dtype=float32), 1.1887646]. 
=============================================
[2019-04-16 12:45:01,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.68303470e-02 8.74205916e-11 1.16079116e-13 2.86471888e-12
 6.73736274e-15 5.29518696e-09 9.62184037e-19 9.63169694e-01
 1.34576204e-11 1.06958520e-09 2.71257192e-12], sum to 1.0000
[2019-04-16 12:45:01,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1964
[2019-04-16 12:45:01,797] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 47.66666666666667, 114.0, 797.3333333333333, 22.5, 25.11193631610293, 0.3129261900093867, 1.0, 1.0, 50.0, 52.284775302061], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3410400.0000, 
sim time next is 3411600.0000, 
raw observation next is [3.0, 46.33333333333334, 115.3333333333333, 806.1666666666666, 22.5, 25.30046145188461, 0.3499272577586268, 1.0, 1.0, 50.0, 49.77849370889428], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.46333333333333343, 0.3844444444444443, 0.8907918968692449, 0.375, 0.6083717876570507, 0.6166424192528756, 1.0, 1.0, 0.7, 0.49778493708894284], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0562067], dtype=float32), 0.45184532]. 
=============================================
[2019-04-16 12:45:06,221] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2926296e-01 6.9287253e-08 6.6608563e-10 6.4321801e-09 2.5832163e-11
 3.2303916e-07 8.0537804e-14 7.7073640e-01 1.8294800e-08 2.7624048e-07
 4.7660982e-09], sum to 1.0000
[2019-04-16 12:45:06,223] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5295
[2019-04-16 12:45:06,229] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2959765e-01 1.0144787e-07 6.3149019e-10 1.2288305e-08 8.0663483e-11
 2.0865757e-07 1.4072756e-13 1.7039981e-01 2.1018209e-08 2.1343908e-06
 1.8876993e-09], sum to 1.0000
[2019-04-16 12:45:06,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9112
[2019-04-16 12:45:06,253] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-4.666666666666666, 67.0, 0.0, 0.0, 19.0, 23.94797201433656, 0.1438240112074794, 0.0, 1.0, 50.0, 39.652343499758004], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3559200.0000, 
sim time next is 3560400.0000, 
raw observation next is [-5.0, 65.0, 0.0, 0.0, 19.0, 23.99335238101038, 0.1327529512258201, 0.0, 1.0, 50.0, 39.499962859641045], 
processed observation next is [0.0, 0.21739130434782608, 0.32409972299168976, 0.65, 0.0, 0.0, 0.08333333333333333, 0.4994460317508649, 0.54425098374194, 0.0, 1.0, 0.7, 0.39499962859641047], 
reward next is 0.0800, 
noisyNet noise sample is [array([0.7501564], dtype=float32), -0.030803759]. 
=============================================
[2019-04-16 12:45:06,258] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 19.0, 23.38493770967541, -0.09152752758844068, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3607200.0000, 
sim time next is 3608400.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 19.0, 23.33526707905613, -0.01891983317533534, 0.0, 1.0, 50.0, 51.05270689305485], 
processed observation next is [0.0, 0.782608695652174, 0.4349030470914128, 0.42, 0.0, 0.0, 0.08333333333333333, 0.4446055899213442, 0.4936933889415549, 0.0, 1.0, 0.7, 0.5105270689305484], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04977923], dtype=float32), -0.6025817]. 
=============================================
[2019-04-16 12:45:08,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3939130e-01 5.3601696e-07 3.9800646e-08 1.8071080e-07 1.0183407e-09
 1.0509175e-06 4.4728327e-12 3.6059794e-01 2.6033996e-07 8.5791025e-06
 3.1882053e-08], sum to 1.0000
[2019-04-16 12:45:08,421] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0099
[2019-04-16 12:45:08,434] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.0, 27.0, 0.0, 0.0, 19.0, 22.43104013542473, -0.3028496176891106, 0.0, 1.0, 50.0, 58.21152904631387], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3654000.0000, 
sim time next is 3655200.0000, 
raw observation next is [8.666666666666668, 28.66666666666667, 0.0, 0.0, 19.0, 22.68802274817489, -0.3790043516621154, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.7026777469990768, 0.28666666666666674, 0.0, 0.0, 0.08333333333333333, 0.3906685623479076, 0.3736652161126282, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.90471816], dtype=float32), -2.169555]. 
=============================================
[2019-04-16 12:45:10,569] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.5611148e-01 7.8452564e-07 5.9280745e-09 6.5799306e-08 3.2225755e-10
 7.0223359e-07 4.8858643e-12 8.4388113e-01 1.1039222e-07 5.6057920e-06
 3.0107543e-08], sum to 1.0000
[2019-04-16 12:45:10,576] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4970
[2019-04-16 12:45:10,608] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [8.333333333333334, 30.33333333333334, 18.16666666666666, 168.0, 19.0, 23.98316036150161, 0.01063360403258769, 0.0, 1.0, 50.0, 34.577107648205995], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3656400.0000, 
sim time next is 3657600.0000, 
raw observation next is [8.0, 32.0, 46.5, 262.0, 19.0, 24.03798541490273, 0.04140794749262965, 0.0, 1.0, 50.0, 34.241617586488005], 
processed observation next is [0.0, 0.34782608695652173, 0.6842105263157896, 0.32, 0.155, 0.28950276243093925, 0.08333333333333333, 0.5031654512418943, 0.5138026491642099, 0.0, 1.0, 0.7, 0.34241617586488005], 
reward next is 0.1326, 
noisyNet noise sample is [array([0.66115093], dtype=float32), 0.96549124]. 
=============================================
[2019-04-16 12:45:17,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7338370e-01 6.1645911e-09 6.5083924e-11 3.6087031e-10 1.9858846e-13
 1.0164797e-08 1.5845042e-15 6.2661630e-01 3.8481049e-09 1.4928963e-08
 7.0680815e-11], sum to 1.0000
[2019-04-16 12:45:17,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8693
[2019-04-16 12:45:17,094] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-8.333333333333334, 50.33333333333334, 0.0, 0.0, 19.0, 24.60833038740208, 0.171581496844235, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 3968400.0000, 
sim time next is 3969600.0000, 
raw observation next is [-8.666666666666668, 51.66666666666666, 0.0, 0.0, 19.0, 24.02636446644222, 0.2052039372778802, 0.0, 1.0, 50.0, 56.397124745820165], 
processed observation next is [1.0, 0.9565217391304348, 0.22253000923361033, 0.5166666666666666, 0.0, 0.0, 0.08333333333333333, 0.5021970388701851, 0.56840131242596, 0.0, 1.0, 0.7, 0.5639712474582016], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3824117], dtype=float32), -0.38311958]. 
=============================================
[2019-04-16 12:45:22,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.28709245e-01 9.78444525e-09 8.32751229e-11 3.22170818e-10
 4.43587224e-14 1.38801809e-07 1.29788624e-15 6.71290517e-01
 3.19052701e-10 1.08020224e-07 1.47957369e-09], sum to 1.0000
[2019-04-16 12:45:22,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3608
[2019-04-16 12:45:22,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.666666666666667, 28.33333333333334, 120.1666666666667, 836.8333333333334, 22.5, 24.51315661047686, 0.1336858632826446, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4105200.0000, 
sim time next is 4106400.0000, 
raw observation next is [2.333333333333333, 28.66666666666666, 119.3333333333333, 839.1666666666667, 22.5, 24.7323608734971, 0.3082054628191507, 1.0, 1.0, 50.0, 53.087966866033156], 
processed observation next is [1.0, 0.5217391304347826, 0.5272391505078486, 0.2866666666666666, 0.3977777777777777, 0.9272559852670351, 0.375, 0.561030072791425, 0.6027351542730502, 1.0, 1.0, 0.7, 0.5308796686603315], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35289624], dtype=float32), 0.63514066]. 
=============================================
[2019-04-16 12:45:22,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5043508e-01 8.4964722e-07 3.9037321e-08 6.9470332e-08 9.9283623e-11
 4.1538810e-06 6.1278469e-12 8.4954941e-01 1.0452570e-07 1.0323988e-05
 4.6737778e-08], sum to 1.0000
[2019-04-16 12:45:22,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6704
[2019-04-16 12:45:22,551] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 40.0, 0.0, 0.0, 19.0, 23.49834631731734, -0.06712644288188989, 0.0, 1.0, 50.0, 41.12395697658991], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4074000.0000, 
sim time next is 4075200.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 19.0, 23.54463146429717, -0.06358345366598013, 0.0, 1.0, 50.0, 40.761026192899706], 
processed observation next is [1.0, 0.17391304347826086, 0.32409972299168976, 0.41, 0.0, 0.0, 0.08333333333333333, 0.46205262202476405, 0.4788055154446733, 0.0, 1.0, 0.7, 0.4076102619289971], 
reward next is 0.0674, 
noisyNet noise sample is [array([-0.62457204], dtype=float32), 0.3099022]. 
=============================================
[2019-04-16 12:45:24,054] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.2026279e-01 4.8415760e-09 1.3078669e-11 1.2905556e-11 2.6918092e-13
 2.4185900e-09 4.9939289e-17 1.7973712e-01 7.3539431e-11 2.3872152e-08
 3.2658331e-11], sum to 1.0000
[2019-04-16 12:45:24,055] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3408
[2019-04-16 12:45:24,077] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 87.33333333333334, 82.66666666666667, 0.0, 22.5, 23.59009631929302, -0.02581870761945973, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4459200.0000, 
sim time next is 4460400.0000, 
raw observation next is [0.0, 85.0, 78.0, 0.0, 22.5, 23.57060427337093, -0.02450850412029176, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.85, 0.26, 0.0, 0.375, 0.46421702278091076, 0.4918304986265694, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0670235], dtype=float32), -2.733807]. 
=============================================
[2019-04-16 12:45:24,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8945161e-01 1.9784913e-08 1.2756410e-10 2.6649849e-10 1.1680570e-12
 1.6410059e-08 9.3593795e-16 4.1054827e-01 1.0587853e-09 7.4675881e-08
 1.9794441e-10], sum to 1.0000
[2019-04-16 12:45:24,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0786
[2019-04-16 12:45:24,608] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 31.0, 0.0, 0.0, 22.5, 24.96908730323507, 0.2549861626282497, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4044000.0000, 
sim time next is 4045200.0000, 
raw observation next is [-4.0, 31.0, 0.0, 0.0, 22.5, 24.34845584276459, 0.14602286373526, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3518005540166205, 0.31, 0.0, 0.0, 0.375, 0.5290379868970492, 0.5486742879117533, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0322413], dtype=float32), -0.615333]. 
=============================================
[2019-04-16 12:45:29,977] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2924652e-01 5.5128457e-09 7.7954171e-12 1.7524249e-10 3.3864488e-13
 8.2371168e-09 7.0159850e-16 1.7075349e-01 2.3748506e-10 7.9195939e-09
 1.0129400e-10], sum to 1.0000
[2019-04-16 12:45:29,977] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3060
[2019-04-16 12:45:29,989] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 92.0, 161.5, 3.0, 22.5, 24.45892909784972, 0.2541012080958961, 1.0, 1.0, 50.0, 66.25481412138294], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4701600.0000, 
sim time next is 4702800.0000, 
raw observation next is [0.0, 92.0, 192.5, 5.0, 22.5, 25.15212135045789, 0.2340691254815507, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.92, 0.6416666666666667, 0.0055248618784530384, 0.375, 0.5960101125381575, 0.5780230418271836, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6860001], dtype=float32), -0.6176102]. 
=============================================
[2019-04-16 12:45:30,088] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.4338979e-01 2.1688324e-09 8.4660889e-12 1.6543013e-11 3.6655839e-14
 2.0512250e-09 3.8983950e-17 2.5661013e-01 1.3803954e-10 5.4364236e-08
 2.6263765e-12], sum to 1.0000
[2019-04-16 12:45:30,091] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8506
[2019-04-16 12:45:30,119] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [8.2, 62.33333333333334, 0.0, 0.0, 19.0, 25.49772272868145, 0.5110040985578074, 0.0, 1.0, 50.0, 35.88460752397346], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4404000.0000, 
sim time next is 4405200.0000, 
raw observation next is [7.9, 62.66666666666667, 0.0, 0.0, 19.0, 25.56533791510374, 0.5161316648538598, 0.0, 1.0, 50.0, 35.66418520776111], 
processed observation next is [1.0, 1.0, 0.6814404432132966, 0.6266666666666667, 0.0, 0.0, 0.08333333333333333, 0.630444826258645, 0.6720438882846199, 0.0, 1.0, 0.7, 0.35664185207761107], 
reward next is 0.1184, 
noisyNet noise sample is [array([1.4265298], dtype=float32), 1.1650511]. 
=============================================
[2019-04-16 12:45:31,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.4310033e-01 1.2381173e-08 3.2227743e-10 6.9786815e-10 2.3737178e-12
 8.0274283e-08 3.5770815e-15 5.6899447e-02 7.7212930e-10 1.4117721e-07
 1.2733703e-10], sum to 1.0000
[2019-04-16 12:45:31,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7839
[2019-04-16 12:45:31,916] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 22.77078838331141, -0.05478759977574656, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4482000.0000, 
sim time next is 4483200.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 22.62881484169844, -0.0867180751847582, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.3857345701415366, 0.47109397493841393, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2095194], dtype=float32), 0.4469124]. 
=============================================
[2019-04-16 12:45:32,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9790222e-02 5.7316418e-09 2.2047496e-11 3.8754538e-11 8.4839904e-14
 3.5848822e-09 1.2052506e-16 9.3020982e-01 7.1025359e-11 3.9177910e-09
 6.0915044e-11], sum to 1.0000
[2019-04-16 12:45:32,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6179
[2019-04-16 12:45:32,055] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 57.0, 0.0, 0.0, 19.0, 25.37724190544798, 0.4945545400908107, 0.0, 1.0, 50.0, 35.18399224831593], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4568400.0000, 
sim time next is 4569600.0000, 
raw observation next is [1.666666666666667, 58.33333333333334, 0.0, 0.0, 19.0, 25.43423537922902, 0.4994092882316412, 0.0, 1.0, 50.0, 34.74460387437081], 
processed observation next is [1.0, 0.9130434782608695, 0.5087719298245615, 0.5833333333333335, 0.0, 0.0, 0.08333333333333333, 0.6195196149357516, 0.6664697627438804, 0.0, 1.0, 0.7, 0.3474460387437081], 
reward next is 0.1276, 
noisyNet noise sample is [array([-0.29264337], dtype=float32), 0.03147633]. 
=============================================
[2019-04-16 12:45:32,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6950303e-01 1.7767556e-09 2.3479916e-11 6.5174428e-11 1.9104317e-13
 7.5141395e-09 9.9500213e-17 3.3049694e-01 2.7411001e-10 1.7173878e-08
 3.6437714e-11], sum to 1.0000
[2019-04-16 12:45:32,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7525
[2019-04-16 12:45:33,013] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [3.0, 45.0, 208.5, 62.5, 22.5, 24.8849174780297, 0.2248692187332412, 1.0, 1.0, 50.0, 64.78556016607529], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4546800.0000, 
sim time next is 4548000.0000, 
raw observation next is [2.666666666666667, 46.0, 171.5, 28.83333333333333, 22.5, 25.36135790147464, 0.4347511214052291, 1.0, 1.0, 50.0, 40.309290312444396], 
processed observation next is [1.0, 0.6521739130434783, 0.5364727608494922, 0.46, 0.5716666666666667, 0.031860036832412515, 0.375, 0.6134464917895533, 0.6449170404684097, 1.0, 1.0, 0.7, 0.40309290312444396], 
reward next is 0.0719, 
noisyNet noise sample is [array([0.22062293], dtype=float32), -1.6696825]. 
=============================================
[2019-04-16 12:45:34,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1432954e-01 8.5762664e-12 6.8461324e-15 4.4554627e-13 1.3345441e-16
 6.8117470e-11 4.1445927e-20 7.8567046e-01 1.5300478e-12 2.0850934e-09
 1.5079703e-13], sum to 1.0000
[2019-04-16 12:45:34,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2870
[2019-04-16 12:45:34,298] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [1.0, 86.0, 196.5, 73.0, 22.5, 27.51154636256713, 0.8848542840432324, 1.0, 1.0, 50.0, 31.454586648365947], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4446000.0000, 
sim time next is 4447200.0000, 
raw observation next is [1.0, 86.0, 160.1666666666667, 24.33333333333333, 22.5, 27.57223158456875, 0.8873456776692579, 1.0, 1.0, 50.0, 30.87876971212656], 
processed observation next is [1.0, 0.4782608695652174, 0.4903047091412743, 0.86, 0.5338888888888891, 0.026887661141804783, 0.375, 0.7976859653807292, 0.7957818925564193, 1.0, 1.0, 0.7, 0.3087876971212656], 
reward next is 0.1662, 
noisyNet noise sample is [array([0.10488328], dtype=float32), -1.3872293]. 
=============================================
[2019-04-16 12:45:34,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.49515101e-01 1.10253415e-08 2.67395342e-11 2.82528115e-11
 5.50506770e-14 6.98833880e-09 1.98450237e-16 7.50484884e-01
 3.00021986e-11 3.11235802e-08 5.38024972e-11], sum to 1.0000
[2019-04-16 12:45:34,642] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6138
[2019-04-16 12:45:34,673] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 26.05959575090895, 0.7033564615564324, 0.0, 1.0, 50.0, 48.9048779508408], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4651200.0000, 
sim time next is 4652400.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 19.0, 26.21064632107615, 0.7210637807336808, 0.0, 1.0, 50.0, 35.05238222850454], 
processed observation next is [1.0, 0.8695652173913043, 0.518005540166205, 0.52, 0.0, 0.0, 0.08333333333333333, 0.6842205267563459, 0.7403545935778936, 0.0, 1.0, 0.7, 0.3505238222850454], 
reward next is 0.1245, 
noisyNet noise sample is [array([0.17290516], dtype=float32), -1.639162]. 
=============================================
[2019-04-16 12:45:37,761] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:37,941] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:38,392] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.1110070e-01 4.1248622e-09 2.9502839e-10 2.9133326e-10 1.0356144e-12
 5.0772977e-09 3.1636620e-16 2.8889930e-01 8.2716251e-10 4.0012512e-08
 5.4411274e-11], sum to 1.0000
[2019-04-16 12:45:38,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4593
[2019-04-16 12:45:38,406] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 67.33333333333334, 157.1666666666667, 452.6666666666667, 22.5, 24.10648442233445, 0.04721273483653007, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4612800.0000, 
sim time next is 4614000.0000, 
raw observation next is [-0.6666666666666667, 63.66666666666667, 158.1666666666667, 552.0, 22.5, 24.14450212222327, 0.04826253416835852, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.44413665743305636, 0.6366666666666667, 0.5272222222222224, 0.6099447513812155, 0.375, 0.5120418435186057, 0.5160875113894529, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.386975], dtype=float32), -0.96284884]. 
=============================================
[2019-04-16 12:45:38,761] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:38,761] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-4:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res4/Eplus-env-sub_run11'

[2019-04-16 12:45:40,119] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:40,233] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:40,257] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:40,297] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:40,400] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:40,420] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:40,853] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.2833099e-01 2.7465167e-06 1.9871769e-07 3.3536762e-07 4.3190003e-09
 6.1743140e-06 5.8886923e-11 1.7165692e-01 1.8089398e-07 2.4495234e-06
 4.0709548e-08], sum to 1.0000
[2019-04-16 12:45:40,853] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8562
[2019-04-16 12:45:40,888] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 65.0, 174.0, 246.0, 19.0, 19.52329234587314, -0.9306484914476583, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 4870800.0000, 
sim time next is 4872000.0000, 
raw observation next is [-2.666666666666667, 63.33333333333334, 196.0, 201.3333333333333, 19.0, 19.84455020741735, -0.7057283332556304, 0.0, 1.0, 50.0, 70.68908925678511], 
processed observation next is [0.0, 0.391304347826087, 0.38873499538319484, 0.6333333333333334, 0.6533333333333333, 0.2224677716390423, 0.08333333333333333, 0.15371251728477908, 0.2647572222481232, 0.0, 1.0, 0.7, 0.7068908925678511], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9056951], dtype=float32), 0.2502304]. 
=============================================
[2019-04-16 12:45:41,117] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:41,117] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res6/Eplus-env-sub_run11'

[2019-04-16 12:45:41,230] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:41,231] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-14:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res11/Eplus-env-sub_run11'

[2019-04-16 12:45:41,257] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:41,261] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-15:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res12/Eplus-env-sub_run11'

[2019-04-16 12:45:41,762] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:41,917] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:42,764] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:42,764] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-17:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res14/Eplus-env-sub_run11'

[2019-04-16 12:45:42,896] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:43,057] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:43,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7691350e-01 8.6823206e-07 9.8276765e-09 6.5880807e-09 8.7734778e-11
 2.4160065e-07 7.6127142e-13 3.2308474e-01 1.7469807e-08 6.0108448e-07
 1.6577443e-08], sum to 1.0000
[2019-04-16 12:45:43,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8367
[2019-04-16 12:45:43,268] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 7, 
current raw observation is [0.3333333333333334, 45.0, 0.0, 0.0, 19.0, 22.96647395600945, -0.1642283888634338, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 50.0], 
sim time this is 5019600.0000, 
sim time next is 5020800.0000, 
raw observation next is [-0.3333333333333333, 50.0, 0.0, 0.0, 19.0, 23.13503349375231, -0.009679490641590465, 0.0, 1.0, 50.0, 67.02842014121791], 
processed observation next is [1.0, 0.08695652173913043, 0.4533702677747, 0.5, 0.0, 0.0, 0.08333333333333333, 0.4279194578126925, 0.49677350311946983, 0.0, 1.0, 0.7, 0.670284201412179], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8794866], dtype=float32), -1.3962077]. 
=============================================
[2019-04-16 12:45:43,734] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:43,878] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:43,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:43,895] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res7/Eplus-env-sub_run11'

[2019-04-16 12:45:44,210] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:44,309] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:44,343] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:44,472] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:44,592] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:44,705] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:44,717] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:44,735] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:44,735] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-18:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res15/Eplus-env-sub_run11'

[2019-04-16 12:45:44,737] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:44,807] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:44,828] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:44,831] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:44,914] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:45,046] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:45,151] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:45,211] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:45,211] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res3/Eplus-env-sub_run11'

[2019-04-16 12:45:45,310] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:45,311] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-19:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res16/Eplus-env-sub_run11'

[2019-04-16 12:45:45,593] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:45,593] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-11:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res8/Eplus-env-sub_run11'

[2019-04-16 12:45:45,706] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:45,706] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-5:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res5/Eplus-env-sub_run11'

[2019-04-16 12:45:45,717] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:45,718] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res2/Eplus-env-sub_run11'

[2019-04-16 12:45:45,809] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:45,809] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-20:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res17/Eplus-env-sub_run11'

[2019-04-16 12:45:45,834] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:45,941] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:46,047] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:46,047] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-13:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res10/Eplus-env-sub_run11'

[2019-04-16 12:45:46,149] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-16 12:45:46,254] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-16 12:45:46,835] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:46,835] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-12:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res9/Eplus-env-sub_run11'

[2019-04-16 12:45:47,150] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-16 12:45:47,150] EPLUS_ENV_Part4-Light-Pit-Train-v3_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
Exception in thread Thread-16:
Traceback (most recent call last):
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 842, in <lambda>
    action_repeat_n, is_add_time_to_state, is_r_term_zero);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/a3c.py", line 420, in train
    time_this, ob_this_raw, is_terminal_cp = env_interact_wrapper.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 13, in reset
    return self._interact(mode = 'reset', actions = None);
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/a3c_v0_1/env_interaction.py", line 31, in _interact
    env_get = self._env.reset();
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/site-packages/gym/core.py", line 104, in reset
    return self._reset()
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/eplus8_6.py", line 255, in _reset
    os.makedirs(eplus_working_dir); # Create the Eplus working directory
  File "/home/zhiangz/Documents/HVAC-RL-Control/src/virt_env/lib/python3.5/os.py", line 241, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/48/Eplus-env-Part4-Light-Pit-Train-v3-res13/Eplus-env-sub_run11'

