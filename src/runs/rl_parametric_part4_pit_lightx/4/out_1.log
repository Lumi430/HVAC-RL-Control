Using TensorFlow backend.
[2019-04-24 09:32:41,156] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part4_v3', activation='linear', agent_num=5, check_args_only=False, clip_norm=1.0, debug_log_prob=0.001, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part4-Light-Pit-Train-Repeat-v2', eval_act_func='part4_v4', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=50000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_add_time_to_state=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_r_term_zero=True, is_warm_start=True, job_mode='Train', learning_rate=5e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2000000, metric_func='part4_v2', model_dir='Part4-Light-Pit-Train-Repeat-v2-res1/model_data/model.ckpt-3000000', model_param=[13, 1], model_type='nn', num_threads=16, output='./Part4-Light-Pit-Train-Repeat-v2-res2', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part4_heuri_v8', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=10.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=11, test_env=['Part4-Light-Pit-Test-Repeat-v3', 'Part4-Light-Pit-Test-Repeat-v4'], test_mode='Multiple', train_act_func='part4_v4', train_freq=25, v_loss_frac=0.5, violation_penalty_scl=5.0, weight_initer='glorot_uniform', window_len=10)
[2019-04-24 09:32:41,156] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-24 09:32:41.187497: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-24 09:32:55,754] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-24 09:32:55,754] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part4-Light-Pit-Train-Repeat-v2', 'Part4-Light-Pit-Test-Repeat-v3', 'Part4-Light-Pit-Test-Repeat-v4'] ...
[2019-04-24 09:32:55,770] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation worker starts!
[2019-04-24 09:32:55,778] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation worker starts!
[2019-04-24 09:32:55,785] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation worker starts!
[2019-04-24 09:32:55,785] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:32:55,786] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-24 09:32:55,845] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:32:55,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run1
[2019-04-24 09:32:56,787] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:32:56,789] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-24 09:32:56,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:32:56,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run1
[2019-04-24 09:32:57,790] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:32:57,791] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2019-04-24 09:32:57,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:32:57,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run1
[2019-04-24 09:32:58,792] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:32:58,793] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2019-04-24 09:32:58,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:32:58,862] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run1
[2019-04-24 09:32:59,794] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:32:59,795] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2019-04-24 09:32:59,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:32:59,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run1
[2019-04-24 09:33:00,796] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:00,797] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2019-04-24 09:33:00,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:00,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run1
[2019-04-24 09:33:01,232] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-24 09:33:01,232] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:33:01,232] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:33:01,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:01,234] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:33:01,235] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:01,235] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:01,237] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run1
[2019-04-24 09:33:01,245] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run1
[2019-04-24 09:33:01,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run1
[2019-04-24 09:33:01,798] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:01,799] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-04-24 09:33:01,899] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:01,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run1
[2019-04-24 09:33:02,800] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:02,800] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-24 09:33:02,897] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:02,898] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run1
[2019-04-24 09:33:03,801] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:03,802] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-24 09:33:03,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:03,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run1
[2019-04-24 09:33:04,803] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:04,803] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-24 09:33:04,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:04,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run1
[2019-04-24 09:33:05,804] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:05,805] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-24 09:33:05,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:05,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run1
[2019-04-24 09:33:06,806] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:06,807] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-24 09:33:06,911] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:06,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run1
[2019-04-24 09:33:07,808] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:07,809] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-24 09:33:07,908] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:07,910] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run1
[2019-04-24 09:33:08,810] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:08,811] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-24 09:33:08,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:08,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run1
[2019-04-24 09:33:09,812] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:09,813] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-24 09:33:09,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:09,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run1
[2019-04-24 09:33:10,813] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-24 09:33:10,814] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-24 09:33:10,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:33:10,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run1
[2019-04-24 09:34:14,917] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3406.5021 65605.0093 -176.4364
[2019-04-24 09:34:14,938] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:34:15,051] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:34:16,907] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.25971228], dtype=float32), 0.6000777]
[2019-04-24 09:34:16,907] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [1.0, 86.0, 196.5, 73.0, 22.5, 24.72564291505476, 0.1061385294443034, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 09:34:16,907] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 09:34:16,909] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [9.4410700e-01 7.7260695e-03 1.4346283e-17 2.5200149e-16 1.9101984e-16
 1.0516687e-17 8.1637648e-18 1.8168075e-18 1.1286268e-13 4.8166882e-02
 4.7429034e-17], sampled 0.36729487242582226
[2019-04-24 09:34:23,846] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3190.9213 80670.8116 -437.8032
[2019-04-24 09:34:23,870] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:34:23,982] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:34:27,956] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([-0.25971228], dtype=float32), 0.6000777]
[2019-04-24 09:34:27,956] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-0.9092076546666668, 44.16873760333333, 0.0, 0.0, 19.0, 20.1616422076487, -0.8478437762263379, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:34:27,956] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 09:34:27,957] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [8.1943566e-01 3.8506500e-02 3.2457205e-14 1.5182942e-13 2.3447458e-13
 3.1200340e-14 2.3380901e-14 3.1378763e-15 2.1200656e-11 1.4205788e-01
 4.9574656e-14], sampled 0.2663250143082023
[2019-04-24 09:34:30,134] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3102.0466 83205.2551 -507.4525
[2019-04-24 09:34:30,155] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:34:30,275] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:34:31,157] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3190.921292578335, 80670.81163402944, -437.80316942686875, 3406.5021129061165, 65605.00928337398, -176.43642003214072, 3102.0465908851925, 83205.25511998698, -507.4525225091449]
[2019-04-24 09:34:34,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.7480122e-01 1.6634660e-02 3.8079422e-16 1.8687448e-15 5.0696891e-15
 5.5304512e-16 4.3177796e-16 1.5361660e-17 3.6270745e-13 1.0856413e-01
 6.9524755e-16], sum to 1.0000
[2019-04-24 09:34:34,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2751
[2019-04-24 09:34:34,530] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.2, 95.0, 0.0, 0.0, 19.0, 18.98487894940429, -0.7867784626477464, 0.0, 1.0, 60.0, 100.2154942102428], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 84000.0000, 
sim time next is 85200.0000, 
raw observation next is [0.1, 95.0, 0.0, 0.0, 19.0, 19.98813853487569, -0.8868226399721509, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.4653739612188367, 0.95, 0.0, 0.0, 0.08333333333333333, 0.16567821123964097, 0.20439245334261635, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3714737], dtype=float32), -0.57394713]. 
=============================================
[2019-04-24 09:34:35,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.16090012e-02 1.17154054e-01 1.22627846e-13 1.27348490e-13
 4.04740450e-13 1.04310134e-14 1.02934601e-13 1.94684560e-14
 1.47131387e-11 7.91236877e-01 1.97609365e-14], sum to 1.0000
[2019-04-24 09:34:35,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4241
[2019-04-24 09:34:36,150] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.466666666666667, 65.66666666666667, 30.83333333333334, 7.5, 22.5, 19.4025979175866, -1.018894523997203, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 116400.0000, 
sim time next is 117600.0000, 
raw observation next is [-7.633333333333333, 63.33333333333333, 38.33333333333334, 7.5, 22.5, 19.78720467846692, -0.7682603795521908, 1.0, 1.0, 60.0, 86.4114133379766], 
processed observation next is [1.0, 0.34782608695652173, 0.2511542012927055, 0.6333333333333333, 0.1277777777777778, 0.008287292817679558, 0.375, 0.14893372320557674, 0.2439132068159364, 1.0, 1.0, 0.9, 0.864114133379766], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5265416], dtype=float32), 0.46317974]. 
=============================================
[2019-04-24 09:34:36,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.89084524e-01 1.04492895e-01 6.49900191e-14 2.39533274e-13
 5.78512173e-13 1.08753906e-14 6.67989969e-14 1.82521489e-14
 1.48902314e-11 6.06422663e-01 3.17097524e-14], sum to 1.0000
[2019-04-24 09:34:36,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1023
[2019-04-24 09:34:36,383] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.8, 61.0, 41.0, 4.5, 22.5, 20.77174818538957, -0.8246390733078549, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 118800.0000, 
sim time next is 120000.0000, 
raw observation next is [-7.8, 65.33333333333334, 43.66666666666666, 1.5, 22.5, 20.54036598348677, -0.8677752518548503, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24653739612188366, 0.6533333333333334, 0.14555555555555552, 0.0016574585635359116, 0.375, 0.21169716529056407, 0.21074158271504992, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5265416], dtype=float32), 0.46317974]. 
=============================================
[2019-04-24 09:34:36,387] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.16961 ]
 [67.70059 ]
 [67.39645 ]
 [68.2041  ]
 [67.50665 ]
 [68.346   ]
 [68.01574 ]
 [69.25106 ]
 [70.415276]
 [70.675735]
 [71.855835]
 [73.04947 ]
 [73.13794 ]
 [74.338165]
 [75.50142 ]
 [76.56757 ]
 [76.58904 ]
 [77.5142  ]
 [77.65909 ]
 [76.719666]
 [76.99367 ]
 [77.90315 ]
 [77.83182 ]
 [78.21861 ]
 [78.31189 ]], R is [[65.50775909]
 [64.85268402]
 [65.20415497]
 [64.55211639]
 [64.90660095]
 [65.25753784]
 [65.60496521]
 [65.94186401]
 [66.28244781]
 [65.72553253]
 [66.06827545]
 [66.40759277]
 [65.74351501]
 [66.08608246]
 [66.4252243 ]
 [66.76097107]
 [66.0933609 ]
 [66.43242645]
 [65.76810455]
 [65.11042786]
 [65.37109375]
 [65.71738434]
 [66.06021118]
 [66.39961243]
 [66.73561859]].
[2019-04-24 09:34:43,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.7502638e-01 1.4829512e-02 3.6728149e-15 2.3896558e-14 4.5145928e-14
 6.7662209e-16 1.0021517e-15 6.3405350e-16 1.5602278e-11 2.1014415e-01
 1.7004568e-15], sum to 1.0000
[2019-04-24 09:34:43,543] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2991
[2019-04-24 09:34:43,601] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 65.0, 0.0, 0.0, 22.5, 22.43810132934331, -0.4981166743107694, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 244800.0000, 
sim time next is 246000.0000, 
raw observation next is [-3.4, 65.0, 0.0, 0.0, 19.0, 21.68056712022765, -0.6470173580122178, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.368421052631579, 0.65, 0.0, 0.0, 0.08333333333333333, 0.3067139266856375, 0.28432754732926074, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81961393], dtype=float32), 0.12841387]. 
=============================================
[2019-04-24 09:34:44,188] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9288042e-01 9.6136130e-02 3.2750485e-14 1.5621105e-13 1.2857955e-13
 4.9372331e-15 1.2118155e-14 2.2843549e-15 6.1228786e-11 1.1098354e-01
 2.0904694e-14], sum to 1.0000
[2019-04-24 09:34:44,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8721
[2019-04-24 09:34:44,335] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-7.833333333333334, 69.66666666666667, 0.0, 0.0, 19.0, 19.7769149590907, -0.7604408982711619, 0.0, 1.0, 60.0, 102.0563607579298], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 267600.0000, 
sim time next is 268800.0000, 
raw observation next is [-8.366666666666667, 68.33333333333333, 0.0, 0.0, 19.0, 20.84030318903027, -0.7004156731366153, 0.0, 1.0, 20.0, 53.15193079377214], 
processed observation next is [1.0, 0.08695652173913043, 0.23084025854108958, 0.6833333333333332, 0.0, 0.0, 0.08333333333333333, 0.2366919324191891, 0.26652810895446155, 0.0, 1.0, 0.1, 0.5315193079377214], 
reward next is 0.3685, 
noisyNet noise sample is [array([-0.5833359], dtype=float32), -0.06614472]. 
=============================================
[2019-04-24 09:34:49,565] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3987307e-01 7.1393296e-02 1.8948825e-12 2.5501105e-12 5.6038937e-12
 5.7227291e-13 3.2113174e-13 2.4638749e-13 2.6734950e-10 4.8873362e-01
 3.0927265e-13], sum to 1.0000
[2019-04-24 09:34:49,567] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0592
[2019-04-24 09:34:49,738] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-14.86666666666667, 74.0, 44.33333333333333, 736.5, 22.5, 21.89026654220662, -0.7218013240107295, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 380400.0000, 
sim time next is 381600.0000, 
raw observation next is [-14.5, 66.0, 55.0, 733.5, 22.5, 21.29801091155475, -0.8256458514075962, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.06094182825484763, 0.66, 0.18333333333333332, 0.8104972375690608, 0.375, 0.27483424262956263, 0.22478471619746795, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14309253], dtype=float32), -2.1177862]. 
=============================================
[2019-04-24 09:34:52,204] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.88888502e-01 1.60780728e-01 1.08521985e-11 4.98507520e-11
 7.79433670e-11 4.48558335e-12 5.60151188e-12 7.40031647e-12
 2.37738584e-09 3.50330770e-01 2.37113280e-12], sum to 1.0000
[2019-04-24 09:34:52,208] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0832
[2019-04-24 09:34:52,316] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 52.0, 0.0, 0.0, 19.0, 18.46962648646774, -1.223961804759121, 0.0, 1.0, 20.0, 53.6967090559062], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 447600.0000, 
sim time next is 448800.0000, 
raw observation next is [-10.8, 52.0, 0.0, 0.0, 19.0, 18.7887098966546, -1.363196298989075, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.1634349030470914, 0.52, 0.0, 0.0, 0.08333333333333333, 0.06572582472121653, 0.04560123367030836, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.66864127], dtype=float32), -0.6740661]. 
=============================================
[2019-04-24 09:34:57,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0565959e-01 3.8215034e-02 3.7747524e-17 3.2496750e-16 1.9682700e-16
 1.6340812e-18 7.8564887e-18 3.3920374e-19 1.9269111e-13 1.5612541e-01
 1.7223699e-17], sum to 1.0000
[2019-04-24 09:34:57,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7376
[2019-04-24 09:34:57,722] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 93.33333333333333, 0.0, 0.0, 19.0, 22.04731710580025, -0.5166272808933273, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 510000.0000, 
sim time next is 511200.0000, 
raw observation next is [2.7, 92.0, 0.0, 0.0, 19.0, 21.57876402866954, -0.6247915305175241, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.5373961218836566, 0.92, 0.0, 0.0, 0.08333333333333333, 0.2982303357224616, 0.2917361564941586, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11293221], dtype=float32), -1.8915029]. 
=============================================
[2019-04-24 09:34:59,705] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.2503158e-01 1.1898875e-01 8.2843102e-13 1.0397238e-12 4.7045310e-12
 5.6736625e-13 4.1127654e-13 6.1389255e-14 2.5590122e-10 6.5597969e-01
 4.5809857e-13], sum to 1.0000
[2019-04-24 09:34:59,706] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4914
[2019-04-24 09:34:59,751] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 66.0, 0.0, 0.0, 19.0, 18.90931741681051, -1.240635640103719, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 627600.0000, 
sim time next is 628800.0000, 
raw observation next is [-4.5, 67.0, 0.0, 0.0, 19.0, 18.85702984815796, -1.011374844099941, 0.0, 1.0, 60.0, 92.42921627523532], 
processed observation next is [0.0, 0.2608695652173913, 0.3379501385041552, 0.67, 0.0, 0.0, 0.08333333333333333, 0.07141915401316339, 0.1628750519666863, 0.0, 1.0, 0.9, 0.9242921627523532], 
reward next is 0.2042, 
noisyNet noise sample is [array([-0.60746276], dtype=float32), 0.5198999]. 
=============================================
[2019-04-24 09:35:00,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0654784e-01 8.1471562e-02 1.6079388e-13 1.9576033e-13 3.5659255e-13
 1.8596742e-14 1.0517600e-13 8.4581398e-15 3.0044005e-11 5.1198059e-01
 6.7618898e-14], sum to 1.0000
[2019-04-24 09:35:00,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4205
[2019-04-24 09:35:00,418] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-3.899999999999999, 78.66666666666667, 0.0, 0.0, 19.0, 20.17071828900874, -1.010002429543368, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 614400.0000, 
sim time next is 615600.0000, 
raw observation next is [-3.9, 75.0, 0.0, 0.0, 19.0, 19.79609157610739, -0.9050053113118767, 0.0, 1.0, 20.0, 68.80929937065466], 
processed observation next is [0.0, 0.13043478260869565, 0.3545706371191136, 0.75, 0.0, 0.0, 0.08333333333333333, 0.14967429800894916, 0.19833156289604112, 0.0, 1.0, 0.1, 0.6880929937065465], 
reward next is 0.2119, 
noisyNet noise sample is [array([0.61642325], dtype=float32), 0.9025375]. 
=============================================
[2019-04-24 09:35:03,627] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.56154442e-01 9.31583717e-02 3.70197647e-14 1.00625156e-13
 1.13309962e-13 3.59534527e-15 1.68824813e-14 3.16879261e-15
 9.91771248e-12 5.50687194e-01 7.52094953e-15], sum to 1.0000
[2019-04-24 09:35:03,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6252
[2019-04-24 09:35:03,737] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 19.0, 19.47205651286285, -1.179323318375354, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 716400.0000, 
sim time next is 717600.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 22.5, 19.31691635776379, -0.9226326389358032, 1.0, 1.0, 60.0, 105.12886824853669], 
processed observation next is [1.0, 0.30434782608695654, 0.3988919667590028, 0.76, 0.0, 0.0, 0.375, 0.10974302981364925, 0.19245578702139896, 1.0, 1.0, 0.9, 1.0512886824853669], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8698005], dtype=float32), 0.7585749]. 
=============================================
[2019-04-24 09:35:09,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.24828005e-01 3.78829166e-02 7.24734349e-15 3.54439785e-14
 3.53029712e-14 1.27993995e-15 1.07762894e-14 3.10583768e-16
 3.47159974e-12 2.37289056e-01 1.24839337e-15], sum to 1.0000
[2019-04-24 09:35:09,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2572
[2019-04-24 09:35:09,360] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 80.0, 0.0, 0.0, 19.0, 20.52288871374807, -0.8507543516768578, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 864000.0000, 
sim time next is 865200.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 19.0, 19.88218952135004, -0.9396388988873005, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3988919667590028, 0.8, 0.0, 0.0, 0.08333333333333333, 0.15684912677916993, 0.1867870337042332, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7532804], dtype=float32), 0.3385844]. 
=============================================
[2019-04-24 09:35:10,013] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1297930e-01 2.6638234e-02 2.8985200e-16 5.4458730e-15 7.6235769e-15
 4.7505345e-16 9.0827237e-16 3.6584289e-17 8.1899965e-13 6.0382441e-02
 2.3886276e-16], sum to 1.0000
[2019-04-24 09:35:10,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8033
[2019-04-24 09:35:10,030] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 73.33333333333334, 0.0, 0.0, 19.0, 21.15202042259913, -0.5791133605311138, 0.0, 1.0, 60.0, 78.49225173965252], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 880800.0000, 
sim time next is 882000.0000, 
raw observation next is [-0.6, 72.0, 0.0, 0.0, 19.0, 21.41318267443259, -0.6878853848546641, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 0.72, 0.0, 0.0, 0.08333333333333333, 0.2844318895360492, 0.270704871715112, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9953724], dtype=float32), -1.5760956]. 
=============================================
[2019-04-24 09:35:12,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3126315e-01 3.0999001e-02 7.3669499e-17 8.6449394e-15 2.1336597e-15
 1.3746852e-16 8.6326395e-17 1.0178600e-17 4.2399434e-13 3.7737850e-02
 2.5830076e-16], sum to 1.0000
[2019-04-24 09:35:12,559] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2905
[2019-04-24 09:35:12,572] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 73.33333333333334, 0.0, 0.0, 19.0, 21.37977486483159, -0.5354569452904735, 0.0, 1.0, 60.0, 78.19025619217216], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 880800.0000, 
sim time next is 882000.0000, 
raw observation next is [-0.6, 72.0, 0.0, 0.0, 19.0, 21.64261509449304, -0.6434170588235681, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.44598337950138506, 0.72, 0.0, 0.0, 0.08333333333333333, 0.3035512578744199, 0.2855276470588106, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08222893], dtype=float32), 1.6394858]. 
=============================================
[2019-04-24 09:35:13,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.50179112e-01 2.15561856e-02 6.58302964e-18 1.00503404e-16
 1.78815048e-16 1.31324755e-18 1.69217155e-18 6.53598364e-19
 4.24397252e-14 2.28264704e-01 2.04755905e-18], sum to 1.0000
[2019-04-24 09:35:13,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6124
[2019-04-24 09:35:13,925] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 19.0, 21.17492431972632, -0.5691970801132149, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 943200.0000, 
sim time next is 944400.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 19.0, 20.9864149402499, -0.6025396275976748, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6011080332409973, 0.96, 0.0, 0.0, 0.08333333333333333, 0.24886791168749176, 0.29915345746744176, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9368555], dtype=float32), -1.1989573]. 
=============================================
[2019-04-24 09:35:14,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5969877e-01 1.6035635e-02 1.7429008e-19 4.1018387e-19 7.3758010e-19
 1.2683798e-20 1.1912324e-20 8.4181157e-22 1.3040163e-15 1.2426556e-01
 3.2841587e-20], sum to 1.0000
[2019-04-24 09:35:14,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6142
[2019-04-24 09:35:14,214] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 76.33333333333334, 0.0, 0.0, 19.0, 23.08038194523284, -0.1054631173939255, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1027200.0000, 
sim time next is 1028400.0000, 
raw observation next is [14.4, 75.66666666666667, 0.0, 0.0, 19.0, 22.82542424305202, -0.14404701699093, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.7566666666666667, 0.0, 0.0, 0.08333333333333333, 0.4021186869210016, 0.45198432766969, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.36684638], dtype=float32), 0.5453072]. 
=============================================
[2019-04-24 09:35:17,576] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5035225e-01 1.0876801e-02 9.7222633e-21 1.1306847e-19 5.3787430e-19
 3.3360925e-21 7.9209264e-21 3.7785418e-22 6.4250811e-17 3.8770910e-02
 6.5255757e-21], sum to 1.0000
[2019-04-24 09:35:17,579] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9824
[2019-04-24 09:35:17,696] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [13.63333333333333, 78.66666666666667, 0.0, 0.0, 19.0, 22.59485812537014, -0.002824861803697389, 0.0, 1.0, 20.0, 72.48731555285941], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1056000.0000, 
sim time next is 1057200.0000, 
raw observation next is [13.46666666666667, 79.33333333333333, 0.0, 0.0, 19.0, 23.79808858599569, 0.1461131341180927, 0.0, 1.0, 60.0, 57.72626134540957], 
processed observation next is [1.0, 0.21739130434782608, 0.8356417359187445, 0.7933333333333333, 0.0, 0.0, 0.08333333333333333, 0.4831740488329741, 0.5487043780393642, 0.0, 1.0, 0.9, 0.5772626134540957], 
reward next is 0.0000, 
noisyNet noise sample is [array([-3.0765], dtype=float32), 0.35090852]. 
=============================================
[2019-04-24 09:35:17,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5761603e-01 8.9876093e-03 1.1318954e-15 9.0617939e-15 1.9061921e-14
 7.9957809e-16 7.3575775e-16 1.3933012e-16 2.0630696e-12 3.3396490e-02
 1.4506940e-14], sum to 1.0000
[2019-04-24 09:35:17,947] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8787
[2019-04-24 09:35:17,954] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.96666666666667, 72.33333333333334, 0.0, 0.0, 19.0, 22.71338421832239, -0.1041060011061698, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1201200.0000, 
sim time next is 1202400.0000, 
raw observation next is [16.6, 75.0, 0.0, 0.0, 19.0, 22.63793004878679, -0.117545795255383, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.922437673130194, 0.75, 0.0, 0.0, 0.08333333333333333, 0.3864941707322324, 0.46081806824820565, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4799368], dtype=float32), -1.4258218]. 
=============================================
[2019-04-24 09:35:18,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.57348228e-01 1.53802997e-02 1.18857615e-20 8.33714099e-19
 1.18981132e-18 9.28121447e-21 3.55152064e-20 1.10755738e-21
 3.49830748e-16 2.72714794e-02 5.21909801e-20], sum to 1.0000
[2019-04-24 09:35:18,928] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8593
[2019-04-24 09:35:19,019] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.2, 66.0, 0.0, 0.0, 19.0, 23.27335495634674, 0.06407141381369551, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1119600.0000, 
sim time next is 1120800.0000, 
raw observation next is [12.0, 67.66666666666667, 0.0, 0.0, 19.0, 23.19046807517337, 0.04419311965573588, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.7950138504155125, 0.6766666666666667, 0.0, 0.0, 0.08333333333333333, 0.4325390062644476, 0.5147310398852453, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.43064666], dtype=float32), -0.30622494]. 
=============================================
[2019-04-24 09:35:19,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6615469e-01 5.9328782e-03 8.9113351e-16 7.9609086e-15 1.7857635e-14
 8.9211998e-16 1.3091360e-15 5.9204893e-16 1.9172357e-12 2.7912416e-02
 1.4665578e-14], sum to 1.0000
[2019-04-24 09:35:19,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2803
[2019-04-24 09:35:19,581] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 78.66666666666667, 0.0, 0.0, 19.0, 23.03774249555666, -0.05664994668527704, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1210800.0000, 
sim time next is 1212000.0000, 
raw observation next is [16.1, 79.33333333333333, 0.0, 0.0, 19.0, 22.89129330349006, -0.07046256216627549, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.7933333333333333, 0.0, 0.0, 0.08333333333333333, 0.40760777529083825, 0.47651247927790813, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3298632], dtype=float32), -2.4262438]. 
=============================================
[2019-04-24 09:35:21,666] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.66772389e-01 4.09964994e-02 3.53337776e-17 3.82759842e-16
 6.21662256e-16 8.46046121e-18 2.81625915e-17 9.36655568e-18
 6.55173141e-14 1.92231134e-01 1.32899296e-17], sum to 1.0000
[2019-04-24 09:35:21,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5367
[2019-04-24 09:35:21,686] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.01515493670064, -0.5588700270682813, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1382400.0000, 
sim time next is 1383600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 20.8256961018108, -0.5822664141512126, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.2354746751508999, 0.30591119528292915, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5888989], dtype=float32), 0.18176584]. 
=============================================
[2019-04-24 09:35:26,039] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.1767806e-01 1.7334769e-02 4.8366882e-17 4.1589720e-16 1.7992770e-16
 3.5433903e-18 6.2164716e-18 1.7895962e-18 2.4932020e-13 6.4987190e-02
 1.3816384e-17], sum to 1.0000
[2019-04-24 09:35:26,039] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0388
[2019-04-24 09:35:26,143] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 41.33333333333334, 0.0, 22.5, 23.59835902900547, -0.1743487488054707, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1438800.0000, 
sim time next is 1440000.0000, 
raw observation next is [1.1, 92.0, 32.0, 0.0, 22.5, 23.3371015619787, -0.2342733932372742, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.92, 0.10666666666666667, 0.0, 0.375, 0.4447584634982249, 0.42190886892090856, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.73645747], dtype=float32), -0.6197838]. 
=============================================
[2019-04-24 09:35:26,151] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[80.66851 ]
 [80.77268 ]
 [79.9193  ]
 [79.99764 ]
 [80.078804]
 [80.26835 ]
 [80.39242 ]
 [80.49664 ]
 [80.64874 ]
 [79.512276]
 [79.5711  ]
 [79.57322 ]
 [79.509125]
 [79.477005]
 [79.35343 ]
 [79.24366 ]
 [79.181274]
 [78.67664 ]
 [79.08705 ]
 [79.27856 ]
 [79.54371 ]
 [79.45572 ]
 [79.897255]
 [80.14397 ]
 [80.1519  ]], R is [[80.77165222]
 [80.96393585]
 [80.15429688]
 [80.35275269]
 [80.54922485]
 [80.74373627]
 [80.93630219]
 [81.12693787]
 [81.3156662 ]
 [80.50251007]
 [80.67188263]
 [80.86516571]
 [81.05651855]
 [81.24595642]
 [81.43349457]
 [81.61916351]
 [81.80297089]
 [80.98493958]
 [80.32717133]
 [79.7614212 ]
 [79.03002167]
 [78.55564117]
 [78.10007477]
 [77.42330933]
 [76.64907837]].
[2019-04-24 09:35:26,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7362614e-01 1.4657972e-02 4.5703947e-19 1.6577408e-17 3.3417352e-17
 6.6486673e-19 8.9558773e-19 1.0233938e-19 2.8361725e-15 1.1715869e-02
 2.8420600e-18], sum to 1.0000
[2019-04-24 09:35:26,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1480
[2019-04-24 09:35:26,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 81.0, 0.0, 0.0, 19.0, 23.35448408314873, -0.172293453776945, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1560000.0000, 
sim time next is 1561200.0000, 
raw observation next is [5.0, 80.0, 0.0, 0.0, 19.0, 22.82272907207513, -0.2944004702057381, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6011080332409973, 0.8, 0.0, 0.0, 0.08333333333333333, 0.4018940893395942, 0.40186650993142065, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0800142], dtype=float32), -0.34690687]. 
=============================================
[2019-04-24 09:35:29,519] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.5820361e-01 2.6750263e-02 4.7026185e-19 1.6488314e-17 1.6302747e-17
 1.9151436e-19 8.2011292e-19 1.7669051e-20 1.9556862e-15 1.5046032e-02
 5.8489771e-19], sum to 1.0000
[2019-04-24 09:35:29,521] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9407
[2019-04-24 09:35:29,552] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.9, 82.66666666666667, 0.0, 0.0, 19.0, 22.4216063762104, -0.1799191569453019, 0.0, 1.0, 60.0, 61.7538040802264], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1575600.0000, 
sim time next is 1576800.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 19.0, 22.95774334780397, -0.2682702826849546, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.6011080332409973, 0.82, 0.0, 0.0, 0.08333333333333333, 0.4131452789836641, 0.4105765724383485, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39562485], dtype=float32), -0.042287897]. 
=============================================
[2019-04-24 09:35:32,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3913823e-01 1.5875118e-02 5.7138328e-16 4.1329058e-15 5.0909162e-15
 1.3348247e-16 2.6511245e-16 3.7222466e-17 8.1542526e-13 4.4986684e-02
 7.1588281e-16], sum to 1.0000
[2019-04-24 09:35:32,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7148
[2019-04-24 09:35:32,926] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.4, 91.66666666666667, 0.0, 0.0, 19.0, 19.68730882123073, -0.7308242944761932, 0.0, 1.0, 20.0, 79.0218218904482], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1732800.0000, 
sim time next is 1734000.0000, 
raw observation next is [0.3, 91.33333333333334, 0.0, 0.0, 19.0, 20.23710852582217, -0.8223870119807537, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.47091412742382277, 0.9133333333333334, 0.0, 0.0, 0.08333333333333333, 0.18642571048518075, 0.22587099600641544, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8054585], dtype=float32), -1.1190387]. 
=============================================
[2019-04-24 09:35:33,999] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.0809635e-01 4.3952722e-02 7.1299565e-16 4.9352574e-15 3.9424225e-15
 1.0029791e-16 1.6633952e-16 1.7969943e-17 3.0844346e-13 1.4795093e-01
 3.9980635e-16], sum to 1.0000
[2019-04-24 09:35:34,000] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6361
[2019-04-24 09:35:34,012] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 19.0, 20.00395710560136, -0.7683924959373482, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1730400.0000, 
sim time next is 1731600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 19.93588241263021, -0.7945851730775905, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.16132353438585087, 0.23513827564080317, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.802538], dtype=float32), -0.12851465]. 
=============================================
[2019-04-24 09:35:38,201] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [5.8439511e-01 2.3034947e-01 1.5801332e-13 1.8333128e-12 1.3465735e-12
 1.9702244e-13 3.7046066e-13 1.9957153e-14 7.5039155e-11 1.8525541e-01
 2.6200342e-13], sum to 1.0000
[2019-04-24 09:35:38,201] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8159
[2019-04-24 09:35:38,361] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-8.4, 78.0, 0.0, 0.0, 19.0, 18.88843276793512, -1.180474966877212, 0.0, 1.0, 60.0, 65.23152331629271], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1915200.0000, 
sim time next is 1916400.0000, 
raw observation next is [-8.566666666666666, 79.33333333333334, 0.0, 0.0, 19.0, 19.17798405996836, -1.125933203950184, 0.0, 1.0, 60.0, 65.57218901983615], 
processed observation next is [1.0, 0.17391304347826086, 0.22530009233610343, 0.7933333333333334, 0.0, 0.0, 0.08333333333333333, 0.09816533833069663, 0.12468893201660536, 0.0, 1.0, 0.9, 0.6557218901983615], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20903991], dtype=float32), 0.76670796]. 
=============================================
[2019-04-24 09:35:41,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9100819e-01 1.1797819e-01 7.8716753e-13 1.3375621e-12 2.2544824e-12
 5.9712998e-13 2.7155673e-13 8.3812358e-14 7.4781480e-11 2.9101360e-01
 2.5719989e-13], sum to 1.0000
[2019-04-24 09:35:41,364] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9930
[2019-04-24 09:35:41,407] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.0, 77.66666666666667, 0.0, 0.0, 19.0, 18.61322032755599, -1.338987667852417, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1892400.0000, 
sim time next is 1893600.0000, 
raw observation next is [-6.2, 75.0, 0.0, 0.0, 19.0, 18.61786099478719, -1.083399480836825, 0.0, 1.0, 60.0, 99.93580891833462], 
processed observation next is [0.0, 0.9565217391304348, 0.2908587257617729, 0.75, 0.0, 0.0, 0.08333333333333333, 0.05148841623226582, 0.13886683972105832, 0.0, 1.0, 0.9, 0.9993580891833461], 
reward next is 0.1979, 
noisyNet noise sample is [array([1.2777337], dtype=float32), -0.75415564]. 
=============================================
[2019-04-24 09:35:41,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0365751e-01 4.8108920e-02 1.4145718e-14 8.2413297e-14 1.4932573e-13
 2.8398266e-15 1.4347832e-14 7.1626461e-15 5.8018826e-11 2.4823359e-01
 4.6454356e-14], sum to 1.0000
[2019-04-24 09:35:41,699] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1629
[2019-04-24 09:35:41,789] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.733333333333333, 77.66666666666667, 156.6666666666667, 288.1666666666667, 22.5, 22.81619850382678, -0.5403128542933763, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1938000.0000, 
sim time next is 1939200.0000, 
raw observation next is [-6.166666666666666, 76.33333333333334, 181.1666666666667, 198.3333333333333, 22.5, 22.10149090712887, -0.6713207328326254, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.29178208679593726, 0.7633333333333334, 0.603888888888889, 0.21915285451197047, 0.375, 0.3417909089274058, 0.27622642238912487, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.2662, 
noisyNet noise sample is [array([-1.3877491], dtype=float32), 2.0045152]. 
=============================================
[2019-04-24 09:35:43,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1791122e-01 3.1550743e-02 8.6413271e-14 3.7458686e-13 1.1764617e-13
 3.0122531e-15 1.3605033e-14 3.4397991e-15 5.9735009e-11 3.5053807e-01
 1.8365772e-14], sum to 1.0000
[2019-04-24 09:35:43,391] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5333
[2019-04-24 09:35:43,447] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.199999999999999, 68.33333333333333, 231.1666666666667, 9.0, 22.5, 22.12304527013562, -0.6587690807807282, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1942800.0000, 
sim time next is 1944000.0000, 
raw observation next is [-5.0, 65.0, 229.5, 7.0, 22.5, 21.73280432864831, -0.7113452075866881, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.32409972299168976, 0.65, 0.765, 0.0077348066298342545, 0.375, 0.3110670273873592, 0.2628849308044373, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.71369016], dtype=float32), 1.5759928]. 
=============================================
[2019-04-24 09:35:50,530] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.0860049e-01 1.1565123e-01 1.9913220e-13 2.2075373e-13 1.0115275e-12
 5.1996402e-14 4.7834952e-14 1.4805016e-14 1.0095163e-10 6.7574829e-01
 6.0998434e-14], sum to 1.0000
[2019-04-24 09:35:50,531] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7896
[2019-04-24 09:35:50,817] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.6, 75.0, 21.5, 131.0, 22.5, 18.94492259384808, -1.16987663406505, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2188800.0000, 
sim time next is 2190000.0000, 
raw observation next is [-5.6, 75.0, 34.50000000000001, 218.3333333333333, 22.5, 19.83522424353481, -0.6876556210736918, 1.0, 1.0, 60.0, 123.14850598602524], 
processed observation next is [1.0, 0.34782608695652173, 0.30747922437673136, 0.75, 0.11500000000000002, 0.24125230202578263, 0.375, 0.15293535362790087, 0.2707814596421027, 1.0, 1.0, 0.9, 1.2314850598602525], 
reward next is 0.9383, 
noisyNet noise sample is [array([0.3436643], dtype=float32), -0.34661385]. 
=============================================
[2019-04-24 09:35:50,832] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[65.9367  ]
 [65.54104 ]
 [65.55137 ]
 [65.49663 ]
 [65.10919 ]
 [65.298416]
 [64.68126 ]
 [64.97879 ]
 [65.40351 ]
 [65.86285 ]
 [66.2187  ]
 [65.64678 ]
 [65.9126  ]
 [65.4933  ]
 [65.94725 ]
 [65.29404 ]
 [65.138824]
 [65.116325]
 [64.62858 ]
 [64.68544 ]
 [64.970116]
 [64.44946 ]
 [64.95904 ]
 [65.27974 ]
 [65.46971 ]], R is [[67.4821701 ]
 [66.80735016]
 [66.1392746 ]
 [65.47788239]
 [64.82310486]
 [65.17487335]
 [64.62458038]
 [64.43313599]
 [64.7888031 ]
 [65.14091492]
 [65.48950958]
 [64.83461761]
 [65.18627167]
 [64.7507782 ]
 [65.10327148]
 [64.45223999]
 [64.80771637]
 [65.15963745]
 [64.62080383]
 [64.97459412]
 [65.32485199]
 [64.67160034]
 [65.02488708]
 [65.37464142]
 [65.72089386]].
[2019-04-24 09:35:54,100] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.5213658e-01 6.9711640e-02 3.1464547e-14 5.5398916e-14 1.0476736e-13
 5.3250480e-15 1.4172717e-14 1.1600172e-15 2.2934135e-11 5.7815170e-01
 1.4072326e-14], sum to 1.0000
[2019-04-24 09:35:54,102] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9810
[2019-04-24 09:35:54,316] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.199999999999999, 72.33333333333333, 104.5, 375.8333333333334, 22.5, 22.61816414961022, -0.51543241645552, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2194800.0000, 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 109.5, 225.5, 22.5, 22.51415617137712, -0.3488664059356762, 1.0, 1.0, 60.0, 80.28735604280996], 
processed observation next is [1.0, 0.43478260869565216, 0.32409972299168976, 0.71, 0.365, 0.24917127071823206, 0.375, 0.37617968094809334, 0.3837111980214412, 1.0, 1.0, 0.9, 0.8028735604280997], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80892956], dtype=float32), -0.38815165]. 
=============================================
[2019-04-24 09:35:55,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1177211e-01 4.0882997e-02 1.8942872e-14 3.6395298e-13 4.3564371e-13
 9.5536406e-15 2.9931888e-14 8.5027607e-15 4.3947231e-11 1.4734487e-01
 1.7029711e-14], sum to 1.0000
[2019-04-24 09:35:55,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0044
[2019-04-24 09:35:55,353] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 91.0, 24.0, 18.0, 22.5, 20.92701826815291, -0.6211940301263826, 1.0, 1.0, 60.0, 102.1435068774754], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2275200.0000, 
sim time next is 2276400.0000, 
raw observation next is [-9.133333333333333, 89.66666666666667, 38.0, 16.66666666666667, 22.5, 21.53646972850736, -0.7029517385078748, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.20960295475530935, 0.8966666666666667, 0.12666666666666668, 0.018416206261510134, 0.375, 0.29470581070894664, 0.2656827538307084, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3925458], dtype=float32), 0.42844033]. 
=============================================
[2019-04-24 09:35:57,599] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.79621172e-01 7.39934389e-03 6.87220171e-16 1.08066774e-13
 9.06182139e-14 2.48884326e-15 4.76314367e-15 3.87451928e-16
 1.23000299e-11 1.29795168e-02 7.39400809e-15], sum to 1.0000
[2019-04-24 09:35:57,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2332
[2019-04-24 09:35:57,615] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 77.33333333333334, 0.0, 0.0, 19.0, 21.25767104314719, -0.5032340559640067, 0.0, 1.0, 60.0, 85.34395531839675], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2251200.0000, 
sim time next is 2252400.0000, 
raw observation next is [-7.1, 79.66666666666667, 0.0, 0.0, 19.0, 21.54183043399997, -0.6660700717437339, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.2659279778393352, 0.7966666666666667, 0.0, 0.0, 0.08333333333333333, 0.2951525361666641, 0.2779766427520887, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.20991558], dtype=float32), -0.052481864]. 
=============================================
[2019-04-24 09:35:57,698] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7905408e-01 8.6567007e-02 2.2249248e-14 4.2134549e-13 4.8913488e-13
 2.2106186e-14 1.0388017e-13 5.2980318e-15 6.8844028e-11 2.3437892e-01
 1.5524628e-14], sum to 1.0000
[2019-04-24 09:35:57,701] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6876
[2019-04-24 09:35:57,745] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-7.633333333333333, 84.66666666666666, 0.0, 0.0, 19.0, 21.47607440812799, -0.7038229995450718, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2256000.0000, 
sim time next is 2257200.0000, 
raw observation next is [-7.8, 86.0, 0.0, 0.0, 19.0, 20.9463113254707, -0.6046210774734194, 0.0, 1.0, 20.0, 69.21653406209964], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.86, 0.0, 0.0, 0.08333333333333333, 0.2455259437892249, 0.2984596408421935, 0.0, 1.0, 0.1, 0.6921653406209964], 
reward next is 0.2078, 
noisyNet noise sample is [array([-0.20991558], dtype=float32), -0.052481864]. 
=============================================
[2019-04-24 09:35:58,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5659200e-01 1.6214210e-01 3.7450357e-13 4.0331773e-13 3.7214239e-13
 3.0608664e-14 5.0910841e-14 2.6044408e-14 3.5241029e-11 4.8126590e-01
 4.0302072e-14], sum to 1.0000
[2019-04-24 09:35:58,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3411
[2019-04-24 09:35:58,248] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.100000000000001, 91.0, 0.0, 0.0, 19.0, 19.28653293770611, -1.048315821902092, 0.0, 1.0, 20.0, 41.99154890125538], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2269200.0000, 
sim time next is 2270400.0000, 
raw observation next is [-9.3, 91.0, 0.0, 0.0, 19.0, 19.13441247941692, -1.158692527111914, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.20498614958448752, 0.91, 0.0, 0.0, 0.08333333333333333, 0.0945343732847433, 0.11376915762936202, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.58799475], dtype=float32), 3.008192]. 
=============================================
[2019-04-24 09:35:58,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.4294716e-01 9.4207823e-02 1.1517411e-13 5.3220828e-13 5.7302069e-13
 8.9924142e-14 9.3935324e-14 9.1397006e-15 4.7055138e-11 1.6284500e-01
 5.4431381e-14], sum to 1.0000
[2019-04-24 09:35:58,543] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2196
[2019-04-24 09:35:58,576] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 66.33333333333334, 0.0, 0.0, 19.0, 20.30187607080476, -0.9121548204357991, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2355600.0000, 
sim time next is 2356800.0000, 
raw observation next is [-3.2, 67.66666666666667, 0.0, 0.0, 19.0, 19.6916067522283, -1.00795252184426, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.37396121883656513, 0.6766666666666667, 0.0, 0.0, 0.08333333333333333, 0.14096722935235828, 0.16401582605191334, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2640074], dtype=float32), -1.1801262]. 
=============================================
[2019-04-24 09:35:59,391] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.10459220e-01 2.83966176e-02 1.03536835e-14 3.60210749e-13
 1.18977636e-13 4.22562418e-15 6.75672803e-15 2.68235556e-15
 1.61418396e-11 6.11441433e-02 2.81250734e-14], sum to 1.0000
[2019-04-24 09:35:59,393] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7573
[2019-04-24 09:35:59,430] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 72.33333333333334, 0.0, 0.0, 19.0, 21.48405934892945, -0.4866768607211038, 0.0, 1.0, 20.0, 68.84976549389758], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2240400.0000, 
sim time next is 2241600.0000, 
raw observation next is [-6.0, 73.66666666666667, 0.0, 0.0, 19.0, 21.38237664973863, -0.6631562748929899, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.7366666666666667, 0.0, 0.0, 0.08333333333333333, 0.2818647208115526, 0.27894790836900335, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.7882824], dtype=float32), 0.3128565]. 
=============================================
[2019-04-24 09:36:09,850] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.2228558e-01 2.0215282e-01 2.2578356e-11 4.6125777e-11 7.9593686e-11
 2.0190873e-11 1.6466302e-11 3.5407421e-12 3.3557799e-09 2.7556160e-01
 2.0897305e-11], sum to 1.0000
[2019-04-24 09:36:09,865] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7565
[2019-04-24 09:36:09,964] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-9.5, 61.0, 0.0, 0.0, 19.0, 19.06325990205871, -1.123900361616643, 0.0, 1.0, 20.0, 46.01131908870373], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2444400.0000, 
sim time next is 2445600.0000, 
raw observation next is [-9.5, 60.0, 0.0, 0.0, 19.0, 19.2156503945595, -1.087736860181844, 0.0, 1.0, 60.0, 60.224215029512145], 
processed observation next is [0.0, 0.30434782608695654, 0.1994459833795014, 0.6, 0.0, 0.0, 0.08333333333333333, 0.10130419954662499, 0.137421046606052, 0.0, 1.0, 0.9, 0.6022421502951214], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8220598], dtype=float32), 0.089829884]. 
=============================================
[2019-04-24 09:36:17,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6398166e-01 2.9982917e-02 6.3908073e-15 3.7829504e-14 6.0391213e-14
 1.3861324e-15 5.3709115e-16 3.7243401e-16 1.7175482e-11 1.0603542e-01
 3.0287696e-15], sum to 1.0000
[2019-04-24 09:36:17,509] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4822
[2019-04-24 09:36:17,528] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666667, 70.0, 0.0, 0.0, 19.0, 21.77809725399818, -0.4162837056533153, 0.0, 1.0, 20.0, 48.85938127405903], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2676000.0000, 
sim time next is 2677200.0000, 
raw observation next is [-6.333333333333333, 71.0, 0.0, 0.0, 19.0, 21.73971772349705, -0.5933053435658494, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.28716528162511545, 0.71, 0.0, 0.0, 0.08333333333333333, 0.31164314362475426, 0.30223155214471686, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0865805], dtype=float32), 0.3614236]. 
=============================================
[2019-04-24 09:36:22,725] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.3896708e-01 4.5824286e-02 1.5873746e-14 2.1933856e-13 1.1634061e-13
 4.0120114e-15 8.3037706e-15 3.7147812e-15 4.0533393e-11 1.1520862e-01
 1.3927434e-14], sum to 1.0000
[2019-04-24 09:36:22,750] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4128
[2019-04-24 09:36:22,814] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 56.0, 0.0, 0.0, 19.0, 20.63933137769678, -0.7250373187318742, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2582400.0000, 
sim time next is 2583600.0000, 
raw observation next is [-2.8, 56.0, 0.0, 0.0, 19.0, 20.47785432016966, -0.757624924635753, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.38504155124653744, 0.56, 0.0, 0.0, 0.08333333333333333, 0.2064878600141382, 0.24745835845474898, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11891779], dtype=float32), 0.23150559]. 
=============================================
[2019-04-24 09:36:25,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5254049e-01 2.0180756e-02 3.4098026e-14 2.2310067e-13 1.2917988e-13
 3.8125808e-15 1.2698608e-14 7.1336064e-15 4.0101717e-11 1.2727875e-01
 5.7024000e-14], sum to 1.0000
[2019-04-24 09:36:25,879] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8664
[2019-04-24 09:36:26,095] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-5.199999999999999, 57.0, 107.8333333333333, 778.8333333333334, 22.5, 21.65211748388275, -0.5004023459656047, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2727600.0000, 
sim time next is 2728800.0000, 
raw observation next is [-4.8, 56.0, 105.5, 760.5, 22.5, 23.09804032945834, -0.188433108242015, 1.0, 1.0, 20.0, 85.92687690826027], 
processed observation next is [1.0, 0.6086956521739131, 0.3296398891966759, 0.56, 0.3516666666666667, 0.8403314917127072, 0.375, 0.42483669412152825, 0.4371889639193283, 1.0, 1.0, 0.1, 0.8592687690826026], 
reward next is 0.0407, 
noisyNet noise sample is [array([-0.90820515], dtype=float32), -1.86728]. 
=============================================
[2019-04-24 09:36:29,923] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.1203035e-01 9.6006274e-02 2.2663893e-13 1.2505125e-12 1.8334125e-12
 1.6160494e-13 1.7622132e-13 2.0964182e-14 9.1011601e-11 1.9196340e-01
 1.3011800e-13], sum to 1.0000
[2019-04-24 09:36:29,925] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6905
[2019-04-24 09:36:29,935] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 19.6796165482695, -1.045178476344397, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2769600.0000, 
sim time next is 2770800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 19.25346184901318, -1.112467586840432, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.10445515408443178, 0.12917747105318936, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.31475756], dtype=float32), -1.0944564]. 
=============================================
[2019-04-24 09:36:31,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5916632e-01 6.1180752e-02 2.7705480e-14 7.9497308e-13 8.1532464e-13
 4.0865372e-14 2.6296143e-14 1.5623396e-14 2.0078210e-11 7.9652950e-02
 1.9114676e-14], sum to 1.0000
[2019-04-24 09:36:31,736] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6460
[2019-04-24 09:36:31,749] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.33503346480421, -0.7740397633663414, 0.0, 1.0, 60.0, 65.48216089000958], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2785200.0000, 
sim time next is 2786400.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.71427370632615, -0.893970039539778, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.22618947552717916, 0.20200998682007398, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21327303], dtype=float32), -0.017851707]. 
=============================================
[2019-04-24 09:36:37,025] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 38817: loss -2.0819
[2019-04-24 09:36:37,103] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 38819: learning rate 0.0000
[2019-04-24 09:36:37,122] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 38832: loss -4.8242
[2019-04-24 09:36:37,124] A3C_AGENT_WORKER-Thread-7 DEBUG:Local step 2500, global step 38832: learning rate 0.0000
[2019-04-24 09:36:37,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 38939: loss 22.1724
[2019-04-24 09:36:37,416] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 38941: learning rate 0.0000
[2019-04-24 09:36:37,851] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0467198e-01 1.2726788e-01 3.3670221e-17 3.7384466e-16 6.7580476e-16
 2.1000475e-17 2.2690994e-17 2.8531635e-18 9.2068761e-14 1.6806012e-01
 1.5086428e-17], sum to 1.0000
[2019-04-24 09:36:37,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0091
[2019-04-24 09:36:37,860] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39115: loss 1.3744
[2019-04-24 09:36:37,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39115: learning rate 0.0000
[2019-04-24 09:36:37,892] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 93.0, 0.0, 0.0, 22.5, 20.77639258934089, -0.844720258273551, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2877600.0000, 
sim time next is 2878800.0000, 
raw observation next is [2.0, 93.0, 17.5, 48.49999999999999, 22.5, 20.01824108057254, -0.9673428506544676, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.518005540166205, 0.93, 0.058333333333333334, 0.053591160220994465, 0.375, 0.16818675671437835, 0.1775523831151775, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05147157], dtype=float32), -0.7273687]. 
=============================================
[2019-04-24 09:36:38,668] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39385: loss -3.9953
[2019-04-24 09:36:38,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39386: learning rate 0.0000
[2019-04-24 09:36:38,789] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1562728e-01 3.8038012e-02 3.9597400e-13 7.0098398e-13 7.5336682e-13
 1.8582164e-13 5.8159938e-14 1.2357341e-14 7.5799284e-11 1.4633477e-01
 2.3670315e-13], sum to 1.0000
[2019-04-24 09:36:38,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7206
[2019-04-24 09:36:38,801] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.00000000000001, 0.0, 0.0, 19.0, 19.57153943322449, -0.9667911657409008, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3003600.0000, 
sim time next is 3004800.0000, 
raw observation next is [-2.0, 60.0, 0.0, 0.0, 19.0, 19.33762387985534, -1.010620076760842, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.40720221606648205, 0.6, 0.0, 0.0, 0.08333333333333333, 0.11146865665461163, 0.16312664107971933, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5809227], dtype=float32), -0.28940335]. 
=============================================
[2019-04-24 09:36:39,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8533924e-01 9.7609371e-02 1.9377984e-12 1.4157780e-12 4.1567370e-12
 7.3114279e-13 2.6958373e-12 1.3166024e-13 3.3295910e-10 6.1705142e-01
 4.6167421e-13], sum to 1.0000
[2019-04-24 09:36:39,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4797
[2019-04-24 09:36:39,515] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.0, 74.66666666666666, 0.0, 0.0, 19.0, 18.58047450886783, -1.252843286004778, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3048000.0000, 
sim time next is 3049200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 18.85031244261987, -0.9851481773591108, 0.0, 1.0, 60.0, 92.00669171873304], 
processed observation next is [0.0, 0.30434782608695654, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.07085937021832252, 0.17161727421362974, 0.0, 1.0, 0.9, 0.9200669171873304], 
reward next is 0.2994, 
noisyNet noise sample is [array([-1.0943489], dtype=float32), 0.17227997]. 
=============================================
[2019-04-24 09:36:39,785] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39761: loss 3.2249
[2019-04-24 09:36:39,790] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39763: learning rate 0.0000
[2019-04-24 09:36:40,165] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39935: loss -4.3727
[2019-04-24 09:36:40,167] A3C_AGENT_WORKER-Thread-4 DEBUG:Local step 2500, global step 39935: learning rate 0.0000
[2019-04-24 09:36:40,885] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 40175: loss 6.2529
[2019-04-24 09:36:40,892] A3C_AGENT_WORKER-Thread-6 DEBUG:Local step 2500, global step 40180: learning rate 0.0000
[2019-04-24 09:36:41,109] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40266: loss -2.6167
[2019-04-24 09:36:41,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40281: learning rate 0.0000
[2019-04-24 09:36:41,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5400082e-01 2.9107189e-02 2.4755186e-15 1.4947838e-14 1.7216246e-14
 8.7381544e-16 6.8398705e-16 2.7211172e-16 2.4166279e-12 3.1689206e-01
 1.8645325e-15], sum to 1.0000
[2019-04-24 09:36:41,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5548
[2019-04-24 09:36:41,297] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 19.0, 20.49717624915336, -0.8840788246372585, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3108000.0000, 
sim time next is 3109200.0000, 
raw observation next is [0.0, 100.0, 0.0, 0.0, 19.0, 19.87158534349717, -1.011211458265195, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.46260387811634357, 1.0, 0.0, 0.0, 0.08333333333333333, 0.15596544529143083, 0.16292951391160168, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3212011], dtype=float32), -0.73169297]. 
=============================================
[2019-04-24 09:36:41,360] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40377: loss 14.7460
[2019-04-24 09:36:41,366] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40378: learning rate 0.0000
[2019-04-24 09:36:41,490] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40439: loss -12.4341
[2019-04-24 09:36:41,491] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40439: learning rate 0.0000
[2019-04-24 09:36:41,616] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 40502: loss -0.8500
[2019-04-24 09:36:41,617] A3C_AGENT_WORKER-Thread-5 DEBUG:Local step 2500, global step 40502: learning rate 0.0000
[2019-04-24 09:36:41,630] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40507: loss -6.0565
[2019-04-24 09:36:41,631] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40507: learning rate 0.0000
[2019-04-24 09:36:42,819] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40940: loss -1.7891
[2019-04-24 09:36:42,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40941: learning rate 0.0000
[2019-04-24 09:36:43,047] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 41039: loss 3.9502
[2019-04-24 09:36:43,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 41039: learning rate 0.0000
[2019-04-24 09:36:43,090] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6592144e-01 3.5266049e-02 1.2947984e-13 6.0410460e-13 7.5654294e-13
 4.9540945e-14 6.0915953e-14 2.3281458e-14 3.1542605e-11 9.8812468e-02
 1.9087145e-13], sum to 1.0000
[2019-04-24 09:36:43,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9230
[2019-04-24 09:36:43,157] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.333333333333333, 61.66666666666667, 0.0, 0.0, 19.0, 19.87765881831537, -0.7412062727178355, 0.0, 1.0, 60.0, 90.5864468099384], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3007200.0000, 
sim time next is 3008400.0000, 
raw observation next is [-2.666666666666667, 63.33333333333333, 0.0, 0.0, 19.0, 20.92162067088807, -0.6275373210538255, 0.0, 1.0, 60.0, 59.92228123125338], 
processed observation next is [0.0, 0.8260869565217391, 0.38873499538319484, 0.6333333333333333, 0.0, 0.0, 0.08333333333333333, 0.2434683892406726, 0.29082089298205815, 0.0, 1.0, 0.9, 0.5992228123125338], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6062522], dtype=float32), -0.49944085]. 
=============================================
[2019-04-24 09:36:43,404] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 41187: loss -0.0976
[2019-04-24 09:36:43,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 41187: learning rate 0.0000
[2019-04-24 09:36:45,816] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.8052925e-01 1.7473079e-03 4.5086231e-21 2.6464442e-19 1.2945109e-19
 1.4327165e-21 3.3704708e-21 1.6931055e-21 8.0470205e-16 1.7723370e-02
 2.6387010e-20], sum to 1.0000
[2019-04-24 09:36:45,817] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5456
[2019-04-24 09:36:45,839] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 112.1666666666667, 808.8333333333334, 22.5, 25.32841071917871, 0.2607581190167989, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3158400.0000, 
sim time next is 3159600.0000, 
raw observation next is [7.0, 100.0, 110.1666666666667, 798.8333333333334, 22.5, 25.14844549888354, 0.2313579771373813, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 1.0, 0.36722222222222234, 0.8826887661141806, 0.375, 0.5957037915736283, 0.5771193257124604, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.85216135], dtype=float32), -1.4456698]. 
=============================================
[2019-04-24 09:36:54,426] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.8699555e-01 2.7200390e-02 5.4331124e-15 1.4216807e-13 4.7362813e-14
 9.1683958e-16 1.8368269e-15 1.4457403e-15 1.6517079e-11 8.5804075e-02
 4.3832837e-15], sum to 1.0000
[2019-04-24 09:36:54,427] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8328
[2019-04-24 09:36:54,470] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 21.58268123304318, -0.4901284133611774, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3362400.0000, 
sim time next is 3363600.0000, 
raw observation next is [-4.333333333333334, 67.0, 0.0, 0.0, 19.0, 21.29993327216802, -0.5975451333331551, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.3425669436749769, 0.67, 0.0, 0.0, 0.08333333333333333, 0.2749944393473349, 0.3008182888889483, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.44764125], dtype=float32), -2.145342]. 
=============================================
[2019-04-24 09:36:56,149] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3442625e-01 6.8452675e-03 7.0433059e-17 8.1324147e-16 1.1041567e-15
 1.9347437e-17 2.4130779e-17 8.4758385e-18 5.7044858e-13 5.8728486e-02
 2.2128205e-16], sum to 1.0000
[2019-04-24 09:36:56,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9738
[2019-04-24 09:36:56,199] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [2.0, 67.0, 64.83333333333333, 544.8333333333333, 22.5, 22.46747456634224, -0.3069794464382655, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3428400.0000, 
sim time next is 3429600.0000, 
raw observation next is [2.0, 67.0, 52.83333333333334, 447.6666666666667, 22.5, 23.3720504165023, 0.02700964285414417, 1.0, 1.0, 60.0, 91.51727246730346], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 0.67, 0.17611111111111113, 0.4946593001841621, 0.375, 0.4476708680418584, 0.5090032142847147, 1.0, 1.0, 0.9, 0.9151727246730346], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0890615], dtype=float32), 1.61274]. 
=============================================
[2019-04-24 09:36:59,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8570132e-01 3.9034367e-03 7.1498779e-18 1.2759518e-16 1.6373737e-16
 1.4270900e-18 4.8784536e-18 1.4038401e-18 2.9215884e-14 1.0395296e-02
 1.1450212e-17], sum to 1.0000
[2019-04-24 09:36:59,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7248
[2019-04-24 09:36:59,415] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 90.33333333333334, 702.6666666666666, 22.5, 25.73556174846169, 0.2215121698135155, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3511200.0000, 
sim time next is 3512400.0000, 
raw observation next is [3.0, 49.0, 83.66666666666667, 660.0, 22.5, 25.19919342101045, 0.2576977323176617, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.5457063711911359, 0.49, 0.2788888888888889, 0.7292817679558011, 0.375, 0.5999327850842041, 0.5858992441058872, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.40265226], dtype=float32), 0.13994318]. 
=============================================
[2019-04-24 09:36:59,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6496526e-01 3.4375288e-02 8.1300662e-15 3.1079058e-14 4.6921221e-14
 1.3183719e-14 4.3771503e-15 1.4110969e-15 1.1086332e-11 1.0065951e-01
 2.0583028e-14], sum to 1.0000
[2019-04-24 09:36:59,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1715
[2019-04-24 09:36:59,680] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.0, 25.0, 0.0, 0.0, 19.0, 20.39837885011525, -0.7263799949412205, 0.0, 1.0, 60.0, 87.7745264442212], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3636000.0000, 
sim time next is 3637200.0000, 
raw observation next is [8.733333333333334, 25.66666666666667, 0.0, 0.0, 19.0, 20.99584459597521, -0.8268484761342908, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.7045244690674055, 0.2566666666666667, 0.0, 0.0, 0.08333333333333333, 0.24965371633126754, 0.22438384128856972, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8050638], dtype=float32), -0.5190126]. 
=============================================
[2019-04-24 09:37:00,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0313170e-01 6.4207077e-02 7.9623828e-14 3.8415563e-13 2.4018258e-13
 5.3454257e-14 6.7698553e-14 5.5661902e-15 3.6827558e-11 1.3266119e-01
 6.1101318e-14], sum to 1.0000
[2019-04-24 09:37:00,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8634
[2019-04-24 09:37:00,751] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-3.666666666666667, 69.0, 0.0, 0.0, 19.0, 19.41745277239182, -0.7866204635382147, 0.0, 1.0, 20.0, 88.54754626054462], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 3555600.0000, 
sim time next is 3556800.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 19.0, 20.37839757170907, -0.7279053946931144, 0.0, 1.0, 20.0, 42.51667918767862], 
processed observation next is [0.0, 0.17391304347826086, 0.3518005540166205, 0.71, 0.0, 0.0, 0.08333333333333333, 0.19819979764242243, 0.2573648684356285, 0.0, 1.0, 0.1, 0.4251667918767862], 
reward next is 0.4748, 
noisyNet noise sample is [array([1.4923377], dtype=float32), 0.21703006]. 
=============================================
[2019-04-24 09:37:00,990] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.98211694e-01 1.01393968e-01 7.66857823e-14 4.43162000e-13
 1.97859659e-13 7.45587064e-14 3.65262935e-14 7.83559009e-15
 3.82397343e-11 1.00394346e-01 8.81900821e-14], sum to 1.0000
[2019-04-24 09:37:00,991] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0557
[2019-04-24 09:37:01,005] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666666, 68.33333333333334, 98.0, 634.1666666666667, 19.0, 20.97596671193082, -0.6878727094646204, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3576000.0000, 
sim time next is 3577200.0000, 
raw observation next is [-5.333333333333333, 66.66666666666666, 101.8333333333333, 689.6666666666666, 19.0, 20.45054743307008, -0.7924320015437566, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3148661126500462, 0.6666666666666665, 0.3394444444444443, 0.7620626151012891, 0.08333333333333333, 0.20421228608917344, 0.23585599948541447, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1352514], dtype=float32), -0.097235724]. 
=============================================
[2019-04-24 09:37:01,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.44955409e-01 7.57256569e-03 7.06923639e-17 1.07811550e-15
 1.48596017e-15 1.51979350e-17 1.09146025e-16 1.87957455e-17
 8.97326376e-13 4.74720187e-02 7.78937255e-17], sum to 1.0000
[2019-04-24 09:37:01,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6139
[2019-04-24 09:37:01,551] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666667, 65.33333333333334, 0.0, 0.0, 22.5, 22.31521607115375, -0.3010227615552748, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3526800.0000, 
sim time next is 3528000.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 22.05894508925787, -0.3475775528654239, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.33824542410482233, 0.38414081571152536, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1093017], dtype=float32), 2.125063]. 
=============================================
[2019-04-24 09:37:03,112] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.9711082e-01 5.7533614e-02 6.5306611e-16 2.6062450e-15 6.2528675e-15
 5.6031717e-16 8.2215866e-16 3.3470686e-17 6.7071007e-13 4.5355551e-02
 1.1723406e-15], sum to 1.0000
[2019-04-24 09:37:03,113] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4870
[2019-04-24 09:37:03,135] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.333333333333334, 30.33333333333334, 18.16666666666666, 168.0, 19.0, 21.01055640565038, -0.5811297131893439, 0.0, 1.0, 20.0, 70.63544820682218], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3656400.0000, 
sim time next is 3657600.0000, 
raw observation next is [8.0, 32.0, 46.5, 262.0, 19.0, 21.48735944788467, -0.6353806056571851, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.6842105263157896, 0.32, 0.155, 0.28950276243093925, 0.08333333333333333, 0.2906132873237226, 0.2882064647809383, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3918688], dtype=float32), -1.3833053]. 
=============================================
[2019-04-24 09:37:03,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6466810e-01 9.4792787e-03 1.5418403e-16 2.1087415e-15 1.6702850e-15
 2.4934011e-16 2.3577435e-16 2.4389407e-17 8.9507443e-13 2.5852639e-02
 1.0361821e-15], sum to 1.0000
[2019-04-24 09:37:03,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1761
[2019-04-24 09:37:03,519] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 44.33333333333334, 105.5, 783.0, 19.0, 20.94685897056069, -0.5812345802303788, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3680400.0000, 
sim time next is 3681600.0000, 
raw observation next is [6.0, 45.66666666666667, 101.1666666666667, 764.1666666666667, 19.0, 21.06106588569307, -0.5675002454636391, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6288088642659281, 0.4566666666666667, 0.3372222222222223, 0.8443830570902395, 0.08333333333333333, 0.2550888238077557, 0.3108332515121203, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23698172], dtype=float32), -0.7989344]. 
=============================================
[2019-04-24 09:37:05,272] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-24 09:37:05,273] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:37:05,273] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:37:05,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run2
[2019-04-24 09:37:05,297] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:37:05,306] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:37:05,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run2
[2019-04-24 09:37:05,342] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:37:05,344] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:37:05,347] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run2
[2019-04-24 09:38:34,697] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3396.1739 61399.0936 -243.0646
[2019-04-24 09:38:34,757] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:38:34,757] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:38:34,961] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:38:34,961] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:38:47,911] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3162.7767 76582.5553 -515.1718
[2019-04-24 09:38:47,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:38:47,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:38:48,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:38:48,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:39:01,168] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3077.8943 80029.6973 -570.0198
[2019-04-24 09:39:01,198] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:39:01,198] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:39:01,322] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:39:01,322] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:39:02,200] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 50000, evaluation results [50000.0, 3162.7767042481187, 76582.55526313598, -515.1717703603182, 3396.17389119516, 61399.093575780775, -243.06464008909873, 3077.894343929703, 80029.6972555303, -570.0197596978936]
[2019-04-24 09:39:07,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5233947e-01 9.4143460e-03 1.5180877e-16 6.3829576e-16 7.9027348e-16
 1.5100472e-17 9.2188038e-18 1.8436869e-18 1.1451002e-12 3.8246173e-02
 1.5606767e-16], sum to 1.0000
[2019-04-24 09:39:07,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1276
[2019-04-24 09:39:07,324] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 51.0, 115.0, 829.5, 22.5, 22.20127980724368, -0.3353267128524364, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3848400.0000, 
sim time next is 3849600.0000, 
raw observation next is [1.333333333333333, 50.00000000000001, 113.6666666666667, 825.8333333333334, 22.5, 22.52092049117519, -0.2741024247390886, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4995383194829178, 0.5000000000000001, 0.378888888888889, 0.912523020257827, 0.375, 0.37674337426459914, 0.40863252508697046, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0319701], dtype=float32), 0.44703358]. 
=============================================
[2019-04-24 09:39:09,243] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.6340197e-01 1.7399164e-02 2.1780019e-16 7.6867766e-15 7.7246076e-15
 2.2151968e-16 3.2376087e-16 1.1659293e-16 1.1748475e-12 1.9198878e-02
 5.0718935e-16], sum to 1.0000
[2019-04-24 09:39:09,256] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9449
[2019-04-24 09:39:09,281] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 67.0, 0.0, 0.0, 19.0, 21.75258178948359, -0.4782074084317791, 0.0, 1.0, 60.0, 62.70901923033149], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3900000.0000, 
sim time next is 3901200.0000, 
raw observation next is [-2.666666666666667, 69.0, 0.0, 0.0, 19.0, 21.7690384794789, -0.6471661554311318, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.38873499538319484, 0.69, 0.0, 0.0, 0.08333333333333333, 0.3140865399565751, 0.28427794818962276, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.373877], dtype=float32), -1.0853025]. 
=============================================
[2019-04-24 09:39:11,918] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.8603445e-01 4.4083595e-03 1.7913652e-15 6.0193333e-14 2.3949193e-14
 1.9973673e-16 5.8530580e-16 2.3390193e-16 5.0901258e-12 9.5572285e-03
 4.0996628e-15], sum to 1.0000
[2019-04-24 09:39:11,920] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0618
[2019-04-24 09:39:11,942] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 38.0, 42.5, 352.5, 22.5, 23.52571876297659, 0.1165067585872772, 1.0, 1.0, 60.0, 90.2708958561388], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3949200.0000, 
sim time next is 3950400.0000, 
raw observation next is [-5.333333333333334, 39.0, 26.83333333333333, 230.1666666666667, 22.5, 24.72852632285153, -0.07167312649218603, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.31486611265004616, 0.39, 0.08944444444444442, 0.2543278084714549, 0.375, 0.5607105269042941, 0.47610895783593804, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.44530737], dtype=float32), -0.12953453]. 
=============================================
[2019-04-24 09:39:12,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6928787e-01 5.6985077e-03 8.1442489e-15 1.0877034e-13 1.4000099e-13
 5.2953607e-15 6.7938814e-15 1.3202683e-15 2.4914241e-11 2.5013607e-02
 2.0658459e-14], sum to 1.0000
[2019-04-24 09:39:12,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8313
[2019-04-24 09:39:12,989] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 26.0, 0.0, 0.0, 22.5, 22.7372585638154, -0.1811798687934605, 1.0, 1.0, 20.0, 70.33291881753804], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4039200.0000, 
sim time next is 4040400.0000, 
raw observation next is [-3.333333333333333, 27.66666666666667, 0.0, 0.0, 22.5, 23.36026673701323, -0.2506633699822098, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.37026777469990774, 0.2766666666666667, 0.0, 0.0, 0.375, 0.4466888947511025, 0.41644554333926337, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6130806], dtype=float32), -1.4440995]. 
=============================================
[2019-04-24 09:39:17,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5754308e-01 1.0631805e-02 2.9235403e-16 1.7793500e-15 2.2709495e-15
 8.1161804e-17 6.9961844e-17 3.5372797e-17 1.6839924e-12 3.1825032e-02
 3.2233744e-16], sum to 1.0000
[2019-04-24 09:39:17,479] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8889
[2019-04-24 09:39:17,502] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 35.0, 19.16666666666667, 47.5, 22.5, 23.28391408854377, -0.1303584507197346, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4124400.0000, 
sim time next is 4125600.0000, 
raw observation next is [3.0, 34.0, 0.0, 0.0, 22.5, 23.34084637403115, -0.136273814591029, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5457063711911359, 0.34, 0.0, 0.0, 0.375, 0.4450705311692624, 0.45457539513632367, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25821212], dtype=float32), 0.2750613]. 
=============================================
[2019-04-24 09:39:22,577] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.29331696e-01 4.98568043e-02 8.03461030e-14 2.70831372e-13
 2.48988243e-12 3.53605288e-14 1.05589996e-13 5.14052988e-15
 4.82381565e-11 1.20811500e-01 1.10062926e-13], sum to 1.0000
[2019-04-24 09:39:22,585] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2286
[2019-04-24 09:39:22,602] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 41.33333333333334, 0.0, 0.0, 19.0, 19.40118762370486, -1.008442408364564, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4152000.0000, 
sim time next is 4153200.0000, 
raw observation next is [-1.666666666666667, 43.66666666666666, 0.0, 0.0, 19.0, 19.28926083366305, -1.036233833994655, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.4164358264081256, 0.4366666666666666, 0.0, 0.0, 0.08333333333333333, 0.10743840280525419, 0.15458872200178164, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4907082], dtype=float32), 0.6525879]. 
=============================================
[2019-04-24 09:39:29,871] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0849799e-01 4.0476557e-02 6.1341042e-18 3.9012184e-17 5.9299784e-17
 5.2883315e-18 6.7310358e-18 2.1938159e-19 1.2109334e-14 5.1025461e-02
 2.6537693e-18], sum to 1.0000
[2019-04-24 09:39:29,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6849
[2019-04-24 09:39:29,924] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.266666666666667, 67.33333333333334, 0.0, 0.0, 19.0, 21.49221323104442, -0.4761935442057391, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4422000.0000, 
sim time next is 4423200.0000, 
raw observation next is [4.033333333333333, 67.66666666666666, 0.0, 0.0, 19.0, 21.38550993131706, -0.5060076014709274, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5743305632502309, 0.6766666666666665, 0.0, 0.0, 0.08333333333333333, 0.28212582760975496, 0.33133079950969085, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.4828904], dtype=float32), 0.10734947]. 
=============================================
[2019-04-24 09:39:30,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.2305076e-01 2.0257318e-02 1.6366372e-17 2.4052501e-16 3.6654149e-16
 4.9350813e-17 3.1539550e-17 3.2942001e-18 1.7150472e-13 5.6691874e-02
 1.2405609e-16], sum to 1.0000
[2019-04-24 09:39:30,622] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7822
[2019-04-24 09:39:30,633] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.933333333333334, 57.33333333333333, 108.3333333333333, 638.5, 19.0, 20.41233588193651, -0.7272110386479436, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4290000.0000, 
sim time next is 4291200.0000, 
raw observation next is [7.0, 56.0, 93.0, 605.5, 19.0, 20.46672505516484, -0.7183313164414719, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6565096952908588, 0.56, 0.31, 0.669060773480663, 0.08333333333333333, 0.20556042126373666, 0.2605562278528427, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.113086], dtype=float32), -0.6110646]. 
=============================================
[2019-04-24 09:39:39,361] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2865187e-01 9.2339190e-03 2.8413816e-17 1.4202438e-16 2.7924167e-16
 6.6383387e-18 3.8003453e-18 4.0766314e-18 5.5995718e-14 6.2114183e-02
 1.5038688e-17], sum to 1.0000
[2019-04-24 09:39:39,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0395
[2019-04-24 09:39:39,416] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1997579e-01 1.8050181e-02 3.3141395e-16 4.2970049e-15 1.9568786e-15
 1.4045267e-16 1.4459636e-16 5.3865224e-17 8.9596836e-13 1.6197407e-01
 3.9789476e-16], sum to 1.0000
[2019-04-24 09:39:39,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3665
[2019-04-24 09:39:39,486] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 23.0583125031374, -0.1943623152811003, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4477200.0000, 
sim time next is 4478400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 22.53146652516339, -0.3016576491311739, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.3776222104302824, 0.39944745028960876, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58562875], dtype=float32), 1.1588069]. 
=============================================
[2019-04-24 09:39:39,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3099898e-01 2.1270534e-02 1.3549049e-16 1.2411183e-15 2.4230587e-15
 2.0612826e-17 8.1302007e-17 2.3527928e-17 1.9093334e-13 4.7730394e-02
 6.8829500e-17], sum to 1.0000
[2019-04-24 09:39:39,504] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1465
[2019-04-24 09:39:39,579] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 68.5, 48.0, 22.5, 22.15978867436136, -0.4512205591780569, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4554000.0000, 
sim time next is 4555200.0000, 
raw observation next is [2.0, 52.0, 41.5, 34.66666666666666, 22.5, 22.24297113861755, -0.5585647631713212, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.52, 0.13833333333333334, 0.03830570902394106, 0.375, 0.35358092821812903, 0.3138117456095596, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9143, 
noisyNet noise sample is [array([-0.11963061], dtype=float32), -1.3199657]. 
=============================================
[2019-04-24 09:39:39,600] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 73.0, 20.5, 28.49999999999999, 22.5, 20.6827172772346, -0.4559007671313677, 1.0, 1.0, 60.0, 116.12583902949802], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4606800.0000, 
sim time next is 4608000.0000, 
raw observation next is [-2.0, 71.0, 61.5, 85.5, 22.5, 22.41174007481642, -0.4665518002428835, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.71, 0.205, 0.09447513812154697, 0.375, 0.3676450062347018, 0.34448273325237216, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7987154], dtype=float32), -1.3205867]. 
=============================================
[2019-04-24 09:39:44,814] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.0262790e-01 9.2256449e-02 6.7638117e-16 2.1766076e-15 2.3271557e-15
 4.2617674e-16 4.7367856e-16 9.8940901e-18 6.5645048e-13 2.0511562e-01
 1.3810095e-16], sum to 1.0000
[2019-04-24 09:39:44,827] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1212
[2019-04-24 09:39:44,976] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.5, 65.66666666666667, 0.0, 0.0, 19.0, 21.39452785798456, -0.594905787804171, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4587600.0000, 
sim time next is 4588800.0000, 
raw observation next is [-0.8, 66.33333333333333, 0.0, 0.0, 19.0, 21.22332550728246, -0.6507817223500661, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.4404432132963989, 0.6633333333333333, 0.0, 0.0, 0.08333333333333333, 0.268610458940205, 0.2830727592166446, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.59342563], dtype=float32), 1.4838967]. 
=============================================
[2019-04-24 09:39:55,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4799923e-01 1.2155160e-01 4.7272806e-17 3.5842204e-16 8.0205783e-16
 2.2485408e-17 1.1616877e-16 1.1280093e-17 2.3104896e-13 2.3044915e-01
 1.5202909e-16], sum to 1.0000
[2019-04-24 09:39:55,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7974
[2019-04-24 09:39:55,398] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.3333333333333333, 94.66666666666667, 0.0, 0.0, 19.0, 21.20151882661378, -0.6532506300218248, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4681200.0000, 
sim time next is 4682400.0000, 
raw observation next is [-0.6666666666666666, 97.33333333333333, 0.0, 0.0, 19.0, 21.42499255077743, -0.3554826922924929, 0.0, 1.0, 60.0, 92.72394344129398], 
processed observation next is [1.0, 0.17391304347826086, 0.44413665743305636, 0.9733333333333333, 0.0, 0.0, 0.08333333333333333, 0.28541604589811903, 0.3815057692358357, 0.0, 1.0, 0.9, 0.9272394344129399], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.71872103], dtype=float32), 1.8692162]. 
=============================================
[2019-04-24 09:39:57,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.25710106e-01 1.44625172e-01 5.83011016e-13 1.14616799e-13
 6.52190812e-13 2.41466027e-13 1.26003239e-13 1.36842205e-14
 7.92264587e-11 3.29664677e-01 1.54788698e-13], sum to 1.0000
[2019-04-24 09:39:57,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8936
[2019-04-24 09:39:57,820] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.666666666666667, 67.33333333333334, 0.0, 0.0, 19.0, 18.87016546850531, -1.197985371736196, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4857600.0000, 
sim time next is 4858800.0000, 
raw observation next is [-3.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 19.01793811862044, -0.939154406831506, 0.0, 1.0, 60.0, 95.3979617878401], 
processed observation next is [0.0, 0.21739130434782608, 0.37026777469990774, 0.6366666666666667, 0.0, 0.0, 0.08333333333333333, 0.08482817655170323, 0.18694853105616469, 0.0, 1.0, 0.9, 0.953979617878401], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02159934], dtype=float32), 1.1338934]. 
=============================================
[2019-04-24 09:40:01,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7040951e-01 1.0684965e-02 1.7780189e-16 5.1519216e-15 5.8483462e-15
 1.3747959e-16 7.0698579e-16 4.5824542e-17 6.2189631e-13 1.8905561e-02
 9.0672876e-16], sum to 1.0000
[2019-04-24 09:40:01,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2018
[2019-04-24 09:40:02,005] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 122.5, 734.5, 19.0, 20.69192411624121, -0.45062451003096, 0.0, 1.0, 20.0, 71.11987127981558], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4806000.0000, 
sim time next is 4807200.0000, 
raw observation next is [3.0, 37.0, 105.5, 729.5, 19.0, 21.75381586587736, -0.479371837797338, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.37, 0.3516666666666667, 0.8060773480662984, 0.08333333333333333, 0.31281798882311335, 0.34020938740088735, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.76754946], dtype=float32), 0.8965139]. 
=============================================
[2019-04-24 09:40:10,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.2586559e-01 1.6050963e-02 1.2059814e-16 1.3547019e-15 3.9781830e-15
 1.1237210e-16 2.3078101e-17 7.7679737e-18 3.5386982e-13 5.8083445e-02
 1.9261091e-16], sum to 1.0000
[2019-04-24 09:40:10,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4080
[2019-04-24 09:40:10,603] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 36.0, 0.0, 0.0, 19.0, 21.50565730311041, -0.5161112960479891, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5008800.0000, 
sim time next is 5010000.0000, 
raw observation next is [2.333333333333333, 38.0, 0.0, 0.0, 19.0, 21.35332983191018, -0.5505183271103488, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.5272391505078486, 0.38, 0.0, 0.0, 0.08333333333333333, 0.2794441526591817, 0.31649389096321706, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1198424], dtype=float32), -0.16679625]. 
=============================================
[2019-04-24 09:40:10,695] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.61739 ]
 [77.11931 ]
 [76.971344]
 [77.73661 ]
 [77.930244]
 [77.77505 ]
 [78.28518 ]
 [78.089165]
 [78.55565 ]
 [79.24252 ]
 [79.299934]
 [79.79162 ]
 [79.58883 ]
 [80.2152  ]
 [80.72105 ]
 [81.388535]
 [82.51403 ]
 [83.54435 ]
 [84.51546 ]
 [85.21156 ]
 [85.59489 ]
 [85.686295]
 [85.53204 ]
 [85.27763 ]
 [85.09898 ]], R is [[76.4752121 ]
 [76.71046448]
 [76.94335938]
 [77.17392731]
 [77.40219116]
 [77.6281662 ]
 [77.85188293]
 [78.07336426]
 [78.29263306]
 [78.50970459]
 [78.72460938]
 [78.93736267]
 [79.14798737]
 [79.35650635]
 [79.5629425 ]
 [79.7673111 ]
 [79.96963501]
 [80.16993713]
 [80.36824036]
 [80.56455994]
 [80.75891876]
 [80.95133209]
 [81.14182281]
 [81.33040619]
 [81.5171051 ]].
[2019-04-24 09:40:12,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:12,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:13,122] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:13,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:13,763] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5310873e-01 2.0765698e-02 4.2553220e-15 3.5241693e-14 6.3502663e-14
 9.3751326e-15 3.8231281e-15 5.4692144e-16 3.1734214e-12 2.6125653e-02
 9.0164590e-15], sum to 1.0000
[2019-04-24 09:40:13,765] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1027
[2019-04-24 09:40:13,798] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666667, 41.0, 0.0, 0.0, 19.0, 19.4770680784476, -0.8153822273204111, 0.0, 1.0, 60.0, 98.35330687253986], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4926000.0000, 
sim time next is 4927200.0000, 
raw observation next is [0.3333333333333334, 42.0, 0.0, 0.0, 19.0, 20.63390081374155, -0.8567423376570357, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4718374884579871, 0.42, 0.0, 0.0, 0.08333333333333333, 0.2194917344784626, 0.2144192207809881, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0809622], dtype=float32), 0.73461175]. 
=============================================
[2019-04-24 09:40:13,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:13,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:13,932] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run2
[2019-04-24 09:40:14,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:14,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:14,019] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run2
[2019-04-24 09:40:14,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:15,187] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:15,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:15,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:15,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:15,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:15,922] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run2
[2019-04-24 09:40:16,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:16,309] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:16,312] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run2
[2019-04-24 09:40:17,003] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:17,108] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:17,232] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:17,307] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:17,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:17,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:17,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:17,981] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:17,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run2
[2019-04-24 09:40:18,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:18,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:18,116] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run2
[2019-04-24 09:40:18,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:18,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:18,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:18,217] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run2
[2019-04-24 09:40:18,450] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:18,884] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:19,039] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:19,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:19,121] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:19,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run2
[2019-04-24 09:40:19,331] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:19,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:19,468] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8683375e-01 3.9002812e-03 1.7540303e-20 5.3733864e-18 3.1551779e-18
 7.8684289e-20 1.8537846e-20 5.1060381e-21 2.0191588e-15 9.2660692e-03
 3.7869554e-19], sum to 1.0000
[2019-04-24 09:40:19,471] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8299
[2019-04-24 09:40:19,501] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.33333333333333, 17.0, 30.0, 243.3333333333333, 22.5, 26.24887311773286, 0.5394536315253885, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5074800.0000, 
sim time next is 5076000.0000, 
raw observation next is [11.0, 17.0, 18.0, 146.0, 22.5, 26.18756757037274, 0.5094371666043688, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.7673130193905818, 0.17, 0.06, 0.16132596685082873, 0.375, 0.6822972975310616, 0.6698123888681229, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14583424], dtype=float32), 0.29439712]. 
=============================================
[2019-04-24 09:40:19,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:19,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7261882e-01 1.1546961e-02 8.2657134e-19 2.5003786e-17 7.2574484e-17
 1.7925786e-18 3.1155812e-19 7.7114900e-19 1.5000140e-14 1.5834205e-02
 6.2045672e-18], sum to 1.0000
[2019-04-24 09:40:19,825] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7283
[2019-04-24 09:40:19,842] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.7, 19.0, 0.0, 0.0, 19.0, 23.93383860945511, 0.09970441153152472, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5090400.0000, 
sim time next is 5091600.0000, 
raw observation next is [8.6, 19.33333333333334, 0.0, 0.0, 19.0, 23.87678239781237, 0.02375884986661471, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.700831024930748, 0.19333333333333338, 0.0, 0.0, 0.08333333333333333, 0.4897318664843642, 0.507919616622205, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.95861465], dtype=float32), -0.6564768]. 
=============================================
[2019-04-24 09:40:19,846] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:19,860] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:19,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:19,862] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run2
[2019-04-24 09:40:20,030] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:20,031] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:20,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run2
[2019-04-24 09:40:20,135] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:20,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:20,285] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:20,426] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:20,456] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:20,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:20,488] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:20,490] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run2
[2019-04-24 09:40:20,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:21,118] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:21,118] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:21,120] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run2
[2019-04-24 09:40:21,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:21,205] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:21,207] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run2
[2019-04-24 09:40:21,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:21,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:21,283] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run2
[2019-04-24 09:40:21,761] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:22,175] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:22,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:40:22,762] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:22,762] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:22,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run2
[2019-04-24 09:40:23,010] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:40:23,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:40:23,586] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:40:23,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run2
[2019-04-24 09:40:37,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3943701e-01 2.9148480e-02 2.7549354e-18 1.1144972e-17 3.2357853e-17
 1.5154998e-18 6.2701291e-18 9.6520791e-20 5.6432672e-15 1.3141452e-01
 4.7316241e-18], sum to 1.0000
[2019-04-24 09:40:37,943] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3155
[2019-04-24 09:40:37,965] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 67.5, 0.0, 19.0, 20.36212945691145, -0.7198910084563979, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 39600.0000, 
sim time next is 40800.0000, 
raw observation next is [7.7, 93.0, 72.5, 0.0, 19.0, 20.21233263413144, -0.748337901360676, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.6759002770083103, 0.93, 0.24166666666666667, 0.0, 0.08333333333333333, 0.18436105284428658, 0.2505540328797747, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24686566], dtype=float32), -0.45842683]. 
=============================================
[2019-04-24 09:40:41,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6984671e-01 3.5201605e-02 1.5266534e-14 4.8598078e-14 4.8105054e-14
 1.6393219e-15 4.7775123e-15 1.1740491e-15 9.0202229e-12 2.9495174e-01
 1.8678771e-15], sum to 1.0000
[2019-04-24 09:40:41,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1721
[2019-04-24 09:40:41,941] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.666666666666666, 76.0, 86.5, 0.0, 22.5, 22.0772397533621, -0.7388716987403344, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 207600.0000, 
sim time next is 208800.0000, 
raw observation next is [-7.3, 75.0, 101.5, 0.0, 22.5, 21.41621389264123, -0.8463272644914229, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.26038781163434904, 0.75, 0.3383333333333333, 0.0, 0.375, 0.2846844910534359, 0.21789091183619236, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0076074], dtype=float32), 0.3800795]. 
=============================================
[2019-04-24 09:40:43,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1366080e-01 7.4601404e-02 7.5700764e-16 4.3061004e-15 8.1272125e-15
 3.9763874e-16 5.5236379e-16 5.4001897e-17 4.1130464e-13 1.1173778e-01
 8.6314913e-16], sum to 1.0000
[2019-04-24 09:40:43,517] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0056
[2019-04-24 09:40:43,536] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 74.0, 0.0, 0.0, 19.0, 19.21176703537505, -0.880298386956872, 0.0, 1.0, 60.0, 81.14664855571033], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 104400.0000, 
sim time next is 105600.0000, 
raw observation next is [-5.566666666666667, 74.33333333333334, 0.0, 0.0, 19.0, 19.5373208737202, -1.008295028134185, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3084025854108957, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.12811007281001677, 0.16390165728860503, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6388568], dtype=float32), 0.21920638]. 
=============================================
[2019-04-24 09:40:47,573] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5463753e-01 1.4646984e-02 6.0143303e-15 1.2402244e-13 7.6705603e-14
 1.9735948e-15 6.2934260e-15 2.7662053e-15 1.4111967e-11 3.0715467e-02
 1.6712385e-14], sum to 1.0000
[2019-04-24 09:40:47,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4906
[2019-04-24 09:40:47,605] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 71.0, 0.0, 0.0, 19.0, 20.47418221551778, -0.5836063789059774, 0.0, 1.0, 60.0, 99.20862352449328], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 168000.0000, 
sim time next is 169200.0000, 
raw observation next is [-8.4, 71.0, 0.0, 0.0, 19.0, 21.13041887541961, -0.717861752306968, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.2299168975069252, 0.71, 0.0, 0.0, 0.08333333333333333, 0.2608682396183009, 0.2607127492310107, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21603876], dtype=float32), 0.0665857]. 
=============================================
[2019-04-24 09:40:48,049] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6389592e-01 1.2185599e-02 1.6185488e-17 2.5229951e-16 3.5350216e-16
 2.2473981e-17 1.1654768e-17 2.6750574e-18 1.1279676e-13 2.3918480e-02
 6.8185312e-17], sum to 1.0000
[2019-04-24 09:40:48,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1128
[2019-04-24 09:40:48,092] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 85.0, 0.0, 0.0, 19.0, 20.81968503266336, -0.5107324817306603, 0.0, 1.0, 60.0, 81.76903941232592], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 75600.0000, 
sim time next is 76800.0000, 
raw observation next is [1.233333333333334, 88.66666666666667, 0.0, 0.0, 19.0, 21.15065349090799, -0.6436704978214066, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.49676823638042483, 0.8866666666666667, 0.0, 0.0, 0.08333333333333333, 0.262554457575666, 0.28544316739286446, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5134544], dtype=float32), -0.12688491]. 
=============================================
[2019-04-24 09:40:52,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5356144e-01 9.1526330e-02 2.3399086e-15 2.1957032e-14 1.0623641e-14
 3.3017503e-16 1.7135733e-15 1.0874905e-15 4.5788625e-12 1.5491234e-01
 8.8211573e-16], sum to 1.0000
[2019-04-24 09:40:52,965] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7492
[2019-04-24 09:40:52,979] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 19.0, 20.12132427258641, -0.9159422573853675, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 255600.0000, 
sim time next is 256800.0000, 
raw observation next is [-4.1, 81.0, 0.0, 0.0, 19.0, 19.84058908761871, -0.9715412729065473, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.3490304709141275, 0.81, 0.0, 0.0, 0.08333333333333333, 0.15338242396822585, 0.17615290903115088, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9732022], dtype=float32), 1.5203826]. 
=============================================
[2019-04-24 09:40:56,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7655845e-01 5.0054174e-03 6.2917528e-16 2.7441347e-14 5.9829901e-15
 1.2324898e-16 4.2115971e-16 3.6093299e-16 4.3122047e-12 1.8436192e-02
 1.6481915e-15], sum to 1.0000
[2019-04-24 09:40:56,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4159
[2019-04-24 09:40:56,897] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 65.0, 141.0, 0.0, 22.5, 22.83216166475718, -0.3324801896905432, 1.0, 1.0, 60.0, 61.43067472975051], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 216000.0000, 
sim time next is 217200.0000, 
raw observation next is [-4.833333333333334, 65.0, 133.0, 0.0, 22.5, 23.09684743760846, -0.5374229849344837, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.32871652816251157, 0.65, 0.44333333333333336, 0.0, 0.375, 0.4247372864673717, 0.3208590050218388, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9650, 
noisyNet noise sample is [array([-1.8160459], dtype=float32), 0.63747096]. 
=============================================
[2019-04-24 09:41:00,482] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5003880e-01 2.5160107e-01 5.4881721e-14 1.0013676e-13 1.2729752e-13
 8.4276924e-15 5.3053966e-14 5.9144190e-15 5.1478564e-11 3.9836016e-01
 4.8754749e-14], sum to 1.0000
[2019-04-24 09:41:00,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8139
[2019-04-24 09:41:00,582] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.833333333333334, 69.66666666666667, 0.0, 0.0, 19.0, 19.69386612263926, -1.02764926134324, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 267600.0000, 
sim time next is 268800.0000, 
raw observation next is [-8.366666666666667, 68.33333333333333, 0.0, 0.0, 19.0, 19.95719568544226, -0.7514113339824645, 0.0, 1.0, 60.0, 101.14890389743552], 
processed observation next is [1.0, 0.08695652173913043, 0.23084025854108958, 0.6833333333333332, 0.0, 0.0, 0.08333333333333333, 0.1630996404535218, 0.2495295553391785, 0.0, 1.0, 0.9, 1.0114890389743552], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8653307], dtype=float32), 1.944794]. 
=============================================
[2019-04-24 09:41:03,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1675711e-01 2.2758197e-02 2.4206765e-13 4.4865513e-12 1.0419509e-12
 3.1558191e-14 1.4020011e-13 5.5227056e-14 8.5989660e-10 6.0484793e-02
 6.5177507e-13], sum to 1.0000
[2019-04-24 09:41:03,917] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6092
[2019-04-24 09:41:03,947] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.900000000000002, 37.33333333333334, 23.66666666666666, 453.6666666666667, 22.5, 22.10716063843819, -0.5384008940590256, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 404400.0000, 
sim time next is 405600.0000, 
raw observation next is [-8.9, 36.66666666666667, 17.5, 338.6666666666667, 22.5, 21.97588416095234, -0.5905830888557747, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.21606648199445982, 0.3666666666666667, 0.058333333333333334, 0.37421731123388585, 0.375, 0.3313236800793617, 0.3031389703814084, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7949, 
noisyNet noise sample is [array([0.55367917], dtype=float32), 0.43075213]. 
=============================================
[2019-04-24 09:41:13,995] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3730859e-01 3.4521084e-02 8.3573345e-13 1.4866689e-11 1.6191194e-11
 3.1043671e-13 3.3523469e-13 5.8376768e-13 1.3477268e-09 1.2817028e-01
 2.8172321e-12], sum to 1.0000
[2019-04-24 09:41:13,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2154
[2019-04-24 09:41:14,086] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.3, 38.66666666666666, 0.0, 0.0, 22.5, 22.91152834113816, -0.4392066985952587, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 409200.0000, 
sim time next is 410400.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 22.5, 22.18642780243569, -0.5987533549285341, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.1994459833795014, 0.4, 0.0, 0.0, 0.375, 0.34886898353630763, 0.3004155483571553, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7562, 
noisyNet noise sample is [array([-0.6563795], dtype=float32), -0.36938962]. 
=============================================
[2019-04-24 09:41:20,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3573312e-01 1.7790191e-01 2.8584516e-15 2.3100206e-14 4.5430666e-14
 2.3747348e-15 7.8581898e-15 6.7549041e-16 2.3367358e-12 4.8636490e-01
 2.4781662e-15], sum to 1.0000
[2019-04-24 09:41:20,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7525
[2019-04-24 09:41:20,541] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.466666666666667, 75.66666666666667, 0.0, 0.0, 19.0, 19.97139859512568, -1.073197616476746, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 708000.0000, 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 19.0, 19.82532404593951, -0.9113382618850658, 0.0, 1.0, 60.0, 81.52391240876139], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.76, 0.0, 0.0, 0.08333333333333333, 0.15211033716162584, 0.19622057937164472, 0.0, 1.0, 0.9, 0.8152391240876139], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6099261], dtype=float32), 1.1914067]. 
=============================================
[2019-04-24 09:41:21,311] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.1301985e-01 6.6074334e-02 1.5063346e-14 2.6838263e-14 3.7677459e-14
 2.5111514e-15 5.0057127e-15 1.0162271e-16 3.0012603e-12 2.2090578e-01
 5.2157913e-15], sum to 1.0000
[2019-04-24 09:41:21,328] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5817
[2019-04-24 09:41:21,509] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 87.0, 0.0, 0.0, 19.0, 20.33516023825855, -0.8557646493761447, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 588000.0000, 
sim time next is 589200.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 19.0, 19.7115480051421, -0.9852282940717586, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.38504155124653744, 0.87, 0.0, 0.0, 0.08333333333333333, 0.14262900042850823, 0.17159056864274713, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3795341], dtype=float32), -0.04722713]. 
=============================================
[2019-04-24 09:41:26,106] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.5658343e-01 9.8490842e-02 7.8952415e-14 2.6823511e-13 3.8406420e-13
 7.2801404e-14 2.2566260e-13 1.8958158e-14 3.6848229e-11 2.4492580e-01
 1.2645059e-13], sum to 1.0000
[2019-04-24 09:41:26,107] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9349
[2019-04-24 09:41:26,195] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 67.0, 0.0, 0.0, 19.0, 19.04836491691784, -0.9320216398022216, 0.0, 1.0, 60.0, 94.15640948244213], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 624000.0000, 
sim time next is 625200.0000, 
raw observation next is [-4.5, 66.0, 0.0, 0.0, 19.0, 19.99794925412222, -0.830593117982949, 0.0, 1.0, 60.0, 62.58708592670013], 
processed observation next is [0.0, 0.21739130434782608, 0.3379501385041552, 0.66, 0.0, 0.0, 0.08333333333333333, 0.16649577117685155, 0.223135627339017, 0.0, 1.0, 0.9, 0.6258708592670013], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.754301], dtype=float32), 0.49405155]. 
=============================================
[2019-04-24 09:41:29,473] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.6607543e-01 1.3558789e-01 5.2339589e-13 8.3730998e-13 9.0430902e-13
 1.0911623e-13 5.0517620e-13 3.1473640e-14 4.5049423e-11 4.9833661e-01
 3.6911855e-13], sum to 1.0000
[2019-04-24 09:41:29,533] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7178
[2019-04-24 09:41:29,634] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.566666666666667, 58.66666666666667, 0.0, 0.0, 19.0, 18.93895863208222, -1.196602633247433, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 670800.0000, 
sim time next is 672000.0000, 
raw observation next is [-1.933333333333333, 60.33333333333333, 0.0, 0.0, 19.0, 19.21763317315155, -0.9107233776505045, 0.0, 1.0, 60.0, 96.52930498168998], 
processed observation next is [0.0, 0.782608695652174, 0.40904893813481075, 0.6033333333333333, 0.0, 0.0, 0.08333333333333333, 0.10146943109596258, 0.19642554078316518, 0.0, 1.0, 0.9, 0.9652930498168998], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10096111], dtype=float32), -0.33168474]. 
=============================================
[2019-04-24 09:41:36,662] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5425147e-01 4.4729952e-02 1.6531259e-14 8.1377620e-14 6.1025451e-14
 1.5728354e-15 3.6124447e-15 6.6349569e-15 2.5946764e-11 6.0101855e-01
 3.3496684e-15], sum to 1.0000
[2019-04-24 09:41:36,662] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9331
[2019-04-24 09:41:36,718] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 71.0, 104.5, 0.0, 22.5, 22.15550250514612, -0.5402580076929965, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 820800.0000, 
sim time next is 822000.0000, 
raw observation next is [-4.5, 73.66666666666667, 100.8333333333333, 0.0, 22.5, 22.57321513512101, -0.3959847402329675, 1.0, 1.0, 60.0, 87.57549250291962], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.7366666666666667, 0.336111111111111, 0.0, 0.375, 0.3811012612600842, 0.3680050865890108, 1.0, 1.0, 0.9, 0.8757549250291962], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5109846], dtype=float32), 1.0313172]. 
=============================================
[2019-04-24 09:41:39,594] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.0409819e-01 6.6853493e-02 1.2887596e-15 2.7081371e-14 1.1447242e-14
 2.7523139e-16 1.4540245e-15 5.9075525e-17 3.6053322e-12 1.2904830e-01
 1.0507400e-15], sum to 1.0000
[2019-04-24 09:41:39,596] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.5402
[2019-04-24 09:41:39,615] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.2, 81.66666666666667, 0.0, 0.0, 19.0, 20.57512108361709, -0.5890919027779364, 0.0, 1.0, 60.0, 91.5159993431578], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 858000.0000, 
sim time next is 859200.0000, 
raw observation next is [-3.0, 80.33333333333334, 0.0, 0.0, 19.0, 21.12890985466064, -0.701479925463572, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.8033333333333335, 0.0, 0.0, 0.08333333333333333, 0.2607424878883868, 0.2661733581788093, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44531995], dtype=float32), -2.288678]. 
=============================================
[2019-04-24 09:41:51,745] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.8274082e-01 3.1758419e-03 5.9611214e-17 3.8449193e-15 2.4356030e-15
 1.9849542e-17 4.4733342e-17 4.9892037e-17 7.5119582e-13 1.4083288e-02
 4.0869956e-16], sum to 1.0000
[2019-04-24 09:41:51,747] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6153
[2019-04-24 09:41:51,764] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 53.0, 0.0, 0.0, 22.5, 24.55626471154033, 0.2987509547271022, 1.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1101600.0000, 
sim time next is 1102800.0000, 
raw observation next is [15.73333333333334, 54.33333333333334, 0.0, 0.0, 22.5, 24.62053362525408, 0.2988071673883009, 1.0, 0.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8984302862419208, 0.5433333333333334, 0.0, 0.0, 0.375, 0.55171113543784, 0.5996023891294336, 1.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1592246], dtype=float32), -0.13250688]. 
=============================================
[2019-04-24 09:41:52,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.5322233e-01 1.7616443e-02 2.6119365e-16 2.6567256e-15 3.2509933e-15
 3.7981129e-16 2.4274980e-16 1.2657840e-17 7.4179676e-13 2.9161258e-02
 2.6214903e-15], sum to 1.0000
[2019-04-24 09:41:52,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4055
[2019-04-24 09:41:52,648] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.16666666666667, 95.0, 0.0, 0.0, 19.0, 22.9552112673691, -0.01348031303722696, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1226400.0000, 
sim time next is 1227600.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 22.8630297575777, -0.02891418085015616, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.4052524797981416, 0.4903619397166146, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9173855], dtype=float32), 0.5587333]. 
=============================================
[2019-04-24 09:41:53,929] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4141150e-01 1.9515783e-02 5.0452587e-18 1.4218773e-16 7.2135337e-17
 7.0012784e-19 3.0680522e-18 2.5478538e-19 8.1845636e-14 3.9072700e-02
 3.7363107e-18], sum to 1.0000
[2019-04-24 09:41:53,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9807
[2019-04-24 09:41:54,001] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.0, 95.0, 87.0, 0.0, 22.5, 23.42457875414457, -0.003643283660894651, 1.0, 1.0, 60.0, 87.87303301230811], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1423200.0000, 
sim time next is 1424400.0000, 
raw observation next is [0.0, 95.0, 91.0, 0.0, 22.5, 24.18400872958046, 0.11627791327233, 1.0, 1.0, 60.0, 56.62440376084286], 
processed observation next is [1.0, 0.4782608695652174, 0.46260387811634357, 0.95, 0.30333333333333334, 0.0, 0.375, 0.5153340607983715, 0.53875930442411, 1.0, 1.0, 0.9, 0.5662440376084286], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03945473], dtype=float32), 0.34852877]. 
=============================================
[2019-04-24 09:41:56,111] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.8773408e-01 3.5422936e-03 4.0839747e-19 2.8131228e-18 2.3772072e-17
 7.6656947e-19 2.1052192e-19 4.5391216e-20 2.7131194e-15 8.7235998e-03
 8.8717271e-19], sum to 1.0000
[2019-04-24 09:41:56,112] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7266
[2019-04-24 09:41:56,147] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.200000000000001, 95.0, 0.0, 0.0, 19.0, 20.98739465281658, -0.2077566787485668, 0.0, 1.0, 60.0, 94.62481778969462], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1297200.0000, 
sim time next is 1298400.0000, 
raw observation next is [4.0, 94.0, 0.0, 0.0, 19.0, 22.01504937993912, -0.2965391386096831, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5734072022160666, 0.94, 0.0, 0.0, 0.08333333333333333, 0.3345874483282601, 0.40115362046343894, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14842318], dtype=float32), 0.47063756]. 
=============================================
[2019-04-24 09:41:57,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0492767e-01 2.9357091e-02 2.0763742e-17 2.0138358e-16 1.4417567e-16
 4.8601406e-18 5.6539718e-18 3.5739778e-18 4.5807095e-14 6.5715231e-02
 1.1318631e-17], sum to 1.0000
[2019-04-24 09:41:57,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3931
[2019-04-24 09:41:57,802] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 22.5, 21.83354090680398, -0.3722992984493563, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1362000.0000, 
sim time next is 1363200.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 21.49145682593682, -0.4332445499212089, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.2909547354947349, 0.3555851500262637, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6141335], dtype=float32), -0.8501137]. 
=============================================
[2019-04-24 09:41:57,923] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.48812604e-01 1.17669292e-02 1.08392416e-17 1.31885889e-16
 9.75724383e-17 7.26111911e-19 1.03415309e-18 7.38098172e-19
 4.25121466e-14 3.94205377e-02 7.53144474e-18], sum to 1.0000
[2019-04-24 09:41:57,924] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6895
[2019-04-24 09:41:57,945] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 93.0, 31.0, 0.0, 22.5, 24.29420273743779, 0.04026781544264346, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1353600.0000, 
sim time next is 1354800.0000, 
raw observation next is [0.9000000000000001, 94.0, 22.33333333333333, 0.0, 22.5, 23.89708328985627, -0.06813970472424236, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.48753462603878117, 0.94, 0.07444444444444442, 0.0, 0.375, 0.49142360748802244, 0.4772867650919192, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2258152], dtype=float32), 0.097584076]. 
=============================================
[2019-04-24 09:41:58,931] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9568030e-01 1.1676816e-01 1.4540087e-16 7.8395149e-16 8.2139861e-16
 1.1468156e-16 1.0366626e-16 1.2413090e-17 2.0927376e-13 3.8755155e-01
 9.3303061e-17], sum to 1.0000
[2019-04-24 09:41:58,931] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8977
[2019-04-24 09:41:58,999] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.4, 98.33333333333333, 0.0, 0.0, 19.0, 20.74739596655148, -0.7122592208621668, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1395600.0000, 
sim time next is 1396800.0000, 
raw observation next is [-0.6, 100.0, 0.0, 0.0, 19.0, 20.82919786357985, -0.4409145352958965, 0.0, 1.0, 60.0, 94.42263478149609], 
processed observation next is [1.0, 0.17391304347826086, 0.44598337950138506, 1.0, 0.0, 0.0, 0.08333333333333333, 0.23576648863165417, 0.3530284882347012, 0.0, 1.0, 0.9, 0.9442263478149608], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45520395], dtype=float32), -0.7155272]. 
=============================================
[2019-04-24 09:42:01,437] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [4.92288291e-01 1.84825495e-01 3.99806169e-17 7.65291356e-17
 1.43543603e-16 4.79610734e-18 1.78763458e-17 1.90376838e-18
 1.12476455e-13 3.22886258e-01 1.83779250e-17], sum to 1.0000
[2019-04-24 09:42:01,437] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8176
[2019-04-24 09:42:01,664] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.433333333333333, 100.0, 22.83333333333333, 0.0, 22.5, 21.8378337423388, -0.5170960776360094, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1500000.0000, 
sim time next is 1501200.0000, 
raw observation next is [1.6, 100.0, 32.5, 0.0, 22.5, 22.81192238921487, -0.1108479136206891, 1.0, 1.0, 60.0, 110.1031217033987], 
processed observation next is [1.0, 0.391304347826087, 0.5069252077562327, 1.0, 0.10833333333333334, 0.0, 0.375, 0.4009935324345726, 0.46305069545977035, 1.0, 1.0, 0.9, 1.101031217033987], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.992904], dtype=float32), 0.9074744]. 
=============================================
[2019-04-24 09:42:03,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9501262e-01 6.1005313e-02 3.7686824e-19 2.4788529e-18 2.6519849e-18
 6.9641848e-20 2.3637221e-19 3.4415431e-20 6.1251705e-16 4.3982070e-02
 3.4409540e-19], sum to 1.0000
[2019-04-24 09:42:03,175] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9254
[2019-04-24 09:42:03,241] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [6.233333333333333, 97.0, 0.0, 0.0, 19.0, 22.34184873159504, -0.2892314837571537, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 1660800.0000, 
sim time next is 1662000.0000, 
raw observation next is [5.866666666666667, 97.0, 0.0, 0.0, 19.0, 22.27023288522929, -0.1450053870720713, 0.0, 1.0, 20.0, 60.90617376781485], 
processed observation next is [1.0, 0.21739130434782608, 0.6251154201292707, 0.97, 0.0, 0.0, 0.08333333333333333, 0.35585274043577425, 0.45166487097597624, 0.0, 1.0, 0.1, 0.6090617376781485], 
reward next is 0.2909, 
noisyNet noise sample is [array([0.4257616], dtype=float32), -0.5056185]. 
=============================================
[2019-04-24 09:42:04,279] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.78218496e-01 8.17135628e-03 1.01579214e-19 3.97606778e-18
 5.88798244e-18 5.01941338e-20 5.01321341e-20 1.31576122e-20
 1.90487588e-15 1.36101060e-02 2.87770577e-19], sum to 1.0000
[2019-04-24 09:42:04,281] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6266
[2019-04-24 09:42:04,341] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.333333333333333, 70.66666666666666, 129.1666666666667, 128.0, 22.5, 23.92192273009169, 0.1434773215822704, 1.0, 1.0, 60.0, 89.63870311384868], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1590000.0000, 
sim time next is 1591200.0000, 
raw observation next is [7.7, 68.0, 157.5, 112.0, 22.5, 24.68438681010598, 0.09740972756243375, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6759002770083103, 0.68, 0.525, 0.12375690607734807, 0.375, 0.5570322341754984, 0.5324699091874779, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6379446], dtype=float32), -1.8837302]. 
=============================================
[2019-04-24 09:42:07,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0886046e-01 1.4445665e-01 1.3389891e-18 1.4881204e-17 3.1974359e-17
 5.4778289e-19 8.6539398e-19 6.2259952e-20 4.9106600e-15 1.4668283e-01
 8.9476706e-19], sum to 1.0000
[2019-04-24 09:42:07,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5676
[2019-04-24 09:42:07,391] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.866666666666667, 92.0, 0.0, 0.0, 22.5, 21.71485825290296, -0.358691846657607, 1.0, 1.0, 20.0, 41.61390825809255], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1669200.0000, 
sim time next is 1670400.0000, 
raw observation next is [3.3, 92.0, 15.5, 0.0, 22.5, 21.9305241464095, -0.3890906256112203, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.554016620498615, 0.92, 0.051666666666666666, 0.0, 0.375, 0.32754367886745833, 0.3703031247962599, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0141679], dtype=float32), 0.74917114]. 
=============================================
[2019-04-24 09:42:13,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1777040e-01 1.1290525e-01 1.1193532e-12 7.8114089e-13 1.6382045e-12
 1.9827899e-13 4.0431867e-13 5.5476694e-14 7.9271832e-11 1.6932428e-01
 4.2205749e-13], sum to 1.0000
[2019-04-24 09:42:13,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9985
[2019-04-24 09:42:13,098] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.733333333333333, 79.66666666666667, 0.0, 0.0, 19.0, 18.6787261551906, -1.138626749023353, 0.0, 1.0, 20.0, 54.874647848507976], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1819200.0000, 
sim time next is 1820400.0000, 
raw observation next is [-5.866666666666667, 81.33333333333333, 0.0, 0.0, 19.0, 18.79480379886539, -1.090643386961316, 0.0, 1.0, 60.0, 68.90974159085775], 
processed observation next is [0.0, 0.043478260869565216, 0.30009233610341646, 0.8133333333333332, 0.0, 0.0, 0.08333333333333333, 0.06623364990544929, 0.13645220434622804, 0.0, 1.0, 0.9, 0.6890974159085775], 
reward next is 0.4104, 
noisyNet noise sample is [array([-0.31798097], dtype=float32), -0.48804703]. 
=============================================
[2019-04-24 09:42:17,460] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.30511963e-01 1.04361705e-01 7.08091517e-13 1.80444743e-12
 2.25155116e-12 4.80447442e-13 2.98766464e-13 5.87961686e-14
 1.21481894e-10 1.65126339e-01 5.56593671e-13], sum to 1.0000
[2019-04-24 09:42:17,461] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0528
[2019-04-24 09:42:17,501] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.700000000000001, 78.0, 22.66666666666667, 0.0, 19.0, 19.39500910817859, -1.169900238916205, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1844400.0000, 
sim time next is 1845600.0000, 
raw observation next is [-6.700000000000001, 78.0, 47.16666666666666, 15.66666666666666, 19.0, 18.40271724208526, -1.335978979353251, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.2770083102493075, 0.78, 0.15722222222222218, 0.017311233885819514, 0.08333333333333333, 0.03355977017377162, 0.054673673548916314, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24993291], dtype=float32), -0.14227027]. 
=============================================
[2019-04-24 09:42:22,027] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6596180e-01 7.6167762e-02 2.4550191e-14 1.3852107e-13 1.7361880e-13
 8.0072760e-15 9.1124897e-15 1.6635706e-15 1.5633196e-11 2.5787038e-01
 1.6512679e-14], sum to 1.0000
[2019-04-24 09:42:22,028] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0751
[2019-04-24 09:42:22,040] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 84.33333333333333, 0.0, 0.0, 19.0, 20.70309836264034, -0.8707473160775437, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1993200.0000, 
sim time next is 1994400.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 19.93526877886028, -1.019842431766519, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.16127239823835668, 0.1600525227444937, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4614657], dtype=float32), -0.12420473]. 
=============================================
[2019-04-24 09:42:22,297] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [2.5502726e-01 1.9395144e-01 9.6401999e-14 7.4819775e-14 1.7881768e-13
 6.4036521e-15 9.1374306e-15 3.6832186e-15 1.3233805e-11 5.5102128e-01
 7.0048151e-15], sum to 1.0000
[2019-04-24 09:42:22,299] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1109
[2019-04-24 09:42:22,337] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 20.62143831022313, -0.9188260367769511, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2006400.0000, 
sim time next is 2007600.0000, 
raw observation next is [-6.199999999999999, 87.0, 0.0, 0.0, 19.0, 19.82818243703606, -1.070929507232062, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.15234853641967158, 0.14302349758931268, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21680138], dtype=float32), 1.9609447]. 
=============================================
[2019-04-24 09:42:30,258] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3621899e-01 8.4639706e-02 1.8661903e-14 1.1242896e-13 6.9062052e-14
 4.8058079e-15 7.2791149e-15 1.8271642e-15 3.0340220e-11 1.7914127e-01
 1.3025920e-14], sum to 1.0000
[2019-04-24 09:42:30,260] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4193
[2019-04-24 09:42:30,342] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.8, 82.0, 191.0, 89.0, 22.5, 22.66554980946649, -0.4821757577702515, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2109600.0000, 
sim time next is 2110800.0000, 
raw observation next is [-7.633333333333333, 79.66666666666667, 202.3333333333333, 69.66666666666666, 22.5, 22.24082019626338, -0.5366844842928128, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2511542012927055, 0.7966666666666667, 0.6744444444444443, 0.07697974217311233, 0.375, 0.3534016830219482, 0.32110517190239574, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9664, 
noisyNet noise sample is [array([0.09225353], dtype=float32), 0.9620777]. 
=============================================
[2019-04-24 09:42:31,490] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.2854381e-01 2.3940276e-02 2.6683939e-15 7.7130888e-14 3.2197491e-14
 1.4400563e-15 1.6608554e-15 3.3618214e-16 1.3135693e-11 4.7515895e-02
 6.2388995e-15], sum to 1.0000
[2019-04-24 09:42:31,491] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3330
[2019-04-24 09:42:31,527] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 72.0, 0.0, 0.0, 22.5, 22.82972843891065, -0.1618646408982107, 1.0, 1.0, 60.0, 87.958193174229], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2139600.0000, 
sim time next is 2140800.0000, 
raw observation next is [-5.0, 73.0, 0.0, 0.0, 22.5, 23.02907711411719, -0.3018341577750858, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.32409972299168976, 0.73, 0.0, 0.0, 0.375, 0.4190897595097658, 0.3993886140749714, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.91819113], dtype=float32), 0.538014]. 
=============================================
[2019-04-24 09:42:37,263] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5760353e-01 5.7798695e-02 5.1893004e-12 1.1424723e-11 1.4289199e-11
 2.4638468e-12 8.7132596e-13 6.7484619e-13 8.7026097e-10 1.8459783e-01
 2.1211754e-12], sum to 1.0000
[2019-04-24 09:42:37,264] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9983
[2019-04-24 09:42:37,324] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.4, 42.33333333333333, 0.0, 0.0, 19.0, 20.10156781783421, -0.8775103704629056, 0.0, 1.0, 20.0, 49.03692194515226], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2418000.0000, 
sim time next is 2419200.0000, 
raw observation next is [-5.6, 43.0, 0.0, 0.0, 19.0, 20.38507812147428, -0.8345812382799874, 0.0, 1.0, 60.0, 59.90607269909439], 
processed observation next is [0.0, 0.0, 0.30747922437673136, 0.43, 0.0, 0.0, 0.08333333333333333, 0.19875651012285664, 0.22180625390667086, 0.0, 1.0, 0.9, 0.5990607269909439], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2094582], dtype=float32), 0.7758797]. 
=============================================
[2019-04-24 09:42:41,534] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.33564669e-01 2.52425909e-01 1.78948748e-13 4.62461070e-13
 4.01560214e-13 1.07362226e-13 2.38704727e-13 3.17181821e-14
 3.84778633e-11 4.14009452e-01 7.07825861e-14], sum to 1.0000
[2019-04-24 09:42:41,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1214
[2019-04-24 09:42:41,552] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 19.0, 19.03311684736738, -1.261860510764275, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2527200.0000, 
sim time next is 2528400.0000, 
raw observation next is [-2.466666666666667, 56.00000000000001, 0.0, 0.0, 19.0, 18.50427211352489, -1.326525391773347, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.39427516158818104, 0.56, 0.0, 0.0, 0.08333333333333333, 0.042022676127074256, 0.057824869408884316, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0170, 
noisyNet noise sample is [array([0.40796733], dtype=float32), 0.357489]. 
=============================================
[2019-04-24 09:42:43,411] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-24 09:42:43,413] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:42:43,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:42:43,416] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run3
[2019-04-24 09:42:43,416] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:42:43,437] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:42:43,439] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:42:43,439] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:42:43,446] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run3
[2019-04-24 09:42:43,458] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run3
[2019-04-24 09:42:49,044] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.27154434], dtype=float32), 0.59565884]
[2019-04-24 09:42:49,045] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 20.28862388949953, -0.7682220093248969, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:42:49,045] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 09:42:49,046] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.16220200e-01 1.22833505e-01 3.28707116e-17 1.31168372e-16
 3.39290376e-16 2.27474338e-17 4.21444055e-17 2.33884388e-18
 8.69214775e-14 1.60946265e-01 3.35754629e-17], sampled 0.5675494720653113
[2019-04-24 09:44:11,888] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3353.2602 67100.0203 -155.9100
[2019-04-24 09:44:11,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:11,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:11,925] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:12,097] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:12,097] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:12,097] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:12,922] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.27154434], dtype=float32), 0.59565884]
[2019-04-24 09:44:12,922] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [0.0, 72.0, 0.0, 0.0, 19.0, 22.55674095888424, -0.2280271966856198, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:44:12,922] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 09:44:12,923] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [9.51608956e-01 1.51121616e-02 9.21209317e-16 1.32860328e-14
 1.11094105e-14 7.87579493e-16 5.49831691e-16 1.24756333e-16
 2.38783516e-12 3.32789682e-02 3.20253226e-15], sampled 0.5132686185244512
[2019-04-24 09:44:24,499] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3163.3454 81216.8728 -441.7856
[2019-04-24 09:44:24,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:24,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:24,570] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:24,808] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:24,808] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:24,808] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:39,189] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3117.5495 85094.1953 -470.0328
[2019-04-24 09:44:39,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:39,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:39,225] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:44:39,395] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:39,395] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:39,395] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:44:40,227] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 100000, evaluation results [100000.0, 3163.345351640952, 81216.87282102622, -441.7855803976401, 3353.260151557511, 67100.02030195354, -155.90997099834993, 3117.5495199656693, 85094.19526471221, -470.03281358427756]
[2019-04-24 09:44:42,534] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1946039e-01 3.0116390e-02 2.9432440e-15 3.8983638e-14 3.1038584e-14
 2.1300221e-16 3.4971896e-15 1.0941732e-15 6.5764547e-12 1.5042321e-01
 1.4219900e-15], sum to 1.0000
[2019-04-24 09:44:42,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4217
[2019-04-24 09:44:42,666] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.3, 29.0, 136.5, 313.0, 22.5, 23.18172666460523, -0.243556448431385, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2559600.0000, 
sim time next is 2560800.0000, 
raw observation next is [3.3, 29.0, 121.5, 338.3333333333333, 22.5, 23.28193868892414, -0.3036956126833654, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.554016620498615, 0.29, 0.405, 0.3738489871086556, 0.375, 0.44016155741034496, 0.3987681291055449, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8255587], dtype=float32), 0.9144895]. 
=============================================
[2019-04-24 09:44:47,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0986626e-01 1.6182193e-01 2.5166058e-12 1.1262931e-11 1.1509106e-11
 5.5892903e-12 2.4975692e-12 1.7860142e-13 4.0976095e-10 2.2831173e-01
 4.3637919e-12], sum to 1.0000
[2019-04-24 09:44:47,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1321
[2019-04-24 09:44:47,760] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 36.0, 81.0, 803.0, 19.0, 19.91139183764272, -1.027036097363281, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2458800.0000, 
sim time next is 2460000.0000, 
raw observation next is [-1.733333333333333, 34.33333333333334, 84.33333333333334, 820.3333333333334, 19.0, 19.42102839147815, -1.090935791739011, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.41458910433979695, 0.34333333333333343, 0.28111111111111114, 0.9064456721915286, 0.08333333333333333, 0.1184190326231791, 0.13635473608699633, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.29422516], dtype=float32), -1.2631135]. 
=============================================
[2019-04-24 09:44:47,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.020863]
 [55.938496]
 [55.679455]
 [54.567577]
 [54.67956 ]
 [54.801785]
 [54.4403  ]
 [53.696453]
 [53.33702 ]
 [52.454857]
 [52.19699 ]
 [52.196987]
 [52.194626]
 [52.497673]
 [52.689598]
 [52.919792]
 [52.72124 ]
 [53.166603]
 [53.130093]
 [52.618076]
 [52.939774]
 [52.69055 ]
 [53.038498]
 [52.975742]
 [52.99708 ]], R is [[56.70307541]
 [57.13604355]
 [57.56468201]
 [56.98903656]
 [56.97782516]
 [57.40804672]
 [56.8339653 ]
 [56.5127182 ]
 [56.94758987]
 [56.74499893]
 [57.01530838]
 [57.4451561 ]
 [56.87070465]
 [56.30199814]
 [56.27787781]
 [56.44644928]
 [55.88198471]
 [56.32316589]
 [56.14296722]
 [55.58153915]
 [55.32458496]
 [54.77133942]
 [54.99509048]
 [54.75750351]
 [54.92810822]].
[2019-04-24 09:44:49,088] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5512589e-01 1.3531460e-01 2.6506154e-12 8.0922543e-12 7.7562245e-12
 2.9309994e-12 1.1149035e-12 2.1769365e-13 6.7153277e-10 3.0955955e-01
 6.2578272e-12], sum to 1.0000
[2019-04-24 09:44:49,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7879
[2019-04-24 09:44:49,280] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.166666666666667, 32.66666666666666, 86.66666666666667, 831.6666666666667, 19.0, 20.39919325014809, -0.9127796460901217, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2461200.0000, 
sim time next is 2462400.0000, 
raw observation next is [-0.6, 31.0, 88.0, 837.0, 19.0, 20.33821089856908, -0.7575180503640077, 0.0, 1.0, 60.0, 76.08024086520639], 
processed observation next is [0.0, 0.5217391304347826, 0.44598337950138506, 0.31, 0.29333333333333333, 0.9248618784530387, 0.08333333333333333, 0.19485090821409004, 0.24749398321199745, 0.0, 1.0, 0.9, 0.7608024086520639], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48002315], dtype=float32), 0.07297457]. 
=============================================
[2019-04-24 09:44:52,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2574772e-01 2.3833656e-01 9.5138266e-14 3.1693374e-13 1.1269202e-12
 4.4531422e-14 1.4239948e-13 1.6241257e-14 6.9480331e-11 2.3591574e-01
 6.8728409e-14], sum to 1.0000
[2019-04-24 09:44:52,998] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4542
[2019-04-24 09:44:53,046] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 19.0, 19.08441357305002, -1.233447231139226, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2523600.0000, 
sim time next is 2524800.0000, 
raw observation next is [-2.3, 57.00000000000001, 0.0, 0.0, 19.0, 18.722414604325, -1.313061453967848, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.5700000000000001, 0.0, 0.0, 0.08333333333333333, 0.06020121702708329, 0.06231284867738399, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.6918, 
noisyNet noise sample is [array([-0.72476786], dtype=float32), -0.09681592]. 
=============================================
[2019-04-24 09:45:17,993] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4251257e-01 7.9324450e-03 1.2616728e-16 5.0415808e-15 4.5910765e-15
 8.1442635e-17 1.3411239e-16 3.4949158e-17 2.8288084e-12 4.9555004e-02
 3.5900197e-16], sum to 1.0000
[2019-04-24 09:45:17,993] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6718
[2019-04-24 09:45:18,019] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 35.0, 213.5, 429.0, 22.5, 22.61020908510635, -0.3779745488950461, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2811600.0000, 
sim time next is 2812800.0000, 
raw observation next is [4.666666666666667, 33.33333333333334, 237.1666666666667, 258.3333333333333, 22.5, 22.42380960831379, -0.4647181274513351, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5918744228993538, 0.3333333333333334, 0.7905555555555557, 0.285451197053407, 0.375, 0.36865080069281575, 0.34509395751622157, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09505185], dtype=float32), 1.8161559]. 
=============================================
[2019-04-24 09:45:19,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0583650e-01 2.9191852e-02 1.7930582e-15 1.8507040e-14 1.2363054e-14
 3.2604850e-16 1.8766517e-15 2.3465587e-16 2.0158207e-11 1.6497165e-01
 1.2684166e-15], sum to 1.0000
[2019-04-24 09:45:19,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1908
[2019-04-24 09:45:19,538] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 24.0, 106.5, 0.0, 22.5, 23.00731637903846, -0.405280108179483, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2818800.0000, 
sim time next is 2820000.0000, 
raw observation next is [6.866666666666667, 24.33333333333333, 98.83333333333333, 0.0, 22.5, 22.57303834380484, -0.5413937631796647, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.6528162511542014, 0.2433333333333333, 0.32944444444444443, 0.0, 0.375, 0.38108652865040327, 0.3195354122734451, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9572, 
noisyNet noise sample is [array([-1.4546132], dtype=float32), -0.5469954]. 
=============================================
[2019-04-24 09:45:19,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.17582 ]
 [71.214355]
 [71.51263 ]
 [71.78884 ]
 [71.06527 ]
 [71.60643 ]
 [71.92254 ]
 [72.07587 ]
 [71.93718 ]
 [71.45658 ]
 [70.99131 ]
 [70.72914 ]
 [70.394936]
 [69.27755 ]
 [68.61564 ]
 [67.6713  ]
 [67.56189 ]
 [67.51873 ]
 [67.57741 ]
 [66.16827 ]
 [65.9616  ]
 [65.60707 ]
 [64.17751 ]
 [62.685158]
 [62.67389 ]], R is [[71.48918152]
 [71.77429199]
 [72.05654907]
 [72.33598328]
 [71.61262512]
 [71.86012268]
 [71.75881958]
 [71.77442932]
 [72.03829193]
 [72.31033325]
 [72.58722687]
 [72.86135864]
 [73.13274384]
 [72.40142059]
 [72.67740631]
 [72.06503296]
 [72.29178619]
 [72.56002045]
 [72.83441925]
 [72.1060791 ]
 [71.3850174 ]
 [71.10158539]
 [70.53930664]
 [70.83391571]
 [70.12557983]].
[2019-04-24 09:45:20,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9925919e-01 8.7607197e-02 1.5491331e-16 7.4882405e-15 1.5008881e-15
 3.3787794e-17 1.1601143e-16 2.9444391e-17 1.0025201e-12 1.1313356e-01
 8.4905577e-17], sum to 1.0000
[2019-04-24 09:45:20,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6903
[2019-04-24 09:45:20,792] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 82.66666666666667, 0.0, 0.0, 19.0, 21.81163162305297, -0.4041229509102851, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2928000.0000, 
sim time next is 2929200.0000, 
raw observation next is [-1.0, 80.33333333333334, 0.0, 0.0, 19.0, 21.43078400421999, -0.4595895995024555, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.8033333333333335, 0.0, 0.0, 0.08333333333333333, 0.28589866701833255, 0.34680346683251484, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80331767], dtype=float32), -0.043085907]. 
=============================================
[2019-04-24 09:45:21,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6080652e-01 3.0248331e-02 1.0733569e-15 9.7723208e-15 2.5402745e-14
 1.2849144e-15 6.5469006e-15 1.9846775e-16 3.5706453e-12 1.0894505e-01
 5.2389742e-15], sum to 1.0000
[2019-04-24 09:45:21,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7153
[2019-04-24 09:45:21,630] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 20.81396538010367, -0.6790279080675875, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2942400.0000, 
sim time next is 2943600.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 20.39359476222294, -0.7389438549977082, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.19946623018524492, 0.2536853816674306, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4001609], dtype=float32), -0.95687634]. 
=============================================
[2019-04-24 09:45:26,125] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.3753399e-01 1.1805519e-01 2.3194637e-14 1.5680611e-13 1.0791473e-13
 1.6150365e-14 1.5094219e-14 2.7635022e-15 7.3414747e-12 1.4441088e-01
 4.0161220e-14], sum to 1.0000
[2019-04-24 09:45:26,127] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7675
[2019-04-24 09:45:26,237] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-3.0, 65.0, 169.1666666666667, 709.1666666666667, 19.0, 20.28556232741221, -0.8130968388684737, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2983200.0000, 
sim time next is 2984400.0000, 
raw observation next is [-3.0, 65.0, 145.5, 745.5, 19.0, 20.30425874587772, -0.6072130283897509, 0.0, 1.0, 20.0, 72.5453006404758], 
processed observation next is [0.0, 0.5652173913043478, 0.3795013850415513, 0.65, 0.485, 0.8237569060773481, 0.08333333333333333, 0.19202156215647678, 0.29759565720341635, 0.0, 1.0, 0.1, 0.725453006404758], 
reward next is 0.1745, 
noisyNet noise sample is [array([0.660945], dtype=float32), 0.61459744]. 
=============================================
[2019-04-24 09:45:36,122] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7713029e-01 9.2887413e-03 3.4026838e-15 2.5985613e-13 6.3173106e-14
 8.7087684e-15 6.3480838e-15 1.1262113e-15 1.7569085e-11 1.3580957e-02
 6.9307488e-14], sum to 1.0000
[2019-04-24 09:45:36,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5477
[2019-04-24 09:45:36,221] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 61.33333333333334, 48.66666666666666, 419.6666666666667, 19.0, 20.26213548514788, -0.6475032849821097, 0.0, 1.0, 60.0, 86.25417656960256], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3084000.0000, 
sim time next is 3085200.0000, 
raw observation next is [0.0, 72.0, 32.0, 287.0, 19.0, 21.03642946178195, -0.7407435484064896, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.46260387811634357, 0.72, 0.10666666666666667, 0.31712707182320443, 0.08333333333333333, 0.2530357884818291, 0.25308548386450347, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.85354054], dtype=float32), 1.9152331]. 
=============================================
[2019-04-24 09:45:48,807] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4838861e-01 2.8846425e-01 7.4354352e-13 9.2665480e-13 1.7231546e-12
 8.7064064e-14 4.9441386e-13 9.3801384e-14 1.5452579e-10 3.6314717e-01
 2.2010567e-13], sum to 1.0000
[2019-04-24 09:45:48,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0361
[2019-04-24 09:45:48,886] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 81.33333333333334, 16.0, 144.3333333333333, 22.5, 20.93276984021173, -0.783993256509711, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3310800.0000, 
sim time next is 3312000.0000, 
raw observation next is [-11.0, 84.0, 44.0, 245.0, 22.5, 20.32450284882829, -0.8933454585844882, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.15789473684210528, 0.84, 0.14666666666666667, 0.27071823204419887, 0.375, 0.1937085707356907, 0.20221818047183726, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6702788], dtype=float32), -0.61547416]. 
=============================================
[2019-04-24 09:46:07,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5804778e-01 7.8260176e-02 5.6134988e-14 5.8369401e-13 7.4454814e-13
 3.5848837e-14 3.7867963e-14 7.8472054e-15 3.8784226e-11 6.3692041e-02
 9.0087531e-14], sum to 1.0000
[2019-04-24 09:46:07,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0778
[2019-04-24 09:46:07,195] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 56.66666666666667, 0.0, 0.0, 19.0, 20.93597292587343, -0.7564433803726037, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3624000.0000, 
sim time next is 3625200.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 19.0, 20.45298342319485, -0.8753982852954046, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.3795013850415513, 0.6, 0.0, 0.0, 0.08333333333333333, 0.20441528526623762, 0.20820057156819846, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2557635], dtype=float32), 1.1331347]. 
=============================================
[2019-04-24 09:46:07,649] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4538039e-01 2.7193127e-02 2.2003645e-16 5.9240336e-16 1.0038944e-15
 1.6482231e-16 1.0926220e-16 4.3467468e-17 3.5741595e-13 2.7426487e-02
 3.7147959e-16], sum to 1.0000
[2019-04-24 09:46:07,667] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5739
[2019-04-24 09:46:07,700] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.666666666666666, 43.0, 116.3333333333333, 827.1666666666667, 19.0, 20.0417667670073, -0.8062578494437241, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3674400.0000, 
sim time next is 3675600.0000, 
raw observation next is [5.0, 42.0, 115.0, 823.5, 19.0, 20.02256942897014, -0.8040424591412346, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6011080332409973, 0.42, 0.38333333333333336, 0.9099447513812154, 0.08333333333333333, 0.16854745241417834, 0.2319858469529218, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29375482], dtype=float32), -0.52205545]. 
=============================================
[2019-04-24 09:46:20,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2435557e-01 2.3238294e-02 4.7178566e-14 3.9932410e-13 2.2889129e-13
 8.4110609e-15 9.7560349e-15 4.2936727e-15 3.8662910e-11 5.2406076e-02
 4.4924090e-14], sum to 1.0000
[2019-04-24 09:46:20,085] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7540
[2019-04-24 09:46:20,112] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666667, 40.0, 15.83333333333333, 140.8333333333333, 22.5, 21.77352454649439, -0.4840822055533298, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3951600.0000, 
sim time next is 3952800.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 22.5, 21.48128786782132, -0.5377317993877012, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.296398891966759, 0.41, 0.0, 0.0, 0.375, 0.2901073223184432, 0.32075606687076624, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9644, 
noisyNet noise sample is [array([-1.9889749], dtype=float32), 1.4544843]. 
=============================================
[2019-04-24 09:46:25,070] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.1329387e-01 2.2567973e-01 2.1949946e-12 4.7230783e-12 9.0229300e-12
 6.1358020e-13 3.3509976e-12 3.7577293e-13 3.9459899e-10 4.6102631e-01
 2.9907047e-13], sum to 1.0000
[2019-04-24 09:46:25,121] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0485
[2019-04-24 09:46:25,217] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 40.0, 0.0, 0.0, 19.0, 17.62876565347247, -1.475251439793079, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4074000.0000, 
sim time next is 4075200.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 19.0, 17.45398413925393, -1.505505000358064, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.32409972299168976, 0.41, 0.0, 0.0, 0.08333333333333333, -0.045501321728839215, -0.0018350001193546313, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6308495], dtype=float32), 0.9735188]. 
=============================================
[2019-04-24 09:46:38,621] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.73294890e-01 7.79145733e-02 1.45907575e-14 8.85084378e-14
 7.42367525e-14 9.09192714e-15 1.38265084e-14 2.23038556e-15
 4.16326045e-12 4.87904847e-02 1.47455544e-14], sum to 1.0000
[2019-04-24 09:46:38,697] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9049
[2019-04-24 09:46:38,815] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [1.0, 43.0, 0.0, 0.0, 19.0, 20.9377207448721, -0.7791618476349383, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 4219200.0000, 
sim time next is 4220400.0000, 
raw observation next is [1.0, 43.0, 0.0, 0.0, 19.0, 20.90213199513387, -0.6032235686895353, 0.0, 1.0, 20.0, 72.28974199448484], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.43, 0.0, 0.0, 0.08333333333333333, 0.2418443329278226, 0.2989254771034882, 0.0, 1.0, 0.1, 0.7228974199448485], 
reward next is 0.1771, 
noisyNet noise sample is [array([0.12660316], dtype=float32), 0.9695642]. 
=============================================
[2019-04-24 09:46:39,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2517159e-01 9.0273917e-02 4.4095824e-14 1.5364263e-13 2.5840219e-13
 8.4269221e-14 4.9419656e-14 4.5166736e-15 1.6366080e-11 8.4554471e-02
 1.1550996e-13], sum to 1.0000
[2019-04-24 09:46:39,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7735
[2019-04-24 09:46:39,885] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.5, 41.66666666666667, 0.0, 0.0, 19.0, 19.65989549991082, -0.9729290679632712, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4214400.0000, 
sim time next is 4215600.0000, 
raw observation next is [1.4, 42.0, 0.0, 0.0, 19.0, 19.54560546983755, -0.9976280430527487, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.5013850415512465, 0.42, 0.0, 0.0, 0.08333333333333333, 0.12880045581979585, 0.1674573189824171, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81312096], dtype=float32), -1.2552685]. 
=============================================
[2019-04-24 09:46:43,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3380684e-01 2.1736601e-02 2.8674507e-17 4.8727910e-16 1.7224800e-16
 9.0685604e-17 2.7089821e-17 2.6850094e-18 1.5942335e-13 4.4456609e-02
 9.5885076e-17], sum to 1.0000
[2019-04-24 09:46:43,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3427
[2019-04-24 09:46:43,321] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 60.0, 47.0, 392.0, 19.0, 20.74925671170658, -0.6852424243292652, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4294800.0000, 
sim time next is 4296000.0000, 
raw observation next is [6.466666666666667, 61.33333333333334, 31.66666666666666, 282.6666666666666, 19.0, 20.68952765234713, -0.709839223178594, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.6417359187442291, 0.6133333333333334, 0.10555555555555554, 0.3123388581952117, 0.08333333333333333, 0.22412730436226092, 0.26338692560713534, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.53476274], dtype=float32), 2.3605428]. 
=============================================
[2019-04-24 09:46:46,651] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3957318e-01 5.5351470e-02 7.8756292e-16 9.2529297e-16 3.3693285e-15
 2.5939582e-16 1.1976550e-16 2.5994248e-17 6.0481459e-13 2.0507535e-01
 8.0040479e-16], sum to 1.0000
[2019-04-24 09:46:46,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0586
[2019-04-24 09:46:46,866] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.466666666666667, 75.66666666666667, 0.0, 0.0, 19.0, 20.23141448929872, -0.8925032706520258, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4318800.0000, 
sim time next is 4320000.0000, 
raw observation next is [4.5, 76.0, 0.0, 0.0, 19.0, 19.87867594734927, -0.9375335259143833, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5872576177285319, 0.76, 0.0, 0.0, 0.08333333333333333, 0.1565563289457724, 0.18748882469520556, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9852012], dtype=float32), -0.050887275]. 
=============================================
[2019-04-24 09:46:46,870] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.77503 ]
 [78.95481 ]
 [79.16175 ]
 [79.40999 ]
 [78.5242  ]
 [78.72053 ]
 [78.86322 ]
 [79.020226]
 [79.17373 ]
 [79.08714 ]
 [79.06124 ]
 [78.98983 ]
 [78.85531 ]
 [78.74996 ]
 [78.50723 ]
 [78.28109 ]
 [78.31599 ]
 [78.630806]
 [79.41643 ]
 [79.93356 ]
 [80.46412 ]
 [80.90129 ]
 [81.26648 ]
 [81.61266 ]
 [80.91435 ]], R is [[79.86690521]
 [80.0682373 ]
 [80.26755524]
 [80.4648819 ]
 [79.66023254]
 [79.8636322 ]
 [80.06499481]
 [80.26434326]
 [80.46170044]
 [80.6570816 ]
 [80.85050964]
 [81.04200745]
 [81.23159027]
 [81.41927338]
 [81.60507965]
 [81.78903198]
 [81.97114563]
 [82.15143585]
 [82.32992554]
 [82.50662994]
 [82.68156433]
 [82.85475159]
 [83.02620697]
 [83.19594574]
 [82.36399078]].
[2019-04-24 09:46:54,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2236159e-01 1.2508194e-01 1.2835156e-17 2.9475849e-16 4.9862199e-16
 5.9394877e-18 8.8184369e-18 1.6079305e-18 7.0504258e-14 5.2556429e-02
 3.3613551e-18], sum to 1.0000
[2019-04-24 09:46:54,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2075
[2019-04-24 09:46:54,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 92.0, 0.0, 0.0, 19.0, 22.37805346939069, -0.3996012589958441, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4680000.0000, 
sim time next is 4681200.0000, 
raw observation next is [-0.3333333333333333, 94.66666666666667, 0.0, 0.0, 19.0, 21.99753167638357, -0.5121311091264117, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4533702677747, 0.9466666666666668, 0.0, 0.0, 0.08333333333333333, 0.33312763969863085, 0.3292896302911961, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.09877], dtype=float32), 0.39392468]. 
=============================================
[2019-04-24 09:46:58,186] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.61007142e-01 1.04164369e-01 1.00609515e-16 1.09532742e-15
 1.82363949e-15 8.66845114e-17 1.97304242e-16 1.26342334e-17
 2.76986929e-13 3.34828496e-01 8.66124607e-17], sum to 1.0000
[2019-04-24 09:46:58,186] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2732
[2019-04-24 09:46:58,254] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 117.0, 33.0, 22.5, 22.93476753837138, -0.3767294325197078, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4525200.0000, 
sim time next is 4526400.0000, 
raw observation next is [0.3333333333333333, 68.33333333333334, 121.0, 11.0, 22.5, 22.66427001729427, -0.4422368495364302, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4718374884579871, 0.6833333333333335, 0.4033333333333333, 0.012154696132596685, 0.375, 0.3886891681078559, 0.35258771682118994, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6916001], dtype=float32), 0.9611489]. 
=============================================
[2019-04-24 09:47:01,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.04017639e-01 1.06304854e-01 2.47546006e-14 9.35930343e-14
 2.09034450e-13 1.03435691e-14 2.17748064e-14 6.63790117e-15
 1.74453906e-11 1.89677581e-01 2.66155167e-14], sum to 1.0000
[2019-04-24 09:47:01,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5412
[2019-04-24 09:47:01,752] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 19.0, 19.75102854526343, -0.9151296856237144, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4756800.0000, 
sim time next is 4758000.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 19.0, 19.53376654452101, -0.9674106131986888, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.3518005540166205, 0.71, 0.0, 0.0, 0.08333333333333333, 0.1278138787100843, 0.17752979560043705, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36436927], dtype=float32), -0.97663015]. 
=============================================
[2019-04-24 09:47:02,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3124080e-01 2.8974263e-02 2.5530689e-15 1.9527445e-14 1.2890445e-14
 2.1633092e-15 7.4903552e-16 1.6911479e-16 2.9774525e-12 3.9784901e-02
 1.0924882e-14], sum to 1.0000
[2019-04-24 09:47:02,122] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9534
[2019-04-24 09:47:02,182] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [3.0, 36.0, 84.5, 578.6666666666666, 19.0, 20.55444652022254, -0.6782528714707082, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 4810800.0000, 
sim time next is 4812000.0000, 
raw observation next is [3.0, 35.0, 73.83333333333334, 488.3333333333333, 19.0, 20.8278191890957, -0.519676600782929, 0.0, 1.0, 20.0, 49.429646144392], 
processed observation next is [0.0, 0.6956521739130435, 0.5457063711911359, 0.35, 0.24611111111111114, 0.5395948434622467, 0.08333333333333333, 0.23565159909130826, 0.32677446640569036, 0.0, 1.0, 0.1, 0.49429646144392003], 
reward next is 0.4057, 
noisyNet noise sample is [array([0.24975406], dtype=float32), 0.26274705]. 
=============================================
[2019-04-24 09:47:03,526] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.3132734e-01 2.9990161e-02 8.0717158e-17 1.1121428e-15 1.0306376e-15
 1.5324899e-17 3.4980691e-17 6.8144049e-18 2.7796160e-13 3.8682487e-02
 5.8649832e-17], sum to 1.0000
[2019-04-24 09:47:03,528] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9661
[2019-04-24 09:47:03,576] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.333333333333333, 59.66666666666667, 0.0, 0.0, 19.0, 22.16041007016675, -0.2455651767575012, 0.0, 1.0, 20.0, 73.20625474651786], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4570800.0000, 
sim time next is 4572000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 19.0, 22.85678399274076, -0.1429953304406354, 0.0, 1.0, 60.0, 59.703886176942774], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.61, 0.0, 0.0, 0.08333333333333333, 0.40473199939506327, 0.4523348898531216, 0.0, 1.0, 0.9, 0.5970388617694278], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04950338], dtype=float32), -0.9811849]. 
=============================================
[2019-04-24 09:47:03,970] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.53007352e-01 1.37704223e-01 1.72515073e-15 7.82789140e-15
 1.84901804e-14 3.53273593e-16 1.79954119e-15 8.76564288e-17
 2.25902868e-12 1.09288454e-01 1.58092082e-15], sum to 1.0000
[2019-04-24 09:47:03,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2687
[2019-04-24 09:47:03,998] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 19.93226836452316, -0.9285390371291463, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4594800.0000, 
sim time next is 4596000.0000, 
raw observation next is [-1.833333333333333, 70.33333333333333, 0.0, 0.0, 19.0, 19.72920997929665, -0.9619562550308983, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.41181902123730385, 0.7033333333333333, 0.0, 0.0, 0.08333333333333333, 0.14410083160805431, 0.17934791498970057, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10298329], dtype=float32), 0.2791049]. 
=============================================
[2019-04-24 09:47:05,219] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6472285e-01 4.6769883e-02 3.5492064e-17 7.2382158e-16 3.0293088e-16
 9.9834620e-18 1.4620970e-17 1.7265929e-18 2.0723000e-13 8.8507257e-02
 1.1080825e-17], sum to 1.0000
[2019-04-24 09:47:05,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0611
[2019-04-24 09:47:05,234] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 50.0, 121.6666666666667, 837.3333333333334, 22.5, 22.4682707451226, -0.3632904031330034, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4621200.0000, 
sim time next is 4622400.0000, 
raw observation next is [3.0, 49.0, 121.0, 846.0, 22.5, 22.41105570205772, -0.34416013965971, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.49, 0.4033333333333333, 0.9348066298342541, 0.375, 0.3675879751714766, 0.3852799534467633, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1480675], dtype=float32), 0.042326644]. 
=============================================
[2019-04-24 09:47:07,844] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2658941e-01 3.3881985e-02 1.2893522e-16 8.1372777e-16 4.1137161e-16
 2.5810123e-17 3.6353840e-17 2.2202067e-17 5.1991614e-13 1.3952860e-01
 8.8034880e-18], sum to 1.0000
[2019-04-24 09:47:07,844] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6046
[2019-04-24 09:47:07,854] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6666666666666666, 78.0, 0.0, 0.0, 22.5, 21.30663822315768, -0.5520545130628961, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4732800.0000, 
sim time next is 4734000.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 22.5, 21.03505643301495, -0.5853707043164311, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.78, 0.0, 0.0, 0.375, 0.2529213694179126, 0.30487643189452296, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8178, 
noisyNet noise sample is [array([-0.9008537], dtype=float32), -2.0981233]. 
=============================================
[2019-04-24 09:47:10,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7843176e-01 8.3284751e-03 1.3713489e-18 5.1478143e-17 3.9352247e-17
 1.2560322e-18 2.9701334e-18 1.5548544e-19 4.3649688e-14 1.3239784e-02
 5.9181150e-18], sum to 1.0000
[2019-04-24 09:47:10,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2336
[2019-04-24 09:47:10,726] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.9, 19.0, 0.0, 0.0, 19.0, 23.23180098224076, -0.08135812073021893, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5088000.0000, 
sim time next is 5089200.0000, 
raw observation next is [8.799999999999999, 19.0, 0.0, 0.0, 19.0, 23.12899194023101, -0.1018874866496489, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7063711911357342, 0.19, 0.0, 0.0, 0.08333333333333333, 0.42741599501925087, 0.46603750445011705, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00181853], dtype=float32), -0.20522852]. 
=============================================
[2019-04-24 09:47:10,957] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:11,120] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:11,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:11,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:11,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run3
[2019-04-24 09:47:12,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8883283e-01 4.5868442e-03 1.7116647e-19 1.0112855e-17 4.5563259e-18
 5.5621816e-19 1.1798784e-19 2.2660469e-20 5.1185837e-15 6.5803216e-03
 5.5390806e-19], sum to 1.0000
[2019-04-24 09:47:12,065] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6238
[2019-04-24 09:47:12,082] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.0, 20.0, 114.5, 839.5, 22.5, 24.97986631500121, 0.2316148519029436, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5061600.0000, 
sim time next is 5062800.0000, 
raw observation next is [11.33333333333333, 19.66666666666667, 112.1666666666667, 825.8333333333333, 22.5, 25.14493452778711, 0.2693592341399233, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7765466297322253, 0.1966666666666667, 0.373888888888889, 0.9125230202578268, 0.375, 0.5954112106489259, 0.5897864113799745, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8332133], dtype=float32), -0.29356337]. 
=============================================
[2019-04-24 09:47:12,904] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:13,109] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:13,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:13,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:13,907] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run3
[2019-04-24 09:47:15,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:15,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:15,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7544038e-01 8.9472514e-03 4.2003566e-18 1.0666461e-16 9.2581363e-17
 7.1406294e-19 2.8686919e-18 3.1475768e-19 7.8161849e-14 1.5612278e-02
 6.7070575e-18], sum to 1.0000
[2019-04-24 09:47:15,964] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3636
[2019-04-24 09:47:15,996] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 24.33333333333334, 0.0, 0.0, 22.5, 24.25838341368532, 0.09159286154822326, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4990800.0000, 
sim time next is 4992000.0000, 
raw observation next is [6.0, 23.66666666666666, 0.0, 0.0, 22.5, 24.14614858361586, 0.06839616862867365, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6288088642659281, 0.2366666666666666, 0.0, 0.0, 0.375, 0.5121790486346551, 0.5227987228762245, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49088988], dtype=float32), 0.3653239]. 
=============================================
[2019-04-24 09:47:16,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:16,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:16,571] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run3
[2019-04-24 09:47:17,053] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:17,271] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:17,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:17,816] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:17,990] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:18,054] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:18,055] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:18,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run3
[2019-04-24 09:47:18,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:18,587] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:18,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:18,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:18,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run3
[2019-04-24 09:47:18,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:18,902] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:18,995] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:19,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:19,006] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run3
[2019-04-24 09:47:19,043] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:19,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:19,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:19,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:19,310] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:19,419] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:19,463] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:19,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:19,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:19,590] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run3
[2019-04-24 09:47:19,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:19,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:19,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:19,907] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run3
[2019-04-24 09:47:19,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:20,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:20,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:20,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run3
[2019-04-24 09:47:20,087] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:20,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:20,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run3
[2019-04-24 09:47:20,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:20,263] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:20,263] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:20,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run3
[2019-04-24 09:47:20,403] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:20,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:20,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:20,780] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:20,782] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run3
[2019-04-24 09:47:20,901] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:21,111] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:21,111] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:21,113] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run3
[2019-04-24 09:47:21,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:21,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:21,619] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run3
[2019-04-24 09:47:21,862] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:22,165] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_1 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:47:22,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:22,518] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_1 ERROR:Aborted (core dumped)

[2019-04-24 09:47:22,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:22,856] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:22,858] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run3
[2019-04-24 09:47:23,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:47:23,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:47:23,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run3
[2019-04-24 09:47:28,257] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.51208174e-01 1.53113585e-02 1.10354290e-15 1.17422306e-14
 4.35438589e-15 1.71432560e-16 2.82728639e-16 3.76813168e-16
 2.72079581e-12 3.34804505e-02 4.45875020e-16], sum to 1.0000
[2019-04-24 09:47:28,257] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3109
[2019-04-24 09:47:28,357] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.799999999999999, 82.0, 189.0, 32.16666666666666, 22.5, 22.33041414564487, -0.3743814959279269, 1.0, 1.0, 60.0, 87.30833521696704], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 124800.0000, 
sim time next is 126000.0000, 
raw observation next is [-7.8, 86.0, 187.0, 24.5, 22.5, 22.555065072175, -0.4989744641935142, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.24653739612188366, 0.86, 0.6233333333333333, 0.02707182320441989, 0.375, 0.3795887560145834, 0.3336751786021619, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2530046], dtype=float32), -1.4418147]. 
=============================================
[2019-04-24 09:47:43,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.02420080e-01 4.86759432e-02 9.63858272e-15 1.38496026e-13
 1.32196188e-13 1.12721484e-14 7.60612463e-15 8.40650385e-15
 2.30483480e-11 1.48903921e-01 8.55355808e-15], sum to 1.0000
[2019-04-24 09:47:43,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0636
[2019-04-24 09:47:43,278] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 22.5, 22.67058734954992, -0.469874327972581, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 147600.0000, 
sim time next is 148800.0000, 
raw observation next is [-7.300000000000001, 67.66666666666667, 0.0, 0.0, 22.5, 22.20877630680539, -0.607500177305773, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.26038781163434904, 0.6766666666666667, 0.0, 0.0, 0.375, 0.3507313589004492, 0.2974999408980757, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7111, 
noisyNet noise sample is [array([-0.05101463], dtype=float32), 1.2348396]. 
=============================================
[2019-04-24 09:47:47,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6323508e-01 1.1919494e-02 6.8099109e-16 1.1922445e-14 1.3757663e-14
 4.4879601e-16 4.1110689e-16 5.3293172e-17 8.0497235e-13 2.4845440e-02
 1.3168726e-15], sum to 1.0000
[2019-04-24 09:47:47,701] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6013
[2019-04-24 09:47:47,715] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 19.0, 20.61027664525222, -0.6933365615265111, 0.0, 1.0, 60.0, 88.69969364688495], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 262800.0000, 
sim time next is 264000.0000, 
raw observation next is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 20.89492774182752, -0.855962365705178, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.27146814404432135, 0.6833333333333335, 0.0, 0.0, 0.08333333333333333, 0.24124397848562662, 0.21467921143160731, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.655514], dtype=float32), 0.85673743]. 
=============================================
[2019-04-24 09:47:55,204] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.7913415e-01 6.4378075e-02 1.7973024e-12 2.9516885e-11 4.5712874e-12
 4.0793706e-13 5.4620295e-13 6.5650832e-13 5.5420563e-10 1.5648775e-01
 8.7652021e-13], sum to 1.0000
[2019-04-24 09:47:55,204] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2966
[2019-04-24 09:47:55,232] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.9, 67.33333333333334, 0.0, 0.0, 19.0, 20.32990791544489, -0.9229846429315444, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 344400.0000, 
sim time next is 345600.0000, 
raw observation next is [-13.9, 66.0, 0.0, 0.0, 19.0, 19.63455084645191, -1.081782018734447, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.07756232686980608, 0.66, 0.0, 0.0, 0.08333333333333333, 0.13621257053765903, 0.13940599375518437, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2898014], dtype=float32), 0.98660177]. 
=============================================
[2019-04-24 09:47:55,578] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.97251964e-01 2.04489846e-02 2.70882543e-17 9.48254245e-17
 4.23014474e-16 1.50981224e-17 1.15624505e-17 1.13201797e-18
 4.49461296e-14 8.22990611e-02 2.85060931e-17], sum to 1.0000
[2019-04-24 09:47:55,578] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1582
[2019-04-24 09:47:55,611] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.533333333333333, 88.33333333333334, 0.0, 0.0, 19.0, 20.4621143153454, -0.6413057039727946, 0.0, 1.0, 60.0, 84.22229550614117], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 524400.0000, 
sim time next is 525600.0000, 
raw observation next is [4.3, 88.0, 0.0, 0.0, 19.0, 21.0193206579973, -0.7329236508168164, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.5817174515235458, 0.88, 0.0, 0.0, 0.08333333333333333, 0.25161005483310844, 0.25569211639439454, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.5799685], dtype=float32), 0.7132786]. 
=============================================
[2019-04-24 09:48:00,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8225446e-01 9.8261602e-02 5.4044425e-15 3.7325842e-14 4.3919563e-14
 1.7797443e-14 7.0071673e-15 3.8275293e-16 3.3791559e-12 1.1948397e-01
 1.5124732e-14], sum to 1.0000
[2019-04-24 09:48:00,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7987
[2019-04-24 09:48:00,450] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-1.2, 83.0, 70.5, 59.0, 19.0, 20.34696121011096, -0.8430166054481584, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 576000.0000, 
sim time next is 577200.0000, 
raw observation next is [-1.366666666666667, 84.33333333333334, 50.83333333333334, 49.66666666666666, 19.0, 20.17712298929292, -0.7657854660426265, 0.0, 1.0, 20.0, 54.8487555169104], 
processed observation next is [0.0, 0.6956521739130435, 0.42474607571560485, 0.8433333333333334, 0.16944444444444448, 0.05488029465930017, 0.08333333333333333, 0.18142691577440986, 0.24473817798579114, 0.0, 1.0, 0.1, 0.548487555169104], 
reward next is 0.3515, 
noisyNet noise sample is [array([0.6936078], dtype=float32), 1.8062731]. 
=============================================
[2019-04-24 09:48:01,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4819977e-01 9.7386338e-02 2.4028587e-13 9.7806388e-13 6.2408808e-13
 9.4987738e-14 1.8157009e-13 4.0981399e-14 4.5797633e-11 3.5441390e-01
 1.2386918e-13], sum to 1.0000
[2019-04-24 09:48:01,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4308
[2019-04-24 09:48:01,986] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 65.0, 0.0, 0.0, 19.0, 19.23662610959455, -1.170542736684261, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 676800.0000, 
sim time next is 678000.0000, 
raw observation next is [-3.0, 66.33333333333334, 0.0, 0.0, 19.0, 18.71502289752245, -1.243678701253287, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.3795013850415513, 0.6633333333333334, 0.0, 0.0, 0.08333333333333333, 0.05958524146020405, 0.08544043291557098, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.6752, 
noisyNet noise sample is [array([1.4462302], dtype=float32), -0.3663885]. 
=============================================
[2019-04-24 09:48:03,538] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0997312e-01 7.7735171e-02 1.5283388e-12 4.0084906e-12 4.2424267e-12
 7.1515988e-14 2.0912466e-13 1.1889139e-13 2.3946226e-10 6.1229169e-01
 1.1972061e-13], sum to 1.0000
[2019-04-24 09:48:03,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7652
[2019-04-24 09:48:03,729] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.9, 26.0, 123.1666666666667, 0.0, 22.5, 20.58246354947238, -1.036566278374107, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 474000.0000, 
sim time next is 475200.0000, 
raw observation next is [-1.7, 25.0, 125.5, 0.0, 22.5, 21.58361699104429, -0.5174627953334282, 1.0, 1.0, 60.0, 121.75742518745028], 
processed observation next is [1.0, 0.5217391304347826, 0.4155124653739613, 0.25, 0.41833333333333333, 0.0, 0.375, 0.29863474925369093, 0.3275124015555239, 1.0, 1.0, 0.9, 1.2175742518745027], 
reward next is 0.0873, 
noisyNet noise sample is [array([-1.9340878], dtype=float32), 1.9250576]. 
=============================================
[2019-04-24 09:48:11,552] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.8382684e-01 7.8872487e-02 1.4195324e-13 6.9139773e-13 8.0430882e-13
 4.4686995e-14 9.1942892e-14 3.7651333e-14 3.7311952e-11 3.3730066e-01
 5.9521066e-14], sum to 1.0000
[2019-04-24 09:48:11,553] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5266
[2019-04-24 09:48:11,631] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 57.00000000000001, 0.0, 0.0, 19.0, 19.73669875966156, -1.081020653644434, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 667200.0000, 
sim time next is 668400.0000, 
raw observation next is [-1.2, 57.0, 0.0, 0.0, 19.0, 18.99248620269851, -1.225031249755567, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.57, 0.0, 0.0, 0.08333333333333333, 0.08270718355820932, 0.09165625008147764, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9998, 
noisyNet noise sample is [array([-0.66857284], dtype=float32), -0.8513348]. 
=============================================
[2019-04-24 09:48:20,845] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.2828850e-01 3.3034772e-02 7.9547013e-16 6.8330741e-15 9.5106265e-15
 1.6221053e-16 7.0279038e-16 7.5956430e-16 2.5424320e-12 1.3867670e-01
 8.3011357e-16], sum to 1.0000
[2019-04-24 09:48:20,859] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9156
[2019-04-24 09:48:21,102] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.733333333333333, 85.0, 0.0, 0.0, 22.5, 21.94508947158282, -0.6001070049072977, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 847200.0000, 
sim time next is 848400.0000, 
raw observation next is [-3.566666666666666, 84.0, 0.0, 0.0, 22.5, 21.96903214062926, -0.322377140229525, 1.0, 1.0, 60.0, 109.8865361654575], 
processed observation next is [1.0, 0.8260869565217391, 0.3638042474607572, 0.84, 0.0, 0.0, 0.375, 0.33075267838577166, 0.392540953256825, 1.0, 1.0, 0.9, 1.098865361654575], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4526598], dtype=float32), -0.26166335]. 
=============================================
[2019-04-24 09:48:22,108] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.2049472e-01 8.8420287e-02 1.6865701e-15 4.8058379e-15 1.2357801e-14
 5.1316363e-16 1.4002013e-15 9.9105618e-16 2.3068639e-12 2.9108500e-01
 1.3764334e-15], sum to 1.0000
[2019-04-24 09:48:22,108] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0234
[2019-04-24 09:48:22,122] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.466666666666667, 79.66666666666666, 0.0, 0.0, 19.0, 20.55032945849384, -0.8096429595669051, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 862800.0000, 
sim time next is 864000.0000, 
raw observation next is [-2.3, 80.0, 0.0, 0.0, 19.0, 20.33140792431475, -0.8503667913036058, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3988919667590028, 0.8, 0.0, 0.0, 0.08333333333333333, 0.1942839936928958, 0.21654440289879806, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4526598], dtype=float32), -0.26166335]. 
=============================================
[2019-04-24 09:48:22,448] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5341439e-01 7.4280091e-02 6.6740288e-16 5.1219621e-15 8.5738445e-15
 7.6085555e-17 3.3973756e-16 9.7731191e-17 3.1450493e-13 5.7230556e-01
 9.8222682e-17], sum to 1.0000
[2019-04-24 09:48:22,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2512
[2019-04-24 09:48:22,508] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3666666666666667, 74.66666666666667, 24.16666666666667, 0.0, 22.5, 21.27331621325424, -0.5260703032965854, 1.0, 1.0, 20.0, 81.93068579956713], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 894000.0000, 
sim time next is 895200.0000, 
raw observation next is [0.7333333333333334, 77.33333333333333, 32.16666666666666, 0.0, 22.5, 22.35068342828556, -0.550119580289859, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4829178208679595, 0.7733333333333333, 0.10722222222222219, 0.0, 0.375, 0.36255695235713, 0.316626806570047, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9372, 
noisyNet noise sample is [array([-0.4599953], dtype=float32), -0.6892815]. 
=============================================
[2019-04-24 09:48:24,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5790689e-01 1.2709704e-01 3.5251238e-16 1.6554991e-15 1.8671020e-15
 6.2507855e-17 1.6346637e-16 1.8943986e-17 7.6050993e-13 2.1499610e-01
 3.9255133e-17], sum to 1.0000
[2019-04-24 09:48:24,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2473
[2019-04-24 09:48:24,685] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 80.0, 38.5, 0.0, 22.5, 22.35318253062555, -0.4618526230587714, 1.0, 1.0, 20.0, 31.185767038472346], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 896400.0000, 
sim time next is 897600.0000, 
raw observation next is [1.1, 81.33333333333334, 44.83333333333333, 0.0, 22.5, 22.48130777857273, -0.5270551531615127, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.49307479224376743, 0.8133333333333335, 0.14944444444444444, 0.0, 0.375, 0.3734423148810609, 0.3243149489461624, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9817, 
noisyNet noise sample is [array([0.08843786], dtype=float32), -0.8845259]. 
=============================================
[2019-04-24 09:48:25,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6209712e-01 3.6698136e-02 5.1876769e-18 5.0016908e-17 3.6707652e-17
 7.4859975e-19 1.7320751e-18 1.5693008e-18 3.0074237e-14 2.0120476e-01
 1.2075008e-18], sum to 1.0000
[2019-04-24 09:48:25,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2228
[2019-04-24 09:48:25,657] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 100.0, 0.0, 0.0, 19.0, 20.21389530173467, -0.7499301256273601, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 939600.0000, 
sim time next is 940800.0000, 
raw observation next is [5.0, 98.66666666666667, 0.0, 0.0, 19.0, 20.07305364256353, -0.7772062809381918, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.6011080332409973, 0.9866666666666667, 0.0, 0.0, 0.08333333333333333, 0.17275447021362744, 0.2409312396872694, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9639911], dtype=float32), -0.20708676]. 
=============================================
[2019-04-24 09:48:25,730] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.8937316e-01 2.0879464e-02 1.7462757e-17 3.5169073e-16 6.9138244e-17
 1.4814112e-18 6.6721546e-18 1.8870140e-18 5.8614876e-14 1.8974736e-01
 3.1237063e-18], sum to 1.0000
[2019-04-24 09:48:25,732] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9170
[2019-04-24 09:48:25,780] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.066666666666667, 95.66666666666667, 102.8333333333333, 0.0, 22.5, 23.66026591881162, -0.2577422184781787, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 908400.0000, 
sim time next is 909600.0000, 
raw observation next is [3.433333333333334, 94.33333333333334, 102.6666666666667, 0.0, 22.5, 23.51561745176969, -0.08381004793921971, 1.0, 1.0, 60.0, 76.0745564944489], 
processed observation next is [1.0, 0.5217391304347826, 0.5577100646352725, 0.9433333333333335, 0.3422222222222223, 0.0, 0.375, 0.45963478764747406, 0.47206331735359347, 1.0, 1.0, 0.9, 0.760745564944489], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11722677], dtype=float32), 0.6596468]. 
=============================================
[2019-04-24 09:48:26,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6805526e-01 6.2808350e-02 5.2260609e-18 6.3042412e-18 6.1840552e-17
 1.7583684e-18 2.6170245e-18 1.6733141e-19 7.8039483e-15 1.6913645e-01
 5.1957865e-18], sum to 1.0000
[2019-04-24 09:48:26,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4875
[2019-04-24 09:48:26,580] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.233333333333333, 84.33333333333334, 0.0, 0.0, 19.0, 20.4538436748451, -0.7134839633714001, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 956400.0000, 
sim time next is 957600.0000, 
raw observation next is [6.6, 82.0, 0.0, 0.0, 19.0, 20.47383390567025, -0.717299995393106, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.6454293628808865, 0.82, 0.0, 0.0, 0.08333333333333333, 0.2061528254725209, 0.26090000153563137, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0810877], dtype=float32), -1.5455468]. 
=============================================
[2019-04-24 09:48:26,618] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-24 09:48:26,620] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:48:26,620] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:48:26,620] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:48:26,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:48:26,622] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run4
[2019-04-24 09:48:26,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:48:26,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:48:26,642] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run4
[2019-04-24 09:48:26,643] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run4
[2019-04-24 09:50:06,117] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3379.9080 65510.3488 -213.4750
[2019-04-24 09:50:06,152] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:06,152] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:06,152] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:06,152] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:06,323] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:06,323] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:06,323] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:06,323] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:13,124] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3153.6680 81740.7550 -423.2543
[2019-04-24 09:50:13,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:13,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:13,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:13,160] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:13,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:13,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:13,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:13,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:24,952] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3071.1131 84661.8222 -542.4972
[2019-04-24 09:50:24,989] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:24,989] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:24,989] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:24,989] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:50:25,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:25,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:25,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:25,160] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:50:25,991] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 150000, evaluation results [150000.0, 3153.667991169917, 81740.75498371276, -423.254270620309, 3379.9079726170835, 65510.3488202436, -213.47498348217457, 3071.1131343387183, 84661.82217003155, -542.4972285138051]
[2019-04-24 09:50:26,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4532967e-01 1.2447128e-02 3.4128733e-21 6.8761010e-20 2.1950620e-19
 3.4186062e-21 2.4882207e-21 1.1140152e-22 3.3716007e-17 4.2223141e-02
 5.1187192e-21], sum to 1.0000
[2019-04-24 09:50:26,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8509
[2019-04-24 09:50:27,016] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 19.0, 23.16526397863547, -0.09126781372347507, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1038000.0000, 
sim time next is 1039200.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 19.0, 23.09634400984229, -0.1276551554867006, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.8614958448753465, 0.75, 0.0, 0.0, 0.08333333333333333, 0.42469533415352423, 0.4574482815044331, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03424165], dtype=float32), -0.57420635]. 
=============================================
[2019-04-24 09:50:29,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8359019e-01 8.1625497e-03 2.0004782e-19 4.0941768e-18 1.6702272e-17
 9.7670850e-20 1.1016210e-19 2.1282787e-20 6.6674796e-15 8.2472209e-03
 1.1047821e-18], sum to 1.0000
[2019-04-24 09:50:29,511] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1708
[2019-04-24 09:50:29,547] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.46666666666667, 61.33333333333333, 0.0, 0.0, 19.0, 23.47760496654517, 0.09588968818248196, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1111200.0000, 
sim time next is 1112400.0000, 
raw observation next is [13.3, 62.0, 0.0, 0.0, 19.0, 23.34932555895581, 0.07220171689015857, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8310249307479226, 0.62, 0.0, 0.0, 0.08333333333333333, 0.4457771299129843, 0.5240672389633861, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9277425], dtype=float32), -1.1209978]. 
=============================================
[2019-04-24 09:50:33,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.79071140e-01 5.54339122e-03 1.00078716e-16 1.29248990e-15
 4.74616277e-15 3.61409186e-16 2.31753614e-16 2.24783503e-17
 5.31075292e-13 1.53854657e-02 8.73602041e-16], sum to 1.0000
[2019-04-24 09:50:33,949] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6282
[2019-04-24 09:50:33,987] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.46666666666667, 64.33333333333333, 169.0, 0.0, 19.0, 23.28165216914709, 0.04107418957197581, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1168800.0000, 
sim time next is 1170000.0000, 
raw observation next is [18.3, 65.0, 165.0, 0.0, 19.0, 23.21813697427919, 0.03388756795715888, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.9695290858725764, 0.65, 0.55, 0.0, 0.08333333333333333, 0.43484474785659916, 0.5112958559857196, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00297246], dtype=float32), -0.112612136]. 
=============================================
[2019-04-24 09:50:34,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.994774]
 [71.942505]
 [73.44797 ]
 [75.25615 ]
 [77.21801 ]
 [79.20157 ]
 [80.960014]
 [81.95174 ]
 [84.23624 ]
 [87.23905 ]
 [90.28553 ]
 [93.08064 ]
 [92.82121 ]
 [92.52121 ]
 [92.25643 ]
 [91.955086]
 [91.78018 ]
 [91.604576]
 [91.4602  ]
 [91.30456 ]
 [91.13375 ]
 [90.96357 ]
 [90.00346 ]
 [89.864105]
 [89.81918 ]], R is [[72.27788544]
 [72.55510712]
 [72.82955933]
 [73.10126495]
 [73.37025452]
 [73.6365509 ]
 [73.90018463]
 [73.16118622]
 [73.42957306]
 [73.69527435]
 [73.95832062]
 [74.21873474]
 [74.47654724]
 [74.73178101]
 [74.98446655]
 [75.23461914]
 [75.48227692]
 [75.72745514]
 [75.97018433]
 [76.21047974]
 [76.44837189]
 [76.6838913 ]
 [76.12789154]
 [76.3666153 ]
 [76.60295105]].
[2019-04-24 09:50:39,251] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.5052558e-01 9.7800111e-03 4.5738906e-18 8.4879458e-17 2.5164704e-17
 1.7645762e-18 1.5593375e-18 5.6146802e-19 3.8349115e-14 3.9694395e-02
 7.0169417e-18], sum to 1.0000
[2019-04-24 09:50:39,252] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7272
[2019-04-24 09:50:39,285] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 22.5, 22.83645321548344, -0.1109404846332773, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1360800.0000, 
sim time next is 1362000.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 22.95209688184458, -0.1587616192264906, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.4126747401537149, 0.44707946025783646, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2303359], dtype=float32), -0.18855524]. 
=============================================
[2019-04-24 09:50:40,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.41365969e-01 1.00649804e-01 8.97987074e-17 2.27593121e-16
 1.04827707e-15 5.72893546e-18 1.56241620e-16 3.12129842e-18
 4.58227918e-14 1.57984167e-01 2.20822234e-17], sum to 1.0000
[2019-04-24 09:50:40,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5595
[2019-04-24 09:50:40,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.10918048727734, -0.6360243921584662, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1393200.0000, 
sim time next is 1394400.0000, 
raw observation next is [-0.2, 96.66666666666667, 0.0, 0.0, 19.0, 20.68669423445356, -0.701270156946545, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.4570637119113574, 0.9666666666666667, 0.0, 0.0, 0.08333333333333333, 0.22389118620446347, 0.2662432810178183, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7939857], dtype=float32), -0.09371183]. 
=============================================
[2019-04-24 09:50:43,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4956392e-01 3.3526761e-03 1.3162107e-19 8.1204619e-18 4.4775539e-18
 4.2981397e-20 4.6600548e-20 6.6262268e-21 1.9514432e-15 4.7083430e-02
 1.2275133e-18], sum to 1.0000
[2019-04-24 09:50:43,382] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1066
[2019-04-24 09:50:43,440] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.066666666666666, 66.33333333333334, 83.33333333333334, 694.6666666666667, 22.5, 23.49907515205951, -0.1357425988749886, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1518000.0000, 
sim time next is 1519200.0000, 
raw observation next is [10.0, 63.0, 80.0, 682.0, 22.5, 23.23081455098739, -0.06283578602481797, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.739612188365651, 0.63, 0.26666666666666666, 0.7535911602209945, 0.375, 0.4359012125822825, 0.4790547379917274, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4306654], dtype=float32), 1.5157093]. 
=============================================
[2019-04-24 09:50:45,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.3734438e-01 1.3866690e-01 7.0163503e-18 3.8458330e-17 3.0036405e-16
 4.9402361e-18 3.6015560e-17 5.8662026e-19 1.7175233e-14 1.2398870e-01
 4.1226702e-18], sum to 1.0000
[2019-04-24 09:50:45,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5311
[2019-04-24 09:50:46,010] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.4, 86.0, 0.0, 0.0, 19.0, 20.36341421295914, -0.694807382910649, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1566000.0000, 
sim time next is 1567200.0000, 
raw observation next is [4.466666666666667, 85.66666666666667, 0.0, 0.0, 19.0, 20.36606552939135, -0.703310617450028, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5863342566943676, 0.8566666666666667, 0.0, 0.0, 0.08333333333333333, 0.19717212744927912, 0.26556312751665734, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4123799], dtype=float32), -0.42625302]. 
=============================================
[2019-04-24 09:50:56,090] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6960212e-01 1.2990057e-01 4.3106379e-18 1.9271684e-17 9.7960823e-17
 2.6154318e-18 7.8671370e-18 1.8394342e-19 2.1726991e-14 1.0049730e-01
 4.3980391e-18], sum to 1.0000
[2019-04-24 09:50:56,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2329
[2019-04-24 09:50:56,201] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 80.0, 0.0, 0.0, 19.0, 20.89596134359901, -0.6374089019436223, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1579200.0000, 
sim time next is 1580400.0000, 
raw observation next is [5.5, 79.0, 0.0, 0.0, 19.0, 20.70793879530165, -0.6695455208640825, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.6149584487534627, 0.79, 0.0, 0.0, 0.08333333333333333, 0.22566156627513756, 0.2768181597119725, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6342126], dtype=float32), -1.5560458]. 
=============================================
[2019-04-24 09:51:05,005] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.4147551e-01 1.7682236e-02 1.8603697e-18 5.1435472e-18 1.2492367e-17
 3.0299923e-19 8.0218528e-20 7.1921693e-20 1.3883567e-15 4.0842239e-02
 3.2026055e-19], sum to 1.0000
[2019-04-24 09:51:05,007] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7270
[2019-04-24 09:51:05,166] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 93.0, 0.0, 0.0, 19.0, 21.56938869292677, -0.3937702160415506, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1645200.0000, 
sim time next is 1646400.0000, 
raw observation next is [6.800000000000001, 94.0, 0.0, 0.0, 19.0, 21.51748142607635, -0.4113943198953165, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.6509695290858727, 0.94, 0.0, 0.0, 0.08333333333333333, 0.29312345217302926, 0.3628685600348945, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.694929], dtype=float32), 0.09923605]. 
=============================================
[2019-04-24 09:51:26,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9683251e-01 2.2896601e-01 2.5746031e-13 1.8724939e-13 2.1973329e-13
 9.6749238e-15 4.0030682e-14 8.7625829e-15 1.8428746e-11 5.7420152e-01
 3.4909518e-14], sum to 1.0000
[2019-04-24 09:51:26,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3311
[2019-04-24 09:51:26,825] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-7.1, 78.66666666666667, 0.0, 0.0, 22.5, 19.12894012713486, -1.196058418170353, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2101200.0000, 
sim time next is 2102400.0000, 
raw observation next is [-7.3, 79.0, 36.5, 18.5, 22.5, 19.65781212106234, -0.8347553987186149, 1.0, 1.0, 20.0, 95.95321139357088], 
processed observation next is [1.0, 0.34782608695652173, 0.26038781163434904, 0.79, 0.12166666666666667, 0.020441988950276244, 0.375, 0.13815101008852823, 0.22174820042712837, 1.0, 1.0, 0.1, 0.9595321139357088], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.11266601], dtype=float32), 2.8635192]. 
=============================================
[2019-04-24 09:51:41,925] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8362846e-01 5.2592993e-02 4.4182723e-14 2.2642997e-13 3.0766381e-13
 4.1222590e-14 4.5702411e-14 5.8956771e-15 4.2748187e-11 1.6377850e-01
 4.2486542e-14], sum to 1.0000
[2019-04-24 09:51:41,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2367
[2019-04-24 09:51:41,962] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 69.0, 7.833333333333332, 0.0, 19.0, 19.44158392084829, -0.8201184539053586, 0.0, 1.0, 60.0, 96.0762767204964], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2360400.0000, 
sim time next is 2361600.0000, 
raw observation next is [-3.4, 69.0, 19.5, 0.0, 19.0, 20.32376785678947, -0.8911523541426983, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.065, 0.0, 0.08333333333333333, 0.19364732139912247, 0.20294921528576723, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8925979], dtype=float32), -1.305747]. 
=============================================
[2019-04-24 09:51:45,713] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9321631e-01 1.6908418e-02 5.5890749e-15 1.2550432e-13 4.3011967e-14
 1.4881553e-15 2.8101165e-15 1.5295484e-15 3.2948980e-11 8.9875199e-02
 6.9854710e-15], sum to 1.0000
[2019-04-24 09:51:45,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1119
[2019-04-24 09:51:45,763] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.4, 64.66666666666667, 163.8333333333333, 100.0, 22.5, 22.64648955825681, -0.4394464667773473, 1.0, 1.0, 60.0, 77.82718212429768], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2287200.0000, 
sim time next is 2288400.0000, 
raw observation next is [-3.8, 61.33333333333333, 177.8333333333333, 104.0, 22.5, 22.6364782252689, -0.4272791912814607, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3573407202216067, 0.6133333333333333, 0.5927777777777776, 0.11491712707182321, 0.375, 0.3863731854390749, 0.3575736029061798, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1671361], dtype=float32), 0.06153746]. 
=============================================
[2019-04-24 09:51:57,428] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5678648e-01 1.6690885e-01 2.4745924e-12 2.3828355e-12 5.9580739e-12
 1.1173921e-12 8.3645233e-13 5.2823051e-13 4.8421578e-10 3.7630460e-01
 1.5786061e-12], sum to 1.0000
[2019-04-24 09:51:57,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9917
[2019-04-24 09:51:57,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.2, 33.0, 0.0, 0.0, 19.0, 19.37861478070239, -1.148640707649524, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2498400.0000, 
sim time next is 2499600.0000, 
raw observation next is [-1.0, 33.66666666666667, 0.0, 0.0, 19.0, 19.60674512009849, -0.8697559746215879, 0.0, 1.0, 60.0, 94.41297701242243], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 0.3366666666666667, 0.0, 0.0, 0.08333333333333333, 0.13389542667487428, 0.21008134179280402, 0.0, 1.0, 0.9, 0.9441297701242243], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0749115], dtype=float32), -0.32792792]. 
=============================================
[2019-04-24 09:52:00,010] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.53090286e-01 7.17106685e-02 1.06451924e-14 1.31982248e-13
 1.47303407e-13 2.74519799e-15 5.94672440e-15 1.73772674e-15
 1.66877640e-11 7.51990974e-02 1.40871032e-14], sum to 1.0000
[2019-04-24 09:52:00,010] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2429
[2019-04-24 09:52:00,028] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.633333333333333, 84.66666666666666, 0.0, 0.0, 19.0, 20.67732095212446, -0.6766599987568985, 0.0, 1.0, 60.0, 86.85603085562151], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2256000.0000, 
sim time next is 2257200.0000, 
raw observation next is [-7.8, 86.0, 0.0, 0.0, 19.0, 20.85873202683461, -0.824551790434057, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.24653739612188366, 0.86, 0.0, 0.0, 0.08333333333333333, 0.23822766890288408, 0.22514940318864765, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.1821094], dtype=float32), 2.5855856]. 
=============================================
[2019-04-24 09:52:10,879] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0395582e-01 3.1595476e-02 2.0160731e-14 6.2991143e-14 1.1645265e-13
 1.8491637e-14 7.9555054e-15 3.0832035e-15 6.7877600e-12 6.4448752e-02
 1.8834066e-14], sum to 1.0000
[2019-04-24 09:52:10,880] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6687
[2019-04-24 09:52:10,993] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 65.0, 0.0, 0.0, 19.0, 20.37459441241545, -0.6018444774919144, 0.0, 1.0, 60.0, 94.87120072337433], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2347200.0000, 
sim time next is 2348400.0000, 
raw observation next is [-3.0, 66.33333333333334, 0.0, 0.0, 19.0, 21.18190401613732, -0.7250342628338758, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.6633333333333334, 0.0, 0.0, 0.08333333333333333, 0.26515866801144333, 0.25832191238870805, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.270178], dtype=float32), -1.6258135]. 
=============================================
[2019-04-24 09:52:12,487] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.53541613e-01 3.37583199e-02 6.51412170e-15 4.54750543e-14
 6.40335495e-14 2.85982590e-15 1.24693296e-14 1.64868737e-15
 1.34711166e-11 1.12700000e-01 4.11865197e-15], sum to 1.0000
[2019-04-24 09:52:12,523] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9222
[2019-04-24 09:52:12,615] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.8, 56.0, 0.0, 0.0, 19.0, 22.01490872138156, -0.4940651878972213, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2583600.0000, 
sim time next is 2584800.0000, 
raw observation next is [-2.8, 56.0, 0.0, 0.0, 19.0, 21.97638482333463, -0.2709213982713157, 0.0, 1.0, 60.0, 90.5566127660511], 
processed observation next is [1.0, 0.9565217391304348, 0.38504155124653744, 0.56, 0.0, 0.0, 0.08333333333333333, 0.3313654019445525, 0.4096928672428948, 0.0, 1.0, 0.9, 0.905566127660511], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60318995], dtype=float32), -0.84088016]. 
=============================================
[2019-04-24 09:52:14,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0850267e-01 3.1025102e-02 2.0607149e-13 4.8571688e-13 1.1631936e-12
 1.4623083e-13 8.6337350e-14 9.7444881e-15 6.2118984e-11 1.6047232e-01
 2.5374023e-13], sum to 1.0000
[2019-04-24 09:52:14,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9377
[2019-04-24 09:52:14,252] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.3, 25.0, 27.0, 161.0, 19.0, 19.51883819575028, -1.026864433554292, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2480400.0000, 
sim time next is 2481600.0000, 
raw observation next is [2.566666666666667, 26.0, 13.0, 82.33333333333333, 19.0, 19.97920303409303, -0.740809305413828, 0.0, 1.0, 60.0, 89.05252346346529], 
processed observation next is [0.0, 0.7391304347826086, 0.5337026777469991, 0.26, 0.043333333333333335, 0.09097605893186003, 0.08333333333333333, 0.16493358617441908, 0.25306356486205733, 0.0, 1.0, 0.9, 0.8905252346346529], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5406827], dtype=float32), -1.915376]. 
=============================================
[2019-04-24 09:52:19,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.67070246e-01 7.27902427e-02 3.79370878e-14 2.34656858e-13
 3.38985188e-13 7.25738422e-15 2.29962279e-14 1.05339855e-14
 3.05716251e-11 3.60139459e-01 6.32193120e-15], sum to 1.0000
[2019-04-24 09:52:19,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3376
[2019-04-24 09:52:19,940] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 64.0, 90.0, 172.5, 22.5, 19.63859574581483, -0.6531699852894667, 1.0, 1.0, 60.0, 145.38150385809766], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2794800.0000, 
sim time next is 2796000.0000, 
raw observation next is [-6.0, 64.0, 115.3333333333333, 211.3333333333333, 22.5, 22.05388442594973, -0.630705015939541, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.3844444444444443, 0.23351749539594838, 0.375, 0.3378237021624774, 0.28976499468681965, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7197, 
noisyNet noise sample is [array([1.6949325], dtype=float32), 0.1547082]. 
=============================================
[2019-04-24 09:52:22,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7917064e-01 1.2506227e-01 1.3143527e-14 1.8066138e-13 1.4576869e-13
 7.5775661e-15 7.7475622e-15 1.0903913e-14 1.4490312e-11 2.9576716e-01
 1.0382206e-14], sum to 1.0000
[2019-04-24 09:52:22,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3762
[2019-04-24 09:52:22,892] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 19.0, 19.23746159331999, -1.123253700638084, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2613600.0000, 
sim time next is 2614800.0000, 
raw observation next is [-6.9, 78.33333333333334, 0.0, 0.0, 19.0, 18.74729306779415, -1.191081662724438, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.27146814404432135, 0.7833333333333334, 0.0, 0.0, 0.08333333333333333, 0.062274422316179155, 0.10297277909185398, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.12403258], dtype=float32), -0.6033659]. 
=============================================
[2019-04-24 09:52:23,848] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6218053e-01 4.1664325e-02 5.6623909e-16 5.2301299e-15 6.2611028e-15
 8.7850452e-17 3.1365670e-16 1.6317547e-16 4.8001284e-13 9.6155167e-02
 4.1373872e-16], sum to 1.0000
[2019-04-24 09:52:23,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1628
[2019-04-24 09:52:23,890] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 74.33333333333334, 0.0, 0.0, 19.0, 20.76761431081511, -0.7817201368664873, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2856000.0000, 
sim time next is 2857200.0000, 
raw observation next is [1.0, 76.66666666666667, 0.0, 0.0, 19.0, 20.35206913645955, -0.8588464429381523, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.7666666666666667, 0.0, 0.0, 0.08333333333333333, 0.19600576137162928, 0.21371785235394924, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5620318], dtype=float32), 0.9338669]. 
=============================================
[2019-04-24 09:52:25,633] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0564812e-01 3.5310242e-02 2.2277614e-14 7.1741773e-14 3.3675780e-14
 2.3953501e-15 5.0550990e-15 1.3903314e-15 2.0099937e-11 2.5904170e-01
 4.7549897e-15], sum to 1.0000
[2019-04-24 09:52:25,641] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7450
[2019-04-24 09:52:25,971] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.1333333333333334, 51.33333333333334, 18.33333333333333, 89.0, 22.5, 21.63184592662258, -0.6409618394733597, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2654400.0000, 
sim time next is 2655600.0000, 
raw observation next is [-0.2333333333333333, 52.66666666666667, 0.0, 0.0, 22.5, 22.60526653989919, -0.270125223844688, 1.0, 1.0, 60.0, 124.72959790462943], 
processed observation next is [1.0, 0.7391304347826086, 0.456140350877193, 0.5266666666666667, 0.0, 0.0, 0.375, 0.38377221165826586, 0.40995825871843733, 1.0, 1.0, 0.9, 1.2472959790462943], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0325263], dtype=float32), 0.30530295]. 
=============================================
[2019-04-24 09:52:46,271] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.59519100e-01 4.96515259e-02 2.12555922e-14 1.75451816e-13
 1.13496486e-13 9.17519387e-15 1.88253056e-14 3.33197118e-15
 5.29067345e-11 1.90829396e-01 1.68950869e-14], sum to 1.0000
[2019-04-24 09:52:46,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8767
[2019-04-24 09:52:46,334] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.666666666666666, 74.66666666666666, 0.0, 0.0, 19.0, 20.70604733568405, -0.7070607018760877, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3289200.0000, 
sim time next is 3290400.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 20.88694028853554, -0.4123677292150794, 0.0, 1.0, 60.0, 98.1356716923131], 
processed observation next is [1.0, 0.08695652173913043, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.24057835737796177, 0.3625440902616402, 0.0, 1.0, 0.9, 0.981356716923131], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.711405], dtype=float32), 0.6530652]. 
=============================================
[2019-04-24 09:52:48,470] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.5216858e-01 7.3863459e-03 9.8295816e-19 9.5272711e-18 9.5695235e-18
 1.2804448e-19 1.0173529e-19 6.7865781e-20 9.5610724e-15 4.0445074e-02
 2.3514995e-18], sum to 1.0000
[2019-04-24 09:52:48,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7194
[2019-04-24 09:52:48,511] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 100.0, 0.0, 0.0, 19.0, 22.19275808990098, -0.2149866718075368, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3188400.0000, 
sim time next is 3189600.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 19.0, 22.13909932700312, -0.2306041778576946, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 1.0, 0.0, 0.0, 0.08333333333333333, 0.34492494391692663, 0.4231319407141018, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6788353], dtype=float32), 0.015953045]. 
=============================================
[2019-04-24 09:52:48,587] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3975788e-01 1.2896852e-02 1.0188532e-15 3.5056793e-14 1.8457854e-14
 5.9449807e-16 7.6998651e-16 1.2704712e-16 1.1100016e-11 4.7345180e-02
 6.6843033e-15], sum to 1.0000
[2019-04-24 09:52:48,597] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5066
[2019-04-24 09:52:48,611] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 53.33333333333333, 9.166666666666668, 110.8333333333333, 22.5, 22.8327288250676, -0.2383355695728429, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3346800.0000, 
sim time next is 3348000.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 22.5, 22.20539876368328, -0.3045188141981629, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3795013850415513, 0.55, 0.0, 0.0, 0.375, 0.35044989697360673, 0.39849372860061233, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2718302], dtype=float32), 0.87876093]. 
=============================================
[2019-04-24 09:52:48,943] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4743901e-01 8.3849793e-03 4.1238530e-20 1.5359317e-18 4.5455255e-19
 9.3340597e-22 1.5101578e-20 9.7919787e-22 5.5612144e-16 4.4176109e-02
 2.5690023e-20], sum to 1.0000
[2019-04-24 09:52:48,943] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8438
[2019-04-24 09:52:48,994] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0973374e-01 1.3427550e-01 8.3127793e-14 2.5345017e-13 2.1704973e-13
 8.4404944e-15 3.5992703e-14 6.2368683e-15 1.1865600e-11 3.5599068e-01
 1.8462620e-14], sum to 1.0000
[2019-04-24 09:52:49,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9207
[2019-04-24 09:52:49,018] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 103.5, 696.5, 22.5, 23.28117254554588, -0.05956248254663624, 1.0, 1.0, 60.0, 86.16097146883513], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3146400.0000, 
sim time next is 3147600.0000, 
raw observation next is [7.0, 100.0, 106.5, 729.5, 22.5, 24.17847628287996, -0.0848499768858796, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.355, 0.8060773480662984, 0.375, 0.51487302357333, 0.47171667437137343, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09833387], dtype=float32), 0.9289796]. 
=============================================
[2019-04-24 09:52:49,046] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-8.3, 77.0, 0.0, 0.0, 19.0, 20.04409654330434, -0.8849241490061809, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3295200.0000, 
sim time next is 3296400.0000, 
raw observation next is [-8.600000000000001, 77.0, 0.0, 0.0, 19.0, 20.01903167650788, -0.7008402412064463, 0.0, 1.0, 60.0, 89.12398988473612], 
processed observation next is [1.0, 0.13043478260869565, 0.22437673130193903, 0.77, 0.0, 0.0, 0.08333333333333333, 0.16825263970898993, 0.2663865862645179, 0.0, 1.0, 0.9, 0.8912398988473612], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0618343], dtype=float32), 1.6240662]. 
=============================================
[2019-04-24 09:52:50,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.57243848e-01 8.97321329e-02 1.00926656e-16 1.12356750e-15
 3.79837102e-15 5.64385464e-17 1.69805542e-16 2.74963008e-17
 1.30486483e-13 2.53023982e-01 1.28795965e-16], sum to 1.0000
[2019-04-24 09:52:50,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8290
[2019-04-24 09:52:50,515] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.0, 94.66666666666666, 0.0, 0.0, 19.0, 20.16301839800855, -0.7841004020834306, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3220800.0000, 
sim time next is 3222000.0000, 
raw observation next is [-3.0, 92.0, 0.0, 0.0, 19.0, 20.41765618034426, -0.4984481950717826, 0.0, 1.0, 60.0, 96.61277298497494], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.92, 0.0, 0.0, 0.08333333333333333, 0.20147134836202163, 0.33385060164273916, 0.0, 1.0, 0.9, 0.9661277298497494], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36929816], dtype=float32), 1.0692564]. 
=============================================
[2019-04-24 09:52:54,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0980132e-01 6.1866615e-02 7.8962995e-15 3.0629908e-15 1.2792293e-14
 1.1140150e-15 1.1870758e-15 9.2359619e-17 5.4770451e-13 2.2833210e-01
 3.3733667e-15], sum to 1.0000
[2019-04-24 09:52:54,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0643
[2019-04-24 09:52:54,548] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.333333333333334, 28.33333333333334, 0.0, 0.0, 19.0, 21.09010213766005, -0.7893835282166658, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3644400.0000, 
sim time next is 3645600.0000, 
raw observation next is [8.666666666666668, 27.66666666666667, 0.0, 0.0, 19.0, 20.62077532264365, -0.8908451748081753, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.7026777469990768, 0.2766666666666667, 0.0, 0.0, 0.08333333333333333, 0.2183979435536374, 0.2030516083972749, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21905819], dtype=float32), 0.8584267]. 
=============================================
[2019-04-24 09:52:56,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1762067e-01 7.3791802e-02 1.2307000e-13 6.4062481e-13 5.2310012e-13
 1.4214231e-13 1.1535937e-13 2.4279029e-14 4.4866916e-11 2.0858753e-01
 2.0469351e-13], sum to 1.0000
[2019-04-24 09:52:56,579] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9239
[2019-04-24 09:52:56,671] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.0, 54.0, 112.5, 787.0, 19.0, 18.85618694131661, -1.037837176418228, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3582000.0000, 
sim time next is 3583200.0000, 
raw observation next is [-3.666666666666667, 54.33333333333334, 113.5, 806.3333333333333, 19.0, 19.45156291688927, -0.6877974727699004, 0.0, 1.0, 60.0, 94.85072585716125], 
processed observation next is [0.0, 0.4782608695652174, 0.3610341643582641, 0.5433333333333334, 0.37833333333333335, 0.8909760589318599, 0.08333333333333333, 0.12096357640743911, 0.2707341757433665, 0.0, 1.0, 0.9, 0.9485072585716126], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10449465], dtype=float32), -1.1807803]. 
=============================================
[2019-04-24 09:52:58,406] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.35395253e-01 7.84009472e-02 3.74740739e-13 2.81920619e-13
 6.92104414e-13 6.14628045e-14 1.34840679e-13 1.34151045e-14
 8.32230812e-11 1.86203733e-01 2.62883682e-13], sum to 1.0000
[2019-04-24 09:52:58,409] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9200
[2019-04-24 09:52:58,486] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.333333333333333, 53.33333333333334, 0.0, 0.0, 19.0, 19.75841185519567, -0.9686487344859843, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3622800.0000, 
sim time next is 3624000.0000, 
raw observation next is [-2.666666666666667, 56.66666666666667, 0.0, 0.0, 19.0, 20.09269084938027, -0.6850521195545275, 0.0, 1.0, 60.0, 92.05256196796287], 
processed observation next is [0.0, 0.9565217391304348, 0.38873499538319484, 0.5666666666666668, 0.0, 0.0, 0.08333333333333333, 0.17439090411502237, 0.27164929348182415, 0.0, 1.0, 0.9, 0.9205256196796288], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37541702], dtype=float32), -0.4617904]. 
=============================================
[2019-04-24 09:53:01,066] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9871005e-01 9.8142952e-02 6.2225941e-15 2.2343038e-14 4.0787933e-14
 2.2134085e-15 1.3949047e-14 2.6441762e-15 6.6555498e-12 1.0314693e-01
 1.4108144e-14], sum to 1.0000
[2019-04-24 09:53:01,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5262
[2019-04-24 09:53:01,082] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 20.36591927001483, -0.9062561447184353, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3723600.0000, 
sim time next is 3724800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 19.76401918969145, -1.006047038236088, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.14700159914095412, 0.16465098725463734, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8165395], dtype=float32), -0.176629]. 
=============================================
[2019-04-24 09:53:03,172] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.41304958e-01 8.68158638e-02 1.13281136e-13 4.33784085e-13
 4.52518665e-13 1.43908282e-13 1.57691893e-13 4.94581691e-15
 2.54661240e-11 7.18791708e-02 1.11632342e-13], sum to 1.0000
[2019-04-24 09:53:03,198] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0993
[2019-04-24 09:53:03,248] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 70.0, 0.0, 0.0, 19.0, 20.287247540264, -0.8800305165766297, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3567600.0000, 
sim time next is 3568800.0000, 
raw observation next is [-6.333333333333333, 70.0, 0.0, 0.0, 19.0, 19.5722621029001, -1.022243805840924, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.28716528162511545, 0.7, 0.0, 0.0, 0.08333333333333333, 0.13102184190834176, 0.159252064719692, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80220854], dtype=float32), 1.5282559]. 
=============================================
[2019-04-24 09:53:06,150] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.6640289e-01 9.4606644e-03 2.0142555e-16 2.4487972e-15 3.1337206e-15
 9.2208430e-17 2.5072596e-16 7.2392346e-17 2.5353284e-13 2.4136454e-02
 8.7384863e-16], sum to 1.0000
[2019-04-24 09:53:06,152] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1806
[2019-04-24 09:53:06,165] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 59.0, 12.5, 137.5, 19.0, 21.01744114538209, -0.6384903085589526, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3692400.0000, 
sim time next is 3693600.0000, 
raw observation next is [4.0, 59.0, 0.0, 0.0, 19.0, 20.90352411538207, -0.6731922614486631, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5734072022160666, 0.59, 0.0, 0.0, 0.08333333333333333, 0.24196034294850577, 0.2756025795171123, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5393727], dtype=float32), -1.0382239]. 
=============================================
[2019-04-24 09:53:06,581] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.2483560e-01 4.1790009e-02 1.1613852e-14 4.0435242e-14 7.1155945e-14
 3.5593688e-15 9.6922126e-15 4.1485488e-15 3.5932002e-12 1.3337433e-01
 1.4428552e-14], sum to 1.0000
[2019-04-24 09:53:06,583] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7393
[2019-04-24 09:53:06,599] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 19.35590118198402, -1.029767140896798, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3711600.0000, 
sim time next is 3712800.0000, 
raw observation next is [-3.0, 67.0, 0.0, 0.0, 19.0, 19.18988461553485, -1.065844593994305, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.3795013850415513, 0.67, 0.0, 0.0, 0.08333333333333333, 0.0991570512945709, 0.14471846866856497, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5393727], dtype=float32), -1.0382239]. 
=============================================
[2019-04-24 09:53:07,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2745242e-01 1.7190766e-01 9.4499190e-14 1.9506154e-13 6.1153215e-13
 3.2512177e-14 1.1608355e-13 2.2225618e-14 8.2448000e-11 5.0063992e-01
 2.4225093e-14], sum to 1.0000
[2019-04-24 09:53:07,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8079
[2019-04-24 09:53:07,395] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.333333333333334, 62.0, 5.0, 135.8333333333333, 22.5, 18.64978178097819, -1.195723087131315, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3914400.0000, 
sim time next is 3915600.0000, 
raw observation next is [-7.666666666666666, 60.0, 20.16666666666666, 213.5, 22.5, 19.52132029179074, -0.6962816602942331, 1.0, 1.0, 60.0, 130.66711777545706], 
processed observation next is [1.0, 0.30434782608695654, 0.25023084025854114, 0.6, 0.0672222222222222, 0.23591160220994475, 0.375, 0.1267766909825617, 0.26790611323525565, 1.0, 1.0, 0.9, 1.3066711777545705], 
reward next is 0.9814, 
noisyNet noise sample is [array([-0.43276006], dtype=float32), 0.66122395]. 
=============================================
[2019-04-24 09:53:14,609] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.5071230e-01 3.2280326e-02 8.3471683e-15 5.1903560e-14 1.8538582e-14
 1.6938389e-15 1.8927881e-15 1.2256520e-15 8.5868404e-12 1.1700736e-01
 1.3044709e-15], sum to 1.0000
[2019-04-24 09:53:14,611] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7762
[2019-04-24 09:53:14,633] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 49.0, 116.5, 792.5, 22.5, 22.58008802790476, -0.3619951457048787, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3927600.0000, 
sim time next is 3928800.0000, 
raw observation next is [-6.0, 49.0, 118.8333333333333, 804.1666666666666, 22.5, 22.45380350608701, -0.386220918659529, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.296398891966759, 0.49, 0.396111111111111, 0.8885819521178637, 0.375, 0.37115029217391743, 0.37125969378015694, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.446501], dtype=float32), -1.807838]. 
=============================================
[2019-04-24 09:53:14,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0369445e-01 1.5728682e-02 1.7853666e-14 8.1092834e-14 5.1006179e-14
 2.3320805e-15 3.6673803e-15 1.8711292e-15 1.0633187e-11 8.0576830e-02
 6.6592100e-15], sum to 1.0000
[2019-04-24 09:53:14,660] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2253
[2019-04-24 09:53:14,680] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 29.0, 116.0, 835.5, 22.5, 22.22964424809665, -0.4010173951707698, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4021200.0000, 
sim time next is 4022400.0000, 
raw observation next is [-3.666666666666667, 28.0, 114.6666666666667, 831.8333333333334, 22.5, 22.34428889342876, -0.3755877496565027, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3610341643582641, 0.28, 0.38222222222222235, 0.9191528545119706, 0.375, 0.36202407445239676, 0.3748040834478324, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0839121], dtype=float32), -0.40532666]. 
=============================================
[2019-04-24 09:53:14,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.10515392e-01 2.83270419e-01 1.88723261e-14 6.58034621e-14
 1.69038286e-13 1.10388493e-14 4.72766146e-15 1.83282048e-15
 6.87206932e-12 2.06214145e-01 1.06969335e-14], sum to 1.0000
[2019-04-24 09:53:14,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1852
[2019-04-24 09:53:14,759] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 36.66666666666666, 94.0, 504.0, 22.5, 22.96086506344229, -0.4290166718624615, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4092000.0000, 
sim time next is 4093200.0000, 
raw observation next is [-3.0, 38.0, 98.0, 574.0, 22.5, 22.57737524856968, -0.5132826271086837, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3795013850415513, 0.38, 0.32666666666666666, 0.6342541436464089, 0.375, 0.3814479373808067, 0.3289057909637721, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9956, 
noisyNet noise sample is [array([2.2583587], dtype=float32), 1.9221519]. 
=============================================
[2019-04-24 09:53:16,363] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9666998e-01 1.5364086e-02 8.6564377e-18 4.9208650e-17 3.5494538e-17
 1.0195102e-18 2.0841568e-18 3.4179940e-19 6.3819440e-14 8.7965935e-02
 1.6139681e-18], sum to 1.0000
[2019-04-24 09:53:16,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3753
[2019-04-24 09:53:16,417] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 122.0, 0.0, 22.5, 23.42774779304917, -0.1491357164933352, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4449600.0000, 
sim time next is 4450800.0000, 
raw observation next is [0.6666666666666667, 88.0, 108.6666666666667, 0.0, 22.5, 22.9457434137695, -0.2315755359312631, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4810710987996307, 0.88, 0.36222222222222233, 0.0, 0.375, 0.4121452844807916, 0.422808154689579, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49398592], dtype=float32), 1.0768924]. 
=============================================
[2019-04-24 09:53:19,022] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.3278009e-01 8.6292084e-03 4.9616382e-15 7.1043093e-14 6.5865600e-14
 1.1711248e-15 1.4055830e-15 7.1184755e-16 1.8998723e-11 5.8590595e-02
 8.3582975e-15], sum to 1.0000
[2019-04-24 09:53:19,024] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2921
[2019-04-24 09:53:19,049] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.333333333333333, 34.33333333333334, 118.1666666666667, 836.8333333333334, 22.5, 23.95035960218787, -0.2484768692158774, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4018800.0000, 
sim time next is 4020000.0000, 
raw observation next is [-4.666666666666666, 31.66666666666666, 117.3333333333333, 839.1666666666667, 22.5, 23.095918364139, -0.2731642890554269, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.33333333333333337, 0.3166666666666666, 0.391111111111111, 0.9272559852670351, 0.375, 0.4246598636782499, 0.40894523698152435, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.537351], dtype=float32), 0.62762433]. 
=============================================
[2019-04-24 09:53:19,061] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[66.2873  ]
 [66.25144 ]
 [65.15715 ]
 [65.23577 ]
 [65.33148 ]
 [65.39383 ]
 [64.39122 ]
 [64.83503 ]
 [65.009964]
 [64.11492 ]
 [62.973534]
 [61.52763 ]
 [61.02229 ]
 [59.40608 ]
 [58.77201 ]
 [57.630085]
 [56.169674]
 [56.678635]
 [57.29812 ]
 [56.747505]
 [57.349422]
 [57.945644]
 [58.45239 ]
 [57.680447]
 [58.092403]], R is [[66.76087189]
 [67.09326172]
 [66.42233276]
 [66.75811005]
 [67.0905304 ]
 [67.41962433]
 [66.74542999]
 [67.07798004]
 [67.40720367]
 [66.73313141]
 [66.06580353]
 [65.9500885 ]
 [65.29058838]
 [65.56206512]
 [64.90644836]
 [65.25738525]
 [65.60481262]
 [64.94876862]
 [65.29927826]
 [65.64628601]
 [64.98982239]
 [64.77733612]
 [65.12956238]
 [65.30753326]
 [64.65445709]].
[2019-04-24 09:53:23,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7590170e-01 1.9177521e-02 7.8257184e-18 4.1165259e-17 1.3597466e-16
 1.4216019e-18 7.8709263e-18 1.3318542e-18 1.4498094e-14 1.0492077e-01
 8.2487543e-18], sum to 1.0000
[2019-04-24 09:53:23,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2976
[2019-04-24 09:53:23,716] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.966666666666667, 70.66666666666667, 0.0, 0.0, 19.0, 21.12577562676593, -0.7765887502074089, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4332000.0000, 
sim time next is 4333200.0000, 
raw observation next is [3.933333333333333, 70.33333333333333, 0.0, 0.0, 19.0, 20.5892655751601, -0.8871074440802115, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5715604801477379, 0.7033333333333333, 0.0, 0.0, 0.08333333333333333, 0.21577213126334152, 0.2042975186399295, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.652433], dtype=float32), -1.6056793]. 
=============================================
[2019-04-24 09:53:24,990] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.8903224e-01 1.5027801e-02 2.0035625e-17 1.6659747e-16 1.3799146e-16
 1.5933808e-17 2.8150402e-17 5.7557579e-19 1.8510311e-14 9.5939964e-02
 2.2586793e-18], sum to 1.0000
[2019-04-24 09:53:24,991] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8181
[2019-04-24 09:53:25,013] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 68.0, 0.0, 0.0, 19.0, 20.78238513068967, -0.6389045862113668, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4428000.0000, 
sim time next is 4429200.0000, 
raw observation next is [2.666666666666667, 72.0, 0.0, 0.0, 19.0, 20.7011606465002, -0.6643685232403943, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.5364727608494922, 0.72, 0.0, 0.0, 0.08333333333333333, 0.22509672054168325, 0.27854382558653523, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5658331], dtype=float32), -0.054512676]. 
=============================================
[2019-04-24 09:53:28,846] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.4296879e-01 7.9351421e-03 9.2395338e-18 9.5665304e-17 9.6531541e-17
 8.9478495e-19 1.9932561e-18 2.8497017e-18 4.2599394e-14 4.9096052e-02
 3.3871652e-18], sum to 1.0000
[2019-04-24 09:53:28,850] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7095
[2019-04-24 09:53:28,865] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 59.66666666666667, 204.6666666666667, 15.0, 22.5, 24.1015522203848, -0.1142483518229374, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4530000.0000, 
sim time next is 4531200.0000, 
raw observation next is [1.666666666666667, 58.33333333333334, 203.8333333333333, 15.0, 22.5, 23.8011850437457, -0.172151278742036, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5087719298245615, 0.5833333333333335, 0.6794444444444443, 0.016574585635359115, 0.375, 0.4834320869788084, 0.4426162404193213, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4358617], dtype=float32), -0.8989481]. 
=============================================
[2019-04-24 09:53:28,903] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8378998e-01 8.3001498e-03 2.9084283e-19 1.2391224e-17 2.5150602e-17
 1.2298536e-19 2.1651233e-19 1.5329080e-20 8.8650140e-16 7.9098754e-03
 1.0973196e-18], sum to 1.0000
[2019-04-24 09:53:28,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0077
[2019-04-24 09:53:28,929] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.266666666666667, 67.33333333333334, 0.0, 0.0, 19.0, 22.1662139921047, -0.1241364792297931, 0.0, 1.0, 60.0, 96.85549217747018], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4422000.0000, 
sim time next is 4423200.0000, 
raw observation next is [4.033333333333333, 67.66666666666666, 0.0, 0.0, 19.0, 23.1158346487148, -0.2189987084565534, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5743305632502309, 0.6766666666666665, 0.0, 0.0, 0.08333333333333333, 0.42631955405956656, 0.42700043051448217, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.67856604], dtype=float32), 1.2400845]. 
=============================================
[2019-04-24 09:53:29,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5539403e-01 1.1308576e-02 1.6617093e-15 6.7905450e-15 1.2315898e-14
 1.0800911e-15 2.3553231e-15 2.2083789e-16 2.3676592e-12 3.3297367e-02
 2.6938479e-15], sum to 1.0000
[2019-04-24 09:53:29,564] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4632
[2019-04-24 09:53:29,599] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 67.5, 252.0, 19.0, 20.26772045355043, -0.6544809819902331, 0.0, 1.0, 20.0, 71.93791823475057], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4899600.0000, 
sim time next is 4900800.0000, 
raw observation next is [2.666666666666667, 44.66666666666667, 44.5, 208.6666666666667, 19.0, 20.95660579448779, -0.7153720113101668, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5364727608494922, 0.4466666666666667, 0.14833333333333334, 0.23057090239410685, 0.08333333333333333, 0.24638381620731575, 0.26154266289661104, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5065284], dtype=float32), -0.2248698]. 
=============================================
[2019-04-24 09:53:31,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2651445e-01 1.3310353e-02 7.5403832e-17 7.3656291e-16 6.9092663e-16
 2.9382938e-17 2.1554166e-17 1.0181196e-17 1.1838158e-13 6.0175218e-02
 3.7951457e-17], sum to 1.0000
[2019-04-24 09:53:31,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1756
[2019-04-24 09:53:31,939] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 55.33333333333334, 0.0, 0.0, 19.0, 21.48040089562625, -0.4831177193000772, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4663200.0000, 
sim time next is 4664400.0000, 
raw observation next is [2.0, 53.66666666666667, 0.0, 0.0, 19.0, 21.3832666668289, -0.515816188214737, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.518005540166205, 0.5366666666666667, 0.0, 0.0, 0.08333333333333333, 0.2819388889024082, 0.32806127059508766, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9452476], dtype=float32), 1.4230179]. 
=============================================
[2019-04-24 09:53:33,687] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.44231606e-01 4.42562997e-02 3.98274468e-16 1.22097777e-15
 1.42437802e-15 2.21110539e-17 1.11525493e-16 7.70818428e-18
 9.10707802e-14 1.11511976e-01 8.31523178e-17], sum to 1.0000
[2019-04-24 09:53:33,688] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7237
[2019-04-24 09:53:33,769] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 73.0, 55.5, 33.0, 22.5, 21.94930618504063, -0.578077104281948, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4521600.0000, 
sim time next is 4522800.0000, 
raw observation next is [-0.5333333333333334, 72.66666666666667, 92.5, 55.0, 22.5, 21.32021270810696, -0.6347989047354367, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44783010156971376, 0.7266666666666667, 0.30833333333333335, 0.06077348066298342, 0.375, 0.2766843923422468, 0.2884003650881878, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.5457, 
noisyNet noise sample is [array([0.63157463], dtype=float32), 0.17785975]. 
=============================================
[2019-04-24 09:53:34,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2572254e-01 6.4357687e-03 1.4821409e-16 5.6030446e-16 5.9083402e-16
 1.0532101e-17 5.0116441e-17 1.0143432e-17 3.9798265e-13 6.7841694e-02
 2.5023676e-17], sum to 1.0000
[2019-04-24 09:53:34,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1970
[2019-04-24 09:53:34,163] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 68.5, 48.0, 22.5, 22.56212861823057, -0.302873747824325, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4554000.0000, 
sim time next is 4555200.0000, 
raw observation next is [2.0, 52.0, 41.5, 34.66666666666666, 22.5, 22.85514781456962, -0.2958711822513121, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.52, 0.13833333333333334, 0.03830570902394106, 0.375, 0.40459565121413493, 0.401376272582896, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17344052], dtype=float32), 0.25691485]. 
=============================================
[2019-04-24 09:53:35,744] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:53:35,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:53:36,747] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:53:36,748] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:53:36,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run4
[2019-04-24 09:53:38,483] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-24 09:53:38,493] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:53:38,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:53:38,495] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:53:38,494] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:53:38,495] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:53:38,497] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run5
[2019-04-24 09:53:38,497] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:53:38,518] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run5
[2019-04-24 09:53:38,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run5
[2019-04-24 09:54:12,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([-0.2553295], dtype=float32), 0.62038296]
[2019-04-24 09:54:12,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [3.3, 83.0, 0.0, 0.0, 19.0, 21.29868037634094, -0.4395346623419192, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:54:12,954] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 09:54:12,955] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [9.1728401e-01 1.1809675e-02 1.5532128e-17 8.3509422e-17 1.5417616e-16
 9.4487840e-18 1.0034533e-17 1.1161408e-18 4.4763089e-14 7.0906378e-02
 2.5128943e-17], sampled 0.7617462600508125
[2019-04-24 09:54:23,890] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([-0.2553295], dtype=float32), 0.62038296]
[2019-04-24 09:54:23,891] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-5.157326305666667, 83.61545167, 0.0, 0.0, 19.0, 21.31814020973395, -0.6914781423377493, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:54:23,891] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 09:54:23,891] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [8.7382162e-01 1.1172671e-02 1.9809485e-15 9.0327449e-15 1.2522916e-14
 6.2454693e-16 4.3915384e-16 1.4516546e-16 1.0514253e-12 1.1500565e-01
 1.2027441e-15], sampled 0.952710580979838
[2019-04-24 09:55:13,020] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([-0.2553295], dtype=float32), 0.62038296]
[2019-04-24 09:55:13,020] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [14.3, 76.0, 0.0, 0.0, 19.0, 26.06638444112926, 0.7443623224233419, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 09:55:13,020] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 09:55:13,021] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [9.9735224e-01 5.8385712e-04 6.8042993e-19 2.5555942e-17 7.3336159e-17
 2.0632995e-18 1.7306722e-18 1.2912580e-19 8.1056987e-15 2.0638644e-03
 1.4350849e-17], sampled 0.9170144984771308
[2019-04-24 09:55:18,400] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3374.0507 58812.2013 -315.5050
[2019-04-24 09:55:18,450] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:18,450] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:18,450] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:18,450] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:18,450] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:18,623] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:18,623] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:18,623] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:18,623] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:18,623] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:30,663] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3140.8174 75254.7697 -531.4232
[2019-04-24 09:55:30,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:30,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:30,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:30,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:30,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:30,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:30,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:30,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:30,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:30,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:43,778] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3086.1502 77497.7768 -596.9446
[2019-04-24 09:55:43,811] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:43,811] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:43,811] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:43,811] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:43,811] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:43,986] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:43,986] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:43,986] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:43,986] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:43,986] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 09:55:44,818] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 200000, evaluation results [200000.0, 3140.8173987125706, 75254.769719885, -531.4231991427636, 3374.0507148221827, 58812.20132821116, -315.50496946496855, 3086.1502275056964, 77497.77683677254, -596.9446030686535]
[2019-04-24 09:55:45,735] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.1600091e-01 4.2352386e-02 2.1307463e-14 8.4183332e-14 4.3425048e-14
 3.6066331e-14 1.8959132e-14 3.4548621e-15 1.7510361e-11 2.4164675e-01
 5.7131464e-14], sum to 1.0000
[2019-04-24 09:55:45,765] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2853
[2019-04-24 09:55:45,866] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.266666666666667, 45.66666666666667, 279.5, 389.6666666666666, 19.0, 18.14289707145553, -1.250994051409551, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4884000.0000, 
sim time next is 4885200.0000, 
raw observation next is [1.4, 45.0, 276.5, 389.0, 19.0, 18.14218301556068, -1.247377231768704, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.5013850415512465, 0.45, 0.9216666666666666, 0.4298342541436464, 0.08333333333333333, 0.011848584630056594, 0.08420758941043201, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.833536], dtype=float32), 0.42704946]. 
=============================================
[2019-04-24 09:55:47,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:47,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8100293e-01 1.9776050e-03 5.5245652e-18 5.2353267e-17 5.7324053e-17
 6.5897509e-19 8.9303815e-19 6.2844349e-19 4.2786158e-14 1.7019391e-02
 2.3717212e-18], sum to 1.0000
[2019-04-24 09:55:47,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3269
[2019-04-24 09:55:47,411] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 22.5, 22.72392046646785, 0.0007451506965290428, 1.0, 1.0, 60.0, 121.3811991535066], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4734000.0000, 
sim time next is 4735200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 22.5, 24.04993540760358, -0.07052190285100486, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4349030470914128, 0.78, 0.0, 0.0, 0.375, 0.504161283966965, 0.476492699049665, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.521791], dtype=float32), -0.5352213]. 
=============================================
[2019-04-24 09:55:47,434] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:55:48,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:55:48,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:55:48,242] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run4
[2019-04-24 09:55:48,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:49,194] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:55:49,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:55:49,825] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:55:49,827] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run4
[2019-04-24 09:55:55,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2886024e-01 4.4563595e-02 8.7566478e-15 2.1313717e-14 8.7593906e-14
 7.0970320e-15 9.7809766e-15 9.7054104e-16 1.1493866e-12 3.2657617e-01
 5.2035424e-15], sum to 1.0000
[2019-04-24 09:55:55,079] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7032
[2019-04-24 09:55:55,144] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.3333333333333334, 42.0, 0.0, 0.0, 19.0, 19.35465471454246, -1.08496242536337, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4927200.0000, 
sim time next is 4928400.0000, 
raw observation next is [0.0, 43.0, 0.0, 0.0, 19.0, 19.93650829678939, -0.7720840010293109, 0.0, 1.0, 60.0, 93.62704040284265], 
processed observation next is [1.0, 0.043478260869565216, 0.46260387811634357, 0.43, 0.0, 0.0, 0.08333333333333333, 0.16137569139911592, 0.24263866632356304, 0.0, 1.0, 0.9, 0.9362704040284265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0060687], dtype=float32), -0.34358263]. 
=============================================
[2019-04-24 09:55:55,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:55,847] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:55:56,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:56,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:55:56,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:55:56,623] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run4
[2019-04-24 09:55:56,743] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:55:57,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:55:57,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:55:57,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:55:57,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run4
[2019-04-24 09:55:57,556] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:55:58,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:55:58,346] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:55:58,348] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run4
[2019-04-24 09:56:00,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:00,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4102210e-01 9.9006044e-03 4.1012408e-19 6.3773557e-18 9.9925775e-18
 3.7084427e-19 1.1043821e-18 7.0530524e-20 6.8489612e-16 4.9077235e-02
 7.3522537e-19], sum to 1.0000
[2019-04-24 09:56:00,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9407
[2019-04-24 09:56:00,809] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.3, 86.0, 91.5, 0.0, 19.0, 21.37336013706448, -0.5704349320987127, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 46800.0000, 
sim time next is 48000.0000, 
raw observation next is [8.100000000000001, 86.0, 88.5, 0.0, 19.0, 20.87637446050884, -0.6386902057165518, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6869806094182827, 0.86, 0.295, 0.0, 0.08333333333333333, 0.23969787170906987, 0.2871032647611494, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06904568], dtype=float32), 0.56664765]. 
=============================================
[2019-04-24 09:56:00,831] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:01,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:01,249] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:01,362] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:01,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:01,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:01,508] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run4
[2019-04-24 09:56:01,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:02,047] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:02,047] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:02,049] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run4
[2019-04-24 09:56:02,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:02,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:02,375] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run4
[2019-04-24 09:56:03,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:03,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:04,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:04,248] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:04,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:04,764] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:04,766] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run4
[2019-04-24 09:56:04,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:04,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:04,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run4
[2019-04-24 09:56:05,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:05,837] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:05,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:06,296] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:06,365] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:06,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:06,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:06,554] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run4
[2019-04-24 09:56:06,613] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:06,775] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:06,838] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:06,838] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:06,840] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run4
[2019-04-24 09:56:06,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:07,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:07,366] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:07,370] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run4
[2019-04-24 09:56:07,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:07,614] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:07,616] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run4
[2019-04-24 09:56:09,153] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_2 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 09:56:09,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_2 ERROR:Aborted (core dumped)

[2019-04-24 09:56:10,154] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 09:56:10,154] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:56:10,156] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run4
[2019-04-24 09:56:24,368] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2628139e-01 7.0249629e-03 1.7424847e-15 9.8929222e-15 2.3671535e-14
 2.5629346e-16 8.6626266e-16 8.0356428e-17 7.8403262e-13 6.6693656e-02
 6.7985697e-16], sum to 1.0000
[2019-04-24 09:56:24,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2664
[2019-04-24 09:56:24,472] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 19.0, 19.61690199333853, -0.8324764336755562, 0.0, 1.0, 60.0, 103.36904953723851], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 262800.0000, 
sim time next is 264000.0000, 
raw observation next is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 20.44883630615704, -0.9545206575049517, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.27146814404432135, 0.6833333333333335, 0.0, 0.0, 0.08333333333333333, 0.20406969217975343, 0.18182644749834942, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16962264], dtype=float32), 0.49661306]. 
=============================================
[2019-04-24 09:56:28,020] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.96843129e-01 4.11871262e-02 1.36937115e-14 3.69786667e-14
 6.31395096e-14 2.04293399e-15 4.34440319e-15 1.25405261e-15
 2.89781176e-12 4.61969763e-01 1.34971575e-14], sum to 1.0000
[2019-04-24 09:56:28,028] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5653
[2019-04-24 09:56:28,303] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.3, 68.0, 18.5, 4.5, 22.5, 21.08020912306813, -0.7887340217032387, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 115200.0000, 
sim time next is 116400.0000, 
raw observation next is [-7.466666666666667, 65.66666666666667, 30.83333333333334, 7.5, 22.5, 21.01080821006747, -0.5336749948726499, 1.0, 1.0, 60.0, 104.63021057584852], 
processed observation next is [1.0, 0.34782608695652173, 0.25577100646352724, 0.6566666666666667, 0.1027777777777778, 0.008287292817679558, 0.375, 0.25090068417228917, 0.32210833504245, 1.0, 1.0, 0.9, 1.0463021057584851], 
reward next is 0.1684, 
noisyNet noise sample is [array([0.9673917], dtype=float32), 1.7496617]. 
=============================================
[2019-04-24 09:56:38,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5359839e-01 2.7957419e-02 1.4337266e-16 2.6460351e-16 6.4980355e-16
 1.0302703e-16 8.2769704e-17 1.3469738e-17 8.4740585e-14 2.1844421e-01
 4.9089967e-17], sum to 1.0000
[2019-04-24 09:56:38,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1060
[2019-04-24 09:56:38,142] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.966666666666667, 84.0, 0.0, 0.0, 19.0, 20.6159484445342, -0.8273771154298903, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 535200.0000, 
sim time next is 536400.0000, 
raw observation next is [1.6, 85.0, 0.0, 0.0, 19.0, 20.0820720551495, -0.9064917726306744, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.5069252077562327, 0.85, 0.0, 0.0, 0.08333333333333333, 0.1735060045957916, 0.19783607578977522, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.35652286], dtype=float32), 0.1435975]. 
=============================================
[2019-04-24 09:56:47,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0228176e-01 8.5638156e-03 2.4983483e-17 1.6083492e-16 7.7360730e-17
 1.5578236e-18 6.6294154e-18 2.8246446e-18 5.8878514e-14 8.9154407e-02
 1.1377956e-17], sum to 1.0000
[2019-04-24 09:56:47,746] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5349
[2019-04-24 09:56:47,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.60336089e-01 1.27187222e-02 1.27843535e-17 1.23560031e-16
 3.48964260e-16 1.97807124e-17 1.54879031e-17 1.93642464e-18
 4.38972148e-14 2.69452110e-02 3.16209443e-17], sum to 1.0000
[2019-04-24 09:56:47,753] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3421
[2019-04-24 09:56:47,773] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 89.66666666666667, 125.6666666666667, 103.1666666666667, 19.0, 21.16455465202304, -0.5011627604582097, 0.0, 1.0, 60.0, 80.09112088208704], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 552000.0000, 
sim time next is 553200.0000, 
raw observation next is [-0.4, 88.33333333333334, 132.8333333333333, 109.3333333333333, 19.0, 21.46508196215386, -0.6316199826506771, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.45152354570637127, 0.8833333333333334, 0.4427777777777776, 0.12081031307550641, 0.08333333333333333, 0.28875683017948833, 0.28946000578310765, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1803443], dtype=float32), -0.7626619]. 
=============================================
[2019-04-24 09:56:47,788] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 84.0, 80.33333333333334, 0.0, 22.5, 23.2140384808167, -0.1342191075530459, 1.0, 1.0, 60.0, 84.91269550587208], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 902400.0000, 
sim time next is 903600.0000, 
raw observation next is [1.1, 84.0, 87.0, 0.0, 22.5, 23.87642558747532, -0.2164805692975626, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.49307479224376743, 0.84, 0.29, 0.0, 0.375, 0.48970213228961007, 0.4278398102341458, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38555592], dtype=float32), 0.72184896]. 
=============================================
[2019-04-24 09:56:48,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2959640e-01 4.3059621e-02 3.7854873e-13 5.8563831e-13 4.3995921e-13
 1.0739441e-14 2.6846542e-14 5.2920901e-14 1.3284733e-10 6.2734401e-01
 5.5307877e-14], sum to 1.0000
[2019-04-24 09:56:48,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4003
[2019-04-24 09:56:48,403] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.766666666666667, 30.66666666666667, 92.0, 0.0, 22.5, 23.50734195206935, -0.4259478982561111, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 469200.0000, 
sim time next is 470400.0000, 
raw observation next is [-3.033333333333333, 29.33333333333333, 102.0, 0.0, 22.5, 23.20632686738579, -0.2776262585687129, 1.0, 1.0, 60.0, 78.64004586035031], 
processed observation next is [1.0, 0.43478260869565216, 0.37857802400738694, 0.2933333333333333, 0.34, 0.0, 0.375, 0.4338605722821492, 0.40745791381042906, 1.0, 1.0, 0.9, 0.7864004586035032], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03154569], dtype=float32), -1.1954868]. 
=============================================
[2019-04-24 09:56:51,938] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.94688797e-01 5.40121198e-02 2.73201278e-14 1.69048708e-13
 1.13683944e-13 2.96566259e-14 1.49480546e-14 3.01416230e-15
 5.87116120e-12 2.51299143e-01 2.85776719e-14], sum to 1.0000
[2019-04-24 09:56:51,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9116
[2019-04-24 09:56:52,042] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.166666666666667, 63.66666666666667, 90.83333333333334, 31.66666666666667, 19.0, 20.76110709828919, -0.8987216692415837, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 645600.0000, 
sim time next is 646800.0000, 
raw observation next is [-2.933333333333334, 62.33333333333333, 92.83333333333334, 48.33333333333333, 19.0, 20.41412897114528, -0.753255814068393, 0.0, 1.0, 60.0, 83.75952524518925], 
processed observation next is [0.0, 0.4782608695652174, 0.38134810710988, 0.6233333333333333, 0.30944444444444447, 0.05340699815837937, 0.08333333333333333, 0.20117741426210678, 0.248914728643869, 0.0, 1.0, 0.9, 0.8375952524518925], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.774065], dtype=float32), 1.1513661]. 
=============================================
[2019-04-24 09:56:52,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1515440e-01 1.2678528e-02 8.0777887e-14 5.0742956e-12 6.7545541e-13
 3.4963504e-14 8.2774587e-14 3.8362559e-14 2.3292049e-10 7.2167024e-02
 2.9156338e-13], sum to 1.0000
[2019-04-24 09:56:52,436] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4960
[2019-04-24 09:56:52,513] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 51.0, 56.5, 896.0, 22.5, 23.06857057284572, -0.3774975569464711, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 392400.0000, 
sim time next is 393600.0000, 
raw observation next is [-11.3, 49.33333333333334, 55.5, 890.0, 22.5, 22.53268585302055, -0.467232114796496, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.14958448753462603, 0.4933333333333334, 0.185, 0.9834254143646409, 0.375, 0.37772382108504576, 0.34425596173450135, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8052685], dtype=float32), 1.0636348]. 
=============================================
[2019-04-24 09:57:10,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4239446e-01 2.7626801e-02 6.5787333e-18 4.4775179e-18 1.9103776e-17
 1.7990333e-18 9.1758132e-19 1.8278162e-19 1.1329646e-14 4.2997873e-01
 2.2916170e-18], sum to 1.0000
[2019-04-24 09:57:10,090] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0645
[2019-04-24 09:57:10,127] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 19.0, 21.43493284886841, -0.5274314886841022, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 946800.0000, 
sim time next is 948000.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 19.0, 21.15937459392019, -0.5737380203433382, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.6011080332409973, 0.96, 0.0, 0.0, 0.08333333333333333, 0.26328121616001593, 0.30875399321888725, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6915791], dtype=float32), 1.3139955]. 
=============================================
[2019-04-24 09:57:10,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1309237e-01 1.2645963e-02 3.4325661e-15 8.5587116e-14 8.6618619e-14
 7.8881510e-16 3.1255181e-15 1.1268049e-15 5.6397205e-12 7.4261606e-02
 7.6275181e-15], sum to 1.0000
[2019-04-24 09:57:10,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2238
[2019-04-24 09:57:10,835] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 71.0, 0.0, 0.0, 19.0, 20.70359740145014, -0.5391675111846536, 0.0, 1.0, 60.0, 94.8584850727668], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 778800.0000, 
sim time next is 780000.0000, 
raw observation next is [-7.3, 71.0, 0.0, 0.0, 19.0, 21.41342706785447, -0.6443449681060333, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.26038781163434904, 0.71, 0.0, 0.0, 0.08333333333333333, 0.28445225565453924, 0.28521834396465556, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.28976676], dtype=float32), 1.9162335]. 
=============================================
[2019-04-24 09:57:11,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.6406  ]
 [65.66074 ]
 [66.353325]
 [66.860146]
 [66.54902 ]
 [65.537766]
 [65.79653 ]
 [66.0466  ]
 [66.55382 ]
 [65.69145 ]
 [66.08387 ]
 [66.9131  ]
 [67.80701 ]
 [68.15001 ]
 [68.68335 ]
 [67.96165 ]
 [68.643616]
 [69.350655]
 [69.93762 ]
 [69.552086]
 [70.01632 ]
 [70.54758 ]
 [70.231155]
 [70.66179 ]
 [71.08742 ]], R is [[66.77394867]
 [66.1062088 ]
 [66.44514465]
 [66.78069305]
 [67.11288452]
 [66.4417572 ]
 [66.77734375]
 [67.10957336]
 [67.43847656]
 [66.76409149]
 [67.09645081]
 [67.4254837 ]
 [67.75122833]
 [67.07371521]
 [67.40297699]
 [66.7289505 ]
 [67.01459503]
 [67.3444519 ]
 [67.67100525]
 [66.99429321]
 [67.32434845]
 [67.65110779]
 [66.97459412]
 [67.30484772]
 [67.63179779]].
[2019-04-24 09:57:13,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0812696e-01 2.6347971e-02 9.0920022e-14 1.3200480e-13 4.0603919e-13
 1.0757895e-14 1.4534403e-14 2.4294754e-15 2.0671654e-11 2.6552507e-01
 1.0060027e-14], sum to 1.0000
[2019-04-24 09:57:13,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4655
[2019-04-24 09:57:13,699] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 71.0, 0.0, 0.0, 19.0, 20.43775656758488, -0.8580023862330676, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 781200.0000, 
sim time next is 782400.0000, 
raw observation next is [-7.466666666666667, 71.0, 0.0, 0.0, 19.0, 19.73952940242512, -0.9929562040461226, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.25577100646352724, 0.71, 0.0, 0.0, 0.08333333333333333, 0.14496078353542666, 0.16901459865129245, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6485186], dtype=float32), -1.6868409]. 
=============================================
[2019-04-24 09:57:18,448] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.2059791e-01 4.3809186e-03 3.7846462e-16 4.5173101e-15 2.2899951e-15
 6.2306897e-17 5.0551489e-17 1.4597339e-17 1.2321777e-12 7.5021125e-02
 3.6544196e-16], sum to 1.0000
[2019-04-24 09:57:18,467] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3274
[2019-04-24 09:57:18,487] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 83.33333333333334, 45.66666666666667, 0.0, 22.5, 23.21795179794003, -0.3171644447225093, 1.0, 1.0, 60.0, 79.52229580936464], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 834000.0000, 
sim time next is 835200.0000, 
raw observation next is [-3.9, 82.0, 39.0, 0.0, 22.5, 23.19866045839596, -0.3524095282196661, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.3545706371191136, 0.82, 0.13, 0.0, 0.375, 0.43322170486633, 0.38253015726011136, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.84451294], dtype=float32), -1.0294]. 
=============================================
[2019-04-24 09:57:22,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3238217e-01 2.1645036e-03 4.1065281e-21 2.2204182e-19 1.9034310e-19
 3.7288947e-21 1.1146192e-20 5.5761844e-22 1.6782822e-16 6.5453328e-02
 4.8301713e-21], sum to 1.0000
[2019-04-24 09:57:22,446] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1467
[2019-04-24 09:57:22,499] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 0.0, 0.0, 19.0, 22.34255654010026, -0.2215359854706841, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1030800.0000, 
sim time next is 1032000.0000, 
raw observation next is [14.4, 75.0, 0.0, 0.0, 19.0, 22.3004437144174, -0.2373993506664435, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.8614958448753465, 0.75, 0.0, 0.0, 0.08333333333333333, 0.35837030953478344, 0.4208668831111855, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.63961023], dtype=float32), 0.058493543]. 
=============================================
[2019-04-24 09:57:24,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7791505e-01 2.2478856e-03 4.3431293e-17 4.6661346e-16 2.0484232e-15
 1.2687057e-16 1.6425099e-16 9.3455701e-18 7.3378857e-14 1.9837115e-02
 4.5197959e-16], sum to 1.0000
[2019-04-24 09:57:24,298] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7023
[2019-04-24 09:57:24,318] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 24.34619886255, 0.18773260007584, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1236000.0000, 
sim time next is 1237200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 23.84672109408056, 0.1038805399780743, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.4872267578400467, 0.5346268466593581, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4489734], dtype=float32), -3.091042]. 
=============================================
[2019-04-24 09:57:29,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7149020e-01 2.1193700e-03 6.8785925e-19 3.8457460e-17 2.0234833e-17
 1.7660163e-19 3.4198865e-19 3.1102211e-19 8.6922233e-15 2.6390469e-02
 2.6595435e-18], sum to 1.0000
[2019-04-24 09:57:29,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1181
[2019-04-24 09:57:29,353] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.9000000000000001, 94.0, 22.33333333333333, 0.0, 22.5, 24.06479588490993, 0.2825977914051394, 1.0, 1.0, 60.0, 93.85415677028328], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1354800.0000, 
sim time next is 1356000.0000, 
raw observation next is [0.7000000000000001, 95.0, 15.0, 0.0, 22.5, 24.9039959539957, 0.06704300366697542, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4819944598337951, 0.95, 0.05, 0.0, 0.375, 0.5753329961663084, 0.5223476678889918, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6989544], dtype=float32), 0.05130522]. 
=============================================
[2019-04-24 09:57:32,715] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8088878e-01 2.0485388e-03 7.0882086e-17 2.5721513e-15 3.6063571e-15
 1.3984536e-16 1.2824320e-16 1.2564663e-17 1.2880778e-12 1.7062686e-02
 2.8771367e-15], sum to 1.0000
[2019-04-24 09:57:32,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2060
[2019-04-24 09:57:32,731] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 79.33333333333333, 0.0, 0.0, 19.0, 23.15543675345746, 0.04330769071535995, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1212000.0000, 
sim time next is 1213200.0000, 
raw observation next is [16.1, 80.0, 0.0, 0.0, 19.0, 23.15299224226327, 0.03299260768212988, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.9085872576177286, 0.8, 0.0, 0.0, 0.08333333333333333, 0.42941602018860586, 0.5109975358940433, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.38103557], dtype=float32), 1.3150189]. 
=============================================
[2019-04-24 09:57:34,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5809038e-01 2.2790531e-02 6.4001404e-18 3.4339143e-17 3.3605539e-17
 5.7830342e-19 3.8456673e-18 3.0814272e-19 8.3527528e-15 2.1911912e-01
 1.1324705e-18], sum to 1.0000
[2019-04-24 09:57:34,150] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6456
[2019-04-24 09:57:34,173] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 92.0, 0.0, 0.0, 19.0, 21.42684999851623, -0.4812735254593496, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1310400.0000, 
sim time next is 1311600.0000, 
raw observation next is [2.0, 92.0, 0.0, 0.0, 19.0, 20.94830471551602, -0.5522240461778349, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.518005540166205, 0.92, 0.0, 0.0, 0.08333333333333333, 0.245692059626335, 0.3159253179407217, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8797967], dtype=float32), -0.6996962]. 
=============================================
[2019-04-24 09:57:36,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4117022e-01 4.3722922e-03 5.9392069e-19 2.0726241e-17 3.4404483e-17
 4.8550451e-19 7.6696202e-19 6.3918954e-20 2.1381003e-15 5.4457482e-02
 2.1693825e-18], sum to 1.0000
[2019-04-24 09:57:36,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5941
[2019-04-24 09:57:36,284] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.200000000000001, 95.0, 0.0, 0.0, 19.0, 21.48995303693355, -0.4250408481988224, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1297200.0000, 
sim time next is 1298400.0000, 
raw observation next is [4.0, 94.0, 0.0, 0.0, 19.0, 21.04301452177096, -0.49576899862412, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5734072022160666, 0.94, 0.0, 0.0, 0.08333333333333333, 0.25358454348091336, 0.3347436671252933, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.413559], dtype=float32), -0.5397375]. 
=============================================
[2019-04-24 09:57:36,794] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.6001720e-01 1.3122498e-03 2.2272117e-19 3.2504552e-18 4.9776491e-18
 3.6926141e-20 1.4465457e-19 1.7459917e-20 2.1775822e-15 3.8670655e-02
 1.9163983e-19], sum to 1.0000
[2019-04-24 09:57:36,798] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1212
[2019-04-24 09:57:36,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3847982e-01 6.1366609e-03 1.7516716e-17 4.1475630e-16 6.7805325e-17
 3.0693444e-18 4.0767046e-18 5.0767739e-18 6.1079763e-14 1.5538359e-01
 1.0146989e-17], sum to 1.0000
[2019-04-24 09:57:36,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7536
[2019-04-24 09:57:36,816] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 75.0, 0.0, 22.5, 22.50590587836312, -0.2679578782485805, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1434000.0000, 
sim time next is 1435200.0000, 
raw observation next is [1.1, 92.0, 67.66666666666667, 0.0, 22.5, 22.71624339773122, -0.2498485884324971, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.92, 0.22555555555555556, 0.0, 0.375, 0.39302028314426823, 0.41671713718916764, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0345], dtype=float32), 0.26842347]. 
=============================================
[2019-04-24 09:57:36,820] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 58.66666666666667, 0.0, 0.0, 22.5, 24.47009019277412, 0.08244412992329886, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1531200.0000, 
sim time next is 1532400.0000, 
raw observation next is [10.16666666666667, 59.33333333333334, 0.0, 0.0, 22.5, 23.48109758830241, 0.04921011283830799, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7442289935364729, 0.5933333333333334, 0.0, 0.0, 0.375, 0.4567581323585343, 0.5164033709461027, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.80806345], dtype=float32), 0.49334535]. 
=============================================
[2019-04-24 09:57:37,592] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0684650e-01 2.8714519e-02 1.8973980e-17 8.1331078e-17 1.6545052e-16
 2.3425170e-18 7.0184257e-18 1.7701005e-18 2.4561172e-14 1.6443892e-01
 9.1862138e-18], sum to 1.0000
[2019-04-24 09:57:37,592] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7133
[2019-04-24 09:57:37,619] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 19.0, 20.42613519226063, -0.6896190684291624, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1483200.0000, 
sim time next is 1484400.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 20.32497500827114, -0.7099853805939035, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.19374791735592822, 0.2633382064686988, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.784585], dtype=float32), 1.0473366]. 
=============================================
[2019-04-24 09:57:44,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6801001e-01 6.2142103e-03 1.4516397e-19 7.5325085e-18 3.2214650e-18
 5.1341336e-20 6.2877611e-20 3.4584454e-20 2.3313394e-15 2.5775837e-02
 3.9977220e-19], sum to 1.0000
[2019-04-24 09:57:44,819] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9310
[2019-04-24 09:57:44,837] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 82.0, 0.0, 0.0, 19.0, 23.39232951824527, -0.09117580748975414, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1552800.0000, 
sim time next is 1554000.0000, 
raw observation next is [5.166666666666666, 82.0, 0.0, 0.0, 19.0, 22.72808897626447, -0.2202208529762095, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.6057248384118191, 0.82, 0.0, 0.0, 0.08333333333333333, 0.3940074146887058, 0.42659304900793016, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05400549], dtype=float32), 1.2797399]. 
=============================================
[2019-04-24 09:57:48,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3163834e-01 1.1724032e-02 7.2193578e-18 9.2340210e-17 6.7567077e-17
 7.6903586e-19 9.8978850e-19 2.8564741e-19 4.5153388e-14 1.5663755e-01
 7.6660518e-18], sum to 1.0000
[2019-04-24 09:57:48,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3149
[2019-04-24 09:57:48,969] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 74.5, 0.0, 22.5, 23.35863305665622, -0.1290150145582928, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1681200.0000, 
sim time next is 1682400.0000, 
raw observation next is [1.1, 89.33333333333334, 80.16666666666667, 0.0, 22.5, 23.23792260783053, -0.149972203683434, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.49307479224376743, 0.8933333333333334, 0.26722222222222225, 0.0, 0.375, 0.4364935506525442, 0.4500092654388553, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.5070608], dtype=float32), 1.4417616]. 
=============================================
[2019-04-24 09:57:49,021] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.21824229e-01 2.12957840e-02 1.28282028e-16 5.09689212e-16
 9.54162922e-16 9.61744535e-18 3.57241506e-17 1.04245155e-17
 1.64993087e-13 2.56880015e-01 1.76290999e-17], sum to 1.0000
[2019-04-24 09:57:49,049] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9259
[2019-04-24 09:57:49,256] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 21.43377498802646, -0.4585680882869459, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1708800.0000, 
sim time next is 1710000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 22.22209053480132, -0.00845204390690201, 1.0, 1.0, 60.0, 126.60279827471696], 
processed observation next is [1.0, 0.8260869565217391, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.3518408779001101, 0.4971826520310327, 1.0, 1.0, 0.9, 1.2660279827471697], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0825399], dtype=float32), 0.8235497]. 
=============================================
[2019-04-24 09:57:49,280] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[78.2463  ]
 [78.34811 ]
 [78.49286 ]
 [78.70826 ]
 [78.97872 ]
 [79.18543 ]
 [79.22863 ]
 [79.346115]
 [79.58941 ]
 [79.91146 ]
 [80.39954 ]
 [80.6     ]
 [80.85578 ]
 [81.18886 ]
 [81.5772  ]
 [80.98106 ]
 [81.42898 ]
 [81.72624 ]
 [82.08284 ]
 [82.45904 ]
 [82.88176 ]
 [82.41866 ]
 [82.89944 ]
 [83.235245]
 [83.660805]], R is [[78.74092102]
 [78.9535141 ]
 [79.16397858]
 [79.37233734]
 [79.57861328]
 [79.78282928]
 [79.98500061]
 [80.18515015]
 [80.38330078]
 [80.57946777]
 [80.77367401]
 [80.96593475]
 [81.15627289]
 [81.3447113 ]
 [81.53126526]
 [80.71595001]
 [80.90879059]
 [81.09970093]
 [81.28870392]
 [81.47581482]
 [81.66105652]
 [80.84444427]
 [81.03600311]
 [81.22564697]
 [81.41339111]].
[2019-04-24 09:57:54,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9508486e-01 2.5704293e-02 6.3920108e-14 4.7122679e-13 3.8732643e-13
 2.8795505e-14 3.8267871e-14 7.9239390e-15 3.0369467e-11 7.9210818e-02
 7.1980209e-14], sum to 1.0000
[2019-04-24 09:57:54,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4308
[2019-04-24 09:57:54,478] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.199999999999999, 84.33333333333333, 0.0, 0.0, 19.0, 20.16873673349688, -0.8499935727655759, 0.0, 1.0, 60.0, 62.97481351321002], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1827600.0000, 
sim time next is 1828800.0000, 
raw observation next is [-6.2, 83.0, 0.0, 0.0, 19.0, 20.00748313797622, -1.045054394036934, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2908587257617729, 0.83, 0.0, 0.0, 0.08333333333333333, 0.1672902614980183, 0.15164853532102204, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.54371053], dtype=float32), 0.11908434]. 
=============================================
[2019-04-24 09:58:02,345] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5835353e-01 2.0970644e-02 6.4251989e-15 3.3038168e-14 7.3583860e-14
 2.8341182e-15 2.1318261e-15 4.9111696e-16 7.7807934e-12 2.2067578e-01
 1.9521513e-15], sum to 1.0000
[2019-04-24 09:58:02,346] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1137
[2019-04-24 09:58:02,436] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.266666666666667, 53.66666666666667, 121.8333333333333, 30.5, 22.5, 23.05522761679538, -0.3420958061660238, 1.0, 1.0, 20.0, 62.06703095358152], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2539200.0000, 
sim time next is 2540400.0000, 
raw observation next is [-1.733333333333333, 51.33333333333333, 135.5, 35.0, 22.5, 23.29720708541732, -0.4215154362625868, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.41458910433979695, 0.5133333333333333, 0.45166666666666666, 0.03867403314917127, 0.375, 0.44143392378477664, 0.3594948545791377, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9031451], dtype=float32), 0.86125106]. 
=============================================
[2019-04-24 09:58:03,362] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2675413e-01 2.5608059e-02 1.7587738e-14 5.8684801e-14 1.2885496e-13
 1.4551539e-15 2.5439957e-15 1.8003469e-15 2.8726847e-12 2.4763779e-01
 5.9809704e-15], sum to 1.0000
[2019-04-24 09:58:03,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3600
[2019-04-24 09:58:03,448] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 84.33333333333334, 0.0, 0.0, 19.0, 20.75672433046991, -0.788176932675289, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1988400.0000, 
sim time next is 1989600.0000, 
raw observation next is [-6.0, 85.66666666666667, 0.0, 0.0, 19.0, 19.99519833841211, -0.9303153491835786, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.8566666666666667, 0.0, 0.0, 0.08333333333333333, 0.1662665282010091, 0.1898948836054738, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7410048], dtype=float32), -0.20168485]. 
=============================================
[2019-04-24 09:58:19,472] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5272677e-01 2.6374619e-02 2.3759991e-12 4.5306042e-12 6.5790273e-12
 8.5640528e-13 3.5218871e-13 3.3406115e-13 1.6319261e-10 3.2089862e-01
 5.1227523e-13], sum to 1.0000
[2019-04-24 09:58:19,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1833
[2019-04-24 09:58:19,519] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.766666666666667, 42.66666666666667, 0.0, 0.0, 19.0, 20.08450465519531, -1.009996608298237, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2409600.0000, 
sim time next is 2410800.0000, 
raw observation next is [-4.133333333333334, 43.33333333333334, 0.0, 0.0, 19.0, 19.24593817792007, -1.163032156631311, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.34810710987996313, 0.4333333333333334, 0.0, 0.0, 0.08333333333333333, 0.10382818149333921, 0.11232261445622964, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.421687], dtype=float32), 0.26313123]. 
=============================================
[2019-04-24 09:58:26,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4659168e-01 8.5788108e-02 5.6764245e-14 1.5088445e-13 1.7056701e-13
 4.2237844e-15 3.4260640e-14 1.9033779e-14 1.6897823e-11 5.6762022e-01
 1.1514838e-14], sum to 1.0000
[2019-04-24 09:58:26,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2395
[2019-04-24 09:58:26,580] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 57.0, 0.0, 0.0, 19.0, 20.09499822036353, -1.069364758090127, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2527200.0000, 
sim time next is 2528400.0000, 
raw observation next is [-2.466666666666667, 56.00000000000001, 0.0, 0.0, 19.0, 19.35756037386444, -1.168362656246928, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.39427516158818104, 0.56, 0.0, 0.0, 0.08333333333333333, 0.11313003115537008, 0.11054578125102399, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1620178], dtype=float32), -0.82615113]. 
=============================================
[2019-04-24 09:58:31,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7394878e-01 2.9733689e-03 1.7351381e-16 6.8793043e-15 3.6990081e-15
 2.2294142e-17 9.7677603e-17 1.1587158e-17 1.3457174e-12 2.3077792e-02
 6.4322777e-16], sum to 1.0000
[2019-04-24 09:58:31,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6148
[2019-04-24 09:58:31,177] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.7, 29.0, 38.5, 83.5, 22.5, 23.52842059285253, -0.1543112839168994, 1.0, 1.0, 60.0, 87.66365426068583], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2566800.0000, 
sim time next is 2568000.0000, 
raw observation next is [1.966666666666667, 31.0, 17.5, 31.16666666666666, 22.5, 23.87502831994288, -0.1840717017696958, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5170821791320407, 0.31, 0.058333333333333334, 0.03443830570902393, 0.375, 0.48958569332857343, 0.43864276607676805, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.08977495], dtype=float32), -0.9874386]. 
=============================================
[2019-04-24 09:58:32,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0321175e-01 6.5123714e-03 3.1715937e-15 1.9429367e-14 7.8036722e-15
 2.1357409e-16 2.3881782e-16 3.2984246e-16 3.6473138e-12 1.9027583e-01
 1.7040031e-15], sum to 1.0000
[2019-04-24 09:58:32,085] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1520
[2019-04-24 09:58:32,128] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 47.0, 204.5, 179.0, 22.5, 23.09324068099172, -0.326833128063846, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2638800.0000, 
sim time next is 2640000.0000, 
raw observation next is [-0.2333333333333334, 45.66666666666667, 177.5, 200.3333333333333, 22.5, 22.874181569634, -0.3526865916355782, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.456140350877193, 0.4566666666666667, 0.5916666666666667, 0.2213627992633517, 0.375, 0.40618179746950006, 0.3824378027881406, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7679381], dtype=float32), 0.3313294]. 
=============================================
[2019-04-24 09:58:32,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.19275 ]
 [70.56786 ]
 [70.90734 ]
 [70.12923 ]
 [70.24724 ]
 [70.35545 ]
 [69.448166]
 [70.09959 ]
 [69.69216 ]
 [69.81374 ]
 [69.24567 ]
 [69.06458 ]
 [69.58451 ]
 [68.90774 ]
 [67.75256 ]
 [68.155914]
 [67.6987  ]
 [66.577225]
 [66.601204]
 [67.25082 ]
 [67.27038 ]
 [67.004944]
 [67.72242 ]
 [68.262535]
 [67.768364]], R is [[70.18481445]
 [70.48296356]
 [70.77813721]
 [70.07035828]
 [70.36965179]
 [70.66595459]
 [69.95929718]
 [70.25970459]
 [70.55710602]
 [70.85153198]
 [70.14302063]
 [70.44122314]
 [70.73680878]
 [70.02944183]
 [69.32914734]
 [68.63585663]
 [67.94950104]
 [67.27000427]
 [66.5973053 ]
 [66.93133545]
 [66.26202393]
 [65.59940338]
 [65.94341278]
 [66.28398132]
 [65.62113953]].
[2019-04-24 09:58:35,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7644523e-01 5.3718966e-03 3.9218316e-15 3.1547095e-14 1.2491018e-14
 6.0379780e-16 6.7959100e-16 2.2606730e-16 4.9246059e-12 1.1818286e-01
 3.5843927e-15], sum to 1.0000
[2019-04-24 09:58:35,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7219
[2019-04-24 09:58:35,084] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 46.0, 73.5, 587.5, 22.5, 22.60928992209093, -0.2215248129994677, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3340800.0000, 
sim time next is 3342000.0000, 
raw observation next is [-2.0, 47.33333333333334, 64.5, 529.8333333333333, 22.5, 23.13234348322634, -0.1842252659066006, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.40720221606648205, 0.47333333333333344, 0.215, 0.5854511970534069, 0.375, 0.4276952902688616, 0.43859157803113313, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.61377305], dtype=float32), -0.6340888]. 
=============================================
[2019-04-24 09:58:35,757] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8170987e-01 6.6634845e-03 1.1566229e-15 1.1885638e-14 6.7908063e-15
 5.9533267e-17 1.9892836e-16 1.3391946e-16 3.0048436e-12 1.1162658e-01
 9.9055813e-16], sum to 1.0000
[2019-04-24 09:58:35,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8405
[2019-04-24 09:58:35,821] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 58.0, 0.0, 0.0, 22.5, 23.3246550415701, -0.2506439314056503, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2659200.0000, 
sim time next is 2660400.0000, 
raw observation next is [-1.2, 60.0, 0.0, 0.0, 22.5, 22.68495550517479, -0.3415320621735058, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.42936288088642666, 0.6, 0.0, 0.0, 0.375, 0.39041295876456594, 0.38615597927549805, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44998246], dtype=float32), 1.4238509]. 
=============================================
[2019-04-24 09:58:35,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2408440e-01 1.4540650e-01 4.5386093e-13 7.9847495e-13 9.7429909e-13
 7.1948327e-14 3.2804553e-13 3.6026195e-14 5.1390503e-11 5.3050911e-01
 5.5619419e-14], sum to 1.0000
[2019-04-24 09:58:35,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7493
[2019-04-24 09:58:36,057] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.61817341833868, -1.052109545820637, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2786400.0000, 
sim time next is 2787600.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.76734779202258, -0.8059832438707214, 0.0, 1.0, 60.0, 99.35685581691732], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.14727898266854833, 0.23133891870975953, 0.0, 1.0, 0.9, 0.9935685581691732], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.65053964], dtype=float32), 0.43942302]. 
=============================================
[2019-04-24 09:58:37,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.1347938e-01 6.5829721e-03 1.1293910e-14 1.0202886e-14 1.6829931e-14
 1.1146413e-15 1.1242109e-15 1.3315844e-16 1.4027553e-12 3.7993774e-01
 1.8506418e-15], sum to 1.0000
[2019-04-24 09:58:37,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6151
[2019-04-24 09:58:37,411] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.8831624779775, -0.4984632888244824, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2943600.0000, 
sim time next is 2944800.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 21.66523631373003, -0.4005056793453023, 0.0, 1.0, 20.0, 67.6335574205203], 
processed observation next is [0.0, 0.08695652173913043, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.30543635947750253, 0.3664981068848992, 0.0, 1.0, 0.1, 0.6763355742052031], 
reward next is 0.2237, 
noisyNet noise sample is [array([-0.6142267], dtype=float32), -0.39606708]. 
=============================================
[2019-04-24 09:58:45,864] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [3.2416713e-01 7.0207819e-02 1.6280790e-12 1.7622208e-12 1.6186847e-12
 3.5335621e-13 4.4443710e-13 8.1839774e-14 4.4114969e-11 6.0562503e-01
 1.8876818e-13], sum to 1.0000
[2019-04-24 09:58:45,865] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5368
[2019-04-24 09:58:46,074] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.0, 60.66666666666666, 85.66666666666667, 405.0, 19.0, 17.94264010293701, -1.338595108042353, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3055200.0000, 
sim time next is 3056400.0000, 
raw observation next is [-6.0, 59.0, 91.0, 497.0, 19.0, 18.97807098033321, -0.8560691633596288, 0.0, 1.0, 60.0, 123.96009489277577], 
processed observation next is [0.0, 0.391304347826087, 0.296398891966759, 0.59, 0.30333333333333334, 0.549171270718232, 0.08333333333333333, 0.08150591502776756, 0.21464361221345707, 0.0, 1.0, 0.9, 1.2396009489277577], 
reward next is 0.0439, 
noisyNet noise sample is [array([0.705693], dtype=float32), 0.4809151]. 
=============================================
[2019-04-24 09:58:52,426] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.43721187e-01 2.15325411e-02 4.05911820e-17 3.18473986e-16
 2.93059741e-16 2.10128492e-17 1.05177884e-17 2.92565759e-18
 3.02517377e-14 2.34746248e-01 3.12259159e-17], sum to 1.0000
[2019-04-24 09:58:52,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2911
[2019-04-24 09:58:52,513] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 43.0, 226.0, 22.5, 22.13102666733783, -0.1151624204726061, 1.0, 1.0, 60.0, 118.31786713621199], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3225600.0000, 
sim time next is 3226800.0000, 
raw observation next is [-3.0, 92.0, 71.00000000000001, 322.0000000000001, 22.5, 23.372975653485, -0.1608681577981734, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3795013850415513, 0.92, 0.23666666666666672, 0.3558011049723758, 0.375, 0.44774797112375, 0.44637728073394217, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30743608], dtype=float32), 2.894584]. 
=============================================
[2019-04-24 09:58:54,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0391296e-01 8.1305662e-03 7.6865545e-16 1.4220772e-14 1.4451881e-14
 1.6977997e-16 5.3276117e-16 2.2591769e-16 4.2529560e-13 8.7956458e-02
 1.9026219e-15], sum to 1.0000
[2019-04-24 09:58:54,910] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5741
[2019-04-24 09:58:54,936] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 74.66666666666667, 0.0, 0.0, 19.0, 21.01436261378457, -0.3748713941073641, 0.0, 1.0, 60.0, 94.36414189471512], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3285600.0000, 
sim time next is 3286800.0000, 
raw observation next is [-7.0, 70.0, 0.0, 0.0, 19.0, 21.69292668765511, -0.5096523633669666, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.2686980609418283, 0.7, 0.0, 0.0, 0.08333333333333333, 0.3077438906379258, 0.3301158788776778, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2853136], dtype=float32), -0.5093168]. 
=============================================
[2019-04-24 09:58:55,380] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9941585e-01 8.2717333e-03 9.0812147e-15 1.6075729e-13 4.7863789e-14
 3.7751437e-15 2.8151722e-15 1.3791681e-15 1.8075342e-11 9.2312448e-02
 1.2037861e-14], sum to 1.0000
[2019-04-24 09:58:55,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5839
[2019-04-24 09:58:55,392] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 45.0, 117.5, 829.5, 22.5, 22.23931441534322, -0.335013604241586, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3934800.0000, 
sim time next is 3936000.0000, 
raw observation next is [-5.666666666666666, 42.66666666666667, 116.5, 825.8333333333334, 22.5, 22.46913791151556, -0.3051940580404326, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3056325023084026, 0.4266666666666667, 0.3883333333333333, 0.912523020257827, 0.375, 0.3724281592929633, 0.3982686473198558, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3078393], dtype=float32), -0.11624887]. 
=============================================
[2019-04-24 09:58:56,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.73263353e-01 1.12802304e-01 1.55449777e-13 9.33447980e-13
 8.40496238e-13 4.79915044e-14 4.88860864e-14 4.06086196e-14
 4.57754563e-11 4.13934410e-01 8.33489094e-14], sum to 1.0000
[2019-04-24 09:58:56,071] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1598
[2019-04-24 09:58:56,133] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 81.33333333333334, 16.0, 144.3333333333333, 22.5, 21.31947543236922, -0.6861520367598142, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3310800.0000, 
sim time next is 3312000.0000, 
raw observation next is [-11.0, 84.0, 44.0, 245.0, 22.5, 20.70805674091185, -0.7960703282024001, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.15789473684210528, 0.84, 0.14666666666666667, 0.27071823204419887, 0.375, 0.22567139507598752, 0.2346432239325333, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5768667], dtype=float32), -1.8184061]. 
=============================================
[2019-04-24 09:58:57,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0004903e-01 7.8998292e-03 1.1709871e-15 6.3282475e-14 2.6798552e-14
 3.8747265e-16 1.4632887e-15 1.3797073e-15 4.2475676e-12 9.2051163e-02
 4.4584583e-15], sum to 1.0000
[2019-04-24 09:58:57,216] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4258
[2019-04-24 09:58:57,259] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 61.66666666666666, 0.0, 0.0, 19.0, 23.09965516171766, -0.2178209524190831, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3357600.0000, 
sim time next is 3358800.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 22.5121649710006, -0.3489185380207125, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.3760137475833834, 0.3836938206597625, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4224037], dtype=float32), 0.48162505]. 
=============================================
[2019-04-24 09:58:59,490] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-24 09:58:59,497] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 09:58:59,498] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:58:59,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run6
[2019-04-24 09:58:59,515] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 09:58:59,516] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:58:59,516] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 09:58:59,517] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 09:58:59,520] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run6
[2019-04-24 09:58:59,520] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run6
[2019-04-24 10:00:48,167] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3429.8032 65714.6092 -127.2138
[2019-04-24 10:00:48,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:00:48,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:00:48,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:00:48,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:00:48,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:00:48,243] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:00:48,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:00:48,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:00:48,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:00:48,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:00:48,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:00:48,596] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:00,709] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3200.8245 82123.8400 -393.2289
[2019-04-24 10:01:00,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:00,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:00,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:00,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:00,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:00,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:00,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:00,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:00,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:00,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:00,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:00,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:08,615] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3122.6639 86513.2157 -438.5475
[2019-04-24 10:01:08,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:08,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:08,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:08,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:08,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:08,650] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:01:08,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:08,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:08,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:08,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:08,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:08,809] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:01:09,652] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 250000, evaluation results [250000.0, 3200.8244808593176, 82123.84001664528, -393.2288881403529, 3429.803151795967, 65714.60916632364, -127.21380413271525, 3122.663924442747, 86513.215694333, -438.54753486421896]
[2019-04-24 10:01:15,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6584177e-01 5.4749744e-03 1.3825646e-16 5.6496551e-15 1.8086544e-15
 4.3619652e-17 6.3735530e-17 5.3113446e-17 5.1148609e-13 2.8683202e-02
 1.6771717e-16], sum to 1.0000
[2019-04-24 10:01:15,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2664
[2019-04-24 10:01:15,872] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 20.81845135578033, -0.4061081450561012, 0.0, 1.0, 60.0, 103.77466091901954], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3799200.0000, 
sim time next is 3800400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 21.68619339184724, -0.5244655022836663, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.30718278265393667, 0.32517816590544457, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34544408], dtype=float32), -0.14341892]. 
=============================================
[2019-04-24 10:01:16,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6324416e-01 6.9029957e-02 7.9057969e-14 5.9995642e-14 2.1291003e-13
 1.4214245e-14 2.8834032e-14 3.1071394e-15 1.5468809e-11 3.6772588e-01
 2.4903279e-14], sum to 1.0000
[2019-04-24 10:01:16,645] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8919
[2019-04-24 10:01:16,722] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.0, 69.0, 0.0, 0.0, 19.0, 20.1842309875842, -0.8284356957271646, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3550800.0000, 
sim time next is 3552000.0000, 
raw observation next is [-3.0, 67.0, 0.0, 0.0, 19.0, 20.32630287319868, -0.5740624121615473, 0.0, 1.0, 60.0, 95.85783976038937], 
processed observation next is [0.0, 0.08695652173913043, 0.3795013850415513, 0.67, 0.0, 0.0, 0.08333333333333333, 0.1938585727665568, 0.30864586261281757, 0.0, 1.0, 0.9, 0.9585783976038936], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8324387], dtype=float32), -0.31975645]. 
=============================================
[2019-04-24 10:01:20,876] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.3833450e-01 2.6069960e-02 1.0623680e-13 1.5675854e-13 2.0002397e-13
 4.5378343e-14 1.9429364e-14 6.2157336e-15 1.5308243e-11 1.3559560e-01
 5.9104990e-14], sum to 1.0000
[2019-04-24 10:01:20,923] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7109
[2019-04-24 10:01:20,982] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 54.33333333333334, 113.5, 806.3333333333333, 19.0, 19.41163563364912, -0.8962803013076884, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3583200.0000, 
sim time next is 3584400.0000, 
raw observation next is [-3.333333333333333, 54.66666666666667, 114.6666666666667, 817.1666666666666, 19.0, 19.36400301018396, -0.9003168611423474, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.37026777469990774, 0.5466666666666667, 0.38222222222222235, 0.9029465930018415, 0.08333333333333333, 0.11366691751533005, 0.19989437961921752, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5455482], dtype=float32), 0.5924064]. 
=============================================
[2019-04-24 10:01:22,586] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8702618e-01 1.2842172e-01 8.6219763e-13 2.8449688e-12 3.1174256e-12
 3.0612820e-13 2.7430166e-13 1.8071403e-13 9.2895025e-11 3.8455215e-01
 4.1085690e-13], sum to 1.0000
[2019-04-24 10:01:22,586] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7489
[2019-04-24 10:01:22,765] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-11.0, 53.0, 97.0, 571.0, 22.5, 21.58373475382822, -0.6893647198085072, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4006800.0000, 
sim time next is 4008000.0000, 
raw observation next is [-10.33333333333333, 50.0, 99.66666666666667, 655.6666666666667, 22.5, 22.15003477053967, -0.3797412913182256, 1.0, 1.0, 60.0, 100.61105056936029], 
processed observation next is [1.0, 0.391304347826087, 0.17636195752539252, 0.5, 0.33222222222222225, 0.7244935543278086, 0.375, 0.3458362308783058, 0.37341956956059147, 1.0, 1.0, 0.9, 1.0061105056936028], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40584743], dtype=float32), 0.058131102]. 
=============================================
[2019-04-24 10:01:25,947] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2507124e-01 2.0154644e-02 4.9106370e-16 1.1012729e-14 1.5135762e-14
 2.5797402e-16 5.8774420e-16 2.3087799e-16 3.3472311e-12 5.4774038e-02
 1.5192733e-15], sum to 1.0000
[2019-04-24 10:01:25,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6026
[2019-04-24 10:01:26,016] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 20.75115926384671, -0.5882349690029313, 0.0, 1.0, 60.0, 92.52558791845775], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3729600.0000, 
sim time next is 3730800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 21.43938050948604, -0.694631934025557, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.2866150424571699, 0.268456021991481, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9356274], dtype=float32), 1.2453032]. 
=============================================
[2019-04-24 10:01:31,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9019834e-01 9.2836842e-02 1.1200237e-14 2.4208090e-14 6.4264729e-14
 4.1248738e-15 1.1824755e-14 2.2411583e-15 1.2114498e-11 3.1696483e-01
 2.9566765e-15], sum to 1.0000
[2019-04-24 10:01:31,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8809
[2019-04-24 10:01:31,298] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 18.91480083986065, -1.171068092622222, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3734400.0000, 
sim time next is 3735600.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 19.33518522304412, -0.8618557718062801, 0.0, 1.0, 60.0, 99.51662589818982], 
processed observation next is [1.0, 0.21739130434782608, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.11126543525367676, 0.21271474273123994, 0.0, 1.0, 0.9, 0.9951662589818981], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4837929], dtype=float32), -0.12219957]. 
=============================================
[2019-04-24 10:01:32,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1092026e-01 3.2612176e-03 1.3376113e-16 2.4036567e-15 3.6978468e-15
 2.0510742e-17 6.1374075e-17 1.1806308e-17 7.7012512e-13 8.5818581e-02
 3.1393018e-16], sum to 1.0000
[2019-04-24 10:01:32,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5173
[2019-04-24 10:01:32,401] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 39.0, 0.0, 0.0, 22.5, 22.92506554873766, -0.1815503929082766, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4130400.0000, 
sim time next is 4131600.0000, 
raw observation next is [1.666666666666667, 41.0, 0.0, 0.0, 22.5, 22.74050091769213, -0.2172220667980105, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5087719298245615, 0.41, 0.0, 0.0, 0.375, 0.3950417431410109, 0.4275926444006632, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11745925], dtype=float32), -0.3242347]. 
=============================================
[2019-04-24 10:02:00,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0922083e-01 1.2875631e-01 1.0142285e-13 3.4361470e-13 4.7396353e-13
 3.0367632e-14 8.1713777e-14 4.2179137e-14 3.0322765e-11 1.6202278e-01
 2.6149991e-14], sum to 1.0000
[2019-04-24 10:02:00,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8519
[2019-04-24 10:02:00,747] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.0, 41.0, 0.0, 0.0, 19.0, 20.03759904451858, -1.024062521399385, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4086000.0000, 
sim time next is 4087200.0000, 
raw observation next is [-4.666666666666667, 38.66666666666667, 0.0, 0.0, 22.5, 19.92085951047818, -0.7711094701684527, 0.0, 1.0, 60.0, 104.19681501872711], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333333, 0.3866666666666667, 0.0, 0.0, 0.375, 0.16007162587318172, 0.2429635099438491, 0.0, 1.0, 0.9, 1.041968150187271], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.97957957], dtype=float32), 0.7664954]. 
=============================================
[2019-04-24 10:02:12,147] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.80442703e-01 1.72614516e-03 3.51334205e-20 2.66145796e-18
 9.51760010e-19 7.24908535e-21 1.01890945e-20 2.27507324e-21
 4.25491702e-16 1.78311169e-02 6.03730242e-20], sum to 1.0000
[2019-04-24 10:02:12,178] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2786
[2019-04-24 10:02:12,241] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.6, 42.0, 7.5, 0.0, 22.5, 24.01793794085466, 0.1107883277211524, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4383600.0000, 
sim time next is 4384800.0000, 
raw observation next is [12.4, 44.0, 0.0, 0.0, 22.5, 24.24638028676456, 0.1294801092288157, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.806094182825485, 0.44, 0.0, 0.0, 0.375, 0.5205316905637133, 0.5431600364096053, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0652037], dtype=float32), 2.6576037]. 
=============================================
[2019-04-24 10:02:14,974] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:15,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:15,958] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:15,958] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:15,964] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run5
[2019-04-24 10:02:24,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0532869e-01 8.5681695e-03 7.8336472e-17 1.0509571e-15 8.4996193e-16
 3.2086250e-17 2.7685836e-17 3.8736326e-18 3.4066313e-13 8.6103179e-02
 4.2951711e-17], sum to 1.0000
[2019-04-24 10:02:24,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0384
[2019-04-24 10:02:24,796] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 59.66666666666667, 0.0, 0.0, 19.0, 21.27715661465643, -0.5116806636240707, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4570800.0000, 
sim time next is 4572000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 19.0, 21.17808330494256, -0.5309584100295498, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4903047091412743, 0.61, 0.0, 0.0, 0.08333333333333333, 0.2648402754118801, 0.3230138633234834, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05446495], dtype=float32), -1.245385]. 
=============================================
[2019-04-24 10:02:27,874] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.3617800e-01 2.1488871e-02 5.5654104e-16 4.1758932e-15 1.5922481e-14
 2.1639542e-16 9.5339837e-16 3.1227799e-17 7.8574251e-13 1.4233318e-01
 3.9156951e-16], sum to 1.0000
[2019-04-24 10:02:27,882] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5833
[2019-04-24 10:02:27,969] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.866666666666667, 76.0, 0.0, 0.0, 19.0, 19.95707743356602, -0.9664464528151072, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4603200.0000, 
sim time next is 4604400.0000, 
raw observation next is [-3.0, 77.0, 0.0, 0.0, 19.0, 19.47579627762553, -1.044999936585082, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.3795013850415513, 0.77, 0.0, 0.0, 0.08333333333333333, 0.12298302313546088, 0.1516666878049727, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.50655687], dtype=float32), 0.106345825]. 
=============================================
[2019-04-24 10:02:30,105] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2081714e-01 1.3041711e-02 3.3291410e-18 1.3904585e-17 1.1199959e-17
 1.8617448e-19 7.0341170e-19 1.4141813e-19 4.0688693e-15 6.6141263e-02
 2.5226490e-18], sum to 1.0000
[2019-04-24 10:02:30,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2270
[2019-04-24 10:02:30,134] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 90.0, 212.1666666666667, 6.0, 22.5, 23.50931081399663, -0.2273544944235509, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4706400.0000, 
sim time next is 4707600.0000, 
raw observation next is [0.6666666666666666, 88.0, 195.5, 5.0, 22.5, 23.01554820612097, -0.3381180103987865, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.4810710987996307, 0.88, 0.6516666666666666, 0.0055248618784530384, 0.375, 0.41796235051008096, 0.38729399653373786, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.48755193], dtype=float32), 0.55838835]. 
=============================================
[2019-04-24 10:02:34,347] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:34,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:35,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:35,357] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:35,359] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run5
[2019-04-24 10:02:37,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5649725e-01 2.9438243e-03 4.9076448e-18 1.5761425e-16 5.5336887e-17
 9.6650151e-19 3.3994906e-18 4.4316729e-19 5.7764347e-14 4.0558912e-02
 6.6612143e-18], sum to 1.0000
[2019-04-24 10:02:37,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5945
[2019-04-24 10:02:37,060] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 32.66666666666667, 121.8333333333333, 839.0, 22.5, 23.70353114427864, -0.2053212860481885, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5052000.0000, 
sim time next is 5053200.0000, 
raw observation next is [7.0, 29.33333333333334, 123.1666666666667, 848.3333333333334, 22.5, 23.56792434830509, -0.09431739963075804, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6565096952908588, 0.2933333333333334, 0.4105555555555557, 0.9373848987108656, 0.375, 0.4639936956920909, 0.46856086678974734, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1481768], dtype=float32), -0.64987004]. 
=============================================
[2019-04-24 10:02:39,348] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:39,591] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:40,350] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:40,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:40,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run5
[2019-04-24 10:02:40,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3526881e-01 2.8519304e-02 5.0111049e-14 9.3035178e-14 2.8603883e-13
 6.6769086e-14 3.0767648e-14 4.6199938e-15 1.3289679e-11 3.3621186e-01
 2.7004847e-14], sum to 1.0000
[2019-04-24 10:02:40,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0709
[2019-04-24 10:02:40,765] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 36.0, 0.0, 0.0, 19.0, 19.60743053060749, -1.047319508209932, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4914000.0000, 
sim time next is 4915200.0000, 
raw observation next is [1.0, 36.0, 0.0, 0.0, 19.0, 19.24912305144438, -1.10219669162044, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.4903047091412743, 0.36, 0.0, 0.0, 0.08333333333333333, 0.10409358762036487, 0.13260110279318668, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3410472], dtype=float32), -1.2751565]. 
=============================================
[2019-04-24 10:02:44,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.15874267e-01 1.69238120e-01 1.11588364e-13 4.10847653e-13
 4.61773415e-13 3.20954878e-14 1.70007888e-13 3.44787743e-14
 2.46440091e-11 3.14887524e-01 2.80861709e-14], sum to 1.0000
[2019-04-24 10:02:44,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6787
[2019-04-24 10:02:44,160] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-9.866666666666667, 69.0, 0.0, 0.0, 19.0, 18.80833505606992, -1.268527910487214, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 274800.0000, 
sim time next is 276000.0000, 
raw observation next is [-10.23333333333333, 68.0, 0.0, 0.0, 19.0, 18.49265664829668, -1.155184553548409, 0.0, 1.0, 20.0, 68.0299645289302], 
processed observation next is [1.0, 0.17391304347826086, 0.1791320406278856, 0.68, 0.0, 0.0, 0.08333333333333333, 0.041054720691390045, 0.1149384821505303, 0.0, 1.0, 0.1, 0.680299645289302], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.213082], dtype=float32), -0.72171444]. 
=============================================
[2019-04-24 10:02:44,281] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.2099577e-01 8.6715734e-03 5.2702475e-15 2.3419177e-14 2.8239979e-14
 1.2098597e-15 1.1077887e-15 2.2848743e-16 1.5296826e-12 7.0332751e-02
 2.0321635e-15], sum to 1.0000
[2019-04-24 10:02:44,326] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1194
[2019-04-24 10:02:44,368] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 44.0, 16.5, 93.5, 19.0, 20.53644475000414, -0.7893592929729825, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4903200.0000, 
sim time next is 4904400.0000, 
raw observation next is [1.666666666666667, 45.0, 0.0, 0.0, 19.0, 20.39399960163503, -0.8245631239103091, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.5087719298245615, 0.45, 0.0, 0.0, 0.08333333333333333, 0.19949996680291923, 0.22514562536323032, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.585466], dtype=float32), 0.5793441]. 
=============================================
[2019-04-24 10:02:45,667] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:45,958] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:46,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:46,673] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:46,675] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run5
[2019-04-24 10:02:50,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.21647131e-01 1.25974342e-02 4.41496204e-17 7.18291721e-16
 1.21576471e-15 1.91836386e-17 1.94829125e-17 3.17041971e-18
 1.88025160e-13 6.57554641e-02 1.01309614e-16], sum to 1.0000
[2019-04-24 10:02:50,394] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1684
[2019-04-24 10:02:50,457] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 35.0, 0.0, 0.0, 19.0, 22.0100301302249, -0.3996537136969822, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5006400.0000, 
sim time next is 5007600.0000, 
raw observation next is [3.0, 34.0, 0.0, 0.0, 19.0, 21.83175971866575, -0.4337050823995777, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.5457063711911359, 0.34, 0.0, 0.0, 0.08333333333333333, 0.31931330988881257, 0.3554316392001408, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3129753], dtype=float32), 0.2603615]. 
=============================================
[2019-04-24 10:02:51,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:51,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:52,079] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:52,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:52,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:52,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:52,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:52,635] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:52,638] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run5
[2019-04-24 10:02:53,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:53,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:53,087] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run5
[2019-04-24 10:02:53,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:53,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:53,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run5
[2019-04-24 10:02:53,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:53,835] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:54,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:54,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:54,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:54,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run5
[2019-04-24 10:02:54,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:54,690] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:54,820] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:54,903] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:55,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:55,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:55,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:55,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run5
[2019-04-24 10:02:55,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:55,593] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:55,595] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run5
[2019-04-24 10:02:55,761] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7733968e-01 2.7853698e-03 2.9327332e-19 2.3035824e-17 4.0890406e-17
 1.5541205e-19 9.3199939e-19 1.2290213e-19 2.2538992e-15 1.9874947e-02
 1.2846672e-18], sum to 1.0000
[2019-04-24 10:02:55,762] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1666
[2019-04-24 10:02:55,774] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.7, 19.0, 0.0, 0.0, 19.0, 23.77371371279806, 0.06265471118744291, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5090400.0000, 
sim time next is 5091600.0000, 
raw observation next is [8.6, 19.33333333333334, 0.0, 0.0, 19.0, 23.716180429569, -0.01333658254453435, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.700831024930748, 0.19333333333333338, 0.0, 0.0, 0.08333333333333333, 0.47634836913075, 0.4955544724851552, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6428929], dtype=float32), -0.032525152]. 
=============================================
[2019-04-24 10:02:55,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:55,913] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:55,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run5
[2019-04-24 10:02:55,984] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:56,286] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:56,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:56,997] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:56,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run5
[2019-04-24 10:02:57,350] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8346658e-01 2.2379927e-02 4.4449265e-15 3.8312713e-14 5.3538002e-14
 1.7242882e-15 3.3984105e-15 9.3599269e-16 1.1932748e-12 1.9415344e-01
 8.7271742e-16], sum to 1.0000
[2019-04-24 10:02:57,350] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0661
[2019-04-24 10:02:57,449] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 78.0, 56.5, 148.0, 22.5, 21.4000987871542, -0.5859363809040804, 1.0, 1.0, 60.0, 105.13729929037102], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 205200.0000, 
sim time next is 206400.0000, 
raw observation next is [-8.033333333333333, 77.0, 71.50000000000001, 49.33333333333332, 22.5, 22.14971487688472, -0.6760461589129759, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.24007386888273316, 0.77, 0.23833333333333337, 0.05451197053406997, 0.375, 0.34580957307372656, 0.2746512803623414, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.2252, 
noisyNet noise sample is [array([0.95497507], dtype=float32), 1.0460035]. 
=============================================
[2019-04-24 10:02:58,057] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:58,335] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:02:59,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:02:59,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:02:59,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run5
[2019-04-24 10:02:59,245] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:02:59,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:03:00,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:03:00,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:03:00,243] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run5
[2019-04-24 10:03:00,294] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:03:00,626] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_3 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:03:00,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:03:00,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_3 ERROR:Aborted (core dumped)

[2019-04-24 10:03:01,296] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:03:01,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:03:01,299] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run5
[2019-04-24 10:03:01,627] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:03:01,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:03:01,630] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run5
[2019-04-24 10:03:05,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2586420e-01 2.0951642e-02 1.6356869e-15 1.7737654e-14 1.6742565e-14
 1.9245101e-16 1.7039689e-15 1.0979257e-16 7.6009327e-13 1.5318413e-01
 1.3738758e-15], sum to 1.0000
[2019-04-24 10:03:05,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4360
[2019-04-24 10:03:05,469] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.966666666666667, 71.0, 0.0, 0.0, 19.0, 20.12545219231925, -0.9628302212943787, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 261600.0000, 
sim time next is 262800.0000, 
raw observation next is [-6.7, 67.0, 0.0, 0.0, 19.0, 19.62390373170635, -1.053449016423148, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.2770083102493075, 0.67, 0.0, 0.0, 0.08333333333333333, 0.1353253109755291, 0.14885032785895067, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00724975], dtype=float32), 0.1710055]. 
=============================================
[2019-04-24 10:03:07,818] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8547450e-01 2.2442060e-02 1.5033244e-13 2.1057449e-13 3.4821121e-13
 1.7770028e-14 7.4139290e-14 2.4435628e-14 2.2272960e-11 5.9208345e-01
 3.5020520e-14], sum to 1.0000
[2019-04-24 10:03:07,818] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0572
[2019-04-24 10:03:07,936] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.7, 63.0, 91.0, 447.5, 22.5, 22.66129807171966, -0.5671785072288901, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 295200.0000, 
sim time next is 296400.0000, 
raw observation next is [-11.33333333333333, 62.00000000000001, 88.33333333333333, 490.5, 22.5, 22.0830052437242, -0.6622505359528068, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.14866112650046176, 0.6200000000000001, 0.29444444444444445, 0.541988950276243, 0.375, 0.3402504369770168, 0.2792498213490644, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.3419, 
noisyNet noise sample is [array([-0.05866687], dtype=float32), 0.3654702]. 
=============================================
[2019-04-24 10:03:10,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.80402327e-01 1.69766713e-02 6.08557759e-19 4.85573631e-18
 1.55359276e-17 9.73638110e-19 1.94339240e-18 6.63312579e-20
 7.74673517e-16 1.02621056e-01 5.84811368e-19], sum to 1.0000
[2019-04-24 10:03:10,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7801
[2019-04-24 10:03:10,421] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.533333333333333, 94.0, 0.0, 0.0, 19.0, 21.64948816646526, -0.5391083694178681, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 13200.0000, 
sim time next is 14400.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 21.07678779571899, -0.6219276876049701, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.2563989829765824, 0.2926907707983433, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07144819], dtype=float32), 1.3091617]. 
=============================================
[2019-04-24 10:03:25,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.7864283e-01 1.3332885e-02 6.1375007e-16 3.5845935e-15 7.8735295e-15
 1.6489268e-16 4.8783322e-16 1.6270391e-16 6.5294341e-13 2.0802428e-01
 1.3169035e-15], sum to 1.0000
[2019-04-24 10:03:25,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7935
[2019-04-24 10:03:25,394] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 19.0, 21.04782926016914, -0.7520999841619941, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 255600.0000, 
sim time next is 256800.0000, 
raw observation next is [-4.1, 81.0, 0.0, 0.0, 19.0, 20.99003182531031, -0.5251428932690086, 0.0, 1.0, 60.0, 94.28746718673594], 
processed observation next is [1.0, 1.0, 0.3490304709141275, 0.81, 0.0, 0.0, 0.08333333333333333, 0.24916931877585924, 0.32495236891033047, 0.0, 1.0, 0.9, 0.9428746718673594], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37895814], dtype=float32), -0.7869129]. 
=============================================
[2019-04-24 10:03:28,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5038044e-01 4.4713761e-03 1.8647220e-20 7.6006712e-20 1.8904788e-19
 2.6461005e-21 2.5330112e-21 4.9844852e-22 3.1096432e-17 4.5148231e-02
 8.1988365e-21], sum to 1.0000
[2019-04-24 10:03:28,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6338
[2019-04-24 10:03:28,898] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.2, 66.0, 0.0, 0.0, 19.0, 23.1781756670058, 0.01957118890549535, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1119600.0000, 
sim time next is 1120800.0000, 
raw observation next is [12.0, 67.66666666666667, 0.0, 0.0, 19.0, 23.05113660264151, -0.004885660608353058, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.7950138504155125, 0.6766666666666667, 0.0, 0.0, 0.08333333333333333, 0.4209280502201258, 0.49837144646388226, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8477028], dtype=float32), -0.19781971]. 
=============================================
[2019-04-24 10:03:28,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9397115e-01 6.9313780e-03 1.7153095e-13 6.3119024e-12 1.1969361e-12
 5.3776384e-14 8.9720738e-14 2.2385329e-14 1.8786593e-10 9.9097461e-02
 1.7704986e-13], sum to 1.0000
[2019-04-24 10:03:28,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2094
[2019-04-24 10:03:29,010] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.63333333333333, 67.66666666666667, 0.0, 0.0, 22.5, 20.77295644703086, -0.4917147682390016, 1.0, 1.0, 60.0, 128.6852076357609], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 330000.0000, 
sim time next is 331200.0000, 
raw observation next is [-12.8, 70.0, 0.0, 0.0, 22.5, 21.81862693091786, -0.6283127259195421, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.1080332409972299, 0.7, 0.0, 0.0, 0.375, 0.3182189109098215, 0.290562424693486, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6004684], dtype=float32), 1.1220647]. 
=============================================
[2019-04-24 10:03:39,283] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.72808290e-01 7.44974473e-03 1.95350630e-17 4.38138611e-17
 2.13572555e-16 5.38483784e-18 1.09289559e-17 7.46009224e-19
 1.83154358e-14 3.19741964e-01 1.25827026e-17], sum to 1.0000
[2019-04-24 10:03:39,289] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4654
[2019-04-24 10:03:39,313] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.3, 88.0, 0.0, 0.0, 19.0, 21.87014211984348, -0.5749481958700834, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 525600.0000, 
sim time next is 526800.0000, 
raw observation next is [4.133333333333333, 87.33333333333334, 0.0, 0.0, 19.0, 21.29119839801162, -0.6935996256233804, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.577100646352724, 0.8733333333333334, 0.0, 0.0, 0.08333333333333333, 0.274266533167635, 0.26880012479220655, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4480141], dtype=float32), -1.5750386]. 
=============================================
[2019-04-24 10:03:42,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9019409e-01 1.4959026e-02 1.9177231e-16 5.6773728e-16 1.5359871e-15
 3.5623883e-17 7.0054297e-17 1.9954091e-17 5.5334470e-14 1.9484690e-01
 1.3006887e-16], sum to 1.0000
[2019-04-24 10:03:42,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7212
[2019-04-24 10:03:42,342] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.433333333333334, 86.0, 0.0, 0.0, 19.0, 21.19998087356491, -0.7198062028866611, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 537600.0000, 
sim time next is 538800.0000, 
raw observation next is [1.266666666666667, 87.0, 0.0, 0.0, 19.0, 20.45927186513131, -0.8451981009192825, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.4976915974145891, 0.87, 0.0, 0.0, 0.08333333333333333, 0.20493932209427582, 0.2182672996935725, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.79389817], dtype=float32), 1.2381281]. 
=============================================
[2019-04-24 10:03:43,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.25742984e-01 1.01558547e-02 6.34937750e-17 7.19860347e-17
 3.10294003e-16 3.52282781e-18 3.04720864e-17 4.61291579e-18
 3.28626862e-14 5.64101219e-01 1.08326274e-17], sum to 1.0000
[2019-04-24 10:03:43,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5387
[2019-04-24 10:03:43,834] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [2.9, 93.33333333333334, 0.0, 0.0, 19.0, 20.25425160670171, -0.8793433147512366, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 512400.0000, 
sim time next is 513600.0000, 
raw observation next is [3.1, 94.66666666666667, 0.0, 0.0, 19.0, 20.54793749657703, -0.5948621615558018, 0.0, 1.0, 60.0, 92.68926948056418], 
processed observation next is [1.0, 0.9565217391304348, 0.5484764542936289, 0.9466666666666668, 0.0, 0.0, 0.08333333333333333, 0.2123281247147526, 0.3017126128147327, 0.0, 1.0, 0.9, 0.9268926948056417], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4899005], dtype=float32), 0.1817058]. 
=============================================
[2019-04-24 10:03:51,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8658732e-01 1.8772408e-02 6.0102714e-14 1.2812047e-13 2.8651422e-13
 2.5097298e-14 3.9773686e-14 3.2157151e-15 2.2251553e-11 9.4640218e-02
 4.1527410e-14], sum to 1.0000
[2019-04-24 10:03:51,792] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5522
[2019-04-24 10:03:51,820] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 83.0, 0.0, 0.0, 19.0, 18.94482636873999, -0.9298021408886105, 0.0, 1.0, 60.0, 102.27818539542889], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1821600.0000, 
sim time next is 1822800.0000, 
raw observation next is [-6.066666666666666, 84.33333333333334, 0.0, 0.0, 19.0, 19.77196887927639, -1.046031141970721, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.2945521698984303, 0.8433333333333334, 0.0, 0.0, 0.08333333333333333, 0.14766407327303246, 0.15132295267642637, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.62838167], dtype=float32), -0.9240848]. 
=============================================
[2019-04-24 10:03:52,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7956909e-01 1.1127287e-02 7.9053866e-16 7.3679593e-15 4.0544867e-15
 7.6236161e-17 8.3532523e-17 9.7615465e-17 1.1508870e-12 2.0930354e-01
 4.0906045e-16], sum to 1.0000
[2019-04-24 10:03:52,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4568
[2019-04-24 10:03:52,886] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 84.66666666666666, 24.16666666666667, 0.0, 22.5, 24.0872746499329, -0.2950873945814091, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 837600.0000, 
sim time next is 838800.0000, 
raw observation next is [-3.9, 86.0, 14.5, 0.0, 22.5, 23.19608104153139, -0.3333174109098379, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.86, 0.04833333333333333, 0.0, 0.375, 0.43300675346094913, 0.3888941963633874, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7521544], dtype=float32), 0.7064666]. 
=============================================
[2019-04-24 10:04:00,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6747944e-01 4.0592314e-03 1.0698356e-20 2.8764278e-20 1.6172341e-19
 1.7011084e-21 2.0412174e-21 9.5179924e-23 3.7026520e-17 1.2846136e-01
 3.6255896e-21], sum to 1.0000
[2019-04-24 10:04:00,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7777
[2019-04-24 10:04:00,972] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 0.0, 0.0, 19.0, 22.14529127985858, -0.2856211728393261, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1026000.0000, 
sim time next is 1027200.0000, 
raw observation next is [14.4, 76.33333333333334, 0.0, 0.0, 19.0, 22.06477948159964, -0.3003347575604332, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.8614958448753465, 0.7633333333333334, 0.0, 0.0, 0.08333333333333333, 0.33873162346663666, 0.39988841414652226, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5615537], dtype=float32), -0.5785545]. 
=============================================
[2019-04-24 10:04:02,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6928698e-01 1.3179416e-03 5.8028762e-20 1.3329875e-18 1.1788056e-18
 8.4342825e-20 3.0054092e-20 8.0960189e-21 6.3151431e-16 2.9395027e-02
 7.6035082e-20], sum to 1.0000
[2019-04-24 10:04:02,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6421
[2019-04-24 10:04:02,321] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 58.66666666666667, 0.0, 0.0, 22.5, 25.01914172250846, 0.2041592889004325, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1531200.0000, 
sim time next is 1532400.0000, 
raw observation next is [10.16666666666667, 59.33333333333334, 0.0, 0.0, 22.5, 24.54333379027898, 0.2001415844745051, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.7442289935364729, 0.5933333333333334, 0.0, 0.0, 0.375, 0.5452778158565815, 0.5667138614915017, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.69006574], dtype=float32), 0.94863504]. 
=============================================
[2019-04-24 10:04:03,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.86962533e-01 1.19530978e-02 3.64820505e-16 3.33937763e-15
 1.04073689e-15 1.23650813e-17 3.99263902e-17 1.08202126e-16
 1.04162425e-12 1.01084262e-01 1.26826283e-16], sum to 1.0000
[2019-04-24 10:04:03,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7999
[2019-04-24 10:04:03,671] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 83.33333333333334, 0.0, 0.0, 22.5, 22.76615674875276, -0.352566279111795, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2056800.0000, 
sim time next is 2058000.0000, 
raw observation next is [-3.899999999999999, 84.66666666666666, 0.0, 0.0, 22.5, 21.92486673453493, -0.4804503643739, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.35457063711911363, 0.8466666666666666, 0.0, 0.0, 0.375, 0.32707222787791085, 0.33984987854203336, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.46596754], dtype=float32), -2.3139398]. 
=============================================
[2019-04-24 10:04:05,355] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.7176522e-01 2.2239927e-03 1.3240057e-16 5.2334913e-15 2.7300342e-15
 2.6131070e-16 7.1601828e-16 4.9299644e-17 2.8787018e-13 2.6010770e-02
 2.4276055e-15], sum to 1.0000
[2019-04-24 10:04:05,357] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3677
[2019-04-24 10:04:05,373] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 63.66666666666667, 169.1666666666667, 0.0, 19.0, 22.20262955263349, -0.1868730573614492, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1167600.0000, 
sim time next is 1168800.0000, 
raw observation next is [18.46666666666667, 64.33333333333333, 169.0, 0.0, 19.0, 22.2587144613794, -0.1757626550073191, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.9741458910433982, 0.6433333333333333, 0.5633333333333334, 0.0, 0.08333333333333333, 0.3548928717816168, 0.44141244833089366, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39682433], dtype=float32), -1.9738231]. 
=============================================
[2019-04-24 10:04:06,735] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2597512e-01 1.2579311e-02 4.1580310e-18 8.4928936e-17 3.8906003e-17
 2.2830677e-18 3.5646749e-18 8.7650529e-19 5.2024319e-15 1.6144556e-01
 2.1374663e-18], sum to 1.0000
[2019-04-24 10:04:06,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4069
[2019-04-24 10:04:06,762] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 21.83285185175932, -0.4482858983957951, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1317600.0000, 
sim time next is 1318800.0000, 
raw observation next is [1.433333333333334, 92.0, 0.0, 0.0, 19.0, 21.07782221951776, -0.5545156441730515, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.502308402585411, 0.92, 0.0, 0.0, 0.08333333333333333, 0.2564851849598133, 0.31516145194231615, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8991037], dtype=float32), -0.9624661]. 
=============================================
[2019-04-24 10:04:06,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.87932968e-01 2.38860603e-02 1.04976805e-17 6.54399722e-17
 2.70794527e-16 3.20790754e-18 2.28583773e-18 4.31332090e-18
 7.77167129e-15 2.88180918e-01 2.01910776e-18], sum to 1.0000
[2019-04-24 10:04:06,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1939
[2019-04-24 10:04:07,030] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 15.0, 0.0, 22.5, 22.74166623434041, -0.310457810438548, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1412400.0000, 
sim time next is 1413600.0000, 
raw observation next is [-0.6, 100.0, 22.66666666666666, 0.0, 22.5, 22.71366217425114, -0.3601590470900682, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.44598337950138506, 1.0, 0.07555555555555554, 0.0, 0.375, 0.39280518118759505, 0.3799469843033106, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47809368], dtype=float32), -1.24909]. 
=============================================
[2019-04-24 10:04:11,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8137370e-01 2.1242715e-02 2.0411459e-18 2.3230916e-17 5.6427151e-17
 1.1498288e-18 2.8424252e-18 3.3374349e-19 9.6768627e-15 9.7383626e-02
 8.6624984e-18], sum to 1.0000
[2019-04-24 10:04:11,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6957
[2019-04-24 10:04:11,910] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 96.0, 0.0, 0.0, 19.0, 21.41817167574114, -0.5899081899214188, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1484400.0000, 
sim time next is 1485600.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 20.83916654655177, -0.6755863917120882, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.23659721221264748, 0.2748045360959706, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.91931105], dtype=float32), 2.505528]. 
=============================================
[2019-04-24 10:04:15,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.74678338e-01 1.04500772e-03 1.07400245e-19 2.88837056e-18
 2.77377978e-18 4.67410457e-20 8.72658356e-20 1.46535142e-20
 4.54424018e-16 2.42766924e-02 3.40552533e-19], sum to 1.0000
[2019-04-24 10:04:15,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2486
[2019-04-24 10:04:15,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.8, 82.66666666666666, 0.0, 0.0, 19.0, 22.16191708629054, -0.2171730225887159, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1633200.0000, 
sim time next is 1634400.0000, 
raw observation next is [6.6, 86.0, 0.0, 0.0, 19.0, 22.04890402766656, -0.2394695765040598, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6454293628808865, 0.86, 0.0, 0.0, 0.08333333333333333, 0.3374086689722133, 0.4201768078319801, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07636854], dtype=float32), 1.3822483]. 
=============================================
[2019-04-24 10:04:17,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6838367e-01 5.3019967e-04 8.5138224e-20 3.2436635e-18 7.6016440e-19
 2.0420083e-20 2.2250339e-20 4.6775367e-21 4.5615128e-16 3.1086128e-02
 4.3783293e-20], sum to 1.0000
[2019-04-24 10:04:17,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4680
[2019-04-24 10:04:17,245] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.2, 50.0, 82.0, 253.0, 22.5, 24.52744655565316, 0.1793815041833267, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1526400.0000, 
sim time next is 1527600.0000, 
raw observation next is [11.63333333333333, 52.66666666666667, 85.33333333333333, 103.0, 22.5, 24.81876157305035, 0.2074886473680868, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.7848568790397045, 0.5266666666666667, 0.28444444444444444, 0.1138121546961326, 0.375, 0.5682301310875291, 0.569162882456029, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6847503], dtype=float32), 1.6764565]. 
=============================================
[2019-04-24 10:04:17,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6821231e-01 1.4260525e-03 2.1382172e-19 4.5535217e-18 4.8491218e-18
 1.9597736e-20 4.4080190e-20 1.2647216e-20 1.2933397e-15 3.0361660e-02
 1.5953654e-19], sum to 1.0000
[2019-04-24 10:04:17,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1672
[2019-04-24 10:04:17,583] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.933333333333334, 69.0, 0.0, 0.0, 22.5, 23.27293995280628, -0.03308707926873999, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1539600.0000, 
sim time next is 1540800.0000, 
raw observation next is [7.2, 73.0, 0.0, 0.0, 22.5, 23.06437053531292, -0.06334752217437982, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.662049861495845, 0.73, 0.0, 0.0, 0.375, 0.42203087794274347, 0.4788841592752067, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.401731], dtype=float32), 1.4026214]. 
=============================================
[2019-04-24 10:04:24,730] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.2054406e-01 5.2060075e-02 4.7293029e-13 9.3358524e-13 6.2511758e-13
 3.3740320e-13 2.9997931e-13 4.6412259e-14 9.3853168e-11 5.2739590e-01
 2.9842364e-13], sum to 1.0000
[2019-04-24 10:04:24,730] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0839
[2019-04-24 10:04:24,750] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.199999999999999, 72.33333333333333, 173.3333333333333, 67.5, 19.0, 18.35047572871545, -1.310536367239878, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1856400.0000, 
sim time next is 1857600.0000, 
raw observation next is [-5.0, 71.0, 152.0, 40.5, 19.0, 18.0090187211708, -1.364438500526592, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.32409972299168976, 0.71, 0.5066666666666667, 0.044751381215469614, 0.08333333333333333, 0.0007515600975667169, 0.045187166491136, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28779778], dtype=float32), -0.4357676]. 
=============================================
[2019-04-24 10:04:24,767] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3869398e-01 1.6354768e-02 2.7189808e-15 2.7121453e-14 3.5018176e-15
 3.1344608e-16 7.6133884e-16 3.4542390e-16 2.0319484e-12 1.4495125e-01
 4.6001015e-16], sum to 1.0000
[2019-04-24 10:04:24,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4327
[2019-04-24 10:04:24,777] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 39.0, 225.0, 46.5, 22.5, 22.99328417239729, -0.4320376223474106, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2548800.0000, 
sim time next is 2550000.0000, 
raw observation next is [1.466666666666667, 36.0, 220.3333333333333, 30.16666666666666, 22.5, 22.70790952086274, -0.474817189623894, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5032317636195753, 0.36, 0.7344444444444442, 0.033333333333333326, 0.375, 0.3923257934052282, 0.341727603458702, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9807695], dtype=float32), 0.35127392]. 
=============================================
[2019-04-24 10:04:24,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.35541 ]
 [71.493225]
 [71.24989 ]
 [70.092285]
 [69.845505]
 [69.86493 ]
 [70.66727 ]
 [70.24596 ]
 [70.34906 ]
 [70.29332 ]
 [69.41449 ]
 [69.68521 ]
 [68.92705 ]
 [68.95506 ]
 [67.75896 ]
 [67.59436 ]
 [67.173584]
 [67.47095 ]
 [67.763535]
 [67.37477 ]
 [66.47919 ]
 [66.61339 ]
 [66.62349 ]
 [66.69006 ]
 [65.854675]], R is [[71.49126434]
 [71.77635193]
 [72.05858612]
 [71.33799744]
 [71.40493774]
 [71.61408234]
 [71.89794159]
 [71.17896271]
 [70.98175049]
 [71.11973572]
 [70.40853882]
 [70.04016113]
 [69.8655777 ]
 [69.16692352]
 [69.47525787]
 [68.78050232]
 [68.09269714]
 [68.41177368]
 [68.7276535 ]
 [68.04037476]
 [67.35997009]
 [67.47029114]
 [67.79558563]
 [68.11763   ]
 [67.43645477]].
[2019-04-24 10:04:26,042] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.21843256e-01 3.27533484e-02 2.93428368e-13 1.85545765e-13
 7.71439932e-13 1.28759774e-14 6.28874462e-14 4.82031373e-14
 1.13849824e-11 8.45403373e-01 2.63711562e-14], sum to 1.0000
[2019-04-24 10:04:26,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7163
[2019-04-24 10:04:26,244] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-9.3, 89.33333333333334, 27.83333333333333, 17.66666666666667, 22.5, 18.8976070457457, -1.315793370958184, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1930800.0000, 
sim time next is 1932000.0000, 
raw observation next is [-9.100000000000001, 87.66666666666666, 41.66666666666666, 109.0, 22.5, 19.63730667708271, -0.9097042983082368, 1.0, 1.0, 60.0, 118.00784696498869], 
processed observation next is [1.0, 0.34782608695652173, 0.21052631578947364, 0.8766666666666666, 0.13888888888888887, 0.12044198895027625, 0.375, 0.13644222309022572, 0.1967652338972544, 1.0, 1.0, 0.9, 1.180078469649887], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7705784], dtype=float32), 0.15616745]. 
=============================================
[2019-04-24 10:04:29,760] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2663364e-01 6.1095417e-03 1.4900201e-14 6.6570522e-14 7.0406693e-14
 7.6686017e-16 3.1214591e-15 2.1411267e-15 1.5435290e-11 3.6725679e-01
 2.2905048e-15], sum to 1.0000
[2019-04-24 10:04:29,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0185
[2019-04-24 10:04:29,793] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.633333333333334, 65.0, 227.8333333333333, 5.0, 22.5, 21.76836782700982, -0.7588312220703651, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1945200.0000, 
sim time next is 1946400.0000, 
raw observation next is [-4.266666666666667, 65.0, 212.0, 3.333333333333333, 22.5, 21.15879345987902, -0.7494092077359467, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3444136657433057, 0.65, 0.7066666666666667, 0.0036832412523020255, 0.375, 0.26323278832325175, 0.25019693075468447, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0942, 
noisyNet noise sample is [array([1.3398678], dtype=float32), 0.340373]. 
=============================================
[2019-04-24 10:04:34,277] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-24 10:04:34,280] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:04:34,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:04:34,300] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:04:34,289] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:04:34,301] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:04:34,303] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:04:34,303] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run7
[2019-04-24 10:04:34,326] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run7
[2019-04-24 10:04:34,341] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run7
[2019-04-24 10:06:17,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3397.6926 65836.9385 -135.8558
[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,308] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:17,608] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:31,951] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3213.2611 80951.4286 -404.1996
[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:32,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,399] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3133.7364 81721.8551 -524.1622
[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,434] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:47,686] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:06:48,436] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 300000, evaluation results [300000.0, 3213.2610771235795, 80951.42858196536, -404.19961420498623, 3397.6925632106927, 65836.93852516216, -135.8557566693547, 3133.73643571224, 81721.85509127595, -524.1622258535119]
[2019-04-24 10:07:04,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2207888e-01 5.9688162e-02 6.4865919e-14 1.3474606e-13 3.6745962e-13
 1.5500710e-14 8.8519768e-14 1.2429966e-14 2.5448499e-11 5.1823294e-01
 1.1789394e-14], sum to 1.0000
[2019-04-24 10:07:04,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2753
[2019-04-24 10:07:04,806] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.66666666666667, 0.0, 0.0, 19.0, 18.86585312924446, -1.200799957328442, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2182800.0000, 
sim time next is 2184000.0000, 
raw observation next is [-5.8, 76.33333333333334, 0.0, 0.0, 19.0, 18.52775115773541, -1.251942202781706, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.30193905817174516, 0.7633333333333334, 0.0, 0.0, 0.08333333333333333, 0.04397926314461742, 0.082685932406098, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.1079, 
noisyNet noise sample is [array([-0.9231398], dtype=float32), -0.62666965]. 
=============================================
[2019-04-24 10:07:10,031] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.4429622e-01 1.0805510e-02 1.2022084e-13 3.6139158e-13 2.3733524e-13
 1.1650597e-14 1.8613873e-14 8.5556020e-15 1.4093911e-11 6.4489830e-01
 1.5442454e-14], sum to 1.0000
[2019-04-24 10:07:10,033] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9726
[2019-04-24 10:07:10,345] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-8.766666666666666, 88.33333333333334, 54.33333333333333, 19.83333333333333, 22.5, 21.17604497259976, -0.8070726299587547, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2277600.0000, 
sim time next is 2278800.0000, 
raw observation next is [-8.4, 87.0, 73.0, 27.5, 22.5, 21.75987237618939, -0.4588593932630728, 1.0, 1.0, 60.0, 111.36015406754818], 
processed observation next is [1.0, 0.391304347826087, 0.2299168975069252, 0.87, 0.24333333333333335, 0.03038674033149171, 0.375, 0.3133226980157824, 0.3470468689123091, 1.0, 1.0, 0.9, 1.1136015406754818], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6289213], dtype=float32), -1.3792605]. 
=============================================
[2019-04-24 10:07:15,386] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.1381094e-01 4.6187162e-02 5.9507270e-14 3.1215997e-13 7.4668781e-13
 4.0822333e-14 1.2417056e-13 1.6109549e-14 1.5138335e-11 1.4000195e-01
 1.0046148e-13], sum to 1.0000
[2019-04-24 10:07:15,389] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5290
[2019-04-24 10:07:15,419] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 40.0, 0.0, 0.0, 19.0, 19.12258544015461, -0.9754877978935493, 0.0, 1.0, 60.0, 98.51684896668584], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2514000.0000, 
sim time next is 2515200.0000, 
raw observation next is [-1.7, 42.0, 0.0, 0.0, 19.0, 19.94991097196858, -1.059560104865685, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.4155124653739613, 0.42, 0.0, 0.0, 0.08333333333333333, 0.16249258099738176, 0.14681329837810497, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15597245], dtype=float32), -0.020755596]. 
=============================================
[2019-04-24 10:07:18,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4189230e-01 1.1428659e-01 3.6864949e-11 2.6799236e-11 2.9847194e-11
 8.4858700e-12 2.0546238e-11 4.9141680e-12 2.0733053e-09 5.4382116e-01
 9.2504285e-12], sum to 1.0000
[2019-04-24 10:07:18,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1431
[2019-04-24 10:07:18,091] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 60.0, 0.0, 0.0, 19.0, 17.36201410295174, -1.532512489528692, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2440800.0000, 
sim time next is 2442000.0000, 
raw observation next is [-9.100000000000001, 60.33333333333334, 0.0, 0.0, 19.0, 17.11928828641255, -1.58537128191838, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.21052631578947364, 0.6033333333333334, 0.0, 0.0, 0.08333333333333333, -0.07339264279895404, -0.028457093972793352, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44124094], dtype=float32), -0.97656727]. 
=============================================
[2019-04-24 10:07:33,369] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0457448e-01 2.5510779e-02 2.4402829e-13 3.5752456e-13 6.0977259e-13
 2.8261800e-14 3.3638490e-14 3.5292932e-14 4.2703459e-11 4.6991476e-01
 2.2622014e-14], sum to 1.0000
[2019-04-24 10:07:33,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9785
[2019-04-24 10:07:33,551] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-13.33333333333333, 86.0, 94.16666666666667, 565.0, 22.5, 22.17894768956515, -0.5774226545912985, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2712000.0000, 
sim time next is 2713200.0000, 
raw observation next is [-12.66666666666667, 81.0, 100.3333333333333, 622.3333333333333, 22.5, 22.35146771379431, -0.3707676678053327, 1.0, 1.0, 60.0, 78.63048602659359], 
processed observation next is [1.0, 0.391304347826087, 0.11172668513388727, 0.81, 0.3344444444444443, 0.6876611418047881, 0.375, 0.3626223094828592, 0.37641077739822243, 1.0, 1.0, 0.9, 0.7863048602659358], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2511338], dtype=float32), 0.99030066]. 
=============================================
[2019-04-24 10:07:33,863] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5857583e-01 4.9759317e-02 2.5129077e-13 1.1255672e-12 5.6101602e-13
 9.7931286e-14 1.1906416e-13 3.5208727e-14 1.3205541e-10 2.9166490e-01
 3.6069397e-14], sum to 1.0000
[2019-04-24 10:07:33,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6627
[2019-04-24 10:07:33,948] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.0121079377126, -1.165459334495413, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2784000.0000, 
sim time next is 2785200.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.2530398933066, -0.9264896838150484, 0.0, 1.0, 20.0, 83.65337807640032], 
processed observation next is [1.0, 0.21739130434782608, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.1044199911088833, 0.19117010539498389, 0.0, 1.0, 0.1, 0.8365337807640032], 
reward next is 0.0635, 
noisyNet noise sample is [array([0.47499523], dtype=float32), -0.9084509]. 
=============================================
[2019-04-24 10:07:34,643] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.1973530e-01 8.1817852e-03 3.2527969e-15 8.6211793e-15 6.4417728e-15
 3.5582430e-16 1.9839464e-16 1.2941687e-16 1.4731353e-12 3.7208292e-01
 1.7112746e-15], sum to 1.0000
[2019-04-24 10:07:34,648] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7941
[2019-04-24 10:07:34,876] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.2, 62.0, 0.0, 0.0, 22.5, 21.94284909437884, -0.5009874003480163, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2662800.0000, 
sim time next is 2664000.0000, 
raw observation next is [-1.2, 63.0, 0.0, 0.0, 22.5, 22.43340637219337, -0.1390088469878273, 0.0, 1.0, 60.0, 116.26302186680898], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.63, 0.0, 0.0, 0.375, 0.36945053101611425, 0.4536637176707243, 0.0, 1.0, 0.9, 1.16263021866809], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4777104], dtype=float32), 0.81404847]. 
=============================================
[2019-04-24 10:07:38,987] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7102592e-01 6.1775468e-02 2.3547627e-13 3.8962046e-13 9.0583595e-13
 7.4906139e-14 2.8734513e-13 1.6981203e-14 3.3218789e-11 5.6719857e-01
 1.5441084e-13], sum to 1.0000
[2019-04-24 10:07:38,989] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1664
[2019-04-24 10:07:39,099] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 18.96128138634484, -1.197890634302117, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2785200.0000, 
sim time next is 2786400.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 18.6191504573916, -1.244817173264138, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.05159587144930011, 0.08506094224528733, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.4198, 
noisyNet noise sample is [array([0.0950057], dtype=float32), 0.16953698]. 
=============================================
[2019-04-24 10:07:40,041] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.88494885e-01 4.09496836e-02 4.25005490e-14 1.83668497e-13
 2.17984891e-13 8.58932320e-15 3.17123003e-14 7.23381807e-15
 3.46239391e-11 1.70555368e-01 1.29079054e-14], sum to 1.0000
[2019-04-24 10:07:40,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9906
[2019-04-24 10:07:40,224] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.35115051324741, -1.036980687293966, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2790000.0000, 
sim time next is 2791200.0000, 
raw observation next is [-6.666666666666667, 64.0, 0.0, 0.0, 22.5, 19.67487121013726, -0.80295647990477, 1.0, 1.0, 60.0, 125.89276233622266], 
processed observation next is [1.0, 0.30434782608695654, 0.27793167128347185, 0.64, 0.0, 0.0, 0.375, 0.13957260084477152, 0.23234784003174333, 1.0, 1.0, 0.9, 1.2589276233622266], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0970944], dtype=float32), -1.4976192]. 
=============================================
[2019-04-24 10:07:46,131] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3074688e-01 1.4731555e-02 3.4410488e-17 1.7037685e-16 7.4750254e-17
 4.0877947e-18 1.4010267e-17 9.0602768e-19 3.1108688e-14 4.5452160e-01
 3.5547500e-18], sum to 1.0000
[2019-04-24 10:07:46,155] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5153
[2019-04-24 10:07:46,240] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 100.0, 63.5, 0.0, 22.5, 22.73673678394161, -0.4508625546884001, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2887200.0000, 
sim time next is 2888400.0000, 
raw observation next is [0.3333333333333333, 97.66666666666667, 73.16666666666666, 0.0, 22.5, 22.37679223239567, -0.4888914784552464, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4718374884579871, 0.9766666666666667, 0.24388888888888885, 0.0, 0.375, 0.36473268603297243, 0.33703617384825124, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.17943935], dtype=float32), 0.85539085]. 
=============================================
[2019-04-24 10:07:53,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6472353e-01 4.8537385e-03 2.4061261e-17 4.2866545e-16 7.8508699e-16
 1.8487225e-17 5.4541506e-18 2.3832511e-18 4.5119670e-14 3.0422697e-02
 3.7891096e-17], sum to 1.0000
[2019-04-24 10:07:53,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2837
[2019-04-24 10:07:53,349] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6666666666666666, 71.33333333333333, 17.16666666666666, 155.6666666666667, 22.5, 20.91585488080364, -0.4060348172414654, 0.0, 1.0, 60.0, 136.57767540199586], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3483600.0000, 
sim time next is 3484800.0000, 
raw observation next is [-1.0, 71.0, 45.5, 253.0, 22.5, 22.32315246711724, -0.4609923063987362, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4349030470914128, 0.71, 0.15166666666666667, 0.2795580110497238, 0.375, 0.3602627055931033, 0.3463358978670879, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25966612], dtype=float32), 0.05452257]. 
=============================================
[2019-04-24 10:08:09,202] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.4053096e-01 5.7779434e-03 1.6291059e-17 1.9901310e-16 2.1337718e-16
 4.3097247e-18 7.2263019e-18 2.5481535e-18 2.1931294e-14 5.3691000e-02
 7.3028980e-18], sum to 1.0000
[2019-04-24 10:08:09,202] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3579
[2019-04-24 10:08:09,299] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 19.0, 21.56166984270712, -0.5868273399637606, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3459600.0000, 
sim time next is 3460800.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 19.0, 20.95654692548442, -0.7000602221260407, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 0.79, 0.0, 0.0, 0.08333333333333333, 0.24637891045703508, 0.2666465926246531, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7211851], dtype=float32), -1.6985769]. 
=============================================
[2019-04-24 10:08:11,295] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8873259e-01 3.9255615e-02 8.5214774e-14 3.0740680e-13 4.4880904e-13
 2.7326923e-14 5.3416235e-14 9.2595033e-15 3.3526685e-11 1.7201179e-01
 2.5267586e-14], sum to 1.0000
[2019-04-24 10:08:11,296] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6221
[2019-04-24 10:08:11,359] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.33333333333333, 76.0, 0.0, 0.0, 19.0, 20.44779162301699, -0.8902102112646527, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3302400.0000, 
sim time next is 3303600.0000, 
raw observation next is [-10.66666666666667, 76.0, 0.0, 0.0, 19.0, 19.46412173489663, -1.057948236666469, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.16712834718374878, 0.76, 0.0, 0.0, 0.08333333333333333, 0.1220101445747191, 0.14735058777784368, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2918974], dtype=float32), 1.3383058]. 
=============================================
[2019-04-24 10:08:20,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2401719e-01 1.0372659e-02 4.2468846e-17 2.5633591e-16 8.7686995e-16
 1.1257375e-17 1.8449656e-17 4.6771522e-18 1.8506711e-14 6.5610200e-02
 7.1769457e-18], sum to 1.0000
[2019-04-24 10:08:20,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3380
[2019-04-24 10:08:20,216] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 68.66666666666667, 0.0, 0.0, 19.0, 22.34001340120487, -0.5065996478763037, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3469200.0000, 
sim time next is 3470400.0000, 
raw observation next is [1.0, 67.0, 0.0, 0.0, 19.0, 21.44078139840293, -0.6692389333534371, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4903047091412743, 0.67, 0.0, 0.0, 0.08333333333333333, 0.2867317832002441, 0.2769203555488543, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.71844816], dtype=float32), -0.29162696]. 
=============================================
[2019-04-24 10:08:20,710] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.1284845e-01 5.4382947e-03 1.8131695e-17 2.9424710e-16 3.7509512e-16
 5.4601158e-18 2.1166170e-18 6.8263758e-18 2.6336856e-14 1.8171328e-01
 9.3309762e-18], sum to 1.0000
[2019-04-24 10:08:20,710] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8316
[2019-04-24 10:08:20,977] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 20.58028512495895, -0.7119930361200919, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3456000.0000, 
sim time next is 3457200.0000, 
raw observation next is [1.0, 83.66666666666667, 0.0, 0.0, 19.0, 20.99750515072041, -0.3935066703888477, 0.0, 1.0, 60.0, 96.80460356210995], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.8366666666666667, 0.0, 0.0, 0.08333333333333333, 0.24979209589336757, 0.3688311098703841, 0.0, 1.0, 0.9, 0.9680460356210995], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3883655], dtype=float32), -0.18463887]. 
=============================================
[2019-04-24 10:08:23,144] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.7030234e-01 1.1860268e-03 1.4414550e-17 1.2392468e-16 4.0838145e-16
 2.1477523e-18 5.3426946e-18 8.5545494e-19 5.0585163e-14 2.8511589e-02
 2.9592423e-17], sum to 1.0000
[2019-04-24 10:08:23,147] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4099
[2019-04-24 10:08:23,164] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 50.0, 21.16666666666666, 213.3333333333333, 22.5, 23.62595777754002, -0.1114649857157701, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3518400.0000, 
sim time next is 3519600.0000, 
raw observation next is [2.333333333333333, 51.0, 10.83333333333333, 125.8333333333333, 22.5, 23.32284948391264, -0.2359569732521944, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5272391505078486, 0.51, 0.0361111111111111, 0.13904235727440142, 0.375, 0.44357079032605345, 0.42134767558260183, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3498878], dtype=float32), -1.4327394]. 
=============================================
[2019-04-24 10:08:26,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7106320e-01 4.8962557e-03 1.4490949e-15 1.4209782e-14 1.1632135e-14
 4.5497713e-16 3.5517831e-16 3.7676364e-16 1.2225569e-12 2.4040531e-02
 2.0193274e-15], sum to 1.0000
[2019-04-24 10:08:26,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3018
[2019-04-24 10:08:26,821] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.333333333333333, 50.33333333333333, 102.1666666666667, 705.8333333333334, 22.5, 22.58991875724127, -0.172360465963492, 1.0, 1.0, 60.0, 115.56421730992022], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3922800.0000, 
sim time next is 3924000.0000, 
raw observation next is [-7.0, 49.0, 106.5, 733.5, 22.5, 23.77287264642207, -0.2197065881447012, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2686980609418283, 0.49, 0.355, 0.8104972375690608, 0.375, 0.4810727205351724, 0.426764470618433, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.44177577], dtype=float32), -0.71871173]. 
=============================================
[2019-04-24 10:08:30,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.76654029e-01 4.43061581e-03 4.11285636e-16 2.11403499e-15
 1.93857170e-15 4.49626761e-17 1.63377965e-16 1.28389979e-17
 3.97572302e-13 1.18915334e-01 1.02688815e-16], sum to 1.0000
[2019-04-24 10:08:30,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5195
[2019-04-24 10:08:30,053] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 67.0, 0.0, 0.0, 22.5, 21.53355796066496, -0.479579065460558, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3786000.0000, 
sim time next is 3787200.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 22.5, 21.3114884741172, -0.5161619470020128, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.40720221606648205, 0.65, 0.0, 0.0, 0.375, 0.2759573728431001, 0.32794601766599574, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9935, 
noisyNet noise sample is [array([-0.72198147], dtype=float32), -1.4174209]. 
=============================================
[2019-04-24 10:08:32,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.5095414e-01 1.4608548e-03 1.0558707e-17 5.3097229e-16 1.6502112e-16
 3.6730823e-18 6.3999059e-18 6.4977395e-18 1.4033151e-13 4.7584902e-02
 1.8305714e-17], sum to 1.0000
[2019-04-24 10:08:32,005] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4432
[2019-04-24 10:08:32,015] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 54.0, 116.3333333333333, 833.1666666666667, 22.5, 22.5260276081496, -0.3079417782406975, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3847200.0000, 
sim time next is 3848400.0000, 
raw observation next is [1.0, 51.0, 115.0, 829.5, 22.5, 22.67818158556896, -0.2910782546834545, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4903047091412743, 0.51, 0.38333333333333336, 0.9165745856353591, 0.375, 0.3898484654640801, 0.40297391510551517, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.78219825], dtype=float32), -0.083416834]. 
=============================================
[2019-04-24 10:08:35,718] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.4115418e-01 2.0572022e-03 1.6432415e-16 1.6903609e-15 4.5439945e-16
 2.6054264e-17 1.0789510e-17 2.5808942e-17 1.6911204e-13 5.6788582e-02
 1.5013168e-16], sum to 1.0000
[2019-04-24 10:08:35,720] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9708
[2019-04-24 10:08:35,832] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.0, 29.66666666666667, 116.6666666666667, 831.8333333333334, 22.5, 22.62202949335266, -0.3183831935617979, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4108800.0000, 
sim time next is 4110000.0000, 
raw observation next is [3.0, 30.33333333333333, 114.3333333333333, 824.0, 22.5, 23.34506538840702, 0.01681342122874092, 1.0, 1.0, 60.0, 83.67312802071034], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.3033333333333333, 0.381111111111111, 0.9104972375690608, 0.375, 0.4454221157005849, 0.5056044737429136, 1.0, 1.0, 0.9, 0.8367312802071034], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04205835], dtype=float32), 0.3240666]. 
=============================================
[2019-04-24 10:08:35,841] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[75.32919 ]
 [74.883514]
 [74.44717 ]
 [74.0237  ]
 [73.75739 ]
 [73.27439 ]
 [72.787964]
 [72.422714]
 [72.17017 ]
 [72.68315 ]
 [71.995964]
 [71.71729 ]
 [71.76786 ]
 [70.41096 ]
 [68.468346]
 [67.71565 ]
 [66.55964 ]
 [66.10646 ]
 [65.31835 ]
 [65.08798 ]
 [64.419334]
 [64.837616]
 [64.31113 ]
 [64.468124]
 [63.62071 ]], R is [[75.89054871]
 [76.1316452 ]
 [76.37033081]
 [76.60662842]
 [76.84056091]
 [77.07215881]
 [77.30143738]
 [77.52842712]
 [77.75314331]
 [77.97560883]
 [77.19585419]
 [77.42389679]
 [77.6496582 ]
 [76.87316132]
 [76.37142181]
 [76.47486115]
 [75.91753387]
 [75.15835571]
 [74.40677643]
 [74.6627121 ]
 [73.91608429]
 [74.17692566]
 [73.70982361]
 [73.97272491]
 [73.23300171]].
[2019-04-24 10:08:36,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5167059e-01 1.0448627e-02 8.0956198e-19 1.2060650e-17 1.5965580e-17
 4.3182729e-19 1.4222409e-18 2.5269778e-19 3.1287512e-15 3.7880678e-02
 4.4316527e-19], sum to 1.0000
[2019-04-24 10:08:36,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6656
[2019-04-24 10:08:36,813] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.666666666666667, 67.0, 0.0, 0.0, 19.0, 22.23305161627837, -0.3345454397877545, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4419600.0000, 
sim time next is 4420800.0000, 
raw observation next is [4.5, 67.0, 0.0, 0.0, 19.0, 22.1677001595535, -0.3752801106096575, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5872576177285319, 0.67, 0.0, 0.0, 0.08333333333333333, 0.3473083466294584, 0.37490662979678085, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7415752], dtype=float32), -2.5099301]. 
=============================================
[2019-04-24 10:08:37,398] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.5009035e-01 2.0117804e-02 8.7857347e-14 2.2694956e-12 7.7393224e-13
 3.3856524e-14 5.0808963e-14 3.8909797e-14 5.0766027e-11 2.9791793e-02
 3.2366950e-13], sum to 1.0000
[2019-04-24 10:08:37,398] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7596
[2019-04-24 10:08:37,418] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.33333333333333, 65.0, 0.0, 0.0, 19.0, 19.97070225836925, -0.8042359020686987, 0.0, 1.0, 60.0, 90.1795731045948], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3990000.0000, 
sim time next is 3991200.0000, 
raw observation next is [-12.66666666666667, 67.0, 0.0, 0.0, 19.0, 20.23714683892593, -0.9769736952552196, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.11172668513388727, 0.67, 0.0, 0.0, 0.08333333333333333, 0.18642890324382755, 0.17434210158159347, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4239816], dtype=float32), -0.83037525]. 
=============================================
[2019-04-24 10:08:40,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.28521490e-01 6.26303814e-03 4.24331015e-17 8.57496451e-16
 1.30786016e-15 7.87849250e-18 2.70053741e-17 1.29888946e-17
 2.07785354e-13 1.65215448e-01 7.64198750e-17], sum to 1.0000
[2019-04-24 10:08:40,314] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0449
[2019-04-24 10:08:40,377] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 0.0, 0.0, 22.5, 22.57436471879006, -0.2870428182700703, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4561200.0000, 
sim time next is 4562400.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 22.3667605996657, -0.3406008737186175, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.3638967166388083, 0.38646637542712753, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5853093], dtype=float32), 0.8805732]. 
=============================================
[2019-04-24 10:08:42,790] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:08:42,971] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:08:43,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6071903e-01 1.9322529e-02 8.3380839e-15 7.1491600e-14 1.5479976e-13
 1.1291265e-14 8.8169235e-15 7.5657152e-16 3.8768134e-12 1.1995852e-01
 1.2674642e-14], sum to 1.0000
[2019-04-24 10:08:43,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0146
[2019-04-24 10:08:43,619] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.5, 41.66666666666667, 0.0, 0.0, 19.0, 19.85341401027786, -0.9516107112821443, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4214400.0000, 
sim time next is 4215600.0000, 
raw observation next is [1.4, 42.0, 0.0, 0.0, 19.0, 19.68613266851899, -0.982117575672623, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.5013850415512465, 0.42, 0.0, 0.0, 0.08333333333333333, 0.14051105570991584, 0.17262747477579232, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13126482], dtype=float32), -1.4302222]. 
=============================================
[2019-04-24 10:08:43,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:08:43,793] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:08:43,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run6
[2019-04-24 10:08:45,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6157427e-01 1.7342534e-02 4.6922454e-16 1.6748092e-15 2.4123511e-15
 8.0591188e-17 2.2180752e-16 1.7207031e-17 1.4542547e-13 2.2108316e-01
 2.1355364e-16], sum to 1.0000
[2019-04-24 10:08:45,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0151
[2019-04-24 10:08:45,632] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 73.0, 0.0, 0.0, 19.0, 19.86880502832157, -0.8856859076692903, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4500000.0000, 
sim time next is 4501200.0000, 
raw observation next is [-0.7333333333333334, 73.0, 0.0, 0.0, 19.0, 19.71587269531835, -0.9171273491148352, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.44228993536472766, 0.73, 0.0, 0.0, 0.08333333333333333, 0.14298939127652913, 0.19429088362838828, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.31390122], dtype=float32), 0.041946523]. 
=============================================
[2019-04-24 10:08:46,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2369871e-01 2.3502275e-02 2.5323852e-14 3.0099790e-14 9.1207911e-14
 8.1840891e-15 1.2442644e-14 4.4532461e-15 6.5770887e-12 3.5279900e-01
 2.0143929e-14], sum to 1.0000
[2019-04-24 10:08:46,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4904
[2019-04-24 10:08:46,972] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 78.0, 0.0, 0.0, 19.0, 20.35730285492192, -0.7886126103960845, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4760400.0000, 
sim time next is 4761600.0000, 
raw observation next is [-5.333333333333334, 85.0, 0.0, 0.0, 19.0, 20.04128868391361, -0.8448692377588322, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.31486611265004616, 0.85, 0.0, 0.0, 0.08333333333333333, 0.17010739032613417, 0.21837692074705595, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09550045], dtype=float32), -1.7893151]. 
=============================================
[2019-04-24 10:08:48,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6742564e-01 1.9990094e-03 1.3750020e-19 1.1141357e-18 1.7820961e-18
 2.0995161e-20 7.6145995e-20 1.2817839e-20 4.8213841e-16 3.0575247e-02
 2.2338504e-19], sum to 1.0000
[2019-04-24 10:08:48,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1112
[2019-04-24 10:08:48,567] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.86666666666667, 39.33333333333334, 113.6666666666667, 762.8333333333333, 22.5, 23.75110938232656, -0.17498838966839, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4357200.0000, 
sim time next is 4358400.0000, 
raw observation next is [11.73333333333333, 36.66666666666666, 115.8333333333333, 788.0, 22.5, 23.55845704669653, -0.1756235267815771, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7876269621421976, 0.3666666666666666, 0.386111111111111, 0.8707182320441988, 0.375, 0.46320475389137766, 0.441458824406141, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4741672], dtype=float32), 0.16648357]. 
=============================================
[2019-04-24 10:08:51,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.16412771e-01 5.70223387e-03 1.25824230e-17 5.17229585e-17
 4.17087494e-17 5.12730384e-19 2.20084016e-18 9.05368619e-19
 1.32690405e-14 7.78849721e-02 2.59108785e-18], sum to 1.0000
[2019-04-24 10:08:51,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1934
[2019-04-24 10:08:51,548] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 80.33333333333334, 67.33333333333334, 0.0, 22.5, 22.44593651489554, -0.3172426742892818, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4462800.0000, 
sim time next is 4464000.0000, 
raw observation next is [0.0, 78.0, 60.0, 0.0, 22.5, 22.58617332985986, -0.3131338988211393, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.46260387811634357, 0.78, 0.2, 0.0, 0.375, 0.38218111082165507, 0.39562203372628685, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.46150678], dtype=float32), -0.2258654]. 
=============================================
[2019-04-24 10:08:52,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1559399e-01 4.6108134e-02 2.2438620e-16 5.9548841e-16 2.7171364e-15
 7.8647466e-17 1.7932058e-16 5.0990593e-17 2.1916524e-13 2.3829792e-01
 1.3834794e-16], sum to 1.0000
[2019-04-24 10:08:52,025] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8473
[2019-04-24 10:08:52,076] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.9333333333333333, 71.0, 0.0, 0.0, 19.0, 19.56238908199986, -0.991312020982118, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4513200.0000, 
sim time next is 4514400.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 19.0, 19.68541069687269, -0.7777983545408325, 0.0, 1.0, 60.0, 85.4074491805111], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.71, 0.0, 0.0, 0.08333333333333333, 0.14045089140605752, 0.24073388181972252, 0.0, 1.0, 0.9, 0.854074491805111], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.78422946], dtype=float32), 1.5363526]. 
=============================================
[2019-04-24 10:08:57,070] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:08:57,239] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:08:58,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:08:58,081] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:08:58,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run6
[2019-04-24 10:08:58,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:08:58,535] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:08:59,298] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:08:59,299] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:08:59,302] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run6
[2019-04-24 10:09:04,183] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1871210e-01 2.7198846e-02 3.0360280e-15 9.7430871e-15 1.7364094e-14
 4.0499022e-16 5.5091012e-16 2.1930415e-16 5.8657701e-13 4.5408905e-01
 1.3907950e-16], sum to 1.0000
[2019-04-24 10:09:04,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4829
[2019-04-24 10:09:04,190] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.3, 80.0, 0.0, 0.0, 19.0, 19.16904882246359, -1.118135679074211, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 258000.0000, 
sim time next is 259200.0000, 
raw observation next is [-4.5, 79.0, 0.0, 0.0, 19.0, 18.91711797213721, -1.165573954963617, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3379501385041552, 0.79, 0.0, 0.0, 0.08333333333333333, 0.07642649767810077, 0.11147534834546098, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9725, 
noisyNet noise sample is [array([-0.08707264], dtype=float32), 1.1393325]. 
=============================================
[2019-04-24 10:09:05,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:05,819] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:06,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:06,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:06,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:06,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run6
[2019-04-24 10:09:06,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:06,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.41990376e-01 4.49968548e-03 3.47279803e-17 2.01662994e-16
 4.26708914e-16 7.39745554e-18 1.00450746e-17 3.36306181e-18
 8.73119258e-14 5.35099283e-02 2.92657626e-17], sum to 1.0000
[2019-04-24 10:09:06,878] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7403
[2019-04-24 10:09:06,907] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 0.0, 0.0, 19.0, 21.99649202498448, -0.3620110425257551, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5004000.0000, 
sim time next is 5005200.0000, 
raw observation next is [3.0, 36.0, 0.0, 0.0, 19.0, 21.85494207502951, -0.450204148503343, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.5457063711911359, 0.36, 0.0, 0.0, 0.08333333333333333, 0.32124517291912574, 0.34993195049888565, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.35677987], dtype=float32), -0.27041453]. 
=============================================
[2019-04-24 10:09:07,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:07,553] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:07,558] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run6
[2019-04-24 10:09:07,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:07,907] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:08,444] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:08,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:08,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:08,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:08,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run6
[2019-04-24 10:09:09,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:09,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:09,463] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run6
[2019-04-24 10:09:09,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:10,034] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:10,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:10,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:10,836] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run6
[2019-04-24 10:09:10,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:11,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:11,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:11,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:11,939] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:11,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:11,941] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:11,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run6
[2019-04-24 10:09:12,128] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:12,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:12,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:12,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run6
[2019-04-24 10:09:12,716] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:12,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:12,946] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:12,950] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run6
[2019-04-24 10:09:12,989] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:13,275] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:13,367] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:13,382] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:13,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:13,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_4 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:09:13,605] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:13,665] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:13,698] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:13,699] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:13,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run6
[2019-04-24 10:09:13,791] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_4 ERROR:Aborted (core dumped)

[2019-04-24 10:09:14,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:14,276] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:14,279] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run6
[2019-04-24 10:09:14,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:14,369] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:14,373] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run6
[2019-04-24 10:09:14,385] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:14,455] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:14,459] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run6
[2019-04-24 10:09:14,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:09:14,514] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:09:14,518] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run6
[2019-04-24 10:09:21,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7890476e-01 7.3795952e-03 3.2553220e-19 1.7829198e-18 7.4982740e-18
 1.9031998e-19 3.0180512e-19 4.8765166e-20 3.1275972e-16 1.1371567e-01
 2.8119209e-19], sum to 1.0000
[2019-04-24 10:09:21,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9460
[2019-04-24 10:09:21,780] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [7.7, 93.0, 56.33333333333333, 0.0, 19.0, 20.64756388222904, -0.4664985939425808, 0.0, 1.0, 20.0, 75.12317634447274], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 37200.0000, 
sim time next is 38400.0000, 
raw observation next is [7.699999999999999, 93.0, 62.5, 0.0, 19.0, 21.86223579913657, -0.3175493397527356, 0.0, 1.0, 60.0, 60.935400922188165], 
processed observation next is [0.0, 0.43478260869565216, 0.6759002770083103, 0.93, 0.20833333333333334, 0.0, 0.08333333333333333, 0.32185298326138084, 0.39415022008242145, 0.0, 1.0, 0.9, 0.6093540092218817], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.665649], dtype=float32), 1.2391455]. 
=============================================
[2019-04-24 10:09:25,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1153948e-01 2.0209162e-02 3.7842959e-15 4.1188237e-14 1.1514126e-14
 5.6955882e-16 2.4905558e-15 3.1292715e-15 2.5594930e-12 3.6825141e-01
 1.2920587e-15], sum to 1.0000
[2019-04-24 10:09:25,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9077
[2019-04-24 10:09:25,358] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.8, 86.0, 187.0, 24.5, 22.5, 22.39564649612824, -0.5490598492105251, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 126000.0000, 
sim time next is 127200.0000, 
raw observation next is [-8.0, 77.66666666666667, 185.0, 16.83333333333333, 22.5, 22.20941595530976, -0.3758941925889913, 1.0, 1.0, 60.0, 87.30689522198197], 
processed observation next is [1.0, 0.4782608695652174, 0.24099722991689754, 0.7766666666666667, 0.6166666666666667, 0.018600368324125226, 0.375, 0.35078466294247984, 0.37470193580366956, 1.0, 1.0, 0.9, 0.8730689522198197], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0377016], dtype=float32), 0.13195534]. 
=============================================
[2019-04-24 10:09:30,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.18149352e-01 4.39542020e-03 1.33752466e-17 5.09265656e-17
 1.69173880e-16 1.09061522e-17 1.23430253e-17 2.16371526e-18
 8.13144006e-15 7.74552971e-02 1.28667746e-17], sum to 1.0000
[2019-04-24 10:09:30,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8428
[2019-04-24 10:09:30,115] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.233333333333334, 88.66666666666667, 0.0, 0.0, 19.0, 21.54491985240202, -0.5310654219153542, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 76800.0000, 
sim time next is 78000.0000, 
raw observation next is [0.8666666666666667, 92.33333333333334, 0.0, 0.0, 19.0, 20.90322673980147, -0.6617621258401459, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.4866112650046169, 0.9233333333333335, 0.0, 0.0, 0.08333333333333333, 0.24193556165012264, 0.2794126247199514, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1809998], dtype=float32), -0.33088273]. 
=============================================
[2019-04-24 10:09:30,186] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5697753e-01 1.2136403e-02 2.5058192e-14 1.6316567e-14 1.6442969e-14
 8.9653260e-16 2.0577640e-16 6.2719275e-16 6.8853317e-12 7.3088610e-01
 1.2315397e-15], sum to 1.0000
[2019-04-24 10:09:30,187] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3870
[2019-04-24 10:09:30,475] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.8, 86.0, 187.0, 24.5, 22.5, 21.54790498078171, -0.6560072361691356, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 126000.0000, 
sim time next is 127200.0000, 
raw observation next is [-8.0, 77.66666666666667, 185.0, 16.83333333333333, 22.5, 22.38680976035988, -0.2474692804939252, 1.0, 1.0, 60.0, 121.06864060144848], 
processed observation next is [1.0, 0.4782608695652174, 0.24099722991689754, 0.7766666666666667, 0.6166666666666667, 0.018600368324125226, 0.375, 0.3655674800299901, 0.4175102398353583, 1.0, 1.0, 0.9, 1.2106864060144849], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05227186], dtype=float32), -0.5149535]. 
=============================================
[2019-04-24 10:09:32,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4498442e-01 1.5814338e-02 2.7694138e-15 1.4227802e-14 9.9214739e-15
 2.8278288e-16 3.9147155e-16 4.3568971e-16 3.9636176e-13 3.3920127e-01
 4.2321062e-16], sum to 1.0000
[2019-04-24 10:09:32,979] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8277
[2019-04-24 10:09:33,114] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.9, 75.0, 0.0, 0.0, 19.0, 19.92759988150713, -0.9380584532071105, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 252000.0000, 
sim time next is 253200.0000, 
raw observation next is [-3.9, 77.33333333333334, 0.0, 0.0, 19.0, 20.32331161487238, -0.6264555255801937, 0.0, 1.0, 60.0, 101.65492459474518], 
processed observation next is [1.0, 0.9565217391304348, 0.3545706371191136, 0.7733333333333334, 0.0, 0.0, 0.08333333333333333, 0.19360930123936507, 0.29118149147326877, 0.0, 1.0, 0.9, 1.0165492459474519], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04639876], dtype=float32), -1.3955721]. 
=============================================
[2019-04-24 10:09:43,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3562350e-01 4.9869763e-03 7.2707103e-19 3.0372037e-18 9.2789027e-18
 8.2594010e-20 4.6301910e-19 4.8308792e-20 1.7351101e-15 1.5938954e-01
 7.7596738e-19], sum to 1.0000
[2019-04-24 10:09:43,365] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3926
[2019-04-24 10:09:43,375] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.166666666666667, 93.66666666666666, 0.0, 0.0, 19.0, 20.78092347691469, -0.6666316733906292, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 951600.0000, 
sim time next is 952800.0000, 
raw observation next is [5.333333333333334, 91.33333333333333, 0.0, 0.0, 19.0, 20.64334585422835, -0.7021097344673645, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6103416435826409, 0.9133333333333333, 0.0, 0.0, 0.08333333333333333, 0.22027882118569586, 0.26596342184421184, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16957518], dtype=float32), 0.28799617]. 
=============================================
[2019-04-24 10:09:46,036] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5623720e-01 1.0168215e-02 5.1876770e-13 4.7214095e-12 3.4854021e-12
 1.9022544e-13 2.6383100e-13 1.7393354e-13 1.6246711e-10 3.3594526e-02
 8.4015976e-13], sum to 1.0000
[2019-04-24 10:09:46,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0310
[2019-04-24 10:09:46,061] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-14.5, 69.0, 0.0, 0.0, 19.0, 19.25712247167924, -0.9812561743705429, 0.0, 1.0, 60.0, 92.44453682168935], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 349200.0000, 
sim time next is 350400.0000, 
raw observation next is [-14.66666666666667, 69.0, 0.0, 0.0, 19.0, 19.60520704274713, -1.133742632475748, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.05632502308402576, 0.69, 0.0, 0.0, 0.08333333333333333, 0.1337672535622607, 0.12208578917475066, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.54715836], dtype=float32), 0.448991]. 
=============================================
[2019-04-24 10:09:50,456] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.3465327e-01 1.1085160e-02 2.5168561e-12 2.2684330e-11 1.8071248e-11
 2.8651102e-13 1.0167971e-12 5.1278171e-13 4.5713197e-10 3.5426164e-01
 6.6938425e-13], sum to 1.0000
[2019-04-24 10:09:50,473] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9001
[2019-04-24 10:09:50,723] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-9.5, 40.0, 0.0, 0.0, 22.5, 20.68553341298087, -0.8436453264297666, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 410400.0000, 
sim time next is 411600.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 22.5, 21.53741933936232, -0.448479590613053, 1.0, 1.0, 60.0, 124.63198909868], 
processed observation next is [1.0, 0.782608695652174, 0.1994459833795014, 0.4, 0.0, 0.0, 0.375, 0.29478494494686, 0.35050680312898236, 1.0, 1.0, 0.9, 1.2463198909867998], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07082688], dtype=float32), 0.2615967]. 
=============================================
[2019-04-24 10:09:56,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.41509789e-01 1.31113855e-02 1.03215877e-15 6.53497248e-16
 2.16370501e-15 3.10987935e-16 2.47545220e-16 2.14664354e-17
 2.04654924e-13 6.45378888e-01 1.45071492e-16], sum to 1.0000
[2019-04-24 10:09:56,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5835
[2019-04-24 10:09:56,352] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.7000000000000001, 90.66666666666666, 0.0, 0.0, 19.0, 19.32641239515585, -1.045888385193997, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 542400.0000, 
sim time next is 543600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 19.72595686900944, -0.7510131426241845, 0.0, 1.0, 60.0, 96.1944729753956], 
processed observation next is [0.0, 0.30434782608695654, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.14382973908412003, 0.2496622857919385, 0.0, 1.0, 0.9, 0.961944729753956], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8508286], dtype=float32), -0.026771542]. 
=============================================
[2019-04-24 10:09:58,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5804764e-01 3.6959338e-03 1.5581014e-17 1.1167413e-16 1.5066371e-16
 2.4952193e-18 4.8352868e-18 7.7231083e-19 1.0971352e-14 2.3825654e-01
 2.4726395e-18], sum to 1.0000
[2019-04-24 10:09:58,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5428
[2019-04-24 10:09:58,048] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.78583005311337, -0.4560082481078696, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1388400.0000, 
sim time next is 1389600.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 21.12518960314317, -0.5495712496076665, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.2604324669285975, 0.3168095834641112, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4802155], dtype=float32), -0.48255607]. 
=============================================
[2019-04-24 10:09:58,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7841245e-01 5.8134354e-04 1.1392324e-17 2.8794668e-16 6.1584245e-16
 2.3433373e-18 4.0514115e-18 2.2802603e-18 5.1348354e-14 2.1006253e-02
 3.0069673e-17], sum to 1.0000
[2019-04-24 10:09:58,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3184
[2019-04-24 10:09:58,799] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 46.66666666666667, 87.5, 763.1666666666667, 22.5, 22.96526712617823, -0.05526714603699458, 1.0, 1.0, 60.0, 114.37007038044011], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 740400.0000, 
sim time next is 741600.0000, 
raw observation next is [0.5, 45.0, 84.5, 743.5, 22.5, 24.22860509282651, -0.1073638820378311, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.4764542936288089, 0.45, 0.2816666666666667, 0.8215469613259668, 0.375, 0.519050424402209, 0.46421203932072297, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.53614634], dtype=float32), 0.039622314]. 
=============================================
[2019-04-24 10:10:00,081] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-24 10:10:00,083] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:10:00,086] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:10:00,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run8
[2019-04-24 10:10:00,101] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:10:00,103] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:10:00,103] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:10:00,104] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:10:00,106] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run8
[2019-04-24 10:10:00,122] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run8
[2019-04-24 10:11:48,340] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3425.1903 68757.8095 -123.1863
[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,371] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:48,553] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:56,893] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3185.3440 82095.0514 -384.0292
[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:56,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:11:57,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,126] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3163.6606 84424.1745 -461.5333
[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,157] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:08,342] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:12:09,159] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 350000, evaluation results [350000.0, 3185.3440288772977, 82095.05141318981, -384.02918699712933, 3425.1902953311956, 68757.80952357239, -123.18631549056208, 3163.660612740138, 84424.17446950596, -461.5333316697655]
[2019-04-24 10:12:22,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0364015e-01 3.6416261e-03 1.9534605e-17 1.2364867e-16 1.8422965e-16
 3.4570581e-18 2.8141086e-18 1.4630567e-18 5.0167583e-14 9.2718244e-02
 1.1245972e-17], sum to 1.0000
[2019-04-24 10:12:22,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4199
[2019-04-24 10:12:22,387] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 84.0, 72.16666666666667, 0.0, 22.5, 22.79764722361387, -0.2337191429559358, 1.0, 1.0, 60.0, 113.19655670398848], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 901200.0000, 
sim time next is 902400.0000, 
raw observation next is [1.1, 84.0, 80.33333333333334, 0.0, 22.5, 23.72202467741216, -0.3012603456265344, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.49307479224376743, 0.84, 0.26777777777777784, 0.0, 0.375, 0.47683538978434675, 0.3995798847911552, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8186818], dtype=float32), 0.03155042]. 
=============================================
[2019-04-24 10:12:35,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9191523e-01 2.8658143e-04 4.6719244e-18 1.3269085e-16 2.2518924e-16
 7.7516584e-19 2.9365925e-18 1.4504783e-18 6.0937461e-14 7.7982266e-03
 5.3675585e-17], sum to 1.0000
[2019-04-24 10:12:35,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3144
[2019-04-24 10:12:35,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 49.0, 100.0, 0.0, 22.5, 26.13379099881757, 0.4899953252285501, 1.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1092000.0000, 
sim time next is 1093200.0000, 
raw observation next is [19.4, 49.0, 82.5, 0.0, 22.5, 25.2815020264821, 0.5066526950122165, 1.0, 0.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.49, 0.275, 0.0, 0.375, 0.6067918355401751, 0.6688842316707388, 1.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5558371], dtype=float32), -0.357513]. 
=============================================
[2019-04-24 10:12:53,001] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.62586617e-01 1.85507555e-02 5.73252656e-19 1.29087439e-18
 3.68120436e-18 5.82428881e-19 2.36924173e-18 3.63711994e-20
 1.28618703e-15 1.18862644e-01 3.81386717e-19], sum to 1.0000
[2019-04-24 10:12:53,033] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3929
[2019-04-24 10:12:53,103] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.1, 77.0, 0.0, 0.0, 19.0, 21.45620342835807, -0.3572270612205948, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1135200.0000, 
sim time next is 1136400.0000, 
raw observation next is [11.1, 77.0, 0.0, 0.0, 19.0, 21.40931547858391, -0.3708763448962538, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.7700831024930749, 0.77, 0.0, 0.0, 0.08333333333333333, 0.2841096232153258, 0.3763745517012487, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9627984], dtype=float32), -1.4424641]. 
=============================================
[2019-04-24 10:12:55,748] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6146595e-01 2.4341701e-03 6.7730171e-17 7.4915903e-16 3.2495837e-15
 6.0644191e-17 2.6824104e-16 2.3000645e-17 4.4048058e-14 3.6099784e-02
 5.3525891e-16], sum to 1.0000
[2019-04-24 10:12:55,781] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6456
[2019-04-24 10:12:55,853] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 22.19567048062619, -0.1749177486453677, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1231200.0000, 
sim time next is 1232400.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 22.14446049532532, -0.1796555267227294, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.3453717079437766, 0.4401148244257569, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7802673], dtype=float32), -0.458975]. 
=============================================
[2019-04-24 10:13:03,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5023489e-01 1.4255663e-03 3.4840665e-18 1.9878144e-17 4.3143954e-17
 1.0015540e-19 6.0886780e-19 7.8436135e-20 5.2112715e-15 4.8339494e-02
 1.6981928e-18], sum to 1.0000
[2019-04-24 10:13:03,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4076
[2019-04-24 10:13:03,986] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 22.5, 23.12808433376686, -0.1657560266831796, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1453200.0000, 
sim time next is 1454400.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 22.53496265919987, -0.2751278406081973, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.3779135549333225, 0.4082907197972676, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6312773], dtype=float32), -0.3890721]. 
=============================================
[2019-04-24 10:13:05,897] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3009543e-01 4.5258342e-03 9.8842756e-18 1.1952226e-16 3.2525732e-16
 9.9309836e-19 6.4383748e-18 2.0350800e-18 4.8819290e-15 6.5378658e-02
 1.1240800e-17], sum to 1.0000
[2019-04-24 10:13:05,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4450
[2019-04-24 10:13:06,046] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.47009891095777, -0.5360870236195862, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1386000.0000, 
sim time next is 1387200.0000, 
raw observation next is [0.0, 95.0, 0.0, 0.0, 19.0, 20.95535905931068, -0.6044416032997513, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.46260387811634357, 0.95, 0.0, 0.0, 0.08333333333333333, 0.24627992160922338, 0.2985194655667496, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.16060708], dtype=float32), -0.20826182]. 
=============================================
[2019-04-24 10:13:09,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.96256626e-01 3.18194320e-03 1.00526085e-17 1.22599536e-16
 2.90601288e-17 1.46848754e-18 2.20041954e-18 3.61217573e-19
 1.71635811e-14 1.00561425e-01 1.11013189e-17], sum to 1.0000
[2019-04-24 10:13:09,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6637
[2019-04-24 10:13:09,982] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 93.0, 95.0, 0.0, 22.5, 22.87669382088176, -0.3122002963048613, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1428000.0000, 
sim time next is 1429200.0000, 
raw observation next is [0.5, 92.0, 93.0, 0.0, 22.5, 22.55266570308679, -0.3630226639604677, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4764542936288089, 0.92, 0.31, 0.0, 0.375, 0.37938880859056595, 0.3789924453465108, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.837633], dtype=float32), -2.1247952]. 
=============================================
[2019-04-24 10:13:15,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6735740e-01 1.0012024e-03 1.6755834e-19 1.8239364e-18 4.0543050e-18
 3.0103274e-20 5.2711296e-20 2.0595164e-20 4.7384489e-16 3.1641353e-02
 2.5359667e-19], sum to 1.0000
[2019-04-24 10:13:15,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2809
[2019-04-24 10:13:15,626] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.3, 96.0, 80.5, 354.0, 22.5, 23.33953336955161, 0.01942943635306868, 1.0, 1.0, 60.0, 88.07514523307825], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1508400.0000, 
sim time next is 1509600.0000, 
raw observation next is [3.666666666666667, 95.0, 85.5, 590.0, 22.5, 24.24454175120918, -0.11933617430602, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.564173591874423, 0.95, 0.285, 0.6519337016574586, 0.375, 0.5203784792674316, 0.46022127523132667, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7096101], dtype=float32), -0.3468917]. 
=============================================
[2019-04-24 10:13:19,288] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1326482e-01 1.2354541e-02 1.0638393e-17 1.3867196e-17 3.9644666e-17
 7.2353762e-19 8.7547049e-19 4.5151054e-19 6.1738787e-15 2.7438059e-01
 1.2374829e-18], sum to 1.0000
[2019-04-24 10:13:19,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1576
[2019-04-24 10:13:19,365] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.966666666666667, 92.0, 49.16666666666667, 0.0, 22.5, 21.49150676553667, -0.4606827730131993, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1675200.0000, 
sim time next is 1676400.0000, 
raw observation next is [1.733333333333333, 92.0, 55.16666666666667, 0.0, 22.5, 21.71416210054512, -0.4369586502634509, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.5106186518928902, 0.92, 0.1838888888888889, 0.0, 0.375, 0.30951350837876007, 0.3543471165788497, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4698758], dtype=float32), -1.2658619]. 
=============================================
[2019-04-24 10:13:26,098] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6807903e-01 7.2058209e-04 1.6107759e-18 2.8011945e-17 2.9734053e-17
 1.2193139e-19 4.0429437e-19 3.9716790e-19 6.3619124e-15 3.1200390e-02
 8.5892315e-19], sum to 1.0000
[2019-04-24 10:13:26,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8914
[2019-04-24 10:13:26,142] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 75.5, 0.0, 22.5, 23.22303538697503, 0.09000292598687638, 1.0, 1.0, 60.0, 93.45767748346928], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1694400.0000, 
sim time next is 1695600.0000, 
raw observation next is [1.1, 88.0, 66.5, 0.0, 22.5, 24.44153369390223, 0.03215166933758683, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.49307479224376743, 0.88, 0.22166666666666668, 0.0, 0.375, 0.5367944744918525, 0.5107172231125289, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24639569], dtype=float32), -1.0179601]. 
=============================================
[2019-04-24 10:13:26,638] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4901925e-01 1.7256654e-03 2.4607198e-18 6.9843452e-17 3.4806334e-17
 1.6266653e-19 4.4644799e-19 1.2006415e-18 8.4479077e-15 4.9255013e-02
 4.2758149e-18], sum to 1.0000
[2019-04-24 10:13:26,640] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5824
[2019-04-24 10:13:26,658] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 90.0, 0.0, 22.5, 23.48217966031229, -0.09734420451462318, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1692000.0000, 
sim time next is 1693200.0000, 
raw observation next is [1.1, 88.0, 83.33333333333334, 0.0, 22.5, 23.47979851502011, -0.1350935653907133, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.49307479224376743, 0.88, 0.2777777777777778, 0.0, 0.375, 0.4566498762516759, 0.45496881153642893, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.52156734], dtype=float32), -0.7146104]. 
=============================================
[2019-04-24 10:13:26,700] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.9747429e-01 3.0780237e-03 9.6006461e-18 1.7877291e-16 7.5367298e-17
 3.8551856e-19 1.7780152e-18 4.6828026e-18 4.0141708e-14 9.9447653e-02
 1.0314105e-17], sum to 1.0000
[2019-04-24 10:13:26,710] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4267
[2019-04-24 10:13:26,741] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 66.5, 0.0, 22.5, 23.12554962299513, -0.2805310089626495, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1695600.0000, 
sim time next is 1696800.0000, 
raw observation next is [1.266666666666667, 85.66666666666667, 57.5, 0.0, 22.5, 22.25763092081123, -0.3366319031070856, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.4976915974145891, 0.8566666666666667, 0.19166666666666668, 0.0, 0.375, 0.35480257673426924, 0.38778936563097144, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.52156734], dtype=float32), -0.7146104]. 
=============================================
[2019-04-24 10:13:28,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2972584e-01 4.4915557e-02 1.1918971e-12 2.0585103e-12 1.7834641e-12
 2.7209300e-13 2.0929530e-13 8.9168527e-14 4.6817532e-11 2.2535853e-01
 6.9275477e-13], sum to 1.0000
[2019-04-24 10:13:28,224] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3606
[2019-04-24 10:13:28,239] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 37.0, 0.0, 0.0, 19.0, 20.17102680926493, -1.049580462609925, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2504400.0000, 
sim time next is 2505600.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 19.0, 19.42128321787584, -1.195772698572639, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.38, 0.0, 0.0, 0.08333333333333333, 0.11844026815631992, 0.10140910047578704, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.38974455], dtype=float32), 0.70772]. 
=============================================
[2019-04-24 10:13:30,512] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.4295135e-01 1.9047441e-02 3.9335511e-15 4.0275083e-15 1.7127352e-14
 1.7154807e-15 7.0825867e-15 6.4987237e-16 2.2328673e-12 5.3800118e-01
 2.6533826e-15], sum to 1.0000
[2019-04-24 10:13:30,512] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1949
[2019-04-24 10:13:30,561] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 83.0, 45.5, 0.0, 19.0, 19.56002479203973, -0.9459434017362393, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1760400.0000, 
sim time next is 1761600.0000, 
raw observation next is [-1.9, 84.33333333333334, 58.5, 0.0, 19.0, 19.24032135990112, -0.9944128161418648, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.4099722991689751, 0.8433333333333334, 0.195, 0.0, 0.08333333333333333, 0.10336011332509336, 0.16852906128604506, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.602629], dtype=float32), 1.6073631]. 
=============================================
[2019-04-24 10:13:31,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4775912e-01 6.8733213e-03 1.2777614e-14 1.9192815e-14 1.8295303e-14
 5.7596155e-16 1.4091579e-15 7.6024166e-16 2.5773587e-12 4.4536749e-01
 1.1479034e-15], sum to 1.0000
[2019-04-24 10:13:31,896] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4802
[2019-04-24 10:13:31,969] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.4, 80.0, 0.0, 0.0, 22.5, 22.18057828379565, -0.506650295573016, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2144400.0000, 
sim time next is 2145600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 22.5, 21.54067015380275, -0.6001707159653634, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.30747922437673136, 0.83, 0.0, 0.0, 0.375, 0.29505584615022923, 0.2999430946782122, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03208939], dtype=float32), -0.518242]. 
=============================================
[2019-04-24 10:13:42,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4120287e-01 1.6616475e-02 4.4432069e-14 1.3932223e-13 7.7287725e-14
 5.0917988e-15 8.9242578e-15 2.6592231e-15 2.3292313e-11 3.4218070e-01
 8.9841354e-15], sum to 1.0000
[2019-04-24 10:13:42,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9237
[2019-04-24 10:13:42,725] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 68.0, 14.0, 0.0, 22.5, 22.39096790476609, -0.4815909729483913, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2134800.0000, 
sim time next is 2136000.0000, 
raw observation next is [-4.666666666666667, 69.0, 5.999999999999999, 0.0, 22.5, 22.86732028919338, -0.3422032754163327, 1.0, 1.0, 60.0, 94.08377169934752], 
processed observation next is [1.0, 0.7391304347826086, 0.3333333333333333, 0.69, 0.019999999999999997, 0.0, 0.375, 0.4056100240994483, 0.38593224152788913, 1.0, 1.0, 0.9, 0.9408377169934752], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14062952], dtype=float32), 0.2078409]. 
=============================================
[2019-04-24 10:13:45,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.53239310e-01 1.28296595e-02 4.80521012e-14 9.17167885e-14
 2.61884996e-13 1.07339047e-14 1.34926902e-14 4.84153741e-15
 4.32653566e-12 3.33931029e-01 2.17803240e-14], sum to 1.0000
[2019-04-24 10:13:45,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5320
[2019-04-24 10:13:45,357] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 19.0, 21.38096847518185, -0.7232461994749931, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2359200.0000, 
sim time next is 2360400.0000, 
raw observation next is [-3.4, 69.0, 7.833333333333332, 0.0, 19.0, 20.457948403396, -0.8839606571579056, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.368421052631579, 0.69, 0.026111111111111106, 0.0, 0.08333333333333333, 0.20482903361633328, 0.20534644761403145, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9289032], dtype=float32), 0.66000795]. 
=============================================
[2019-04-24 10:13:46,278] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.4574516e-01 5.5631259e-03 7.3387799e-15 3.9485999e-14 2.1682149e-14
 9.0065204e-16 1.6849133e-15 4.9511755e-16 5.4176052e-12 3.4869173e-01
 1.0691510e-15], sum to 1.0000
[2019-04-24 10:13:46,279] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2782
[2019-04-24 10:13:46,294] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.0, 6.999999999999999, 0.0, 22.5, 21.12888052001107, -0.7071249833220151, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2049600.0000, 
sim time next is 2050800.0000, 
raw observation next is [-3.899999999999999, 82.0, 0.0, 0.0, 22.5, 20.86961408943245, -0.7163979782402446, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.35457063711911363, 0.82, 0.0, 0.0, 0.375, 0.23913450745270412, 0.26120067391991847, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6108943], dtype=float32), 0.36148614]. 
=============================================
[2019-04-24 10:13:50,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.5933384e-01 9.9840974e-03 1.1224908e-15 4.7504830e-14 4.7459459e-14
 7.4005554e-16 1.3179788e-15 4.3930551e-16 1.5022845e-12 3.0681998e-02
 2.1286105e-15], sum to 1.0000
[2019-04-24 10:13:50,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5551
[2019-04-24 10:13:50,772] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 54.0, 0.0, 0.0, 19.0, 20.45412664420679, -0.8229767894061718, 0.0, 1.0, 60.0, 78.54278658850862], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2530800.0000, 
sim time next is 2532000.0000, 
raw observation next is [-2.8, 54.00000000000001, 0.0, 0.0, 22.5, 20.63397137041935, -0.9519752541753927, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.38504155124653744, 0.54, 0.0, 0.0, 0.375, 0.21949761420161243, 0.1826749152748691, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.617957], dtype=float32), -0.6312256]. 
=============================================
[2019-04-24 10:13:50,870] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.0203015e-01 4.4053956e-03 5.5885341e-15 3.4592300e-14 2.1105193e-14
 2.6507539e-16 3.5479394e-16 7.0025336e-16 4.6104362e-12 1.9356449e-01
 1.5973352e-15], sum to 1.0000
[2019-04-24 10:13:50,875] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4044
[2019-04-24 10:13:50,983] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 72.0, 0.0, 0.0, 22.5, 23.71701213955324, -0.2127447997535297, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2139600.0000, 
sim time next is 2140800.0000, 
raw observation next is [-5.0, 73.0, 0.0, 0.0, 22.5, 22.86269860466335, -0.3548399299189027, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.32409972299168976, 0.73, 0.0, 0.0, 0.375, 0.40522488372194587, 0.38172002336036576, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5427148], dtype=float32), -0.8665106]. 
=============================================
[2019-04-24 10:14:00,210] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2802304e-01 1.0453575e-02 5.7937228e-16 1.9511187e-14 1.6658146e-14
 5.7919552e-16 6.5711863e-16 2.6050080e-16 5.6484017e-13 6.1523438e-02
 7.0290426e-16], sum to 1.0000
[2019-04-24 10:14:00,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4263
[2019-04-24 10:14:00,257] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 54.66666666666667, 0.0, 0.0, 19.0, 22.26021426474514, -0.4167918138342245, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2323200.0000, 
sim time next is 2324400.0000, 
raw observation next is [-1.7, 55.33333333333333, 0.0, 0.0, 19.0, 21.68074483469459, -0.4972978357756399, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4155124653739613, 0.5533333333333332, 0.0, 0.0, 0.08333333333333333, 0.30672873622454916, 0.33423405474145335, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5282373], dtype=float32), 0.03501531]. 
=============================================
[2019-04-24 10:14:02,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9633610e-01 1.8396163e-02 1.3824745e-13 4.3924198e-14 1.0326880e-13
 2.5078384e-14 1.6784757e-14 2.7380617e-15 3.7872721e-12 4.8526779e-01
 2.9989486e-14], sum to 1.0000
[2019-04-24 10:14:02,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5076
[2019-04-24 10:14:02,921] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-2.466666666666667, 63.0, 143.6666666666667, 426.0, 19.0, 19.50532323508544, -1.000963732335309, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2371200.0000, 
sim time next is 2372400.0000, 
raw observation next is [-2.3, 62.0, 153.0, 378.0, 19.0, 19.72270644389788, -0.7687780198804394, 0.0, 1.0, 20.0, 74.8001070756924], 
processed observation next is [0.0, 0.4782608695652174, 0.3988919667590028, 0.62, 0.51, 0.4176795580110497, 0.08333333333333333, 0.1435588703248234, 0.24374066003985354, 0.0, 1.0, 0.1, 0.7480010707569239], 
reward next is 0.1520, 
noisyNet noise sample is [array([1.5128711], dtype=float32), -0.700684]. 
=============================================
[2019-04-24 10:14:07,877] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.05451715e-01 6.14430988e-03 1.35662798e-15 2.20377373e-14
 1.39444866e-14 4.93624438e-16 8.24967368e-16 9.07100712e-16
 1.69626802e-12 8.84040520e-02 3.01157948e-15], sum to 1.0000
[2019-04-24 10:14:07,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5643
[2019-04-24 10:14:07,892] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.0462689668764, -0.4402725961372149, 0.0, 1.0, 60.0, 92.10915639002945], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3370800.0000, 
sim time next is 3372000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.62947955136379, -0.5469588026179638, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.30245662928031586, 0.3176803991273454, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9354363], dtype=float32), 0.73932827]. 
=============================================
[2019-04-24 10:14:09,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1363913e-01 2.9890963e-03 3.0503526e-17 2.6954116e-16 6.6197213e-16
 3.1424172e-18 2.6569948e-17 1.1043637e-18 5.8547839e-14 8.3371848e-02
 2.3818873e-17], sum to 1.0000
[2019-04-24 10:14:09,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0335
[2019-04-24 10:14:09,957] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 47.66666666666666, 116.3333333333333, 815.1666666666667, 22.5, 22.46035541156778, -0.2907025943280642, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3415200.0000, 
sim time next is 3416400.0000, 
raw observation next is [3.0, 49.0, 115.0, 811.5, 22.5, 22.15330719641101, -0.3505548934609186, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.38333333333333336, 0.8966850828729281, 0.375, 0.34610893303425083, 0.38314836884636044, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.16968024], dtype=float32), -0.8582561]. 
=============================================
[2019-04-24 10:14:17,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.8687769e-01 1.6977767e-02 3.6691932e-14 9.0166515e-14 6.7436609e-14
 4.6017407e-15 7.1507089e-15 4.0852607e-15 1.1362746e-11 1.9614451e-01
 8.3877844e-15], sum to 1.0000
[2019-04-24 10:14:17,067] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5806
[2019-04-24 10:14:17,123] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 62.33333333333334, 0.0, 0.0, 19.0, 21.09986029246464, -0.6484175467183356, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2755200.0000, 
sim time next is 2756400.0000, 
raw observation next is [-6.0, 60.66666666666666, 0.0, 0.0, 19.0, 20.70821593636774, -0.7116926305701586, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.296398891966759, 0.6066666666666666, 0.0, 0.0, 0.08333333333333333, 0.22568466136397833, 0.26276912314328044, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3942157], dtype=float32), -0.9256364]. 
=============================================
[2019-04-24 10:14:20,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2162284e-01 1.0066425e-02 3.1662203e-14 1.0407728e-13 6.7449030e-14
 2.2888736e-15 6.4683201e-15 1.0736994e-14 5.7790283e-12 4.6831065e-01
 4.2018611e-15], sum to 1.0000
[2019-04-24 10:14:20,177] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1480
[2019-04-24 10:14:20,207] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 59.0, 0.0, 0.0, 19.0, 20.58185514567622, -0.7429687892662624, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2757600.0000, 
sim time next is 2758800.0000, 
raw observation next is [-6.0, 59.0, 0.0, 0.0, 19.0, 20.33381999977063, -0.848419251129145, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.59, 0.0, 0.0, 0.08333333333333333, 0.19448499998088575, 0.21719358295695168, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1034741], dtype=float32), -1.1196485]. 
=============================================
[2019-04-24 10:14:21,424] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.6061344e-01 2.8009664e-02 6.3490117e-15 2.6557856e-14 3.8467466e-14
 3.5882145e-15 2.7129004e-15 2.0796950e-16 9.5899775e-13 2.1137694e-01
 1.6687520e-14], sum to 1.0000
[2019-04-24 10:14:21,426] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0879
[2019-04-24 10:14:21,443] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 79.33333333333333, 0.0, 0.0, 19.0, 21.06268023941621, -0.7138285286239313, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2958000.0000, 
sim time next is 2959200.0000, 
raw observation next is [-4.0, 77.0, 0.0, 0.0, 19.0, 20.23345100898299, -0.8693110639928006, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.3518005540166205, 0.77, 0.0, 0.0, 0.08333333333333333, 0.18612091741524908, 0.21022964533573316, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0826826], dtype=float32), -1.3554387]. 
=============================================
[2019-04-24 10:14:33,188] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.4082717e-01 9.2359390e-03 5.8620847e-17 1.9370014e-16 2.1656263e-16
 1.7408656e-17 1.9873046e-17 2.2285288e-18 3.4005198e-14 1.4993690e-01
 2.2721371e-17], sum to 1.0000
[2019-04-24 10:14:33,188] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2316
[2019-04-24 10:14:33,210] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 100.0, 0.0, 0.0, 19.0, 20.49565518717829, -0.8601966310370263, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3114000.0000, 
sim time next is 3115200.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 19.0, 20.2220042122679, -0.9443011767470146, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.08333333333333333, 0.18516701768899177, 0.18523294108432845, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.20437242], dtype=float32), 0.75788623]. 
=============================================
[2019-04-24 10:14:36,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7423502e-01 3.3800039e-02 4.6668593e-16 7.5284214e-16 1.4864270e-15
 3.4092699e-17 7.2404502e-17 3.2444356e-17 3.6039490e-14 3.9196491e-01
 3.8523333e-17], sum to 1.0000
[2019-04-24 10:14:36,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5711
[2019-04-24 10:14:36,580] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 15.0, 130.0, 22.5, 20.96513039544569, -0.6889526004556267, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3224400.0000, 
sim time next is 3225600.0000, 
raw observation next is [-3.0, 92.0, 43.0, 226.0, 22.5, 20.40046176432782, -0.7407323505375069, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.3795013850415513, 0.92, 0.14333333333333334, 0.24972375690607734, 0.375, 0.20003848036065155, 0.2530892164874977, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6766738], dtype=float32), -0.45728675]. 
=============================================
[2019-04-24 10:14:43,837] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.1905600e-01 2.0065673e-03 9.8551332e-18 1.5247641e-16 8.7414998e-17
 2.1206413e-18 1.0680882e-18 8.5904852e-19 2.3165797e-14 7.8937404e-02
 1.3022853e-17], sum to 1.0000
[2019-04-24 10:14:43,841] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1717
[2019-04-24 10:14:43,851] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 47.66666666666667, 114.0, 797.3333333333333, 22.5, 23.98808202785298, -0.1198030754351556, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3410400.0000, 
sim time next is 3411600.0000, 
raw observation next is [3.0, 46.33333333333334, 115.3333333333333, 806.1666666666666, 22.5, 23.48815298432989, -0.27961113158128, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.46333333333333343, 0.3844444444444443, 0.8907918968692449, 0.375, 0.45734608202749083, 0.4067962894729067, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4772691], dtype=float32), 0.63141876]. 
=============================================
[2019-04-24 10:14:45,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8332465e-01 4.5448999e-04 1.5233609e-18 5.0122993e-17 9.5315407e-17
 4.7221771e-19 9.6271612e-19 1.1198540e-19 1.1142789e-14 1.6220910e-02
 1.0625042e-18], sum to 1.0000
[2019-04-24 10:14:45,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6441
[2019-04-24 10:14:45,044] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.3385072e-01 5.7751695e-03 2.3092254e-16 2.4986784e-16 4.9112474e-16
 2.8144334e-17 2.3261197e-17 5.8033048e-18 6.4350909e-14 2.6037410e-01
 5.9879810e-17], sum to 1.0000
[2019-04-24 10:14:45,044] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8022
[2019-04-24 10:14:45,053] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 79.0, 0.0, 0.0, 22.5, 22.3124241953648, -0.09427116714476012, 0.0, 1.0, 60.0, 98.83403526985765], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3439200.0000, 
sim time next is 3440400.0000, 
raw observation next is [1.0, 79.0, 0.0, 0.0, 22.5, 23.04584150714035, -0.1971275328287238, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4903047091412743, 0.79, 0.0, 0.0, 0.375, 0.4204867922616957, 0.4342908223904254, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9347658], dtype=float32), 1.2847018]. 
=============================================
[2019-04-24 10:14:45,100] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.9999999999999999, 52.0, 100.6666666666667, 675.6666666666666, 22.5, 23.78396702027369, -0.1913444593887444, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3404400.0000, 
sim time next is 3405600.0000, 
raw observation next is [2.0, 48.0, 104.0, 711.0, 22.5, 23.99630309980463, 0.06216653056024709, 1.0, 1.0, 60.0, 80.46830898177527], 
processed observation next is [1.0, 0.43478260869565216, 0.518005540166205, 0.48, 0.3466666666666667, 0.7856353591160221, 0.375, 0.4996919249837193, 0.5207221768534157, 1.0, 1.0, 0.9, 0.8046830898177526], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4418781], dtype=float32), 0.97477573]. 
=============================================
[2019-04-24 10:14:46,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6875900e-01 2.5224513e-03 3.7224507e-17 4.1578637e-16 9.4313911e-16
 8.2244762e-17 2.4852837e-17 1.4892254e-17 6.1901378e-14 2.8718576e-02
 1.2253451e-16], sum to 1.0000
[2019-04-24 10:14:46,637] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5837
[2019-04-24 10:14:46,685] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.0, 59.0, 23.16666666666666, 224.5, 19.0, 21.7527394905026, -0.4626418456228356, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3691200.0000, 
sim time next is 3692400.0000, 
raw observation next is [4.0, 59.0, 12.5, 137.5, 19.0, 21.62170662251939, -0.4977320453144948, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5734072022160666, 0.59, 0.041666666666666664, 0.15193370165745856, 0.08333333333333333, 0.3018088852099492, 0.3340893182285017, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3345538], dtype=float32), -0.40598214]. 
=============================================
[2019-04-24 10:14:46,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8927248e-01 4.8444633e-04 1.6101433e-18 8.7957463e-17 3.9643117e-17
 1.3571384e-19 1.5419748e-19 1.7856669e-20 3.5050552e-15 1.0243096e-02
 2.2456078e-18], sum to 1.0000
[2019-04-24 10:14:46,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4350
[2019-04-24 10:14:46,728] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.2864062e-01 1.9149434e-02 7.6330340e-15 7.6875033e-15 2.9364962e-14
 4.3536202e-15 7.3511533e-15 2.6899326e-16 1.1865207e-12 2.5220993e-01
 2.9216339e-15], sum to 1.0000
[2019-04-24 10:14:46,729] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6810
[2019-04-24 10:14:46,735] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 19.20768191877589, -1.041149126895562, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3717600.0000, 
sim time next is 3718800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 19.2234161843351, -1.063513945200687, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.1019513486945917, 0.145495351599771, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.2793038], dtype=float32), 1.3618768]. 
=============================================
[2019-04-24 10:14:46,736] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 53.83333333333334, 462.6666666666667, 22.5, 25.85014993367261, 0.3455101522475141, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3516000.0000, 
sim time next is 3517200.0000, 
raw observation next is [3.0, 49.0, 37.5, 338.0, 22.5, 25.44970127285843, 0.1276352227814588, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5457063711911359, 0.49, 0.125, 0.3734806629834254, 0.375, 0.6208084394048692, 0.5425450742604863, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.40183246], dtype=float32), -1.0937327]. 
=============================================
[2019-04-24 10:14:47,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.86238122e-01 1.06088433e-03 1.06985674e-16 4.83912549e-15
 4.01831583e-15 7.23371299e-17 3.64100421e-17 3.26351339e-17
 3.66122090e-13 1.27009563e-02 3.11885922e-16], sum to 1.0000
[2019-04-24 10:14:47,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2484
[2019-04-24 10:14:47,122] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.333333333333333, 40.33333333333334, 114.1666666666667, 818.0, 22.5, 23.60012092547461, 0.1346494969336511, 1.0, 1.0, 60.0, 89.01101023510961], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3937200.0000, 
sim time next is 3938400.0000, 
raw observation next is [-5.0, 38.0, 110.5, 806.0, 22.5, 24.66924550854452, 0.0999619888831285, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.32409972299168976, 0.38, 0.36833333333333335, 0.8906077348066298, 0.375, 0.5557704590453767, 0.5333206629610429, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1051834], dtype=float32), -1.4132273]. 
=============================================
[2019-04-24 10:14:47,935] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5791751e-01 1.4173697e-03 3.0366439e-17 1.4322610e-16 3.5907590e-16
 3.1902259e-18 3.9611930e-18 2.9258859e-18 6.1159506e-14 4.0665101e-02
 2.4459296e-17], sum to 1.0000
[2019-04-24 10:14:47,936] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5503
[2019-04-24 10:14:47,959] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.3874348e-01 1.5870279e-02 4.6074327e-14 1.9566973e-14 9.6186439e-14
 6.6802609e-15 1.8199365e-14 1.2350736e-15 2.8771850e-12 2.4538618e-01
 8.3875583e-15], sum to 1.0000
[2019-04-24 10:14:47,960] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4819
[2019-04-24 10:14:47,971] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 51.0, 10.83333333333333, 125.8333333333333, 22.5, 23.70675565072941, -0.151134521326586, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3519600.0000, 
sim time next is 3520800.0000, 
raw observation next is [2.0, 52.0, 0.0, 0.0, 22.5, 23.29296615448428, -0.09235282513964597, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.52, 0.0, 0.0, 0.375, 0.44108051287368993, 0.4692157249534514, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.86226493], dtype=float32), -0.12403085]. 
=============================================
[2019-04-24 10:14:47,976] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 67.33333333333333, 0.0, 0.0, 19.0, 19.77497626115351, -0.8612187251539815, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3548400.0000, 
sim time next is 3549600.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 19.63805434937333, -0.8861140243964428, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.13650452911444422, 0.20462865853451906, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7072111], dtype=float32), 1.496454]. 
=============================================
[2019-04-24 10:14:48,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.47220457e-01 3.26407626e-02 2.28926345e-15 7.58626086e-15
 1.15508435e-14 1.07004582e-15 4.84404166e-15 5.15468306e-16
 1.34637332e-12 2.20138773e-01 2.03254322e-15], sum to 1.0000
[2019-04-24 10:14:48,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7246
[2019-04-24 10:14:48,621] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 19.44545841533286, -0.9914053119130092, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3717600.0000, 
sim time next is 3718800.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 19.44861859422535, -1.015264536602323, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.12071821618544594, 0.16157848779922568, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0942665], dtype=float32), 0.074993424]. 
=============================================
[2019-04-24 10:14:54,715] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.75800848e-01 7.65470928e-03 6.92223449e-17 2.10674630e-16
 5.82430707e-16 1.15345034e-17 3.08168718e-17 1.04124495e-17
 1.96399768e-14 1.16544485e-01 5.66108912e-17], sum to 1.0000
[2019-04-24 10:14:54,716] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9118
[2019-04-24 10:14:54,812] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.666666666666667, 77.0, 98.16666666666667, 634.0, 22.5, 23.38844055642816, -0.3421908304107473, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3748800.0000, 
sim time next is 3750000.0000, 
raw observation next is [-3.333333333333333, 77.0, 101.8333333333333, 690.6666666666666, 22.5, 23.35717359135381, -0.170048709433946, 1.0, 1.0, 60.0, 78.73211447972102], 
processed observation next is [1.0, 0.391304347826087, 0.37026777469990774, 0.77, 0.3394444444444443, 0.7631675874769797, 0.375, 0.44643113261281747, 0.4433170968553513, 1.0, 1.0, 0.9, 0.7873211447972102], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1838927], dtype=float32), -0.058709286]. 
=============================================
[2019-04-24 10:14:54,820] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[79.14062 ]
 [78.79657 ]
 [77.10272 ]
 [75.396675]
 [74.14806 ]
 [73.502945]
 [72.87684 ]
 [71.29545 ]
 [71.448135]
 [70.628784]
 [70.839455]
 [70.01486 ]
 [70.28964 ]
 [70.53963 ]
 [70.77292 ]
 [71.08273 ]
 [71.440475]
 [70.686485]
 [71.05062 ]
 [71.35392 ]
 [71.0624  ]
 [69.70228 ]
 [70.22497 ]
 [69.93705 ]
 [70.17403 ]], R is [[79.15071869]
 [79.35921478]
 [78.56562042]
 [77.80416107]
 [77.02612305]
 [77.25585938]
 [76.48329926]
 [76.71846771]
 [76.95128632]
 [76.18177795]
 [76.41996002]
 [75.96779633]
 [75.20812225]
 [74.45603943]
 [74.66791534]
 [74.92123413]
 [75.17201996]
 [74.42030334]
 [74.67610168]
 [74.92934418]
 [75.18005371]
 [74.42825317]
 [73.94968414]
 [73.86271667]
 [74.1240921 ]].
[2019-04-24 10:14:59,570] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8769915e-01 4.3753354e-04 5.1104188e-21 3.5230462e-20 2.9423143e-19
 4.3488855e-21 1.9352026e-21 2.2601334e-22 4.4855910e-17 1.1863267e-02
 9.0508301e-21], sum to 1.0000
[2019-04-24 10:14:59,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3767
[2019-04-24 10:14:59,588] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.56666666666667, 29.66666666666667, 115.5, 843.8333333333334, 22.5, 24.19956229514344, 0.07716667683167003, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4368000.0000, 
sim time next is 4369200.0000, 
raw observation next is [14.53333333333333, 30.33333333333333, 128.3333333333333, 806.5, 22.5, 24.56241885502673, 0.1338745008507692, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.8651892890120036, 0.3033333333333333, 0.42777777777777765, 0.8911602209944751, 0.375, 0.5468682379188943, 0.544624833616923, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3151119], dtype=float32), 0.06480649]. 
=============================================
[2019-04-24 10:15:02,420] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0863655e-01 1.9598737e-02 3.6918903e-13 1.0454815e-12 2.6305468e-12
 1.2272014e-13 3.4024132e-13 8.4259016e-14 1.1829393e-10 1.7176472e-01
 3.6156516e-13], sum to 1.0000
[2019-04-24 10:15:02,421] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3477
[2019-04-24 10:15:02,452] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.66666666666667, 61.33333333333334, 0.0, 0.0, 19.0, 19.67246555653234, -1.009167953348652, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3980400.0000, 
sim time next is 3981600.0000, 
raw observation next is [-12.0, 63.0, 0.0, 0.0, 19.0, 19.04784861175972, -1.101093796963117, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.13019390581717452, 0.63, 0.0, 0.0, 0.08333333333333333, 0.08732071764664322, 0.1329687343456277, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3798052], dtype=float32), 0.10328564]. 
=============================================
[2019-04-24 10:15:03,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1315299e-01 1.1138625e-02 1.7201414e-16 9.0402365e-16 2.4901737e-15
 5.7188985e-17 1.1776615e-16 2.2317834e-17 1.1708814e-13 7.5708345e-02
 3.9474869e-17], sum to 1.0000
[2019-04-24 10:15:03,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9633
[2019-04-24 10:15:03,996] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.9666666666666668, 73.0, 0.0, 0.0, 19.0, 21.13266267709398, -0.6928461794838277, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4504800.0000, 
sim time next is 4506000.0000, 
raw observation next is [-0.9333333333333333, 73.0, 0.0, 0.0, 19.0, 21.07150955776322, -0.4972634836087417, 0.0, 1.0, 60.0, 89.21837854283483], 
processed observation next is [1.0, 0.13043478260869565, 0.4367497691597415, 0.73, 0.0, 0.0, 0.08333333333333333, 0.25595912981360175, 0.33424550546375276, 0.0, 1.0, 0.9, 0.8921837854283483], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06930451], dtype=float32), 1.0285207]. 
=============================================
[2019-04-24 10:15:05,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6840093e-01 1.0678366e-02 7.4604587e-15 3.4626480e-14 1.2909069e-14
 5.2338725e-15 2.8880162e-15 3.5629859e-16 2.8702284e-12 1.2092071e-01
 3.9524827e-15], sum to 1.0000
[2019-04-24 10:15:05,317] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3086
[2019-04-24 10:15:05,337] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 40.0, 46.0, 356.5, 19.0, 19.93442611358499, -0.8809506552824643, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4208400.0000, 
sim time next is 4209600.0000, 
raw observation next is [1.9, 40.33333333333334, 31.33333333333333, 227.5, 19.0, 19.83747934847542, -0.9158288434746878, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.515235457063712, 0.40333333333333343, 0.10444444444444442, 0.2513812154696133, 0.08333333333333333, 0.15312327903961828, 0.19472371884177073, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8197793], dtype=float32), 0.81242317]. 
=============================================
[2019-04-24 10:15:05,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1674846e-01 9.4606653e-03 5.9424596e-15 4.0101105e-14 1.5667828e-14
 5.0768089e-15 3.3779644e-15 3.8661961e-16 2.8815483e-12 7.3790878e-02
 5.0026020e-15], sum to 1.0000
[2019-04-24 10:15:05,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5831
[2019-04-24 10:15:05,385] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.9, 40.33333333333334, 31.33333333333333, 227.5, 19.0, 19.83747934847542, -0.9158288434746878, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4209600.0000, 
sim time next is 4210800.0000, 
raw observation next is [1.8, 40.66666666666667, 20.0, 135.8333333333333, 19.0, 19.70561414355011, -0.9497579063740779, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5124653739612189, 0.40666666666666673, 0.06666666666666667, 0.1500920810313075, 0.08333333333333333, 0.14213451196250926, 0.18341403120864072, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8197793], dtype=float32), 0.81242317]. 
=============================================
[2019-04-24 10:15:05,958] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:15:06,159] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:15:06,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:15:06,953] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:15:06,960] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run7
[2019-04-24 10:15:10,585] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6905367e-01 1.8751649e-02 4.2450937e-14 3.4162438e-14 1.1398964e-13
 2.8149214e-14 3.2569128e-14 7.4919065e-15 2.5008010e-12 3.1219462e-01
 1.7209895e-14], sum to 1.0000
[2019-04-24 10:15:10,588] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8745
[2019-04-24 10:15:10,649] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 18.85295140718035, -1.102950365791745, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4765200.0000, 
sim time next is 4766400.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 19.25240679344378, -0.7869256492791905, 0.0, 1.0, 60.0, 102.45696830963755], 
processed observation next is [0.0, 0.17391304347826086, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.10436723278698157, 0.23769145024026983, 0.0, 1.0, 0.9, 1.0245696830963755], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00713858], dtype=float32), -0.3587044]. 
=============================================
[2019-04-24 10:15:11,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4124365e-01 1.8784539e-03 5.0450738e-17 2.4316026e-16 5.0196215e-16
 1.2754338e-17 1.6543475e-17 1.4254943e-18 2.1666368e-14 5.6877941e-02
 8.1008484e-17], sum to 1.0000
[2019-04-24 10:15:11,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3383
[2019-04-24 10:15:11,226] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.2, 64.0, 0.0, 0.0, 19.0, 20.82257677442052, -0.7317009593718388, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4298400.0000, 
sim time next is 4299600.0000, 
raw observation next is [6.133333333333334, 65.66666666666667, 0.0, 0.0, 19.0, 20.71813298725538, -0.7558498226835045, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.6325023084025855, 0.6566666666666667, 0.0, 0.0, 0.08333333333333333, 0.2265110822712817, 0.2480500591054985, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09605575], dtype=float32), 1.1445842]. 
=============================================
[2019-04-24 10:15:14,025] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-24 10:15:14,027] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:15:14,028] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:15:14,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:15:14,028] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:15:14,030] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run9
[2019-04-24 10:15:14,029] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:15:14,051] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:15:14,050] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run9
[2019-04-24 10:15:14,053] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run9
[2019-04-24 10:17:04,792] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3377.0734 57427.5638 -370.4871
[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:04,833] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:05,137] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,382] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3118.8030 72052.6888 -596.4684
[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:23,601] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,002] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3017.7480 74285.6198 -652.3124
[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,032] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:32,186] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:17:33,034] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 400000, evaluation results [400000.0, 3118.8029809407412, 72052.68878105858, -596.4683826416097, 3377.0734298661228, 57427.563778360425, -370.4871012728445, 3017.7480192988855, 74285.61976232527, -652.3124018560336]
[2019-04-24 10:17:33,834] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4467050e-01 9.6909637e-03 5.5098485e-19 1.5944675e-18 1.1596917e-17
 2.1553019e-19 4.3829752e-19 2.8612413e-20 1.1489137e-15 4.5638498e-02
 5.9177251e-19], sum to 1.0000
[2019-04-24 10:17:33,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6427
[2019-04-24 10:17:33,889] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.366666666666667, 66.66666666666667, 0.0, 0.0, 19.0, 22.1873840668269, -0.3126447488961965, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4416000.0000, 
sim time next is 4417200.0000, 
raw observation next is [5.0, 67.0, 0.0, 0.0, 19.0, 22.07155332540041, -0.3501281512720021, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6011080332409973, 0.67, 0.0, 0.0, 0.08333333333333333, 0.33929611045003405, 0.38329061624266597, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0082104], dtype=float32), -0.6703658]. 
=============================================
[2019-04-24 10:17:37,791] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.07338440e-01 1.45540375e-03 3.26531553e-18 2.31794007e-17
 1.82505789e-17 3.99027507e-19 1.99062565e-18 1.76027537e-19
 1.19276545e-14 9.12060961e-02 2.12567207e-19], sum to 1.0000
[2019-04-24 10:17:37,791] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3734
[2019-04-24 10:17:37,811] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 82.66666666666667, 73.33333333333334, 0.0, 22.5, 23.0292697639595, -0.1856225406047562, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4461600.0000, 
sim time next is 4462800.0000, 
raw observation next is [0.0, 80.33333333333334, 67.33333333333334, 0.0, 22.5, 23.0959606982519, -0.1828314398888559, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.8033333333333335, 0.22444444444444447, 0.0, 0.375, 0.4246633915209917, 0.43905618670371466, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5322642], dtype=float32), 2.800736]. 
=============================================
[2019-04-24 10:17:42,988] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:43,163] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:17:43,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:17:43,992] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:17:43,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run7
[2019-04-24 10:17:45,505] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:45,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:17:46,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:17:46,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:17:46,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run7
[2019-04-24 10:17:49,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4390422e-01 1.3870894e-02 2.2291781e-15 3.4981261e-14 4.0836597e-14
 1.4519158e-15 2.8911386e-15 2.5736387e-16 9.0669833e-13 4.2224817e-02
 2.2140084e-15], sum to 1.0000
[2019-04-24 10:17:49,513] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6777
[2019-04-24 10:17:49,565] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 20.82149158748788, -0.7522968502437823, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4764000.0000, 
sim time next is 4765200.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 20.06727594854632, -0.9002102056909985, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.17227299571219343, 0.19992993143633384, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6257178], dtype=float32), -1.2856194]. 
=============================================
[2019-04-24 10:17:51,871] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8835385e-01 4.3839970e-04 9.7530364e-19 9.5947723e-17 8.2055870e-18
 1.3611072e-19 1.2719477e-19 3.5054420e-19 1.5138760e-15 1.1207711e-02
 2.4065718e-18], sum to 1.0000
[2019-04-24 10:17:51,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1492
[2019-04-24 10:17:51,929] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 72.0, 107.8333333333333, 9.166666666666668, 22.5, 22.6849210533491, -0.1239756013340918, 1.0, 1.0, 60.0, 102.50923393836285], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4724400.0000, 
sim time next is 4725600.0000, 
raw observation next is [1.0, 72.0, 88.16666666666667, 13.83333333333333, 22.5, 23.3756617358961, -0.1914198396335126, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4903047091412743, 0.72, 0.2938888888888889, 0.015285451197053403, 0.375, 0.4479718113246749, 0.4361933867888291, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6729333], dtype=float32), 1.346254]. 
=============================================
[2019-04-24 10:17:52,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.60113764e-01 3.35977739e-03 2.28753635e-16 2.40336197e-15
 2.02695492e-15 3.85185520e-17 1.09971346e-16 1.37402376e-17
 5.76783223e-14 3.65263745e-02 5.54849131e-17], sum to 1.0000
[2019-04-24 10:17:52,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6235
[2019-04-24 10:17:52,925] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 79.66666666666667, 0.0, 0.0, 19.0, 20.395940344816, -0.5173217127474393, 0.0, 1.0, 60.0, 104.34259298463621], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4753200.0000, 
sim time next is 4754400.0000, 
raw observation next is [-4.0, 75.33333333333333, 0.0, 0.0, 19.0, 21.23675222081725, -0.6380158353491076, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.3518005540166205, 0.7533333333333333, 0.0, 0.0, 0.08333333333333333, 0.269729351734771, 0.28732805488363083, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.054802], dtype=float32), -1.4806367]. 
=============================================
[2019-04-24 10:17:55,331] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.7791505e-01 1.1758376e-03 1.8943280e-17 1.5926009e-16 1.2131314e-16
 2.4948855e-18 7.8114920e-19 2.8002519e-19 1.9416668e-14 2.0909132e-02
 5.9867457e-18], sum to 1.0000
[2019-04-24 10:17:55,337] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8761
[2019-04-24 10:17:55,345] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333333, 25.0, 0.0, 0.0, 19.0, 22.56634614577273, -0.2645648713652703, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4998000.0000, 
sim time next is 4999200.0000, 
raw observation next is [4.666666666666666, 27.0, 0.0, 0.0, 19.0, 22.39735872696512, -0.2962613828227509, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.5918744228993538, 0.27, 0.0, 0.0, 0.08333333333333333, 0.36644656058042663, 0.4012462057257497, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.045554], dtype=float32), 0.49080753]. 
=============================================
[2019-04-24 10:17:59,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:17:59,412] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:00,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:00,223] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:00,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run7
[2019-04-24 10:18:00,442] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:00,507] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:00,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:00,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:01,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:01,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:01,449] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run7
[2019-04-24 10:18:01,511] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:01,541] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:01,544] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run7
[2019-04-24 10:18:01,888] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.7363726e-01 3.4846548e-02 2.8593699e-16 5.8406543e-15 9.6854236e-15
 7.1225629e-16 6.4424611e-16 1.9451512e-16 7.8861060e-13 9.1516197e-02
 1.0963553e-15], sum to 1.0000
[2019-04-24 10:18:01,889] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8115
[2019-04-24 10:18:01,919] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 50.0, 0.0, 0.0, 19.0, 20.68446697186537, -0.908394467009011, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4938000.0000, 
sim time next is 4939200.0000, 
raw observation next is [-2.0, 50.0, 0.0, 0.0, 19.0, 19.9783358437229, -1.057943167629271, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.40720221606648205, 0.5, 0.0, 0.0, 0.08333333333333333, 0.1648613203102416, 0.14735227745690968, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3340592], dtype=float32), 0.75896955]. 
=============================================
[2019-04-24 10:18:02,500] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:02,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:03,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:03,497] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:03,504] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run7
[2019-04-24 10:18:05,284] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:05,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:05,894] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0490085e-01 9.8248916e-03 3.3420786e-14 2.6934996e-14 9.5764623e-14
 6.9941361e-15 4.4020019e-15 4.0691522e-15 4.0276775e-12 8.5274257e-02
 1.0929360e-14], sum to 1.0000
[2019-04-24 10:18:05,900] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4467
[2019-04-24 10:18:05,922] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 19.0, 19.65934540475971, -0.8817391249150526, 0.0, 1.0, 60.0, 68.19866816126302], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 180000.0000, 
sim time next is 181200.0000, 
raw observation next is [-8.900000000000002, 75.33333333333334, 0.0, 0.0, 19.0, 19.96034183068751, -1.00295328566568, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.2160664819944598, 0.7533333333333334, 0.0, 0.0, 0.08333333333333333, 0.1633618192239593, 0.16568223811144, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3141572], dtype=float32), 1.2179437]. 
=============================================
[2019-04-24 10:18:06,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:06,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:06,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run7
[2019-04-24 10:18:06,914] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.2974142e-01 3.5244893e-02 5.0345754e-16 3.2474445e-15 4.2302833e-15
 1.5239224e-16 2.9484730e-16 4.0802798e-17 2.6002510e-13 1.3501360e-01
 1.6276555e-16], sum to 1.0000
[2019-04-24 10:18:06,920] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9541
[2019-04-24 10:18:07,083] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.0, 55.0, 0.0, 0.0, 19.0, 20.63211102958091, -0.7410704100040393, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 5025600.0000, 
sim time next is 5026800.0000, 
raw observation next is [-1.0, 53.33333333333334, 0.0, 0.0, 19.0, 21.00444268668732, -0.4293458882701566, 0.0, 1.0, 60.0, 94.9679426188448], 
processed observation next is [1.0, 0.17391304347826086, 0.4349030470914128, 0.5333333333333334, 0.0, 0.0, 0.08333333333333333, 0.25037022389061, 0.3568847039099478, 0.0, 1.0, 0.9, 0.949679426188448], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.164057], dtype=float32), -2.1656792]. 
=============================================
[2019-04-24 10:18:07,826] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:07,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8475891e-01 5.9697806e-04 6.9951562e-20 3.5302129e-18 2.5444636e-18
 3.3313497e-20 2.4277564e-20 7.0891745e-21 1.3287268e-15 1.4644067e-02
 7.7806283e-19], sum to 1.0000
[2019-04-24 10:18:07,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2690
[2019-04-24 10:18:07,996] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.0, 20.0, 114.5, 839.5, 22.5, 25.25054458775666, 0.2658286351757995, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5061600.0000, 
sim time next is 5062800.0000, 
raw observation next is [11.33333333333333, 19.66666666666667, 112.1666666666667, 825.8333333333333, 22.5, 24.94796412306806, 0.2734895656374111, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7765466297322253, 0.1966666666666667, 0.373888888888889, 0.9125230202578268, 0.375, 0.5789970102556717, 0.5911631885458037, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9808201], dtype=float32), 0.36841297]. 
=============================================
[2019-04-24 10:18:08,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:08,828] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:08,828] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:08,835] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run7
[2019-04-24 10:18:08,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:09,214] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:09,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:09,574] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:09,588] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:09,726] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:09,834] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:09,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:09,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:09,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:09,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run7
[2019-04-24 10:18:10,167] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:10,241] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:10,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_5 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:18:10,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:10,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:10,352] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run7
[2019-04-24 10:18:10,429] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:10,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:10,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:10,572] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:10,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:10,589] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:10,592] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run7
[2019-04-24 10:18:10,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run7
[2019-04-24 10:18:10,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_5 ERROR:Aborted (core dumped)

[2019-04-24 10:18:11,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:11,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:11,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run7
[2019-04-24 10:18:11,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:11,261] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:11,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run7
[2019-04-24 10:18:11,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:18:11,324] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:18:11,337] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run7
[2019-04-24 10:18:21,538] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.6340588e-01 9.0980045e-03 1.4033270e-18 2.9803894e-18 2.1572521e-17
 2.3104656e-19 1.6113302e-18 5.8887582e-20 1.0406164e-15 1.2749614e-01
 9.6778653e-19], sum to 1.0000
[2019-04-24 10:18:21,539] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4767
[2019-04-24 10:18:21,565] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.533333333333333, 94.0, 0.0, 0.0, 19.0, 21.25383353115616, -0.6083243877628078, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 13200.0000, 
sim time next is 14400.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 20.81372975247069, -0.6739907474307438, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.2344774793725574, 0.2753364175230854, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42553738], dtype=float32), -1.8938756]. 
=============================================
[2019-04-24 10:18:25,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3612907e-01 3.6264912e-03 2.1523657e-18 2.0056743e-18 7.2030929e-18
 2.1985117e-19 2.1040295e-19 7.1509305e-20 5.9186480e-16 1.6024446e-01
 1.2328541e-18], sum to 1.0000
[2019-04-24 10:18:25,864] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5575
[2019-04-24 10:18:25,876] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.3, 86.0, 91.5, 0.0, 19.0, 20.68599134345266, -0.6390509487355833, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 46800.0000, 
sim time next is 48000.0000, 
raw observation next is [8.100000000000001, 86.0, 88.5, 0.0, 19.0, 20.50971117915596, -0.6673608759206623, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.6869806094182827, 0.86, 0.295, 0.0, 0.08333333333333333, 0.20914259826299672, 0.27754637469311255, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4761776], dtype=float32), 0.80650306]. 
=============================================
[2019-04-24 10:18:26,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0448022e-01 3.0070271e-03 1.2982975e-18 2.4396627e-18 7.7907071e-18
 1.4424332e-19 2.5570358e-19 2.4844305e-20 7.5947563e-16 9.2512742e-02
 6.1300566e-19], sum to 1.0000
[2019-04-24 10:18:26,551] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2373
[2019-04-24 10:18:26,603] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.533333333333333, 86.0, 80.33333333333334, 0.0, 19.0, 21.7606944438451, -0.4734127022173011, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 51600.0000, 
sim time next is 52800.0000, 
raw observation next is [7.366666666666667, 86.0, 74.16666666666667, 0.0, 19.0, 21.40486371269738, -0.5596973841632925, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6666666666666667, 0.86, 0.24722222222222223, 0.0, 0.08333333333333333, 0.2837386427247817, 0.3134342052789025, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.3793323], dtype=float32), 0.82775646]. 
=============================================
[2019-04-24 10:18:37,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9945893e-01 1.5238714e-02 1.2814692e-13 9.8491195e-14 1.9986672e-13
 3.4113822e-14 5.2172967e-14 9.5506785e-15 7.4961105e-12 7.8530240e-01
 2.8404064e-14], sum to 1.0000
[2019-04-24 10:18:37,546] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4323
[2019-04-24 10:18:37,618] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.9, 71.0, 77.0, 25.5, 19.0, 18.95045258904997, -1.22406912535708, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 637200.0000, 
sim time next is 638400.0000, 
raw observation next is [-3.9, 69.0, 115.6666666666667, 42.5, 19.0, 18.88178419040957, -0.9817626927424089, 0.0, 1.0, 60.0, 91.59250224129383], 
processed observation next is [0.0, 0.391304347826087, 0.3545706371191136, 0.69, 0.38555555555555565, 0.04696132596685083, 0.08333333333333333, 0.07348201586746406, 0.1727457690858637, 0.0, 1.0, 0.9, 0.9159250224129383], 
reward next is 0.1805, 
noisyNet noise sample is [array([-2.203064], dtype=float32), -0.29882523]. 
=============================================
[2019-04-24 10:18:37,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1647576e-01 1.9049043e-02 5.0159916e-14 9.4833057e-14 1.0506197e-13
 1.6084631e-14 1.6601544e-14 6.0605322e-15 6.9301535e-12 3.6447525e-01
 1.6587807e-14], sum to 1.0000
[2019-04-24 10:18:37,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3678
[2019-04-24 10:18:37,672] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 67.0, 129.1666666666667, 42.5, 19.0, 19.48686566232689, -1.098391405309511, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 639600.0000, 
sim time next is 640800.0000, 
raw observation next is [-3.9, 65.0, 117.5, 25.5, 19.0, 18.92882658102996, -1.222803003348177, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3545706371191136, 0.65, 0.39166666666666666, 0.0281767955801105, 0.08333333333333333, 0.07740221508582994, 0.09239899888394103, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9797, 
noisyNet noise sample is [array([-2.203064], dtype=float32), -0.29882523]. 
=============================================
[2019-04-24 10:18:39,717] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.98468029e-01 2.63113081e-02 7.38385996e-14 1.01560714e-13
 1.62822514e-13 1.82859590e-14 4.95348933e-14 1.12126181e-14
 9.90856269e-12 2.75220633e-01 2.03457602e-14], sum to 1.0000
[2019-04-24 10:18:39,719] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3778
[2019-04-24 10:18:39,733] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 69.0, 0.0, 0.0, 19.0, 18.97531931109478, -0.9894607492234871, 0.0, 1.0, 60.0, 95.2525061938733], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 682800.0000, 
sim time next is 684000.0000, 
raw observation next is [-3.4, 69.0, 0.0, 0.0, 19.0, 19.73522922117667, -1.102485067543902, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.368421052631579, 0.69, 0.0, 0.0, 0.08333333333333333, 0.14460243509805584, 0.13250497748536602, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15601209], dtype=float32), -0.1876923]. 
=============================================
[2019-04-24 10:18:42,463] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.5590259e-01 5.9813811e-03 1.5912897e-17 2.8050806e-16 1.3533833e-16
 8.9788119e-19 1.5144451e-17 9.5592073e-19 7.3659937e-14 2.3811607e-01
 6.6129161e-18], sum to 1.0000
[2019-04-24 10:18:42,465] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6991
[2019-04-24 10:18:42,520] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 96.0, 0.0, 0.0, 19.0, 21.11445160309753, -0.7678648847616948, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 507600.0000, 
sim time next is 508800.0000, 
raw observation next is [1.966666666666667, 94.66666666666666, 0.0, 0.0, 19.0, 20.52751557362514, -0.8498948761838502, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.5170821791320407, 0.9466666666666665, 0.0, 0.0, 0.08333333333333333, 0.2106262978020951, 0.2167017079387166, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5881912], dtype=float32), 0.77181137]. 
=============================================
[2019-04-24 10:18:43,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7836397e-01 7.3565375e-03 2.2654159e-15 9.5121775e-15 4.9240587e-15
 3.6919310e-16 5.1218298e-16 6.0023163e-17 3.0608572e-13 1.1427944e-01
 1.3273415e-15], sum to 1.0000
[2019-04-24 10:18:43,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9842
[2019-04-24 10:18:43,707] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.2, 83.0, 90.16666666666667, 68.33333333333333, 19.0, 20.37678060596036, -0.8576341065787872, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 574800.0000, 
sim time next is 576000.0000, 
raw observation next is [-1.2, 83.0, 70.5, 59.0, 19.0, 20.32107282112122, -0.6254538085376619, 0.0, 1.0, 60.0, 88.59503943937578], 
processed observation next is [0.0, 0.6956521739130435, 0.42936288088642666, 0.83, 0.235, 0.06519337016574586, 0.08333333333333333, 0.193422735093435, 0.29151539715411273, 0.0, 1.0, 0.9, 0.8859503943937578], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52924395], dtype=float32), 0.05833521]. 
=============================================
[2019-04-24 10:18:47,285] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7765450e-01 4.0616017e-02 2.4353303e-14 2.9054948e-14 7.8499402e-14
 1.4641686e-14 1.3407116e-14 4.6009059e-15 3.2217228e-12 2.8172946e-01
 2.2014557e-14], sum to 1.0000
[2019-04-24 10:18:47,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5858
[2019-04-24 10:18:47,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5046277e-01 4.4053607e-03 7.2424202e-16 2.7233007e-15 2.5707873e-15
 1.2028865e-17 6.4271556e-17 9.9969277e-17 5.0588776e-13 2.4513191e-01
 1.7952319e-16], sum to 1.0000
[2019-04-24 10:18:47,298] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1243
[2019-04-24 10:18:47,312] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.3, 75.0, 0.0, 0.0, 19.0, 19.28182630941184, -0.9021574361289854, 0.0, 1.0, 60.0, 94.55289315478542], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 618000.0000, 
sim time next is 619200.0000, 
raw observation next is [-4.5, 75.0, 0.0, 0.0, 19.0, 19.79879992003223, -1.040724679209032, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.3379501385041552, 0.75, 0.0, 0.0, 0.08333333333333333, 0.14989999333601922, 0.1530917735969893, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6538458], dtype=float32), -1.1371009]. 
=============================================
[2019-04-24 10:18:47,398] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 82.0, 0.0, 0.0, 22.5, 23.24619063778209, -0.3589557862016783, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 842400.0000, 
sim time next is 843600.0000, 
raw observation next is [-3.9, 83.33333333333334, 0.0, 0.0, 22.5, 22.29390113310545, -0.5351506492407044, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.8333333333333335, 0.0, 0.0, 0.375, 0.3578250944254542, 0.32161645025309854, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9691, 
noisyNet noise sample is [array([0.7669066], dtype=float32), 1.373599]. 
=============================================
[2019-04-24 10:18:51,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5287895e-01 1.7315001e-03 1.9033131e-16 5.4517577e-15 3.1717077e-15
 5.1239875e-17 3.8713757e-17 4.4258732e-17 3.1358358e-13 4.5389567e-02
 3.9632907e-16], sum to 1.0000
[2019-04-24 10:18:51,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9872
[2019-04-24 10:18:51,894] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.6, 45.0, 76.5, 17.0, 22.5, 24.35472327113258, -0.07941662106849269, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 748800.0000, 
sim time next is 750000.0000, 
raw observation next is [-1.333333333333333, 48.0, 70.83333333333334, 7.666666666666665, 22.5, 24.37913489483405, -0.03749705360641337, 1.0, 1.0, 60.0, 78.36979248620585], 
processed observation next is [1.0, 0.6956521739130435, 0.42566943674976926, 0.48, 0.23611111111111113, 0.008471454880294658, 0.375, 0.5315945745695041, 0.4875009821311955, 1.0, 1.0, 0.9, 0.7836979248620586], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7509323], dtype=float32), 0.013108547]. 
=============================================
[2019-04-24 10:18:51,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.30042 ]
 [72.07973 ]
 [72.245735]
 [73.46396 ]
 [74.48073 ]
 [75.31188 ]
 [76.01648 ]
 [76.50797 ]
 [75.87357 ]
 [76.0654  ]
 [76.442696]
 [77.19538 ]
 [77.96937 ]
 [78.48055 ]
 [77.40763 ]
 [76.88067 ]
 [76.432335]
 [75.389496]
 [76.2129  ]
 [76.668625]
 [76.14237 ]
 [74.96156 ]
 [74.911934]
 [75.300644]
 [74.43839 ]], R is [[70.81775665]
 [71.10958099]
 [70.39848328]
 [70.69449615]
 [70.98754883]
 [71.27767181]
 [71.56489563]
 [71.84925079]
 [71.13076019]
 [71.41945648]
 [71.70526123]
 [71.98821259]
 [72.26833344]
 [72.5456543 ]
 [71.82019806]
 [72.10199738]
 [72.38098145]
 [71.65717316]
 [71.94060516]
 [72.22119904]
 [71.49898529]
 [70.78399658]
 [70.07615662]
 [69.88464355]
 [69.47670746]].
[2019-04-24 10:18:51,905] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8883516e-01 2.3359818e-02 4.8198685e-12 2.8277923e-11 1.1827833e-11
 8.2267201e-13 5.2003991e-12 1.8730776e-12 1.1997436e-09 4.8780501e-01
 2.1147489e-12], sum to 1.0000
[2019-04-24 10:18:51,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0178
[2019-04-24 10:18:51,983] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-10.6, 49.0, 0.0, 0.0, 19.0, 19.209802616175, -1.139981779370617, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 424800.0000, 
sim time next is 426000.0000, 
raw observation next is [-10.96666666666667, 50.66666666666667, 0.0, 0.0, 19.0, 18.91900790534174, -1.195392602251751, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.15881809787626952, 0.5066666666666667, 0.0, 0.0, 0.08333333333333333, 0.07658399211181166, 0.10153579924941636, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9738, 
noisyNet noise sample is [array([-0.27829757], dtype=float32), 0.5579283]. 
=============================================
[2019-04-24 10:18:52,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2778955e-01 1.0135008e-02 2.7219226e-14 1.7532414e-13 2.9819205e-13
 1.3975865e-14 3.7857030e-14 4.2385795e-15 7.2633978e-12 1.6207540e-01
 1.0633231e-14], sum to 1.0000
[2019-04-24 10:18:52,412] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1014
[2019-04-24 10:18:52,427] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.633333333333333, 71.0, 0.0, 0.0, 19.0, 20.900517058491, -0.8560432275756882, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 783600.0000, 
sim time next is 784800.0000, 
raw observation next is [-7.8, 71.0, 0.0, 0.0, 19.0, 19.78397387254926, -1.038742811952373, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.71, 0.0, 0.0, 0.08333333333333333, 0.14866448937910506, 0.15375239601587568, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.23925704], dtype=float32), -0.673535]. 
=============================================
[2019-04-24 10:18:53,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2103380e-01 1.9409334e-03 2.2424385e-18 2.6163025e-17 1.3191426e-17
 1.8390913e-19 3.6970553e-19 2.7276188e-19 2.0814253e-15 7.7025265e-02
 1.5527466e-18], sum to 1.0000
[2019-04-24 10:18:53,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8805
[2019-04-24 10:18:53,694] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 23.59359671348186, -0.01704962447213929, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1712400.0000, 
sim time next is 1713600.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 23.01626287867506, -0.1357111620257846, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.4180219065562551, 0.45476294599140515, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24299625], dtype=float32), -0.8491358]. 
=============================================
[2019-04-24 10:18:53,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7406271e-01 1.6327266e-02 1.2376687e-14 6.0140207e-14 5.5285522e-14
 1.5554066e-15 2.9086218e-15 2.1956182e-15 1.0097720e-11 4.0961006e-01
 3.4065605e-15], sum to 1.0000
[2019-04-24 10:18:53,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3506
[2019-04-24 10:18:53,783] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.7333333333333334, 35.0, 50.00000000000001, 0.0, 22.5, 22.53356112833101, -0.5143739300934534, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 488400.0000, 
sim time next is 489600.0000, 
raw observation next is [1.1, 34.0, 38.0, 0.0, 22.5, 22.41437916946463, -0.5292018838824393, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.34, 0.12666666666666668, 0.0, 0.375, 0.36786493078871924, 0.3235993720391869, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9787, 
noisyNet noise sample is [array([0.5918338], dtype=float32), -0.8856105]. 
=============================================
[2019-04-24 10:18:56,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8930395e-01 2.0963144e-04 1.9923220e-22 7.3094703e-21 1.5885101e-20
 2.7833698e-23 8.1845240e-23 9.7758452e-23 6.0659483e-18 1.0486328e-02
 3.3096120e-22], sum to 1.0000
[2019-04-24 10:18:56,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8941
[2019-04-24 10:18:56,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 81.0, 87.83333333333334, 0.0, 22.5, 24.3340901409457, 0.371229606573116, 1.0, 1.0, 60.0, 83.6397940872783], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1003200.0000, 
sim time next is 1004400.0000, 
raw observation next is [14.4, 81.0, 75.5, 0.0, 22.5, 24.99797540746914, 0.2440447360097601, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.8614958448753465, 0.81, 0.25166666666666665, 0.0, 0.375, 0.5831646172890951, 0.5813482453365867, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.534909], dtype=float32), 1.1508845]. 
=============================================
[2019-04-24 10:18:56,744] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.81951809e-01 5.25828497e-03 1.49740327e-15 2.71334164e-14
 1.05011663e-14 9.44857947e-16 5.62736715e-16 2.11829970e-16
 5.89359345e-13 1.12789854e-01 2.91642443e-15], sum to 1.0000
[2019-04-24 10:18:56,745] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4348
[2019-04-24 10:18:56,762] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.633333333333333, 87.0, 0.0, 0.0, 19.0, 20.83152527209018, -0.7765107877187885, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 585600.0000, 
sim time next is 586800.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 19.0, 20.07529634566676, -0.9214914640753311, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.38504155124653744, 0.87, 0.0, 0.0, 0.08333333333333333, 0.17294136213889674, 0.1928361786415563, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.88700587], dtype=float32), -0.071447276]. 
=============================================
[2019-04-24 10:18:58,673] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.5145332e-01 1.1164184e-02 1.2030380e-15 4.7460344e-15 6.4976842e-15
 2.5607413e-16 1.1010256e-15 2.1704065e-16 1.7514202e-13 3.3738247e-01
 8.9238299e-16], sum to 1.0000
[2019-04-24 10:18:58,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9739
[2019-04-24 10:18:58,745] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.6, 83.0, 83.0, 138.0, 19.0, 19.4264425474715, -1.00369474863476, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 558000.0000, 
sim time next is 559200.0000, 
raw observation next is [-0.6666666666666667, 82.33333333333334, 87.0, 136.0, 19.0, 19.88705156272818, -0.6922370481957248, 0.0, 1.0, 60.0, 94.68359179985384], 
processed observation next is [0.0, 0.4782608695652174, 0.44413665743305636, 0.8233333333333335, 0.29, 0.15027624309392265, 0.08333333333333333, 0.15725429689401485, 0.26925431726809174, 0.0, 1.0, 0.9, 0.9468359179985384], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06643046], dtype=float32), -0.6486858]. 
=============================================
[2019-04-24 10:19:03,590] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.5679944e-01 5.4415027e-03 1.3507563e-14 6.1242224e-14 3.3782100e-14
 1.4807472e-15 6.4938560e-15 4.8174368e-15 7.8146821e-12 3.3775911e-01
 2.8193917e-15], sum to 1.0000
[2019-04-24 10:19:03,591] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4483
[2019-04-24 10:19:03,600] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 54.0, 0.0, 0.0, 22.5, 20.7734931348314, -0.6909200868735681, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 758400.0000, 
sim time next is 759600.0000, 
raw observation next is [-3.9, 53.0, 0.0, 0.0, 22.5, 20.58459806052465, -0.7365147708092006, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3545706371191136, 0.53, 0.0, 0.0, 0.375, 0.21538317171038765, 0.25449507639693314, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8727575], dtype=float32), -0.045864996]. 
=============================================
[2019-04-24 10:19:05,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8680840e-01 6.2085653e-04 6.2911803e-21 1.6118805e-20 3.0905264e-20
 2.5243463e-22 2.5820431e-21 4.7872781e-23 2.6850896e-17 1.1257077e-01
 3.4581731e-22], sum to 1.0000
[2019-04-24 10:19:05,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0154
[2019-04-24 10:19:05,340] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 81.0, 106.5, 0.0, 22.5, 24.15943492171332, 0.0932185483936319, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1000800.0000, 
sim time next is 1002000.0000, 
raw observation next is [14.4, 81.0, 98.16666666666667, 0.0, 22.5, 24.39199170984492, 0.1275246402428871, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.8614958448753465, 0.81, 0.32722222222222225, 0.0, 0.375, 0.53266597582041, 0.5425082134142957, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17260733], dtype=float32), 2.49343]. 
=============================================
[2019-04-24 10:19:08,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8170127e-01 7.0483759e-03 2.6593220e-15 7.5460818e-15 4.2635484e-15
 9.7814882e-17 6.5798229e-16 1.5856656e-15 3.9545923e-12 2.1125033e-01
 5.6086461e-16], sum to 1.0000
[2019-04-24 10:19:08,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4425
[2019-04-24 10:19:08,264] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.733333333333333, 85.0, 0.0, 0.0, 22.5, 20.66722319991071, -0.8014023193004641, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 847200.0000, 
sim time next is 848400.0000, 
raw observation next is [-3.566666666666666, 84.0, 0.0, 0.0, 22.5, 20.18034115054664, -0.8783991794427912, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3638042474607572, 0.84, 0.0, 0.0, 0.375, 0.18169509587888655, 0.20720027351906958, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13550189], dtype=float32), -0.7810419]. 
=============================================
[2019-04-24 10:19:10,815] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8339003e-01 8.1465190e-04 1.1571083e-16 1.7309406e-15 1.9060842e-15
 8.9987205e-17 6.1557961e-17 7.8515792e-17 2.7687827e-13 1.5795408e-02
 6.5741462e-16], sum to 1.0000
[2019-04-24 10:19:10,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3655
[2019-04-24 10:19:10,834] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.26666666666667, 77.0, 0.0, 0.0, 19.0, 22.68697403115654, -0.100590052959508, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1208400.0000, 
sim time next is 1209600.0000, 
raw observation next is [16.1, 78.0, 0.0, 0.0, 19.0, 22.59629521609954, -0.1143483509714707, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.78, 0.0, 0.0, 0.08333333333333333, 0.38302460134162847, 0.4618838830095098, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2911986], dtype=float32), -0.3125968]. 
=============================================
[2019-04-24 10:19:13,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6132165e-01 9.7039767e-04 7.7875584e-20 2.8953392e-19 1.9996300e-19
 3.1879210e-21 2.6411255e-21 1.3439983e-21 6.1410037e-16 3.7707932e-02
 9.5146878e-21], sum to 1.0000
[2019-04-24 10:19:13,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4302
[2019-04-24 10:19:13,448] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 49.0, 133.8333333333333, 0.0, 22.5, 25.09878616532543, 0.2962494052693078, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1608000.0000, 
sim time next is 1609200.0000, 
raw observation next is [13.8, 49.0, 111.5, 0.0, 22.5, 25.23072689182752, 0.3092625011237382, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.844875346260388, 0.49, 0.37166666666666665, 0.0, 0.375, 0.6025605743189599, 0.6030875003745794, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0084194], dtype=float32), 0.42175123]. 
=============================================
[2019-04-24 10:19:14,249] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6148053e-01 2.8681299e-03 9.4322413e-18 1.9959448e-17 4.5960851e-17
 1.0921527e-18 2.5549750e-18 1.8714355e-18 3.7878602e-14 1.3565139e-01
 3.8390871e-18], sum to 1.0000
[2019-04-24 10:19:14,249] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2536
[2019-04-24 10:19:14,263] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 90.66666666666667, 0.0, 0.0, 22.5, 23.65033158901364, -0.3787139046739205, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1444800.0000, 
sim time next is 1446000.0000, 
raw observation next is [1.1, 89.33333333333334, 0.0, 0.0, 22.5, 21.90193404381161, -0.3853509931735014, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.49307479224376743, 0.8933333333333334, 0.0, 0.0, 0.375, 0.32516117031763425, 0.3715496689421662, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15730089], dtype=float32), 0.864309]. 
=============================================
[2019-04-24 10:19:15,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.1074876e-01 2.7426162e-03 3.3294197e-20 1.3193855e-19 3.6596386e-20
 9.0273284e-22 1.0919366e-20 3.7582871e-22 9.2354021e-17 1.8650867e-01
 2.7183560e-21], sum to 1.0000
[2019-04-24 10:19:15,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2904
[2019-04-24 10:19:15,401] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.36666666666667, 86.0, 126.6666666666667, 0.0, 22.5, 24.17524590455827, -0.07296036720163826, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 994800.0000, 
sim time next is 996000.0000, 
raw observation next is [12.53333333333333, 86.0, 126.5, 0.0, 22.5, 23.18817565960745, -0.0969458061259375, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.8097876269621421, 0.86, 0.4216666666666667, 0.0, 0.375, 0.43234797163395405, 0.4676847312913542, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.51948094], dtype=float32), -1.9905818]. 
=============================================
[2019-04-24 10:19:17,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3114632e-01 1.5020130e-03 1.5324368e-18 5.1135375e-18 8.3144142e-18
 6.4742563e-19 3.6100706e-19 4.9023334e-20 8.2592917e-16 6.7351669e-02
 6.2698243e-19], sum to 1.0000
[2019-04-24 10:19:17,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6336
[2019-04-24 10:19:17,132] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.63333333333333, 69.66666666666667, 90.83333333333333, 0.0, 19.0, 21.76452144584873, -0.2928399211371865, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1158000.0000, 
sim time next is 1159200.0000, 
raw observation next is [17.2, 67.0, 106.5, 0.0, 19.0, 21.7738454910657, -0.2864714141229586, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.9390581717451525, 0.67, 0.355, 0.0, 0.08333333333333333, 0.314487124255475, 0.4045095286256804, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.65010935], dtype=float32), -0.95349115]. 
=============================================
[2019-04-24 10:19:17,995] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.7264910e-01 1.6400927e-03 6.3074050e-17 4.9893994e-16 2.0897457e-15
 4.3507004e-17 7.0402308e-17 2.0296951e-17 7.7557074e-14 2.5710782e-02
 1.6463275e-16], sum to 1.0000
[2019-04-24 10:19:18,003] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6480
[2019-04-24 10:19:18,012] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.0, 96.0, 0.0, 0.0, 19.0, 22.23374535221268, -0.1784398974027937, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1230000.0000, 
sim time next is 1231200.0000, 
raw observation next is [15.0, 96.0, 0.0, 0.0, 19.0, 22.19578444235351, -0.1869433161704417, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.8781163434903049, 0.96, 0.0, 0.0, 0.08333333333333333, 0.34964870352945915, 0.4376855612765194, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.626527], dtype=float32), -0.9640194]. 
=============================================
[2019-04-24 10:19:25,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3186034e-01 2.7614128e-02 5.4087499e-14 3.7199524e-13 2.7066508e-13
 1.5784586e-14 1.3643840e-13 1.8802381e-14 2.1215045e-11 2.4052554e-01
 1.9242283e-14], sum to 1.0000
[2019-04-24 10:19:25,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2683
[2019-04-24 10:19:25,347] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.3, 88.0, 0.0, 0.0, 19.0, 17.53808108226521, -1.328775295582426, 0.0, 1.0, 20.0, 82.09297470100695], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1924800.0000, 
sim time next is 1926000.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 19.0, 18.14921956982927, -1.43561490686191, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.08333333333333333, 0.012434964152439202, 0.02146169771269668, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.47854], dtype=float32), 0.58549947]. 
=============================================
[2019-04-24 10:19:25,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.27123344e-01 2.31173225e-02 5.33921526e-14 5.03526582e-13
 6.08458975e-13 7.23014652e-14 8.19608053e-14 2.14505215e-14
 1.99352063e-11 1.49759337e-01 1.02926666e-13], sum to 1.0000
[2019-04-24 10:19:25,976] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9409
[2019-04-24 10:19:26,054] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.1, 28.0, 0.0, 0.0, 19.0, 19.3236093125792, -1.111025655834191, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2484000.0000, 
sim time next is 2485200.0000, 
raw observation next is [0.7333333333333335, 28.66666666666667, 0.0, 0.0, 19.0, 19.78380442816836, -0.8003493385433721, 0.0, 1.0, 60.0, 94.87490715908177], 
processed observation next is [0.0, 0.782608695652174, 0.4829178208679595, 0.28666666666666674, 0.0, 0.0, 0.08333333333333333, 0.14865036901402995, 0.2332168871522093, 0.0, 1.0, 0.9, 0.9487490715908177], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.025073], dtype=float32), -0.4325196]. 
=============================================
[2019-04-24 10:19:26,179] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.2094842e-01 7.9442495e-03 1.4695007e-16 5.6945755e-16 6.7458826e-16
 1.1719986e-17 5.9411936e-17 7.9702938e-18 4.2638243e-14 1.7110728e-01
 2.0394360e-17], sum to 1.0000
[2019-04-24 10:19:26,180] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7186
[2019-04-24 10:19:26,202] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 0.0, 0.0, 19.0, 20.60191246514194, -0.6579846164547725, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1730400.0000, 
sim time next is 1731600.0000, 
raw observation next is [0.5, 92.0, 0.0, 0.0, 19.0, 20.47248611766237, -0.6917387762900007, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.4764542936288089, 0.92, 0.0, 0.0, 0.08333333333333333, 0.20604050980519753, 0.2694204079033331, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7170992], dtype=float32), 0.8105528]. 
=============================================
[2019-04-24 10:19:28,349] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.4581079e-01 1.4496375e-03 1.3172703e-18 1.7376009e-17 1.6295751e-17
 3.9192670e-19 4.3784505e-19 6.9843972e-19 3.3779043e-15 5.2739505e-02
 1.4727087e-18], sum to 1.0000
[2019-04-24 10:19:28,350] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0256
[2019-04-24 10:19:28,370] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 84.0, 95.0, 0.0, 22.5, 23.67484577328385, -0.1290172095237369, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1684800.0000, 
sim time next is 1686000.0000, 
raw observation next is [1.1, 85.33333333333334, 103.0, 0.0, 22.5, 23.47597559351626, -0.2527665692005712, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.8533333333333334, 0.3433333333333333, 0.0, 0.375, 0.45633129945968837, 0.4157444769331429, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.327675], dtype=float32), -0.06566]. 
=============================================
[2019-04-24 10:19:29,907] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.7014272e-01 5.9983146e-04 2.7784834e-19 2.1300376e-18 8.4439874e-19
 6.4063188e-21 2.3443533e-20 3.8572147e-21 6.4272638e-16 2.9257325e-02
 5.7241965e-20], sum to 1.0000
[2019-04-24 10:19:29,910] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1102
[2019-04-24 10:19:29,925] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.6, 86.0, 0.0, 0.0, 19.0, 22.98355191542014, -0.07252234395878197, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1634400.0000, 
sim time next is 1635600.0000, 
raw observation next is [6.800000000000001, 84.66666666666667, 0.0, 0.0, 19.0, 22.77483907893674, -0.1696192825865174, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6509695290858727, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.39790325657806164, 0.4434602391378275, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.8092463], dtype=float32), -0.65441453]. 
=============================================
[2019-04-24 10:19:31,873] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.7729343e-01 7.4079010e-04 3.1504285e-20 4.1745970e-19 1.1729986e-18
 1.4043388e-20 2.7127947e-20 5.1802255e-21 1.3048772e-16 2.1965774e-02
 2.4583153e-20], sum to 1.0000
[2019-04-24 10:19:31,881] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2536
[2019-04-24 10:19:31,902] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 92.0, 0.0, 0.0, 19.0, 22.95795563248221, -0.1900752792935126, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1666800.0000, 
sim time next is 1668000.0000, 
raw observation next is [4.433333333333334, 92.0, 0.0, 0.0, 22.5, 22.60050723367483, -0.2830227449872814, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.5854108956602032, 0.92, 0.0, 0.0, 0.375, 0.3833756028062358, 0.4056590850042395, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.49525756], dtype=float32), 0.08061565]. 
=============================================
[2019-04-24 10:19:34,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0085334e-01 5.7653252e-02 9.5814979e-12 1.5862891e-11 7.7575281e-12
 9.2559673e-13 4.7112492e-12 1.1838697e-12 3.0414543e-10 5.4149348e-01
 1.0525057e-12], sum to 1.0000
[2019-04-24 10:19:34,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7964
[2019-04-24 10:19:35,109] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-15.0, 83.0, 0.0, 0.0, 19.0, 19.31185263360628, -1.170326856440746, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2703600.0000, 
sim time next is 2704800.0000, 
raw observation next is [-15.0, 83.0, 0.0, 0.0, 22.5, 18.96453074995269, -0.9194176593883404, 0.0, 1.0, 60.0, 104.44385477483564], 
processed observation next is [1.0, 0.30434782608695654, 0.04709141274238226, 0.83, 0.0, 0.0, 0.375, 0.0803775624960575, 0.1935274468705532, 0.0, 1.0, 0.9, 1.0444385477483564], 
reward next is 0.0659, 
noisyNet noise sample is [array([-0.51400214], dtype=float32), -0.8599888]. 
=============================================
[2019-04-24 10:19:43,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0851296e-01 2.7344950e-02 2.9120266e-13 2.3935045e-13 4.3691025e-13
 6.5612988e-14 1.9491742e-13 2.1143875e-14 2.3309771e-11 6.6414207e-01
 4.9642094e-14], sum to 1.0000
[2019-04-24 10:19:43,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4082
[2019-04-24 10:19:43,925] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.0, 86.0, 0.0, 0.0, 19.0, 18.54047096770321, -1.252058591921417, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1804800.0000, 
sim time next is 1806000.0000, 
raw observation next is [-5.0, 86.0, 0.0, 0.0, 19.0, 18.84091856920199, -0.9356256547894514, 0.0, 1.0, 60.0, 103.04017819069259], 
processed observation next is [0.0, 0.9130434782608695, 0.32409972299168976, 0.86, 0.0, 0.0, 0.08333333333333333, 0.07007654743349907, 0.18812478173684954, 0.0, 1.0, 0.9, 1.0304017819069258], 
reward next is 0.3182, 
noisyNet noise sample is [array([0.86365604], dtype=float32), -0.21582535]. 
=============================================
[2019-04-24 10:19:46,152] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5471019e-01 6.3185737e-04 7.7850941e-19 2.0497157e-17 1.5568748e-17
 1.1300783e-19 2.5412555e-19 1.8659579e-19 2.6779902e-15 4.4657968e-02
 8.8987284e-19], sum to 1.0000
[2019-04-24 10:19:46,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3963
[2019-04-24 10:19:46,167] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 93.0, 16.83333333333333, 43.16666666666667, 22.5, 24.0309637769526, -0.09139043783362562, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2913600.0000, 
sim time next is 2914800.0000, 
raw observation next is [1.333333333333333, 93.0, 0.0, 0.0, 22.5, 23.43063876911051, -0.1852701197025233, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4995383194829178, 0.93, 0.0, 0.0, 0.375, 0.45255323075920906, 0.43824329343249224, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.179961], dtype=float32), -1.4936433]. 
=============================================
[2019-04-24 10:19:47,817] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5927340e-01 1.7031017e-03 1.9679858e-15 5.3460749e-14 5.8843599e-15
 9.0722066e-17 2.5593153e-16 5.0500814e-16 3.5335502e-12 3.9023537e-02
 1.0907833e-15], sum to 1.0000
[2019-04-24 10:19:47,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1777
[2019-04-24 10:19:47,855] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 62.0, 124.5, 0.0, 22.5, 22.5194185835773, -0.427698296387559, 1.0, 1.0, 60.0, 90.75229480055614], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1951200.0000, 
sim time next is 1952400.0000, 
raw observation next is [-3.2, 62.0, 116.1666666666667, 0.0, 22.5, 22.79810391317476, -0.421848197695566, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.37396121883656513, 0.62, 0.38722222222222236, 0.0, 0.375, 0.39984199276456334, 0.359383934101478, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.87040424], dtype=float32), -0.2517133]. 
=============================================
[2019-04-24 10:19:47,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6493046e-01 1.4025651e-02 6.0902868e-14 1.1838000e-13 3.1227069e-13
 1.5124542e-14 1.6864248e-14 3.8769096e-15 6.9522157e-12 3.2104391e-01
 3.6299404e-14], sum to 1.0000
[2019-04-24 10:19:47,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7476
[2019-04-24 10:19:48,063] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 83.0, 0.0, 0.0, 19.0, 20.60098664127345, -0.9505528870393413, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1882800.0000, 
sim time next is 1884000.0000, 
raw observation next is [-4.866666666666667, 84.0, 0.0, 0.0, 19.0, 20.3494417755525, -0.8029038514025766, 0.0, 1.0, 60.0, 85.68918962197174], 
processed observation next is [0.0, 0.8260869565217391, 0.3277931671283472, 0.84, 0.0, 0.0, 0.08333333333333333, 0.19578681462937494, 0.2323653828658078, 0.0, 1.0, 0.9, 0.8568918962197174], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6354235], dtype=float32), -0.74266475]. 
=============================================
[2019-04-24 10:19:52,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.9838061e-01 1.6963871e-02 3.4168729e-15 9.4944235e-14 2.5682305e-14
 8.0289777e-16 2.3337342e-15 2.7359783e-15 1.8735343e-12 1.8465556e-01
 1.3431653e-15], sum to 1.0000
[2019-04-24 10:19:52,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2641
[2019-04-24 10:19:52,265] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 87.0, 0.0, 0.0, 19.0, 20.26920447809211, -0.9476800162296725, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2005200.0000, 
sim time next is 2006400.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 19.0, 19.70578741918539, -1.036677949604033, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.1421489515987826, 0.15444068346532233, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9461797], dtype=float32), -0.17851686]. 
=============================================
[2019-04-24 10:19:56,802] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.7120427e-01 3.5093438e-02 9.6840626e-14 7.9157445e-14 1.9930833e-13
 2.3945962e-15 3.1377065e-14 3.7801844e-15 3.3771139e-12 2.9370236e-01
 5.0428784e-15], sum to 1.0000
[2019-04-24 10:19:56,804] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5952
[2019-04-24 10:19:56,821] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 78.0, 0.0, 0.0, 19.0, 20.63045573666216, -0.8900481786997467, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2170800.0000, 
sim time next is 2172000.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 20.03246445247417, -1.041230082225932, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.16937203770618078, 0.15292330592468936, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7553271], dtype=float32), 0.4844901]. 
=============================================
[2019-04-24 10:20:02,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4670333e-01 1.2436726e-02 3.3704190e-14 9.9729076e-14 1.0446156e-13
 1.6271042e-14 3.1157016e-14 3.1608741e-15 1.0026914e-11 2.4085988e-01
 1.4059736e-13], sum to 1.0000
[2019-04-24 10:20:02,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8101
[2019-04-24 10:20:02,524] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.566666666666667, 52.0, 181.1666666666667, 325.6666666666666, 19.0, 19.51629521334905, -0.9785830471358081, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2374800.0000, 
sim time next is 2376000.0000, 
raw observation next is [-1.2, 47.0, 209.5, 365.0, 19.0, 19.90389583966741, -0.6653309223036149, 0.0, 1.0, 60.0, 91.04768744286915], 
processed observation next is [0.0, 0.5217391304347826, 0.42936288088642666, 0.47, 0.6983333333333334, 0.40331491712707185, 0.08333333333333333, 0.1586579866389508, 0.27822302589879505, 0.0, 1.0, 0.9, 0.9104768744286915], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33408445], dtype=float32), -0.36929998]. 
=============================================
[2019-04-24 10:20:04,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5022701e-01 5.1178392e-03 8.6306245e-15 1.6836752e-14 2.5882134e-14
 2.6329937e-16 8.9718238e-16 1.8280851e-15 6.1971652e-12 3.4465519e-01
 1.3598346e-15], sum to 1.0000
[2019-04-24 10:20:04,553] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0976
[2019-04-24 10:20:04,575] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 63.0, 0.0, 0.0, 22.5, 20.2520537919714, -0.7732120722895749, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2664000.0000, 
sim time next is 2665200.0000, 
raw observation next is [-1.2, 63.66666666666667, 0.0, 0.0, 19.0, 20.08105892547455, -0.8101497571069979, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.6366666666666667, 0.0, 0.0, 0.08333333333333333, 0.17342157712287923, 0.22995008096433403, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5592141], dtype=float32), 0.113260634]. 
=============================================
[2019-04-24 10:20:06,109] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.4083545e-01 3.4372523e-02 2.9691207e-13 1.7405957e-13 3.0058508e-13
 5.6835087e-14 1.0645569e-13 2.3187120e-14 1.5743653e-11 6.2479198e-01
 3.0711619e-14], sum to 1.0000
[2019-04-24 10:20:06,111] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4308
[2019-04-24 10:20:06,205] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.4, 69.0, 31.16666666666667, 0.0, 19.0, 20.17180785798106, -0.9977265615295027, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2362800.0000, 
sim time next is 2364000.0000, 
raw observation next is [-3.4, 69.0, 51.0, 59.99999999999999, 19.0, 19.83670281632081, -0.8360197984790035, 0.0, 1.0, 60.0, 85.24027286485315], 
processed observation next is [0.0, 0.34782608695652173, 0.368421052631579, 0.69, 0.17, 0.06629834254143646, 0.08333333333333333, 0.1530585680267341, 0.22132673384033216, 0.0, 1.0, 0.9, 0.8524027286485315], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23151945], dtype=float32), 0.58642244]. 
=============================================
[2019-04-24 10:20:06,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0320710e-01 1.1578277e-02 1.1673373e-13 1.2856346e-13 2.3551915e-13
 6.3535582e-14 2.3716077e-14 3.4754234e-15 8.8304104e-12 1.8521462e-01
 1.3708289e-13], sum to 1.0000
[2019-04-24 10:20:06,742] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3459
[2019-04-24 10:20:06,777] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.3, 26.66666666666667, 64.66666666666667, 697.3333333333334, 19.0, 20.14761710602994, -0.9090999752180688, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2474400.0000, 
sim time next is 2475600.0000, 
raw observation next is [3.3, 26.33333333333334, 59.66666666666667, 613.1666666666667, 19.0, 19.95281392439598, -0.9377228884470377, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.554016620498615, 0.2633333333333334, 0.1988888888888889, 0.6775322283609577, 0.08333333333333333, 0.16273449369966494, 0.18742570385098745, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2420077], dtype=float32), -0.9995627]. 
=============================================
[2019-04-24 10:20:11,285] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.3449880e-01 1.8270012e-02 7.0568296e-13 1.1889183e-12 1.4740723e-12
 1.1080494e-13 1.8871651e-13 5.5178559e-14 3.9642463e-11 2.4723123e-01
 3.1850970e-13], sum to 1.0000
[2019-04-24 10:20:11,286] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6725
[2019-04-24 10:20:11,295] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 35.0, 0.0, 0.0, 19.0, 19.8811526892132, -1.066007236575029, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2502000.0000, 
sim time next is 2503200.0000, 
raw observation next is [-0.9666666666666667, 36.0, 0.0, 0.0, 19.0, 19.36060438936269, -1.142813336214018, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.43582640812557716, 0.36, 0.0, 0.0, 0.08333333333333333, 0.11338369911355735, 0.11906222126199399, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8185322], dtype=float32), 0.51822805]. 
=============================================
[2019-04-24 10:20:17,955] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2790598e-01 2.7584350e-03 2.8542401e-15 3.9816152e-15 4.1249488e-15
 4.2572016e-16 3.1353539e-16 7.7506340e-17 6.5082293e-13 6.9335580e-02
 7.1119242e-16], sum to 1.0000
[2019-04-24 10:20:17,957] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7394
[2019-04-24 10:20:17,996] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 84.33333333333334, 0.0, 0.0, 19.0, 20.09128525262379, -0.5691944936031851, 0.0, 1.0, 60.0, 101.17071973956459], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2947200.0000, 
sim time next is 2948400.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 21.01079799097067, -0.6943871844200499, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.2508998325808891, 0.2685376051933167, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6119531], dtype=float32), 1.0014491]. 
=============================================
[2019-04-24 10:20:19,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1643822e-01 6.9822842e-04 4.9297571e-19 3.0015584e-18 2.7497235e-18
 1.5869061e-20 2.9156288e-20 1.8995531e-20 2.0256435e-15 8.2863554e-02
 6.8458041e-19], sum to 1.0000
[2019-04-24 10:20:19,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9732
[2019-04-24 10:20:19,992] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 19.0, 22.24654157163892, -0.2145929139713948, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3184800.0000, 
sim time next is 3186000.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 19.0, 22.70157399653713, 0.0947579305534552, 0.0, 1.0, 60.0, 91.81481059753287], 
processed observation next is [1.0, 0.9130434782608695, 0.5457063711911359, 1.0, 0.0, 0.0, 0.08333333333333333, 0.39179783304476096, 0.5315859768511517, 0.0, 1.0, 0.9, 0.9181481059753287], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.65902185], dtype=float32), 1.4800599]. 
=============================================
[2019-04-24 10:20:21,220] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.3150083e-01 1.5010821e-02 5.7159335e-14 3.9969330e-13 5.1869977e-13
 2.8799357e-14 9.0156452e-14 2.7532269e-14 2.3379566e-11 1.5348835e-01
 2.9176667e-13], sum to 1.0000
[2019-04-24 10:20:21,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0518
[2019-04-24 10:20:21,251] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 19.0, 20.4747126856981, -0.9219625968725516, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3028800.0000, 
sim time next is 3030000.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 19.0, 19.6445097387436, -1.076066934443149, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.32409972299168976, 0.71, 0.0, 0.0, 0.08333333333333333, 0.13704247822863339, 0.14131102185228364, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.806694], dtype=float32), 0.20365693]. 
=============================================
[2019-04-24 10:20:21,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.668976]
 [62.87082 ]
 [62.436947]
 [62.56333 ]
 [61.64205 ]
 [62.13245 ]
 [62.517662]
 [62.901165]
 [62.336693]
 [62.740746]
 [63.146973]
 [63.65772 ]
 [64.08341 ]
 [64.579475]
 [65.07711 ]
 [64.33354 ]
 [64.45283 ]
 [64.46706 ]
 [64.474434]
 [64.50124 ]
 [64.444984]
 [64.4941  ]
 [63.733383]
 [64.110985]
 [65.00511 ]], R is [[62.8255043 ]
 [63.19725037]
 [62.5652771 ]
 [62.93962479]
 [62.31023026]
 [62.68712997]
 [63.06026077]
 [63.42965698]
 [62.79536057]
 [63.16740799]
 [63.53573608]
 [63.90037918]
 [64.26137543]
 [64.61875916]
 [64.97257233]
 [64.32284546]
 [64.67961884]
 [65.03282166]
 [65.38249207]
 [65.72866821]
 [66.07138062]
 [66.41066742]
 [65.74655914]
 [66.08909607]
 [66.4282074 ]].
[2019-04-24 10:20:22,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4774216e-01 6.4940023e-04 1.0771394e-18 2.2308494e-17 1.2763131e-17
 1.6934140e-19 9.9639623e-19 1.0519100e-19 7.6047592e-15 5.1608473e-02
 8.3246304e-19], sum to 1.0000
[2019-04-24 10:20:22,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5253
[2019-04-24 10:20:22,057] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 100.0, 131.0, 0.0, 22.5, 23.02834315234134, -0.2220555198738984, 1.0, 1.0, 60.0, 99.2193089894478], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2894400.0000, 
sim time next is 2895600.0000, 
raw observation next is [1.333333333333333, 100.0, 160.3333333333333, 0.0, 22.5, 23.62080138116979, -0.2088243295983689, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4995383194829178, 1.0, 0.5344444444444443, 0.0, 0.375, 0.4684001150974826, 0.430391890133877, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.55653703], dtype=float32), -0.83922374]. 
=============================================
[2019-04-24 10:20:22,603] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.9316263e-01 1.3180622e-02 2.1557034e-14 2.3422890e-14 5.0269139e-14
 2.5055139e-15 5.0030365e-15 7.4626075e-16 1.9013261e-12 4.9365672e-01
 4.1543769e-15], sum to 1.0000
[2019-04-24 10:20:22,606] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.1010
[2019-04-24 10:20:22,632] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 19.17874583090018, -1.008419962167872, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2950800.0000, 
sim time next is 2952000.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 19.00093619420731, -1.045998047717245, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.08341134951727576, 0.15133398409425167, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3729777], dtype=float32), 0.87866586]. 
=============================================
[2019-04-24 10:20:28,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6557811e-01 1.2030605e-02 9.5385952e-14 4.5377188e-14 8.7230238e-14
 3.8049076e-15 3.4283855e-15 2.2849908e-15 8.7693091e-12 5.2239132e-01
 8.5930417e-15], sum to 1.0000
[2019-04-24 10:20:28,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4815
[2019-04-24 10:20:28,555] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 19.0, 19.82479770757897, -0.8843447939847594, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3292800.0000, 
sim time next is 3294000.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 20.09605773997748, -0.5812992820030572, 0.0, 1.0, 60.0, 101.94122479437246], 
processed observation next is [1.0, 0.13043478260869565, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.17467147833145655, 0.3062335726656476, 0.0, 1.0, 0.9, 1.0194122479437246], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5535834], dtype=float32), 0.32476854]. 
=============================================
[2019-04-24 10:20:29,339] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.4743989e-01 1.0030909e-03 1.5658893e-18 2.5034787e-17 3.1023227e-17
 1.3297383e-19 7.8724645e-19 3.0857603e-19 6.9219384e-15 1.5155713e-01
 4.2335799e-19], sum to 1.0000
[2019-04-24 10:20:29,343] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8363
[2019-04-24 10:20:29,379] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 100.0, 160.3333333333333, 0.0, 22.5, 23.29638869406575, -0.3185529288839107, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2895600.0000, 
sim time next is 2896800.0000, 
raw observation next is [1.666666666666667, 100.0, 173.1666666666667, 0.0, 22.5, 22.80704060991929, -0.3748639801753866, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5087719298245615, 1.0, 0.5772222222222224, 0.0, 0.375, 0.40058671749327424, 0.3750453399415378, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5699191], dtype=float32), 0.99882054]. 
=============================================
[2019-04-24 10:20:30,742] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.7028804e-01 1.1855920e-03 1.4099671e-17 1.7123596e-16 7.6625003e-17
 2.5702301e-18 3.4626488e-18 2.9640309e-19 6.1685174e-15 2.8526375e-02
 1.5538894e-17], sum to 1.0000
[2019-04-24 10:20:30,742] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1845
[2019-04-24 10:20:30,781] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 20.65560146978947, -0.4607125518195703, 0.0, 1.0, 60.0, 102.56568319272667], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3454800.0000, 
sim time next is 3456000.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 21.66336040106885, -0.543869337604923, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.3052800334224042, 0.31871022079835903, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10238948], dtype=float32), -1.5503527]. 
=============================================
[2019-04-24 10:20:32,610] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-24 10:20:32,617] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:20:32,617] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:20:32,619] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run10
[2019-04-24 10:20:32,638] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:20:32,640] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:20:32,642] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:20:32,644] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run10
[2019-04-24 10:20:32,661] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:20:32,665] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run10
[2019-04-24 10:21:25,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([-0.252531], dtype=float32), 0.6305966]
[2019-04-24 10:21:25,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [11.2, 80.0, 83.5, 140.0, 19.0, 21.30978400177204, -0.1983973049098779, 0.0, 1.0, 60.0, 92.10874923686288]
[2019-04-24 10:21:25,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:21:25,756] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [9.8138499e-01 7.7397563e-04 4.8335569e-20 4.1835598e-19 1.1146014e-18
 3.2477344e-20 3.5587837e-20 2.9249630e-21 8.9763311e-17 1.7840954e-02
 9.3075468e-20], sampled 0.31424448120056814
[2019-04-24 10:22:38,754] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3411.6603 61962.8117 -245.1097
[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,788] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:38,979] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,445] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3177.3664 77189.3977 -493.3348
[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,481] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:22:51,778] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,738] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3118.5672 79348.2819 -528.6674
[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,787] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:05,983] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:23:06,789] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 450000, evaluation results [450000.0, 3177.366416115961, 77189.39767218429, -493.33476859590985, 3411.6602814211783, 61962.81167397078, -245.10966985417411, 3118.56716031024, 79348.28185378396, -528.6673910665796]
[2019-04-24 10:23:10,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5379559e-01 6.5782975e-04 2.7373787e-18 7.3268069e-18 9.6585728e-18
 4.8702853e-20 4.4916342e-19 3.4539708e-20 2.9591505e-15 1.4554660e-01
 2.0072665e-19], sum to 1.0000
[2019-04-24 10:23:10,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1052
[2019-04-24 10:23:10,560] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 100.0, 151.6666666666667, 0.0, 22.5, 23.75869313883443, -0.1714222567270219, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2900400.0000, 
sim time next is 2901600.0000, 
raw observation next is [2.0, 100.0, 127.0, 0.0, 22.5, 23.52553448718939, -0.2281994134183899, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.518005540166205, 1.0, 0.42333333333333334, 0.0, 0.375, 0.4604612072657825, 0.42393352886053676, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7421283], dtype=float32), 0.33913413]. 
=============================================
[2019-04-24 10:23:17,869] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.8036546e-01 1.7915787e-04 3.6043810e-21 9.0277083e-20 4.2806855e-20
 2.8143089e-22 1.9901180e-21 4.6016349e-23 2.0403263e-17 1.9455381e-02
 3.1434129e-21], sum to 1.0000
[2019-04-24 10:23:17,870] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8676
[2019-04-24 10:23:17,969] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.866666666666667, 99.66666666666667, 86.83333333333333, 693.0, 22.5, 24.22229544928159, 0.1277811538342682, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3165600.0000, 
sim time next is 3166800.0000, 
raw observation next is [6.733333333333333, 99.33333333333334, 79.66666666666666, 649.0, 22.5, 24.32324356989183, 0.1506147343430458, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.649122807017544, 0.9933333333333334, 0.26555555555555554, 0.7171270718232045, 0.375, 0.5269369641576525, 0.5502049114476819, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24367404], dtype=float32), 1.507772]. 
=============================================
[2019-04-24 10:23:19,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6329808e-01 2.6335090e-03 3.4309493e-15 5.3650040e-14 2.1458961e-14
 4.0595989e-15 5.4509844e-15 4.8297993e-16 4.0936620e-12 3.4068409e-02
 2.2509311e-14], sum to 1.0000
[2019-04-24 10:23:19,253] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2679
[2019-04-24 10:23:19,282] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 53.33333333333334, 113.5, 815.0, 19.0, 19.3878085032387, -0.7788179392101982, 0.0, 1.0, 60.0, 84.2604296846562], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3068400.0000, 
sim time next is 3069600.0000, 
raw observation next is [-2.333333333333333, 51.66666666666666, 113.1666666666667, 815.1666666666667, 19.0, 20.44316523825577, -0.8201159907237119, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3979686057248385, 0.5166666666666666, 0.37722222222222235, 0.9007366482504605, 0.08333333333333333, 0.20359710318798077, 0.22662800309209605, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58718354], dtype=float32), 0.21429501]. 
=============================================
[2019-04-24 10:23:21,279] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.3503439e-01 2.4133190e-03 4.3245714e-18 1.8927214e-17 8.6107497e-17
 1.0328179e-18 3.3177883e-18 2.3173814e-19 2.6476689e-15 6.2552303e-02
 1.1911993e-18], sum to 1.0000
[2019-04-24 10:23:21,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8230
[2019-04-24 10:23:21,360] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 100.0, 0.0, 0.0, 19.0, 20.29652614364502, -0.8023756915789139, 0.0, 1.0, 60.0, 89.01192564060713], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3121200.0000, 
sim time next is 3122400.0000, 
raw observation next is [2.2, 100.0, 0.0, 0.0, 19.0, 20.58724729090067, -0.9550440315684742, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5235457063711911, 1.0, 0.0, 0.0, 0.08333333333333333, 0.2156039409083892, 0.18165198947717529, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.68831676], dtype=float32), -2.1660361]. 
=============================================
[2019-04-24 10:23:24,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.3493984e-01 5.5183833e-03 4.8203260e-18 2.9503193e-17 6.4722985e-17
 3.3584980e-19 2.7037720e-18 6.7672411e-19 2.6893442e-15 1.5954174e-01
 1.8333900e-18], sum to 1.0000
[2019-04-24 10:23:24,817] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1961
[2019-04-24 10:23:24,943] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.866666666666667, 100.0, 0.0, 0.0, 19.0, 20.55981413798073, -0.9197946686162731, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3127200.0000, 
sim time next is 3128400.0000, 
raw observation next is [3.0, 100.0, 0.0, 0.0, 19.0, 19.97817770722002, -1.010077426752823, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.5457063711911359, 1.0, 0.0, 0.0, 0.08333333333333333, 0.164848142268335, 0.16330752441572569, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47249585], dtype=float32), -0.24348536]. 
=============================================
[2019-04-24 10:23:27,450] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.1280273e-01 1.6910991e-02 1.7446714e-13 1.5040906e-12 8.6770429e-13
 2.4799985e-14 7.0517722e-14 1.0012578e-13 4.8913217e-11 1.7028628e-01
 4.7815992e-14], sum to 1.0000
[2019-04-24 10:23:27,470] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9869
[2019-04-24 10:23:27,632] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-11.0, 76.0, 0.0, 0.0, 19.0, 19.39691011028388, -1.084541461985727, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3308400.0000, 
sim time next is 3309600.0000, 
raw observation next is [-11.0, 78.66666666666667, 0.0, 0.0, 22.5, 19.25348870098757, -0.8311721530125885, 1.0, 1.0, 60.0, 108.16575057472909], 
processed observation next is [1.0, 0.30434782608695654, 0.15789473684210528, 0.7866666666666667, 0.0, 0.0, 0.375, 0.10445739174896425, 0.2229426156624705, 1.0, 1.0, 0.9, 1.0816575057472908], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6749421], dtype=float32), 1.8205721]. 
=============================================
[2019-04-24 10:23:34,547] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7799152e-01 1.1617515e-03 4.1190670e-16 1.5817428e-15 1.4695903e-15
 2.8960573e-17 6.6835055e-17 4.4760834e-17 2.8501092e-13 2.0846633e-02
 1.4046480e-16], sum to 1.0000
[2019-04-24 10:23:34,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0772
[2019-04-24 10:23:34,621] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666667, 88.33333333333333, 0.0, 0.0, 19.0, 22.46046145563565, -0.3090186891745445, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3274800.0000, 
sim time next is 3276000.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 21.87433506268795, -0.4340592379324921, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.32286125522399595, 0.35531358735583596, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2957234], dtype=float32), 0.44404048]. 
=============================================
[2019-04-24 10:23:40,904] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.6973890e-01 9.7818521e-04 1.3852340e-16 7.1979976e-16 3.0068055e-16
 5.4461940e-18 2.0383726e-18 2.5553663e-18 5.4179819e-14 2.9282935e-02
 3.0149125e-17], sum to 1.0000
[2019-04-24 10:23:40,907] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0085
[2019-04-24 10:23:40,933] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 60.0, 56.16666666666667, 473.6666666666667, 22.5, 23.13073519802582, -0.1916283688144963, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3775200.0000, 
sim time next is 3776400.0000, 
raw observation next is [0.0, 60.0, 40.5, 343.0, 22.5, 23.33808283739887, -0.1800152750819669, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.6, 0.135, 0.37900552486187844, 0.375, 0.4448402364499057, 0.439994908306011, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.37651035], dtype=float32), 1.7428756]. 
=============================================
[2019-04-24 10:23:44,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3287120e-01 9.0637729e-03 1.9230986e-13 1.3849955e-12 5.7866282e-13
 3.9372192e-14 4.8273597e-14 8.0579661e-14 1.4806953e-11 1.5806498e-01
 7.7965344e-14], sum to 1.0000
[2019-04-24 10:23:44,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0780
[2019-04-24 10:23:44,837] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 19.0, 20.0675492724914, -0.8661492108158854, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4060800.0000, 
sim time next is 4062000.0000, 
raw observation next is [-6.0, 38.33333333333334, 0.0, 0.0, 19.0, 19.89383458183869, -0.9061342247892381, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.3833333333333334, 0.0, 0.0, 0.08333333333333333, 0.15781954848655744, 0.1979552584035873, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.2039726], dtype=float32), -1.1064379]. 
=============================================
[2019-04-24 10:23:45,003] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3463687e-01 1.4649442e-03 1.2586288e-16 6.6868000e-16 7.7732341e-16
 1.8341314e-17 6.3154221e-17 1.0726591e-17 3.3767935e-13 1.6389818e-01
 4.5518829e-17], sum to 1.0000
[2019-04-24 10:23:45,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9075
[2019-04-24 10:23:45,048] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.0, 60.00000000000001, 115.8333333333333, 814.1666666666666, 22.5, 23.09036675187485, -0.288528822950478, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3842400.0000, 
sim time next is 3843600.0000, 
raw observation next is [-1.0, 60.0, 117.0, 824.1666666666666, 22.5, 23.52853010622894, 0.01153613731927246, 1.0, 1.0, 60.0, 86.61582585098375], 
processed observation next is [1.0, 0.4782608695652174, 0.4349030470914128, 0.6, 0.39, 0.9106813996316758, 0.375, 0.4607108421857449, 0.5038453791064241, 1.0, 1.0, 0.9, 0.8661582585098375], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2657648], dtype=float32), -0.16685222]. 
=============================================
[2019-04-24 10:23:46,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4334173e-01 5.0282343e-03 1.3828845e-14 6.7780098e-14 1.2708817e-13
 1.2615997e-14 1.4601437e-14 7.7756889e-16 4.4765615e-12 5.1630039e-02
 1.1062961e-14], sum to 1.0000
[2019-04-24 10:23:46,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3036
[2019-04-24 10:23:46,733] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 35.0, 114.8333333333333, 782.0, 19.0, 20.71258581839939, -0.7442915264440774, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4185600.0000, 
sim time next is 4186800.0000, 
raw observation next is [-1.0, 35.0, 116.5, 798.0, 19.0, 20.36453497423327, -0.8202981810042816, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.4349030470914128, 0.35, 0.3883333333333333, 0.881767955801105, 0.08333333333333333, 0.19704458118610577, 0.2265672729985728, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3596932], dtype=float32), 1.3994751]. 
=============================================
[2019-04-24 10:23:46,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0111269e-01 2.4817331e-02 1.4168709e-14 3.6964972e-14 3.8820912e-14
 1.2418415e-15 2.1687180e-15 1.2071932e-15 2.2297080e-12 2.7406996e-01
 5.7680974e-16], sum to 1.0000
[2019-04-24 10:23:46,967] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6797
[2019-04-24 10:23:46,990] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.333333333333334, 62.0, 5.0, 135.8333333333333, 22.5, 20.37713784225224, -0.831236956142464, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3914400.0000, 
sim time next is 3915600.0000, 
raw observation next is [-7.666666666666666, 60.0, 20.16666666666666, 213.5, 22.5, 19.99542844550443, -0.9253035917362832, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.25023084025854114, 0.6, 0.0672222222222222, 0.23591160220994475, 0.375, 0.16628570379203586, 0.19156546942123895, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.566588], dtype=float32), -0.5422873]. 
=============================================
[2019-04-24 10:23:49,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6190066e-01 2.0799607e-02 5.6602894e-13 1.9969987e-12 2.4337648e-12
 1.1918728e-13 2.9991469e-13 1.7597077e-13 1.3140362e-10 2.1729973e-01
 2.5998461e-13], sum to 1.0000
[2019-04-24 10:23:49,571] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9655
[2019-04-24 10:23:49,651] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-11.0, 58.0, 0.0, 0.0, 19.0, 18.83916546464329, -1.142493466640704, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3978000.0000, 
sim time next is 3979200.0000, 
raw observation next is [-11.33333333333333, 59.66666666666667, 0.0, 0.0, 19.0, 19.46153203669925, -0.7883226675576148, 0.0, 1.0, 60.0, 109.45456819683173], 
processed observation next is [1.0, 0.043478260869565216, 0.14866112650046176, 0.5966666666666667, 0.0, 0.0, 0.08333333333333333, 0.12179433639160415, 0.23722577748079507, 0.0, 1.0, 0.9, 1.0945456819683173], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3317952], dtype=float32), -0.27089307]. 
=============================================
[2019-04-24 10:23:54,238] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:23:54,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:23:55,231] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:23:55,231] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:23:55,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run8
[2019-04-24 10:23:59,024] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6004430e-01 1.3180266e-02 7.0019364e-15 1.3338303e-14 8.1130103e-14
 2.5295567e-15 5.4100994e-15 7.8926017e-16 5.9715937e-13 1.2677550e-01
 2.0055834e-15], sum to 1.0000
[2019-04-24 10:23:59,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9606
[2019-04-24 10:23:59,082] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.0, 47.66666666666666, 0.0, 0.0, 19.0, 19.51351635406126, -1.129250988515422, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4254000.0000, 
sim time next is 4255200.0000, 
raw observation next is [3.0, 49.0, 0.0, 0.0, 19.0, 19.58055246870596, -0.9337161968706083, 0.0, 1.0, 60.0, 86.10254013088561], 
processed observation next is [0.0, 0.2608695652173913, 0.5457063711911359, 0.49, 0.0, 0.0, 0.08333333333333333, 0.13171270572549668, 0.18876126770979726, 0.0, 1.0, 0.9, 0.8610254013088562], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6457605], dtype=float32), -0.65841234]. 
=============================================
[2019-04-24 10:24:02,001] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0825386e-01 1.4500744e-02 6.3484503e-14 5.6024131e-14 1.0806001e-13
 2.1012214e-14 1.4890771e-14 2.2262927e-15 6.8576052e-12 2.7724540e-01
 2.5594151e-14], sum to 1.0000
[2019-04-24 10:24:02,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8721
[2019-04-24 10:24:02,072] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.0, 44.33333333333334, 0.0, 0.0, 19.0, 19.6925750259435, -1.027592606876438, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4224000.0000, 
sim time next is 4225200.0000, 
raw observation next is [1.0, 45.66666666666667, 0.0, 0.0, 19.0, 19.98555579995609, -0.733772843333027, 0.0, 1.0, 60.0, 94.17075273578592], 
processed observation next is [0.0, 0.9130434782608695, 0.4903047091412743, 0.4566666666666667, 0.0, 0.0, 0.08333333333333333, 0.16546298332967405, 0.25540905222232435, 0.0, 1.0, 0.9, 0.9417075273578592], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14775567], dtype=float32), 0.13964759]. 
=============================================
[2019-04-24 10:24:09,510] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.0474048e-01 1.6392509e-03 2.7319195e-18 7.7167049e-19 4.4207299e-18
 1.2731378e-19 1.6542384e-19 2.9133401e-20 1.5143392e-15 4.9362031e-01
 1.7689665e-19], sum to 1.0000
[2019-04-24 10:24:09,516] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8983
[2019-04-24 10:24:09,571] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [8.766666666666666, 47.0, 108.3333333333333, 694.1666666666667, 22.5, 22.88362681215302, -0.3302453900474923, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4354800.0000, 
sim time next is 4356000.0000, 
raw observation next is [10.0, 42.0, 111.0, 728.5, 22.5, 23.55664591271053, -0.007070887719882672, 1.0, 1.0, 60.0, 81.92217878599749], 
processed observation next is [1.0, 0.43478260869565216, 0.739612188365651, 0.42, 0.37, 0.8049723756906078, 0.375, 0.46305382605921075, 0.4976430374267058, 1.0, 1.0, 0.9, 0.8192217878599749], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6338887], dtype=float32), 0.36603653]. 
=============================================
[2019-04-24 10:24:13,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9833094e-01 2.5681364e-03 2.5098863e-17 2.5102693e-17 1.5885679e-16
 3.9847834e-18 9.6244884e-19 1.0970524e-18 1.4020013e-14 2.9910100e-01
 3.1232810e-18], sum to 1.0000
[2019-04-24 10:24:13,918] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9023
[2019-04-24 10:24:14,008] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.3333333333333333, 68.33333333333334, 121.0, 11.0, 22.5, 23.75037974865403, -0.2284393536823516, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4526400.0000, 
sim time next is 4527600.0000, 
raw observation next is [0.6666666666666666, 64.66666666666667, 139.3333333333333, 2.999999999999999, 22.5, 23.58501633512917, -0.05726208587823622, 1.0, 1.0, 60.0, 77.07469471879742], 
processed observation next is [1.0, 0.391304347826087, 0.4810710987996307, 0.6466666666666667, 0.46444444444444427, 0.0033149171270718224, 0.375, 0.4654180279274307, 0.4809126380405879, 1.0, 1.0, 0.9, 0.7707469471879742], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0111884], dtype=float32), -0.2080131]. 
=============================================
[2019-04-24 10:24:15,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:15,510] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:16,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:16,340] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:16,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run8
[2019-04-24 10:24:17,875] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:18,046] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:18,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:18,882] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:18,887] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run8
[2019-04-24 10:24:21,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:21,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:22,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:22,162] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:22,166] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run8
[2019-04-24 10:24:25,400] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.6649929e-01 2.8215477e-02 8.9504097e-16 2.3214357e-15 7.5551536e-15
 2.9137200e-16 4.4040819e-16 1.5861878e-16 4.5158525e-13 4.0528527e-01
 5.0370498e-16], sum to 1.0000
[2019-04-24 10:24:25,401] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0741
[2019-04-24 10:24:25,418] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 20.93370538669941, -0.7332423243617967, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5036400.0000, 
sim time next is 5037600.0000, 
raw observation next is [-2.666666666666667, 65.0, 49.16666666666667, 84.16666666666667, 22.5, 20.49920880407345, -0.7763004497976648, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.38873499538319484, 0.65, 0.16388888888888892, 0.09300184162062615, 0.375, 0.20826740033945423, 0.2412331834007784, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0566223], dtype=float32), 0.17528942]. 
=============================================
[2019-04-24 10:24:25,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:26,013] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:26,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:26,195] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:26,454] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:26,628] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:26,892] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:26,893] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:26,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run8
[2019-04-24 10:24:27,002] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:27,002] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:27,008] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run8
[2019-04-24 10:24:27,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:27,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:27,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:27,461] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:27,465] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run8
[2019-04-24 10:24:28,091] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:28,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:28,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run8
[2019-04-24 10:24:29,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:29,708] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:30,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:30,509] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:30,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run8
[2019-04-24 10:24:31,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4555486e-01 2.7508806e-02 1.7072246e-14 2.8140716e-14 5.8430549e-14
 8.9248643e-15 5.7931374e-15 1.2222966e-15 2.8561992e-12 2.2693641e-01
 9.8448776e-15], sum to 1.0000
[2019-04-24 10:24:31,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1965
[2019-04-24 10:24:31,270] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 49.66666666666667, 0.0, 0.0, 19.0, 19.78243822378408, -0.9115481407767799, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4826400.0000, 
sim time next is 4827600.0000, 
raw observation next is [0.0, 51.0, 0.0, 0.0, 19.0, 19.6452061988596, -0.9432527876598588, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.46260387811634357, 0.51, 0.0, 0.0, 0.08333333333333333, 0.13710051657163339, 0.18558240411338042, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0432438], dtype=float32), 0.63045484]. 
=============================================
[2019-04-24 10:24:31,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:32,193] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:32,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:32,894] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:32,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run8
[2019-04-24 10:24:33,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:33,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:34,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:34,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:34,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run8
[2019-04-24 10:24:34,484] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:34,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:35,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:35,485] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:35,489] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run8
[2019-04-24 10:24:39,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:39,632] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:39,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:39,885] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:40,133] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:40,176] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:40,344] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:40,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:40,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run8
[2019-04-24 10:24:40,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:40,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:40,876] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run8
[2019-04-24 10:24:40,911] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:40,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:40,924] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run8
[2019-04-24 10:24:41,003] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_6 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:24:41,181] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_6 ERROR:Aborted (core dumped)

[2019-04-24 10:24:42,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:24:42,004] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:24:42,007] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run8
[2019-04-24 10:24:42,650] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2048073e-01 3.0580210e-03 1.6249876e-15 1.4257072e-14 1.8792973e-14
 7.9871835e-16 7.0124047e-16 1.7777273e-16 1.7454060e-12 7.6461144e-02
 2.3448608e-15], sum to 1.0000
[2019-04-24 10:24:42,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3684
[2019-04-24 10:24:42,726] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 63.0, 0.0, 0.0, 19.0, 21.01190798727003, -0.7362521158263582, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 769200.0000, 
sim time next is 770400.0000, 
raw observation next is [-6.2, 64.0, 0.0, 0.0, 19.0, 20.4898709552235, -0.8237616891120214, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2908587257617729, 0.64, 0.0, 0.0, 0.08333333333333333, 0.20748924626862486, 0.22541277029599285, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.90463626], dtype=float32), -0.5498143]. 
=============================================
[2019-04-24 10:24:45,655] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7078663e-01 1.5722701e-03 9.6699136e-15 2.5157754e-13 9.8682225e-14
 1.8119117e-15 1.9501290e-15 3.6271514e-15 9.2295390e-12 2.7641082e-02
 9.5696588e-15], sum to 1.0000
[2019-04-24 10:24:45,657] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6486
[2019-04-24 10:24:45,672] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.5, 42.0, 76.0, 550.0, 22.5, 22.51930017714868, -0.2391563941746655, 1.0, 1.0, 20.0, 79.56955483456912], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 313200.0000, 
sim time next is 314400.0000, 
raw observation next is [-9.5, 42.0, 72.0, 501.3333333333333, 22.5, 23.31966837635242, -0.3947580548786345, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.1994459833795014, 0.42, 0.24, 0.5539594843462247, 0.375, 0.4433056980293684, 0.36841398170712186, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8312904], dtype=float32), -0.96046084]. 
=============================================
[2019-04-24 10:24:53,632] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8216647e-01 5.9019856e-04 6.2014558e-20 6.1607378e-19 1.7872308e-18
 7.1410722e-20 5.6376656e-20 3.7012507e-20 3.3839985e-16 1.7243313e-02
 1.0195339e-19], sum to 1.0000
[2019-04-24 10:24:53,632] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4676
[2019-04-24 10:24:53,671] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.366666666666667, 86.0, 74.16666666666667, 0.0, 19.0, 21.39889790787512, -0.31772884386875, 0.0, 1.0, 60.0, 87.43310252573886], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 52800.0000, 
sim time next is 54000.0000, 
raw observation next is [7.2, 86.0, 64.5, 0.0, 19.0, 22.16048999998413, -0.4083948530028643, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.662049861495845, 0.86, 0.215, 0.0, 0.08333333333333333, 0.34670749999867745, 0.36386838233237856, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.74219453], dtype=float32), 1.0108752]. 
=============================================
[2019-04-24 10:24:57,769] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.2966427e-01 4.6058536e-02 1.7078309e-12 2.6590674e-11 5.5287407e-12
 1.2200312e-12 5.3711105e-13 5.8419621e-13 1.8031394e-10 2.2427720e-01
 1.2083662e-12], sum to 1.0000
[2019-04-24 10:24:57,816] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4925
[2019-04-24 10:24:57,882] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.2, 70.33333333333334, 0.0, 0.0, 19.0, 19.49697374294806, -1.00316944329812, 0.0, 1.0, 60.0, 67.18766861776217], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 357600.0000, 
sim time next is 358800.0000, 
raw observation next is [-15.4, 71.66666666666667, 0.0, 0.0, 19.0, 19.53743969781326, -1.214256023653902, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.03601108033240995, 0.7166666666666667, 0.0, 0.0, 0.08333333333333333, 0.12811997481777157, 0.09524799211536601, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06751368], dtype=float32), 1.1188107]. 
=============================================
[2019-04-24 10:25:01,609] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1247150e-01 6.0289502e-03 2.5016417e-14 2.0716288e-14 3.8608819e-14
 5.4110434e-16 1.9076395e-15 1.6869510e-15 5.6525084e-12 4.8149955e-01
 2.2146487e-15], sum to 1.0000
[2019-04-24 10:25:01,610] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4424
[2019-04-24 10:25:01,660] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.566666666666666, 73.0, 128.8333333333333, 0.0, 22.5, 22.66144484906206, -0.5449897109358997, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 211200.0000, 
sim time next is 212400.0000, 
raw observation next is [-6.2, 72.0, 138.5, 0.0, 22.5, 22.12334758256903, -0.6324605930184489, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.2908587257617729, 0.72, 0.46166666666666667, 0.0, 0.375, 0.34361229854741904, 0.2891798023271837, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.5614, 
noisyNet noise sample is [array([-0.5787921], dtype=float32), -0.2121683]. 
=============================================
[2019-04-24 10:25:08,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1243395e-01 2.1947127e-02 2.5628531e-12 1.0539159e-11 1.6811649e-11
 8.3579031e-13 1.6182282e-12 7.5440278e-13 2.0394904e-10 4.6561894e-01
 6.8328633e-13], sum to 1.0000
[2019-04-24 10:25:08,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6472
[2019-04-24 10:25:09,086] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-9.866666666666667, 46.66666666666667, 0.0, 0.0, 19.0, 19.29228264040774, -1.293741396028178, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 452400.0000, 
sim time next is 453600.0000, 
raw observation next is [-9.5, 44.0, 0.0, 0.0, 19.0, 18.77227064259009, -1.144301583366646, 0.0, 1.0, 60.0, 89.49241596416311], 
processed observation next is [1.0, 0.2608695652173913, 0.1994459833795014, 0.44, 0.0, 0.0, 0.08333333333333333, 0.06435588688250753, 0.11856613887778471, 0.0, 1.0, 0.9, 0.8949241596416312], 
reward next is 0.2480, 
noisyNet noise sample is [array([1.3145019], dtype=float32), -0.9647491]. 
=============================================
[2019-04-24 10:25:09,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8776568e-01 1.7894741e-02 2.6815685e-15 1.1835607e-14 1.1940636e-14
 2.5454703e-16 5.5946251e-16 2.1039833e-16 5.4292107e-13 5.9433961e-01
 2.0638316e-16], sum to 1.0000
[2019-04-24 10:25:09,195] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1671
[2019-04-24 10:25:09,207] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.466666666666667, 75.66666666666667, 0.0, 0.0, 19.0, 19.92320726931872, -1.123455498376783, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 708000.0000, 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 19.0, 19.14014830670245, -1.255422679537419, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.76, 0.0, 0.0, 0.08333333333333333, 0.09501235889187083, 0.08152577348752699, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5900429], dtype=float32), 1.2169394]. 
=============================================
[2019-04-24 10:25:22,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2689013e-01 6.4001177e-03 6.2607077e-15 7.2764169e-14 6.7896406e-14
 5.6287639e-15 1.1259874e-14 6.1780271e-15 3.7098475e-12 6.6709742e-02
 1.2796495e-14], sum to 1.0000
[2019-04-24 10:25:22,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9654
[2019-04-24 10:25:22,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7121340e-01 7.6305302e-04 1.1164359e-16 3.2867261e-15 6.0867237e-16
 4.3006468e-18 1.6023524e-17 2.5983161e-17 1.3492826e-13 2.8023530e-02
 1.1347399e-16], sum to 1.0000
[2019-04-24 10:25:22,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8471
[2019-04-24 10:25:22,203] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.0, 83.33333333333334, 0.0, 0.0, 19.0, 18.72141796119028, -0.9451530573100096, 0.0, 1.0, 60.0, 101.20688255298981], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1809600.0000, 
sim time next is 1810800.0000, 
raw observation next is [-5.0, 82.0, 0.0, 0.0, 19.0, 19.9320959586208, -0.8237018347279985, 0.0, 1.0, 60.0, 65.3148861646489], 
processed observation next is [0.0, 1.0, 0.32409972299168976, 0.82, 0.0, 0.0, 0.08333333333333333, 0.16100799655173326, 0.22543272175733384, 0.0, 1.0, 0.9, 0.653148861646489], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37919074], dtype=float32), -1.7065076]. 
=============================================
[2019-04-24 10:25:22,220] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 86.0, 14.5, 0.0, 22.5, 22.52798124479798, -0.1718880695591027, 1.0, 1.0, 60.0, 117.02288850220069], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 838800.0000, 
sim time next is 840000.0000, 
raw observation next is [-3.9, 84.66666666666667, 0.0, 0.0, 22.5, 23.85868311819345, -0.2587052698964097, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3545706371191136, 0.8466666666666667, 0.0, 0.0, 0.375, 0.4882235931827876, 0.41376491003453014, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.9685756], dtype=float32), 0.19012755]. 
=============================================
[2019-04-24 10:25:22,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.83201 ]
 [72.63403 ]
 [72.77153 ]
 [72.94806 ]
 [73.15275 ]
 [72.22981 ]
 [72.18736 ]
 [72.06045 ]
 [71.0813  ]
 [71.19288 ]
 [71.29564 ]
 [71.48343 ]
 [71.58187 ]
 [70.87351 ]
 [71.102516]
 [70.428535]
 [70.63138 ]
 [70.83227 ]
 [70.87688 ]
 [70.11729 ]
 [70.06248 ]
 [69.95826 ]
 [70.369446]
 [69.74764 ]
 [69.8365  ]], R is [[73.92865753]
 [73.1893692 ]
 [73.21101379]
 [73.47890472]
 [73.74411774]
 [73.00667572]
 [73.21852112]
 [73.48633575]
 [72.75147247]
 [72.91728973]
 [73.12413788]
 [73.32614136]
 [73.59288025]
 [72.85694885]
 [73.12837982]
 [72.39709473]
 [72.57167053]
 [72.74966431]
 [73.02217102]
 [72.29194641]
 [72.56903076]
 [71.84333801]
 [72.12490845]
 [71.40366364]
 [71.68769836]].
[2019-04-24 10:25:28,717] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7344875e-01 2.9135458e-04 8.4302985e-20 4.0610775e-18 4.2442997e-18
 2.3391616e-20 5.8274357e-20 4.5860444e-20 1.1478652e-15 2.6259813e-02
 3.7229867e-19], sum to 1.0000
[2019-04-24 10:25:28,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9850
[2019-04-24 10:25:28,790] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [4.8, 92.33333333333333, 15.0, 0.0, 22.5, 23.52924319152753, 0.0132218287374714, 1.0, 1.0, 60.0, 87.5747479809189], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 924000.0000, 
sim time next is 925200.0000, 
raw observation next is [5.0, 92.0, 9.0, 0.0, 22.5, 24.56119743637632, 0.150428034729436, 1.0, 1.0, 60.0, 56.543243199419145], 
processed observation next is [1.0, 0.7391304347826086, 0.6011080332409973, 0.92, 0.03, 0.0, 0.375, 0.5467664530313602, 0.5501426782431453, 1.0, 1.0, 0.9, 0.5654324319941915], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.371773], dtype=float32), 0.7837653]. 
=============================================
[2019-04-24 10:25:29,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7482471e-01 1.5917573e-02 5.2039258e-14 2.6726489e-13 2.9714783e-13
 9.1610315e-15 2.0926459e-14 3.2545384e-15 4.4818867e-12 3.0925766e-01
 2.5985692e-14], sum to 1.0000
[2019-04-24 10:25:29,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5704
[2019-04-24 10:25:29,072] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 54.0, 55.0, 26.5, 19.0, 19.68787330600898, -1.068657139424148, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 662400.0000, 
sim time next is 663600.0000, 
raw observation next is [-0.8, 55.00000000000001, 36.33333333333333, 18.83333333333333, 19.0, 19.12346577327027, -1.159500268266109, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.4404432132963989, 0.55, 0.1211111111111111, 0.020810313075506442, 0.08333333333333333, 0.09362214777252238, 0.11349991057796364, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.87971056], dtype=float32), -0.930881]. 
=============================================
[2019-04-24 10:25:29,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.5280442e-01 3.3708648e-03 4.4881409e-15 1.8392656e-14 6.2228999e-15
 1.9558146e-16 6.9501187e-16 3.8377808e-16 2.0334969e-12 1.4382471e-01
 6.3239803e-16], sum to 1.0000
[2019-04-24 10:25:29,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3398
[2019-04-24 10:25:29,483] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 45.0, 76.5, 17.0, 22.5, 22.37495287071317, -0.5063610610057324, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 748800.0000, 
sim time next is 750000.0000, 
raw observation next is [-1.333333333333333, 48.0, 70.83333333333334, 7.666666666666665, 22.5, 21.61575284262248, -0.5290058459429015, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.42566943674976926, 0.48, 0.23611111111111113, 0.008471454880294658, 0.375, 0.3013127368852067, 0.32366471801903285, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9790, 
noisyNet noise sample is [array([0.2773242], dtype=float32), 0.90657806]. 
=============================================
[2019-04-24 10:25:29,501] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.82431 ]
 [70.61009 ]
 [71.73238 ]
 [72.91488 ]
 [73.93555 ]
 [74.79731 ]
 [75.55596 ]
 [76.00653 ]
 [76.22523 ]
 [76.38102 ]
 [76.85906 ]
 [76.79333 ]
 [77.57929 ]
 [78.03707 ]
 [76.93764 ]
 [76.3733  ]
 [75.98433 ]
 [74.870224]
 [75.66574 ]
 [76.120476]
 [76.284966]
 [75.05081 ]
 [74.93808 ]
 [75.52644 ]
 [75.91358 ]], R is [[69.56363678]
 [69.86698914]
 [70.1683197 ]
 [70.46663666]
 [70.76197052]
 [71.05435181]
 [71.34381104]
 [71.63037109]
 [71.91407013]
 [72.19493103]
 [72.47298431]
 [71.74825287]
 [72.03076935]
 [72.31046295]
 [71.58735657]
 [71.87148285]
 [72.152771  ]
 [71.4312439 ]
 [71.47747803]
 [71.72674561]
 [72.00947571]
 [71.28938293]
 [70.57649231]
 [69.87072754]
 [69.31743622]].
[2019-04-24 10:25:32,850] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7150112e-01 2.2400515e-02 1.8509440e-18 8.2178748e-18 1.1463792e-17
 7.5312241e-19 4.1020972e-19 1.3539051e-19 1.7923916e-15 2.0609839e-01
 4.1363841e-19], sum to 1.0000
[2019-04-24 10:25:32,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4982
[2019-04-24 10:25:32,886] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 19.0, 21.4970958222161, -0.5992160612543452, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 961200.0000, 
sim time next is 962400.0000, 
raw observation next is [7.7, 81.0, 0.0, 0.0, 19.0, 20.93372950130853, -0.6756972025909538, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.81, 0.0, 0.0, 0.08333333333333333, 0.24447745844237753, 0.27476759913634874, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12647937], dtype=float32), -2.0093377]. 
=============================================
[2019-04-24 10:25:33,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8439193e-01 1.1625382e-04 7.8741283e-18 2.2771438e-16 1.0965187e-16
 6.6408789e-19 1.3420113e-18 2.1620981e-18 3.1730488e-14 1.5491755e-02
 1.5902051e-17], sum to 1.0000
[2019-04-24 10:25:33,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6232
[2019-04-24 10:25:33,851] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 49.0, 116.0, 0.0, 22.5, 25.37452505682887, 0.5043781444390633, 1.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1090800.0000, 
sim time next is 1092000.0000, 
raw observation next is [19.4, 49.0, 100.0, 0.0, 22.5, 25.7506499432617, 0.5611771755746634, 1.0, 0.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.49, 0.3333333333333333, 0.0, 0.375, 0.6458874952718082, 0.6870590585248878, 1.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7450469], dtype=float32), 0.88340664]. 
=============================================
[2019-04-24 10:25:35,655] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.1666374e-01 5.1787128e-03 4.2329467e-18 2.3569875e-18 3.4295811e-17
 5.5227587e-19 7.0001690e-19 3.8396978e-20 5.5850764e-16 1.7815755e-01
 1.1971362e-18], sum to 1.0000
[2019-04-24 10:25:35,657] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2188
[2019-04-24 10:25:35,679] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.200000000000001, 95.0, 0.0, 0.0, 19.0, 20.60937305280483, -0.5529963275196342, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1297200.0000, 
sim time next is 1298400.0000, 
raw observation next is [4.0, 94.0, 0.0, 0.0, 19.0, 20.47168944099674, -0.5814831190986602, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5734072022160666, 0.94, 0.0, 0.0, 0.08333333333333333, 0.20597412008306173, 0.3061722936337799, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2834748], dtype=float32), 1.092059]. 
=============================================
[2019-04-24 10:25:37,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.88821626e-01 6.68594986e-03 7.66920889e-16 9.02081873e-15
 1.16904955e-14 2.55881877e-16 3.20668754e-16 2.14127070e-16
 8.66649634e-13 5.04492402e-01 4.18170293e-16], sum to 1.0000
[2019-04-24 10:25:37,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1218
[2019-04-24 10:25:37,413] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.899999999999999, 84.66666666666666, 0.0, 0.0, 22.5, 21.63889750227123, -0.6393047391206171, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 844800.0000, 
sim time next is 846000.0000, 
raw observation next is [-3.9, 86.0, 0.0, 0.0, 22.5, 20.91519875787083, -0.7365686659584529, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3545706371191136, 0.86, 0.0, 0.0, 0.375, 0.24293322982256912, 0.25447711134718237, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9514219], dtype=float32), 0.5990858]. 
=============================================
[2019-04-24 10:25:43,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.6331483e-01 1.4201605e-03 5.9434303e-20 2.9130310e-19 2.1307569e-18
 6.4644137e-21 5.3685405e-20 2.1808587e-21 3.0850981e-17 3.5264995e-02
 2.8814539e-20], sum to 1.0000
[2019-04-24 10:25:43,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9709
[2019-04-24 10:25:43,154] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [5.5, 97.0, 0.0, 0.0, 19.0, 22.86429988115181, -0.2113432274513208, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1663200.0000, 
sim time next is 1664400.0000, 
raw observation next is [5.333333333333334, 95.33333333333334, 0.0, 0.0, 19.0, 23.0853450447006, -0.005480067949454936, 0.0, 1.0, 60.0, 81.0794410781899], 
processed observation next is [1.0, 0.2608695652173913, 0.6103416435826409, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.4237787537250499, 0.49817331068351506, 0.0, 1.0, 0.9, 0.8107944107818991], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3966048], dtype=float32), 0.4283824]. 
=============================================
[2019-04-24 10:25:43,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2838043e-01 1.9387407e-03 4.3887950e-21 1.0479688e-20 8.3841618e-20
 8.3822668e-22 1.7605754e-21 1.7340001e-22 1.2104795e-17 6.9680810e-02
 5.2113061e-21], sum to 1.0000
[2019-04-24 10:25:43,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1121
[2019-04-24 10:25:43,295] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 77.0, 0.0, 0.0, 19.0, 22.20316807563974, -0.2810117070388513, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1042800.0000, 
sim time next is 1044000.0000, 
raw observation next is [13.8, 78.0, 0.0, 0.0, 19.0, 22.08684880826911, -0.2883859306964803, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.844875346260388, 0.78, 0.0, 0.0, 0.08333333333333333, 0.3405707340224258, 0.4038713564345066, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5178021], dtype=float32), -0.75518644]. 
=============================================
[2019-04-24 10:25:43,431] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2541003e-01 2.6867243e-03 1.0724859e-18 8.2041452e-18 5.0477990e-18
 2.3977363e-19 3.2353562e-19 4.1752646e-20 3.0903372e-16 7.1903326e-02
 2.6638705e-19], sum to 1.0000
[2019-04-24 10:25:43,433] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1453
[2019-04-24 10:25:43,449] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.166666666666666, 82.0, 0.0, 0.0, 19.0, 21.42292407284432, -0.4409562065017834, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1554000.0000, 
sim time next is 1555200.0000, 
raw observation next is [5.0, 82.0, 0.0, 0.0, 19.0, 21.24225956933154, -0.4755996527287328, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6011080332409973, 0.82, 0.0, 0.0, 0.08333333333333333, 0.27018829744429507, 0.3414667824237558, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.36673814], dtype=float32), -0.28657994]. 
=============================================
[2019-04-24 10:25:43,768] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.69985533e-01 1.39287645e-02 1.65659736e-13 6.52419850e-13
 4.83373703e-13 7.47486315e-14 8.61747468e-14 2.02090474e-14
 1.66827090e-11 3.16085726e-01 4.63359752e-14], sum to 1.0000
[2019-04-24 10:25:43,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5355
[2019-04-24 10:25:43,797] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.366666666666667, 78.66666666666667, 0.0, 0.0, 19.0, 19.16126975178073, -1.187414856408077, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1837200.0000, 
sim time next is 1838400.0000, 
raw observation next is [-6.533333333333333, 78.33333333333334, 0.0, 0.0, 19.0, 18.3335910128298, -1.341907215444984, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.2816251154201293, 0.7833333333333334, 0.0, 0.0, 0.08333333333333333, 0.02779925106914997, 0.05269759485167199, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0265255], dtype=float32), -0.30287522]. 
=============================================
[2019-04-24 10:25:45,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.7445459e-01 8.5002696e-03 3.7507595e-19 1.1258606e-18 5.5693152e-18
 6.7753640e-20 2.7179648e-19 5.3182469e-20 5.2963927e-16 2.1704513e-01
 8.5629679e-20], sum to 1.0000
[2019-04-24 10:25:45,841] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2713
[2019-04-24 10:25:45,865] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.8, 96.66666666666666, 0.0, 0.0, 19.0, 21.17298665399914, -0.5012579567313247, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1651200.0000, 
sim time next is 1652400.0000, 
raw observation next is [6.6, 97.0, 0.0, 0.0, 19.0, 21.11298371192996, -0.5311630733171772, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6454293628808865, 0.97, 0.0, 0.0, 0.08333333333333333, 0.2594153093274967, 0.32294564222760763, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9556618], dtype=float32), 1.8635372]. 
=============================================
[2019-04-24 10:25:46,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8636760e-01 2.1506572e-02 6.0770675e-15 1.4108601e-14 2.4682903e-14
 3.1141450e-15 4.9547764e-15 3.6422888e-16 3.5637617e-13 1.9212578e-01
 3.0742148e-15], sum to 1.0000
[2019-04-24 10:25:46,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9620
[2019-04-24 10:25:46,708] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.8, 83.0, 115.6666666666667, 0.0, 19.0, 19.75783339281879, -0.9655939174897797, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1777200.0000, 
sim time next is 1778400.0000, 
raw observation next is [-2.8, 83.0, 109.0, 0.0, 19.0, 19.91681284969181, -0.7078356910971993, 0.0, 1.0, 60.0, 96.48137462746732], 
processed observation next is [0.0, 0.6086956521739131, 0.38504155124653744, 0.83, 0.36333333333333334, 0.0, 0.08333333333333333, 0.15973440414098405, 0.2640547696342669, 0.0, 1.0, 0.9, 0.9648137462746732], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39519942], dtype=float32), 0.38769925]. 
=============================================
[2019-04-24 10:25:50,269] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.3970001e-01 7.0897443e-03 9.7130983e-16 3.6716888e-15 6.9339146e-15
 8.7969729e-16 7.9092951e-16 7.3383480e-17 4.8200474e-13 5.3210270e-02
 6.0668121e-16], sum to 1.0000
[2019-04-24 10:25:50,271] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9095
[2019-04-24 10:25:50,393] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 87.0, 81.0, 0.0, 19.0, 19.22704774193833, -0.7348436238454291, 0.0, 1.0, 60.0, 134.00311450637352], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1764000.0000, 
sim time next is 1765200.0000, 
raw observation next is [-2.3, 87.0, 91.66666666666667, 0.0, 19.0, 20.76810870872573, -0.7993482389373581, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3988919667590028, 0.87, 0.3055555555555556, 0.0, 0.08333333333333333, 0.2306757257271442, 0.23355058702088063, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47151643], dtype=float32), 0.5297065]. 
=============================================
[2019-04-24 10:25:54,584] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.6701235e-01 1.1411278e-03 4.1839519e-18 7.0478197e-17 3.6879484e-17
 5.4920460e-19 8.5369341e-19 1.0113101e-18 6.0718989e-15 3.1846486e-02
 1.9440268e-18], sum to 1.0000
[2019-04-24 10:25:54,586] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4474
[2019-04-24 10:25:54,610] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 23.54869940689535, -0.09666647587451148, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1707600.0000, 
sim time next is 1708800.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 22.91191940717906, -0.2098351416983675, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.40932661726492164, 0.43005495276721084, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.33690986], dtype=float32), 0.4771033]. 
=============================================
[2019-04-24 10:25:55,091] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-24 10:25:55,097] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:25:55,098] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:25:55,100] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run11
[2019-04-24 10:25:55,118] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:25:55,120] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:25:55,120] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:25:55,121] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:25:55,124] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run11
[2019-04-24 10:25:55,144] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run11
[2019-04-24 10:26:15,623] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.25333348], dtype=float32), 0.63330513]
[2019-04-24 10:26:15,623] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-0.6, 54.00000000000001, 82.66666666666667, 41.0, 19.0, 19.99857384620866, -1.033903854785946, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:26:15,623] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:26:15,625] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.9576814e-01 2.0942317e-02 8.1593383e-14 1.9988466e-13 1.6807530e-13
 2.4057211e-14 3.2206107e-14 1.0609837e-14 8.1686585e-12 1.8328954e-01
 3.1523002e-14], sampled 0.13522949894005232
[2019-04-24 10:27:50,796] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([-0.25333348], dtype=float32), 0.63330513]
[2019-04-24 10:27:50,798] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [-6.01276708, 65.48245984, 0.0, 0.0, 19.0, 19.25748579148651, -1.043771666497529, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:27:50,798] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:27:50,799] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [6.46805406e-01 2.78859828e-02 2.15666799e-13 1.93852692e-13
 3.58737996e-13 4.41928903e-14 6.38220352e-14 1.48407016e-14
 1.02106735e-11 3.25308621e-01 3.53595361e-14], sampled 0.21141386252444538
[2019-04-24 10:27:56,632] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3407.7986 58640.0995 -311.9534
[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,723] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:27:56,904] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,737] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3174.7674 73838.0475 -547.0872
[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,773] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:14,949] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,258] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3081.4760 76895.1481 -615.8511
[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,287] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:25,445] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:28:26,289] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 500000, evaluation results [500000.0, 3174.7673812962016, 73838.04752735942, -547.0871687101088, 3407.798550346888, 58640.09945291836, -311.9534332753923, 3081.475996111592, 76895.14809723022, -615.8511200872018]
[2019-04-24 10:28:34,036] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.39204335e-01 5.48588997e-03 1.93150130e-15 1.31943805e-14
 1.47252358e-14 5.44090502e-16 2.40701167e-16 8.59236151e-16
 1.79328958e-12 5.53097054e-02 7.80807941e-16], sum to 1.0000
[2019-04-24 10:28:34,040] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3795
[2019-04-24 10:28:34,146] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 83.0, 0.0, 0.0, 19.0, 20.35676002213527, -0.6819874376247052, 0.0, 1.0, 20.0, 81.13125839682118], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1982400.0000, 
sim time next is 1983600.0000, 
raw observation next is [-5.6, 83.0, 0.0, 0.0, 19.0, 20.82007814562486, -0.7985171207973621, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.30747922437673136, 0.83, 0.0, 0.0, 0.08333333333333333, 0.23500651213540488, 0.23382762640087928, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02340566], dtype=float32), 1.8323792]. 
=============================================
[2019-04-24 10:28:38,028] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3219272e-01 3.6707644e-03 8.1384191e-18 5.0918267e-17 1.2174930e-16
 3.8577293e-18 7.2969572e-18 6.3474014e-18 1.5157885e-14 1.6413654e-01
 6.2248931e-18], sum to 1.0000
[2019-04-24 10:28:38,028] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6046
[2019-04-24 10:28:38,067] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 0.0, 0.0, 19.0, 21.26774101209265, -0.5467332010482676, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1724400.0000, 
sim time next is 1725600.0000, 
raw observation next is [0.1666666666666667, 94.0, 0.0, 0.0, 19.0, 20.75240009794513, -0.6171335424808788, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4672206832871654, 0.94, 0.0, 0.0, 0.08333333333333333, 0.2293666748287609, 0.2942888191730404, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5556806], dtype=float32), -1.0554787]. 
=============================================
[2019-04-24 10:28:42,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5060766e-01 2.0418365e-02 2.6184694e-13 5.1141545e-13 3.5594306e-13
 4.5459581e-14 1.0295582e-13 2.6310842e-14 2.4312712e-11 6.2897402e-01
 1.1061000e-13], sum to 1.0000
[2019-04-24 10:28:42,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5603
[2019-04-24 10:28:42,337] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.2, 78.66666666666667, 0.0, 0.0, 19.0, 19.08596193365923, -1.178877738901586, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1815600.0000, 
sim time next is 1816800.0000, 
raw observation next is [-5.4, 78.33333333333334, 0.0, 0.0, 19.0, 18.96854818054403, -0.9474587695638118, 0.0, 1.0, 60.0, 96.07248146869684], 
processed observation next is [0.0, 0.0, 0.31301939058171746, 0.7833333333333334, 0.0, 0.0, 0.08333333333333333, 0.08071234837866914, 0.18418041014539607, 0.0, 1.0, 0.9, 0.9607248146869684], 
reward next is 0.0589, 
noisyNet noise sample is [array([-0.3366628], dtype=float32), 0.43403244]. 
=============================================
[2019-04-24 10:28:42,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4599851e-01 3.5941552e-02 2.0382513e-13 4.9186946e-13 5.3942625e-13
 4.3174293e-14 1.0583469e-13 8.8868444e-15 2.0214738e-11 4.1805986e-01
 6.0349735e-14], sum to 1.0000
[2019-04-24 10:28:42,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8779
[2019-04-24 10:28:42,844] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.633333333333333, 77.0, 0.0, 0.0, 19.0, 18.76849789910655, -1.293308449315841, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1906800.0000, 
sim time next is 1908000.0000, 
raw observation next is [-7.8, 78.0, 0.0, 0.0, 19.0, 18.78525759226065, -1.05313145656279, 0.0, 1.0, 60.0, 95.40264826658446], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.78, 0.0, 0.0, 0.08333333333333333, 0.06543813268838743, 0.14895618114573664, 0.0, 1.0, 0.9, 0.9540264826658447], 
reward next is 0.2810, 
noisyNet noise sample is [array([-0.7674263], dtype=float32), -1.9927273]. 
=============================================
[2019-04-24 10:28:43,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6331451e-01 3.7958494e-03 2.3968635e-15 2.3378162e-14 1.3844077e-14
 9.9997302e-17 1.2545445e-15 6.8076091e-16 4.8054451e-12 1.3288969e-01
 2.2440306e-15], sum to 1.0000
[2019-04-24 10:28:43,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6879
[2019-04-24 10:28:43,536] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.3, 70.0, 29.66666666666667, 0.0, 22.5, 22.71245388042476, -0.4177059498711372, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2220000.0000, 
sim time next is 2221200.0000, 
raw observation next is [-4.5, 71.0, 19.0, 0.0, 22.5, 22.24636808501914, -0.5076513559815482, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3379501385041552, 0.71, 0.06333333333333334, 0.0, 0.375, 0.3538640070849282, 0.3307828813394839, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9985, 
noisyNet noise sample is [array([0.7779589], dtype=float32), -0.63711745]. 
=============================================
[2019-04-24 10:28:47,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2032519e-01 4.4764318e-02 1.4960054e-14 1.9871239e-14 6.3189701e-14
 8.0347994e-16 1.6737849e-15 1.7636995e-15 2.1491116e-12 5.3491050e-01
 1.6449524e-15], sum to 1.0000
[2019-04-24 10:28:47,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3927
[2019-04-24 10:28:47,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 34.50000000000001, 218.3333333333333, 22.5, 21.56914709490365, -0.6920064176301474, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2190000.0000, 
sim time next is 2191200.0000, 
raw observation next is [-5.6, 75.0, 51.16666666666667, 293.5, 22.5, 21.37420219856508, -0.7435348834300902, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.30747922437673136, 0.75, 0.17055555555555557, 0.3243093922651934, 0.375, 0.28118351654708995, 0.2521550388566366, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33285236], dtype=float32), 0.12362325]. 
=============================================
[2019-04-24 10:28:50,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5563517e-01 3.4533006e-03 7.6800274e-15 2.8266299e-14 1.2070631e-14
 2.7174177e-16 5.2369215e-16 9.7532265e-16 1.1043652e-12 1.4091152e-01
 2.9436031e-16], sum to 1.0000
[2019-04-24 10:28:50,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6460
[2019-04-24 10:28:51,089] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 22.5, 22.4772156591205, -0.412780787362086, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2232000.0000, 
sim time next is 2233200.0000, 
raw observation next is [-5.0, 70.0, 0.0, 0.0, 19.0, 21.71148951042729, -0.5363172513992825, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.7, 0.0, 0.0, 0.08333333333333333, 0.3092907925356074, 0.32122758286690584, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1678681], dtype=float32), -0.76572156]. 
=============================================
[2019-04-24 10:28:53,478] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.3623716e-01 3.7422990e-03 2.1008321e-15 4.9105146e-14 7.7052182e-15
 3.0278289e-16 4.7905955e-16 5.4852625e-16 1.8491777e-12 6.0020488e-02
 3.0229714e-15], sum to 1.0000
[2019-04-24 10:28:53,479] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0215
[2019-04-24 10:28:53,535] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.566666666666666, 69.33333333333333, 0.0, 0.0, 22.5, 22.60152845081631, -0.164138810298801, 1.0, 1.0, 60.0, 117.55533024241913], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2227200.0000, 
sim time next is 2228400.0000, 
raw observation next is [-4.6, 70.0, 0.0, 0.0, 22.5, 23.50821238181047, -0.2713547600996865, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.33518005540166207, 0.7, 0.0, 0.0, 0.375, 0.4590176984842058, 0.40954841330010455, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7692368], dtype=float32), -0.36566722]. 
=============================================
[2019-04-24 10:28:55,323] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8798627e-01 6.1250199e-04 2.5778569e-16 3.3714726e-15 2.2725665e-15
 1.9609795e-17 1.4273364e-16 1.2191714e-16 1.9746078e-13 1.1401209e-02
 2.2239731e-16], sum to 1.0000
[2019-04-24 10:28:55,326] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0302
[2019-04-24 10:28:55,354] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.8, 79.66666666666667, 0.0, 0.0, 19.0, 22.00570144976553, -0.3213884380703119, 0.0, 1.0, 60.0, 83.16165712311617], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1977600.0000, 
sim time next is 1978800.0000, 
raw observation next is [-6.0, 81.33333333333333, 0.0, 0.0, 19.0, 22.28969170826056, -0.4620046057145629, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.296398891966759, 0.8133333333333332, 0.0, 0.0, 0.08333333333333333, 0.35747430902171323, 0.3459984647618124, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1663725], dtype=float32), 0.8697141]. 
=============================================
[2019-04-24 10:28:55,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.3497139e-01 1.7321352e-03 3.5720031e-16 5.9899519e-15 2.0590147e-15
 1.8865824e-17 1.3682646e-16 5.1932083e-17 4.7970368e-13 6.3296430e-02
 2.0621734e-16], sum to 1.0000
[2019-04-24 10:28:55,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9536
[2019-04-24 10:28:55,857] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.5333333333333334, 41.66666666666667, 229.6666666666667, 62.83333333333334, 22.5, 23.96101268582124, -0.06998295778528353, 1.0, 1.0, 60.0, 72.20776657826886], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2547600.0000, 
sim time next is 2548800.0000, 
raw observation next is [1.1, 39.0, 225.0, 46.5, 22.5, 24.48526223665301, 0.002940961682528086, 1.0, 1.0, 60.0, 51.422955599528514], 
processed observation next is [1.0, 0.5217391304347826, 0.49307479224376743, 0.39, 0.75, 0.05138121546961326, 0.375, 0.5404385197210843, 0.5009803205608426, 1.0, 1.0, 0.9, 0.5142295559952852], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2700271], dtype=float32), 0.38274404]. 
=============================================
[2019-04-24 10:29:00,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3857354e-01 4.6757623e-03 6.4404408e-15 3.0223775e-14 3.2049447e-14
 2.0926366e-15 2.1982152e-15 9.7852687e-16 8.8005970e-13 5.6750678e-02
 7.9528220e-15], sum to 1.0000
[2019-04-24 10:29:00,481] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5463
[2019-04-24 10:29:00,500] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 51.66666666666667, 241.8333333333333, 353.3333333333334, 19.0, 21.11216029014027, -0.6773620367518882, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2378400.0000, 
sim time next is 2379600.0000, 
raw observation next is [-0.6, 54.0, 221.5, 212.0, 19.0, 20.65438351740178, -0.7898706175002097, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.44598337950138506, 0.54, 0.7383333333333333, 0.23425414364640884, 0.08333333333333333, 0.2211986264501483, 0.23670979416659677, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0154787], dtype=float32), 0.12119772]. 
=============================================
[2019-04-24 10:29:02,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8630201e-01 1.6170913e-02 1.6363595e-12 3.0197537e-12 6.7085803e-12
 5.5341457e-13 2.3155715e-13 1.6505207e-13 1.2260945e-10 2.9752707e-01
 4.4379566e-13], sum to 1.0000
[2019-04-24 10:29:02,018] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0717
[2019-04-24 10:29:02,091] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 41.0, 0.0, 0.0, 19.0, 20.06952423333889, -0.9705472105660263, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2415600.0000, 
sim time next is 2416800.0000, 
raw observation next is [-5.2, 41.66666666666667, 0.0, 0.0, 19.0, 19.36870800166116, -1.104757032305337, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.31855955678670367, 0.41666666666666674, 0.0, 0.0, 0.08333333333333333, 0.11405900013843014, 0.131747655898221, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3915263], dtype=float32), 1.095275]. 
=============================================
[2019-04-24 10:29:04,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6424941e-01 3.7857448e-03 1.1610824e-14 7.7333302e-14 4.4222486e-14
 1.5335492e-15 1.9517587e-15 5.5992462e-16 6.2275090e-12 1.3196483e-01
 1.3404261e-14], sum to 1.0000
[2019-04-24 10:29:04,753] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2023
[2019-04-24 10:29:04,799] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.266666666666667, 54.66666666666667, 99.33333333333333, 713.1666666666667, 22.5, 22.39857698313418, -0.392239820408091, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2731200.0000, 
sim time next is 2732400.0000, 
raw observation next is [-4.0, 54.0, 94.0, 673.5, 22.5, 22.48233939745448, -0.3783015663503517, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.3518005540166205, 0.54, 0.31333333333333335, 0.7441988950276243, 0.375, 0.3735282831212068, 0.3738994778832161, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7756395], dtype=float32), 0.036382537]. 
=============================================
[2019-04-24 10:29:17,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4798500e-02 4.7607403e-02 2.5529747e-11 8.1715416e-12 1.3724200e-11
 4.9827165e-12 9.7446200e-12 1.1647792e-12 2.5840555e-10 8.6759412e-01
 1.2320439e-12], sum to 1.0000
[2019-04-24 10:29:17,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5884
[2019-04-24 10:29:17,250] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-8.2, 59.0, 0.0, 0.0, 19.0, 17.71012328049778, -1.48483433521462, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2432400.0000, 
sim time next is 2433600.0000, 
raw observation next is [-8.4, 61.0, 0.0, 0.0, 19.0, 17.94270959521602, -1.199335813696063, 0.0, 1.0, 60.0, 100.38112142576446], 
processed observation next is [0.0, 0.17391304347826086, 0.2299168975069252, 0.61, 0.0, 0.0, 0.08333333333333333, -0.004774200398665052, 0.10022139543464566, 0.0, 1.0, 0.9, 1.0038112142576445], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2121251], dtype=float32), -1.8751695]. 
=============================================
[2019-04-24 10:29:19,416] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.76058757e-01 5.96870016e-03 2.05964256e-15 2.06810611e-15
 3.40755912e-15 4.40916833e-16 1.51774037e-16 1.42716184e-16
 1.83380858e-13 1.17972456e-01 7.60764336e-16], sum to 1.0000
[2019-04-24 10:29:19,420] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0460
[2019-04-24 10:29:19,436] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 65.33333333333334, 0.0, 0.0, 19.0, 21.10666724552503, -0.6606733246354523, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3705600.0000, 
sim time next is 3706800.0000, 
raw observation next is [0.6666666666666667, 68.66666666666667, 0.0, 0.0, 19.0, 20.8466852196078, -0.7088199318051193, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.4810710987996307, 0.6866666666666668, 0.0, 0.0, 0.08333333333333333, 0.23722376830064995, 0.2637266893982936, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06986676], dtype=float32), -0.61153394]. 
=============================================
[2019-04-24 10:29:22,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0530311e-01 1.5730012e-02 1.4037105e-14 2.9831037e-14 3.6045887e-14
 5.3040335e-16 1.0654407e-15 9.4716357e-16 1.6467746e-12 3.7896678e-01
 2.6328797e-15], sum to 1.0000
[2019-04-24 10:29:22,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2729
[2019-04-24 10:29:22,428] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.166666666666667, 57.0, 0.0, 0.0, 19.0, 21.17252820970051, -0.6894859905369072, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2586000.0000, 
sim time next is 2587200.0000, 
raw observation next is [-3.533333333333333, 58.0, 0.0, 0.0, 19.0, 20.47609707766816, -0.7796996464815256, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.36472760849492153, 0.58, 0.0, 0.0, 0.08333333333333333, 0.2063414231390134, 0.24010011783949148, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.57741565], dtype=float32), -0.89025414]. 
=============================================
[2019-04-24 10:29:29,250] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.1720930e-01 1.2310470e-02 8.8355416e-14 1.5685042e-13 2.1799461e-13
 2.9973931e-14 2.4371423e-14 2.1841736e-14 6.7528045e-12 1.7048021e-01
 9.5623955e-14], sum to 1.0000
[2019-04-24 10:29:29,251] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2437
[2019-04-24 10:29:29,270] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 19.990470924973, -0.9938646300704294, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3018000.0000, 
sim time next is 3019200.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 19.29805369370091, -1.133640068896228, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.1081711411417426, 0.12211997703459065, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7871562], dtype=float32), 0.47758505]. 
=============================================
[2019-04-24 10:29:29,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.61017108e-01 5.49031328e-03 4.02021358e-18 2.24508531e-17
 1.27367956e-17 2.59148836e-19 6.78681582e-19 1.06605900e-19
 8.00907768e-16 1.33492634e-01 1.15120432e-18], sum to 1.0000
[2019-04-24 10:29:29,527] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7711
[2019-04-24 10:29:29,548] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 97.66666666666666, 0.0, 0.0, 19.0, 21.56211802000354, -0.3937441603532656, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3199200.0000, 
sim time next is 3200400.0000, 
raw observation next is [1.0, 100.0, 0.0, 0.0, 19.0, 21.53664849228399, -0.406347053213532, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.4903047091412743, 1.0, 0.0, 0.0, 0.08333333333333333, 0.2947207076903326, 0.364550982262156, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.1178688], dtype=float32), 0.5526851]. 
=============================================
[2019-04-24 10:29:32,073] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.4990981e-01 4.6861009e-03 6.1927015e-15 1.5959212e-14 1.2617434e-14
 3.8900162e-15 1.0798105e-15 7.6627884e-16 6.7229414e-13 4.5404047e-02
 7.9973996e-15], sum to 1.0000
[2019-04-24 10:29:32,082] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.0550
[2019-04-24 10:29:32,119] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 75.33333333333334, 15.33333333333333, 154.3333333333333, 19.0, 21.47273865801584, -0.6397139919065105, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3086400.0000, 
sim time next is 3087600.0000, 
raw observation next is [-0.4, 78.66666666666667, 0.0, 0.0, 19.0, 21.0271398223129, -0.7607837801366081, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.45152354570637127, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.25226165185940835, 0.24640540662113064, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0383842], dtype=float32), -0.73080665]. 
=============================================
[2019-04-24 10:29:32,986] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4972116e-01 8.0629885e-03 5.0426256e-15 9.5981261e-14 7.2012071e-14
 2.0075094e-15 5.2508263e-15 1.5191620e-15 4.0854715e-12 4.2215884e-02
 6.1761856e-15], sum to 1.0000
[2019-04-24 10:29:32,988] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8003
[2019-04-24 10:29:33,030] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.9611177724902, -0.676675926508726, 0.0, 1.0, 60.0, 60.354248392712776], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2784000.0000, 
sim time next is 2785200.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 21.03937664258967, -0.8480339460842474, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.2532813868824724, 0.21732201797191752, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.42199728], dtype=float32), 0.2429329]. 
=============================================
[2019-04-24 10:29:33,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3372378e-01 1.2480176e-02 2.4979561e-15 2.0169347e-15 9.7429634e-15
 3.4888993e-16 8.0522769e-16 2.6123573e-16 3.5774167e-13 5.5379605e-01
 2.0809978e-16], sum to 1.0000
[2019-04-24 10:29:33,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7539
[2019-04-24 10:29:33,427] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.80208433e-01 2.51563103e-03 2.55677996e-15 2.90394031e-14
 1.02560011e-14 1.91473426e-16 1.71638283e-16 9.37909855e-17
 8.42448236e-13 1.17275864e-01 6.73364564e-16], sum to 1.0000
[2019-04-24 10:29:33,432] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4640
[2019-04-24 10:29:33,445] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.333333333333334, 57.33333333333334, 116.3333333333333, 800.1666666666666, 22.5, 23.98533440064795, -0.1027016341466058, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3325200.0000, 
sim time next is 3326400.0000, 
raw observation next is [-6.0, 54.0, 117.0, 804.5, 22.5, 23.43914960896185, -0.2854814185776914, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.296398891966759, 0.54, 0.39, 0.888950276243094, 0.375, 0.45326246741348736, 0.4048395271407695, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.30026522], dtype=float32), -0.48006308]. 
=============================================
[2019-04-24 10:29:33,481] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 18.86818666085824, -1.175914806259096, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3102000.0000, 
sim time next is 3103200.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 19.0, 19.31102603509317, -0.8523314062969002, 0.0, 1.0, 60.0, 100.18701858258265], 
processed observation next is [0.0, 0.9565217391304348, 0.4349030470914128, 1.0, 0.0, 0.0, 0.08333333333333333, 0.10925216959109758, 0.2158895312343666, 0.0, 1.0, 0.9, 1.0018701858258265], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.52583706], dtype=float32), -0.46462134]. 
=============================================
[2019-04-24 10:29:34,387] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.70230937e-01 1.20615226e-03 4.29108142e-21 7.33318102e-19
 1.05135576e-18 4.81889091e-21 1.23697106e-20 8.63505393e-21
 6.15998888e-17 2.85629965e-02 1.74382323e-20], sum to 1.0000
[2019-04-24 10:29:34,389] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3075
[2019-04-24 10:29:34,489] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 100.0, 42.0, 237.0, 22.5, 22.75991582596955, -0.2573063299918291, 1.0, 1.0, 60.0, 75.17459369367765], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3139200.0000, 
sim time next is 3140400.0000, 
raw observation next is [6.333333333333333, 100.0, 69.33333333333334, 340.3333333333334, 22.5, 23.13154549498654, -0.3523690888760057, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.6380424746075716, 1.0, 0.23111111111111116, 0.3760589318600369, 0.375, 0.4276287912488783, 0.3825436370413315, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.40933183], dtype=float32), -1.5641146]. 
=============================================
[2019-04-24 10:29:39,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.3235832e-01 4.4246484e-03 1.5929617e-15 1.9437216e-14 2.5734121e-14
 5.2138213e-16 5.0599508e-15 1.7975987e-16 8.3932102e-13 6.3217059e-02
 2.7530002e-15], sum to 1.0000
[2019-04-24 10:29:39,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3030
[2019-04-24 10:29:39,346] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 19.0, 21.06743002293156, -0.4611631365496017, 0.0, 1.0, 60.0, 67.2129486648038], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3290400.0000, 
sim time next is 3291600.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 21.41997770181016, -0.6164499269544631, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.28499814181751343, 0.29451669101517897, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02275073], dtype=float32), 1.4185699]. 
=============================================
[2019-04-24 10:29:39,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3855098e-01 2.2677079e-02 8.8804167e-14 2.9297914e-14 4.6876640e-14
 5.8605553e-15 1.3641203e-14 2.8666416e-15 2.0043663e-12 5.3877193e-01
 8.4608283e-15], sum to 1.0000
[2019-04-24 10:29:39,500] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2353
[2019-04-24 10:29:39,551] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 218.5, 487.5, 19.0, 19.91419379238523, -0.8999748970689749, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2980800.0000, 
sim time next is 2982000.0000, 
raw observation next is [-3.0, 65.0, 193.5, 623.1666666666667, 19.0, 19.59432537109003, -0.9388225613453433, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.65, 0.645, 0.6885819521178638, 0.08333333333333333, 0.1328604475908358, 0.18705914621821892, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17600186], dtype=float32), -0.65330523]. 
=============================================
[2019-04-24 10:29:41,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.2832536e-01 6.5448843e-03 4.0554603e-16 6.2302505e-15 8.0216180e-15
 2.1081791e-16 2.2324302e-16 5.3274653e-17 2.8511029e-13 6.5129831e-02
 7.0442187e-16], sum to 1.0000
[2019-04-24 10:29:41,467] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9765
[2019-04-24 10:29:41,498] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.0, 65.0, 0.0, 0.0, 19.0, 21.30479462115502, -0.5765309822193067, 0.0, 1.0, 60.0, 62.10564807817573], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3729600.0000, 
sim time next is 3730800.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 19.0, 21.85057440052039, -0.5152797663850067, 0.0, 1.0, 60.0, 59.54002776004883], 
processed observation next is [1.0, 0.17391304347826086, 0.3795013850415513, 0.65, 0.0, 0.0, 0.08333333333333333, 0.32088120004336584, 0.3282400778716644, 0.0, 1.0, 0.9, 0.5954002776004883], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1691486], dtype=float32), -0.26085785]. 
=============================================
[2019-04-24 10:29:51,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7673815e-01 4.9372466e-04 4.9538542e-16 9.5743404e-15 3.0684071e-15
 7.8342785e-17 7.0519437e-17 6.0840735e-17 5.8579096e-13 2.2768132e-02
 8.0940774e-16], sum to 1.0000
[2019-04-24 10:29:51,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2780
[2019-04-24 10:29:51,188] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.333333333333334, 51.33333333333333, 112.6666666666667, 792.0, 22.5, 22.59324992311364, -0.08734329649636498, 1.0, 1.0, 60.0, 116.12173369596279], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3332400.0000, 
sim time next is 3333600.0000, 
raw observation next is [-4.0, 50.0, 110.0, 776.0, 22.5, 24.20630204455132, -0.1931018153984854, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3518005540166205, 0.5, 0.36666666666666664, 0.8574585635359117, 0.375, 0.5171918370459435, 0.43563272820050486, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.81568176], dtype=float32), -1.3354985]. 
=============================================
[2019-04-24 10:29:53,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5497417e-01 1.8934247e-03 1.2294235e-16 8.1494972e-16 2.9197485e-16
 6.4978350e-18 7.1844400e-18 6.5245608e-18 1.1766262e-13 4.3132424e-02
 1.7142648e-17], sum to 1.0000
[2019-04-24 10:29:53,046] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4989
[2019-04-24 10:29:53,072] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 45.66666666666667, 15.0, 149.1666666666667, 22.5, 23.15103364584005, -0.1304106214210313, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3865200.0000, 
sim time next is 3866400.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 22.5, 23.0490593658437, -0.1478176669534476, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.518005540166205, 0.48, 0.0, 0.0, 0.375, 0.42075494715364165, 0.45072744434885076, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4130995], dtype=float32), -0.9673939]. 
=============================================
[2019-04-24 10:29:55,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5576715e-01 1.0167428e-03 1.5331765e-17 9.1508304e-17 9.2937295e-17
 3.8599655e-18 8.6416753e-19 7.7100859e-19 1.0261755e-14 4.3216024e-02
 4.9547627e-18], sum to 1.0000
[2019-04-24 10:29:55,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7863
[2019-04-24 10:29:55,960] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 108.0, 790.5, 22.5, 22.18020157152684, -0.3796583140685923, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3420000.0000, 
sim time next is 3421200.0000, 
raw observation next is [3.0, 52.0, 104.6666666666667, 780.1666666666667, 22.5, 22.48085731111899, -0.4172356588202342, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.52, 0.348888888888889, 0.8620626151012892, 0.375, 0.3734047759265824, 0.36092144705992196, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.5545117], dtype=float32), -1.0269362]. 
=============================================
[2019-04-24 10:30:04,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:05,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:05,839] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:05,840] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:05,843] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run9
[2019-04-24 10:30:06,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7351700e-01 6.3669833e-04 5.0436559e-20 1.0332072e-18 9.0390606e-19
 1.3035664e-20 2.2036203e-20 3.5722998e-21 3.5397660e-16 2.5846371e-02
 8.7286295e-20], sum to 1.0000
[2019-04-24 10:30:06,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9908
[2019-04-24 10:30:07,052] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [12.6, 34.0, 117.5, 804.0, 22.5, 24.07149647967123, -0.03139200302004882, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4359600.0000, 
sim time next is 4360800.0000, 
raw observation next is [13.4, 32.0, 119.1666666666667, 820.0, 22.5, 24.59679237417636, 0.2781506534739963, 1.0, 1.0, 60.0, 75.66329510587252], 
processed observation next is [1.0, 0.4782608695652174, 0.8337950138504157, 0.32, 0.3972222222222223, 0.9060773480662984, 0.375, 0.54973269784803, 0.5927168844913321, 1.0, 1.0, 0.9, 0.7566329510587252], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33735165], dtype=float32), 1.0245023]. 
=============================================
[2019-04-24 10:30:07,808] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.3164831e-01 2.7382022e-03 6.0240174e-15 3.0717785e-14 1.2231772e-14
 3.1629732e-16 3.0514711e-16 1.2495059e-16 6.9345875e-13 6.5613464e-02
 1.4328669e-15], sum to 1.0000
[2019-04-24 10:30:07,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8523
[2019-04-24 10:30:07,834] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 38.0, 110.5, 806.0, 22.5, 22.43879880926568, -0.3157841294050447, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3938400.0000, 
sim time next is 3939600.0000, 
raw observation next is [-4.666666666666667, 38.0, 106.8333333333333, 794.0, 22.5, 22.59678234637354, -0.2981217284944794, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3333333333333333, 0.38, 0.356111111111111, 0.8773480662983425, 0.375, 0.3830651955311284, 0.40062609050184017, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03252348], dtype=float32), 0.5699485]. 
=============================================
[2019-04-24 10:30:17,692] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.91288221e-01 1.25816325e-03 1.32660150e-17 3.49470309e-17
 1.31589189e-16 4.06256084e-19 7.30400119e-19 5.68272305e-19
 4.04947944e-15 1.07453555e-01 2.71095149e-18], sum to 1.0000
[2019-04-24 10:30:17,695] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3733
[2019-04-24 10:30:17,716] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 78.0, 37.0, 27.5, 22.5, 23.00815294318219, -0.2058100080015139, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4467600.0000, 
sim time next is 4468800.0000, 
raw observation next is [0.0, 76.0, 29.0, 45.83333333333334, 22.5, 22.71433992646617, -0.2941619283849948, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.46260387811634357, 0.76, 0.09666666666666666, 0.050644567219152864, 0.375, 0.3928616605388475, 0.4019460238716684, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.47051275], dtype=float32), -0.6855538]. 
=============================================
[2019-04-24 10:30:18,371] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.8854982e-01 1.5118762e-02 7.4925215e-16 1.4899295e-15 5.2715494e-15
 6.5128654e-17 3.3600534e-16 4.3850426e-17 1.9884085e-13 2.9633144e-01
 1.2653883e-16], sum to 1.0000
[2019-04-24 10:30:18,377] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3839
[2019-04-24 10:30:18,393] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 73.0, 0.0, 0.0, 19.0, 19.06983323535975, -1.028500144544003, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4500000.0000, 
sim time next is 4501200.0000, 
raw observation next is [-0.7333333333333334, 73.0, 0.0, 0.0, 19.0, 18.98869616287792, -1.05021457253042, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.44228993536472766, 0.73, 0.0, 0.0, 0.08333333333333333, 0.08239134690649319, 0.14992847582319335, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9995, 
noisyNet noise sample is [array([-1.0499948], dtype=float32), 0.28053254]. 
=============================================
[2019-04-24 10:30:19,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.5454049e-01 6.9661823e-04 6.2280548e-19 5.2204183e-18 6.4732657e-18
 5.2830177e-20 2.8058874e-19 9.7387773e-20 2.2858004e-15 4.4762842e-02
 1.9768032e-19], sum to 1.0000
[2019-04-24 10:30:19,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8031
[2019-04-24 10:30:19,197] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 112.5, 0.0, 22.5, 22.95000027394547, -0.3262333083274425, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4711200.0000, 
sim time next is 4712400.0000, 
raw observation next is [1.0, 86.0, 121.5, 0.0, 22.5, 22.35117908465195, -0.4100940441399348, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4903047091412743, 0.86, 0.405, 0.0, 0.375, 0.36259825705432913, 0.3633019852866884, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0896769], dtype=float32), -0.5003767]. 
=============================================
[2019-04-24 10:30:20,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7843837e-01 3.9831162e-03 4.0610320e-14 7.9279750e-14 3.9422855e-14
 4.6149669e-16 2.9394011e-15 2.8065727e-15 3.8752521e-12 3.1757855e-01
 2.9824568e-15], sum to 1.0000
[2019-04-24 10:30:20,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1960
[2019-04-24 10:30:20,128] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.9, 66.33333333333334, 32.66666666666666, 9.999999999999998, 22.5, 21.7007079534629, -0.5869925575147409, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 145200.0000, 
sim time next is 146400.0000, 
raw observation next is [-7.1, 68.66666666666666, 22.5, 2.5, 22.5, 21.55397963727199, -0.634622407423287, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.2659279778393352, 0.6866666666666665, 0.075, 0.0027624309392265192, 0.375, 0.2961649697726658, 0.288459197525571, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.5469, 
noisyNet noise sample is [array([1.3165678], dtype=float32), -0.26173136]. 
=============================================
[2019-04-24 10:30:21,944] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.9480839e-01 9.7335344e-03 4.1449070e-16 4.8906242e-16 2.5367398e-15
 8.3523934e-17 3.0832545e-16 2.8611638e-17 1.4309964e-13 1.9545814e-01
 8.8650667e-17], sum to 1.0000
[2019-04-24 10:30:21,953] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0348
[2019-04-24 10:30:21,969] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.5, 69.0, 0.0, 0.0, 19.0, 20.04470380025142, -0.8829333314065071, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4593600.0000, 
sim time next is 4594800.0000, 
raw observation next is [-1.666666666666667, 69.66666666666667, 0.0, 0.0, 19.0, 19.87482875887534, -0.9166722550018708, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4164358264081256, 0.6966666666666668, 0.0, 0.0, 0.08333333333333333, 0.1562357299062782, 0.19444258166604309, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.386739], dtype=float32), 1.2088985]. 
=============================================
[2019-04-24 10:30:22,661] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.1843873e-01 6.3916068e-03 8.8416363e-17 8.4265200e-17 3.6156001e-16
 9.8167438e-18 1.5625060e-17 2.1547093e-18 3.1648658e-14 7.5169712e-02
 1.2733601e-17], sum to 1.0000
[2019-04-24 10:30:22,663] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3955
[2019-04-24 10:30:22,696] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8333333333333334, 71.66666666666666, 0.0, 0.0, 19.0, 21.29725951620773, -0.6305214887391791, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4509600.0000, 
sim time next is 4510800.0000, 
raw observation next is [-0.8, 71.0, 0.0, 0.0, 19.0, 20.88020273014651, -0.7414433642317647, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.4404432132963989, 0.71, 0.0, 0.0, 0.08333333333333333, 0.24001689417887592, 0.2528522119227451, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0246035], dtype=float32), -0.6327033]. 
=============================================
[2019-04-24 10:30:22,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8240131e-01 2.9106226e-04 6.7587248e-21 3.2181542e-19 4.9492284e-19
 1.0455382e-21 7.0894621e-21 7.2561410e-22 1.3549156e-16 1.7307660e-02
 8.2033036e-21], sum to 1.0000
[2019-04-24 10:30:22,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5818
[2019-04-24 10:30:23,016] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.6, 42.0, 7.5, 0.0, 22.5, 24.14635722284242, 0.1071583851083965, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4383600.0000, 
sim time next is 4384800.0000, 
raw observation next is [12.4, 44.0, 0.0, 0.0, 22.5, 24.29081384731458, 0.1140354907247124, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.806094182825485, 0.44, 0.0, 0.0, 0.375, 0.5242344872762151, 0.5380118302415707, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3906735], dtype=float32), 0.85370797]. 
=============================================
[2019-04-24 10:30:23,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4838953e-01 1.0483722e-03 2.6568793e-18 2.6448572e-17 1.3995491e-17
 9.5229562e-20 2.6793610e-19 3.8904976e-20 1.1745273e-15 5.0562035e-02
 2.2219209e-19], sum to 1.0000
[2019-04-24 10:30:23,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2111
[2019-04-24 10:30:23,558] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333334, 90.0, 117.6666666666667, 0.9999999999999998, 22.5, 22.84846360062457, -0.2655230575254714, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4452000.0000, 
sim time next is 4453200.0000, 
raw observation next is [0.0, 92.0, 149.0, 3.0, 22.5, 22.49320278740892, -0.3341863000361378, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.46260387811634357, 0.92, 0.49666666666666665, 0.0033149171270718232, 0.375, 0.37443356561740987, 0.38860456665462073, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3256106], dtype=float32), 1.8224965]. 
=============================================
[2019-04-24 10:30:26,402] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:26,577] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:27,404] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:27,405] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:27,409] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run9
[2019-04-24 10:30:28,733] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:28,996] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:29,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:29,721] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:29,731] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run9
[2019-04-24 10:30:30,681] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:30,890] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:31,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:31,686] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:31,689] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run9
[2019-04-24 10:30:34,043] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6012950e-01 9.6897432e-04 2.4936716e-18 2.4116184e-17 3.9717815e-17
 4.8265932e-19 4.0008369e-19 3.3494616e-19 3.8311275e-15 3.8901526e-02
 1.8464572e-18], sum to 1.0000
[2019-04-24 10:30:34,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4598
[2019-04-24 10:30:34,085] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.666666666666667, 50.33333333333334, 0.0, 0.0, 22.5, 23.85885080243761, 0.0398800257804412, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4645200.0000, 
sim time next is 4646400.0000, 
raw observation next is [3.333333333333333, 51.66666666666666, 0.0, 0.0, 22.5, 23.72453026072539, 0.01179818866583045, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5549399815327793, 0.5166666666666666, 0.0, 0.0, 0.375, 0.4770441883937826, 0.5039327295552768, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30758363], dtype=float32), 2.5157337]. 
=============================================
[2019-04-24 10:30:34,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2342429e-01 2.8084865e-02 3.0169492e-16 5.2065411e-16 1.7317027e-15
 1.8723234e-16 1.7934802e-16 1.4748538e-17 7.3122335e-14 3.4849080e-01
 5.1440159e-17], sum to 1.0000
[2019-04-24 10:30:34,786] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0244
[2019-04-24 10:30:34,804] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 73.0, 20.5, 28.49999999999999, 22.5, 19.45019358381061, -0.9710648351603325, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4606800.0000, 
sim time next is 4608000.0000, 
raw observation next is [-2.0, 71.0, 61.5, 85.5, 22.5, 19.49430307406752, -0.9622696949657078, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.40720221606648205, 0.71, 0.205, 0.09447513812154697, 0.375, 0.12452525617229337, 0.17924343501143072, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0880, 
noisyNet noise sample is [array([0.16980886], dtype=float32), 0.25864506]. 
=============================================
[2019-04-24 10:30:35,084] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:35,318] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:36,038] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:36,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:36,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:36,096] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run9
[2019-04-24 10:30:36,230] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:36,526] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:36,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:36,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:36,916] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:37,034] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:37,034] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:37,042] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run9
[2019-04-24 10:30:37,131] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6657220e-01 5.6993039e-03 8.7941190e-19 1.4305881e-18 1.0363946e-17
 1.8421383e-19 1.1741958e-18 6.6826086e-20 5.7880064e-16 1.2772839e-01
 4.8815743e-19], sum to 1.0000
[2019-04-24 10:30:37,131] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7602
[2019-04-24 10:30:37,138] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 49.0, 0.0, 19.0, 19.9401440734128, -0.8418933127561358, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 36000.0000, 
sim time next is 37200.0000, 
raw observation next is [7.7, 93.0, 56.33333333333333, 0.0, 19.0, 19.71385744345169, -0.8665870130102834, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.6759002770083103, 0.93, 0.18777777777777777, 0.0, 0.08333333333333333, 0.1428214536209742, 0.21113766232990552, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.50239366], dtype=float32), 2.6217258]. 
=============================================
[2019-04-24 10:30:37,235] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.6025211e-01 9.1399794e-04 2.0296893e-18 7.4958942e-18 1.6818317e-17
 2.1078222e-19 2.7983717e-19 1.7833529e-19 3.9979227e-15 3.8833801e-02
 4.0863265e-19], sum to 1.0000
[2019-04-24 10:30:37,235] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0943
[2019-04-24 10:30:37,262] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 32.66666666666667, 121.8333333333333, 839.0, 22.5, 23.63600099592964, -0.06103678365331758, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5052000.0000, 
sim time next is 5053200.0000, 
raw observation next is [7.0, 29.33333333333334, 123.1666666666667, 848.3333333333334, 22.5, 23.90141718545662, -0.03933723725393623, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6565096952908588, 0.2933333333333334, 0.4105555555555557, 0.9373848987108656, 0.375, 0.4917847654547183, 0.4868875875820213, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.87910575], dtype=float32), -0.2993652]. 
=============================================
[2019-04-24 10:30:37,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:37,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:37,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run9
[2019-04-24 10:30:37,642] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:37,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:37,647] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run9
[2019-04-24 10:30:38,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.8652855e-01 1.7215386e-03 5.1814759e-18 1.2079597e-17 8.6020307e-18
 1.4152882e-19 3.1808962e-19 1.0124496e-18 5.2966757e-15 1.1174993e-01
 5.5816669e-19], sum to 1.0000
[2019-04-24 10:30:38,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9064
[2019-04-24 10:30:38,269] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.6666666666666666, 88.0, 195.5, 5.0, 22.5, 23.46128416351456, -0.2155280995379626, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4707600.0000, 
sim time next is 4708800.0000, 
raw observation next is [1.0, 86.0, 160.5, 3.0, 22.5, 23.77714823368938, 0.0578154091208267, 1.0, 1.0, 60.0, 102.36313719471673], 
processed observation next is [1.0, 0.5217391304347826, 0.4903047091412743, 0.86, 0.535, 0.0033149171270718232, 0.375, 0.4814290194741151, 0.5192718030402755, 1.0, 1.0, 0.9, 1.0236313719471672], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5811158], dtype=float32), -0.7914018]. 
=============================================
[2019-04-24 10:30:38,581] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:38,920] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:38,947] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:39,127] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:39,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:39,585] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:39,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run9
[2019-04-24 10:30:39,905] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:39,906] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:39,910] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run9
[2019-04-24 10:30:42,023] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:42,207] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:42,463] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2377565e-01 1.0383738e-02 6.7697897e-15 1.5993015e-14 2.0121774e-14
 4.5305332e-15 4.6096969e-15 3.1588892e-16 9.2694830e-13 1.6584063e-01
 2.9751543e-15], sum to 1.0000
[2019-04-24 10:30:42,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4942
[2019-04-24 10:30:42,474] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 42.33333333333333, 0.0, 0.0, 19.0, 19.97162782014182, -0.9392122523444, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4909200.0000, 
sim time next is 4910400.0000, 
raw observation next is [1.0, 40.0, 0.0, 0.0, 19.0, 19.70698160907163, -0.9816175586583897, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.4, 0.0, 0.0, 0.08333333333333333, 0.14224846742263578, 0.1727941471138701, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.39209], dtype=float32), 1.3500302]. 
=============================================
[2019-04-24 10:30:42,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:42,942] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:43,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:43,021] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:43,025] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run9
[2019-04-24 10:30:43,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:43,655] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:43,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run9
[2019-04-24 10:30:45,754] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:46,014] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:46,296] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:46,619] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:46,755] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:46,756] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:46,759] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run9
[2019-04-24 10:30:47,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:47,297] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:47,300] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run9
[2019-04-24 10:30:48,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:49,234] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:49,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:49,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:49,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run9
[2019-04-24 10:30:50,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_7 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:30:51,164] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_7 ERROR:Aborted (core dumped)

[2019-04-24 10:30:51,879] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:30:51,880] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:30:51,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run9
[2019-04-24 10:30:54,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5764375e-01 3.0516756e-03 5.8201743e-18 7.1880295e-17 1.3167156e-16
 2.9354675e-18 1.1626486e-17 2.0008682e-18 1.8939750e-15 3.9304525e-02
 5.1302941e-18], sum to 1.0000
[2019-04-24 10:30:54,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3597
[2019-04-24 10:30:54,531] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.433333333333333, 88.33333333333334, 0.0, 0.0, 19.0, 20.45684483417747, -0.6317943909636948, 0.0, 1.0, 60.0, 86.31566671810916], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 96000.0000, 
sim time next is 97200.0000, 
raw observation next is [-2.8, 87.0, 0.0, 0.0, 19.0, 20.7858428312203, -0.7767738398106262, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.38504155124653744, 0.87, 0.0, 0.0, 0.08333333333333333, 0.23215356926835837, 0.24107538672979126, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12388686], dtype=float32), 1.2227622]. 
=============================================
[2019-04-24 10:30:56,448] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.60079229e-01 1.10599715e-02 4.65476968e-19 1.34463844e-18
 6.32162733e-18 3.72266224e-19 5.47842805e-19 6.64606212e-20
 2.89846442e-16 1.28860831e-01 1.58934638e-19], sum to 1.0000
[2019-04-24 10:30:56,448] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.7905
[2019-04-24 10:30:56,474] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 20.80304700669825, -0.6417973876560417, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 21600.0000, 
sim time next is 22800.0000, 
raw observation next is [7.7, 93.0, 0.0, 0.0, 19.0, 20.58200978269404, -0.6756039984208232, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.21516748189117005, 0.27479866719305895, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4543183], dtype=float32), -0.24531]. 
=============================================
[2019-04-24 10:30:57,359] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.6525116e-01 1.9373136e-03 6.1834868e-19 3.6963753e-18 6.6418926e-18
 4.7488997e-19 5.0108270e-19 2.8196131e-20 6.1938130e-16 2.3281154e-01
 1.0436889e-18], sum to 1.0000
[2019-04-24 10:30:57,359] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0489
[2019-04-24 10:30:57,378] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.533333333333333, 86.0, 80.33333333333334, 0.0, 19.0, 20.97382519632489, -0.6078518496262734, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 51600.0000, 
sim time next is 52800.0000, 
raw observation next is [7.366666666666667, 86.0, 74.16666666666667, 0.0, 19.0, 20.76250049057516, -0.6404595642745771, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.6666666666666667, 0.86, 0.24722222222222223, 0.0, 0.08333333333333333, 0.2302083742145967, 0.286513478575141, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7433122], dtype=float32), -0.046576478]. 
=============================================
[2019-04-24 10:31:01,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4823979e-01 1.9457405e-02 1.2590981e-16 3.1597749e-16 1.7357394e-15
 1.9866501e-17 1.3226581e-16 3.4961493e-17 2.9024414e-14 3.3230287e-01
 4.1099739e-17], sum to 1.0000
[2019-04-24 10:31:01,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3275
[2019-04-24 10:31:01,642] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.2, 81.66666666666667, 0.0, 0.0, 19.0, 20.62914233762355, -0.819254160014224, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 99600.0000, 
sim time next is 100800.0000, 
raw observation next is [-3.4, 79.0, 0.0, 0.0, 19.0, 19.80376608793183, -0.9715641208050365, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.368421052631579, 0.79, 0.0, 0.0, 0.08333333333333333, 0.15031384066098585, 0.17614529306498783, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.95319], dtype=float32), 0.0676837]. 
=============================================
[2019-04-24 10:31:06,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7580460e-01 9.5327105e-03 6.0326760e-13 3.4360845e-12 1.0173566e-12
 6.7638549e-14 4.7051555e-14 5.3778654e-14 1.6711982e-10 1.1466264e-01
 1.7146588e-13], sum to 1.0000
[2019-04-24 10:31:06,235] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2003
[2019-04-24 10:31:06,286] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.0, 78.66666666666667, 0.0, 0.0, 19.0, 19.16183924816195, -0.9235396099829248, 0.0, 1.0, 60.0, 108.3108622617045], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 336000.0000, 
sim time next is 337200.0000, 
raw observation next is [-13.2, 80.33333333333333, 0.0, 0.0, 19.0, 19.82181155848406, -1.0737007203229, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.09695290858725764, 0.8033333333333332, 0.0, 0.0, 0.08333333333333333, 0.15181762987367176, 0.14209975989236664, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4719146], dtype=float32), 0.001198431]. 
=============================================
[2019-04-24 10:31:07,235] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7215071e-01 3.9093744e-02 2.0911022e-12 4.7082746e-12 5.4261829e-12
 5.6597527e-13 7.7922971e-13 4.7598118e-13 5.4077739e-11 4.8875546e-01
 5.6749294e-13], sum to 1.0000
[2019-04-24 10:31:07,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1309
[2019-04-24 10:31:07,264] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-11.0, 51.0, 0.0, 0.0, 19.0, 18.37895747126578, -1.172533682347177, 0.0, 1.0, 60.0, 98.89199558894228], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 445200.0000, 
sim time next is 446400.0000, 
raw observation next is [-11.2, 52.0, 0.0, 0.0, 19.0, 18.86647982915286, -1.331774131515445, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.15235457063711913, 0.52, 0.0, 0.0, 0.08333333333333333, 0.07220665242940487, 0.05607528949485167, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5295525], dtype=float32), -0.50121826]. 
=============================================
[2019-04-24 10:31:14,072] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-24 10:31:14,076] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:31:14,077] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:31:14,076] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:31:14,084] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:31:14,086] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run12
[2019-04-24 10:31:14,079] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run12
[2019-04-24 10:31:14,110] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:31:14,135] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:31:14,139] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run12
[2019-04-24 10:31:40,224] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.24746567], dtype=float32), 0.6432364]
[2019-04-24 10:31:40,226] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-3.9, 55.0, 0.0, 0.0, 22.5, 21.86722700079466, -0.5706072395665435, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:31:40,227] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:31:40,228] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [5.0679886e-01 9.2762513e-03 5.3249868e-14 8.0296623e-14 9.3821848e-14
 4.0614167e-15 1.2516393e-14 4.6219458e-15 8.1901664e-12 4.8392487e-01
 1.3178608e-14], sampled 0.5433316371344652
[2019-04-24 10:32:41,681] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.24746567], dtype=float32), 0.6432364]
[2019-04-24 10:32:41,682] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-6.0, 77.0, 0.0, 0.0, 19.0, 18.94141774076801, -0.9355368009697118, 0.0, 1.0, 60.0, 92.2806027025348]
[2019-04-24 10:32:41,682] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:32:41,683] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [8.4901553e-01 2.2566486e-02 3.7450051e-14 1.4130698e-13 1.2277760e-13
 1.1915679e-14 2.4880966e-14 6.5797854e-15 6.4847693e-12 1.2841795e-01
 1.9192374e-14], sampled 0.9966483328669438
[2019-04-24 10:33:05,728] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([-0.24746567], dtype=float32), 0.6432364]
[2019-04-24 10:33:05,728] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [15.63333333333333, 64.33333333333334, 0.0, 0.0, 19.0, 27.40549494213803, 0.9601192598419935, 0.0, 0.0, 15.0, 0.0]
[2019-04-24 10:33:05,728] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:33:05,729] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [9.9901605e-01 4.2061325e-05 1.5661345e-18 1.0910851e-16 9.5994522e-17
 1.6154360e-18 1.0775007e-18 4.8187898e-19 9.0912580e-15 9.4194658e-04
 3.4949350e-17], sampled 0.9136179485956303
[2019-04-24 10:33:12,426] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3426.2611 69241.4944 -75.5699
[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,464] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:12,639] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,500] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3203.5057 86765.8828 -270.5575
[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,531] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:21,707] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:31,815] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3130.6095 89510.9220 -362.6289
[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:31,851] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,033] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:33:32,853] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 550000, evaluation results [550000.0, 3203.505722257702, 86765.88282398913, -270.5575191770752, 3426.261129128453, 69241.4943855455, -75.56986546444662, 3130.609513910982, 89510.92195208435, -362.62889950629483]
[2019-04-24 10:33:37,369] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3798394e-01 8.0301888e-02 9.1763212e-12 2.3781418e-11 1.8543007e-11
 2.4535090e-12 5.6516636e-12 3.5936085e-12 2.8465358e-10 6.8171418e-01
 1.5061927e-12], sum to 1.0000
[2019-04-24 10:33:37,369] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9175
[2019-04-24 10:33:37,503] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-15.0, 69.0, 0.0, 0.0, 19.0, 18.53669790284498, -1.334520924239423, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 356400.0000, 
sim time next is 357600.0000, 
raw observation next is [-15.2, 70.33333333333334, 0.0, 0.0, 19.0, 18.61220320472414, -1.067848053982367, 0.0, 1.0, 60.0, 103.78181155821225], 
processed observation next is [1.0, 0.13043478260869565, 0.04155124653739613, 0.7033333333333335, 0.0, 0.0, 0.08333333333333333, 0.05101693372701158, 0.14405064867254436, 0.0, 1.0, 0.9, 1.0378181155821224], 
reward next is 0.4669, 
noisyNet noise sample is [array([0.6058378], dtype=float32), -0.2270269]. 
=============================================
[2019-04-24 10:33:38,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6935679e-01 2.5396382e-02 1.2204479e-12 4.7443594e-12 2.1088977e-12
 1.4094470e-13 3.3552300e-13 5.4575978e-13 1.2452327e-10 7.0524687e-01
 3.4069817e-13], sum to 1.0000
[2019-04-24 10:33:38,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2412
[2019-04-24 10:33:38,946] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.73333333333333, 74.0, 0.0, 0.0, 19.0, 19.51047551886806, -1.066445079061781, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 340800.0000, 
sim time next is 342000.0000, 
raw observation next is [-13.9, 70.0, 0.0, 0.0, 19.0, 19.08996165454481, -1.140232527176113, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.07756232686980608, 0.7, 0.0, 0.0, 0.08333333333333333, 0.09083013787873402, 0.1199224909412957, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6306918], dtype=float32), -0.49859318]. 
=============================================
[2019-04-24 10:33:43,588] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.8023446e-01 1.5675813e-02 3.0887827e-16 1.0479795e-15 4.5244811e-15
 6.1467361e-17 1.9768019e-16 3.4558286e-17 7.9244960e-14 2.0408970e-01
 5.7659412e-16], sum to 1.0000
[2019-04-24 10:33:43,589] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.9343
[2019-04-24 10:33:43,699] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.8, 81.0, 109.5, 265.5, 19.0, 20.27551366377635, -0.8693880717511394, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 561600.0000, 
sim time next is 562800.0000, 
raw observation next is [-0.9333333333333333, 80.66666666666667, 123.1666666666667, 352.5, 19.0, 20.27978689755926, -0.6218871350330987, 0.0, 1.0, 60.0, 89.09308765763615], 
processed observation next is [0.0, 0.5217391304347826, 0.4367497691597415, 0.8066666666666668, 0.4105555555555557, 0.38950276243093923, 0.08333333333333333, 0.18998224146327156, 0.29270428832230044, 0.0, 1.0, 0.9, 0.8909308765763615], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4296639], dtype=float32), -0.77449137]. 
=============================================
[2019-04-24 10:33:44,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.39234316e-01 2.72496603e-04 3.94023543e-20 1.38771426e-19
 1.71120753e-19 1.19050627e-21 1.00775206e-21 5.80724512e-22
 2.43922675e-17 6.04931638e-02 1.08400606e-20], sum to 1.0000
[2019-04-24 10:33:44,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5692
[2019-04-24 10:33:44,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.2, 73.0, 92.5, 700.5, 22.5, 25.32003610630375, 0.3667591975248337, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1515600.0000, 
sim time next is 1516800.0000, 
raw observation next is [8.133333333333333, 69.66666666666667, 87.5, 700.8333333333334, 22.5, 25.34280946079747, 0.3524554410363281, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.687903970452447, 0.6966666666666668, 0.2916666666666667, 0.774401473296501, 0.375, 0.611900788399789, 0.6174851470121093, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.339237], dtype=float32), 1.0513592]. 
=============================================
[2019-04-24 10:33:46,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4429204e-01 1.4140932e-02 2.8277296e-13 1.1128515e-13 2.5333300e-13
 1.8118494e-14 3.3136888e-14 5.1891547e-15 6.3294608e-12 7.4156708e-01
 1.8771170e-14], sum to 1.0000
[2019-04-24 10:33:46,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6836
[2019-04-24 10:33:46,679] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.2, 57.0, 0.0, 0.0, 19.0, 18.63742558667293, -1.239420952369181, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 668400.0000, 
sim time next is 669600.0000, 
raw observation next is [-1.2, 57.0, 0.0, 0.0, 19.0, 19.02878240745769, -0.9283121510383131, 0.0, 1.0, 60.0, 99.34173110330252], 
processed observation next is [0.0, 0.782608695652174, 0.42936288088642666, 0.57, 0.0, 0.0, 0.08333333333333333, 0.08573186728814086, 0.1905626163205623, 0.0, 1.0, 0.9, 0.9934173110330252], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1800709], dtype=float32), -0.5490912]. 
=============================================
[2019-04-24 10:33:50,387] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.5886950e-01 1.1331887e-02 2.5512997e-14 8.4354398e-14 1.4514269e-13
 8.1097425e-15 5.6750915e-15 7.6211298e-15 4.9698340e-12 3.2979861e-01
 7.4221575e-15], sum to 1.0000
[2019-04-24 10:33:50,400] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7111
[2019-04-24 10:33:50,574] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.8, 55.00000000000001, 36.33333333333333, 18.83333333333333, 19.0, 20.46962183261644, -0.9258646116253858, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 663600.0000, 
sim time next is 664800.0000, 
raw observation next is [-1.0, 56.0, 22.5, 12.83333333333333, 19.0, 20.31343976379018, -0.7650931024460462, 0.0, 1.0, 60.0, 84.69564965520797], 
processed observation next is [0.0, 0.6956521739130435, 0.4349030470914128, 0.56, 0.075, 0.014180478821362795, 0.08333333333333333, 0.19278664698251488, 0.24496896585131792, 0.0, 1.0, 0.9, 0.8469564965520797], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.297632], dtype=float32), 0.87644786]. 
=============================================
[2019-04-24 10:34:00,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2986999e-01 6.6057700e-03 6.6223028e-14 7.7361450e-14 6.7907085e-14
 8.0280930e-16 2.0863044e-15 1.5878065e-15 3.7082095e-12 6.6352427e-01
 3.1799845e-15], sum to 1.0000
[2019-04-24 10:34:00,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5411
[2019-04-24 10:34:00,682] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.4, 35.66666666666667, 98.16666666666667, 0.0, 22.5, 22.07083700437358, -0.7050806341076902, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 483600.0000, 
sim time next is 484800.0000, 
raw observation next is [-0.2, 36.33333333333333, 87.66666666666667, 0.0, 22.5, 22.13669252386867, -0.3385541336731417, 1.0, 1.0, 60.0, 94.54083651310326], 
processed observation next is [1.0, 0.6086956521739131, 0.4570637119113574, 0.3633333333333333, 0.2922222222222222, 0.0, 0.375, 0.34472437698905595, 0.3871486221089528, 1.0, 1.0, 0.9, 0.9454083651310325], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1628292], dtype=float32), 0.010197879]. 
=============================================
[2019-04-24 10:34:04,255] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.86598897e-01 1.61096212e-02 2.61272700e-14 1.07370242e-13
 9.25264504e-14 1.39454446e-14 9.43693298e-15 6.13592869e-15
 1.63393214e-12 2.97291517e-01 1.20994320e-14], sum to 1.0000
[2019-04-24 10:34:04,256] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4252
[2019-04-24 10:34:04,360] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 71.0, 0.0, 0.0, 19.0, 19.5008893096116, -1.128655281057248, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 691200.0000, 
sim time next is 692400.0000, 
raw observation next is [-3.733333333333333, 71.33333333333334, 0.0, 0.0, 19.0, 18.85427764413767, -1.268656501325724, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.35918744228993543, 0.7133333333333334, 0.0, 0.0, 0.08333333333333333, 0.07118980367813925, 0.07711449955809198, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9151, 
noisyNet noise sample is [array([0.48211977], dtype=float32), 1.1587944]. 
=============================================
[2019-04-24 10:34:04,602] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [2.7524757e-01 2.3213729e-02 2.6681829e-14 3.5871198e-14 6.1882770e-14
 7.5552959e-15 1.0872283e-14 3.3974849e-15 1.6019982e-12 7.0153868e-01
 4.6224964e-15], sum to 1.0000
[2019-04-24 10:34:04,603] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0295
[2019-04-24 10:34:04,662] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 73.0, 0.0, 0.0, 19.0, 17.74588425939931, -1.442601101363312, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 696000.0000, 
sim time next is 697200.0000, 
raw observation next is [-3.4, 74.0, 0.0, 0.0, 19.0, 17.54967839569495, -1.481947164099112, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.368421052631579, 0.74, 0.0, 0.0, 0.08333333333333333, -0.03752680035875411, 0.006017611966962673, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48211977], dtype=float32), 1.1587944]. 
=============================================
[2019-04-24 10:34:15,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8861432e-01 6.0773047e-04 8.0251799e-17 6.2434190e-16 1.8459251e-15
 1.2731976e-16 3.7202005e-17 1.1159676e-17 5.5141452e-14 1.0777870e-02
 3.4290030e-16], sum to 1.0000
[2019-04-24 10:34:15,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1325
[2019-04-24 10:34:15,945] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.33333333333334, 69.66666666666667, 0.0, 0.0, 19.0, 23.01125629584386, -0.02386765137068227, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1200000.0000, 
sim time next is 1201200.0000, 
raw observation next is [16.96666666666667, 72.33333333333334, 0.0, 0.0, 19.0, 23.00232289695384, -0.02522324667579929, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.9325946445060022, 0.7233333333333334, 0.0, 0.0, 0.08333333333333333, 0.4168602414128199, 0.49159225110806687, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.029566], dtype=float32), -0.51952875]. 
=============================================
[2019-04-24 10:34:20,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9144554e-01 2.2816502e-04 5.4554888e-19 7.0960839e-18 2.3664421e-17
 8.0485494e-20 1.0971307e-19 2.6000653e-20 2.7372393e-15 8.3261868e-03
 1.4383390e-18], sum to 1.0000
[2019-04-24 10:34:20,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3140
[2019-04-24 10:34:20,535] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 60.0, 0.0, 0.0, 22.5, 24.22091789197796, 0.2527208307450289, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1108800.0000, 
sim time next is 1110000.0000, 
raw observation next is [13.63333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 24.05176880644244, 0.2243162235373567, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.840258541089566, 0.6066666666666667, 0.0, 0.0, 0.08333333333333333, 0.5043140672035366, 0.5747720745124522, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1398194], dtype=float32), -1.5384003]. 
=============================================
[2019-04-24 10:34:20,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[82.0449  ]
 [79.315025]
 [75.83758 ]
 [73.18117 ]
 [73.54923 ]
 [73.88212 ]
 [74.27123 ]
 [74.68329 ]
 [75.13812 ]
 [75.52681 ]
 [75.71959 ]
 [75.7964  ]
 [75.794754]
 [75.7095  ]
 [75.70359 ]
 [75.66171 ]
 [75.43186 ]
 [76.90456 ]
 [78.96081 ]
 [81.5584  ]
 [84.39141 ]
 [86.78306 ]
 [89.373535]
 [92.41001 ]
 [96.05971 ]], R is [[84.64404297]
 [84.79759979]
 [84.94962311]
 [85.10012817]
 [85.24913025]
 [85.39663696]
 [85.5426712 ]
 [85.68724823]
 [85.83037567]
 [85.97207642]
 [86.11235809]
 [86.25123596]
 [86.38872528]
 [86.52484131]
 [86.65959167]
 [86.79299927]
 [86.92507172]
 [87.05582428]
 [87.18526459]
 [87.31341553]
 [87.44028473]
 [87.56587982]
 [87.69022369]
 [87.81332397]
 [87.93518829]].
[2019-04-24 10:34:20,757] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7759264e-01 5.0687911e-03 7.9679009e-15 2.8359712e-14 2.1179032e-14
 4.6123093e-16 8.9913468e-16 6.2937550e-16 2.1556361e-12 3.1733847e-01
 5.2607785e-15], sum to 1.0000
[2019-04-24 10:34:20,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4635
[2019-04-24 10:34:20,893] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.533333333333333, 55.33333333333333, 0.0, 0.0, 22.5, 21.85945972184495, -0.5452054663185519, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 754800.0000, 
sim time next is 756000.0000, 
raw observation next is [-3.9, 56.0, 0.0, 0.0, 22.5, 21.28434180986634, -0.6077079242940414, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3545706371191136, 0.56, 0.0, 0.0, 0.375, 0.27369515082219503, 0.2974306919019862, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.9524587], dtype=float32), 2.2359746]. 
=============================================
[2019-04-24 10:34:22,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4200242e-01 1.5261733e-03 1.2966091e-15 2.7173871e-14 6.9766440e-15
 4.3576821e-17 8.9310876e-17 1.8733445e-16 6.4846479e-13 5.6471329e-02
 1.8712518e-16], sum to 1.0000
[2019-04-24 10:34:22,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3246
[2019-04-24 10:34:22,582] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 53.0, 0.0, 0.0, 22.5, 21.56258121150106, -0.2869894588371211, 1.0, 1.0, 60.0, 121.20693129272428], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 759600.0000, 
sim time next is 760800.0000, 
raw observation next is [-4.266666666666667, 54.66666666666667, 0.0, 0.0, 22.5, 22.89496251312563, -0.3703248232415512, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3444136657433057, 0.5466666666666667, 0.0, 0.0, 0.375, 0.4079135427604692, 0.37655839225281623, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.12151937], dtype=float32), 1.3543217]. 
=============================================
[2019-04-24 10:34:23,806] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.5653323e-01 5.5666091e-03 5.2649358e-19 9.5515869e-19 2.7608505e-18
 3.3583610e-20 3.0659884e-19 1.8502324e-20 4.1315562e-16 1.3790010e-01
 3.2073238e-19], sum to 1.0000
[2019-04-24 10:34:23,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5824
[2019-04-24 10:34:23,814] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.6, 81.0, 0.0, 0.0, 19.0, 21.76132774591778, -0.3098716570980187, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1143600.0000, 
sim time next is 1144800.0000, 
raw observation next is [11.6, 83.0, 0.0, 0.0, 19.0, 21.69239538125674, -0.3244259283953078, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.7839335180055402, 0.83, 0.0, 0.0, 0.08333333333333333, 0.30769961510472843, 0.3918580238682307, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1249998], dtype=float32), 0.31923392]. 
=============================================
[2019-04-24 10:34:27,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9445565e-01 1.4902679e-02 3.5102464e-19 4.0995150e-18 9.0949633e-18
 2.9463098e-19 7.0495465e-19 1.1398407e-19 5.7112366e-16 1.9064172e-01
 1.3898336e-19], sum to 1.0000
[2019-04-24 10:34:27,077] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2184
[2019-04-24 10:34:27,095] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.699999999999999, 82.0, 0.0, 0.0, 19.0, 21.20347159456782, -0.6567456674910278, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 963600.0000, 
sim time next is 964800.0000, 
raw observation next is [7.7, 83.0, 0.0, 0.0, 19.0, 20.76736152251531, -0.7231012725437803, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.6759002770083103, 0.83, 0.0, 0.0, 0.08333333333333333, 0.23061346020960904, 0.25896624248540656, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0763704], dtype=float32), 0.82157326]. 
=============================================
[2019-04-24 10:34:28,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.7518728e-01 1.2691369e-02 1.6646167e-18 2.6958562e-17 1.1458077e-17
 2.4849108e-19 2.0088381e-18 2.0658003e-19 8.4981847e-16 1.1212133e-01
 1.0019369e-18], sum to 1.0000
[2019-04-24 10:34:28,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3060
[2019-04-24 10:34:28,277] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 95.33333333333334, 0.0, 0.0, 19.0, 22.44216191326457, -0.4031951453936242, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1482000.0000, 
sim time next is 1483200.0000, 
raw observation next is [2.2, 96.0, 0.0, 0.0, 19.0, 21.5056215161703, -0.5595278192517682, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5235457063711911, 0.96, 0.0, 0.0, 0.08333333333333333, 0.2921351263475251, 0.31349072691607727, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1921504], dtype=float32), -0.05876441]. 
=============================================
[2019-04-24 10:34:31,009] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.8346921e-01 2.0026566e-02 8.1829951e-18 6.1703048e-17 1.6110462e-16
 2.7034624e-18 5.0339598e-18 2.6434372e-18 4.9176001e-15 3.9650428e-01
 1.3350222e-18], sum to 1.0000
[2019-04-24 10:34:31,020] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1602
[2019-04-24 10:34:31,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.6252052e-01 7.1672592e-03 1.1547513e-17 4.7663963e-17 3.7486872e-17
 3.5299147e-19 1.2675153e-18 9.6785684e-19 1.1495909e-14 1.3031217e-01
 2.1982558e-18], sum to 1.0000
[2019-04-24 10:34:31,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6420
[2019-04-24 10:34:31,073] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 41.33333333333334, 0.0, 22.5, 23.06641733338409, -0.217327843742331, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1438800.0000, 
sim time next is 1440000.0000, 
raw observation next is [1.1, 92.0, 32.0, 0.0, 22.5, 22.80211646766994, -0.243564341670851, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.92, 0.10666666666666667, 0.0, 0.375, 0.4001763723058283, 0.4188118861097163, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7622503], dtype=float32), 0.59077364]. 
=============================================
[2019-04-24 10:34:31,083] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[82.9315  ]
 [83.17158 ]
 [83.29574 ]
 [83.45296 ]
 [83.612144]
 [82.87819 ]
 [82.98486 ]
 [83.21034 ]
 [83.59124 ]
 [83.10213 ]
 [83.40582 ]
 [83.74559 ]
 [83.049805]
 [83.282585]
 [83.46853 ]
 [83.6547  ]
 [83.69015 ]
 [83.80159 ]
 [84.26807 ]
 [83.71096 ]
 [83.956184]
 [82.96046 ]
 [83.232605]
 [83.4926  ]
 [82.175644]], R is [[82.94616699]
 [83.11670685]
 [83.28553772]
 [83.4526825 ]
 [83.61815643]
 [82.78197479]
 [82.95415497]
 [83.1246109 ]
 [83.29336548]
 [82.46043396]
 [82.63583374]
 [82.80947876]
 [81.98138428]
 [82.16156769]
 [82.33995056]
 [82.51654816]
 [82.69138336]
 [81.86447144]
 [82.04582977]
 [81.22537231]
 [81.41311646]
 [80.59898376]
 [80.79299164]
 [80.98506165]
 [80.17520905]].
[2019-04-24 10:34:31,093] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 22.66666666666666, 0.0, 22.5, 22.35381706945062, -0.4482764729515775, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1413600.0000, 
sim time next is 1414800.0000, 
raw observation next is [-0.6, 100.0, 32.0, 0.0, 22.5, 22.17986000789776, -0.4695325617802452, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.44598337950138506, 1.0, 0.10666666666666667, 0.0, 0.375, 0.34832166732481323, 0.3434891460732516, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.52963746], dtype=float32), -0.04120291]. 
=============================================
[2019-04-24 10:34:31,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7709109e-01 2.8101569e-03 6.8950992e-18 5.0407367e-17 2.8233071e-17
 4.0288912e-19 1.2293899e-18 1.2403374e-18 8.3620092e-15 2.2009875e-01
 9.2031763e-19], sum to 1.0000
[2019-04-24 10:34:31,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4231
[2019-04-24 10:34:31,788] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 41.33333333333334, 0.0, 22.5, 22.94988099111942, -0.232593599000177, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1438800.0000, 
sim time next is 1440000.0000, 
raw observation next is [1.1, 92.0, 32.0, 0.0, 22.5, 22.6698720795643, -0.284113803582471, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.49307479224376743, 0.92, 0.10666666666666667, 0.0, 0.375, 0.3891560066303583, 0.405295398805843, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.0232719], dtype=float32), 0.9200986]. 
=============================================
[2019-04-24 10:34:31,799] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[82.50633 ]
 [82.59506 ]
 [82.66366 ]
 [82.762405]
 [82.85697 ]
 [83.084496]
 [82.322136]
 [82.57284 ]
 [82.8708  ]
 [82.1661  ]
 [82.4703  ]
 [82.687706]
 [82.9729  ]
 [83.105705]
 [83.29819 ]
 [83.28679 ]
 [83.308334]
 [84.113106]
 [83.79591 ]
 [83.962616]
 [83.23439 ]
 [83.14716 ]
 [83.528946]
 [83.82519 ]
 [82.541504]], R is [[82.50940704]
 [82.68431091]
 [82.85746765]
 [83.02889252]
 [83.19860077]
 [83.3666153 ]
 [82.53295135]
 [82.70762634]
 [82.8805542 ]
 [82.05175018]
 [82.23123169]
 [82.40892029]
 [82.58483124]
 [82.75898743]
 [82.93139648]
 [83.1020813 ]
 [83.27106476]
 [83.43835449]
 [82.60397339]
 [82.77793121]
 [81.95014954]
 [82.13064575]
 [82.30934143]
 [82.48625183]
 [81.66139221]].
[2019-04-24 10:34:31,998] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.00977254e-01 6.17919397e-03 1.17439885e-19 4.63246889e-19
 9.08049305e-19 3.87855199e-20 1.03521796e-19 4.77410199e-21
 5.34326515e-17 9.28435698e-02 2.88458301e-20], sum to 1.0000
[2019-04-24 10:34:32,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5053
[2019-04-24 10:34:32,011] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.7, 80.0, 0.0, 0.0, 19.0, 22.03562052167209, -0.2595223709973798, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1148400.0000, 
sim time next is 1149600.0000, 
raw observation next is [12.7, 81.33333333333334, 0.0, 0.0, 19.0, 21.94348622732635, -0.2753930008159304, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.8144044321329641, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.3286238522771958, 0.4082023330613565, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.159968], dtype=float32), -0.7615599]. 
=============================================
[2019-04-24 10:34:33,539] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.5556817e-01 6.4195916e-03 7.6622964e-18 4.6953194e-17 3.2543383e-17
 5.0061694e-19 1.6992147e-18 7.6651281e-19 5.3372084e-15 1.3801232e-01
 1.6425873e-18], sum to 1.0000
[2019-04-24 10:34:33,539] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0975
[2019-04-24 10:34:33,550] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 59.0, 0.0, 22.5, 24.20026478012863, -0.0866842527784245, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1418400.0000, 
sim time next is 1419600.0000, 
raw observation next is [0.0, 95.0, 67.66666666666667, 0.0, 22.5, 23.68284793841149, -0.1776584235270603, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.46260387811634357, 0.95, 0.22555555555555556, 0.0, 0.375, 0.47357066153429095, 0.44078052549097996, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2351336], dtype=float32), 0.5161107]. 
=============================================
[2019-04-24 10:34:35,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8753291e-01 9.4408379e-04 7.9130579e-20 8.0216243e-19 2.4249025e-18
 7.4957065e-20 5.4096749e-20 3.6623926e-21 1.0985413e-16 1.1522966e-02
 1.1775005e-19], sum to 1.0000
[2019-04-24 10:34:35,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5094
[2019-04-24 10:34:35,447] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 82.0, 0.0, 0.0, 19.0, 22.51478079696154, -0.05998868848901689, 0.0, 1.0, 60.0, 90.77114358304948], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1576800.0000, 
sim time next is 1578000.0000, 
raw observation next is [5.166666666666667, 81.0, 0.0, 0.0, 19.0, 23.47478879090672, -0.1580085802995611, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.6057248384118191, 0.81, 0.0, 0.0, 0.08333333333333333, 0.4562323992422268, 0.4473304732334797, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.00570869], dtype=float32), -0.8669671]. 
=============================================
[2019-04-24 10:34:38,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9425832e-01 7.6427907e-03 1.6040363e-19 2.1516035e-18 2.2482217e-18
 4.7945230e-20 1.1267995e-19 2.3892401e-20 2.0938174e-16 9.8098934e-02
 9.9471189e-20], sum to 1.0000
[2019-04-24 10:34:38,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3962
[2019-04-24 10:34:38,080] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.933333333333334, 92.0, 25.16666666666667, 0.0, 22.5, 23.62499874534083, -0.05849738585036159, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1671600.0000, 
sim time next is 1672800.0000, 
raw observation next is [2.566666666666667, 92.0, 33.83333333333333, 0.0, 22.5, 23.37740334618716, -0.1003030658636202, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.5337026777469991, 0.92, 0.11277777777777777, 0.0, 0.375, 0.44811694551559683, 0.46656564471212664, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0902125], dtype=float32), -0.6562458]. 
=============================================
[2019-04-24 10:34:46,733] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.4179177e-01 9.1083106e-03 1.7632488e-14 8.0859208e-14 1.0002469e-13
 4.4975984e-15 7.6293681e-15 5.3017105e-15 2.2242774e-12 4.9100000e-02
 1.0979084e-14], sum to 1.0000
[2019-04-24 10:34:46,737] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3420
[2019-04-24 10:34:46,775] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.4, 78.33333333333334, 0.0, 0.0, 19.0, 18.69381380656108, -0.9898541302828159, 0.0, 1.0, 60.0, 102.1907818749389], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1816800.0000, 
sim time next is 1818000.0000, 
raw observation next is [-5.6, 78.0, 0.0, 0.0, 19.0, 19.53411791275698, -1.104194919719783, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.30747922437673136, 0.78, 0.0, 0.0, 0.08333333333333333, 0.12784315939641497, 0.13193502676007238, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.3519082], dtype=float32), 0.8522349]. 
=============================================
[2019-04-24 10:34:47,327] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [5.8906478e-01 4.6314709e-02 1.8553991e-13 3.2596763e-13 7.2896290e-13
 5.9985240e-14 1.5107841e-13 3.5534658e-14 8.6906012e-12 3.6462048e-01
 1.4920442e-13], sum to 1.0000
[2019-04-24 10:34:47,329] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4748
[2019-04-24 10:34:47,340] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 79.0, 0.0, 0.0, 19.0, 18.6793060516104, -1.287712694094916, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1832400.0000, 
sim time next is 1833600.0000, 
raw observation next is [-6.2, 79.0, 0.0, 0.0, 19.0, 17.9124084248747, -1.418079492985353, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.2908587257617729, 0.79, 0.0, 0.0, 0.08333333333333333, -0.007299297927108188, 0.027306835671548974, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24068461], dtype=float32), 2.3046186]. 
=============================================
[2019-04-24 10:34:49,460] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.5879852e-01 1.7040374e-02 2.2449651e-13 2.1955304e-13 4.3735515e-13
 2.6949487e-14 3.1510388e-14 9.0872193e-15 4.2363344e-12 3.2416114e-01
 1.9614266e-14], sum to 1.0000
[2019-04-24 10:34:49,461] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0782
[2019-04-24 10:34:49,498] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 79.0, 0.0, 0.0, 19.0, 19.4113719356652, -1.105567506655908, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1814400.0000, 
sim time next is 1815600.0000, 
raw observation next is [-5.2, 78.66666666666667, 0.0, 0.0, 19.0, 18.63761193854094, -1.254390124277014, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.31855955678670367, 0.7866666666666667, 0.0, 0.0, 0.08333333333333333, 0.05313432821174491, 0.0818699585743287, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.4747, 
noisyNet noise sample is [array([2.1799812], dtype=float32), -0.6960681]. 
=============================================
[2019-04-24 10:34:53,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7638863e-01 1.6457422e-03 9.6579417e-16 1.6613406e-14 3.9279552e-15
 6.1130183e-17 6.0643160e-16 4.1299863e-16 1.9506668e-12 2.1965601e-02
 7.8013344e-16], sum to 1.0000
[2019-04-24 10:34:53,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7975
[2019-04-24 10:34:53,525] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.366666666666667, 64.0, 150.6666666666667, 111.6666666666667, 22.5, 22.49425993589152, -0.1451933853941912, 1.0, 1.0, 60.0, 112.4514247370417], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2119200.0000, 
sim time next is 2120400.0000, 
raw observation next is [-6.2, 64.0, 150.0, 67.0, 22.5, 23.90350879960229, -0.2933052681843754, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.2908587257617729, 0.64, 0.5, 0.07403314917127071, 0.375, 0.49195906663352407, 0.4022315772718749, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3601488], dtype=float32), -0.5929834]. 
=============================================
[2019-04-24 10:34:55,914] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7975761e-01 5.9648273e-03 2.3916661e-16 2.0494506e-15 2.1498221e-15
 1.3278811e-16 8.8364562e-17 1.8489393e-17 6.3658599e-14 1.4277593e-02
 4.2548482e-16], sum to 1.0000
[2019-04-24 10:34:55,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1530
[2019-04-24 10:34:55,939] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.1, 85.66666666666667, 70.33333333333334, 0.0, 19.0, 21.06966208543173, -0.5013208114215647, 0.0, 1.0, 60.0, 62.90489091796721], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1762800.0000, 
sim time next is 1764000.0000, 
raw observation next is [-2.3, 87.0, 81.0, 0.0, 19.0, 21.30112012416527, -0.6737889342542659, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3988919667590028, 0.87, 0.27, 0.0, 0.08333333333333333, 0.2750933436804391, 0.2754036885819114, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7160456], dtype=float32), 0.124851756]. 
=============================================
[2019-04-24 10:34:58,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.5938495e-01 7.6997750e-03 2.6140662e-16 1.5588663e-15 1.2576547e-15
 7.5532065e-17 5.1107940e-17 2.0436791e-17 5.7658373e-14 1.3291520e-01
 3.5620343e-17], sum to 1.0000
[2019-04-24 10:34:58,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1774
[2019-04-24 10:34:58,910] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 19.0, 21.91498539322102, -0.5628639891356673, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2847600.0000, 
sim time next is 2848800.0000, 
raw observation next is [1.666666666666667, 65.33333333333334, 0.0, 0.0, 19.0, 21.34283856624169, -0.6481919410285557, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.5087719298245615, 0.6533333333333334, 0.0, 0.0, 0.08333333333333333, 0.2785698805201407, 0.2839360196571481, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.89645344], dtype=float32), 0.11486756]. 
=============================================
[2019-04-24 10:35:05,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8761551e-01 3.1760059e-02 4.0873941e-14 1.3470270e-13 1.5786715e-13
 3.1062768e-14 3.0912881e-14 1.5090353e-14 1.0946751e-11 2.8062445e-01
 1.0151847e-13], sum to 1.0000
[2019-04-24 10:35:05,683] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7137
[2019-04-24 10:35:05,765] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [0.0, 47.0, 123.0, 170.5, 19.0, 19.68657370669557, -0.9654382073917588, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2386800.0000, 
sim time next is 2388000.0000, 
raw observation next is [0.0, 47.0, 98.33333333333333, 284.1666666666667, 19.0, 19.98807523525405, -0.7271573221588342, 0.0, 1.0, 20.0, 74.02093087965932], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.3277777777777778, 0.31399631675874773, 0.08333333333333333, 0.16567293627117094, 0.25761422594705524, 0.0, 1.0, 0.1, 0.7402093087965932], 
reward next is 0.1598, 
noisyNet noise sample is [array([0.361135], dtype=float32), 0.21204017]. 
=============================================
[2019-04-24 10:35:14,250] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.1829593e-01 6.7098439e-02 2.4317640e-14 1.5302648e-13 1.2449177e-13
 3.4255175e-15 1.5951426e-14 3.7735356e-15 4.7709853e-12 2.1460569e-01
 5.2480561e-15], sum to 1.0000
[2019-04-24 10:35:14,315] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6562
[2019-04-24 10:35:14,337] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.3, 91.0, 0.0, 0.0, 19.0, 20.07021152410794, -1.005082259139165, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2270400.0000, 
sim time next is 2271600.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 19.0, 19.19950674485007, -1.169736904581195, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.08333333333333333, 0.09995889540417242, 0.11008769847293502, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5340627], dtype=float32), -0.35997748]. 
=============================================
[2019-04-24 10:35:15,322] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.4807798e-01 4.8153130e-03 3.5848264e-15 5.0619885e-14 4.7394973e-14
 1.4704579e-15 2.3395082e-15 3.9085327e-16 5.1682828e-13 4.7106687e-02
 7.5612209e-15], sum to 1.0000
[2019-04-24 10:35:15,323] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2590
[2019-04-24 10:35:15,360] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 47.0, 209.5, 365.0, 19.0, 19.63865871080208, -0.7228747705518658, 0.0, 1.0, 60.0, 97.11936962371686], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2376000.0000, 
sim time next is 2377200.0000, 
raw observation next is [-1.0, 49.33333333333334, 237.8333333333333, 404.3333333333334, 19.0, 20.66165981320587, -0.782450525445639, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4349030470914128, 0.4933333333333334, 0.7927777777777776, 0.44677716390423583, 0.08333333333333333, 0.22180498443382243, 0.239183158184787, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9592876], dtype=float32), 1.4322252]. 
=============================================
[2019-04-24 10:35:21,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1662699e-01 9.4547262e-03 4.2611714e-14 9.2221857e-14 3.2176315e-13
 9.4643896e-15 1.8940670e-14 2.3253458e-15 6.1156687e-12 7.3918290e-02
 2.4894475e-14], sum to 1.0000
[2019-04-24 10:35:21,376] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8208
[2019-04-24 10:35:21,400] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.8, 27.66666666666667, 87.5, 834.1666666666667, 19.0, 20.77947667453639, -0.8218081604580193, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2467200.0000, 
sim time next is 2468400.0000, 
raw observation next is [2.0, 27.33333333333334, 85.5, 824.0, 19.0, 20.36226403446436, -0.9086758927075659, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.518005540166205, 0.2733333333333334, 0.285, 0.9104972375690608, 0.08333333333333333, 0.19685533620536333, 0.1971080357641447, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05884991], dtype=float32), -0.68519616]. 
=============================================
[2019-04-24 10:35:24,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2699729e-01 1.5752535e-02 1.3613009e-14 5.4257593e-14 3.4550643e-14
 1.2694329e-15 4.8279404e-15 1.4410867e-15 2.1080039e-12 3.5725024e-01
 1.4472679e-15], sum to 1.0000
[2019-04-24 10:35:24,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7287
[2019-04-24 10:35:24,205] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.566666666666666, 71.33333333333333, 175.1666666666667, 60.0, 22.5, 22.50092099063839, -0.5280675298036527, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2284800.0000, 
sim time next is 2286000.0000, 
raw observation next is [-5.0, 68.0, 169.5, 80.0, 22.5, 22.76250340701746, -0.2740418631889189, 1.0, 1.0, 60.0, 86.6231824170762], 
processed observation next is [1.0, 0.4782608695652174, 0.32409972299168976, 0.68, 0.565, 0.08839779005524862, 0.375, 0.39687528391812155, 0.4086527122703603, 1.0, 1.0, 0.9, 0.8662318241707619], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5710079], dtype=float32), 0.18724504]. 
=============================================
[2019-04-24 10:35:24,917] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7319670e-01 2.4007356e-02 1.4518825e-12 2.8252964e-12 2.6067993e-12
 2.2955208e-13 3.6859619e-13 1.4753700e-13 3.3208273e-11 2.0279595e-01
 5.6270711e-13], sum to 1.0000
[2019-04-24 10:35:24,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2011
[2019-04-24 10:35:24,952] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 44.0, 0.0, 0.0, 19.0, 19.57973581573554, -1.090510765975542, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2412000.0000, 
sim time next is 2413200.0000, 
raw observation next is [-4.666666666666667, 43.0, 0.0, 0.0, 19.0, 19.06734097157744, -1.187431145833816, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.3333333333333333, 0.43, 0.0, 0.0, 0.08333333333333333, 0.0889450809647867, 0.10418961805539466, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.04737964], dtype=float32), -1.7159054]. 
=============================================
[2019-04-24 10:35:25,307] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9883460e-01 3.4719788e-02 6.6721661e-13 5.3414781e-12 2.9553744e-12
 1.5004357e-12 5.2987860e-13 2.2689084e-13 1.3581435e-10 2.6644561e-01
 1.2025634e-12], sum to 1.0000
[2019-04-24 10:35:25,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5597
[2019-04-24 10:35:25,408] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.166666666666666, 45.33333333333333, 63.5, 683.6666666666667, 19.0, 19.04410584961379, -0.97910034405328, 0.0, 1.0, 60.0, 89.70609160889288], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2454000.0000, 
sim time next is 2455200.0000, 
raw observation next is [-5.6, 43.0, 68.5, 721.0, 19.0, 19.66847341968808, -1.073579135978266, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.43, 0.22833333333333333, 0.7966850828729282, 0.08333333333333333, 0.13903945164067336, 0.14214028800724465, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.025321], dtype=float32), -1.3350866]. 
=============================================
[2019-04-24 10:35:26,248] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.6455816e-01 7.6007862e-03 2.5112723e-15 3.7731625e-14 7.2556935e-15
 2.8571287e-16 5.6254873e-16 4.2869319e-16 2.1668381e-12 1.2784100e-01
 5.1771263e-16], sum to 1.0000
[2019-04-24 10:35:26,250] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4674
[2019-04-24 10:35:26,262] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2333333333333334, 45.66666666666667, 177.5, 200.3333333333333, 22.5, 21.8297146010396, -0.5336165578532334, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2640000.0000, 
sim time next is 2641200.0000, 
raw observation next is [0.1333333333333333, 44.33333333333333, 172.6666666666667, 197.5, 22.5, 22.05581808109478, -0.5068061737132937, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.46629732225300097, 0.4433333333333333, 0.5755555555555557, 0.21823204419889503, 0.375, 0.33798484009123175, 0.3310646087622354, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.25652984], dtype=float32), 0.5244168]. 
=============================================
[2019-04-24 10:35:27,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8510344e-01 1.4549036e-02 3.6373964e-13 1.4709654e-12 1.2065907e-12
 1.0467332e-13 8.4973275e-14 5.2645503e-14 2.3629950e-11 2.0034756e-01
 1.5140152e-13], sum to 1.0000
[2019-04-24 10:35:27,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9776
[2019-04-24 10:35:28,061] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.333333333333333, 37.0, 0.0, 0.0, 19.0, 20.14951039253442, -1.029113789364028, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2504400.0000, 
sim time next is 2505600.0000, 
raw observation next is [-1.7, 38.0, 0.0, 0.0, 19.0, 20.08646907512244, -0.8649564582337912, 0.0, 1.0, 60.0, 83.30357196910128], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.38, 0.0, 0.0, 0.08333333333333333, 0.17387242292687008, 0.21168118058873628, 0.0, 1.0, 0.9, 0.8330357196910129], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5655657], dtype=float32), 1.4106711]. 
=============================================
[2019-04-24 10:35:36,993] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [3.45660329e-01 1.00494318e-01 5.58564913e-13 3.68243007e-13
 3.39688753e-13 2.37926439e-14 8.17590285e-14 1.36310285e-14
 1.58454725e-11 5.53845346e-01 3.72462749e-14], sum to 1.0000
[2019-04-24 10:35:36,994] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.9363
[2019-04-24 10:35:37,074] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.3023619364368, -1.129143915456228, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2785200.0000, 
sim time next is 2786400.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 19.57972794429408, -0.8347623475514343, 0.0, 1.0, 60.0, 94.68544419139731], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.1316439953578401, 0.2217458841495219, 0.0, 1.0, 0.9, 0.946854441913973], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23334956], dtype=float32), 0.15394495]. 
=============================================
[2019-04-24 10:35:38,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.5576606e-01 1.7735908e-02 6.9599769e-14 1.4914440e-13 1.6345788e-13
 1.9301075e-14 2.1542506e-14 2.4246900e-15 9.2266559e-12 1.2649809e-01
 6.9194609e-14], sum to 1.0000
[2019-04-24 10:35:38,404] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6318
[2019-04-24 10:35:38,415] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 51.66666666666666, 113.1666666666667, 815.1666666666667, 19.0, 19.22850879467936, -1.029525102599437, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3069600.0000, 
sim time next is 3070800.0000, 
raw observation next is [-2.0, 50.0, 111.5, 811.5, 19.0, 19.0600415463414, -1.050106776402956, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.40720221606648205, 0.5, 0.37166666666666665, 0.8966850828729281, 0.08333333333333333, 0.0883367955284499, 0.14996440786568135, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.03354279], dtype=float32), 0.24435543]. 
=============================================
[2019-04-24 10:35:40,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4195116e-01 1.8026879e-03 3.4303335e-19 2.7796557e-18 1.3089356e-18
 2.4260753e-20 9.0786672e-20 1.1812206e-20 7.1360615e-16 5.6246176e-02
 1.3668211e-19], sum to 1.0000
[2019-04-24 10:35:40,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2356
[2019-04-24 10:35:41,019] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 100.0, 0.0, 0.0, 19.0, 22.64094274422911, -0.1062854977796223, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3188400.0000, 
sim time next is 3189600.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 19.0, 22.57422443292047, -0.1241774850079641, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.518005540166205, 1.0, 0.0, 0.0, 0.08333333333333333, 0.38118536941003917, 0.4586075049973453, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.10874572], dtype=float32), 1.38066]. 
=============================================
[2019-04-24 10:35:44,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.7585217e-01 2.2041736e-02 1.0915308e-14 4.9004183e-14 6.0671926e-14
 2.1780747e-15 6.5186737e-15 4.5817029e-15 1.1901989e-12 1.0210616e-01
 5.5628846e-15], sum to 1.0000
[2019-04-24 10:35:44,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6120
[2019-04-24 10:35:44,123] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.0, 77.0, 0.0, 0.0, 19.0, 21.79704516548411, -0.6064664086695981, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3292800.0000, 
sim time next is 3294000.0000, 
raw observation next is [-8.0, 77.0, 0.0, 0.0, 19.0, 20.71143022408849, -0.7767163689520832, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.24099722991689754, 0.77, 0.0, 0.0, 0.08333333333333333, 0.22595251867404098, 0.24109454368263894, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8432472], dtype=float32), -0.060139135]. 
=============================================
[2019-04-24 10:35:52,396] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.11316574e-01 2.56258529e-03 1.29191475e-17 1.46059079e-16
 2.07135382e-16 1.06190118e-18 1.61045251e-18 1.91943952e-18
 1.40982883e-14 8.61208737e-02 5.37829608e-18], sum to 1.0000
[2019-04-24 10:35:52,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0841
[2019-04-24 10:35:52,449] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 80.66666666666666, 98.33333333333334, 755.1666666666667, 22.5, 23.51561775691781, -0.1476325771326161, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3249600.0000, 
sim time next is 3250800.0000, 
raw observation next is [-2.0, 71.0, 93.0, 727.5, 22.5, 22.31521200857151, -0.1959833326113398, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.40720221606648205, 0.71, 0.31, 0.8038674033149171, 0.375, 0.3596010007142925, 0.4346722224628867, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.46125966], dtype=float32), -0.42230418]. 
=============================================
[2019-04-24 10:35:53,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7804910e-01 4.3426952e-03 8.6151298e-17 2.4103100e-15 8.0133885e-16
 2.0064262e-17 3.5808417e-17 1.6411058e-17 5.0437973e-14 1.7608192e-02
 4.4467671e-17], sum to 1.0000
[2019-04-24 10:35:53,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4494
[2019-04-24 10:35:53,230] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 0.0, 0.0, 19.0, 21.5468482008441, -0.2025785531953584, 0.0, 1.0, 60.0, 96.98468034474658], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3276000.0000, 
sim time next is 3277200.0000, 
raw observation next is [-6.0, 92.0, 0.0, 0.0, 19.0, 22.34597700722379, -0.3798264520628312, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.296398891966759, 0.92, 0.0, 0.0, 0.08333333333333333, 0.36216475060198255, 0.37339118264572296, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.86680096], dtype=float32), -0.7322503]. 
=============================================
[2019-04-24 10:35:55,534] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8138139e-01 9.3116434e-03 2.6277691e-14 6.6042203e-14 5.2653235e-14
 9.7712408e-15 6.8637634e-15 8.6404386e-16 1.7194015e-12 1.0930702e-01
 4.9359280e-14], sum to 1.0000
[2019-04-24 10:35:55,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3645
[2019-04-24 10:35:55,563] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 104.0, 790.5, 19.0, 20.65635891984709, -0.7770498873561543, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3074400.0000, 
sim time next is 3075600.0000, 
raw observation next is [-0.6666666666666667, 41.0, 100.6666666666667, 780.1666666666667, 19.0, 20.32355300296224, -0.8228024403163766, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.44413665743305636, 0.41, 0.33555555555555566, 0.8620626151012892, 0.08333333333333333, 0.1936294169135199, 0.22573251989454113, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02596768], dtype=float32), -1.5054889]. 
=============================================
[2019-04-24 10:35:56,109] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8452491e-01 5.8524939e-04 1.4271108e-19 6.3697172e-19 5.8983556e-19
 1.3048327e-20 9.0415882e-21 3.1848598e-21 6.9075206e-17 1.4889832e-02
 6.9309224e-20], sum to 1.0000
[2019-04-24 10:35:56,122] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4710
[2019-04-24 10:35:56,150] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 100.0, 0.0, 0.0, 19.0, 24.3726846134312, 0.1823656119955712, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3186000.0000, 
sim time next is 3187200.0000, 
raw observation next is [2.666666666666667, 100.0, 0.0, 0.0, 19.0, 23.88644548792089, 0.07851157280871578, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.5364727608494922, 1.0, 0.0, 0.0, 0.08333333333333333, 0.4905371239934076, 0.5261705242695719, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6577568], dtype=float32), 0.0032212036]. 
=============================================
[2019-04-24 10:35:56,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7799066e-01 2.1255288e-02 9.6721187e-18 8.0237049e-17 6.2213485e-17
 6.8657288e-19 2.2238130e-18 3.4020007e-18 6.5160199e-15 1.0075408e-01
 3.3200509e-18], sum to 1.0000
[2019-04-24 10:35:56,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4913
[2019-04-24 10:35:56,930] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 100.0, 0.0, 0.0, 19.0, 21.02002297904847, -0.8635372934757477, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3121200.0000, 
sim time next is 3122400.0000, 
raw observation next is [2.2, 100.0, 0.0, 0.0, 19.0, 20.11864586345985, -1.015356573845626, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5235457063711911, 1.0, 0.0, 0.0, 0.08333333333333333, 0.1765538219549875, 0.16154780871812466, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.67342734], dtype=float32), -0.75797606]. 
=============================================
[2019-04-24 10:36:00,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0506361e-01 2.7213346e-02 4.9792422e-14 9.7960783e-14 7.0129422e-14
 1.9735653e-14 1.7795666e-14 6.0676765e-15 4.1078573e-12 1.6772301e-01
 2.9278544e-14], sum to 1.0000
[2019-04-24 10:36:00,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3007
[2019-04-24 10:36:00,639] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 53.33333333333334, 117.3333333333333, 821.8333333333334, 19.0, 20.16146983703135, -0.7957222856727989, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3586800.0000, 
sim time next is 3588000.0000, 
raw observation next is [-2.333333333333333, 51.66666666666666, 117.3333333333333, 821.1666666666667, 19.0, 19.9321647639583, -0.8245699623734932, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3979686057248385, 0.5166666666666666, 0.391111111111111, 0.9073664825046042, 0.08333333333333333, 0.16101373032985844, 0.22514334587550225, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2934007], dtype=float32), 0.64553845]. 
=============================================
[2019-04-24 10:36:09,216] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8878175e-01 1.3923560e-03 4.5031481e-18 1.3728077e-16 8.9677880e-17
 8.0381746e-19 1.8846967e-18 1.0585668e-18 2.2306408e-14 9.8259160e-03
 6.0232811e-18], sum to 1.0000
[2019-04-24 10:36:09,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3711
[2019-04-24 10:36:09,235] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333333, 74.0, 0.0, 0.0, 19.0, 21.56343384935877, -0.2243682030333285, 0.0, 1.0, 60.0, 99.97151137410907], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3532800.0000, 
sim time next is 3534000.0000, 
raw observation next is [-0.6666666666666666, 76.0, 0.0, 0.0, 19.0, 22.59754583726419, -0.297068703492245, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.44413665743305636, 0.76, 0.0, 0.0, 0.08333333333333333, 0.38312881977201574, 0.4009770988359183, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0758089], dtype=float32), -0.7896223]. 
=============================================
[2019-04-24 10:36:09,393] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2410749e-01 9.8024225e-03 1.2410376e-14 2.0810481e-14 4.8931067e-14
 1.5344797e-15 2.1673337e-15 2.4929768e-16 1.0277060e-12 6.6090010e-02
 2.4511096e-15], sum to 1.0000
[2019-04-24 10:36:09,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8348
[2019-04-24 10:36:09,406] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 108.0, 800.0, 19.0, 20.2477692951696, -0.7474717704264707, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3592800.0000, 
sim time next is 3594000.0000, 
raw observation next is [-1.0, 42.0, 104.0, 792.0, 19.0, 20.15184869004033, -0.7605955598831753, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.4349030470914128, 0.42, 0.3466666666666667, 0.8751381215469614, 0.08333333333333333, 0.17932072417002765, 0.24646814670560824, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.05480245], dtype=float32), -0.20899525]. 
=============================================
[2019-04-24 10:36:11,606] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0604100e-01 1.3349176e-02 7.5891814e-14 1.5746234e-13 3.0391865e-13
 7.7590496e-15 2.1123411e-14 7.0989776e-15 4.6569801e-12 1.8060988e-01
 1.6023812e-14], sum to 1.0000
[2019-04-24 10:36:11,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6336
[2019-04-24 10:36:11,640] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 19.0, 20.47717096461355, -0.774903776155996, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3609600.0000, 
sim time next is 3610800.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 19.0, 20.33463747482291, -0.803296266448521, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.4349030470914128, 0.42, 0.0, 0.0, 0.08333333333333333, 0.19455312290190907, 0.23223457785049298, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0391116], dtype=float32), 2.1554244]. 
=============================================
[2019-04-24 10:36:16,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9198589e-01 1.7035794e-02 8.8324378e-15 3.5830066e-14 4.0791267e-14
 1.0888355e-14 5.9503937e-15 6.2195872e-16 1.4722156e-12 9.0978302e-02
 1.8873053e-14], sum to 1.0000
[2019-04-24 10:36:16,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0600
[2019-04-24 10:36:16,878] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 30.0, 118.5, 834.5, 19.0, 20.99358272043803, -0.6428924856634994, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4190400.0000, 
sim time next is 4191600.0000, 
raw observation next is [1.333333333333333, 31.33333333333334, 118.1666666666667, 842.8333333333334, 19.0, 20.76099317090027, -0.6688682155032346, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4995383194829178, 0.3133333333333334, 0.393888888888889, 0.9313075506445673, 0.08333333333333333, 0.23008276424168925, 0.2770439281655885, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.229858], dtype=float32), 0.10842009]. 
=============================================
[2019-04-24 10:36:18,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:36:18,331] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:36:19,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:36:19,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:36:19,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run10
[2019-04-24 10:36:22,231] A3C_AGENT_WORKER-Thread-7 INFO:Evaluating...
[2019-04-24 10:36:22,232] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:36:22,233] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:36:22,235] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run13
[2019-04-24 10:36:22,260] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:36:22,262] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:36:22,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:36:22,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:36:22,266] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run13
[2019-04-24 10:36:22,286] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run13
[2019-04-24 10:37:01,160] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:NoisyNet noise sample: [array([-0.24405259], dtype=float32), 0.64809614]
[2019-04-24 10:37:01,160] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation this: [4.911899154, 96.84022807666668, 0.0, 0.0, 19.0, 20.95371581647242, -0.4978982613343347, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:37:01,160] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 DEBUG:Observation forecast: []
[2019-04-24 10:37:01,161] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Softmax [9.4496262e-01 4.5712530e-03 2.4255665e-18 8.4719383e-18 1.5318594e-17
 5.1913891e-19 7.9894904e-19 1.6076162e-19 1.5315863e-15 5.0466131e-02
 1.5226245e-18], sampled 0.48909392658178286
[2019-04-24 10:38:14,504] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([-0.24405259], dtype=float32), 0.64809614]
[2019-04-24 10:38:14,505] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [10.43333333333333, 45.0, 112.1666666666667, 568.8333333333333, 22.5, 22.89329776330451, -0.06218751711003215, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:38:14,505] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:38:14,507] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [9.48643088e-01 3.86857381e-03 4.86934912e-19 8.37917779e-19
 3.86775882e-18 1.09089264e-19 1.07988746e-19 1.22715927e-20
 1.80772898e-16 4.74882796e-02 2.10933835e-19], sampled 0.9054926768344792
[2019-04-24 10:38:23,907] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3370.1990 56586.7479 -341.1435
[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,023] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:24,253] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,525] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3104.9287 71565.8714 -616.9447
[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,563] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:39,735] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:48,968] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3033.1774 74268.6071 -679.2161
[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,001] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:49,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:38:50,003] A3C_AGENT_WORKER-Thread-7 INFO:Global step: 600000, evaluation results [600000.0, 3104.9287029769107, 71565.87141632334, -616.9447488236669, 3370.199032659307, 56586.74786958453, -341.1434991447962, 3033.1773525079557, 74268.60711277221, -679.2160611946746]
[2019-04-24 10:39:03,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1216570e-01 1.6634051e-02 5.4423273e-15 2.0046739e-14 9.9275285e-15
 2.3602626e-15 2.5563393e-15 3.0473175e-16 6.1545625e-13 7.1200177e-02
 2.1748153e-15], sum to 1.0000
[2019-04-24 10:39:03,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1673
[2019-04-24 10:39:03,270] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.9, 40.33333333333334, 31.33333333333333, 227.5, 19.0, 20.06045530309298, -0.8647919309171247, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4209600.0000, 
sim time next is 4210800.0000, 
raw observation next is [1.8, 40.66666666666667, 20.0, 135.8333333333333, 19.0, 19.90108666653382, -0.899632853185973, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5124653739612189, 0.40666666666666673, 0.06666666666666667, 0.1500920810313075, 0.08333333333333333, 0.15842388887781844, 0.20012238227134235, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9401671], dtype=float32), -2.0991757]. 
=============================================
[2019-04-24 10:39:08,827] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5209140e-01 9.0408511e-02 3.2487245e-13 8.2244717e-14 2.0599718e-13
 4.7787166e-14 8.8075292e-14 1.9502591e-14 3.9841064e-12 5.5750006e-01
 2.4927739e-14], sum to 1.0000
[2019-04-24 10:39:08,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4289
[2019-04-24 10:39:08,938] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-3.0, 60.00000000000001, 0.0, 0.0, 19.0, 18.46650215567514, -1.281585290605465, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 4850400.0000, 
sim time next is 4851600.0000, 
raw observation next is [-3.0, 60.0, 0.0, 0.0, 19.0, 18.71856961683664, -1.047687589670459, 0.0, 1.0, 20.0, 79.94845204709199], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.6, 0.0, 0.0, 0.08333333333333333, 0.05988080140305326, 0.15077080344318036, 0.0, 1.0, 0.1, 0.7994845204709199], 
reward next is 0.6068, 
noisyNet noise sample is [array([-0.04624452], dtype=float32), -0.38878056]. 
=============================================
[2019-04-24 10:39:11,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7453827e-01 1.1426132e-03 1.4656565e-18 2.0753856e-17 1.1017119e-17
 3.5747263e-20 1.4924838e-19 1.3794788e-20 2.9941156e-15 2.4319177e-02
 5.5484241e-19], sum to 1.0000
[2019-04-24 10:39:11,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2792
[2019-04-24 10:39:11,918] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 72.66666666666667, 185.8333333333333, 5.0, 22.5, 23.99514694311032, -0.09501251340196526, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4717200.0000, 
sim time next is 4718400.0000, 
raw observation next is [1.333333333333333, 72.33333333333334, 187.8333333333333, 5.0, 22.5, 23.90962514786352, -0.1405636626923734, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.4995383194829178, 0.7233333333333334, 0.626111111111111, 0.0055248618784530384, 0.375, 0.4924687623219599, 0.45314544576920884, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0105156], dtype=float32), -0.6006301]. 
=============================================
[2019-04-24 10:39:12,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8503244e-01 3.1309098e-04 3.8280875e-20 3.9834217e-20 1.8908390e-19
 1.0301659e-21 4.5931683e-21 8.8703900e-23 1.2836062e-17 1.4654575e-02
 1.5691145e-21], sum to 1.0000
[2019-04-24 10:39:12,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0001
[2019-04-24 10:39:12,827] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.2, 59.0, 0.0, 0.0, 19.0, 23.11762780486174, -0.07050443888849307, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4395600.0000, 
sim time next is 4396800.0000, 
raw observation next is [9.933333333333334, 59.66666666666667, 0.0, 0.0, 19.0, 23.09521613317235, -0.08092365043952872, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7377654662973223, 0.5966666666666667, 0.0, 0.0, 0.08333333333333333, 0.4246013444310292, 0.47302544985349043, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7698336], dtype=float32), -0.1275053]. 
=============================================
[2019-04-24 10:39:14,892] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.8458750e-01 4.3514743e-02 1.5104582e-15 4.8711713e-15 5.8504358e-15
 4.7707050e-16 1.1867034e-15 6.5890190e-16 4.3697435e-13 1.7189778e-01
 1.7200299e-15], sum to 1.0000
[2019-04-24 10:39:14,897] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3442
[2019-04-24 10:39:14,977] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 69.0, 170.5, 472.5, 19.0, 21.05830508532591, -0.7056000226732552, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4786800.0000, 
sim time next is 4788000.0000, 
raw observation next is [-3.0, 65.0, 163.5, 575.5, 19.0, 20.5699507409766, -0.8103399762001815, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3795013850415513, 0.65, 0.545, 0.6359116022099448, 0.08333333333333333, 0.21416256174805012, 0.2298866745999395, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6263901], dtype=float32), 2.8183918]. 
=============================================
[2019-04-24 10:39:15,179] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.6648327e-01 1.2626087e-02 1.4553272e-15 6.2343141e-15 6.6040423e-15
 4.5000944e-16 1.2917608e-15 2.7399086e-16 4.9914104e-13 1.2089060e-01
 1.8940974e-15], sum to 1.0000
[2019-04-24 10:39:15,179] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3140
[2019-04-24 10:39:15,207] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 42.0, 162.0, 795.6666666666667, 19.0, 19.8875501800797, -0.813371986138928, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4796400.0000, 
sim time next is 4797600.0000, 
raw observation next is [1.666666666666667, 41.0, 178.3333333333333, 750.5, 19.0, 19.90920157371791, -0.7939208174431105, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5087719298245615, 0.41, 0.5944444444444443, 0.8292817679558011, 0.08333333333333333, 0.15910013114315932, 0.23535972751896317, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6263901], dtype=float32), 2.8183918]. 
=============================================
[2019-04-24 10:39:16,911] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [4.0437475e-01 1.1314606e-01 3.4507605e-13 1.3775327e-13 7.0540264e-13
 9.0116723e-14 4.7197077e-13 2.9116219e-14 9.3781762e-12 4.8247918e-01
 3.9319402e-14], sum to 1.0000
[2019-04-24 10:39:16,921] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4754
[2019-04-24 10:39:16,983] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 19.0, 17.44532960457883, -1.485455891013326, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 4860000.0000, 
sim time next is 4861200.0000, 
raw observation next is [-3.333333333333333, 61.66666666666667, 0.0, 0.0, 19.0, 17.92859537430627, -1.196136484798159, 0.0, 1.0, 20.0, 86.69849031045332], 
processed observation next is [0.0, 0.2608695652173913, 0.37026777469990774, 0.6166666666666667, 0.0, 0.0, 0.08333333333333333, -0.005950385474477571, 0.10128783840061366, 0.0, 1.0, 0.1, 0.8669849031045332], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0385547], dtype=float32), 1.4530246]. 
=============================================
[2019-04-24 10:39:18,643] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:18,848] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:19,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:19,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:19,645] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:19,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:19,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run10
[2019-04-24 10:39:20,262] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:20,263] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:20,265] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run10
[2019-04-24 10:39:20,684] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:20,889] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:21,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:21,709] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:21,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run10
[2019-04-24 10:39:23,542] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.9859123e-01 5.9227154e-02 2.4233071e-14 5.4267104e-14 7.2071126e-14
 9.2694627e-15 1.1698627e-14 6.2112456e-15 2.5733339e-12 2.4218166e-01
 1.8069595e-14], sum to 1.0000
[2019-04-24 10:39:23,566] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0718
[2019-04-24 10:39:23,582] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 60.0, 0.0, 0.0, 19.0, 20.05779441553477, -0.9927795858456919, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4852800.0000, 
sim time next is 4854000.0000, 
raw observation next is [-3.333333333333333, 63.66666666666667, 0.0, 0.0, 19.0, 19.43716710014228, -1.110242689114011, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.37026777469990774, 0.6366666666666667, 0.0, 0.0, 0.08333333333333333, 0.11976392501185658, 0.12991910362866302, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.049099], dtype=float32), 1.2641176]. 
=============================================
[2019-04-24 10:39:23,750] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:23,927] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:24,594] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:24,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:24,753] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:24,765] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run10
[2019-04-24 10:39:24,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:25,597] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:25,598] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:25,602] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run10
[2019-04-24 10:39:26,455] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:26,639] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:27,203] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:27,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:27,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:27,448] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run10
[2019-04-24 10:39:27,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:28,175] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9404154e-01 1.9884069e-02 1.8652068e-13 2.9107342e-14 8.8750757e-14
 1.5965822e-14 6.7629889e-14 2.4400465e-15 3.0851010e-12 7.8607440e-01
 7.5751673e-15], sum to 1.0000
[2019-04-24 10:39:28,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9154
[2019-04-24 10:39:28,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:28,197] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:28,202] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run10
[2019-04-24 10:39:28,279] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 19.0, 18.87703323772003, -1.224292893581178, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4856400.0000, 
sim time next is 4857600.0000, 
raw observation next is [-3.666666666666667, 67.33333333333334, 0.0, 0.0, 19.0, 19.02837486730135, -0.9536009454835326, 0.0, 1.0, 60.0, 92.30400427055199], 
processed observation next is [0.0, 0.21739130434782608, 0.3610341643582641, 0.6733333333333335, 0.0, 0.0, 0.08333333333333333, 0.0856979056084457, 0.1821330181721558, 0.0, 1.0, 0.9, 0.9230400427055199], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43387127], dtype=float32), -0.54542404]. 
=============================================
[2019-04-24 10:39:29,501] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:29,722] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:30,499] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:30,499] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:30,506] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run10
[2019-04-24 10:39:31,319] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:31,701] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:32,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:32,313] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:32,317] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run10
[2019-04-24 10:39:32,551] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:32,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.43921721e-01 3.26291285e-02 4.44895585e-15 1.22289314e-14
 3.21722731e-14 7.32102329e-16 1.24980251e-15 1.50374733e-15
 1.39487749e-12 1.23449109e-01 1.15563595e-15], sum to 1.0000
[2019-04-24 10:39:32,622] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8909
[2019-04-24 10:39:32,829] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:32,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:32,999] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.300000000000001, 68.0, 0.0, 0.0, 22.5, 19.58123083325023, -1.044490398803347, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 112800.0000, 
sim time next is 114000.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 22.5, 20.0932092815731, -0.7169978863321019, 0.0, 1.0, 60.0, 117.31606375536796], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.375, 0.17443410679775825, 0.261000704555966, 0.0, 1.0, 0.9, 1.1731606375536796], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03964337], dtype=float32), -0.91015047]. 
=============================================
[2019-04-24 10:39:33,074] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:33,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:33,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:33,556] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run10
[2019-04-24 10:39:33,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:33,833] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:33,850] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run10
[2019-04-24 10:39:35,564] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:35,803] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:35,925] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:36,125] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:36,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:36,565] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:36,569] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run10
[2019-04-24 10:39:36,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:36,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:36,809] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run10
[2019-04-24 10:39:36,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:37,150] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:37,651] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_8 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:39:37,853] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_8 ERROR:Aborted (core dumped)

[2019-04-24 10:39:37,867] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:37,868] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:37,872] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run10
[2019-04-24 10:39:38,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:39:38,657] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:39:38,661] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run10
[2019-04-24 10:39:43,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.2891390e-01 1.4287019e-02 4.1242828e-18 6.4886049e-18 1.0660829e-17
 2.7653852e-19 4.7095730e-19 8.4307321e-20 2.0602279e-16 2.5679910e-01
 1.6109933e-19], sum to 1.0000
[2019-04-24 10:39:43,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2570
[2019-04-24 10:39:43,160] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 0.0, 0.0, 19.0, 20.25008185787557, -0.7555989017601527, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 26400.0000, 
sim time next is 27600.0000, 
raw observation next is [7.699999999999999, 93.0, 0.0, 0.0, 19.0, 20.06716584905429, -0.7855710137574871, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.6759002770083103, 0.93, 0.0, 0.0, 0.08333333333333333, 0.17226382075452426, 0.23814299541417097, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02362959], dtype=float32), -1.6634905]. 
=============================================
[2019-04-24 10:39:49,316] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.0604429e-01 5.0524864e-02 4.0499318e-14 2.8987978e-14 8.0729843e-14
 1.8583354e-15 5.0205311e-15 2.8996149e-15 1.8315735e-12 3.4343082e-01
 1.0964295e-15], sum to 1.0000
[2019-04-24 10:39:49,316] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5286
[2019-04-24 10:39:49,347] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 67.0, 0.0, 0.0, 19.0, 20.24737412042151, -0.9696404704693831, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 270000.0000, 
sim time next is 271200.0000, 
raw observation next is [-9.100000000000001, 68.0, 0.0, 0.0, 19.0, 19.29399622886847, -1.131195045156134, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.21052631578947364, 0.68, 0.0, 0.0, 0.08333333333333333, 0.10783301907237242, 0.12293498494795536, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.78057206], dtype=float32), -1.6399845]. 
=============================================
[2019-04-24 10:39:53,568] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [6.6105986e-01 1.1247624e-02 4.3059721e-13 1.3697486e-12 1.3511130e-12
 2.0706071e-14 5.1039654e-14 6.9064946e-14 6.7499270e-11 3.2769245e-01
 5.3480017e-14], sum to 1.0000
[2019-04-24 10:39:53,568] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3435
[2019-04-24 10:39:53,700] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.46666666666667, 65.33333333333334, 0.0, 0.0, 22.5, 21.60108595513877, -0.6975663922788241, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 328800.0000, 
sim time next is 330000.0000, 
raw observation next is [-12.63333333333333, 67.66666666666667, 0.0, 0.0, 22.5, 20.56708954131445, -0.8495710626991314, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.11265004616805181, 0.6766666666666667, 0.0, 0.0, 0.375, 0.2139241284428707, 0.2168096457669562, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25260463], dtype=float32), -0.04304062]. 
=============================================
[2019-04-24 10:39:53,710] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[60.10315 ]
 [60.307392]
 [60.789894]
 [59.585   ]
 [59.72126 ]
 [60.00236 ]
 [59.134975]
 [60.035187]
 [60.755283]
 [61.39761 ]
 [61.042862]
 [61.540787]
 [60.8797  ]
 [61.332405]
 [61.732258]
 [62.150673]
 [62.68024 ]
 [61.74228 ]
 [62.33337 ]
 [62.97517 ]
 [63.58442 ]
 [64.22361 ]
 [64.726326]
 [65.32305 ]
 [65.634796]], R is [[59.14896774]
 [58.58166885]
 [58.99583435]
 [58.40587616]
 [58.42041016]
 [58.83620834]
 [58.24784851]
 [58.40446472]
 [58.77039719]
 [59.18269348]
 [58.59086609]
 [59.00495911]
 [58.41490936]
 [58.70425415]
 [58.85797882]
 [59.26939774]
 [59.67670441]
 [59.07993698]
 [58.48913956]
 [57.90424728]
 [57.32520676]
 [56.75195694]
 [56.98353195]
 [57.40766144]
 [57.83358383]].
[2019-04-24 10:39:54,255] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.1311327e-01 1.1273359e-02 2.9597306e-14 6.3587543e-14 9.7518063e-14
 1.7134991e-15 4.6494121e-15 1.4180284e-15 2.0796028e-12 1.7561345e-01
 4.6473195e-15], sum to 1.0000
[2019-04-24 10:39:54,259] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.5605
[2019-04-24 10:39:54,275] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 74.0, 0.0, 0.0, 19.0, 20.05582340720056, -0.7004802255500627, 0.0, 1.0, 60.0, 95.44305509046663], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 178800.0000, 
sim time next is 180000.0000, 
raw observation next is [-8.9, 74.0, 0.0, 0.0, 19.0, 20.71389454319752, -0.838582732263788, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.21606648199445982, 0.74, 0.0, 0.0, 0.08333333333333333, 0.22615787859979322, 0.22047242257873734, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5289822], dtype=float32), 0.021798795]. 
=============================================
[2019-04-24 10:39:54,283] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[67.187164]
 [66.42366 ]
 [66.745   ]
 [67.124825]
 [66.23787 ]
 [66.141785]
 [66.66328 ]
 [66.288605]
 [65.82965 ]
 [65.713776]
 [64.49168 ]
 [64.85542 ]
 [65.04421 ]
 [65.47949 ]
 [65.696754]
 [66.06194 ]
 [67.07443 ]
 [68.09513 ]
 [68.70383 ]
 [68.30414 ]
 [68.73878 ]
 [68.19941 ]
 [68.53199 ]
 [67.69123 ]
 [67.99249 ]], R is [[67.11615753]
 [66.44499969]
 [66.7805481 ]
 [67.11273956]
 [66.44161224]
 [66.77719879]
 [67.10942841]
 [66.4383316 ]
 [65.93302155]
 [66.27368927]
 [65.61095428]
 [65.95484161]
 [66.29529572]
 [66.63234711]
 [66.96602631]
 [67.29636383]
 [67.62339783]
 [67.94716644]
 [68.26769257]
 [67.58501434]
 [67.90916443]
 [67.23007202]
 [67.55776978]
 [66.88219452]
 [67.21183014]].
[2019-04-24 10:39:59,376] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3816289e-01 6.5484241e-02 1.9710817e-12 1.0562299e-12 1.2701404e-12
 1.9840977e-13 2.4721382e-13 1.5737201e-13 4.3023262e-11 6.9635290e-01
 9.4253130e-14], sum to 1.0000
[2019-04-24 10:39:59,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0951
[2019-04-24 10:39:59,482] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.6, 90.0, 32.0, 607.5, 22.5, 21.21741138066071, -0.7665152997749374, 1.0, 1.0, 20.0, 60.536402675217644], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 378000.0000, 
sim time next is 379200.0000, 
raw observation next is [-15.23333333333333, 82.0, 36.66666666666666, 694.5, 22.5, 21.11635264689914, -0.9235916591563926, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.04062788550323182, 0.82, 0.12222222222222219, 0.7674033149171271, 0.375, 0.2596960539082618, 0.19213611361453578, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1194803], dtype=float32), 1.3339242]. 
=============================================
[2019-04-24 10:40:09,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9540865e-01 2.5385018e-02 1.0676532e-12 2.1615329e-12 1.1249512e-12
 1.9757726e-14 7.6726663e-14 3.0519540e-13 7.5189389e-11 4.7920632e-01
 7.7573961e-14], sum to 1.0000
[2019-04-24 10:40:09,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2026
[2019-04-24 10:40:09,771] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-14.13333333333333, 64.0, 65.66666666666667, 730.5, 22.5, 21.96470251295042, -0.6782910304808389, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 382800.0000, 
sim time next is 384000.0000, 
raw observation next is [-13.76666666666667, 62.0, 68.83333333333334, 734.8333333333333, 22.5, 21.5345295559037, -0.7389339394789524, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.08125577100646345, 0.62, 0.22944444444444448, 0.8119705340699815, 0.375, 0.2945441296586416, 0.25368868684034923, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06432429], dtype=float32), 0.48137623]. 
=============================================
[2019-04-24 10:40:12,798] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.2241794e-01 1.8835764e-02 2.4818599e-15 4.8361881e-14 5.1221014e-14
 3.0422306e-15 4.5728044e-15 9.0709934e-16 2.1405453e-12 5.8746323e-02
 2.0330446e-14], sum to 1.0000
[2019-04-24 10:40:12,801] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2889
[2019-04-24 10:40:12,846] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 57.0, 13.5, 8.5, 19.0, 20.19603462829378, -0.7857031415768367, 0.0, 1.0, 60.0, 82.50683480060977], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 666000.0000, 
sim time next is 667200.0000, 
raw observation next is [-1.2, 57.00000000000001, 0.0, 0.0, 19.0, 20.53983015390393, -0.9212729867470105, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.5700000000000001, 0.0, 0.0, 0.08333333333333333, 0.21165251282532763, 0.19290900441766315, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.82838905], dtype=float32), 1.6544648]. 
=============================================
[2019-04-24 10:40:13,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3349806e-01 4.6239320e-02 1.7900271e-15 9.9462607e-15 2.0578040e-14
 9.2043989e-16 7.6713715e-16 2.4277746e-16 3.0599045e-13 1.2026267e-01
 7.0801504e-16], sum to 1.0000
[2019-04-24 10:40:13,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7320
[2019-04-24 10:40:13,132] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.2, 75.0, 0.0, 0.0, 19.0, 20.51618314362467, -0.960490155886775, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 703200.0000, 
sim time next is 704400.0000, 
raw observation next is [-3.0, 75.0, 0.0, 0.0, 19.0, 19.70469306235697, -1.122703289725683, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.3795013850415513, 0.75, 0.0, 0.0, 0.08333333333333333, 0.14205775519641417, 0.125765570091439, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3720983], dtype=float32), 0.3210296]. 
=============================================
[2019-04-24 10:40:15,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8673234e-01 2.2191834e-02 6.5406732e-14 3.2541651e-13 2.5248317e-13
 2.5432938e-14 5.2895497e-14 1.2559182e-14 7.2759485e-12 5.9107584e-01
 2.0024779e-14], sum to 1.0000
[2019-04-24 10:40:15,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8341
[2019-04-24 10:40:15,450] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.0, 71.0, 152.0, 40.5, 19.0, 19.60887252059728, -1.08357073455145, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1857600.0000, 
sim time next is 1858800.0000, 
raw observation next is [-4.833333333333334, 71.0, 130.6666666666667, 13.5, 19.0, 19.42632344031765, -0.9271234075372501, 0.0, 1.0, 60.0, 84.56318818088266], 
processed observation next is [0.0, 0.5217391304347826, 0.32871652816251157, 0.71, 0.4355555555555557, 0.014917127071823204, 0.08333333333333333, 0.11886028669313742, 0.19095886415424998, 0.0, 1.0, 0.9, 0.8456318818088266], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.51489997], dtype=float32), -0.24597234]. 
=============================================
[2019-04-24 10:40:16,337] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.5785273e-01 6.1529865e-03 7.5852698e-15 1.3445488e-14 9.5129356e-15
 9.4767105e-16 3.9519426e-16 2.4361615e-16 3.5660277e-13 2.3599434e-01
 1.8504244e-15], sum to 1.0000
[2019-04-24 10:40:16,339] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9187
[2019-04-24 10:40:16,477] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.2, 83.0, 70.5, 59.0, 19.0, 20.51929231642369, -0.8085760920752493, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 576000.0000, 
sim time next is 577200.0000, 
raw observation next is [-1.366666666666667, 84.33333333333334, 50.83333333333334, 49.66666666666666, 19.0, 20.56868190181363, -0.5779001269650205, 0.0, 1.0, 60.0, 87.88234425014134], 
processed observation next is [0.0, 0.6956521739130435, 0.42474607571560485, 0.8433333333333334, 0.16944444444444448, 0.05488029465930017, 0.08333333333333333, 0.2140568251511358, 0.3073666243449932, 0.0, 1.0, 0.9, 0.8788234425014134], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60198796], dtype=float32), 1.2409248]. 
=============================================
[2019-04-24 10:40:17,028] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3784019e-01 5.3051189e-02 1.5725500e-13 3.0115643e-13 2.6824571e-13
 1.5900696e-14 7.6339712e-14 7.7916943e-15 9.9133809e-12 4.0910870e-01
 5.2822323e-14], sum to 1.0000
[2019-04-24 10:40:17,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9843
[2019-04-24 10:40:17,105] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.8, 71.0, 0.0, 0.0, 19.0, 19.43692077353449, -1.092478843053448, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 784800.0000, 
sim time next is 786000.0000, 
raw observation next is [-7.8, 72.0, 0.0, 0.0, 19.0, 19.42294424082467, -0.8522454274374494, 0.0, 1.0, 60.0, 94.73077193013569], 
processed observation next is [1.0, 0.08695652173913043, 0.24653739612188366, 0.72, 0.0, 0.0, 0.08333333333333333, 0.11857868673538914, 0.21591819085418354, 0.0, 1.0, 0.9, 0.9473077193013569], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3805943], dtype=float32), -0.71574605]. 
=============================================
[2019-04-24 10:40:20,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5829575e-01 2.8327679e-02 3.0588033e-16 7.1689676e-16 1.0982028e-15
 2.6917018e-17 3.8029228e-17 2.8799746e-17 3.1148197e-14 3.1337664e-01
 3.7814985e-17], sum to 1.0000
[2019-04-24 10:40:20,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1547
[2019-04-24 10:40:20,246] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 20.62019484317128, -0.6225321131775434, 0.0, 1.0, 60.0, 87.10099738195002], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 885600.0000, 
sim time next is 886800.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 21.22011749848268, -0.7432425558497099, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.2683431248735566, 0.25225248138343004, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2471969], dtype=float32), 0.9631511]. 
=============================================
[2019-04-24 10:40:20,807] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.6731787e-01 1.7129013e-02 8.7728571e-14 1.2538886e-13 2.4895916e-13
 3.5768213e-14 4.5999706e-14 6.9816801e-15 2.2153039e-12 3.1555310e-01
 2.1114458e-14], sum to 1.0000
[2019-04-24 10:40:20,811] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4538
[2019-04-24 10:40:20,821] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 57.0, 13.5, 8.5, 19.0, 19.48749543421001, -1.13421395759088, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 666000.0000, 
sim time next is 667200.0000, 
raw observation next is [-1.2, 57.00000000000001, 0.0, 0.0, 19.0, 18.9845137104805, -1.209516139061486, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.42936288088642666, 0.5700000000000001, 0.0, 0.0, 0.08333333333333333, 0.08204280920670826, 0.09682795364617136, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9990, 
noisyNet noise sample is [array([1.1872442], dtype=float32), -1.0888755]. 
=============================================
[2019-04-24 10:40:25,442] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.8230147e-01 5.0642696e-04 1.7582928e-20 1.5967554e-18 1.1596597e-18
 1.2586389e-20 8.8466159e-21 9.5688302e-21 1.3278546e-16 1.7192099e-02
 1.6014142e-20], sum to 1.0000
[2019-04-24 10:40:25,443] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6626
[2019-04-24 10:40:25,458] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 19.0, 22.07828041078528, -0.1819618666324166, 0.0, 1.0, 60.0, 87.59265910675008], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 950400.0000, 
sim time next is 951600.0000, 
raw observation next is [5.166666666666667, 93.66666666666666, 0.0, 0.0, 19.0, 22.82554081176804, -0.2588317235179876, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.6057248384118191, 0.9366666666666665, 0.0, 0.0, 0.08333333333333333, 0.40212840098067, 0.4137227588273375, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.47214037], dtype=float32), -1.6487163]. 
=============================================
[2019-04-24 10:40:28,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.70597386e-01 6.81080390e-04 1.17486414e-19 1.48334505e-18
 1.95423591e-18 1.02745065e-20 4.85226215e-20 1.11787264e-20
 3.34319378e-16 2.87216436e-02 1.50872225e-19], sum to 1.0000
[2019-04-24 10:40:28,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2287
[2019-04-24 10:40:28,151] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.0, 0.0, 0.0, 19.0, 21.51339169540424, -0.2733543679087131, 0.0, 1.0, 60.0, 93.54081089896175], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 943200.0000, 
sim time next is 944400.0000, 
raw observation next is [5.0, 96.0, 0.0, 0.0, 19.0, 22.45956122344304, -0.3578281959818548, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.6011080332409973, 0.96, 0.0, 0.0, 0.08333333333333333, 0.3716301019535866, 0.3807239346727151, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7163257], dtype=float32), 1.7172176]. 
=============================================
[2019-04-24 10:40:30,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0074035e-01 1.4583643e-02 2.6371780e-15 1.3013615e-14 8.2666892e-15
 1.1467084e-16 5.0411547e-16 6.1216633e-16 1.3726163e-12 4.8467600e-01
 1.1802110e-15], sum to 1.0000
[2019-04-24 10:40:30,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7804
[2019-04-24 10:40:30,859] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.1, 79.0, 85.66666666666667, 0.0, 22.5, 22.81203005774408, -0.4430609688164992, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 826800.0000, 
sim time next is 828000.0000, 
raw observation next is [-3.9, 79.0, 75.0, 0.0, 22.5, 23.06730006273677, -0.2939849646687919, 1.0, 1.0, 60.0, 89.18347024075317], 
processed observation next is [1.0, 0.6086956521739131, 0.3545706371191136, 0.79, 0.25, 0.0, 0.375, 0.42227500522806416, 0.4020050117770693, 1.0, 1.0, 0.9, 0.8918347024075317], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1236589], dtype=float32), -1.5854]. 
=============================================
[2019-04-24 10:40:32,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7415836e-01 4.2470610e-03 1.5179836e-17 3.9688665e-17 9.1830131e-17
 2.6068282e-19 2.8807351e-18 5.1310009e-18 1.0456940e-14 2.2159457e-01
 1.6817801e-18], sum to 1.0000
[2019-04-24 10:40:32,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1459
[2019-04-24 10:40:32,489] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 22.5, 22.23817866323188, -0.2731828648079433, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1362000.0000, 
sim time next is 1363200.0000, 
raw observation next is [0.5, 96.0, 0.0, 0.0, 22.5, 21.89245788380237, -0.3340405229233663, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4764542936288089, 0.96, 0.0, 0.0, 0.375, 0.324371490316864, 0.3886531590255446, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0649078], dtype=float32), 0.05923742]. 
=============================================
[2019-04-24 10:40:32,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8930625e-01 1.0656307e-02 1.0269448e-15 2.6137664e-15 1.5003245e-15
 3.5151517e-17 9.3920813e-17 1.4118451e-16 4.7307947e-13 1.0003751e-01
 1.2037977e-16], sum to 1.0000
[2019-04-24 10:40:32,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9954
[2019-04-24 10:40:32,764] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-3.899999999999999, 83.66666666666666, 57.33333333333334, 0.0, 22.5, 23.02826389357002, -0.3654735183632503, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 830400.0000, 
sim time next is 831600.0000, 
raw observation next is [-3.9, 86.0, 54.0, 0.0, 22.5, 23.41148941066616, -0.2843830299980255, 1.0, 1.0, 60.0, 81.15962531679511], 
processed observation next is [1.0, 0.6521739130434783, 0.3545706371191136, 0.86, 0.18, 0.0, 0.375, 0.4509574508888467, 0.40520565666732483, 1.0, 1.0, 0.9, 0.8115962531679511], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18462718], dtype=float32), -0.34425804]. 
=============================================
[2019-04-24 10:40:34,447] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3591250e-01 9.2809349e-03 1.5956613e-17 4.7558303e-17 3.4574763e-17
 1.2280130e-18 3.5260439e-18 1.7728437e-18 5.0400154e-15 2.5480646e-01
 2.3645481e-18], sum to 1.0000
[2019-04-24 10:40:34,457] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6977
[2019-04-24 10:40:34,485] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.7, 97.0, 100.5, 0.0, 22.5, 22.48092238588811, -0.5332728802997452, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 907200.0000, 
sim time next is 908400.0000, 
raw observation next is [3.066666666666667, 95.66666666666667, 102.8333333333333, 0.0, 22.5, 21.59025311770449, -0.5722960087008363, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5475530932594646, 0.9566666666666667, 0.3427777777777777, 0.0, 0.375, 0.2991877598087074, 0.3092346637663879, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8693, 
noisyNet noise sample is [array([1.1667835], dtype=float32), -0.10775664]. 
=============================================
[2019-04-24 10:40:35,516] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.6774465e-01 4.5014540e-04 1.4228993e-21 8.7687405e-21 2.0460860e-20
 2.9140667e-23 1.5537014e-22 9.4521169e-23 1.8761927e-18 3.1805169e-02
 2.2334417e-22], sum to 1.0000
[2019-04-24 10:40:35,516] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.9202
[2019-04-24 10:40:35,543] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.76666666666667, 80.0, 0.0, 0.0, 22.5, 24.73507213084761, 0.1467824225134735, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1014000.0000, 
sim time next is 1015200.0000, 
raw observation next is [14.4, 81.0, 0.0, 0.0, 22.5, 24.44596712321303, 0.05188691604531465, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.8614958448753465, 0.81, 0.0, 0.0, 0.375, 0.5371639269344192, 0.5172956386817715, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.78064764], dtype=float32), 0.55277586]. 
=============================================
[2019-04-24 10:40:35,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8314500e-01 5.6002714e-04 1.1882897e-16 7.5834892e-16 3.9371917e-15
 1.2756368e-16 2.0403912e-16 1.8343390e-17 3.7031691e-14 1.6295077e-02
 3.9340072e-16], sum to 1.0000
[2019-04-24 10:40:35,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0087
[2019-04-24 10:40:35,842] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.1, 78.66666666666667, 0.0, 0.0, 19.0, 22.19902873603677, -0.193927952491724, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1210800.0000, 
sim time next is 1212000.0000, 
raw observation next is [16.1, 79.33333333333333, 0.0, 0.0, 19.0, 22.19410271194904, -0.189055228681164, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.0, 0.9085872576177286, 0.7933333333333333, 0.0, 0.0, 0.08333333333333333, 0.3495085593290866, 0.436981590439612, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39273944], dtype=float32), 1.0865211]. 
=============================================
[2019-04-24 10:40:36,222] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8994422e-01 1.8775978e-03 9.7121135e-17 4.9615813e-16 6.3378303e-16
 5.1305126e-17 4.4420704e-17 4.2470836e-18 2.2965159e-14 8.1782592e-03
 4.1465505e-17], sum to 1.0000
[2019-04-24 10:40:36,222] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2047
[2019-04-24 10:40:36,230] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 63.66666666666667, 169.1666666666667, 0.0, 19.0, 22.71789724700373, -0.1009364027721033, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1167600.0000, 
sim time next is 1168800.0000, 
raw observation next is [18.46666666666667, 64.33333333333333, 169.0, 0.0, 19.0, 22.70427907827439, -0.09829027598530136, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.9741458910433982, 0.6433333333333333, 0.5633333333333334, 0.0, 0.08333333333333333, 0.3920232565228658, 0.46723657467156626, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3198783], dtype=float32), 1.3087547]. 
=============================================
[2019-04-24 10:40:38,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.79184389e-01 1.29746506e-03 6.13975416e-21 4.93081596e-21
 5.58189555e-20 1.04655595e-22 7.84154599e-22 5.57346133e-23
 1.01661345e-18 1.95181966e-02 1.02203617e-21], sum to 1.0000
[2019-04-24 10:40:38,143] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5801
[2019-04-24 10:40:38,153] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.8, 100.0, 45.66666666666666, 0.0, 19.0, 23.46461602594713, 0.0360076268818408, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1266000.0000, 
sim time next is 1267200.0000, 
raw observation next is [13.8, 100.0, 35.0, 0.0, 19.0, 23.11452690953232, -0.03986781845838231, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.844875346260388, 1.0, 0.11666666666666667, 0.0, 0.08333333333333333, 0.42621057579435995, 0.48671072718053926, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2731189], dtype=float32), 0.39233744]. 
=============================================
[2019-04-24 10:40:38,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1238695e-01 1.9680632e-03 7.3041946e-21 2.1402072e-20 4.5298336e-20
 1.8512182e-22 1.7589416e-21 7.4658295e-23 8.1148362e-18 8.5644923e-02
 4.6986838e-22], sum to 1.0000
[2019-04-24 10:40:38,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9319
[2019-04-24 10:40:38,385] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [14.0, 77.66666666666667, 0.0, 0.0, 19.0, 22.56195681345979, -0.2337406550127854, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1045200.0000, 
sim time next is 1046400.0000, 
raw observation next is [14.2, 77.33333333333333, 0.0, 0.0, 19.0, 22.91911489771083, 0.03428680230329998, 0.0, 1.0, 60.0, 86.02408617974805], 
processed observation next is [1.0, 0.08695652173913043, 0.8559556786703602, 0.7733333333333333, 0.0, 0.0, 0.08333333333333333, 0.40992624147590256, 0.5114289341011, 0.0, 1.0, 0.9, 0.8602408617974805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4725591], dtype=float32), -0.51197314]. 
=============================================
[2019-04-24 10:40:39,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4358448e-01 1.2176670e-02 7.8557186e-18 1.5161135e-17 2.6641633e-17
 7.4959469e-19 2.4510569e-18 7.9624876e-19 1.1720099e-15 1.4423883e-01
 2.3134017e-18], sum to 1.0000
[2019-04-24 10:40:39,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2106
[2019-04-24 10:40:39,345] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 19.0, 21.62405327942759, -0.4682947970052228, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1470000.0000, 
sim time next is 1471200.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 19.0, 21.5137650624506, -0.495750925030829, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5069252077562327, 0.92, 0.0, 0.0, 0.08333333333333333, 0.29281375520421654, 0.33474969165639035, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01999331], dtype=float32), -0.16753402]. 
=============================================
[2019-04-24 10:40:40,128] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.5507509e-01 1.4951944e-03 3.1330339e-19 1.5612940e-18 9.4582819e-19
 9.7443750e-21 7.0110908e-21 7.4392198e-21 1.5907477e-16 4.3429606e-02
 3.8004681e-20], sum to 1.0000
[2019-04-24 10:40:40,128] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2054
[2019-04-24 10:40:40,145] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [8.133333333333333, 69.66666666666667, 87.5, 700.8333333333334, 22.5, 22.88010957028028, -0.106741718456904, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1516800.0000, 
sim time next is 1518000.0000, 
raw observation next is [9.066666666666666, 66.33333333333334, 83.33333333333334, 694.6666666666667, 22.5, 23.61638152117424, -0.02833165077160492, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.713758079409049, 0.6633333333333334, 0.2777777777777778, 0.7675874769797423, 0.375, 0.46803179343118667, 0.490556116409465, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3576363], dtype=float32), 0.77661544]. 
=============================================
[2019-04-24 10:40:40,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2255855e-01 4.4241040e-03 4.1580053e-19 3.3441369e-19 3.0391286e-18
 1.6870632e-19 1.2622416e-19 3.6924674e-20 6.0921793e-17 7.3017389e-02
 1.4560991e-19], sum to 1.0000
[2019-04-24 10:40:40,795] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5567
[2019-04-24 10:40:40,802] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.1, 77.0, 0.0, 0.0, 19.0, 21.75682529277298, -0.3102638202172996, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1134000.0000, 
sim time next is 1135200.0000, 
raw observation next is [11.1, 77.0, 0.0, 0.0, 19.0, 21.68762747149805, -0.3253225384475152, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.7700831024930749, 0.77, 0.0, 0.0, 0.08333333333333333, 0.3073022892915042, 0.3915591538508283, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.31451538], dtype=float32), -0.52437234]. 
=============================================
[2019-04-24 10:40:54,557] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4561300e-01 5.5586405e-02 3.1426142e-14 1.5655245e-13 1.2174982e-13
 9.8860722e-15 3.9614382e-14 5.4772970e-15 5.3173598e-12 9.8800480e-02
 4.1169189e-14], sum to 1.0000
[2019-04-24 10:40:54,564] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2288
[2019-04-24 10:40:54,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 81.66666666666667, 0.0, 0.0, 19.0, 18.19965267621442, -1.097511742418455, 0.0, 1.0, 60.0, 104.20022664339061], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1830000.0000, 
sim time next is 1831200.0000, 
raw observation next is [-6.199999999999999, 80.33333333333334, 0.0, 0.0, 19.0, 19.06349727215411, -1.212492049029636, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2908587257617729, 0.8033333333333335, 0.0, 0.0, 0.08333333333333333, 0.08862477267950908, 0.09583598365678798, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0426698], dtype=float32), -0.95753103]. 
=============================================
[2019-04-24 10:40:55,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.45876539e-01 5.08566126e-02 1.54222101e-14 1.49896304e-14
 1.07000675e-14 2.13516479e-16 1.13205521e-14 1.31289080e-15
 1.40649883e-12 5.03266871e-01 4.27130075e-16], sum to 1.0000
[2019-04-24 10:40:55,303] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6932
[2019-04-24 10:40:55,508] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.6, 83.0, 96.5, 0.0, 22.5, 20.80436533059613, -0.8987612100200475, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2024400.0000, 
sim time next is 2025600.0000, 
raw observation next is [-5.6, 83.0, 109.5, 0.0, 22.5, 21.45450568997382, -0.5232660355146169, 1.0, 1.0, 60.0, 116.62389183105014], 
processed observation next is [1.0, 0.43478260869565216, 0.30747922437673136, 0.83, 0.365, 0.0, 0.375, 0.2878754741644851, 0.32557798816179434, 1.0, 1.0, 0.9, 1.1662389183105015], 
reward next is 0.1163, 
noisyNet noise sample is [array([-0.31310952], dtype=float32), 0.589552]. 
=============================================
[2019-04-24 10:40:59,632] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4943362e-01 3.4647041e-03 3.8639483e-16 5.0783500e-15 1.5353617e-15
 1.9369053e-17 2.6680484e-16 1.3500808e-16 4.2470435e-13 4.7101669e-02
 2.0592479e-16], sum to 1.0000
[2019-04-24 10:40:59,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1741
[2019-04-24 10:40:59,703] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.233333333333333, 80.33333333333334, 139.5, 0.0, 22.5, 21.71701951458464, -0.3714151178486104, 1.0, 1.0, 60.0, 121.95640572774818], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2028000.0000, 
sim time next is 2029200.0000, 
raw observation next is [-4.866666666666667, 77.66666666666667, 148.5, 0.0, 22.5, 22.97852072064633, -0.4709184829506535, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3277931671283472, 0.7766666666666667, 0.495, 0.0, 0.375, 0.4148767267205275, 0.3430271723497822, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.51095706], dtype=float32), 0.8776183]. 
=============================================
[2019-04-24 10:41:01,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6751797e-01 2.3375938e-03 7.4700418e-16 6.2881778e-15 3.1200308e-15
 1.3031488e-17 1.3900347e-16 7.5306662e-17 1.7230759e-13 3.0144546e-02
 2.8158205e-16], sum to 1.0000
[2019-04-24 10:41:01,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4820
[2019-04-24 10:41:01,562] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 73.66666666666666, 0.0, 0.0, 22.5, 22.65557919485311, -0.3670463683842585, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1968000.0000, 
sim time next is 1969200.0000, 
raw observation next is [-4.5, 71.0, 0.0, 0.0, 22.5, 22.26608516247946, -0.4651295791933299, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3379501385041552, 0.71, 0.0, 0.0, 0.375, 0.3555070968732883, 0.3449568069355567, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.781114], dtype=float32), -0.97192794]. 
=============================================
[2019-04-24 10:41:09,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2238241e-01 4.2041359e-03 4.5156330e-15 9.4030262e-15 1.0484473e-14
 2.5040250e-16 1.3818001e-15 3.7061058e-16 6.2200077e-13 7.3413342e-02
 1.2821311e-15], sum to 1.0000
[2019-04-24 10:41:09,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5018
[2019-04-24 10:41:09,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.333333333333334, 83.0, 0.0, 0.0, 19.0, 21.61060226683012, -0.5867496781608557, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2151600.0000, 
sim time next is 2152800.0000, 
raw observation next is [-6.7, 83.0, 0.0, 0.0, 19.0, 20.98842508085414, -0.682717732335771, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2770083102493075, 0.83, 0.0, 0.0, 0.08333333333333333, 0.24903542340451157, 0.272427422554743, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0758736], dtype=float32), -0.5373928]. 
=============================================
[2019-04-24 10:41:13,883] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.6393088e-01 4.3247920e-03 3.7903818e-15 1.3334156e-14 1.7760495e-14
 1.3765287e-16 3.5421179e-16 4.7532583e-16 1.8048563e-12 1.3174434e-01
 1.2259603e-15], sum to 1.0000
[2019-04-24 10:41:13,884] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3118
[2019-04-24 10:41:13,973] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 70.0, 0.0, 0.0, 19.0, 22.99899892735848, -0.2041653496054641, 0.0, 1.0, 20.0, 50.58201792039982], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2233200.0000, 
sim time next is 2234400.0000, 
raw observation next is [-5.0, 69.0, 0.0, 0.0, 19.0, 22.73692997262209, -0.3927236986606614, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.32409972299168976, 0.69, 0.0, 0.0, 0.08333333333333333, 0.3947441643851741, 0.3690921004464462, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.487348], dtype=float32), -0.5381753]. 
=============================================
[2019-04-24 10:41:22,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9200115e-01 3.2407322e-03 8.6775177e-17 2.2326904e-16 1.4438337e-16
 2.5011789e-18 4.8019315e-18 6.1270451e-18 1.3562335e-14 1.0475813e-01
 1.9636634e-17], sum to 1.0000
[2019-04-24 10:41:22,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4322
[2019-04-24 10:41:22,188] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 113.6666666666667, 807.8333333333334, 22.5, 23.27442235349196, -0.1841432829942296, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3417600.0000, 
sim time next is 3418800.0000, 
raw observation next is [3.0, 49.0, 111.3333333333333, 800.8333333333334, 22.5, 23.25766139738347, -0.2147834963555048, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5457063711911359, 0.49, 0.371111111111111, 0.8848987108655617, 0.375, 0.43813844978195576, 0.42840550121483173, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.296732], dtype=float32), 1.6284465]. 
=============================================
[2019-04-24 10:41:22,193] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [1.7313121e-01 7.4049667e-02 1.6938692e-11 5.1336734e-12 6.9696011e-12
 2.6872460e-12 2.9882032e-12 4.9573843e-13 1.4424825e-10 7.5281912e-01
 1.6052769e-12], sum to 1.0000
[2019-04-24 10:41:22,201] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.3342
[2019-04-24 10:41:22,273] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-7.3, 50.0, 50.5, 540.5, 19.0, 18.91688374235917, -1.240756704257572, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2451600.0000, 
sim time next is 2452800.0000, 
raw observation next is [-6.733333333333333, 47.66666666666667, 57.5, 623.5, 19.0, 18.82199166040434, -1.059128277179912, 0.0, 1.0, 60.0, 82.75333131766999], 
processed observation next is [0.0, 0.391304347826087, 0.2760849492151431, 0.47666666666666674, 0.19166666666666668, 0.6889502762430939, 0.08333333333333333, 0.06849930503369499, 0.14695724094002935, 0.0, 1.0, 0.9, 0.8275333131766999], 
reward next is 0.2293, 
noisyNet noise sample is [array([0.01024781], dtype=float32), -0.17037906]. 
=============================================
[2019-04-24 10:41:25,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8968760e-01 2.4469628e-03 8.2266288e-17 1.8495200e-16 2.6628921e-16
 2.9915926e-18 5.1643963e-18 6.2031024e-19 3.0694309e-14 1.0786539e-01
 6.1172174e-18], sum to 1.0000
[2019-04-24 10:41:25,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9656
[2019-04-24 10:41:25,417] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [2.0, 55.33333333333334, 115.8333333333333, 820.8333333333334, 22.5, 23.17390551012233, -0.1559514401300534, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3500400.0000, 
sim time next is 3501600.0000, 
raw observation next is [2.0, 53.66666666666667, 115.8333333333333, 820.1666666666667, 22.5, 23.8000865661209, 0.06355405715141117, 1.0, 1.0, 60.0, 88.32533988507112], 
processed observation next is [1.0, 0.5217391304347826, 0.518005540166205, 0.5366666666666667, 0.386111111111111, 0.9062615101289135, 0.375, 0.48334054717674163, 0.521184685717137, 1.0, 1.0, 0.9, 0.8832533988507112], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29204175], dtype=float32), -0.18122903]. 
=============================================
[2019-04-24 10:41:30,772] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [4.2040804e-01 5.3687889e-02 6.6512481e-12 2.8643951e-12 5.5170031e-12
 1.4509681e-12 2.4281447e-12 1.9976829e-13 5.7597916e-11 5.2590412e-01
 3.4205707e-12], sum to 1.0000
[2019-04-24 10:41:30,773] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1269
[2019-04-24 10:41:30,853] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 43.0, 68.5, 721.0, 19.0, 19.95320961722831, -1.048487296592294, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2455200.0000, 
sim time next is 2456400.0000, 
raw observation next is [-4.5, 40.66666666666667, 73.5, 758.3333333333333, 19.0, 19.38957336247635, -1.116868709041807, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.3379501385041552, 0.40666666666666673, 0.245, 0.8379373848987108, 0.08333333333333333, 0.11579778020636262, 0.12771043031939766, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8137455], dtype=float32), 1.088969]. 
=============================================
[2019-04-24 10:41:31,696] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.7545854e-01 1.0241781e-02 3.8784900e-14 1.5543061e-13 1.3450807e-13
 1.5291342e-14 8.3350981e-15 2.3778102e-15 3.3444148e-12 1.1429969e-01
 2.1005175e-14], sum to 1.0000
[2019-04-24 10:41:31,706] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8304
[2019-04-24 10:41:31,806] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.566666666666667, 26.0, 13.0, 82.33333333333333, 19.0, 22.02702415110562, -0.628948843897121, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2481600.0000, 
sim time next is 2482800.0000, 
raw observation next is [1.833333333333333, 27.0, 0.0, 0.0, 19.0, 21.19939193583419, -0.7855504437466454, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5133887349953832, 0.27, 0.0, 0.0, 0.08333333333333333, 0.2666159946528491, 0.23814985208445152, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.17153491], dtype=float32), 0.634539]. 
=============================================
[2019-04-24 10:41:34,454] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8155767e-01 1.2540533e-03 9.8958025e-17 4.6599047e-15 6.7946696e-16
 1.3632505e-17 1.5976970e-17 1.6764622e-17 2.8808371e-13 1.7188324e-02
 1.7498883e-16], sum to 1.0000
[2019-04-24 10:41:34,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4389
[2019-04-24 10:41:34,489] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1333333333333333, 44.33333333333333, 172.6666666666667, 197.5, 22.5, 23.37712018635074, -0.02273736168947421, 1.0, 1.0, 60.0, 90.2337447465363], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2641200.0000, 
sim time next is 2642400.0000, 
raw observation next is [0.5, 43.0, 190.0, 170.5, 22.5, 24.35594084407947, -0.1863650623961613, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.4764542936288089, 0.43, 0.6333333333333333, 0.18839779005524862, 0.375, 0.5296617370066224, 0.4378783125346129, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2991688], dtype=float32), -0.9111025]. 
=============================================
[2019-04-24 10:41:34,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5442442e-01 3.7790164e-03 6.8389361e-16 4.5270104e-15 3.7625415e-15
 5.8993304e-17 1.0847342e-16 3.3399786e-17 2.4958621e-13 1.4179654e-01
 1.9773260e-16], sum to 1.0000
[2019-04-24 10:41:34,964] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7622
[2019-04-24 10:41:34,976] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 63.66666666666667, 0.0, 0.0, 19.0, 20.88239493337162, -0.6373898086351667, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2665200.0000, 
sim time next is 2666400.0000, 
raw observation next is [-1.2, 64.33333333333333, 0.0, 0.0, 19.0, 20.66136088252624, -0.6776250188762893, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.42936288088642666, 0.6433333333333333, 0.0, 0.0, 0.08333333333333333, 0.22178007354385323, 0.27412499370790355, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2991688], dtype=float32), -0.9111025]. 
=============================================
[2019-04-24 10:41:37,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9429938e-01 1.7879048e-02 3.0095889e-18 2.3757651e-17 2.0156628e-17
 1.1869181e-19 4.6091083e-19 1.1701007e-18 3.2100446e-15 3.8782153e-01
 1.1862806e-18], sum to 1.0000
[2019-04-24 10:41:37,037] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9608
[2019-04-24 10:41:37,114] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.0, 93.0, 77.0, 78.0, 22.5, 23.07645603573988, -0.4068037010847673, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2883600.0000, 
sim time next is 2884800.0000, 
raw observation next is [0.6666666666666667, 95.33333333333334, 58.33333333333333, 25.99999999999999, 22.5, 22.91650251328536, -0.2139918760139621, 1.0, 1.0, 60.0, 94.86555442020193], 
processed observation next is [1.0, 0.391304347826087, 0.4810710987996307, 0.9533333333333335, 0.19444444444444442, 0.028729281767955788, 0.375, 0.4097085427737799, 0.42866937466201266, 1.0, 1.0, 0.9, 0.9486555442020194], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1784515], dtype=float32), 0.4395909]. 
=============================================
[2019-04-24 10:41:40,029] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.6815649e-01 5.5986200e-03 1.8115828e-15 2.0791620e-15 5.4954435e-15
 2.1985882e-16 1.8557313e-16 1.9449900e-16 3.3500804e-13 1.2624492e-01
 2.3682438e-16], sum to 1.0000
[2019-04-24 10:41:40,030] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2764
[2019-04-24 10:41:40,043] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666667, 70.0, 0.0, 0.0, 19.0, 20.44337310112871, -0.5644832894468347, 0.0, 1.0, 20.0, 82.76675155316397], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2676000.0000, 
sim time next is 2677200.0000, 
raw observation next is [-6.333333333333333, 71.0, 0.0, 0.0, 19.0, 20.96178335098137, -0.6784275839666706, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.28716528162511545, 0.71, 0.0, 0.0, 0.08333333333333333, 0.24681527924844757, 0.2738574720111098, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.29066727], dtype=float32), -1.9093802]. 
=============================================
[2019-04-24 10:41:40,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5484976e-01 2.9876594e-02 3.5076558e-15 1.2129587e-14 1.2110123e-14
 4.9863517e-16 1.6745511e-15 1.6735742e-15 1.1361327e-12 1.1527361e-01
 7.0480765e-16], sum to 1.0000
[2019-04-24 10:41:40,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8881
[2019-04-24 10:41:40,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.4, 76.66666666666667, 0.0, 0.0, 19.0, 21.18703816628269, -0.7423279187630101, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2605200.0000, 
sim time next is 2606400.0000, 
raw observation next is [-5.6, 78.0, 0.0, 0.0, 19.0, 21.03243238596992, -0.5898662146541572, 0.0, 1.0, 60.0, 84.51033547277578], 
processed observation next is [1.0, 0.17391304347826086, 0.30747922437673136, 0.78, 0.0, 0.0, 0.08333333333333333, 0.2527026988308266, 0.3033779284486143, 0.0, 1.0, 0.9, 0.8451033547277578], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05469195], dtype=float32), -2.1183584]. 
=============================================
[2019-04-24 10:41:41,569] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.8794107e-01 1.5234608e-02 3.9782603e-14 1.6867077e-13 7.2369567e-14
 4.7188680e-15 6.1484864e-15 9.6024119e-15 3.3958782e-12 2.9682431e-01
 3.8954152e-15], sum to 1.0000
[2019-04-24 10:41:41,570] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2398
[2019-04-24 10:41:41,628] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.0, 76.0, 107.0, 643.0, 22.5, 23.54924057209648, -0.2815673854656082, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2714400.0000, 
sim time next is 2715600.0000, 
raw observation next is [-11.0, 72.0, 113.6666666666667, 663.6666666666667, 22.5, 23.19012525178833, -0.3595323259638536, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.15789473684210528, 0.72, 0.378888888888889, 0.7333333333333334, 0.375, 0.4325104376490276, 0.38015589134538214, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.15923359], dtype=float32), -0.9841907]. 
=============================================
[2019-04-24 10:41:42,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1474359e-01 4.8891557e-03 4.3744788e-15 6.0329998e-15 5.1542586e-15
 3.7931793e-17 3.5688733e-16 1.1399584e-16 7.0311893e-13 3.8036719e-01
 6.0115400e-16], sum to 1.0000
[2019-04-24 10:41:42,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7341
[2019-04-24 10:41:42,205] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-24 10:41:42,208] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:41:42,209] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:41:42,211] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run14
[2019-04-24 10:41:42,229] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:41:42,232] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:41:42,232] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:41:42,236] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:41:42,239] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run14
[2019-04-24 10:41:42,264] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run14
[2019-04-24 10:41:42,289] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.2333333333333333, 52.66666666666667, 0.0, 0.0, 22.5, 21.88045579486102, -0.4706194706594178, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2655600.0000, 
sim time next is 2656800.0000, 
raw observation next is [-0.6, 54.0, 0.0, 0.0, 22.5, 23.04353163356661, 0.00214829494702686, 1.0, 1.0, 60.0, 120.14507767226675], 
processed observation next is [1.0, 0.782608695652174, 0.44598337950138506, 0.54, 0.0, 0.0, 0.375, 0.4202943027972174, 0.5007160983156757, 1.0, 1.0, 0.9, 1.2014507767226674], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.52573687], dtype=float32), -0.07781278]. 
=============================================
[2019-04-24 10:42:21,949] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.25018528], dtype=float32), 0.6441741]
[2019-04-24 10:42:21,950] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [4.766666666666667, 97.33333333333334, 0.0, 0.0, 19.0, 21.83336329177673, -0.3103037246160696, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:42:21,950] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:42:21,951] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.98852026e-01 7.26535916e-03 5.57082030e-18 1.14609695e-17
 1.92572444e-17 7.43588945e-19 1.08932852e-18 3.19942966e-19
 1.35638128e-15 1.93882555e-01 1.89685170e-18], sampled 0.35401234536715187
[2019-04-24 10:42:30,692] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.25018528], dtype=float32), 0.6441741]
[2019-04-24 10:42:30,692] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [13.3, 51.0, 64.0, 18.5, 22.5, 24.95547282170071, 0.2532958589737869, 1.0, 1.0, 15.0, 0.0]
[2019-04-24 10:42:30,692] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:42:30,693] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [9.4220030e-01 1.3923269e-03 2.0079329e-19 9.6700350e-19 1.3593100e-18
 1.7024398e-20 4.8181015e-20 8.3275011e-21 1.8882826e-16 5.6407399e-02
 7.8112778e-20], sampled 0.29026169663964907
[2019-04-24 10:42:33,971] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.25018528], dtype=float32), 0.6441741]
[2019-04-24 10:42:33,971] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [0.5, 92.0, 0.0, 0.0, 19.0, 20.86269521128504, -0.3720587951794228, 0.0, 1.0, 60.0, 97.1270825754601]
[2019-04-24 10:42:33,971] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:42:33,972] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [9.69616473e-01 2.22141040e-03 2.77056685e-17 2.67701163e-16
 3.33164581e-16 6.28936729e-18 1.83731339e-17 2.94585589e-18
 1.27461035e-14 2.81621329e-02 2.95803063e-17], sampled 0.6788172408517764
[2019-04-24 10:42:35,618] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.25018528], dtype=float32), 0.6441741]
[2019-04-24 10:42:35,619] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-5.0, 86.0, 0.0, 0.0, 19.0, 18.3199122063374, -1.010327416254459, 0.0, 1.0, 60.0, 107.08050109919401]
[2019-04-24 10:42:35,620] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:42:35,622] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [8.1632376e-01 1.3487202e-02 4.5388881e-14 1.1660392e-13 1.5214342e-13
 1.0776774e-14 1.9903883e-14 4.7969822e-15 3.3554622e-12 1.7018898e-01
 2.2144160e-14], sampled 0.13504643993966448
[2019-04-24 10:42:36,098] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:NoisyNet noise sample: [array([-0.25018528], dtype=float32), 0.6441741]
[2019-04-24 10:42:36,098] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation this: [14.56666666666667, 66.33333333333333, 0.0, 0.0, 19.0, 22.88872183457117, -0.07507818907525783, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:42:36,099] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 DEBUG:Observation forecast: []
[2019-04-24 10:42:36,100] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Softmax [9.85710263e-01 8.29063472e-04 6.27394409e-18 4.94235618e-17
 1.53471425e-16 4.33373241e-18 3.59443518e-18 7.05026871e-19
 5.18342405e-15 1.34605905e-02 2.49698464e-17], sampled 0.17771653638128582
[2019-04-24 10:43:49,132] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3445.2300 66566.8964 -91.4919
[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,169] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:49,422] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:43:59,808] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3185.3515 82583.2316 -385.7096
[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:43:59,852] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:00,097] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:15,992] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3171.4537 84830.3426 -432.0537
[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,027] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:16,219] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:44:17,029] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 650000, evaluation results [650000.0, 3185.3514830947292, 82583.23159841626, -385.7095665054983, 3445.2299758238123, 66566.89641858259, -91.49194192847563, 3171.4537381831383, 84830.34256085189, -432.0536701690716]
[2019-04-24 10:44:20,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3071632e-01 5.7388254e-02 6.0349941e-12 1.1047713e-11 8.7505359e-12
 5.4465059e-13 9.7204157e-13 1.8319185e-12 1.8541085e-10 3.1189540e-01
 1.4990031e-12], sum to 1.0000
[2019-04-24 10:44:20,953] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2404
[2019-04-24 10:44:21,047] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 0.0, 0.0, 19.0, 19.60571193136008, -1.100245375616585, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2703600.0000, 
sim time next is 2704800.0000, 
raw observation next is [-15.0, 83.0, 0.0, 0.0, 22.5, 18.76993931292589, -1.227707576431041, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.04709141274238226, 0.83, 0.0, 0.0, 0.375, 0.06416160941049072, 0.090764141189653, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.7883, 
noisyNet noise sample is [array([0.43228474], dtype=float32), -0.3604535]. 
=============================================
[2019-04-24 10:44:21,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7464735e-01 3.5486259e-02 1.6405921e-12 1.6687496e-12 1.6683358e-12
 3.3637830e-14 2.8080180e-13 8.5886715e-14 2.2120595e-11 5.8986640e-01
 5.6591654e-14], sum to 1.0000
[2019-04-24 10:44:21,386] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3919
[2019-04-24 10:44:21,467] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-15.0, 88.33333333333334, 0.0, 0.0, 19.0, 19.88148261955724, -0.9587054658860078, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 2694000.0000, 
sim time next is 2695200.0000, 
raw observation next is [-15.0, 85.66666666666666, 0.0, 0.0, 19.0, 19.53513743074182, -0.9158772181803752, 0.0, 1.0, 20.0, 51.07329612138241], 
processed observation next is [1.0, 0.17391304347826086, 0.04709141274238226, 0.8566666666666666, 0.0, 0.0, 0.08333333333333333, 0.127928119228485, 0.19470759393987494, 0.0, 1.0, 0.1, 0.5107329612138242], 
reward next is 0.3893, 
noisyNet noise sample is [array([-0.83926433], dtype=float32), -0.6658481]. 
=============================================
[2019-04-24 10:44:21,775] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.5711489e-01 3.3251382e-02 4.7495807e-14 1.7338254e-13 1.6451826e-13
 2.9944133e-15 5.2076453e-14 4.6976655e-15 9.5644066e-12 2.0963375e-01
 2.4248444e-14], sum to 1.0000
[2019-04-24 10:44:21,796] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4173
[2019-04-24 10:44:21,833] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 64.0, 0.0, 0.0, 19.0, 20.03851316136438, -1.041748238217878, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2787600.0000, 
sim time next is 2788800.0000, 
raw observation next is [-7.0, 64.0, 0.0, 0.0, 19.0, 18.93928928598779, -1.233099402641324, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2686980609418283, 0.64, 0.0, 0.0, 0.08333333333333333, 0.0782741071656492, 0.08896686578622533, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9853, 
noisyNet noise sample is [array([0.44194564], dtype=float32), -0.5423578]. 
=============================================
[2019-04-24 10:44:26,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6778147e-01 3.6653504e-02 1.1267690e-13 2.3430463e-13 3.9933568e-13
 6.4241052e-14 9.3235146e-14 2.4994065e-14 4.0040211e-12 2.9556504e-01
 5.3903168e-14], sum to 1.0000
[2019-04-24 10:44:26,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8224
[2019-04-24 10:44:26,468] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 20.06009259635439, -1.038843210136543, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3038400.0000, 
sim time next is 3039600.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 19.72485842527303, -0.9029536644741002, 0.0, 1.0, 60.0, 81.13619533777663], 
processed observation next is [0.0, 0.17391304347826086, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.14373820210608587, 0.19901544517529993, 0.0, 1.0, 0.9, 0.8113619533777663], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9546769], dtype=float32), 0.45433393]. 
=============================================
[2019-04-24 10:44:30,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4278698e-01 4.6827003e-02 2.9953697e-14 3.3687551e-14 5.4726304e-14
 1.6382684e-14 1.3313617e-14 7.1829664e-15 1.5633078e-12 3.1038597e-01
 1.7111399e-14], sum to 1.0000
[2019-04-24 10:44:30,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9929
[2019-04-24 10:44:30,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3460541e-01 1.9351907e-02 1.5201384e-17 1.7150489e-16 2.4621638e-16
 4.2695647e-18 2.9239018e-17 4.3737998e-18 7.2647246e-15 3.4604260e-01
 3.0902341e-18], sum to 1.0000
[2019-04-24 10:44:30,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0186
[2019-04-24 10:44:30,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 93.0, 0.0, 0.0, 19.0, 20.50105269844914, -0.8713262794590136, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2869200.0000, 
sim time next is 2870400.0000, 
raw observation next is [1.0, 95.33333333333334, 0.0, 0.0, 19.0, 19.91181189820128, -0.9541852787808106, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.4903047091412743, 0.9533333333333335, 0.0, 0.0, 0.08333333333333333, 0.1593176581834399, 0.18193824040639647, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.06678608], dtype=float32), 0.18150805]. 
=============================================
[2019-04-24 10:44:30,547] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.0, 71.0, 166.0, 78.0, 19.0, 20.1609744583206, -0.9401059693466935, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2973600.0000, 
sim time next is 2974800.0000, 
raw observation next is [-3.666666666666667, 69.0, 174.0, 42.0, 19.0, 20.05025094368155, -0.6901552765760464, 0.0, 1.0, 60.0, 101.00376636026064], 
processed observation next is [0.0, 0.43478260869565216, 0.3610341643582641, 0.69, 0.58, 0.04640883977900553, 0.08333333333333333, 0.1708542453067959, 0.2699482411413179, 0.0, 1.0, 0.9, 1.0100376636026065], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16016446], dtype=float32), -0.39774144]. 
=============================================
[2019-04-24 10:44:41,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9095771e-01 7.0406459e-02 6.3966031e-13 1.7927154e-13 6.7896952e-13
 9.7600144e-14 1.5938052e-13 3.6439357e-14 2.7043600e-11 5.3863585e-01
 1.1062731e-13], sum to 1.0000
[2019-04-24 10:44:41,424] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9165
[2019-04-24 10:44:41,500] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.0, 71.0, 0.0, 0.0, 19.0, 18.59489928079232, -1.241578857532938, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3031200.0000, 
sim time next is 3032400.0000, 
raw observation next is [-5.333333333333334, 73.0, 0.0, 0.0, 19.0, 18.77314920590678, -0.9895324341793802, 0.0, 1.0, 60.0, 93.74270359425478], 
processed observation next is [0.0, 0.08695652173913043, 0.31486611265004616, 0.73, 0.0, 0.0, 0.08333333333333333, 0.06442910049223165, 0.17015585527353994, 0.0, 1.0, 0.9, 0.9374270359425477], 
reward next is 0.4537, 
noisyNet noise sample is [array([0.8132874], dtype=float32), 0.44681248]. 
=============================================
[2019-04-24 10:44:43,208] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.7438532e-01 2.6454539e-03 4.2478500e-17 4.8936894e-16 5.0485117e-16
 2.1466047e-17 3.0772866e-17 1.0941807e-17 2.5412181e-14 2.2969214e-02
 6.7970629e-17], sum to 1.0000
[2019-04-24 10:44:43,210] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8595
[2019-04-24 10:44:43,247] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 100.0, 0.0, 0.0, 19.0, 20.8495164445056, -0.6467675199574258, 0.0, 1.0, 60.0, 82.68755061534873], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3108000.0000, 
sim time next is 3109200.0000, 
raw observation next is [0.0, 100.0, 0.0, 0.0, 19.0, 21.1542077096115, -0.7812263925592934, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.46260387811634357, 1.0, 0.0, 0.0, 0.08333333333333333, 0.26285064246762513, 0.23959120248023555, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5689555], dtype=float32), 0.34502703]. 
=============================================
[2019-04-24 10:44:45,144] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3938601e-01 9.2987334e-03 4.9807909e-15 3.1260161e-14 3.5560839e-14
 4.5755504e-15 1.8700031e-15 4.8057177e-16 8.2657183e-13 5.1315274e-02
 1.9747601e-14], sum to 1.0000
[2019-04-24 10:44:45,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5851
[2019-04-24 10:44:45,165] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 39.33333333333334, 86.5, 690.0, 19.0, 21.15451408718154, -0.6522770966214906, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3079200.0000, 
sim time next is 3080400.0000, 
raw observation next is [0.6666666666666666, 39.66666666666666, 79.5, 641.8333333333334, 19.0, 20.84962676872509, -0.7215321878051663, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4810710987996307, 0.39666666666666656, 0.265, 0.7092081031307551, 0.08333333333333333, 0.23746889739375762, 0.25948927073161127, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4368521], dtype=float32), -0.05592889]. 
=============================================
[2019-04-24 10:44:46,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.4362074e-01 3.7466220e-03 2.4425231e-20 3.9997275e-20 4.7273450e-19
 3.1633552e-21 2.2650469e-21 8.1874487e-22 2.3242030e-17 5.2632593e-02
 7.8169941e-21], sum to 1.0000
[2019-04-24 10:44:46,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5394
[2019-04-24 10:44:46,386] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 109.0, 755.8333333333334, 22.5, 23.44381434773957, -0.1836424834681422, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3148800.0000, 
sim time next is 3150000.0000, 
raw observation next is [7.0, 100.0, 111.0, 775.5, 22.5, 23.438932198911, -0.1673383980348334, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.6565096952908588, 1.0, 0.37, 0.8569060773480663, 0.375, 0.45324434990925005, 0.44422053398838884, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.81296104], dtype=float32), 0.53503615]. 
=============================================
[2019-04-24 10:44:46,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[94.69646 ]
 [94.69897 ]
 [95.090935]
 [95.04943 ]
 [94.645546]
 [93.08597 ]
 [92.20149 ]
 [91.390015]
 [90.31762 ]
 [88.34184 ]
 [87.38928 ]
 [85.345566]
 [85.07435 ]
 [84.94685 ]
 [84.88253 ]
 [84.94563 ]
 [83.913734]
 [83.94706 ]
 [84.05463 ]
 [83.2835  ]
 [83.42352 ]
 [82.41236 ]
 [82.42386 ]
 [82.361664]
 [81.08651 ]], R is [[94.75685883]
 [94.80928802]
 [94.86119843]
 [94.91259003]
 [94.96346283]
 [94.01383209]
 [94.00630188]
 [93.92675018]
 [93.91581726]
 [93.0840683 ]
 [92.15322876]
 [92.23169708]
 [92.30937958]
 [92.38628387]
 [92.46242523]
 [92.53780365]
 [91.61242676]
 [91.69630432]
 [91.77934265]
 [90.86154938]
 [90.95293427]
 [90.04340363]
 [90.14296722]
 [90.241539  ]
 [89.33912659]].
[2019-04-24 10:44:52,791] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.6786052e-01 6.1877705e-03 6.7218692e-16 5.6016779e-15 5.9892628e-15
 1.1734585e-16 8.3866175e-17 2.2665215e-16 1.5212084e-13 2.5951752e-02
 1.8922547e-16], sum to 1.0000
[2019-04-24 10:44:52,793] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.5487
[2019-04-24 10:44:52,806] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666666, 69.0, 0.0, 0.0, 19.0, 22.16673238528566, -0.4694095276327581, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3364800.0000, 
sim time next is 3366000.0000, 
raw observation next is [-5.0, 71.0, 0.0, 0.0, 19.0, 21.38111702447202, -0.6192297147689186, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.32409972299168976, 0.71, 0.0, 0.0, 0.08333333333333333, 0.2817597520393349, 0.2935900950770271, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.706274], dtype=float32), -1.1257325]. 
=============================================
[2019-04-24 10:44:54,015] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2697263e-01 1.7367067e-02 6.6523460e-14 1.4686426e-13 1.5395969e-13
 1.1526337e-14 1.8579437e-14 2.4095718e-15 2.3711510e-12 5.5660326e-02
 1.5864670e-14], sum to 1.0000
[2019-04-24 10:44:54,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1421
[2019-04-24 10:44:54,030] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 19.0, 20.94329538918154, -0.712375704174808, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3609600.0000, 
sim time next is 3610800.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 19.0, 20.62444572928829, -0.7933429601229173, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.4349030470914128, 0.42, 0.0, 0.0, 0.08333333333333333, 0.21870381077402415, 0.23555234662569424, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2879032], dtype=float32), -0.6405688]. 
=============================================
[2019-04-24 10:44:56,546] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6362330e-01 5.1190220e-02 5.6272343e-16 1.4614597e-15 4.4752969e-15
 7.5777281e-17 2.4847836e-16 1.5204657e-16 5.0356888e-14 1.8518656e-01
 2.1571465e-16], sum to 1.0000
[2019-04-24 10:44:56,549] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8937
[2019-04-24 10:44:56,640] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.333333333333334, 73.0, 92.66666666666667, 485.8333333333333, 22.5, 22.28624954344738, -0.5296158043504066, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3832800.0000, 
sim time next is 3834000.0000, 
raw observation next is [-4.0, 71.0, 96.0, 563.5, 22.5, 22.35181334771875, -0.3116490363325229, 1.0, 1.0, 60.0, 84.53053129074063], 
processed observation next is [1.0, 0.391304347826087, 0.3518005540166205, 0.71, 0.32, 0.6226519337016575, 0.375, 0.36265111230989583, 0.39611698788915906, 1.0, 1.0, 0.9, 0.8453053129074063], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.510284], dtype=float32), 0.3636927]. 
=============================================
[2019-04-24 10:44:58,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5988120e-01 1.3604969e-02 1.3325454e-14 3.4704834e-14 1.9098467e-14
 1.3549395e-15 3.1473258e-15 4.2291018e-16 2.2138747e-12 2.2651391e-01
 3.9281928e-15], sum to 1.0000
[2019-04-24 10:44:58,906] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2116
[2019-04-24 10:44:58,964] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 49.0, 106.5, 733.5, 22.5, 23.48391794900811, -0.2784646597427759, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3924000.0000, 
sim time next is 3925200.0000, 
raw observation next is [-6.666666666666667, 49.0, 110.8333333333333, 761.1666666666667, 22.5, 23.07497685881792, -0.315319031244573, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.27793167128347185, 0.49, 0.36944444444444435, 0.8410681399631676, 0.375, 0.4229147382348266, 0.394893656251809, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5060647], dtype=float32), -0.16411431]. 
=============================================
[2019-04-24 10:44:59,249] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.1914982e-01 6.1859163e-03 8.5384415e-17 1.2180102e-15 1.1811576e-15
 4.6551955e-18 3.2749037e-17 4.0381081e-17 1.7736840e-13 7.4664265e-02
 1.3558262e-16], sum to 1.0000
[2019-04-24 10:44:59,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2168
[2019-04-24 10:44:59,262] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 69.0, 0.0, 0.0, 22.5, 22.22759731380356, -0.3760306819356591, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3784800.0000, 
sim time next is 3786000.0000, 
raw observation next is [-2.0, 67.0, 0.0, 0.0, 22.5, 21.77377787762054, -0.4423385709757875, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.40720221606648205, 0.67, 0.0, 0.0, 0.375, 0.3144814898017116, 0.35255380967473754, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.21260487], dtype=float32), -0.19634607]. 
=============================================
[2019-04-24 10:45:03,262] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.9988062e-01 1.7451730e-02 1.9143851e-13 2.5263859e-13 1.1656512e-13
 8.8105479e-15 1.2134404e-14 1.9170222e-14 1.8907490e-11 1.8266763e-01
 4.3401955e-14], sum to 1.0000
[2019-04-24 10:45:03,272] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7871
[2019-04-24 10:45:03,358] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 45.0, 0.0, 0.0, 19.0, 21.80636381771718, -0.5053289309669341, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3963600.0000, 
sim time next is 3964800.0000, 
raw observation next is [-7.333333333333334, 46.33333333333334, 0.0, 0.0, 19.0, 21.22782810268422, -0.5951977562982526, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.2594644506001847, 0.46333333333333343, 0.0, 0.0, 0.08333333333333333, 0.26898567522368505, 0.3016007479005825, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32887107], dtype=float32), -0.99389154]. 
=============================================
[2019-04-24 10:45:05,525] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:05,757] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:06,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:06,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:06,524] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run11
[2019-04-24 10:45:06,826] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.61033642e-01 2.42813141e-03 2.25858308e-17 1.98661228e-16
 5.90994475e-17 1.91804055e-18 2.82520167e-18 8.53625732e-19
 1.07899165e-14 3.65381204e-02 4.89262195e-18], sum to 1.0000
[2019-04-24 10:45:06,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0782
[2019-04-24 10:45:06,880] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 61.66666666666667, 118.3333333333333, 827.1666666666667, 22.5, 23.231365060803, -0.2133800867737948, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3760800.0000, 
sim time next is 3762000.0000, 
raw observation next is [-1.0, 60.0, 117.0, 823.5, 22.5, 23.04350657055161, -0.2286851930710314, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.4349030470914128, 0.6, 0.39, 0.9099447513812154, 0.375, 0.4202922142126342, 0.4237716023096562, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4988444], dtype=float32), -2.576297]. 
=============================================
[2019-04-24 10:45:06,891] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4639919e-01 3.4790888e-02 8.5102491e-14 4.6624492e-14 2.0797001e-13
 4.7027561e-14 3.4529301e-14 8.0896610e-15 7.1286341e-12 1.1880998e-01
 4.1529314e-14], sum to 1.0000
[2019-04-24 10:45:06,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2491
[2019-04-24 10:45:06,936] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 48.66666666666666, 0.0, 0.0, 19.0, 20.33366260611332, -0.8683590612771334, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4156800.0000, 
sim time next is 4158000.0000, 
raw observation next is [-3.0, 50.0, 0.0, 0.0, 19.0, 19.82388320487294, -0.945078117418667, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.5, 0.0, 0.0, 0.08333333333333333, 0.15199026707274488, 0.18497396086044435, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7967448], dtype=float32), -2.1463444]. 
=============================================
[2019-04-24 10:45:10,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3052315e-01 5.0213460e-02 2.5100412e-14 2.7079415e-14 8.4713330e-14
 6.0873251e-15 5.8145957e-15 8.5440536e-16 1.9486556e-12 3.1926340e-01
 9.1255815e-15], sum to 1.0000
[2019-04-24 10:45:10,058] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5898
[2019-04-24 10:45:10,095] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 19.0, 19.89971347392243, -0.982408545511773, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4227600.0000, 
sim time next is 4228800.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 19.0, 19.56944456846266, -1.031965613791525, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4903047091412743, 0.47, 0.0, 0.0, 0.08333333333333333, 0.1307870473718884, 0.15601146206949168, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8634367], dtype=float32), 0.40582427]. 
=============================================
[2019-04-24 10:45:13,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.4768051e-01 3.3629123e-02 8.4874592e-14 4.6650319e-13 6.3427914e-13
 3.4965324e-14 1.2857094e-13 1.3742854e-14 5.3272935e-11 1.1869040e-01
 5.2523219e-14], sum to 1.0000
[2019-04-24 10:45:13,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0995
[2019-04-24 10:45:13,567] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 41.0, 0.0, 0.0, 19.0, 19.6055707849462, -1.025332221406802, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4066800.0000, 
sim time next is 4068000.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 19.0, 19.35397072632318, -1.07926815546185, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.41, 0.0, 0.0, 0.08333333333333333, 0.11283089386026497, 0.14024394817938335, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26546463], dtype=float32), 1.9091654]. 
=============================================
[2019-04-24 10:45:15,337] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2969940e-01 2.4423575e-02 1.7417961e-13 5.5654830e-13 3.8109107e-13
 3.4959526e-14 6.2234906e-14 5.1042307e-14 3.0867909e-11 1.4587690e-01
 4.1152655e-14], sum to 1.0000
[2019-04-24 10:45:15,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9704
[2019-04-24 10:45:15,428] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-9.666666666666666, 56.33333333333333, 0.0, 0.0, 19.0, 19.40050745609685, -0.9864570068924561, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3973200.0000, 
sim time next is 3974400.0000, 
raw observation next is [-10.0, 58.0, 0.0, 0.0, 19.0, 19.7444645962485, -0.6884482169538718, 0.0, 1.0, 60.0, 102.81084311469803], 
processed observation next is [1.0, 0.0, 0.18559556786703602, 0.58, 0.0, 0.0, 0.08333333333333333, 0.14537204968737485, 0.27051726101537604, 0.0, 1.0, 0.9, 1.0281084311469804], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22459044], dtype=float32), 0.09366751]. 
=============================================
[2019-04-24 10:45:16,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4418362e-01 2.5482886e-03 1.1138517e-17 4.0768652e-17 3.8688336e-16
 9.5661680e-19 4.4216472e-18 1.1966071e-18 1.0678816e-14 1.5326807e-01
 3.7205604e-18], sum to 1.0000
[2019-04-24 10:45:16,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3143
[2019-04-24 10:45:16,931] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 21.87938952578191, -0.3632196023676111, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4471200.0000, 
sim time next is 4472400.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 21.92754068594333, -0.3814308163928705, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.32729505716194424, 0.3728563945357098, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02515082], dtype=float32), -0.47053382]. 
=============================================
[2019-04-24 10:45:17,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5036019e-01 2.3963939e-02 1.5872094e-16 3.0196330e-16 2.1316562e-16
 3.6809646e-17 5.2983651e-17 7.5670913e-18 8.4276212e-15 2.2567596e-01
 4.8903646e-17], sum to 1.0000
[2019-04-24 10:45:17,918] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7179
[2019-04-24 10:45:17,947] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 55.0, 162.5, 713.0, 19.0, 20.46143867595732, -0.794080599432029, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4273200.0000, 
sim time next is 4274400.0000, 
raw observation next is [5.666666666666667, 54.0, 134.8333333333333, 785.6666666666666, 19.0, 20.17679658181549, -0.8202886497738008, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.6195752539242845, 0.54, 0.4494444444444443, 0.8681399631675875, 0.08333333333333333, 0.18139971515129094, 0.22657045007539975, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2973139], dtype=float32), 0.41336256]. 
=============================================
[2019-04-24 10:45:18,778] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0496933e-01 1.0443057e-02 4.5312637e-15 5.1138551e-15 1.5214186e-14
 7.0970916e-16 1.1132416e-15 1.6885645e-16 4.1665073e-14 8.4587514e-02
 5.5097482e-16], sum to 1.0000
[2019-04-24 10:45:18,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3742
[2019-04-24 10:45:18,803] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 48.0, 0.0, 0.0, 19.0, 21.13351947389922, -0.7626765751087974, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4236000.0000, 
sim time next is 4237200.0000, 
raw observation next is [2.0, 48.0, 0.0, 0.0, 19.0, 20.48904922315491, -0.8934917594765958, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.518005540166205, 0.48, 0.0, 0.0, 0.08333333333333333, 0.2074207685962426, 0.2021694135078014, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.8365218], dtype=float32), 0.3909131]. 
=============================================
[2019-04-24 10:45:18,865] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0198630e-01 1.4198289e-02 4.0289673e-15 8.4961996e-15 1.8566044e-14
 4.4594538e-16 5.1930261e-16 5.1811539e-16 4.7701426e-13 8.3815418e-02
 5.4712828e-16], sum to 1.0000
[2019-04-24 10:45:18,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5360
[2019-04-24 10:45:18,928] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 68.0, 0.0, 0.0, 22.5, 18.14984587570847, -0.9595149166258577, 1.0, 1.0, 60.0, 121.9785745946389], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 112800.0000, 
sim time next is 114000.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 22.5, 19.6794912310265, -1.034841631324396, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.375, 0.13995760258554166, 0.15505278955853466, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.32206988], dtype=float32), 1.4433153]. 
=============================================
[2019-04-24 10:45:21,403] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7396735e-01 2.8433318e-03 3.4725150e-18 1.7959942e-17 2.3433476e-17
 4.6213159e-19 2.8203898e-18 1.4919092e-19 1.9724706e-15 1.2318928e-01
 1.4998933e-18], sum to 1.0000
[2019-04-24 10:45:21,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4923
[2019-04-24 10:45:21,423] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 82.66666666666667, 73.33333333333334, 0.0, 22.5, 22.69176278951041, -0.2876425989374545, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4461600.0000, 
sim time next is 4462800.0000, 
raw observation next is [0.0, 80.33333333333334, 67.33333333333334, 0.0, 22.5, 22.67388513756785, -0.2919365319257405, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.8033333333333335, 0.22444444444444447, 0.0, 0.375, 0.3894904281306542, 0.40268782269141984, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.26712644], dtype=float32), -0.51525253]. 
=============================================
[2019-04-24 10:45:24,623] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.7807389e-01 4.6441358e-04 1.3489915e-19 2.7545644e-18 3.8909356e-18
 3.3971503e-20 3.9721711e-20 1.0384385e-20 1.6834863e-16 2.1461707e-02
 6.1104959e-19], sum to 1.0000
[2019-04-24 10:45:24,627] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8285
[2019-04-24 10:45:24,664] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.466666666666667, 49.0, 149.6666666666667, 777.3333333333333, 22.5, 24.46601545980376, 0.1336950872736374, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4628400.0000, 
sim time next is 4629600.0000, 
raw observation next is [4.7, 49.0, 171.0, 706.0, 22.5, 24.60095734229117, 0.08468028189442461, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.592797783933518, 0.49, 0.57, 0.7801104972375691, 0.375, 0.5500797785242643, 0.5282267606314749, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.0076178], dtype=float32), -2.1866066]. 
=============================================
[2019-04-24 10:45:26,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8480780e-01 2.2445172e-02 3.5585331e-16 4.6377330e-16 8.9195375e-16
 4.4484738e-17 4.6106187e-17 1.1513835e-17 8.0638438e-14 1.9274701e-01
 3.3190549e-17], sum to 1.0000
[2019-04-24 10:45:26,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0499
[2019-04-24 10:45:26,217] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 71.0, 0.0, 0.0, 19.0, 19.54947876396889, -0.9764930762297589, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4514400.0000, 
sim time next is 4515600.0000, 
raw observation next is [-1.0, 71.0, 0.0, 0.0, 19.0, 19.28999894446902, -1.024020426389556, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 0.71, 0.0, 0.0, 0.08333333333333333, 0.10749991203908493, 0.158659857870148, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.7278735], dtype=float32), -1.0572172]. 
=============================================
[2019-04-24 10:45:28,379] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.71687138e-01 1.24655105e-03 1.25302894e-20 5.45592305e-20
 1.52077660e-19 2.05665514e-21 2.71921591e-21 2.25702698e-22
 4.25297311e-18 2.70662922e-02 3.23308066e-21], sum to 1.0000
[2019-04-24 10:45:28,389] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5075
[2019-04-24 10:45:28,420] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.33333333333333, 55.33333333333333, 0.0, 0.0, 22.5, 24.27316621485873, 0.1521379389651774, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4390800.0000, 
sim time next is 4392000.0000, 
raw observation next is [11.0, 58.0, 0.0, 0.0, 22.5, 24.06118423151656, 0.1247805438240243, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.7673130193905818, 0.58, 0.0, 0.0, 0.375, 0.5050986859597133, 0.5415935146080081, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01919252], dtype=float32), 0.70381033]. 
=============================================
[2019-04-24 10:45:30,609] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.6717906e-01 2.1658307e-03 1.9815325e-17 5.8988850e-17 6.5483780e-17
 1.0928372e-18 2.0122446e-18 1.5091096e-18 4.8131207e-15 3.0655066e-02
 3.9321267e-18], sum to 1.0000
[2019-04-24 10:45:30,610] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4243
[2019-04-24 10:45:30,622] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 50.66666666666666, 95.50000000000001, 61.33333333333334, 22.5, 23.88797859145586, -0.1038311953057869, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4552800.0000, 
sim time next is 4554000.0000, 
raw observation next is [2.0, 52.0, 68.5, 48.0, 22.5, 23.78512677617411, -0.1536297327451909, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.518005540166205, 0.52, 0.22833333333333333, 0.05303867403314917, 0.375, 0.48209389801450914, 0.44879008908493634, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.34363186], dtype=float32), 1.5680027]. 
=============================================
[2019-04-24 10:45:31,407] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1232765e-01 7.8921495e-03 1.4675374e-15 2.7378849e-15 2.8172725e-15
 6.3649200e-16 1.2675792e-15 1.8516897e-16 1.3466996e-13 7.9780281e-02
 2.2735906e-15], sum to 1.0000
[2019-04-24 10:45:31,410] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1582
[2019-04-24 10:45:31,426] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 122.5, 734.5, 19.0, 19.66777724255984, -0.8315751793626712, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4806000.0000, 
sim time next is 4807200.0000, 
raw observation next is [3.0, 37.0, 105.5, 729.5, 19.0, 19.75081369096852, -0.8251441386310262, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.37, 0.3516666666666667, 0.8060773480662984, 0.08333333333333333, 0.14590114091404338, 0.22495195378965793, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.0112936], dtype=float32), -1.5440278]. 
=============================================
[2019-04-24 10:45:33,357] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [2.8046614e-01 3.6299046e-02 1.0617210e-14 5.7086217e-15 1.8892743e-14
 1.5572844e-15 1.7907488e-15 3.8753078e-16 4.9687554e-13 6.8323481e-01
 4.5665420e-16], sum to 1.0000
[2019-04-24 10:45:33,358] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.4851
[2019-04-24 10:45:33,415] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.0, 50.0, 0.0, 0.0, 19.0, 18.99880311155945, -1.218286689332316, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4939200.0000, 
sim time next is 4940400.0000, 
raw observation next is [-2.0, 48.66666666666667, 0.0, 0.0, 19.0, 19.14954853960042, -0.9272735871787757, 0.0, 1.0, 60.0, 92.32107782157412], 
processed observation next is [1.0, 0.17391304347826086, 0.40720221606648205, 0.4866666666666667, 0.0, 0.0, 0.08333333333333333, 0.09579571163336838, 0.19090880427374143, 0.0, 1.0, 0.9, 0.9232107782157413], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0216442], dtype=float32), 1.5407126]. 
=============================================
[2019-04-24 10:45:34,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0726721e-01 6.7673605e-03 6.2526765e-16 3.2799195e-15 3.3924368e-15
 2.0779113e-16 4.0145177e-16 3.2150538e-17 5.4956354e-13 8.5965492e-02
 9.3451843e-16], sum to 1.0000
[2019-04-24 10:45:34,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2238
[2019-04-24 10:45:34,555] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 45.0, 0.0, 0.0, 19.0, 22.76519810214323, -0.4104807410620218, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4904400.0000, 
sim time next is 4905600.0000, 
raw observation next is [1.333333333333333, 46.0, 0.0, 0.0, 19.0, 22.12671447668415, -0.5363661425188267, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.4995383194829178, 0.46, 0.0, 0.0, 0.08333333333333333, 0.3438928730570125, 0.32121128582705777, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5132942], dtype=float32), -1.6527374]. 
=============================================
[2019-04-24 10:45:36,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:36,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:36,749] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:36,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:37,117] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:37,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:37,334] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:37,338] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:37,348] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run11
[2019-04-24 10:45:37,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:37,742] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:37,750] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run11
[2019-04-24 10:45:38,129] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:38,130] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:38,138] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run11
[2019-04-24 10:45:38,532] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:38,783] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:39,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:39,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:39,560] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run11
[2019-04-24 10:45:40,621] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:40,756] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4547068e-01 4.2974677e-02 1.8773255e-14 1.7768839e-14 3.8617099e-14
 4.1703049e-15 9.2713050e-15 1.6449443e-15 9.9974326e-13 3.1155464e-01
 4.8944389e-15], sum to 1.0000
[2019-04-24 10:45:40,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1346
[2019-04-24 10:45:40,815] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 62.0, 209.5, 19.0, 20.07635257907388, -0.9098706815462818, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4780800.0000, 
sim time next is 4782000.0000, 
raw observation next is [-5.666666666666666, 87.0, 103.3333333333333, 349.1666666666667, 19.0, 19.57403962487915, -1.003742016241039, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.3056325023084026, 0.87, 0.34444444444444433, 0.3858195211786372, 0.08333333333333333, 0.13116996873992903, 0.16541932791965364, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.14597538], dtype=float32), 2.2115953]. 
=============================================
[2019-04-24 10:45:40,874] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:41,169] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:41,371] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:41,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:41,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:41,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run11
[2019-04-24 10:45:42,200] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:42,200] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:42,204] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run11
[2019-04-24 10:45:42,362] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.88279593e-01 1.23891551e-02 1.52792970e-14 1.34287765e-14
 5.28557639e-14 2.49872411e-15 3.80321647e-15 6.10980694e-16
 6.97047292e-13 1.99331298e-01 2.26785300e-15], sum to 1.0000
[2019-04-24 10:45:42,401] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6680
[2019-04-24 10:45:42,469] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 19.0, 19.58695642592932, -0.9851893902735989, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4910400.0000, 
sim time next is 4911600.0000, 
raw observation next is [1.0, 38.66666666666667, 0.0, 0.0, 19.0, 19.45736121646744, -1.016165283486918, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.4903047091412743, 0.3866666666666667, 0.0, 0.0, 0.08333333333333333, 0.12144676803895334, 0.16127823883769402, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.13709651], dtype=float32), 0.8803262]. 
=============================================
[2019-04-24 10:45:43,548] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6414260e-01 1.0905404e-02 4.9792838e-17 8.5328650e-17 1.5312781e-16
 2.6104191e-18 4.9689215e-18 1.3688259e-18 3.5167302e-15 1.2495210e-01
 8.8380113e-18], sum to 1.0000
[2019-04-24 10:45:43,548] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3320
[2019-04-24 10:45:43,716] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.110223024625157e-16, 53.0, 99.5, 560.5, 22.5, 23.22537525168113, -0.2466280421691863, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5042400.0000, 
sim time next is 5043600.0000, 
raw observation next is [1.0, 47.0, 104.5, 615.5, 22.5, 23.239804752765, -0.271884632653471, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4903047091412743, 0.47, 0.34833333333333333, 0.6801104972375691, 0.375, 0.43665039606375, 0.4093717891155097, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5790147], dtype=float32), -0.8480845]. 
=============================================
[2019-04-24 10:45:43,919] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:44,250] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:44,916] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:44,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:44,928] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run11
[2019-04-24 10:45:45,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:45,656] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:45,682] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.85594451e-01 8.82468477e-04 3.53881599e-20 9.65277072e-19
 7.69474425e-19 5.82084614e-21 3.95562842e-20 3.92173033e-21
 5.68627842e-17 1.35231465e-02 1.03576054e-19], sum to 1.0000
[2019-04-24 10:45:45,690] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0015
[2019-04-24 10:45:45,723] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 21.66666666666666, 116.8333333333333, 853.1666666666667, 22.5, 24.62923068698461, 0.1789238964978265, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5060400.0000, 
sim time next is 5061600.0000, 
raw observation next is [11.0, 20.0, 114.5, 839.5, 22.5, 24.6551883340775, 0.2095496190379772, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7673130193905818, 0.2, 0.38166666666666665, 0.9276243093922651, 0.375, 0.5545990278397918, 0.5698498730126591, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.03359377], dtype=float32), -1.730314]. 
=============================================
[2019-04-24 10:45:46,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:46,414] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:46,418] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run11
[2019-04-24 10:45:46,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:47,258] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:47,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:47,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:47,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run11
[2019-04-24 10:45:48,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5340234e-01 7.4787773e-03 7.5734918e-15 3.2516026e-14 1.7872282e-14
 1.6925904e-15 1.0415582e-15 1.6312542e-15 6.7071891e-13 3.9118841e-02
 6.2991566e-15], sum to 1.0000
[2019-04-24 10:45:48,612] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9930
[2019-04-24 10:45:48,648] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-1.566666666666667, 58.66666666666667, 0.0, 0.0, 19.0, 19.25392302675924, -0.9292931281647469, 0.0, 1.0, 60.0, 97.5467462144521], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 670800.0000, 
sim time next is 672000.0000, 
raw observation next is [-1.933333333333333, 60.33333333333333, 0.0, 0.0, 19.0, 20.38298594829947, -0.8122515515297907, 0.0, 1.0, 60.0, 62.896181945830506], 
processed observation next is [0.0, 0.782608695652174, 0.40904893813481075, 0.6033333333333333, 0.0, 0.0, 0.08333333333333333, 0.1985821623582892, 0.2292494828234031, 0.0, 1.0, 0.9, 0.6289618194583051], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07032314], dtype=float32), -0.74457294]. 
=============================================
[2019-04-24 10:45:48,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:49,028] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:49,520] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:49,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:49,654] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:49,659] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run11
[2019-04-24 10:45:49,738] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:50,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:50,529] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:50,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run11
[2019-04-24 10:45:51,168] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:51,433] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:52,144] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:52,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:52,172] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:52,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run11
[2019-04-24 10:45:52,428] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:52,633] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:52,979] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:52,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_9 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:45:53,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:53,131] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:53,136] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run11
[2019-04-24 10:45:53,237] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_9 ERROR:Aborted (core dumped)

[2019-04-24 10:45:53,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:53,634] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:53,637] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run11
[2019-04-24 10:45:53,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:45:53,985] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:45:53,999] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run11
[2019-04-24 10:46:01,156] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1073256e-01 1.2292672e-02 2.4339536e-17 4.7995656e-17 1.1990307e-16
 7.6411740e-19 3.1090615e-18 5.5938614e-18 4.4611150e-15 3.7697473e-01
 1.4639294e-18], sum to 1.0000
[2019-04-24 10:46:01,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6004
[2019-04-24 10:46:01,185] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 84.0, 72.16666666666667, 0.0, 22.5, 22.14639877842411, -0.5455572895667314, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 901200.0000, 
sim time next is 902400.0000, 
raw observation next is [1.1, 84.0, 80.33333333333334, 0.0, 22.5, 22.04239814495698, -0.5645906915981025, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.49307479224376743, 0.84, 0.26777777777777784, 0.0, 0.375, 0.3368665120797483, 0.3118031028006325, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8957, 
noisyNet noise sample is [array([1.2373548], dtype=float32), -1.904208]. 
=============================================
[2019-04-24 10:46:02,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2562217e-01 2.3713070e-03 2.3070649e-15 8.1946516e-15 7.7274384e-15
 5.5928672e-17 5.0666149e-16 1.5147129e-16 1.4513688e-12 7.2006546e-02
 1.6643745e-15], sum to 1.0000
[2019-04-24 10:46:02,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0055
[2019-04-24 10:46:02,861] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 67.66666666666667, 0.0, 0.0, 22.5, 23.09473916352631, -0.2630328294068848, 1.0, 1.0, 60.0, 94.09167960465868], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 148800.0000, 
sim time next is 150000.0000, 
raw observation next is [-7.3, 64.33333333333333, 0.0, 0.0, 22.5, 22.78001845859829, -0.3969722641750242, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.26038781163434904, 0.6433333333333333, 0.0, 0.0, 0.375, 0.39833487154985736, 0.3676759119416586, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.513796], dtype=float32), -1.8057766]. 
=============================================
[2019-04-24 10:46:02,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.98806 ]
 [69.02421 ]
 [69.23792 ]
 [69.33609 ]
 [68.41697 ]
 [68.60133 ]
 [69.03658 ]
 [69.78183 ]
 [69.585396]
 [70.68894 ]
 [71.70788 ]
 [72.59793 ]
 [72.555504]
 [73.408325]
 [73.101616]
 [73.37117 ]
 [73.57498 ]
 [72.90649 ]
 [73.55692 ]
 [72.421585]
 [73.271935]
 [72.52666 ]
 [71.25636 ]
 [71.40146 ]
 [70.555046]], R is [[69.90155792]
 [69.20254517]
 [69.51052094]
 [69.81541443]
 [69.11726379]
 [69.42609406]
 [69.73183441]
 [70.03451538]
 [69.33416748]
 [69.64082336]
 [69.94441223]
 [70.24497223]
 [69.54252625]
 [69.8470993 ]
 [69.14862823]
 [69.45714569]
 [69.76257324]
 [69.06494904]
 [69.3742981 ]
 [68.68055725]
 [68.92906952]
 [69.23977661]
 [68.54737854]
 [68.86190796]
 [68.17328644]].
[2019-04-24 10:46:07,815] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3211480e-01 8.1136152e-02 2.8353190e-14 1.4595034e-13 7.6330239e-14
 2.8749948e-15 2.7689732e-14 7.6719916e-15 3.3447722e-12 3.8674906e-01
 2.9255656e-15], sum to 1.0000
[2019-04-24 10:46:07,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3823
[2019-04-24 10:46:07,859] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 67.0, 0.0, 0.0, 19.0, 19.30276566188509, -1.135780358299898, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 270000.0000, 
sim time next is 271200.0000, 
raw observation next is [-9.100000000000001, 68.0, 0.0, 0.0, 19.0, 18.77618805957238, -1.210857103719026, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.21052631578947364, 0.68, 0.0, 0.0, 0.08333333333333333, 0.06468233829769836, 0.0963809654269913, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.7996, 
noisyNet noise sample is [array([-0.5763979], dtype=float32), -0.49228883]. 
=============================================
[2019-04-24 10:46:08,636] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [7.86552906e-01 5.90103455e-02 1.18003253e-12 1.63431890e-11
 5.02628278e-12 1.72757967e-13 5.11613538e-13 3.94755138e-13
 1.07579876e-10 1.54436752e-01 2.66763554e-13], sum to 1.0000
[2019-04-24 10:46:08,636] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5277
[2019-04-24 10:46:08,662] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 19.0, 19.00892277830958, -1.046569209058345, 0.0, 1.0, 60.0, 90.97452482754687], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 363600.0000, 
sim time next is 364800.0000, 
raw observation next is [-15.8, 74.66666666666667, 0.0, 0.0, 19.0, 19.41641448346395, -1.216311782126233, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.024930747922437636, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, 0.11803454028866245, 0.09456273929125565, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3072275], dtype=float32), -0.83377993]. 
=============================================
[2019-04-24 10:46:10,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4673573e-02 7.5659327e-02 2.2113524e-12 9.8979700e-13 1.4912842e-12
 2.2923736e-13 6.9607449e-13 1.9720003e-13 2.2476000e-11 8.5966712e-01
 7.2917339e-14], sum to 1.0000
[2019-04-24 10:46:10,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0451
[2019-04-24 10:46:10,088] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.46666666666667, 68.0, 0.0, 0.0, 22.5, 17.60079052598759, -1.472704169396345, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 285600.0000, 
sim time next is 286800.0000, 
raw observation next is [-12.63333333333333, 69.0, 0.0, 0.0, 22.5, 17.25530393329898, -1.523597169734821, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.11265004616805181, 0.69, 0.0, 0.0, 0.375, -0.062058005558418415, -0.007865723244940318, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.91495496], dtype=float32), -0.39327097]. 
=============================================
[2019-04-24 10:46:17,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8170341e-01 9.3404660e-03 1.2644461e-17 6.8999787e-17 1.0222317e-16
 3.0334669e-18 8.1154974e-19 1.3436661e-18 5.7068197e-15 2.0895611e-01
 4.4003535e-18], sum to 1.0000
[2019-04-24 10:46:17,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2908
[2019-04-24 10:46:17,558] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 96.0, 0.0, 0.0, 22.5, 22.777519695533, -0.4373379377168731, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 502800.0000, 
sim time next is 504000.0000, 
raw observation next is [1.1, 96.0, 0.0, 0.0, 22.5, 22.0714669267085, -0.5687093176108803, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.49307479224376743, 0.96, 0.0, 0.0, 0.375, 0.3392889105590416, 0.3104302274630399, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8820, 
noisyNet noise sample is [array([0.5721227], dtype=float32), -0.35043553]. 
=============================================
[2019-04-24 10:46:19,427] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [4.8430964e-01 3.1695187e-02 4.8480421e-12 3.8447110e-12 5.1521374e-12
 1.8452183e-13 6.3057643e-13 4.9435640e-13 1.2820636e-10 4.8399523e-01
 5.8743461e-13], sum to 1.0000
[2019-04-24 10:46:19,427] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0974
[2019-04-24 10:46:19,450] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-13.9, 66.0, 0.0, 0.0, 19.0, 19.61409859382703, -1.096774932601633, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 345600.0000, 
sim time next is 346800.0000, 
raw observation next is [-14.1, 67.0, 0.0, 0.0, 19.0, 18.92502032211694, -1.207574834322886, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.07202216066481995, 0.67, 0.0, 0.0, 0.08333333333333333, 0.07708502684307827, 0.09747505522570465, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9775, 
noisyNet noise sample is [array([-0.436315], dtype=float32), -1.5526899]. 
=============================================
[2019-04-24 10:46:24,050] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.8418434e-01 1.2848460e-02 1.3468810e-12 3.6466433e-12 2.3286403e-12
 1.3492201e-13 1.7252246e-13 1.5438584e-13 2.6507438e-10 2.0296721e-01
 4.8638838e-13], sum to 1.0000
[2019-04-24 10:46:24,050] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.2014
[2019-04-24 10:46:24,071] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 36.0, 10.5, 210.0, 22.5, 22.34626298577061, -0.5770253738016821, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 406800.0000, 
sim time next is 408000.0000, 
raw observation next is [-9.100000000000001, 37.33333333333334, 0.0, 0.0, 22.5, 21.77199769498623, -0.6779504756623336, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.21052631578947364, 0.3733333333333334, 0.0, 0.0, 0.375, 0.3143331412488524, 0.27401650811255546, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.2083, 
noisyNet noise sample is [array([0.904854], dtype=float32), -1.6367006]. 
=============================================
[2019-04-24 10:46:26,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0346271e-01 5.0058268e-02 3.4352287e-13 1.1101153e-13 1.6854491e-13
 1.9995429e-14 2.9725158e-14 1.1811520e-14 5.6710448e-12 7.4647903e-01
 7.5089479e-15], sum to 1.0000
[2019-04-24 10:46:26,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1776
[2019-04-24 10:46:26,466] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.1, 73.66666666666666, 38.33333333333333, 8.499999999999998, 19.0, 19.4197868094369, -1.146196632871229, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 636000.0000, 
sim time next is 637200.0000, 
raw observation next is [-3.9, 71.0, 77.0, 25.5, 19.0, 18.57495783413977, -1.282227031757291, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3545706371191136, 0.71, 0.25666666666666665, 0.0281767955801105, 0.08333333333333333, 0.04791315284498084, 0.07259098941423632, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.2774, 
noisyNet noise sample is [array([-0.57721543], dtype=float32), -0.6276088]. 
=============================================
[2019-04-24 10:46:28,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.11772919e-01 1.02475202e-02 2.03277087e-12 1.40816464e-11
 3.83290058e-12 1.50917188e-13 3.15717098e-13 5.38622424e-13
 2.87644575e-10 2.77979583e-01 4.83577425e-13], sum to 1.0000
[2019-04-24 10:46:28,578] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4050
[2019-04-24 10:46:28,598] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.3, 38.66666666666666, 0.0, 0.0, 22.5, 21.56078398447611, -0.6547310995688946, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 409200.0000, 
sim time next is 410400.0000, 
raw observation next is [-9.5, 40.0, 0.0, 0.0, 22.5, 21.18006799313938, -0.7194464715968074, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.1994459833795014, 0.4, 0.0, 0.0, 0.375, 0.26500566609494847, 0.26018450946773086, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7291683], dtype=float32), 0.8570373]. 
=============================================
[2019-04-24 10:46:28,771] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.2923037e-01 9.0461876e-03 7.4704715e-15 3.2134529e-14 1.3184262e-14
 8.5789620e-16 2.1954162e-15 1.5925892e-15 7.5419494e-13 1.6172345e-01
 2.5909410e-15], sum to 1.0000
[2019-04-24 10:46:28,772] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8334
[2019-04-24 10:46:28,888] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-0.4, 35.66666666666667, 98.16666666666667, 0.0, 22.5, 23.81141181897137, -0.3446656724193204, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 483600.0000, 
sim time next is 484800.0000, 
raw observation next is [-0.2, 36.33333333333333, 87.66666666666667, 0.0, 22.5, 23.59317855958354, -0.3393158098922702, 1.0, 1.0, 20.0, 63.14441691183849], 
processed observation next is [1.0, 0.6086956521739131, 0.4570637119113574, 0.3633333333333333, 0.2922222222222222, 0.0, 0.375, 0.4660982132986282, 0.38689473003590996, 1.0, 1.0, 0.1, 0.6314441691183849], 
reward next is 0.2686, 
noisyNet noise sample is [array([0.3843667], dtype=float32), -0.2379001]. 
=============================================
[2019-04-24 10:46:29,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2161053e-01 5.3289505e-03 3.0650774e-16 1.5354501e-15 6.7670484e-16
 2.3708937e-17 2.7265003e-16 1.9129749e-17 4.0892985e-14 7.3060498e-02
 1.1801159e-16], sum to 1.0000
[2019-04-24 10:46:29,629] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8951
[2019-04-24 10:46:29,660] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.366666666666667, 87.0, 0.0, 0.0, 19.0, 21.82095996015592, -0.4873524781788721, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1750800.0000, 
sim time next is 1752000.0000, 
raw observation next is [-1.533333333333333, 87.0, 0.0, 0.0, 19.0, 21.05848040820257, -0.6328696297743073, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.42012927054478305, 0.87, 0.0, 0.0, 0.08333333333333333, 0.25487336735021415, 0.2890434567418976, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5649446], dtype=float32), 0.53274006]. 
=============================================
[2019-04-24 10:46:31,836] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.25584459e-01 4.70972061e-02 3.69556883e-14 1.16199381e-13
 7.35201220e-14 3.58324710e-15 1.35513828e-14 1.15381735e-14
 5.10422564e-12 4.27318305e-01 1.18897303e-14], sum to 1.0000
[2019-04-24 10:46:31,836] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1359
[2019-04-24 10:46:31,875] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.8, 74.0, 0.0, 0.0, 19.0, 19.27964083092378, -0.8710654598284319, 0.0, 1.0, 60.0, 93.9893344210481], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 788400.0000, 
sim time next is 789600.0000, 
raw observation next is [-7.633333333333333, 74.33333333333334, 0.0, 0.0, 19.0, 20.135776952849, -0.9957559131919099, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.2511542012927055, 0.7433333333333334, 0.0, 0.0, 0.08333333333333333, 0.17798141273741663, 0.16808136226936335, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1682465], dtype=float32), -0.7015197]. 
=============================================
[2019-04-24 10:46:43,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8616415e-01 3.7839709e-04 1.9415666e-18 6.2105759e-17 2.2002439e-17
 6.3797871e-19 1.0239420e-18 1.1465464e-18 3.3579323e-15 1.3457455e-02
 3.8243256e-18], sum to 1.0000
[2019-04-24 10:46:43,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4070
[2019-04-24 10:46:43,646] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 54.0, 155.5, 0.0, 22.5, 24.82194098972273, 0.3736105552719481, 1.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1087200.0000, 
sim time next is 1088400.0000, 
raw observation next is [19.0, 52.33333333333334, 145.1666666666667, 0.0, 22.5, 25.58476398724007, 0.4461885918774438, 1.0, 0.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.9889196675900279, 0.5233333333333334, 0.48388888888888903, 0.0, 0.375, 0.6320636656033392, 0.6487295306258146, 1.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2491119], dtype=float32), -1.7368659]. 
=============================================
[2019-04-24 10:46:45,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6229351e-01 2.6728550e-03 1.5550058e-16 1.5000861e-15 4.1011811e-15
 7.5775687e-17 2.1457096e-16 4.5084907e-17 4.0311982e-14 3.5033695e-02
 4.7623173e-16], sum to 1.0000
[2019-04-24 10:46:45,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3698
[2019-04-24 10:46:45,982] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [15.7, 89.66666666666667, 0.0, 0.0, 19.0, 22.18786487344228, -0.1984337054526475, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1219200.0000, 
sim time next is 1220400.0000, 
raw observation next is [15.5, 93.0, 0.0, 0.0, 19.0, 22.1332085485191, -0.2067612882962319, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.8919667590027703, 0.93, 0.0, 0.0, 0.08333333333333333, 0.34443404570992503, 0.4310795705679227, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7257312], dtype=float32), -0.56094086]. 
=============================================
[2019-04-24 10:46:47,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7327772e-01 4.9294522e-03 2.5449395e-19 2.0062592e-19 1.5308599e-18
 3.2418656e-20 1.8757325e-20 1.5851146e-20 4.9489415e-17 1.2179277e-01
 1.2634068e-20], sum to 1.0000
[2019-04-24 10:46:47,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0746
[2019-04-24 10:46:47,254] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [12.7, 82.66666666666667, 0.0, 0.0, 19.0, 22.03221175189962, -0.2948535961417217, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1150800.0000, 
sim time next is 1152000.0000, 
raw observation next is [12.7, 84.0, 16.0, 0.5, 19.0, 21.88256620442672, -0.3183098047798251, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.8144044321329641, 0.84, 0.05333333333333334, 0.0005524861878453039, 0.08333333333333333, 0.3235471837022266, 0.3938967317400583, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.63945895], dtype=float32), -0.43740147]. 
=============================================
[2019-04-24 10:46:50,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6115527e-01 1.3659886e-02 6.2089421e-16 3.7083369e-15 3.0018312e-15
 3.8518664e-17 1.5552271e-16 3.5180465e-16 2.8075865e-13 1.2518491e-01
 3.1298749e-16], sum to 1.0000
[2019-04-24 10:46:50,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2987
[2019-04-24 10:46:50,417] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 71.0, 104.5, 0.0, 22.5, 23.54502701993723, -0.4364130827044155, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 820800.0000, 
sim time next is 822000.0000, 
raw observation next is [-4.5, 73.66666666666667, 100.8333333333333, 0.0, 22.5, 22.59237765199188, -0.5076869189751805, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3379501385041552, 0.7366666666666667, 0.336111111111111, 0.0, 0.375, 0.38269813766599015, 0.33077102700827316, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9985, 
noisyNet noise sample is [array([-0.15564388], dtype=float32), -0.6276578]. 
=============================================
[2019-04-24 10:46:53,659] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5934756e-01 2.3675891e-02 8.3778970e-18 2.3811299e-17 4.8432669e-17
 1.9431465e-18 5.6265855e-18 2.2723913e-19 1.9264028e-15 2.1697655e-01
 7.7480178e-19], sum to 1.0000
[2019-04-24 10:46:53,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5514
[2019-04-24 10:46:53,695] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.2, 94.0, 0.0, 0.0, 19.0, 20.54948653087627, -0.6996827706717487, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1479600.0000, 
sim time next is 1480800.0000, 
raw observation next is [2.2, 94.66666666666667, 0.0, 0.0, 19.0, 20.32793246896422, -0.7243610853050938, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.5235457063711911, 0.9466666666666668, 0.0, 0.0, 0.08333333333333333, 0.19399437241368508, 0.25854630489830205, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3563134], dtype=float32), -0.2387891]. 
=============================================
[2019-04-24 10:46:56,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3096290e-01 1.1638610e-02 4.0401324e-15 9.6898511e-15 5.6994128e-15
 1.9672981e-16 2.7114324e-16 4.2408417e-16 1.2805166e-12 1.5739854e-01
 4.1014839e-16], sum to 1.0000
[2019-04-24 10:46:56,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1672
[2019-04-24 10:46:56,261] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.4, 47.33333333333333, 35.00000000000001, 0.0, 22.5, 21.86411534604485, -0.547619956531282, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2306400.0000, 
sim time next is 2307600.0000, 
raw observation next is [-0.6, 49.0, 23.0, 0.0, 22.5, 22.02267805464598, -0.5360047480042115, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.44598337950138506, 0.49, 0.07666666666666666, 0.0, 0.375, 0.3352231712204983, 0.3213317506652628, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9885, 
noisyNet noise sample is [array([-0.1397061], dtype=float32), -2.027961]. 
=============================================
[2019-04-24 10:46:57,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.70902061e-01 8.94545112e-03 4.83630543e-18 2.55484203e-18
 3.26631091e-17 6.34629665e-19 1.11100479e-18 4.71012377e-20
 5.13823897e-16 1.20152555e-01 5.68630992e-19], sum to 1.0000
[2019-04-24 10:46:57,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7281
[2019-04-24 10:46:57,250] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 79.0, 0.0, 0.0, 19.0, 21.08710353716675, -0.5285241356949303, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1562400.0000, 
sim time next is 1563600.0000, 
raw observation next is [4.800000000000001, 81.33333333333334, 0.0, 0.0, 19.0, 21.01685103173094, -0.5451702664785861, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5955678670360112, 0.8133333333333335, 0.0, 0.0, 0.08333333333333333, 0.25140425264424504, 0.3182765778404713, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3543999], dtype=float32), -0.4743273]. 
=============================================
[2019-04-24 10:46:58,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6073943e-01 2.9145633e-03 1.5283064e-19 1.3440833e-18 1.1079730e-18
 2.6271701e-21 8.5279082e-21 4.3738613e-21 4.3736199e-17 3.6346000e-02
 5.2061694e-21], sum to 1.0000
[2019-04-24 10:46:58,053] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3373
[2019-04-24 10:46:58,070] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.2, 82.0, 0.0, 0.0, 19.0, 22.8535183279682, -0.1291868330891562, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1638000.0000, 
sim time next is 1639200.0000, 
raw observation next is [7.200000000000001, 83.33333333333334, 0.0, 0.0, 19.0, 22.68701413012736, -0.1566793981072226, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.662049861495845, 0.8333333333333335, 0.0, 0.0, 0.08333333333333333, 0.3905845108439466, 0.4477735339642592, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2079477], dtype=float32), -1.368411]. 
=============================================
[2019-04-24 10:46:59,909] A3C_AGENT_WORKER-Thread-6 INFO:Evaluating...
[2019-04-24 10:46:59,912] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:46:59,913] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:46:59,914] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:46:59,915] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:46:59,915] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:46:59,918] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:46:59,923] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run15
[2019-04-24 10:46:59,944] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run15
[2019-04-24 10:46:59,957] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run15
[2019-04-24 10:47:10,007] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.24583973], dtype=float32), 0.65312785]
[2019-04-24 10:47:10,007] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-7.833333333333334, 69.66666666666667, 0.0, 0.0, 19.0, 19.49569983010755, -0.8921806413447121, 0.0, 1.0, 20.0, 85.57016691126438]
[2019-04-24 10:47:10,007] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:47:10,008] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.8794336e-01 1.9763513e-02 1.4636910e-13 1.3568052e-13 2.5037947e-13
 1.6546162e-14 3.6139037e-14 1.0996459e-14 7.1433254e-12 1.9229317e-01
 3.1820280e-14], sampled 0.832282222260078
[2019-04-24 10:49:03,518] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3417.5345 57567.9543 -330.4500
[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,557] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:03,857] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,162] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3199.3737 74722.3734 -545.3052
[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,215] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:19,425] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:32,924] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3072.5315 75411.5193 -653.6521
[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:32,963] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,130] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:49:33,962] A3C_AGENT_WORKER-Thread-6 INFO:Global step: 700000, evaluation results [700000.0, 3199.373737814057, 74722.37337209797, -545.3052392216861, 3417.534474862607, 57567.95432470618, -330.4499553450188, 3072.5315345966224, 75411.51934511622, -653.6520658400093]
[2019-04-24 10:49:46,228] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.37973106e-01 1.29273646e-02 5.08845768e-15 1.00344605e-14
 1.21874531e-14 3.02465910e-16 8.76965345e-16 6.83257539e-16
 6.14837987e-13 4.49099571e-01 8.17858274e-16], sum to 1.0000
[2019-04-24 10:49:46,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1246
[2019-04-24 10:49:46,303] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 79.0, 128.0, 392.5, 22.5, 21.58192757980107, -0.7733898367809626, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1936800.0000, 
sim time next is 1938000.0000, 
raw observation next is [-6.733333333333333, 77.66666666666667, 156.6666666666667, 288.1666666666667, 22.5, 21.23103356750288, -0.8217157622648341, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.2760849492151431, 0.7766666666666667, 0.5222222222222224, 0.3184162062615101, 0.375, 0.2692527972919067, 0.22609474591172196, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75946915], dtype=float32), 0.1313698]. 
=============================================
[2019-04-24 10:49:48,545] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.7434413e-01 7.1682897e-04 1.5616517e-19 1.0750158e-18 8.9914181e-19
 1.8959365e-21 4.5428783e-21 2.6490895e-21 1.7308569e-16 2.4938950e-02
 3.1082623e-20], sum to 1.0000
[2019-04-24 10:49:48,562] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4245
[2019-04-24 10:49:48,587] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.600000000000001, 60.66666666666667, 0.0, 0.0, 22.5, 23.98316288031022, 0.09760798718542484, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1536000.0000, 
sim time next is 1537200.0000, 
raw observation next is [9.4, 61.0, 0.0, 0.0, 22.5, 23.8496258060948, 0.06483592402084637, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7229916897506927, 0.61, 0.0, 0.0, 0.375, 0.48746881717456664, 0.5216119746736155, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8878615], dtype=float32), -0.52208304]. 
=============================================
[2019-04-24 10:50:09,914] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9823985e-01 1.6428836e-02 4.8999577e-15 1.2510529e-13 4.8843955e-14
 3.9887139e-16 4.7558727e-15 1.1920735e-15 9.7078584e-13 8.5331351e-02
 6.1979556e-15], sum to 1.0000
[2019-04-24 10:50:09,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5127
[2019-04-24 10:50:09,974] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.133333333333333, 89.66666666666667, 38.0, 16.66666666666667, 22.5, 21.32484247825975, -0.5220496853304349, 1.0, 1.0, 60.0, 101.4639064218019], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2276400.0000, 
sim time next is 2277600.0000, 
raw observation next is [-8.766666666666666, 88.33333333333334, 54.33333333333333, 19.83333333333333, 22.5, 22.39010888166246, -0.5799299988860996, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.2197599261311173, 0.8833333333333334, 0.18111111111111108, 0.021915285451197048, 0.375, 0.365842406805205, 0.3066900003713001, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8403, 
noisyNet noise sample is [array([0.49630615], dtype=float32), -1.2384992]. 
=============================================
[2019-04-24 10:50:18,235] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4838969e-01 2.8025001e-02 6.3884174e-15 6.5924181e-14 2.6215726e-14
 1.2913767e-15 3.4032719e-15 9.2610400e-16 1.6357281e-12 1.2358538e-01
 6.7357061e-16], sum to 1.0000
[2019-04-24 10:50:18,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0486
[2019-04-24 10:50:18,292] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 57.00000000000001, 0.0, 0.0, 19.0, 20.6421454688205, -0.9239565827391868, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2524800.0000, 
sim time next is 2526000.0000, 
raw observation next is [-2.3, 57.0, 0.0, 0.0, 19.0, 20.15894589557796, -1.042227626285686, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3988919667590028, 0.57, 0.0, 0.0, 0.08333333333333333, 0.1799121579648301, 0.15259079123810468, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.66702735], dtype=float32), -1.054288]. 
=============================================
[2019-04-24 10:50:20,087] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.8422716e-01 5.8782357e-03 3.5837951e-15 4.2528379e-14 1.4067932e-14
 1.0280596e-16 1.9527979e-16 6.3639195e-16 7.9438203e-13 1.0989466e-01
 4.9686810e-16], sum to 1.0000
[2019-04-24 10:50:20,088] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.8377
[2019-04-24 10:50:20,132] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 35.0, 0.0, 0.0, 22.5, 22.18331740453446, -0.4063315817524058, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2570400.0000, 
sim time next is 2571600.0000, 
raw observation next is [0.1333333333333334, 35.33333333333334, 0.0, 0.0, 22.5, 22.09093835979615, -0.4409460598091124, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.46629732225300097, 0.35333333333333344, 0.0, 0.0, 0.375, 0.3409115299830126, 0.3530179800636292, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.26921758], dtype=float32), 0.33182794]. 
=============================================
[2019-04-24 10:50:20,523] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.16159189e-01 7.46013504e-03 8.27675174e-16 9.44582767e-15
 5.49561795e-15 9.00027564e-17 2.44099119e-16 1.07140536e-16
 2.79499758e-13 1.76380768e-01 3.32426868e-16], sum to 1.0000
[2019-04-24 10:50:20,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6627
[2019-04-24 10:50:20,587] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.3, 29.0, 92.0, 256.5, 22.5, 21.90112063564939, -0.4832320544621818, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2563200.0000, 
sim time next is 2564400.0000, 
raw observation next is [3.1, 29.0, 77.33333333333333, 193.5, 22.5, 22.41232511139965, -0.4388610698990763, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5484764542936289, 0.29, 0.2577777777777778, 0.2138121546961326, 0.375, 0.3676937592833041, 0.35371297670030794, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.02143674], dtype=float32), 1.7195507]. 
=============================================
[2019-04-24 10:50:22,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6581548e-01 1.6335808e-03 2.4432672e-17 2.9730025e-16 1.3869167e-16
 1.6427672e-18 5.7920332e-18 1.2744102e-18 1.8497558e-14 3.2550979e-02
 7.8465964e-18], sum to 1.0000
[2019-04-24 10:50:22,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1084
[2019-04-24 10:50:22,697] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 53.83333333333334, 462.6666666666667, 22.5, 24.02723359640554, 0.03485050657291499, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3516000.0000, 
sim time next is 3517200.0000, 
raw observation next is [3.0, 49.0, 37.5, 338.0, 22.5, 24.014529718982, 0.01168254445964447, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.5457063711911359, 0.49, 0.125, 0.3734806629834254, 0.375, 0.5012108099151668, 0.5038941814865482, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.05465692], dtype=float32), 0.23293146]. 
=============================================
[2019-04-24 10:50:22,717] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.9523048e-01 4.5975622e-02 2.9276450e-14 5.7059155e-14 5.3056911e-14
 1.5389518e-14 1.3305517e-14 1.7671778e-15 7.7846497e-13 2.5879383e-01
 6.4406107e-15], sum to 1.0000
[2019-04-24 10:50:22,719] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.3636
[2019-04-24 10:50:22,755] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 66.33333333333333, 124.0, 375.0, 19.0, 19.59029986913108, -1.024653734782258, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2367600.0000, 
sim time next is 2368800.0000, 
raw observation next is [-2.8, 65.0, 130.0, 405.0, 19.0, 19.00910273131335, -1.095793643804091, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.38504155124653744, 0.65, 0.43333333333333335, 0.44751381215469616, 0.08333333333333333, 0.08409189427611263, 0.13473545206530302, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3394159], dtype=float32), 0.009567377]. 
=============================================
[2019-04-24 10:50:23,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3213394e-01 1.2374243e-02 5.5877489e-15 1.4110545e-14 1.2522943e-14
 4.7292338e-16 9.6109578e-16 4.7429282e-16 7.3685670e-13 4.5549178e-01
 5.6889846e-16], sum to 1.0000
[2019-04-24 10:50:23,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9261
[2019-04-24 10:50:23,869] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.266666666666667, 63.0, 164.0, 257.6666666666667, 22.5, 22.94214023920652, -0.4300612975342686, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2630400.0000, 
sim time next is 2631600.0000, 
raw observation next is [-3.9, 62.0, 188.0, 223.0, 22.5, 23.16119263362106, -0.1807611881263435, 1.0, 1.0, 60.0, 89.14834103362989], 
processed observation next is [1.0, 0.4782608695652174, 0.3545706371191136, 0.62, 0.6266666666666667, 0.24640883977900552, 0.375, 0.4300993861350883, 0.4397462706245521, 1.0, 1.0, 0.9, 0.8914834103362989], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9187976], dtype=float32), 1.0226375]. 
=============================================
[2019-04-24 10:50:25,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4811279e-01 9.2181079e-03 8.5366813e-16 4.3216625e-15 4.3698201e-15
 4.5798595e-17 1.1801158e-16 4.1696275e-17 2.8598600e-13 4.2669084e-02
 2.2977659e-16], sum to 1.0000
[2019-04-24 10:50:25,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4072
[2019-04-24 10:50:25,258] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.733333333333333, 51.66666666666667, 241.5, 151.0, 22.5, 23.72832864638894, -0.2268898872801854, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2636400.0000, 
sim time next is 2637600.0000, 
raw observation next is [-1.166666666666667, 49.33333333333334, 231.5, 157.6666666666667, 22.5, 23.17698737740024, -0.3362350053335665, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.43028624192059095, 0.4933333333333334, 0.7716666666666666, 0.17421731123388587, 0.375, 0.43141561478335344, 0.38792166488881114, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.09494513], dtype=float32), 0.4663]. 
=============================================
[2019-04-24 10:50:25,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3434442e-01 4.1690841e-03 1.3890826e-15 3.5767817e-15 6.3010311e-15
 3.9151868e-17 9.2095788e-17 7.4073905e-17 3.2794205e-13 2.6148647e-01
 1.4851710e-16], sum to 1.0000
[2019-04-24 10:50:25,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4782
[2019-04-24 10:50:25,712] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 88.33333333333333, 137.6666666666667, 22.5, 22.9302393056433, -0.2913920854103589, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2650800.0000, 
sim time next is 2652000.0000, 
raw observation next is [0.5, 50.0, 63.66666666666666, 117.0, 22.5, 23.00221592540193, -0.2937270046165463, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4764542936288089, 0.5, 0.2122222222222222, 0.1292817679558011, 0.375, 0.41685132711682754, 0.4020909984611512, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.02684286], dtype=float32), -1.0155095]. 
=============================================
[2019-04-24 10:50:29,462] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1118926e-01 5.1742671e-03 7.2657461e-15 6.7055980e-14 5.7260708e-14
 6.0973757e-16 1.4898104e-15 9.6578019e-16 5.9446454e-12 8.3636522e-02
 2.9849519e-15], sum to 1.0000
[2019-04-24 10:50:29,499] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5827
[2019-04-24 10:50:29,544] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 54.0, 0.0, 0.0, 22.5, 21.72944613824134, -0.5039180908635565, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2743200.0000, 
sim time next is 2744400.0000, 
raw observation next is [-4.333333333333334, 55.66666666666667, 0.0, 0.0, 22.5, 21.63524587231874, -0.5871146080282444, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3425669436749769, 0.5566666666666668, 0.0, 0.0, 0.375, 0.30293715602656174, 0.30429513065725183, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8103, 
noisyNet noise sample is [array([0.9608897], dtype=float32), 1.8952549]. 
=============================================
[2019-04-24 10:50:34,840] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.41822457e-01 1.22265145e-02 1.19854262e-15 1.52412042e-14
 3.75741105e-15 7.56531116e-17 3.29088844e-16 9.41572214e-17
 1.17287224e-12 3.45951080e-01 5.33300626e-16], sum to 1.0000
[2019-04-24 10:50:34,853] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8814
[2019-04-24 10:50:34,923] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.2333333333333333, 52.66666666666667, 0.0, 0.0, 22.5, 21.91856586653186, -0.3896603016385789, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2655600.0000, 
sim time next is 2656800.0000, 
raw observation next is [-0.6, 54.0, 0.0, 0.0, 22.5, 22.90009430004768, -0.02715282935967708, 1.0, 1.0, 60.0, 91.6898013855919], 
processed observation next is [1.0, 0.782608695652174, 0.44598337950138506, 0.54, 0.0, 0.0, 0.375, 0.40834119167064004, 0.49094905688010765, 1.0, 1.0, 0.9, 0.9168980138559191], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4644075], dtype=float32), 0.3582223]. 
=============================================
[2019-04-24 10:50:34,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8412082e-01 1.6708372e-02 2.8922006e-15 6.2660016e-15 1.9486632e-14
 6.0801682e-16 2.1289498e-15 3.2070316e-16 1.5540172e-12 4.9917084e-01
 6.2758069e-16], sum to 1.0000
[2019-04-24 10:50:34,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2166
[2019-04-24 10:50:35,045] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 49.0, 134.5, 39.0, 22.5, 22.59468565560746, -0.5865758489681167, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2541600.0000, 
sim time next is 2542800.0000, 
raw observation next is [-1.0, 48.33333333333334, 133.5, 43.0, 22.5, 22.18854601972749, -0.643057049831924, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.4349030470914128, 0.48333333333333345, 0.445, 0.04751381215469613, 0.375, 0.3490455016439575, 0.2856476500560253, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.4884, 
noisyNet noise sample is [array([0.18088897], dtype=float32), -0.32816583]. 
=============================================
[2019-04-24 10:50:39,099] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.7420067e-01 2.4759674e-03 1.1757828e-15 1.3245458e-14 1.5286222e-14
 3.9593311e-17 2.2880708e-16 4.0617077e-16 1.3673254e-12 2.3323391e-02
 5.5099641e-16], sum to 1.0000
[2019-04-24 10:50:39,101] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7409
[2019-04-24 10:50:39,170] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 59.0, 0.0, 0.0, 22.5, 21.85947350599784, -0.1614110473657299, 1.0, 1.0, 60.0, 141.85413233281702], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2746800.0000, 
sim time next is 2748000.0000, 
raw observation next is [-5.0, 59.0, 0.0, 0.0, 22.5, 23.20842208383831, -0.2799253399771199, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.32409972299168976, 0.59, 0.0, 0.0, 0.375, 0.4340351736531926, 0.4066915533409601, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4095396], dtype=float32), 0.18269783]. 
=============================================
[2019-04-24 10:50:43,503] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5458910e-01 9.9809967e-02 3.7189636e-13 4.7537251e-13 6.2314075e-13
 2.2388665e-14 5.3299924e-14 2.4478703e-14 4.7234859e-12 5.4560095e-01
 6.3327714e-14], sum to 1.0000
[2019-04-24 10:50:43,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3386
[2019-04-24 10:50:43,557] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 19.84680828373494, -1.061514573965155, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3034800.0000, 
sim time next is 3036000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 19.0384623434922, -1.209587183473928, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.08653852862434992, 0.09680427217535732, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.56872135], dtype=float32), 0.26360515]. 
=============================================
[2019-04-24 10:50:44,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.8843027e-01 4.2202134e-02 1.5873543e-14 1.7084287e-14 4.4554302e-14
 3.6550641e-15 2.9183540e-15 1.1906475e-15 6.1352296e-13 1.6936761e-01
 2.4890404e-15], sum to 1.0000
[2019-04-24 10:50:44,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4321
[2019-04-24 10:50:45,013] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 119.0, 90.5, 19.0, 20.79305630374012, -0.8279775230260222, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2970000.0000, 
sim time next is 2971200.0000, 
raw observation next is [-4.0, 71.0, 142.3333333333333, 118.1666666666667, 19.0, 20.1125394741826, -0.9466528243461921, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3518005540166205, 0.71, 0.4744444444444443, 0.13057090239410685, 0.08333333333333333, 0.1760449561818834, 0.18444905855126928, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.79436076], dtype=float32), -0.1859776]. 
=============================================
[2019-04-24 10:50:48,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.1112514e-01 5.9910811e-02 3.6605148e-17 1.2283058e-16 3.3592580e-16
 3.9367866e-18 3.1051103e-17 1.2424706e-18 6.6737328e-15 2.2896400e-01
 1.2595218e-17], sum to 1.0000
[2019-04-24 10:50:48,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8374
[2019-04-24 10:50:48,072] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.0, 90.66666666666667, 0.0, 0.0, 19.0, 20.74380002423497, -0.837787293947776, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2864400.0000, 
sim time next is 2865600.0000, 
raw observation next is [1.0, 93.0, 0.0, 0.0, 19.0, 20.42685742351708, -0.6783597081513748, 0.0, 1.0, 60.0, 88.64284312867517], 
processed observation next is [1.0, 0.17391304347826086, 0.4903047091412743, 0.93, 0.0, 0.0, 0.08333333333333333, 0.2022381186264234, 0.27388009728287505, 0.0, 1.0, 0.9, 0.8864284312867516], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23832221], dtype=float32), 1.5507499]. 
=============================================
[2019-04-24 10:50:48,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6416626e-01 2.7636787e-02 2.7702431e-14 1.0796311e-13 9.3730409e-14
 1.1232594e-14 1.5038384e-14 3.2933471e-15 2.6258292e-12 1.0819693e-01
 6.3602511e-14], sum to 1.0000
[2019-04-24 10:50:48,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4996
[2019-04-24 10:50:48,755] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 54.66666666666667, 111.5, 807.0, 19.0, 20.35135632972761, -0.8644257350776918, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3066000.0000, 
sim time next is 3067200.0000, 
raw observation next is [-3.0, 55.0, 112.5, 811.0, 19.0, 19.83550170932522, -0.924771284794406, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.375, 0.8961325966850828, 0.08333333333333333, 0.15295847577710178, 0.19174290506853134, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.00261917], dtype=float32), 1.2005638]. 
=============================================
[2019-04-24 10:50:52,510] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [8.32252800e-01 1.09285982e-02 4.70671010e-16 4.87207475e-16
 5.27712008e-16 2.83909165e-17 4.55212844e-17 2.30218559e-17
 6.90067781e-14 1.56818613e-01 1.02689503e-16], sum to 1.0000
[2019-04-24 10:50:52,511] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9591
[2019-04-24 10:50:52,525] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0628222e-01 4.8041310e-02 4.8443601e-15 7.5959679e-15 1.6357218e-14
 1.1334890e-15 3.3299341e-15 3.5984829e-16 2.8430359e-13 1.4567639e-01
 8.2183356e-16], sum to 1.0000
[2019-04-24 10:50:52,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3713
[2019-04-24 10:50:52,539] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 0.0, 0.0, 19.0, 20.43252277795792, -0.8176894015146221, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2949600.0000, 
sim time next is 2950800.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 19.80234869711524, -0.9576359519788601, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.15019572475960322, 0.18078801600704664, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.33266822], dtype=float32), 3.6003659]. 
=============================================
[2019-04-24 10:50:52,570] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.0, 85.0, 0.0, 0.0, 19.0, 19.97092945945914, -0.8113048802647128, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2935200.0000, 
sim time next is 2936400.0000, 
raw observation next is [-2.0, 85.0, 0.0, 0.0, 19.0, 20.32559223907784, -0.4853421024294068, 0.0, 1.0, 60.0, 100.90187469400328], 
processed observation next is [1.0, 1.0, 0.40720221606648205, 0.85, 0.0, 0.0, 0.08333333333333333, 0.19379935325648656, 0.3382192991901977, 0.0, 1.0, 0.9, 1.009018746940033], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4215424], dtype=float32), -2.2094972]. 
=============================================
[2019-04-24 10:50:53,712] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.9650393e-01 9.2668813e-03 1.7495940e-15 7.0380857e-15 1.1800770e-14
 7.9072101e-17 3.4093325e-16 9.5536469e-17 2.0402828e-13 9.4229221e-02
 5.7522314e-16], sum to 1.0000
[2019-04-24 10:50:53,715] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6497
[2019-04-24 10:50:53,750] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 20.66730273695212, -0.5585114782352899, 0.0, 1.0, 20.0, 80.37633887195311], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3370800.0000, 
sim time next is 3372000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 21.15376183867424, -0.652226294704143, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.2628134865561866, 0.282591235098619, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3428778], dtype=float32), 0.0014807257]. 
=============================================
[2019-04-24 10:50:56,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4914305e-01 4.4759447e-03 9.3728654e-18 7.8924174e-17 5.7282965e-17
 5.5311432e-19 2.1969257e-18 1.6658335e-18 1.4074862e-15 4.6380982e-02
 1.5968730e-18], sum to 1.0000
[2019-04-24 10:50:56,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5410
[2019-04-24 10:50:56,868] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 0.0, 0.0, 19.0, 22.52935562174486, -0.3601711975935809, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3451200.0000, 
sim time next is 3452400.0000, 
raw observation next is [1.0, 86.0, 0.0, 0.0, 19.0, 21.76973623806403, -0.5028189580675265, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4903047091412743, 0.86, 0.0, 0.0, 0.08333333333333333, 0.3141446865053359, 0.3323936806441578, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.6963253], dtype=float32), 1.2440779]. 
=============================================
[2019-04-24 10:50:58,246] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.75564682e-01 8.18725675e-02 1.01663524e-13 3.77024746e-13
 2.72597076e-13 1.27016707e-14 7.29098246e-14 7.15068179e-15
 3.35490316e-12 3.42562646e-01 1.89365193e-14], sum to 1.0000
[2019-04-24 10:50:58,246] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.6051
[2019-04-24 10:50:58,305] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-10.33333333333333, 76.0, 0.0, 0.0, 19.0, 19.44145111989477, -1.083210668304446, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 3302400.0000, 
sim time next is 3303600.0000, 
raw observation next is [-10.66666666666667, 76.0, 0.0, 0.0, 19.0, 19.03942565470296, -0.918004225997212, 0.0, 1.0, 20.0, 79.44929434520645], 
processed observation next is [1.0, 0.21739130434782608, 0.16712834718374878, 0.76, 0.0, 0.0, 0.08333333333333333, 0.08661880455858, 0.19399859133426267, 0.0, 1.0, 0.1, 0.7944929434520646], 
reward next is 0.1055, 
noisyNet noise sample is [array([0.29339573], dtype=float32), -1.1345102]. 
=============================================
[2019-04-24 10:51:01,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9720047e-01 5.3777043e-03 1.7072879e-17 1.6958969e-16 5.9132330e-17
 1.6025572e-18 6.5851191e-18 9.8828655e-19 9.4960516e-15 9.7421914e-02
 5.9618137e-18], sum to 1.0000
[2019-04-24 10:51:01,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2566
[2019-04-24 10:51:01,089] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 46.33333333333334, 115.3333333333333, 806.1666666666666, 22.5, 23.22284007097875, -0.2098254036045107, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3411600.0000, 
sim time next is 3412800.0000, 
raw observation next is [3.0, 45.0, 116.0, 810.5, 22.5, 23.24849567290997, -0.1991435298411266, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5457063711911359, 0.45, 0.38666666666666666, 0.8955801104972375, 0.375, 0.43737463940916427, 0.43361882338629115, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7485926], dtype=float32), 0.41744635]. 
=============================================
[2019-04-24 10:51:01,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9705229e-01 4.5893169e-03 2.0473875e-17 1.1145523e-16 6.0512609e-17
 5.4224481e-19 4.8745795e-18 4.2148169e-18 9.8772216e-15 9.8358326e-02
 3.7759335e-18], sum to 1.0000
[2019-04-24 10:51:01,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2341
[2019-04-24 10:51:01,412] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 88.0, 107.6666666666667, 735.5, 22.5, 23.03776451431663, -0.2006194391752895, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3234000.0000, 
sim time next is 3235200.0000, 
raw observation next is [-2.6, 84.0, 109.6666666666667, 761.8333333333334, 22.5, 22.96612695103047, -0.1998690181414405, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.3905817174515236, 0.84, 0.3655555555555557, 0.841804788213628, 0.375, 0.4138439125858726, 0.4333769939528532, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3531305], dtype=float32), 0.067931496]. 
=============================================
[2019-04-24 10:51:01,458] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.8734329e-01 1.9280029e-02 1.6607861e-14 8.9337453e-14 6.6332119e-14
 2.8437491e-14 1.9940192e-14 3.6665748e-15 2.6756188e-12 9.3376733e-02
 2.4367525e-14], sum to 1.0000
[2019-04-24 10:51:01,460] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.7886
[2019-04-24 10:51:01,476] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 54.66666666666667, 114.6666666666667, 817.1666666666666, 19.0, 19.93638133642628, -0.8096168671392872, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3584400.0000, 
sim time next is 3585600.0000, 
raw observation next is [-3.0, 55.0, 116.0, 819.5, 19.0, 19.7594086283427, -0.8343936146758212, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3795013850415513, 0.55, 0.38666666666666666, 0.905524861878453, 0.08333333333333333, 0.1466173856952251, 0.2218687951080596, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.0048326], dtype=float32), 0.4989753]. 
=============================================
[2019-04-24 10:51:03,525] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [5.9768581e-01 1.5534653e-02 6.1740454e-16 1.4969060e-16 1.6675965e-15
 1.4528226e-16 9.8308894e-17 1.1107009e-17 2.0652261e-14 3.8677958e-01
 6.5728857e-17], sum to 1.0000
[2019-04-24 10:51:03,534] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.5404
[2019-04-24 10:51:03,546] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.0, 28.0, 91.0, 446.3333333333334, 19.0, 19.58557215414832, -0.9969437942035618, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3660000.0000, 
sim time next is 3661200.0000, 
raw observation next is [11.0, 26.0, 95.0, 533.0, 19.0, 19.52313252216165, -0.9847389501957168, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.7673130193905818, 0.26, 0.31666666666666665, 0.5889502762430939, 0.08333333333333333, 0.12692771018013746, 0.1717536832680944, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.43783885], dtype=float32), -2.2709062]. 
=============================================
[2019-04-24 10:51:04,107] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0526241e-01 1.6680012e-02 6.6208403e-17 1.8565489e-16 4.0942764e-16
 2.3847811e-18 2.2968025e-17 4.9395582e-18 7.4190430e-15 7.8057587e-02
 1.2445174e-17], sum to 1.0000
[2019-04-24 10:51:04,108] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1440
[2019-04-24 10:51:04,122] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 0.0, 0.0, 19.0, 21.48604823814659, -0.4663961037739071, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3535200.0000, 
sim time next is 3536400.0000, 
raw observation next is [-1.0, 74.0, 0.0, 0.0, 19.0, 21.36317825134628, -0.5534469441052638, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.74, 0.0, 0.0, 0.08333333333333333, 0.28026485427885667, 0.31551768529824537, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5895352], dtype=float32), 1.1108923]. 
=============================================
[2019-04-24 10:51:05,492] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4264126e-01 3.1820012e-03 9.3449909e-17 4.4557469e-16 1.1625372e-16
 1.1689045e-17 1.2109560e-17 1.7395104e-18 1.3194710e-14 5.4176755e-02
 2.6770680e-17], sum to 1.0000
[2019-04-24 10:51:05,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0512
[2019-04-24 10:51:05,538] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 60.0, 102.8333333333333, 765.1666666666667, 22.5, 23.1444326221632, -0.1923628948220593, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3768000.0000, 
sim time next is 3769200.0000, 
raw observation next is [0.0, 60.0, 96.5, 743.5, 22.5, 23.25621457079007, -0.1711145912636158, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.46260387811634357, 0.6, 0.32166666666666666, 0.8215469613259668, 0.375, 0.4380178808991726, 0.44296180291212806, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.13831227], dtype=float32), -1.8404508]. 
=============================================
[2019-04-24 10:51:07,003] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4384360e-01 1.1203546e-02 1.4199992e-15 1.2017571e-14 1.4360016e-14
 2.7127535e-16 1.0173083e-15 5.3893387e-16 1.7124296e-13 4.4952869e-02
 1.1547639e-15], sum to 1.0000
[2019-04-24 10:51:07,003] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0096
[2019-04-24 10:51:07,028] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 19.81221801153547, -0.6822391499982462, 0.0, 1.0, 60.0, 100.0797383894431], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3378000.0000, 
sim time next is 3379200.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 20.70591108303697, -0.7861329553876706, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.2254925902530808, 0.23795568153744315, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.18583626], dtype=float32), 1.1792927]. 
=============================================
[2019-04-24 10:51:10,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4252012e-01 4.1169938e-02 1.4987894e-15 6.4535728e-15 1.1575922e-14
 3.7164637e-16 8.6233867e-16 4.2181060e-16 7.2947952e-13 1.1630997e-01
 8.9935555e-16], sum to 1.0000
[2019-04-24 10:51:10,713] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6086
[2019-04-24 10:51:10,728] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.333333333333333, 60.66666666666667, 0.0, 0.0, 19.0, 20.47031502813109, -0.8787894795216348, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3910800.0000, 
sim time next is 3912000.0000, 
raw observation next is [-6.666666666666666, 62.33333333333333, 0.0, 0.0, 19.0, 19.76134406673028, -1.000587107098556, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2779316712834719, 0.6233333333333333, 0.0, 0.0, 0.08333333333333333, 0.14677867222752342, 0.16647096430048136, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.15024766], dtype=float32), -1.4699908]. 
=============================================
[2019-04-24 10:51:11,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.5782275e-01 1.7148089e-02 2.4665393e-16 1.0778848e-15 6.2856875e-16
 2.6913385e-17 4.2747076e-17 4.4980063e-17 1.2266718e-13 2.2502926e-01
 9.7005006e-17], sum to 1.0000
[2019-04-24 10:51:11,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4062
[2019-04-24 10:51:11,104] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 69.0, 114.3333333333333, 813.1666666666666, 22.5, 23.03470787108095, -0.3483239717147595, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3756000.0000, 
sim time next is 3757200.0000, 
raw observation next is [-2.333333333333333, 67.0, 115.6666666666667, 823.1666666666666, 22.5, 22.87671990737621, -0.3592794903220839, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3979686057248385, 0.67, 0.38555555555555565, 0.9095764272559852, 0.375, 0.4063933256146841, 0.3802401698926387, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6577982], dtype=float32), -0.98926675]. 
=============================================
[2019-04-24 10:51:11,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3793205e-01 2.8276024e-02 2.3491678e-16 8.6126882e-16 1.1132135e-15
 1.6130366e-17 1.1696405e-16 1.7250650e-17 6.2751331e-14 1.3379195e-01
 1.1455876e-16], sum to 1.0000
[2019-04-24 10:51:11,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8736
[2019-04-24 10:51:11,642] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.0, 73.0, 75.0, 380.1666666666667, 22.5, 21.53726529941617, -0.6651989199946674, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3745200.0000, 
sim time next is 3746400.0000, 
raw observation next is [-4.0, 75.0, 90.83333333333334, 470.0, 22.5, 22.39205459355407, -0.2812028419609153, 1.0, 1.0, 60.0, 108.99083315117181], 
processed observation next is [1.0, 0.34782608695652173, 0.3518005540166205, 0.75, 0.3027777777777778, 0.5193370165745856, 0.375, 0.3660045494628393, 0.40626571934636163, 1.0, 1.0, 0.9, 1.0899083315117182], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17649637], dtype=float32), -0.75501865]. 
=============================================
[2019-04-24 10:51:16,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.9074624e-01 1.5478184e-02 5.1956723e-14 2.9581258e-13 1.6531570e-13
 9.2490941e-15 1.6056255e-14 1.4095360e-14 4.2569177e-12 9.3775600e-02
 8.8828320e-15], sum to 1.0000
[2019-04-24 10:51:16,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4421
[2019-04-24 10:51:16,057] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 39.66666666666666, 0.0, 0.0, 19.0, 21.11271145057229, -0.729142108905013, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4063200.0000, 
sim time next is 4064400.0000, 
raw observation next is [-6.0, 41.0, 0.0, 0.0, 19.0, 20.58076013742763, -0.809303769808063, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.296398891966759, 0.41, 0.0, 0.0, 0.08333333333333333, 0.21506334478563596, 0.2302320767306457, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.85809445], dtype=float32), 1.0371991]. 
=============================================
[2019-04-24 10:51:16,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:16,513] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:17,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:17,325] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:17,330] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run12
[2019-04-24 10:51:17,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1805990e-01 4.9932580e-02 7.1989412e-14 2.0363346e-13 4.3537816e-13
 5.1678522e-15 4.0054081e-14 6.8142441e-15 2.2174354e-12 2.3200743e-01
 6.8368188e-15], sum to 1.0000
[2019-04-24 10:51:17,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4890
[2019-04-24 10:51:17,551] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.333333333333334, 36.33333333333333, 0.0, 0.0, 19.0, 20.0305574195168, -1.006548501731937, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4077600.0000, 
sim time next is 4078800.0000, 
raw observation next is [-4.0, 34.0, 0.0, 0.0, 19.0, 19.52624287997144, -1.071444890851476, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.3518005540166205, 0.34, 0.0, 0.0, 0.08333333333333333, 0.12718690666428678, 0.142851703049508, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.28486967], dtype=float32), 0.8341783]. 
=============================================
[2019-04-24 10:51:18,247] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7436081e-01 1.2860402e-01 7.5334319e-13 4.3696336e-12 2.8590316e-12
 2.0666914e-13 4.9192096e-13 1.8039589e-13 7.3188094e-11 1.9703521e-01
 1.6987757e-13], sum to 1.0000
[2019-04-24 10:51:18,248] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7284
[2019-04-24 10:51:18,327] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [-12.0, 63.0, 0.0, 0.0, 19.0, 19.13423319160032, -1.146325121773015, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 20.0], 
sim time this is 3985200.0000, 
sim time next is 3986400.0000, 
raw observation next is [-12.0, 63.00000000000001, 0.0, 0.0, 19.0, 19.23436006457015, -0.9574635451987491, 0.0, 1.0, 20.0, 81.19911583669564], 
processed observation next is [1.0, 0.13043478260869565, 0.13019390581717452, 0.6300000000000001, 0.0, 0.0, 0.08333333333333333, 0.10286333871417923, 0.1808454849337503, 0.0, 1.0, 0.1, 0.8119911583669563], 
reward next is 0.0880, 
noisyNet noise sample is [array([-0.25741497], dtype=float32), -0.15782796]. 
=============================================
[2019-04-24 10:51:18,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1790010e-01 4.9173016e-02 4.8509146e-13 5.0441341e-13 1.4109194e-12
 7.4737776e-14 6.8375434e-14 6.1832050e-14 1.6845263e-11 2.3292693e-01
 8.1670171e-14], sum to 1.0000
[2019-04-24 10:51:18,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0346
[2019-04-24 10:51:18,424] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 37.0, 0.0, 0.0, 19.0, 19.1427760881102, -1.071818319261576, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4060800.0000, 
sim time next is 4062000.0000, 
raw observation next is [-6.0, 38.33333333333334, 0.0, 0.0, 19.0, 18.99212308045367, -1.107404094927553, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.296398891966759, 0.3833333333333334, 0.0, 0.0, 0.08333333333333333, 0.08267692337113915, 0.13086530169081567, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9998, 
noisyNet noise sample is [array([0.9799093], dtype=float32), 0.39490515]. 
=============================================
[2019-04-24 10:51:22,897] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.4067049e-01 3.3323718e-03 2.4013075e-15 2.5629902e-14 1.4183688e-14
 1.0151188e-15 9.0097995e-16 2.3106794e-16 1.1659230e-12 5.5997107e-02
 2.1785893e-15], sum to 1.0000
[2019-04-24 10:51:22,898] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7534
[2019-04-24 10:51:22,916] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 21.33333333333334, 85.33333333333334, 684.6666666666667, 22.5, 22.6111042687133, -0.3242128195329501, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4030800.0000, 
sim time next is 4032000.0000, 
raw observation next is [-1.0, 22.0, 78.0, 630.0, 22.5, 22.80942205957916, -0.2931532147390518, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4349030470914128, 0.22, 0.26, 0.6961325966850829, 0.375, 0.4007851716315966, 0.4022822617536494, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32603383], dtype=float32), -0.794294]. 
=============================================
[2019-04-24 10:51:22,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8977703e-01 3.6100638e-03 1.1219323e-15 1.0709520e-14 4.0760089e-15
 1.3629295e-15 3.8856747e-16 2.3798820e-16 2.4855695e-13 6.6129141e-03
 2.7384346e-15], sum to 1.0000
[2019-04-24 10:51:22,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0812
[2019-04-24 10:51:22,943] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 31.33333333333334, 118.1666666666667, 842.8333333333334, 19.0, 20.30960184734307, -0.5423804202233443, 0.0, 1.0, 60.0, 85.84949425955935], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4191600.0000, 
sim time next is 4192800.0000, 
raw observation next is [1.666666666666667, 32.66666666666666, 134.0, 817.3333333333334, 19.0, 21.47907050476487, -0.5789061914578896, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5087719298245615, 0.32666666666666655, 0.44666666666666666, 0.9031307550644567, 0.08333333333333333, 0.2899225420637392, 0.3070312695140368, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7021405], dtype=float32), -0.5444372]. 
=============================================
[2019-04-24 10:51:22,993] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.4303632e-01 3.0749878e-03 2.2271965e-15 2.4881752e-14 1.3980285e-14
 8.2973823e-16 8.3520662e-16 2.2573375e-16 1.1709999e-12 5.3888720e-02
 1.8502181e-15], sum to 1.0000
[2019-04-24 10:51:22,994] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4185
[2019-04-24 10:51:23,033] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 23.33333333333334, 59.16666666666667, 488.8333333333334, 22.5, 22.38444925489134, -0.3461812837690115, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4034400.0000, 
sim time next is 4035600.0000, 
raw observation next is [-2.0, 24.0, 43.5, 370.5, 22.5, 22.79261005866037, -0.3143431093612565, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.40720221606648205, 0.24, 0.145, 0.4093922651933702, 0.375, 0.39938417155503075, 0.3952189635462478, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.32603383], dtype=float32), -0.794294]. 
=============================================
[2019-04-24 10:51:23,062] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5284843e-01 2.8481637e-03 7.3624488e-17 3.4668484e-16 6.0207832e-16
 3.0537083e-18 2.6248113e-17 8.5974630e-18 5.8418521e-14 4.4303473e-02
 2.7889751e-17], sum to 1.0000
[2019-04-24 10:51:23,064] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0935
[2019-04-24 10:51:23,086] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 49.0, 0.0, 0.0, 22.5, 22.56362734156767, -0.3059530113659775, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3867600.0000, 
sim time next is 3868800.0000, 
raw observation next is [1.333333333333333, 50.0, 0.0, 0.0, 22.5, 22.26640105076382, -0.3441189271228666, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4995383194829178, 0.5, 0.0, 0.0, 0.375, 0.35553342089698514, 0.3852936909590445, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8875965], dtype=float32), -0.26927733]. 
=============================================
[2019-04-24 10:51:26,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6458451e-01 2.8371623e-02 9.9031746e-16 5.5433893e-15 4.8089834e-15
 1.1132989e-16 2.7826197e-16 1.1969085e-16 7.3412949e-14 1.0704388e-01
 1.9618544e-16], sum to 1.0000
[2019-04-24 10:51:26,553] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1432
[2019-04-24 10:51:26,577] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 73.0, 0.0, 0.0, 19.0, 21.20825657030256, -0.7276483513427011, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3811200.0000, 
sim time next is 3812400.0000, 
raw observation next is [-4.0, 71.0, 0.0, 0.0, 19.0, 20.27919812188444, -0.8801980932678988, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.3518005540166205, 0.71, 0.0, 0.0, 0.08333333333333333, 0.18993317682370345, 0.20660063557736708, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.58231455], dtype=float32), 0.31864503]. 
=============================================
[2019-04-24 10:51:28,498] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.6459264e-01 4.5008729e-03 7.2216817e-16 1.2117368e-14 1.2825641e-14
 1.5715037e-16 2.9143749e-16 2.6674523e-16 9.2223917e-13 3.0906493e-02
 2.7188508e-15], sum to 1.0000
[2019-04-24 10:51:28,500] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2032
[2019-04-24 10:51:28,510] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 28.0, 114.6666666666667, 831.8333333333334, 22.5, 23.31896832266319, -0.2250182261226337, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4022400.0000, 
sim time next is 4023600.0000, 
raw observation next is [-3.333333333333333, 27.0, 112.3333333333333, 824.0, 22.5, 23.21446159383005, -0.232035029827895, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.37026777469990774, 0.27, 0.37444444444444436, 0.9104972375690608, 0.375, 0.434538466152504, 0.42265499005736834, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8325663], dtype=float32), -0.93960124]. 
=============================================
[2019-04-24 10:51:29,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0641961e-01 2.4163293e-02 7.7348460e-16 2.2771386e-15 6.7258986e-15
 1.4178171e-16 2.0332082e-16 8.1418388e-17 1.1732587e-13 1.6941705e-01
 1.7065122e-16], sum to 1.0000
[2019-04-24 10:51:29,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6820
[2019-04-24 10:51:29,039] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 19.77742321440552, -0.8811771161197698, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3888000.0000, 
sim time next is 3889200.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 19.64010291347275, -0.9128724686984778, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.13667524278939572, 0.1957091771005074, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.34171078], dtype=float32), 0.78924936]. 
=============================================
[2019-04-24 10:51:30,864] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1946043e-01 3.2441907e-02 3.7992964e-16 8.2823602e-16 1.8582319e-15
 1.6742814e-17 1.1672066e-16 1.6708296e-17 2.6830255e-14 2.4809763e-01
 5.2535922e-17], sum to 1.0000
[2019-04-24 10:51:30,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2169
[2019-04-24 10:51:30,888] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 73.0, 0.0, 0.0, 19.0, 19.58966780981557, -0.9392661776545843, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4500000.0000, 
sim time next is 4501200.0000, 
raw observation next is [-0.7333333333333334, 73.0, 0.0, 0.0, 19.0, 19.49474121478131, -0.9629240191654415, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.44228993536472766, 0.73, 0.0, 0.0, 0.08333333333333333, 0.12456176789844253, 0.17902532694485285, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.98369527], dtype=float32), 1.6982149]. 
=============================================
[2019-04-24 10:51:31,230] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.6966131e-01 1.9066403e-02 5.8258622e-17 9.4472933e-17 4.5955243e-16
 1.5525168e-17 2.5331586e-17 8.5022231e-18 1.1047524e-14 2.1127228e-01
 2.6060931e-17], sum to 1.0000
[2019-04-24 10:51:31,231] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.6021
[2019-04-24 10:51:31,248] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.6, 71.66666666666667, 0.0, 0.0, 19.0, 20.78586838756146, -0.7638868574590587, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4304400.0000, 
sim time next is 4305600.0000, 
raw observation next is [5.4, 73.0, 0.0, 0.0, 19.0, 20.50488179744058, -0.8098066227943012, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.6121883656509697, 0.73, 0.0, 0.0, 0.08333333333333333, 0.20874014978671487, 0.2300644590685663, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.75130785], dtype=float32), 0.13313365]. 
=============================================
[2019-04-24 10:51:31,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1467494e-01 5.5847778e-03 8.0508352e-20 4.4327678e-19 7.6929270e-19
 6.2242861e-21 1.6702484e-20 1.2155499e-20 6.8210769e-17 7.9740301e-02
 1.7584028e-20], sum to 1.0000
[2019-04-24 10:51:31,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9840
[2019-04-24 10:51:31,390] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [10.0, 42.0, 111.0, 728.5, 22.5, 23.37732996909223, -0.2208850627606178, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4356000.0000, 
sim time next is 4357200.0000, 
raw observation next is [10.86666666666667, 39.33333333333334, 113.6666666666667, 762.8333333333333, 22.5, 24.0648085774149, 0.1166766179532868, 1.0, 1.0, 60.0, 82.82373756164922], 
processed observation next is [1.0, 0.43478260869565216, 0.7636195752539245, 0.3933333333333334, 0.378888888888889, 0.8429097605893185, 0.375, 0.505400714784575, 0.5388922059844289, 1.0, 1.0, 0.9, 0.8282373756164922], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6152757], dtype=float32), 0.13253264]. 
=============================================
[2019-04-24 10:51:31,905] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.5487300e-01 9.1068903e-03 6.9064796e-18 1.0872093e-17 1.9262709e-17
 7.9805698e-19 4.3285291e-19 1.6856361e-19 9.8421554e-16 1.3602012e-01
 9.4935529e-19], sum to 1.0000
[2019-04-24 10:51:31,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8663670e-01 3.0872351e-03 7.1054674e-18 1.3121664e-16 1.1415791e-16
 2.1765560e-18 1.4092365e-17 1.2890945e-18 3.9559861e-15 1.0276132e-02
 1.1440591e-17], sum to 1.0000
[2019-04-24 10:51:31,911] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8162
[2019-04-24 10:51:31,912] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7220
[2019-04-24 10:51:31,922] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.4, 73.0, 0.0, 0.0, 19.0, 21.6919180227133, -0.6357838556951653, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4326000.0000, 
sim time next is 4327200.0000, 
raw observation next is [4.5, 72.0, 0.0, 0.0, 19.0, 21.25978072542102, -0.7000044003794653, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5872576177285319, 0.72, 0.0, 0.0, 0.08333333333333333, 0.27164839378508504, 0.26666519987351156, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.27920404], dtype=float32), -0.6666581]. 
=============================================
[2019-04-24 10:51:31,949] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 73.0, 0.0, 0.0, 19.0, 20.85896910304506, -0.4591994489615085, 0.0, 1.0, 60.0, 99.78257333844891], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4498800.0000, 
sim time next is 4500000.0000, 
raw observation next is [-0.6, 73.0, 0.0, 0.0, 19.0, 21.59225855626226, -0.5922373346985901, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.44598337950138506, 0.73, 0.0, 0.0, 0.08333333333333333, 0.29935487968852154, 0.30258755510047, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6113285], dtype=float32), -1.6166503]. 
=============================================
[2019-04-24 10:51:31,969] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[79.34781 ]
 [78.37357 ]
 [78.543816]
 [78.869446]
 [79.04643 ]
 [77.835144]
 [78.319176]
 [78.68025 ]
 [78.56107 ]
 [78.49819 ]
 [78.60439 ]
 [78.577286]
 [79.43371 ]
 [79.14751 ]
 [79.037315]
 [79.509674]
 [79.89627 ]
 [81.14209 ]
 [79.93932 ]
 [79.87162 ]
 [80.217026]
 [80.053925]
 [80.96024 ]
 [81.59061 ]
 [82.319466]], R is [[79.45368195]
 [78.65914917]
 [78.87255859]
 [79.08383179]
 [79.29299164]
 [78.50006104]
 [78.71505737]
 [78.92790985]
 [79.13863373]
 [79.34725189]
 [79.5537796 ]
 [79.75823975]
 [79.96065521]
 [80.16104889]
 [80.35943604]
 [80.55583954]
 [80.75028229]
 [80.94277954]
 [80.13335419]
 [79.98345184]
 [79.99441528]
 [80.11147308]
 [80.31035614]
 [80.50725555]
 [80.70218658]].
[2019-04-24 10:51:35,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6874243e-01 1.7755653e-03 4.0811040e-18 2.6578560e-17 1.3395623e-17
 4.8912240e-20 5.3996148e-19 2.9129075e-19 2.0778616e-15 2.9481968e-02
 6.4345734e-19], sum to 1.0000
[2019-04-24 10:51:35,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3544
[2019-04-24 10:51:35,263] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 22.5, 23.56842411863997, -0.1161595115096933, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4472400.0000, 
sim time next is 4473600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 22.5, 23.10819217143493, -0.2179237986155753, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.46260387811634357, 0.72, 0.0, 0.0, 0.375, 0.4256826809529108, 0.4273587337948082, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9852178], dtype=float32), 1.1736934]. 
=============================================
[2019-04-24 10:51:38,394] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5167381e-01 9.0588694e-03 5.7928181e-16 1.1948555e-15 4.4179032e-15
 3.2997166e-16 4.2244447e-16 3.1504361e-17 8.2489191e-14 3.9267309e-02
 5.0329448e-16], sum to 1.0000
[2019-04-24 10:51:38,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2485
[2019-04-24 10:51:38,429] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 139.5, 739.5, 19.0, 19.92488677231839, -0.7835099810044551, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4804800.0000, 
sim time next is 4806000.0000, 
raw observation next is [3.0, 37.0, 122.5, 734.5, 19.0, 19.93029245139078, -0.7747165430988536, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5457063711911359, 0.37, 0.4083333333333333, 0.8116022099447514, 0.08333333333333333, 0.16085770428256504, 0.24176115230038212, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1095169], dtype=float32), 1.5539713]. 
=============================================
[2019-04-24 10:51:40,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8686373e-01 6.7459315e-04 2.6696241e-19 1.2500171e-17 4.2043825e-18
 2.9133324e-20 1.2895923e-19 2.5255624e-20 5.8324275e-16 1.2461713e-02
 5.1757389e-19], sum to 1.0000
[2019-04-24 10:51:40,295] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6424
[2019-04-24 10:51:40,308] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 43.0, 156.0, 138.0, 22.5, 24.4757332358644, 0.1102325771238784, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4636800.0000, 
sim time next is 4638000.0000, 
raw observation next is [5.733333333333333, 44.0, 130.0, 144.0, 22.5, 24.27686597915464, 0.07371633355030166, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.6214219759926132, 0.44, 0.43333333333333335, 0.1591160220994475, 0.375, 0.5230721649295532, 0.5245721111834339, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.73978156], dtype=float32), -2.4597046]. 
=============================================
[2019-04-24 10:51:41,864] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.0401204e-01 1.9918786e-02 6.6461527e-17 1.0951301e-16 9.1978884e-17
 5.0458154e-18 1.5393631e-17 3.9001152e-18 2.8984013e-15 2.7606919e-01
 4.8898629e-18], sum to 1.0000
[2019-04-24 10:51:41,866] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4472
[2019-04-24 10:51:41,913] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 19.0, 20.48708757743259, -0.7859244540191677, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4686000.0000, 
sim time next is 4687200.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 19.0, 20.2507890139614, -0.8398683881788465, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.4349030470914128, 1.0, 0.0, 0.0, 0.08333333333333333, 0.18756575116344987, 0.2200438706070512, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6338198], dtype=float32), 0.114483714]. 
=============================================
[2019-04-24 10:51:42,995] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.5351499e-01 8.7514138e-03 6.2719076e-18 5.4161176e-17 6.9665409e-17
 6.8197847e-19 1.5884022e-18 1.3441978e-18 4.7607330e-15 3.7733581e-02
 2.2321669e-18], sum to 1.0000
[2019-04-24 10:51:42,995] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1370
[2019-04-24 10:51:43,089] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.5333333333333334, 72.66666666666667, 92.5, 55.0, 22.5, 20.9170673848652, -0.3560885539295156, 1.0, 1.0, 60.0, 121.86667495310058], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4522800.0000, 
sim time next is 4524000.0000, 
raw observation next is [-0.2666666666666667, 72.33333333333334, 113.0, 55.0, 22.5, 22.99132508731751, -0.3733406047025318, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.4552169898430287, 0.7233333333333334, 0.37666666666666665, 0.06077348066298342, 0.375, 0.4159437572764591, 0.3755531317658227, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1185188], dtype=float32), -0.14706367]. 
=============================================
[2019-04-24 10:51:44,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4040514e-01 1.2722892e-02 4.3283129e-15 9.7803837e-15 7.6752468e-15
 1.7889027e-15 2.4902199e-15 2.8527307e-16 4.3900514e-13 2.4687198e-01
 3.3336938e-15], sum to 1.0000
[2019-04-24 10:51:44,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3709
[2019-04-24 10:51:44,408] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.133333333333333, 46.33333333333334, 281.3333333333334, 376.3333333333333, 19.0, 20.26205407970803, -0.8673464569295198, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4882800.0000, 
sim time next is 4884000.0000, 
raw observation next is [1.266666666666667, 45.66666666666667, 279.5, 389.6666666666666, 19.0, 20.09164230255059, -0.8931216219895425, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4976915974145891, 0.4566666666666667, 0.9316666666666666, 0.4305709023941067, 0.08333333333333333, 0.1743035252125491, 0.20229279267015252, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4966038], dtype=float32), -0.074590154]. 
=============================================
[2019-04-24 10:51:47,864] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:48,007] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:48,051] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:48,186] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:48,702] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:48,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:48,865] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:48,869] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run12
[2019-04-24 10:51:48,944] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:49,031] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:49,033] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:49,039] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run12
[2019-04-24 10:51:49,705] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:49,706] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:49,711] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run12
[2019-04-24 10:51:49,977] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:50,199] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:50,909] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:50,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:50,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:50,983] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run12
[2019-04-24 10:51:51,123] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:51,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:51,917] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:51,921] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run12
[2019-04-24 10:51:54,695] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:54,883] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:55,009] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:55,085] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:55,184] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:55,363] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:55,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.33512509e-01 1.15482239e-02 1.30953479e-14 2.44493299e-14
 4.84016920e-14 5.69668451e-15 1.26375384e-14 1.14208925e-15
 1.39793461e-12 5.49392961e-02 9.87619918e-15], sum to 1.0000
[2019-04-24 10:51:55,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8984
[2019-04-24 10:51:55,476] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 67.0, 0.0, 0.0, 19.0, 18.79259807887034, -0.9917033096373987, 0.0, 1.0, 60.0, 94.02165818697068], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4864800.0000, 
sim time next is 4866000.0000, 
raw observation next is [-4.0, 69.0, 23.5, 52.16666666666666, 19.0, 19.66611416910647, -1.078030856639834, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.3518005540166205, 0.69, 0.07833333333333334, 0.05764272559852669, 0.08333333333333333, 0.1388428474255393, 0.14065638112005532, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3253956], dtype=float32), -1.5436238]. 
=============================================
[2019-04-24 10:51:55,641] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:55,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:55,697] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:55,700] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run12
[2019-04-24 10:51:55,821] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:55,978] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:51:56,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:56,041] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:56,045] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run12
[2019-04-24 10:51:56,088] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:56,089] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:56,092] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run12
[2019-04-24 10:51:56,322] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:51:56,642] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:56,642] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:56,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run12
[2019-04-24 10:51:56,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:51:56,972] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:51:56,976] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run12
[2019-04-24 10:52:00,229] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5939850e-01 7.1595699e-02 1.6882646e-15 2.7312965e-15 4.7340604e-15
 2.6738323e-16 8.2011202e-16 1.4989230e-16 3.8945667e-13 2.6900584e-01
 3.6762005e-16], sum to 1.0000
[2019-04-24 10:52:00,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9024
[2019-04-24 10:52:00,469] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.3, 76.0, 0.0, 0.0, 19.0, 18.5646067606595, -1.388930930247774, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 716400.0000, 
sim time next is 717600.0000, 
raw observation next is [-2.3, 76.0, 0.0, 0.0, 22.5, 18.5403383264953, -1.053069826399664, 1.0, 1.0, 60.0, 113.25950423089634], 
processed observation next is [1.0, 0.30434782608695654, 0.3988919667590028, 0.76, 0.0, 0.0, 0.375, 0.04502819387460821, 0.14897672453344532, 1.0, 1.0, 0.9, 1.1325950423089635], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0614568], dtype=float32), -0.42993692]. 
=============================================
[2019-04-24 10:52:02,547] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:02,812] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:52:03,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:03,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:52:03,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:03,536] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run12
[2019-04-24 10:52:03,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:03,687] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:52:03,813] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:03,822] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,143] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:52:04,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:52:04,345] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:04,349] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run12
[2019-04-24 10:52:04,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:52:04,579] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:04,591] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run12
[2019-04-24 10:52:04,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:52:04,814] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:04,818] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run12
[2019-04-24 10:52:07,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3560693e-01 1.5085701e-02 4.7704710e-16 5.9906829e-16 3.6187200e-15
 4.2122373e-17 3.1973839e-16 1.6786670e-16 9.0083167e-14 1.4930744e-01
 5.1515024e-16], sum to 1.0000
[2019-04-24 10:52:07,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7716
[2019-04-24 10:52:07,017] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 0.0, 0.0, 19.0, 21.4259945757544, -0.596013281129003, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5018400.0000, 
sim time next is 5019600.0000, 
raw observation next is [0.3333333333333334, 45.0, 0.0, 0.0, 19.0, 21.1480139168761, -0.6353642319343732, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.4718374884579871, 0.45, 0.0, 0.0, 0.08333333333333333, 0.26233449307300827, 0.2882119226885423, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1854297], dtype=float32), 0.3933987]. 
=============================================
[2019-04-24 10:52:09,430] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_10 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:52:09,679] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_10 ERROR:Aborted (core dumped)

[2019-04-24 10:52:10,431] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 10:52:10,432] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:10,435] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run12
[2019-04-24 10:52:12,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8113246e-01 4.5995088e-03 1.9842382e-18 1.5067329e-18 3.1046034e-18
 6.1344623e-21 1.1448150e-19 2.5744129e-20 1.3839078e-16 2.1426801e-01
 7.1278948e-20], sum to 1.0000
[2019-04-24 10:52:12,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0762
[2019-04-24 10:52:12,562] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.600000000000001, 100.0, 0.0, 0.0, 22.5, 21.25349371856433, -0.6122572701883636, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 933600.0000, 
sim time next is 934800.0000, 
raw observation next is [4.8, 100.0, 0.0, 0.0, 22.5, 20.8966767742228, -0.6651263484826514, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.5955678670360112, 1.0, 0.0, 0.0, 0.375, 0.2413897311852334, 0.27829121717244953, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.94114685], dtype=float32), 1.316028]. 
=============================================
[2019-04-24 10:52:12,942] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-24 10:52:12,945] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:52:12,945] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:12,959] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:52:12,960] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:12,961] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run16
[2019-04-24 10:52:12,987] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:52:12,990] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:52:12,992] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run16
[2019-04-24 10:52:12,990] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run16
[2019-04-24 10:53:01,970] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.24017721], dtype=float32), 0.661357]
[2019-04-24 10:53:01,970] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [1.466666666666667, 98.66666666666666, 0.0, 0.0, 19.0, 20.42487132326161, -0.7368188479984639, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:53:01,970] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:53:01,971] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [7.6469272e-01 1.5537815e-02 2.9125264e-17 3.6497002e-17 1.1843110e-16
 4.0254492e-18 1.5886622e-17 1.2163277e-18 2.3749167e-15 2.1976951e-01
 4.7137731e-18], sampled 0.6941920716449812
[2019-04-24 10:54:18,709] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3435.0840 59172.3765 -291.7870
[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,755] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:18,965] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,276] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3175.4721 75390.1506 -536.5483
[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:32,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,052] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3115.2516 76376.8852 -616.1729
[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,113] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:46,399] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:54:47,116] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 750000, evaluation results [750000.0, 3175.472057312033, 75390.1505968719, -536.548265296555, 3435.084018416491, 59172.37645795153, -291.7869673962921, 3115.2516480849704, 76376.8852270139, -616.172939146764]
[2019-04-24 10:54:47,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.08193886e-01 1.20694805e-02 2.64355065e-15 1.84627145e-14
 3.08088482e-14 6.51972694e-16 2.72568765e-15 2.20888617e-16
 2.40784606e-13 7.97366351e-02 1.42453906e-15], sum to 1.0000
[2019-04-24 10:54:47,390] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1784
[2019-04-24 10:54:47,501] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.2, 96.0, 0.0, 0.0, 19.0, 21.8301161636435, -0.469210887143427, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 7200.0000, 
sim time next is 8400.0000, 
raw observation next is [7.200000000000001, 96.0, 0.0, 0.0, 19.0, 21.4102253469196, -0.558464316622401, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.662049861495845, 0.96, 0.0, 0.0, 0.08333333333333333, 0.2841854455766333, 0.313845227792533, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2739838], dtype=float32), 0.4657612]. 
=============================================
[2019-04-24 10:54:48,402] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [3.7942734e-01 2.8544055e-02 2.3905550e-14 1.6143496e-14 5.4572967e-14
 1.4637152e-15 7.2302089e-15 5.5020656e-16 9.0074909e-13 5.9202868e-01
 1.4444126e-15], sum to 1.0000
[2019-04-24 10:54:48,402] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1792
[2019-04-24 10:54:48,471] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 67.0, 0.0, 0.0, 19.0, 18.37698421822002, -1.342141136952198, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 262800.0000, 
sim time next is 264000.0000, 
raw observation next is [-6.9, 68.33333333333334, 0.0, 0.0, 19.0, 18.02231887454393, -1.409663265201846, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.27146814404432135, 0.6833333333333335, 0.0, 0.0, 0.08333333333333333, 0.0018599062119942407, 0.030112244932718024, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5862151], dtype=float32), -0.4523519]. 
=============================================
[2019-04-24 10:54:58,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2326797e-01 1.1803625e-02 3.7981649e-14 2.1855346e-13 5.2220039e-14
 2.6282924e-15 3.8909492e-15 5.7349840e-15 6.5272943e-12 2.6492840e-01
 5.4291314e-15], sum to 1.0000
[2019-04-24 10:54:58,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8490
[2019-04-24 10:54:58,392] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.700000000000001, 61.0, 133.5, 95.83333333333334, 22.5, 21.19677939543464, -0.6467855761584594, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 139200.0000, 
sim time next is 140400.0000, 
raw observation next is [-6.7, 61.0, 104.5, 75.5, 22.5, 22.44966231747409, -0.2810298182911846, 1.0, 1.0, 60.0, 126.81603384363189], 
processed observation next is [1.0, 0.6521739130434783, 0.2770083102493075, 0.61, 0.34833333333333333, 0.08342541436464089, 0.375, 0.3708051931228408, 0.4063233939029385, 1.0, 1.0, 0.9, 1.268160338436319], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46927842], dtype=float32), 0.058817737]. 
=============================================
[2019-04-24 10:55:00,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2516452e-01 7.5726863e-03 5.5758911e-19 4.6878393e-18 4.7567782e-18
 1.8616577e-19 1.8072738e-19 7.5530605e-20 4.6080938e-16 6.7262776e-02
 4.4457598e-19], sum to 1.0000
[2019-04-24 10:55:00,553] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6661
[2019-04-24 10:55:00,577] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.133333333333334, 98.66666666666667, 0.0, 0.0, 19.0, 22.01192023785867, -0.3276643401778919, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1293600.0000, 
sim time next is 1294800.0000, 
raw observation next is [4.766666666666667, 97.33333333333334, 0.0, 0.0, 19.0, 21.5252648114623, -0.4359375934608646, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5946445060018468, 0.9733333333333334, 0.0, 0.0, 0.08333333333333333, 0.2937720676218583, 0.35468746884637853, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5950775], dtype=float32), 0.7761625]. 
=============================================
[2019-04-24 10:55:02,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.6118803e-01 2.2490045e-02 3.8832219e-14 1.2538635e-13 9.6250814e-14
 2.2438371e-15 4.2139250e-15 2.9343405e-15 1.2824218e-12 2.1632189e-01
 5.4632185e-15], sum to 1.0000
[2019-04-24 10:55:02,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2387
[2019-04-24 10:55:02,342] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 0.0, 0.0, 19.0, 20.19274628965476, -0.98548270101249, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 186000.0000, 
sim time next is 187200.0000, 
raw observation next is [-8.9, 78.0, 0.0, 0.0, 19.0, 19.29629065621638, -1.136192495079944, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.21606648199445982, 0.78, 0.0, 0.0, 0.08333333333333333, 0.10802422135136514, 0.12126916830668533, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.11738551], dtype=float32), -0.15640569]. 
=============================================
[2019-04-24 10:55:05,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1429268e-01 4.4884682e-02 1.6395406e-17 2.7202238e-17 1.1192479e-16
 1.1315937e-18 5.4323490e-18 1.5695349e-18 3.6852498e-15 3.4082261e-01
 4.1382349e-18], sum to 1.0000
[2019-04-24 10:55:05,132] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8773
[2019-04-24 10:55:05,228] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.2, 96.66666666666667, 0.0, 0.0, 19.0, 20.32276773987821, -0.7217055961316041, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1394400.0000, 
sim time next is 1395600.0000, 
raw observation next is [-0.4, 98.33333333333333, 0.0, 0.0, 19.0, 20.7836677587845, -0.3969701561219217, 0.0, 1.0, 60.0, 98.84323717155192], 
processed observation next is [1.0, 0.13043478260869565, 0.45152354570637127, 0.9833333333333333, 0.0, 0.0, 0.08333333333333333, 0.23197231323204162, 0.36767661462602613, 0.0, 1.0, 0.9, 0.9884323717155192], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42338756], dtype=float32), -1.2401638]. 
=============================================
[2019-04-24 10:55:17,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0786725e-01 3.2779943e-02 1.2319921e-13 1.1121717e-13 1.5279023e-13
 2.1293683e-14 2.4556701e-14 8.4016122e-15 5.2712882e-12 5.5935287e-01
 1.5190013e-14], sum to 1.0000
[2019-04-24 10:55:17,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3189
[2019-04-24 10:55:17,209] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 62.0, 0.0, 0.0, 19.0, 19.29339589905285, -1.178101951106941, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 673200.0000, 
sim time next is 674400.0000, 
raw observation next is [-2.466666666666667, 63.0, 0.0, 0.0, 19.0, 18.72016030975827, -1.263803039225019, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.39427516158818104, 0.63, 0.0, 0.0, 0.08333333333333333, 0.06001335914652254, 0.078732320258327, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.6868, 
noisyNet noise sample is [array([-1.8109419], dtype=float32), 1.3221449]. 
=============================================
[2019-04-24 10:55:21,654] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [6.0406226e-01 3.2172978e-02 4.6412205e-14 1.2593426e-13 7.3610809e-14
 1.3444206e-15 3.5969915e-15 4.4979597e-15 4.8220807e-12 3.6376479e-01
 2.9791911e-15], sum to 1.0000
[2019-04-24 10:55:21,654] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2391
[2019-04-24 10:55:21,664] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.8, 32.66666666666666, 114.8333333333333, 0.0, 22.5, 21.90737416297943, -0.6307871600826925, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 481200.0000, 
sim time next is 482400.0000, 
raw observation next is [-0.6, 35.0, 106.5, 0.0, 22.5, 21.74918588129088, -0.6535965313375953, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.44598337950138506, 0.35, 0.355, 0.0, 0.375, 0.3124321567742401, 0.2821344895541349, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.4102, 
noisyNet noise sample is [array([1.0689073], dtype=float32), -0.86834717]. 
=============================================
[2019-04-24 10:55:27,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6316805e-01 3.1911515e-02 3.8949180e-14 3.6190275e-14 2.2213368e-14
 3.2907012e-15 3.4620435e-15 1.6764227e-15 1.6863701e-12 4.0492046e-01
 2.8823796e-15], sum to 1.0000
[2019-04-24 10:55:27,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2182
[2019-04-24 10:55:27,245] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.3, 87.0, 0.0, 0.0, 19.0, 19.14450658654861, -1.079838092062816, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 583200.0000, 
sim time next is 584400.0000, 
raw observation next is [-2.466666666666667, 87.0, 0.0, 0.0, 19.0, 18.89998816698635, -1.123687562005422, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.39427516158818104, 0.87, 0.0, 0.0, 0.08333333333333333, 0.07499901391552921, 0.12543747933152596, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9600, 
noisyNet noise sample is [array([0.43580687], dtype=float32), -0.043875255]. 
=============================================
[2019-04-24 10:55:32,632] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.5539707e-01 6.4883190e-03 6.2531701e-20 6.9282094e-19 1.7317476e-18
 2.7934665e-20 2.8470636e-20 3.0729656e-20 5.1871934e-17 3.8114585e-02
 5.2408477e-20], sum to 1.0000
[2019-04-24 10:55:32,632] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6431
[2019-04-24 10:55:32,670] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.7, 80.0, 0.0, 0.0, 19.0, 21.05751521357845, -0.3569160392132073, 0.0, 1.0, 60.0, 92.61970744332199], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 961200.0000, 
sim time next is 962400.0000, 
raw observation next is [7.7, 81.0, 0.0, 0.0, 19.0, 21.99211127355371, -0.4356781430433652, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.6759002770083103, 0.81, 0.0, 0.0, 0.08333333333333333, 0.3326759394628092, 0.35477395231887826, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9605587], dtype=float32), -0.024417883]. 
=============================================
[2019-04-24 10:55:44,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8283225e-01 6.7565555e-04 1.3050689e-16 1.0502943e-15 1.4745620e-15
 7.6691495e-17 3.6932542e-17 2.3017124e-17 4.1314452e-14 1.6492087e-02
 2.0049269e-16], sum to 1.0000
[2019-04-24 10:55:44,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7920
[2019-04-24 10:55:44,050] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.7, 67.0, 0.0, 0.0, 19.0, 22.58991667663179, -0.1263744402886629, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1191600.0000, 
sim time next is 1192800.0000, 
raw observation next is [17.7, 67.0, 0.0, 0.0, 19.0, 22.53721191550441, -0.134943311862579, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.9529085872576178, 0.67, 0.0, 0.0, 0.08333333333333333, 0.3781009929587009, 0.45501889604580703, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.266642], dtype=float32), 0.06764405]. 
=============================================
[2019-04-24 10:55:47,580] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9545920e-01 6.4396311e-04 8.5967154e-19 1.8391388e-17 2.3659013e-17
 7.4983602e-19 5.1749763e-19 4.0981316e-20 1.1015829e-15 3.8967947e-03
 2.8498277e-18], sum to 1.0000
[2019-04-24 10:55:47,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3533
[2019-04-24 10:55:47,609] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 65.0, 145.0, 0.0, 19.0, 23.00782601856617, 0.1017831397845349, 0.0, 0.0, 60.0, 83.00669852217331], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1162800.0000, 
sim time next is 1164000.0000, 
raw observation next is [18.46666666666667, 64.33333333333334, 155.0, 0.0, 19.0, 23.82320484647989, 0.04266816492162404, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.9741458910433982, 0.6433333333333334, 0.5166666666666667, 0.0, 0.08333333333333333, 0.4852670705399908, 0.5142227216405414, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.4159889], dtype=float32), -0.9416872]. 
=============================================
[2019-04-24 10:55:49,716] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8909551e-01 4.0237361e-04 4.3129250e-21 2.9139133e-19 1.6533077e-19
 2.2632780e-21 7.2733329e-21 1.5300150e-21 1.3494741e-17 1.0502051e-02
 1.3009369e-20], sum to 1.0000
[2019-04-24 10:55:49,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8944
[2019-04-24 10:55:49,727] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.0, 63.0, 80.0, 682.0, 22.5, 25.06269343590523, 0.2241253738042498, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1519200.0000, 
sim time next is 1520400.0000, 
raw observation next is [10.53333333333333, 59.33333333333334, 76.66666666666666, 669.3333333333333, 22.5, 24.92040055587625, 0.1881900600574179, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.7543859649122806, 0.5933333333333334, 0.25555555555555554, 0.7395948434622467, 0.375, 0.5767000463230207, 0.5627300200191393, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.5930176], dtype=float32), -3.0186734]. 
=============================================
[2019-04-24 10:55:49,909] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.01877582e-01 7.78773846e-03 1.02625310e-18 9.56223270e-18
 1.01762646e-17 1.91528915e-19 3.52063320e-19 2.46783184e-19
 8.85294431e-16 9.03346464e-02 1.49542395e-18], sum to 1.0000
[2019-04-24 10:55:49,911] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.2797
[2019-04-24 10:55:49,932] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.6, 85.0, 0.0, 0.0, 19.0, 21.22526193085988, -0.5491236948297633, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1569600.0000, 
sim time next is 1570800.0000, 
raw observation next is [4.633333333333334, 84.66666666666667, 0.0, 0.0, 19.0, 21.05902853730968, -0.5893235467745072, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5909510618651893, 0.8466666666666667, 0.0, 0.0, 0.08333333333333333, 0.25491904477580657, 0.30355881774183097, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.21631923], dtype=float32), 0.84909415]. 
=============================================
[2019-04-24 10:55:53,701] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4768691e-01 2.3373645e-03 4.0541127e-18 2.4571541e-17 2.1149936e-17
 4.5722651e-19 6.9641106e-19 2.9780684e-19 2.8956465e-15 4.9975682e-02
 1.5478635e-18], sum to 1.0000
[2019-04-24 10:55:53,702] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.4817
[2019-04-24 10:55:53,721] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 19.0, 21.51333124911732, -0.4228196554402158, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1375200.0000, 
sim time next is 1376400.0000, 
raw observation next is [0.3333333333333334, 95.66666666666666, 0.0, 0.0, 19.0, 21.21088734813204, -0.5355731640049015, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4718374884579871, 0.9566666666666666, 0.0, 0.0, 0.08333333333333333, 0.26757394567767, 0.32147561199836616, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9304199], dtype=float32), -0.33957675]. 
=============================================
[2019-04-24 10:55:55,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0837806e-01 5.3150058e-03 8.0210802e-18 4.6828531e-17 2.0043056e-17
 4.6474874e-19 8.9210612e-19 5.1394748e-19 8.9292163e-15 8.6306892e-02
 1.0975855e-18], sum to 1.0000
[2019-04-24 10:55:55,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3870
[2019-04-24 10:55:55,380] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 22.79995584122592, -0.221703419933072, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1713600.0000, 
sim time next is 1714800.0000, 
raw observation next is [0.9000000000000001, 89.33333333333334, 0.0, 0.0, 19.0, 22.22823211155976, -0.2978013422113578, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.48753462603878117, 0.8933333333333334, 0.0, 0.0, 0.08333333333333333, 0.35235267596331327, 0.4007328859295474, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.4602545], dtype=float32), 2.7307925]. 
=============================================
[2019-04-24 10:55:56,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5565188e-01 3.3704385e-02 3.5271319e-14 2.9185845e-14 2.0638900e-14
 1.7827096e-15 1.3246640e-14 1.6862265e-15 1.3001917e-12 5.1064378e-01
 2.2329161e-15], sum to 1.0000
[2019-04-24 10:55:56,424] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3875
[2019-04-24 10:55:56,437] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 85.66666666666667, 93.5, 0.0, 19.0, 18.20520333273085, -1.227054489426644, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1780800.0000, 
sim time next is 1782000.0000, 
raw observation next is [-2.8, 87.0, 82.5, 0.0, 19.0, 18.03460646525428, -1.261636836494238, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.38504155124653744, 0.87, 0.275, 0.0, 0.08333333333333333, 0.002883872104523455, 0.07945438783525398, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9392643], dtype=float32), -1.6198463]. 
=============================================
[2019-04-24 10:55:57,265] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5349526e-01 2.0620385e-03 2.6042621e-19 1.1706852e-18 1.4924080e-18
 5.7831824e-21 3.2865731e-20 4.2531390e-21 1.7868823e-16 4.4442765e-02
 4.2140749e-20], sum to 1.0000
[2019-04-24 10:55:57,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5007
[2019-04-24 10:55:57,296] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.4, 61.0, 0.0, 0.0, 22.5, 23.36473983059489, -0.05273166213262206, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1537200.0000, 
sim time next is 1538400.0000, 
raw observation next is [8.666666666666668, 65.0, 0.0, 0.0, 22.5, 23.17046012433262, -0.0816821749383304, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.7026777469990768, 0.65, 0.0, 0.0, 0.375, 0.4308716770277184, 0.4727726083538899, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2937611], dtype=float32), 1.7482249]. 
=============================================
[2019-04-24 10:55:57,957] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.6702296e-01 2.0862937e-03 1.7986897e-20 1.8292474e-19 1.5146378e-19
 2.1084226e-21 3.4281745e-21 1.8034157e-21 3.2407262e-17 3.0890742e-02
 1.5917706e-20], sum to 1.0000
[2019-04-24 10:55:57,960] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2864
[2019-04-24 10:55:57,988] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.3, 51.0, 64.0, 18.5, 22.5, 24.06414563371066, 0.08185234930525852, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1612800.0000, 
sim time next is 1614000.0000, 
raw observation next is [12.93333333333334, 52.00000000000001, 54.66666666666667, 30.83333333333334, 22.5, 24.45514669687058, 0.1231850629946568, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8208679593721148, 0.52, 0.18222222222222223, 0.03406998158379374, 0.375, 0.5379288914058818, 0.5410616876648856, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.12511359], dtype=float32), -0.16959319]. 
=============================================
[2019-04-24 10:55:59,881] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.3590790e-01 3.6103425e-03 1.2595391e-18 3.9005627e-18 9.1071105e-18
 1.1803372e-19 5.6494053e-19 3.9289922e-20 5.8468509e-16 6.0481727e-02
 8.7773789e-20], sum to 1.0000
[2019-04-24 10:55:59,883] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.2074
[2019-04-24 10:55:59,905] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 74.5, 0.0, 22.5, 24.04412491902274, -0.06476115392285257, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1681200.0000, 
sim time next is 1682400.0000, 
raw observation next is [1.1, 89.33333333333334, 80.16666666666667, 0.0, 22.5, 23.41119333268696, -0.188830941142137, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.49307479224376743, 0.8933333333333334, 0.26722222222222225, 0.0, 0.375, 0.4509327777239133, 0.437056352952621, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.97922444], dtype=float32), 0.7870701]. 
=============================================
[2019-04-24 10:56:10,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4025663e-01 2.1176541e-02 7.8565680e-14 2.8443984e-13 4.0729987e-13
 2.8272510e-14 5.5630925e-14 1.0906136e-14 4.0301425e-12 1.3856679e-01
 4.4452096e-14], sum to 1.0000
[2019-04-24 10:56:10,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8214
[2019-04-24 10:56:10,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.133333333333333, 85.66666666666667, 0.0, 0.0, 19.0, 18.8268558633423, -1.036604942399132, 0.0, 1.0, 60.0, 91.01169838854626], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1824000.0000, 
sim time next is 1825200.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 19.0, 19.14922835764835, -1.195236946091844, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.09576902980402924, 0.10158768463605201, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8394766], dtype=float32), -0.47210833]. 
=============================================
[2019-04-24 10:56:12,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5726225e-01 5.3929839e-02 8.9456430e-14 6.7843355e-14 7.4793849e-14
 2.8300082e-15 1.4251423e-14 4.0903344e-15 2.9222369e-12 5.8880794e-01
 7.1042801e-15], sum to 1.0000
[2019-04-24 10:56:12,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8441
[2019-04-24 10:56:12,473] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-8.9, 86.0, 59.0, 285.0, 22.5, 20.15837980900691, -0.8363568007670646, 1.0, 1.0, 60.0, 115.25492482617888], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1933200.0000, 
sim time next is 1934400.0000, 
raw observation next is [-8.366666666666667, 83.66666666666667, 76.33333333333334, 461.0, 22.5, 21.71978748890402, -0.616926145907445, 1.0, 1.0, 60.0, 75.77689082763061], 
processed observation next is [1.0, 0.391304347826087, 0.23084025854108958, 0.8366666666666667, 0.2544444444444445, 0.5093922651933702, 0.375, 0.3099822907420018, 0.294357951364185, 1.0, 1.0, 0.9, 0.757768908276306], 
reward next is 0.5846, 
noisyNet noise sample is [array([-0.65494686], dtype=float32), 0.9614302]. 
=============================================
[2019-04-24 10:56:14,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2873189e-01 2.6599407e-02 1.0285412e-14 7.6860156e-14 1.1047825e-13
 2.5519243e-15 3.0703977e-15 2.2859075e-15 8.8044708e-13 1.4466876e-01
 4.3138143e-15], sum to 1.0000
[2019-04-24 10:56:14,967] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4530
[2019-04-24 10:56:14,996] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 0.0, 0.0, 19.0, 20.27954727229531, -0.9465909378073974, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2185200.0000, 
sim time next is 2186400.0000, 
raw observation next is [-5.6, 75.0, 0.0, 0.0, 22.5, 19.62300203292484, -1.08927785865502, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.30747922437673136, 0.75, 0.0, 0.0, 0.375, 0.13525016941040344, 0.13690738044832665, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35942373], dtype=float32), -1.0185348]. 
=============================================
[2019-04-24 10:56:22,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4586819e-01 3.4750481e-03 7.2539388e-16 7.7665366e-15 1.8958514e-15
 2.8268017e-17 1.5332522e-16 9.1399037e-17 3.8033631e-13 5.0656807e-02
 2.3408931e-16], sum to 1.0000
[2019-04-24 10:56:22,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1817
[2019-04-24 10:56:22,801] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.2, 52.0, 0.0, 0.0, 22.5, 23.22473034759038, -0.04579014313279087, 1.0, 1.0, 60.0, 83.43530598334922], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2311200.0000, 
sim time next is 2312400.0000, 
raw observation next is [-1.2, 52.66666666666667, 0.0, 0.0, 22.5, 23.67035948198167, -0.1985692349351447, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.42936288088642666, 0.5266666666666667, 0.0, 0.0, 0.375, 0.4725299568318058, 0.43381025502161846, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5540214], dtype=float32), 1.3535675]. 
=============================================
[2019-04-24 10:56:22,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2514859e-01 1.2716559e-02 1.5932668e-19 7.4503661e-19 1.7923844e-18
 1.2451091e-20 1.1812545e-19 5.9571670e-21 6.4718366e-17 3.6213481e-01
 1.4418029e-20], sum to 1.0000
[2019-04-24 10:56:22,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9771
[2019-04-24 10:56:23,025] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [6.666666666666666, 100.0, 85.66666666666667, 434.5, 22.5, 22.52294044891655, -0.2327984598415085, 1.0, 1.0, 60.0, 108.92016676335733], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3141600.0000, 
sim time next is 3142800.0000, 
raw observation next is [7.0, 100.0, 91.0, 519.5, 22.5, 23.94136330682466, -0.02576404421049243, 1.0, 1.0, 60.0, 70.24163045404441], 
processed observation next is [1.0, 0.391304347826087, 0.6565096952908588, 1.0, 0.30333333333333334, 0.5740331491712707, 0.375, 0.4951136089020549, 0.49141198526316915, 1.0, 1.0, 0.9, 0.7024163045404441], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2674836], dtype=float32), 0.07081753]. 
=============================================
[2019-04-24 10:56:28,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.62178653e-01 5.81821539e-02 6.81621304e-14 1.86706458e-13
 2.22168136e-13 6.86631631e-15 3.22339506e-14 2.57836423e-14
 2.36952905e-12 5.79639196e-01 1.26843955e-14], sum to 1.0000
[2019-04-24 10:56:28,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2363
[2019-04-24 10:56:28,691] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-9.266666666666667, 76.66666666666667, 0.0, 0.0, 19.0, 19.82079865185549, -0.9714860330775071, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3298800.0000, 
sim time next is 3300000.0000, 
raw observation next is [-9.633333333333333, 76.33333333333333, 0.0, 0.0, 19.0, 19.11440010301459, -1.08534031312196, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.19575253924284397, 0.7633333333333333, 0.0, 0.0, 0.08333333333333333, 0.09286667525121572, 0.1382198956260133, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0012803], dtype=float32), -0.30272654]. 
=============================================
[2019-04-24 10:56:28,717] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.08135 ]
 [64.52808 ]
 [65.19944 ]
 [65.32691 ]
 [65.13171 ]
 [65.26502 ]
 [64.615005]
 [65.244576]
 [65.74059 ]
 [66.30004 ]
 [67.00457 ]
 [67.91269 ]
 [67.62598 ]
 [67.96947 ]
 [68.729164]
 [69.211555]
 [69.644554]
 [69.350655]
 [69.85461 ]
 [69.746376]
 [69.30951 ]
 [69.3942  ]
 [69.03606 ]
 [69.1645  ]
 [69.46165 ]], R is [[63.87134933]
 [64.2326355 ]
 [64.59030914]
 [64.44717407]
 [63.97962952]
 [64.33982849]
 [63.69643021]
 [64.0594635 ]
 [64.41886902]
 [64.77468109]
 [65.12693787]
 [65.47566986]
 [64.84057617]
 [65.19216919]
 [65.54024506]
 [65.88484192]
 [66.22599792]
 [66.56373596]
 [66.89810181]
 [67.22911835]
 [67.55683136]
 [67.88126373]
 [68.20245361]
 [68.52043152]
 [68.83522797]].
[2019-04-24 10:56:29,410] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8091919e-01 7.7834152e-02 1.6118324e-14 2.4395084e-14 2.0653040e-14
 5.5274771e-16 2.6123716e-15 1.9172983e-15 1.0167881e-12 5.4124665e-01
 1.5994225e-15], sum to 1.0000
[2019-04-24 10:56:29,411] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6898
[2019-04-24 10:56:29,605] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.6, 75.0, 34.50000000000001, 218.3333333333333, 22.5, 21.93998446522995, -0.6295222948786685, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2190000.0000, 
sim time next is 2191200.0000, 
raw observation next is [-5.6, 75.0, 51.16666666666667, 293.5, 22.5, 22.39041643988173, -0.3485171137182411, 1.0, 1.0, 60.0, 98.48588472434761], 
processed observation next is [1.0, 0.34782608695652173, 0.30747922437673136, 0.75, 0.17055555555555557, 0.3243093922651934, 0.375, 0.3658680366568108, 0.38382762876058624, 1.0, 1.0, 0.9, 0.9848588472434762], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34353158], dtype=float32), 0.11040072]. 
=============================================
[2019-04-24 10:56:29,650] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [8.4413543e-02 2.0095972e-02 3.9803507e-13 8.6202868e-14 2.1773405e-13
 1.3973217e-14 3.6408532e-14 1.2079257e-14 1.9264403e-12 8.9549047e-01
 8.4508265e-15], sum to 1.0000
[2019-04-24 10:56:29,652] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.3774
[2019-04-24 10:56:29,723] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-9.3, 91.0, 0.0, 0.0, 19.0, 18.48133044638845, -1.300313374790688, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2270400.0000, 
sim time next is 2271600.0000, 
raw observation next is [-9.5, 91.0, 0.0, 0.0, 19.0, 18.55306352283262, -1.039428856197347, 0.0, 1.0, 60.0, 100.6508301027795], 
processed observation next is [1.0, 0.30434782608695654, 0.1994459833795014, 0.91, 0.0, 0.0, 0.08333333333333333, 0.04608862690271831, 0.15352371460088432, 0.0, 1.0, 0.9, 1.0065083010277949], 
reward next is 0.4155, 
noisyNet noise sample is [array([-1.3421917], dtype=float32), -0.29394805]. 
=============================================
[2019-04-24 10:56:30,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.41675484e-01 1.15693705e-02 3.05691345e-14 1.82127750e-13
 1.97755495e-13 2.73913345e-14 1.09713230e-14 3.58197867e-15
 7.20186757e-12 4.67551611e-02 7.20587191e-14], sum to 1.0000
[2019-04-24 10:56:30,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4026
[2019-04-24 10:56:30,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1333333333333333, 30.0, 89.33333333333333, 842.3333333333334, 19.0, 20.85644620015439, -0.8055509718660857, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2463600.0000, 
sim time next is 2464800.0000, 
raw observation next is [0.8666666666666667, 29.0, 89.5, 842.8333333333334, 19.0, 20.37456600420824, -0.8914249408661995, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.4866112650046169, 0.29, 0.29833333333333334, 0.9313075506445673, 0.08333333333333333, 0.19788050035068672, 0.20285835304460018, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.01715861], dtype=float32), -1.6513437]. 
=============================================
[2019-04-24 10:56:33,922] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.0589759e-01 3.2393653e-02 6.4006871e-14 5.9997261e-14 6.7734575e-14
 2.7431560e-15 6.5544345e-15 3.4668804e-15 1.3064683e-12 6.6170865e-01
 5.1399264e-15], sum to 1.0000
[2019-04-24 10:56:33,924] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2016
[2019-04-24 10:56:33,987] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.4, 87.0, 73.0, 27.5, 22.5, 22.22812785703149, -0.6503392407418314, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2278800.0000, 
sim time next is 2280000.0000, 
raw observation next is [-7.833333333333334, 84.0, 91.66666666666667, 35.16666666666666, 22.5, 21.67047599500868, -0.7566229059790953, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.2456140350877193, 0.84, 0.3055555555555556, 0.038858195211786364, 0.375, 0.3058729995840566, 0.24779236467363489, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29765633], dtype=float32), 0.4345299]. 
=============================================
[2019-04-24 10:56:33,996] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[66.55809 ]
 [66.48666 ]
 [65.81493 ]
 [66.00785 ]
 [64.87404 ]
 [64.79722 ]
 [64.63461 ]
 [65.05914 ]
 [64.638054]
 [65.01715 ]
 [65.44729 ]
 [65.83356 ]
 [65.289955]
 [65.69424 ]
 [66.04999 ]
 [66.450775]
 [66.85347 ]
 [66.33962 ]
 [66.64289 ]
 [66.54676 ]
 [66.56648 ]
 [66.38482 ]
 [65.61896 ]
 [65.78569 ]
 [66.145355]], R is [[65.78373718]
 [65.56085205]
 [65.17985535]
 [64.52806091]
 [64.88278198]
 [64.23395538]
 [63.59161758]
 [63.95570374]
 [63.31614685]
 [63.51940918]
 [63.88421631]
 [64.24537659]
 [63.60292435]
 [63.73767471]
 [64.10029602]
 [64.45928955]
 [64.81469727]
 [64.16654968]
 [64.52488708]
 [64.87963867]
 [65.23084259]
 [64.57853699]
 [63.9327507 ]
 [64.29342651]
 [64.65049744]].
[2019-04-24 10:56:35,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0903244e-01 1.4189310e-02 2.5875327e-14 1.7472328e-14 1.8876604e-14
 6.3230597e-16 7.3866551e-16 2.1645671e-15 7.2912298e-13 6.7677826e-01
 4.2255361e-16], sum to 1.0000
[2019-04-24 10:56:35,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0282
[2019-04-24 10:56:35,964] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.133333333333335, 71.66666666666667, 90.33333333333333, 75.83333333333334, 22.5, 22.39400005016542, -0.3743057828329684, 1.0, 1.0, 20.0, 86.39848478922828], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2625600.0000, 
sim time next is 2626800.0000, 
raw observation next is [-5.566666666666666, 68.33333333333333, 102.8333333333333, 121.6666666666667, 22.5, 22.97263571850927, -0.4423727129796211, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.3084025854108957, 0.6833333333333332, 0.3427777777777777, 0.134438305709024, 0.375, 0.4143863098757725, 0.35254242900679295, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.07027752], dtype=float32), 0.4835902]. 
=============================================
[2019-04-24 10:56:36,889] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4183739e-01 2.6558414e-02 4.9419507e-13 5.4292654e-13 8.0930076e-13
 1.1573382e-13 3.7114875e-13 4.1975378e-14 1.2218440e-11 4.3160418e-01
 1.3457971e-13], sum to 1.0000
[2019-04-24 10:56:36,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2918
[2019-04-24 10:56:36,906] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 38.0, 0.0, 0.0, 19.0, 18.89564968931678, -1.224732542058835, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2505600.0000, 
sim time next is 2506800.0000, 
raw observation next is [-1.7, 38.66666666666667, 0.0, 0.0, 19.0, 18.64766830363958, -1.245025444100239, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.0, 0.4155124653739613, 0.3866666666666667, 0.0, 0.0, 0.08333333333333333, 0.05397235863663171, 0.08499151863325365, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.5034, 
noisyNet noise sample is [array([0.30837148], dtype=float32), 1.3928097]. 
=============================================
[2019-04-24 10:56:39,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.44605649e-01 3.02603585e-03 5.55499930e-16 1.13981243e-14
 5.47226017e-15 1.12195178e-16 2.08539472e-16 2.91385395e-16
 1.11455245e-13 5.23682758e-02 3.05115429e-16], sum to 1.0000
[2019-04-24 10:56:39,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8357
[2019-04-24 10:56:39,177] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.666666666666667, 70.0, 0.0, 0.0, 19.0, 20.08681904259385, -0.6088429959165752, 0.0, 1.0, 60.0, 104.09725515527288], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2676000.0000, 
sim time next is 2677200.0000, 
raw observation next is [-6.333333333333333, 71.0, 0.0, 0.0, 19.0, 21.02053515953865, -0.7187659873341669, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.28716528162511545, 0.71, 0.0, 0.0, 0.08333333333333333, 0.25171126329488747, 0.26041133755527773, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.5201568], dtype=float32), -1.3027726]. 
=============================================
[2019-04-24 10:56:39,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.31016421e-01 1.22806365e-02 4.02146578e-14 1.07456741e-13
 1.69702861e-13 4.81311971e-14 1.68407192e-14 1.38464849e-14
 8.39988409e-12 1.56702921e-01 3.88135806e-14], sum to 1.0000
[2019-04-24 10:56:39,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5461
[2019-04-24 10:56:39,360] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 48.66666666666667, 147.6666666666667, 56.83333333333332, 19.0, 19.3416901715822, -1.042048713511972, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2385600.0000, 
sim time next is 2386800.0000, 
raw observation next is [0.0, 47.0, 123.0, 170.5, 19.0, 19.1348194714614, -1.06924044641477, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.41, 0.18839779005524862, 0.08333333333333333, 0.09456828928845014, 0.14358651786174334, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.22827612], dtype=float32), 0.52266127]. 
=============================================
[2019-04-24 10:56:43,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3965042e-01 4.7758422e-03 5.5752324e-17 3.6439222e-16 8.3295108e-16
 7.5872559e-17 3.8787260e-17 6.1937398e-18 2.1090834e-14 5.5573646e-02
 2.3354353e-16], sum to 1.0000
[2019-04-24 10:56:43,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8390
[2019-04-24 10:56:43,258] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333333, 49.0, 83.16666666666666, 674.5, 19.0, 21.07343611618598, -0.5665828883558756, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3685200.0000, 
sim time next is 3686400.0000, 
raw observation next is [5.0, 50.0, 75.5, 613.5, 19.0, 21.07691969000334, -0.5681588698828616, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6011080332409973, 0.5, 0.25166666666666665, 0.6779005524861879, 0.08333333333333333, 0.256409974166945, 0.31061371003904614, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.20959017], dtype=float32), -0.3217069]. 
=============================================
[2019-04-24 10:56:48,004] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.87169576e-01 6.35051262e-03 7.29258098e-16 1.26047346e-14
 3.37137324e-15 1.90597170e-16 1.38148797e-16 1.96388731e-16
 2.97367518e-13 2.06479892e-01 1.79720777e-16], sum to 1.0000
[2019-04-24 10:56:48,032] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7414
[2019-04-24 10:56:48,083] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 77.0, 0.0, 0.0, 19.0, 20.8639108017999, -0.6253855696593277, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3794400.0000, 
sim time next is 3795600.0000, 
raw observation next is [-3.0, 75.0, 0.0, 0.0, 19.0, 20.71005966041587, -0.7162889845352735, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.75, 0.0, 0.0, 0.08333333333333333, 0.22583830503465574, 0.26123700515490883, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.73711604], dtype=float32), -0.9524325]. 
=============================================
[2019-04-24 10:56:57,575] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.3919451e-01 4.0869405e-03 8.4452394e-18 2.6153264e-17 1.0912871e-17
 1.4677018e-19 1.3193239e-18 4.1880850e-19 1.2128403e-15 2.5671852e-01
 8.5401249e-19], sum to 1.0000
[2019-04-24 10:56:57,576] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7738
[2019-04-24 10:56:57,742] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [2.0, 100.0, 78.0, 27.0, 22.5, 22.07453614988313, -0.5469926606657177, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2908800.0000, 
sim time next is 2910000.0000, 
raw observation next is [2.0, 97.66666666666667, 73.33333333333334, 45.0, 22.5, 22.78140109900512, -0.05740153223189236, 1.0, 1.0, 60.0, 122.1008022084547], 
processed observation next is [1.0, 0.6956521739130435, 0.518005540166205, 0.9766666666666667, 0.24444444444444446, 0.049723756906077346, 0.375, 0.39845009158375994, 0.48086615592270254, 1.0, 1.0, 0.9, 1.221008022084547], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5333264], dtype=float32), 0.09243758]. 
=============================================
[2019-04-24 10:56:57,782] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[83.6635  ]
 [83.5501  ]
 [83.442955]
 [83.488396]
 [83.699425]
 [84.036354]
 [84.38297 ]
 [84.59452 ]
 [84.67766 ]
 [84.74554 ]
 [84.64604 ]
 [84.410446]
 [83.96896 ]
 [83.639366]
 [83.66534 ]
 [83.07681 ]
 [83.47662 ]
 [83.73087 ]
 [84.64953 ]
 [84.40829 ]
 [85.20425 ]
 [86.21787 ]
 [85.52399 ]
 [85.69053 ]
 [85.34441 ]], R is [[84.0196228 ]
 [84.1242218 ]
 [84.28298187]
 [84.44015503]
 [84.59575653]
 [84.7387619 ]
 [84.89137268]
 [85.04245758]
 [85.19203186]
 [85.34011078]
 [85.48670959]
 [85.63184357]
 [85.77552795]
 [85.91777039]
 [86.05859375]
 [85.19800568]
 [85.34602356]
 [85.49256134]
 [85.63763428]
 [84.78125763]
 [84.93344879]
 [85.08411407]
 [84.23327637]
 [84.02962494]
 [84.16973877]].
[2019-04-24 10:56:58,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.92578661e-01 1.29528099e-03 5.49396158e-17 8.39478935e-17
 1.89212708e-16 1.22688773e-18 3.70170562e-18 3.13016042e-18
 8.41929997e-15 1.06126055e-01 2.46202306e-18], sum to 1.0000
[2019-04-24 10:56:58,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4190
[2019-04-24 10:56:58,777] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 80.33333333333334, 0.0, 0.0, 19.0, 22.97950044750421, -0.239395361915389, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2929200.0000, 
sim time next is 2930400.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 19.0, 22.3525004926166, -0.3616532218078789, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4349030470914128, 0.78, 0.0, 0.0, 0.08333333333333333, 0.3627083743847166, 0.37944892606404035, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8245562], dtype=float32), 2.5224369]. 
=============================================
[2019-04-24 10:57:02,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.81422913e-01 3.25643946e-03 1.36523215e-17 2.21174384e-16
 6.66410450e-17 9.70630791e-19 1.29700080e-18 1.29190485e-18
 2.22906732e-14 2.15320677e-01 3.00832126e-18], sum to 1.0000
[2019-04-24 10:57:02,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1308
[2019-04-24 10:57:03,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 82.66666666666667, 0.0, 0.0, 22.5, 21.35682718268901, -0.5346320382234921, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2922000.0000, 
sim time next is 2923200.0000, 
raw observation next is [-1.0, 78.0, 0.0, 0.0, 22.5, 20.88920356848849, -0.6000373515338259, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4349030470914128, 0.78, 0.0, 0.0, 0.375, 0.24076696404070752, 0.2999875494887247, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6184051], dtype=float32), -0.22253805]. 
=============================================
[2019-04-24 10:57:06,587] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1433231e-01 1.8633344e-03 2.5186882e-20 4.9856570e-20 1.1844103e-19
 4.7134290e-22 2.6472348e-21 5.5154151e-22 3.3182545e-18 1.8380432e-01
 5.1436021e-21], sum to 1.0000
[2019-04-24 10:57:06,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4197
[2019-04-24 10:57:06,633] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 100.5, 663.5, 22.5, 24.08951109673638, -0.1052980469172673, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3145200.0000, 
sim time next is 3146400.0000, 
raw observation next is [7.0, 100.0, 103.5, 696.5, 22.5, 23.78343215163367, -0.1490336623396552, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.6565096952908588, 1.0, 0.345, 0.7696132596685082, 0.375, 0.4819526793028057, 0.45032211255344823, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0491802], dtype=float32), -0.52036715]. 
=============================================
[2019-04-24 10:57:06,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0315557e-01 1.0127623e-02 7.2027853e-15 2.9124777e-14 1.8784294e-14
 7.5479032e-16 2.6237157e-15 5.9306351e-16 7.5928212e-13 8.6716942e-02
 3.1845210e-15], sum to 1.0000
[2019-04-24 10:57:06,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3866
[2019-04-24 10:57:06,996] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 19.23916734957357, -0.8003883562720283, 0.0, 1.0, 60.0, 107.48743849660107], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3376800.0000, 
sim time next is 3378000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 20.23639271586126, -0.8892342414468485, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.18636605965510503, 0.20358858618438383, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.5260765], dtype=float32), -1.1785936]. 
=============================================
[2019-04-24 10:57:07,018] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6348375e-01 2.7002656e-04 1.1993881e-19 5.4412406e-19 5.3823634e-19
 6.4421310e-22 2.6112412e-21 6.5413831e-22 4.9827031e-17 3.6246203e-02
 3.8435345e-20], sum to 1.0000
[2019-04-24 10:57:07,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6433
[2019-04-24 10:57:07,044] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [6.0, 100.0, 0.0, 0.0, 22.5, 24.26983652794103, 0.1866228121842104, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3175200.0000, 
sim time next is 3176400.0000, 
raw observation next is [5.333333333333333, 100.0, 0.0, 0.0, 22.5, 24.17663314019197, 0.1571281230569959, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6103416435826409, 1.0, 0.0, 0.0, 0.375, 0.5147194283493309, 0.5523760410189986, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.8472495], dtype=float32), 1.0226912]. 
=============================================
[2019-04-24 10:57:08,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9718791e-01 6.0819848e-03 9.7747238e-17 2.9179152e-16 3.0257719e-16
 5.7579563e-18 2.1119336e-17 8.9973386e-18 3.5481322e-14 4.9673009e-01
 3.8346621e-17], sum to 1.0000
[2019-04-24 10:57:08,576] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8610
[2019-04-24 10:57:08,599] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9226059e-01 7.0163221e-03 7.2798565e-14 9.5229075e-14 6.3011885e-14
 5.2805360e-15 1.1549887e-14 1.8700275e-15 2.1303651e-12 2.0072313e-01
 5.0517648e-14], sum to 1.0000
[2019-04-24 10:57:08,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5222
[2019-04-24 10:57:08,624] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.6666666666666667, 50.66666666666667, 61.5, 517.1666666666666, 19.0, 20.26625778265648, -0.830922562914815, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3082800.0000, 
sim time next is 3084000.0000, 
raw observation next is [0.3333333333333334, 61.33333333333334, 48.66666666666666, 419.6666666666667, 19.0, 20.09069893274604, -0.867012153504719, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.4718374884579871, 0.6133333333333334, 0.16222222222222218, 0.4637200736648251, 0.08333333333333333, 0.17422491106217, 0.21099594883176032, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([2.1161988], dtype=float32), -0.9433956]. 
=============================================
[2019-04-24 10:57:08,636] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [3.0, 49.0, 112.0, 784.0, 22.5, 23.37706249319192, -0.3726957800652251, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3409200.0000, 
sim time next is 3410400.0000, 
raw observation next is [3.0, 47.66666666666667, 114.0, 797.3333333333333, 22.5, 23.30321386987949, 0.0308371429205552, 1.0, 1.0, 60.0, 101.58586342104621], 
processed observation next is [1.0, 0.4782608695652174, 0.5457063711911359, 0.47666666666666674, 0.38, 0.8810313075506445, 0.375, 0.4419344891566241, 0.5102790476401851, 1.0, 1.0, 0.9, 1.015858634210462], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2638315], dtype=float32), -1.9690418]. 
=============================================
[2019-04-24 10:57:09,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2108798e-01 1.5708532e-03 2.0809999e-15 1.7327953e-14 6.4158756e-15
 5.7093753e-17 1.3411717e-16 4.2908631e-17 5.5488199e-13 7.7341236e-02
 6.4708563e-16], sum to 1.0000
[2019-04-24 10:57:09,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8254
[2019-04-24 10:57:09,077] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 47.33333333333334, 64.5, 529.8333333333333, 22.5, 23.14893629954993, -0.3106717205366633, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3342000.0000, 
sim time next is 3343200.0000, 
raw observation next is [-2.0, 48.66666666666666, 51.83333333333334, 439.6666666666667, 22.5, 22.70564599765138, -0.2663484311190193, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.40720221606648205, 0.4866666666666666, 0.1727777777777778, 0.48581952117863725, 0.375, 0.3921371664709484, 0.41121718962699355, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.36288187], dtype=float32), -1.42638]. 
=============================================
[2019-04-24 10:57:11,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5451355e-01 2.7711867e-04 2.5560309e-21 2.3734217e-20 3.3759386e-20
 5.0700223e-23 6.1606917e-22 2.5468706e-22 4.8991480e-18 4.5209296e-02
 2.1169151e-21], sum to 1.0000
[2019-04-24 10:57:11,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7629
[2019-04-24 10:57:11,403] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 112.5, 814.5, 22.5, 24.18880918652923, 0.08371120540987566, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3157200.0000, 
sim time next is 3158400.0000, 
raw observation next is [7.0, 100.0, 112.1666666666667, 808.8333333333334, 22.5, 24.23992135436128, 0.1046374657223479, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6565096952908588, 1.0, 0.373888888888889, 0.8937384898710866, 0.375, 0.5199934461967732, 0.5348791552407827, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.0003102], dtype=float32), 1.0936476]. 
=============================================
[2019-04-24 10:57:14,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5112062e-01 1.4225296e-03 6.1381731e-18 7.1967062e-17 8.1892277e-17
 4.1705038e-19 3.4173201e-18 7.4294245e-19 5.9180714e-15 4.7456946e-02
 3.2689127e-18], sum to 1.0000
[2019-04-24 10:57:14,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1336
[2019-04-24 10:57:14,649] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.666666666666667, 50.0, 112.8333333333333, 801.8333333333334, 22.5, 23.10278735937719, -0.1423624164183593, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3505200.0000, 
sim time next is 3506400.0000, 
raw observation next is [3.0, 49.0, 108.5, 793.5, 22.5, 23.24121667483293, -0.1222447526478933, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.49, 0.3616666666666667, 0.8767955801104972, 0.375, 0.43676805623607756, 0.4592517491173689, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0397093], dtype=float32), -0.36998263]. 
=============================================
[2019-04-24 10:57:15,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2260406e-01 5.5058184e-03 3.9718510e-15 1.3811655e-14 2.3350254e-14
 2.5599713e-16 8.0227435e-16 4.4607836e-16 2.2010280e-12 1.7189014e-01
 1.7239964e-15], sum to 1.0000
[2019-04-24 10:57:15,757] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5292
[2019-04-24 10:57:15,770] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 55.0, 0.0, 0.0, 22.5, 22.65222253944536, -0.2998784965142884, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3348000.0000, 
sim time next is 3349200.0000, 
raw observation next is [-3.0, 55.0, 0.0, 0.0, 22.5, 22.55312556473514, -0.3357175269201529, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.3795013850415513, 0.55, 0.0, 0.0, 0.375, 0.379427130394595, 0.38809415769328237, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.1984533], dtype=float32), 1.0030946]. 
=============================================
[2019-04-24 10:57:16,693] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.1869384e-01 3.0489573e-03 2.4913126e-15 7.1095262e-15 6.3161591e-15
 2.3143574e-16 6.5171463e-17 5.6222262e-17 3.4846599e-13 7.8257233e-02
 7.5767420e-16], sum to 1.0000
[2019-04-24 10:57:16,694] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.2406
[2019-04-24 10:57:16,702] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.333333333333334, 51.33333333333333, 112.6666666666667, 792.0, 22.5, 22.96620493525493, -0.1814665593856401, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3332400.0000, 
sim time next is 3333600.0000, 
raw observation next is [-4.0, 50.0, 110.0, 776.0, 22.5, 23.15970245011758, -0.1587228114237398, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.3518005540166205, 0.5, 0.36666666666666664, 0.8574585635359117, 0.375, 0.4299752041764651, 0.44709239619208674, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.30225566], dtype=float32), -0.28602812]. 
=============================================
[2019-04-24 10:57:17,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6535069e-01 1.5941757e-03 2.2478385e-17 5.5308266e-16 1.8841466e-16
 1.3318307e-17 2.5314038e-17 1.1933938e-18 9.6016538e-15 3.3055142e-02
 3.9681720e-17], sum to 1.0000
[2019-04-24 10:57:17,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0780
[2019-04-24 10:57:17,601] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [5.0, 50.0, 75.5, 613.5, 19.0, 21.49571856960231, -0.4773248252879652, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3686400.0000, 
sim time next is 3687600.0000, 
raw observation next is [4.666666666666667, 53.0, 67.83333333333333, 552.5, 19.0, 21.50850016438515, -0.4806402122979965, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5918744228993538, 0.53, 0.2261111111111111, 0.6104972375690608, 0.08333333333333333, 0.29237501369876256, 0.33978659590066784, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.3082327], dtype=float32), -0.7943615]. 
=============================================
[2019-04-24 10:57:19,148] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.29509139e-01 1.88353993e-02 5.73001695e-16 2.08900030e-15
 2.13025927e-15 3.35286081e-17 2.06721514e-16 1.23494638e-16
 1.02081694e-13 1.51655510e-01 1.93591127e-16], sum to 1.0000
[2019-04-24 10:57:19,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0566
[2019-04-24 10:57:19,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 60.00000000000001, 72.83333333333333, 369.5, 22.5, 21.61789970738182, -0.3586639737922614, 1.0, 1.0, 60.0, 111.8666956605762], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3399600.0000, 
sim time next is 3400800.0000, 
raw observation next is [-1.333333333333333, 60.0, 89.0, 461.3333333333333, 22.5, 22.97507965273866, -0.3963766391445038, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.42566943674976926, 0.6, 0.2966666666666667, 0.5097605893186004, 0.375, 0.41458997106155504, 0.36787445361849874, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.478184], dtype=float32), -0.30828658]. 
=============================================
[2019-04-24 10:57:19,720] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [7.4388409e-01 2.5058510e-02 1.3614913e-14 1.0807411e-13 9.9056797e-14
 2.1394931e-14 6.2550376e-15 2.5239879e-15 1.7746988e-12 2.3105741e-01
 3.2170565e-14], sum to 1.0000
[2019-04-24 10:57:19,721] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.4360
[2019-04-24 10:57:19,746] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 53.33333333333334, 117.3333333333333, 821.8333333333334, 19.0, 19.38898165754977, -0.897845807449334, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3586800.0000, 
sim time next is 3588000.0000, 
raw observation next is [-2.333333333333333, 51.66666666666666, 117.3333333333333, 821.1666666666667, 19.0, 19.37779716037614, -0.8991103868751865, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3979686057248385, 0.5166666666666666, 0.391111111111111, 0.9073664825046042, 0.08333333333333333, 0.11481643003134501, 0.20029653770827116, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.99300563], dtype=float32), -0.9313161]. 
=============================================
[2019-04-24 10:57:25,687] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.3050170e-01 3.4770274e-03 1.8030961e-16 7.8625579e-16 2.9252980e-15
 3.2950002e-17 5.6377501e-17 1.0008707e-17 1.7302494e-14 6.6021256e-02
 1.8273595e-16], sum to 1.0000
[2019-04-24 10:57:25,687] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.4614
[2019-04-24 10:57:25,699] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 0.0, 0.0, 19.0, 21.80828520763114, -0.5036893324291323, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3799200.0000, 
sim time next is 3800400.0000, 
raw observation next is [-3.0, 71.0, 0.0, 0.0, 19.0, 21.17326668790712, -0.638480055347675, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 1.0, 0.3795013850415513, 0.71, 0.0, 0.0, 0.08333333333333333, 0.2644388906589266, 0.2871733148841083, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1278259], dtype=float32), -0.044242688]. 
=============================================
[2019-04-24 10:57:27,168] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-24 10:57:27,170] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 10:57:27,170] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:57:27,173] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run17
[2019-04-24 10:57:27,196] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 10:57:27,198] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:57:27,199] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 10:57:27,201] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 10:57:27,203] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run17
[2019-04-24 10:57:27,218] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run17
[2019-04-24 10:58:22,801] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.24481072], dtype=float32), 0.65941024]
[2019-04-24 10:58:22,802] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [0.9000000000000001, 89.33333333333334, 0.0, 0.0, 19.0, 21.37067661831773, -0.4121196686479355, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:58:22,802] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:58:22,804] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [8.87515664e-01 1.53946271e-03 3.14014602e-17 8.89772906e-17
 1.01196317e-16 2.96950395e-18 4.24964412e-18 1.42960715e-18
 7.56559833e-15 1.10944800e-01 9.88916508e-18], sampled 0.6740227104552635
[2019-04-24 10:58:44,915] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:NoisyNet noise sample: [array([-0.24481072], dtype=float32), 0.65941024]
[2019-04-24 10:58:44,916] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation this: [-2.3, 64.0, 0.0, 0.0, 19.0, 21.58569889152104, -0.624739466756369, 0.0, 1.0, 15.0, 0.0]
[2019-04-24 10:58:44,916] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 DEBUG:Observation forecast: []
[2019-04-24 10:58:44,917] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Softmax [8.82968903e-01 6.48374390e-03 4.87279843e-15 1.36448995e-14
 2.76069163e-14 1.09699629e-15 1.09024618e-15 3.74377789e-16
 2.10649898e-13 1.10547304e-01 1.88186602e-15], sampled 0.02533365515326258
[2019-04-24 10:59:39,040] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3436.7255 62653.1857 -216.3769
[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,081] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:39,262] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,562] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3209.5105 78419.8382 -447.9706
[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,599] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 10:59:52,787] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,116] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3115.6064 80745.9896 -542.8804
[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,150] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:00,319] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:00:01,152] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 800000, evaluation results [800000.0, 3209.5105302151346, 78419.83818598256, -447.9706063880468, 3436.7254972909614, 62653.18572582419, -216.37693747727866, 3115.6064127282366, 80745.98955771564, -542.8804387721418]
[2019-04-24 11:00:02,873] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:03,164] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:03,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:03,855] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:03,863] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run13
[2019-04-24 11:00:14,559] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [9.91823733e-01 3.21215426e-04 2.17533219e-18 8.98190164e-17
 5.92916115e-17 1.60513395e-18 1.38561345e-18 2.88631207e-19
 4.82871545e-15 7.85499997e-03 1.06405015e-17], sum to 1.0000
[2019-04-24 11:00:14,560] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7329
[2019-04-24 11:00:14,573] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.0, 30.33333333333333, 114.3333333333333, 824.0, 22.5, 23.35770113855713, 0.02961378305529157, 1.0, 1.0, 60.0, 83.91936132672879], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4110000.0000, 
sim time next is 4111200.0000, 
raw observation next is [3.0, 31.0, 111.0, 812.0, 22.5, 24.5660828146, -0.0903894034449837, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5457063711911359, 0.31, 0.37, 0.8972375690607735, 0.375, 0.5471735678833335, 0.4698701988516721, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.25266278], dtype=float32), -0.48803696]. 
=============================================
[2019-04-24 11:00:14,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7327907e-01 6.0099531e-02 5.2003462e-14 2.6002125e-13 1.6411227e-13
 9.7517785e-15 6.3500739e-14 1.2024098e-14 5.8069352e-12 1.6662139e-01
 1.8697033e-14], sum to 1.0000
[2019-04-24 11:00:14,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4598
[2019-04-24 11:00:15,015] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 39.0, 0.0, 0.0, 19.0, 20.38088752307873, -0.9621667347644257, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4072800.0000, 
sim time next is 4074000.0000, 
raw observation next is [-5.0, 40.0, 0.0, 0.0, 19.0, 19.66184010430081, -1.062959232996494, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.32409972299168976, 0.4, 0.0, 0.0, 0.08333333333333333, 0.13848667535840095, 0.1456802556678353, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7955472], dtype=float32), 0.7009938]. 
=============================================
[2019-04-24 11:00:16,475] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5145816e-01 9.3817953e-03 5.6619468e-15 5.1584113e-14 6.2885203e-14
 7.8968670e-16 4.0274236e-15 6.1516816e-16 3.4851109e-12 3.9160069e-02
 1.0630740e-14], sum to 1.0000
[2019-04-24 11:00:16,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5774
[2019-04-24 11:00:16,493] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 40.0, 0.0, 0.0, 19.0, 20.0049909771015, -0.7236098639474718, 0.0, 1.0, 60.0, 97.22811010760958], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4074000.0000, 
sim time next is 4075200.0000, 
raw observation next is [-5.0, 41.0, 0.0, 0.0, 19.0, 20.74273223145333, -0.8304645036406945, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.32409972299168976, 0.41, 0.0, 0.0, 0.08333333333333333, 0.2285610192877776, 0.22317849878643517, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-3.8274984], dtype=float32), -0.50643533]. 
=============================================
[2019-04-24 11:00:19,945] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9085778e-01 8.4420317e-04 2.8668600e-21 4.4203223e-20 6.0893909e-20
 2.9737014e-22 4.0319832e-22 7.7960176e-23 4.9379324e-18 8.2980627e-03
 2.1111016e-21], sum to 1.0000
[2019-04-24 11:00:19,946] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1816
[2019-04-24 11:00:19,963] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.933333333333334, 59.66666666666667, 0.0, 0.0, 19.0, 24.23063568071972, 0.1522932903697277, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4396800.0000, 
sim time next is 4398000.0000, 
raw observation next is [9.666666666666668, 60.33333333333333, 0.0, 0.0, 19.0, 24.01451610959719, 0.117913346460313, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.7303785780240075, 0.6033333333333333, 0.0, 0.0, 0.08333333333333333, 0.5012096757997657, 0.5393044488201043, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.31025594], dtype=float32), 1.1073304]. 
=============================================
[2019-04-24 11:00:23,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6000059e-01 2.4377046e-02 8.6381863e-17 2.1934446e-16 1.6735104e-16
 8.1753775e-18 9.0525298e-18 6.4934108e-18 6.5816023e-15 2.1562243e-01
 1.2240389e-17], sum to 1.0000
[2019-04-24 11:00:23,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5159
[2019-04-24 11:00:23,489] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.533333333333333, 75.33333333333334, 0.0, 0.0, 19.0, 19.58728320932578, -0.9615839876270785, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4315200.0000, 
sim time next is 4316400.0000, 
raw observation next is [4.4, 75.0, 0.0, 0.0, 19.0, 19.53210829999522, -0.9750679671048008, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5844875346260389, 0.75, 0.0, 0.0, 0.08333333333333333, 0.12767569166626824, 0.17497734429839973, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2905823], dtype=float32), 0.28141636]. 
=============================================
[2019-04-24 11:00:24,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1699604e-01 3.1265758e-03 4.8753570e-18 2.4373950e-17 6.2065103e-18
 3.0569654e-19 8.2433284e-19 3.4001980e-19 1.8898514e-15 1.7987734e-01
 1.5931856e-18], sum to 1.0000
[2019-04-24 11:00:24,885] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4441
[2019-04-24 11:00:24,908] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 51.0, 123.1666666666667, 822.0, 22.5, 24.26726353751169, -0.08963441208834404, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4620000.0000, 
sim time next is 4621200.0000, 
raw observation next is [2.666666666666667, 50.0, 121.6666666666667, 837.3333333333334, 22.5, 23.88982290965999, 0.001212589225993358, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5364727608494922, 0.5, 0.40555555555555567, 0.9252302025782689, 0.375, 0.4908185758049992, 0.5004041964086644, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.7973409], dtype=float32), -0.6975859]. 
=============================================
[2019-04-24 11:00:26,125] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4609648e-01 6.8802545e-03 1.4703977e-17 7.7349891e-17 9.9692734e-17
 6.3137817e-19 3.5609493e-18 3.1895053e-19 2.0132429e-15 4.7023255e-02
 2.8401739e-18], sum to 1.0000
[2019-04-24 11:00:26,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0951
[2019-04-24 11:00:26,153] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 72.0, 0.0, 0.0, 19.0, 21.43869527532896, -0.3527674387485502, 0.0, 1.0, 20.0, 81.43345283813844], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4677600.0000, 
sim time next is 4678800.0000, 
raw observation next is [0.6666666666666667, 82.0, 0.0, 0.0, 19.0, 22.02413044465312, -0.4295881188976116, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.4810710987996307, 0.82, 0.0, 0.0, 0.08333333333333333, 0.3353442037210934, 0.3568039603674628, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.954725], dtype=float32), -0.32704136]. 
=============================================
[2019-04-24 11:00:28,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9026239e-01 3.3188460e-03 1.4923873e-18 3.5420575e-17 1.6594452e-17
 5.0384042e-19 6.8633936e-19 7.7197787e-20 5.6834540e-16 6.4187851e-03
 3.0157864e-18], sum to 1.0000
[2019-04-24 11:00:28,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9069
[2019-04-24 11:00:28,281] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.0, 62.0, 0.0, 0.0, 19.0, 22.52046718171652, -0.1873825978454761, 0.0, 1.0, 60.0, 81.99726753624502], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4676400.0000, 
sim time next is 4677600.0000, 
raw observation next is [1.333333333333333, 72.0, 0.0, 0.0, 19.0, 23.08430359752531, -0.3147963130477187, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.4995383194829178, 0.72, 0.0, 0.0, 0.08333333333333333, 0.42369196646044244, 0.39506789565076045, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.74863523], dtype=float32), 0.9816516]. 
=============================================
[2019-04-24 11:00:29,044] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [7.2312272e-01 9.6585369e-03 1.5984999e-18 4.9171003e-18 9.9389175e-18
 9.4737564e-20 1.2355965e-19 2.7057375e-20 2.4544797e-16 2.6721883e-01
 1.8331775e-19], sum to 1.0000
[2019-04-24 11:00:29,045] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.1657
[2019-04-24 11:00:29,141] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.3, 84.0, 142.5, 131.5, 22.5, 24.21344622381475, -0.07458832822360921, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4438800.0000, 
sim time next is 4440000.0000, 
raw observation next is [1.2, 84.66666666666667, 157.5, 64.5, 22.5, 23.69480094968247, -0.1252376579737046, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4958448753462604, 0.8466666666666667, 0.525, 0.0712707182320442, 0.375, 0.4745667458068725, 0.4582541140087651, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.24930522], dtype=float32), 1.1544819]. 
=============================================
[2019-04-24 11:00:29,155] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[90.479065]
 [90.319984]
 [90.00738 ]
 [88.4624  ]
 [86.26047 ]
 [85.76913 ]
 [85.20326 ]
 [85.32897 ]
 [85.57298 ]
 [85.93542 ]
 [85.25282 ]
 [85.707   ]
 [86.13595 ]
 [86.56579 ]
 [86.98415 ]
 [87.394005]
 [87.804634]
 [88.23173 ]
 [88.66957 ]
 [88.760376]
 [88.938515]
 [89.45491 ]
 [89.73214 ]
 [90.09884 ]
 [90.54206 ]], R is [[90.07398987]
 [90.17324829]
 [90.27151489]
 [89.3687973 ]
 [88.47511292]
 [87.95960999]
 [87.54699707]
 [87.67153168]
 [87.79481506]
 [87.91687012]
 [87.03770447]
 [87.16732788]
 [87.2956543 ]
 [87.42269897]
 [87.54846954]
 [87.67298889]
 [87.79625702]
 [87.91829681]
 [88.03911591]
 [88.15872192]
 [88.27713776]
 [88.39437103]
 [88.51042938]
 [88.62532806]
 [88.73907471]].
[2019-04-24 11:00:31,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3149954e-01 1.1176730e-03 3.7068006e-18 9.1776748e-18 9.3456313e-18
 2.6034463e-19 2.9543032e-19 2.6215843e-19 2.0271216e-15 6.7382812e-02
 6.5554327e-19], sum to 1.0000
[2019-04-24 11:00:31,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8827
[2019-04-24 11:00:31,435] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.333333333333333, 49.0, 120.3333333333333, 854.6666666666667, 22.5, 23.83743386179748, -0.0544404661064094, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4623600.0000, 
sim time next is 4624800.0000, 
raw observation next is [3.666666666666667, 49.0, 123.1666666666667, 851.3333333333334, 22.5, 23.55232132442553, -0.05730112148956713, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.564173591874423, 0.49, 0.4105555555555557, 0.9406998158379374, 0.375, 0.46269344370212756, 0.4808996261701443, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.24308737], dtype=float32), 0.2506785]. 
=============================================
[2019-04-24 11:00:39,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:39,515] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:39,609] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:39,789] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:40,054] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:40,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3993872e-01 1.3740360e-02 8.1726556e-16 1.2412097e-14 1.7541687e-15
 2.8373420e-16 1.4810619e-16 1.0138954e-16 2.9924026e-13 4.6320852e-02
 6.6412052e-16], sum to 1.0000
[2019-04-24 11:00:40,071] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6208
[2019-04-24 11:00:40,092] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0666666666666666, 50.33333333333334, 285.8333333333333, 284.0, 19.0, 19.83310587223064, -0.7473451405816024, 0.0, 1.0, 20.0, 70.42337586211237], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4879200.0000, 
sim time next is 4880400.0000, 
raw observation next is [0.5333333333333332, 48.66666666666667, 282.6666666666667, 321.6666666666667, 19.0, 20.56966665915858, -0.7965918545518372, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.4773776546629733, 0.4866666666666667, 0.9422222222222223, 0.3554327808471455, 0.08333333333333333, 0.21413888826321514, 0.23446938181605426, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1241888], dtype=float32), -0.31606308]. 
=============================================
[2019-04-24 11:00:40,255] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:40,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:40,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:40,323] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:40,336] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res11/Eplus-env-sub_run13
[2019-04-24 11:00:40,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:40,445] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:40,583] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:40,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:40,604] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:40,608] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res14/Eplus-env-sub_run13
[2019-04-24 11:00:41,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:41,056] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:41,059] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res2/Eplus-env-sub_run13
[2019-04-24 11:00:41,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:41,269] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:41,272] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res13/Eplus-env-sub_run13
[2019-04-24 11:00:41,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:41,413] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:41,417] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res5/Eplus-env-sub_run13
[2019-04-24 11:00:41,546] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:41,915] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:42,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:42,549] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:42,552] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res10/Eplus-env-sub_run13
[2019-04-24 11:00:43,642] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:43,859] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:43,912] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:44,301] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:44,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:44,646] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:44,660] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res12/Eplus-env-sub_run13
[2019-04-24 11:00:44,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:44,857] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:44,861] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res4/Eplus-env-sub_run13
[2019-04-24 11:00:45,479] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:45,805] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:46,161] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:46,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:46,447] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:46,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:46,480] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:46,483] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res7/Eplus-env-sub_run13
[2019-04-24 11:00:46,530] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:46,713] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:47,017] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:47,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:47,146] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:47,190] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res16/Eplus-env-sub_run13
[2019-04-24 11:00:47,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:47,264] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:47,268] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res3/Eplus-env-sub_run13
[2019-04-24 11:00:47,714] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:47,715] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:47,734] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res9/Eplus-env-sub_run13
[2019-04-24 11:00:49,467] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.7640926e-01 8.4487512e-04 2.3088790e-19 3.9802823e-18 1.7454822e-18
 2.4301455e-20 2.4913265e-20 3.8920350e-21 1.7019114e-16 2.2745840e-02
 1.5507291e-19], sum to 1.0000
[2019-04-24 11:00:49,467] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.8107
[2019-04-24 11:00:49,494] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [9.666666666666668, 23.33333333333334, 119.0, 860.8333333333334, 22.5, 24.20971503810448, 0.0834272337660185, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 5059200.0000, 
sim time next is 5060400.0000, 
raw observation next is [10.33333333333333, 21.66666666666666, 116.8333333333333, 853.1666666666667, 22.5, 24.50234135419233, 0.1410037969234351, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.7488457987072946, 0.21666666666666662, 0.3894444444444443, 0.9427255985267036, 0.375, 0.5418617795160273, 0.547001265641145, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.1622845], dtype=float32), -1.0210664]. 
=============================================
[2019-04-24 11:00:50,101] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:50,402] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:50,533] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:50,842] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:51,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:51,102] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:51,106] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res6/Eplus-env-sub_run13
[2019-04-24 11:00:51,304] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_11 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:00:51,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:51,534] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:51,538] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res17/Eplus-env-sub_run13
[2019-04-24 11:00:51,600] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11-EPLUSPROCESS_EPI_11 ERROR:Aborted (core dumped)

[2019-04-24 11:00:52,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:00:52,305] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:00:52,308] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res8/Eplus-env-sub_run13
[2019-04-24 11:00:55,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.8302574e-01 5.6614269e-02 4.3830054e-15 1.0966708e-14 1.4745390e-14
 4.6070180e-16 1.9064190e-15 8.6647262e-16 5.0243501e-13 1.6036007e-01
 5.4962597e-16], sum to 1.0000
[2019-04-24 11:00:55,737] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7661
[2019-04-24 11:00:55,758] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.1, 70.33333333333333, 0.0, 0.0, 19.0, 19.03109244150569, -1.147396666612047, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 110400.0000, 
sim time next is 111600.0000, 
raw observation next is [-7.3, 68.0, 0.0, 0.0, 19.0, 18.35562280962607, -1.250552638455105, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.26038781163434904, 0.68, 0.0, 0.0, 0.08333333333333333, 0.0296352341355058, 0.08314912051496504, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9942268], dtype=float32), 0.6218381]. 
=============================================
[2019-04-24 11:00:57,084] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7991222e-01 2.3737859e-03 1.4728859e-16 9.8888323e-16 6.5050018e-16
 6.1955187e-18 4.5117461e-17 7.1590761e-17 9.8895596e-14 1.7713957e-02
 1.0483044e-16], sum to 1.0000
[2019-04-24 11:00:57,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7120
[2019-04-24 11:00:57,124] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-8.2, 69.33333333333334, 175.0, 111.3333333333333, 22.5, 22.36527787888858, -0.3075136639913948, 1.0, 1.0, 60.0, 84.97399543673532], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 128400.0000, 
sim time next is 129600.0000, 
raw observation next is [-8.4, 61.0, 157.0, 308.0, 22.5, 22.76918670202773, -0.4103519610419474, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.2299168975069252, 0.61, 0.5233333333333333, 0.34033149171270716, 0.375, 0.39743222516897764, 0.3632160129860176, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.578831], dtype=float32), -0.63996017]. 
=============================================
[2019-04-24 11:00:57,909] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7997324e-01 1.5278620e-02 1.5478524e-16 1.8548280e-16 7.2114336e-16
 1.7456489e-17 2.7568926e-17 1.4206648e-17 7.2584659e-15 3.0474824e-01
 7.0036464e-18], sum to 1.0000
[2019-04-24 11:00:57,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6794
[2019-04-24 11:00:57,937] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 0.0, 0.0, 19.0, 19.40648320421422, -0.9460298513954731, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 79200.0000, 
sim time next is 80400.0000, 
raw observation next is [0.4333333333333333, 95.66666666666666, 0.0, 0.0, 19.0, 19.16872851697695, -0.9876969312325654, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.4746075715604802, 0.9566666666666666, 0.0, 0.0, 0.08333333333333333, 0.09739404308141264, 0.17076768958914487, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.53278583], dtype=float32), -0.21698982]. 
=============================================
[2019-04-24 11:01:01,132] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1562296e-01 1.0792602e-02 1.9828423e-14 3.1347415e-14 5.6818404e-14
 2.7741060e-16 4.7686430e-15 9.9078492e-16 3.6721789e-12 2.7358446e-01
 1.6250446e-15], sum to 1.0000
[2019-04-24 11:01:01,133] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4438
[2019-04-24 11:01:01,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 67.66666666666667, 0.0, 0.0, 22.5, 21.73192124515343, -0.5997289075472726, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 148800.0000, 
sim time next is 150000.0000, 
raw observation next is [-7.3, 64.33333333333333, 0.0, 0.0, 22.5, 21.19003798493814, -0.7052003039351878, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.26038781163434904, 0.6433333333333333, 0.0, 0.0, 0.375, 0.265836498744845, 0.26493323202160407, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2470793], dtype=float32), 0.8009196]. 
=============================================
[2019-04-24 11:01:01,202] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.56261 ]
 [68.622505]
 [68.84724 ]
 [68.81748 ]
 [68.839226]
 [68.85024 ]
 [69.41854 ]
 [68.44491 ]
 [69.10444 ]
 [69.83915 ]
 [70.752556]
 [71.50052 ]
 [71.128105]
 [71.79056 ]
 [72.52298 ]
 [72.988045]
 [71.478935]
 [71.74513 ]
 [72.420204]
 [72.66807 ]
 [73.076614]
 [72.508995]
 [72.1617  ]
 [72.2266  ]
 [71.37965 ]], R is [[67.71102905]
 [67.78527069]
 [67.8899765 ]
 [68.21107483]
 [68.52896118]
 [68.84367371]
 [69.15523529]
 [68.46368408]
 [68.72865295]
 [69.04136658]
 [69.35095215]
 [69.65744019]
 [68.96086884]
 [69.27126312]
 [69.57855225]
 [69.88276672]
 [69.18393707]
 [68.96617126]
 [68.71813202]
 [68.61721802]
 [68.72532654]
 [69.01179504]
 [69.32167816]
 [69.62846375]
 [68.93218231]].
[2019-04-24 11:01:10,122] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.3910766e-01 4.3512774e-03 1.1819153e-15 3.7353950e-14 2.0455317e-14
 1.4073061e-16 5.5594250e-16 1.3855782e-15 9.0302039e-13 5.6541100e-02
 3.0320895e-15], sum to 1.0000
[2019-04-24 11:01:10,124] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.6232
[2019-04-24 11:01:10,184] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 64.0, 44.0, 24.0, 22.5, 23.34191746639462, -0.2561793536630415, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 144000.0000, 
sim time next is 145200.0000, 
raw observation next is [-6.9, 66.33333333333334, 32.66666666666666, 9.999999999999998, 22.5, 23.2464235327615, -0.3245239097892304, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.27146814404432135, 0.6633333333333334, 0.10888888888888885, 0.011049723756906075, 0.375, 0.4372019610634584, 0.3918253634035899, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.49395385], dtype=float32), 0.54390085]. 
=============================================
[2019-04-24 11:01:10,751] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [7.6301849e-01 1.2792151e-02 1.7964698e-15 1.6795872e-14 8.2770899e-15
 9.2737826e-17 6.0590887e-16 3.4728248e-16 8.2800992e-13 2.2418930e-01
 8.6516093e-16], sum to 1.0000
[2019-04-24 11:01:10,752] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0040
[2019-04-24 11:01:10,799] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 60.0, 66.16666666666667, 0.0, 22.5, 21.98574340935053, -0.604032509051344, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 228000.0000, 
sim time next is 229200.0000, 
raw observation next is [-3.2, 61.0, 49.66666666666667, 0.0, 22.5, 21.8265602155196, -0.6445658746566222, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.37396121883656513, 0.61, 0.16555555555555557, 0.0, 0.375, 0.3188800179599666, 0.2851447084477926, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.4775, 
noisyNet noise sample is [array([0.51493686], dtype=float32), -1.374939]. 
=============================================
[2019-04-24 11:01:14,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1579291e-01 9.6229039e-02 1.1647042e-13 1.1977766e-13 3.2018846e-13
 8.1551392e-15 2.1863491e-14 2.0914522e-14 4.1303159e-12 3.8797802e-01
 1.7289738e-14], sum to 1.0000
[2019-04-24 11:01:14,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7127
[2019-04-24 11:01:14,466] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-10.23333333333333, 68.0, 0.0, 0.0, 19.0, 20.12701409220257, -0.9893324323866891, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 276000.0000, 
sim time next is 277200.0000, 
raw observation next is [-10.6, 67.0, 0.0, 0.0, 19.0, 19.79889976386401, -0.8363111461847454, 0.0, 1.0, 60.0, 89.98754383976657], 
processed observation next is [1.0, 0.21739130434782608, 0.1689750692520776, 0.67, 0.0, 0.0, 0.08333333333333333, 0.14990831365533422, 0.2212296179384182, 0.0, 1.0, 0.9, 0.8998754383976657], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09482998], dtype=float32), 1.5342311]. 
=============================================
[2019-04-24 11:01:16,109] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9483535e-01 2.8172594e-02 6.4124507e-14 1.3531606e-12 6.5980999e-13
 1.5264467e-14 9.4050310e-14 2.8668792e-14 8.6864361e-12 7.6992087e-02
 6.2605025e-14], sum to 1.0000
[2019-04-24 11:01:16,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7108
[2019-04-24 11:01:16,148] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-12.3, 67.0, 0.0, 0.0, 19.0, 19.39036196433666, -0.9634006086883166, 0.0, 1.0, 60.0, 88.83664704682695], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 284400.0000, 
sim time next is 285600.0000, 
raw observation next is [-12.46666666666667, 68.0, 0.0, 0.0, 22.5, 19.56321376819177, -1.140063921044999, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.11726685133887339, 0.68, 0.0, 0.0, 0.375, 0.13026781401598075, 0.11997869298500034, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6783858], dtype=float32), 0.7200532]. 
=============================================
[2019-04-24 11:01:22,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3422970e-01 2.6461208e-02 4.8284070e-16 6.5927555e-16 6.7690034e-16
 1.2687568e-16 5.5943450e-16 2.5727827e-17 5.6187324e-14 4.3930918e-01
 5.0553590e-17], sum to 1.0000
[2019-04-24 11:01:22,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9369
[2019-04-24 11:01:22,394] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.6, 84.33333333333333, 79.0, 140.0, 19.0, 19.91141284838841, -0.8858900533745501, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 556800.0000, 
sim time next is 558000.0000, 
raw observation next is [-0.6, 83.0, 83.0, 138.0, 19.0, 20.2694849159811, -0.5861797917903094, 0.0, 1.0, 60.0, 92.85962679240001], 
processed observation next is [0.0, 0.4782608695652174, 0.44598337950138506, 0.83, 0.27666666666666667, 0.15248618784530388, 0.08333333333333333, 0.18912374299842494, 0.30460673606989686, 0.0, 1.0, 0.9, 0.9285962679240001], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.749811], dtype=float32), 0.24104987]. 
=============================================
[2019-04-24 11:01:24,575] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4523481e-01 1.3238773e-02 7.7617781e-18 7.5631757e-17 5.2235126e-17
 1.4741394e-19 6.3241582e-19 5.1043155e-19 1.3431029e-15 1.4152651e-01
 1.4544392e-18], sum to 1.0000
[2019-04-24 11:01:24,577] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8369
[2019-04-24 11:01:24,590] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.433333333333333, 96.0, 0.0, 0.0, 19.0, 22.06983183988574, -0.5363676206508045, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 506400.0000, 
sim time next is 507600.0000, 
raw observation next is [1.6, 96.0, 0.0, 0.0, 19.0, 21.34732009111384, -0.6717612415763777, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.5069252077562327, 0.96, 0.0, 0.0, 0.08333333333333333, 0.2789433409261533, 0.2760795861412074, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.9794511], dtype=float32), -1.9419738]. 
=============================================
[2019-04-24 11:01:24,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0407181e-01 4.3749295e-02 1.1727828e-13 5.5321470e-14 7.2315377e-14
 3.2576553e-15 6.4365470e-15 3.3194495e-15 1.3556372e-12 6.5217882e-01
 3.8729175e-15], sum to 1.0000
[2019-04-24 11:01:24,712] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8012
[2019-04-24 11:01:24,771] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-4.5, 72.66666666666667, 0.0, 0.0, 19.0, 19.21107516153676, -1.141866322683324, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 620400.0000, 
sim time next is 621600.0000, 
raw observation next is [-4.5, 70.33333333333333, 0.0, 0.0, 19.0, 19.16313253913518, -0.9069327345947152, 0.0, 1.0, 60.0, 93.78744733969201], 
processed observation next is [0.0, 0.17391304347826086, 0.3379501385041552, 0.7033333333333333, 0.0, 0.0, 0.08333333333333333, 0.09692771159459834, 0.19768908846842825, 0.0, 1.0, 0.9, 0.9378744733969201], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20639925], dtype=float32), 0.8453142]. 
=============================================
[2019-04-24 11:01:29,911] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [2.6584640e-01 4.4735249e-02 5.0756623e-16 3.2934359e-16 1.1380383e-15
 1.6547617e-16 2.7586320e-16 3.8363545e-17 3.8539840e-14 6.8941832e-01
 1.9681165e-16], sum to 1.0000
[2019-04-24 11:01:29,912] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.0277
[2019-04-24 11:01:29,922] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.1666666666666667, 91.33333333333334, 52.33333333333333, 103.8333333333333, 19.0, 19.65063787542178, -0.9686803058710568, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 549600.0000, 
sim time next is 550800.0000, 
raw observation next is [0.0, 91.0, 89.0, 103.5, 19.0, 19.36245186376605, -1.010947346774817, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.46260387811634357, 0.91, 0.2966666666666667, 0.1143646408839779, 0.08333333333333333, 0.11353765531383757, 0.16301755107506102, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.7991061], dtype=float32), -0.019502856]. 
=============================================
[2019-04-24 11:01:30,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5258713e-01 9.6921772e-03 3.5257746e-15 8.8987303e-14 2.2062230e-14
 3.7989008e-15 4.1736617e-15 6.8220272e-16 8.1913653e-13 3.7720703e-02
 3.9466323e-15], sum to 1.0000
[2019-04-24 11:01:30,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4793
[2019-04-24 11:01:30,223] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.7, 61.0, 100.5, 69.0, 19.0, 20.38924353525982, -0.7421509582192204, 0.0, 1.0, 60.0, 84.52694731521265], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 648000.0000, 
sim time next is 649200.0000, 
raw observation next is [-2.566666666666667, 60.33333333333334, 108.1666666666667, 89.66666666666667, 19.0, 20.63519425356173, -0.8852307075214094, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.39150507848568794, 0.6033333333333334, 0.3605555555555557, 0.0990791896869245, 0.08333333333333333, 0.21959952113014403, 0.20492309749286353, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.3206201], dtype=float32), -0.7133655]. 
=============================================
[2019-04-24 11:01:31,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9829923e-01 9.8624565e-03 1.8435020e-17 2.2269730e-17 8.8520753e-17
 8.3591605e-19 4.5356373e-18 8.1413225e-19 2.3669343e-15 2.9183826e-01
 9.9441511e-18], sum to 1.0000
[2019-04-24 11:01:31,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1677
[2019-04-24 11:01:31,101] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.533333333333333, 88.33333333333334, 0.0, 0.0, 19.0, 21.96766485864872, -0.5883020361231694, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 524400.0000, 
sim time next is 525600.0000, 
raw observation next is [4.3, 88.0, 0.0, 0.0, 19.0, 21.26461947471499, -0.7190771403120445, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.5817174515235458, 0.88, 0.0, 0.0, 0.08333333333333333, 0.2720516228929159, 0.26030761989598517, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4410299], dtype=float32), -0.08048781]. 
=============================================
[2019-04-24 11:01:31,464] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0687815e-01 1.8253403e-02 5.7334178e-17 1.6939817e-16 3.5222073e-16
 7.3611771e-18 2.5582127e-17 6.6536183e-18 1.0195738e-14 1.7486848e-01
 5.6147650e-17], sum to 1.0000
[2019-04-24 11:01:31,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6128
[2019-04-24 11:01:31,497] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.266666666666667, 87.0, 0.0, 0.0, 19.0, 20.44805065028265, -0.6094604248519593, 0.0, 1.0, 60.0, 90.53444807096409], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 538800.0000, 
sim time next is 540000.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 19.0, 21.18253624192265, -0.7293035082789846, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.49307479224376743, 0.88, 0.0, 0.0, 0.08333333333333333, 0.2652113534935543, 0.2568988305736718, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.4410299], dtype=float32), -0.08048781]. 
=============================================
[2019-04-24 11:01:31,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.47834 ]
 [77.14511 ]
 [77.77697 ]
 [78.522575]
 [78.297035]
 [79.111336]
 [79.93036 ]
 [80.600746]
 [81.20644 ]
 [80.472206]
 [80.77709 ]
 [80.92037 ]
 [81.51877 ]
 [81.74021 ]
 [81.39692 ]
 [81.614624]
 [81.77438 ]
 [82.29418 ]
 [83.76537 ]
 [83.615295]
 [81.7163  ]
 [81.13916 ]
 [81.69281 ]
 [82.251495]
 [80.89222 ]], R is [[77.08184052]
 [76.3110199 ]
 [76.5479126 ]
 [76.78243256]
 [76.01461029]
 [76.2544632 ]
 [76.49192047]
 [76.727005  ]
 [76.95973206]
 [76.19013214]
 [76.42823029]
 [76.66394806]
 [76.89730835]
 [77.12833405]
 [76.35704803]
 [76.59347534]
 [75.82753754]
 [76.06925964]
 [76.30857086]
 [76.54548645]
 [75.7800293 ]
 [76.02223206]
 [76.26200867]
 [76.49938965]
 [75.73439789]].
[2019-04-24 11:01:36,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8893105e-01 9.5249854e-02 9.6520633e-15 4.9164977e-14 6.4388185e-14
 9.3781063e-16 1.4325136e-14 2.2171456e-15 1.1784670e-12 2.1581908e-01
 2.4312711e-15], sum to 1.0000
[2019-04-24 11:01:36,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6808
[2019-04-24 11:01:36,519] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.7, 75.0, 16.0, 0.0, 22.5, 21.62233170392649, -0.6110989099049885, 1.0, 1.0, 20.0, 56.19716798818522], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 806400.0000, 
sim time next is 807600.0000, 
raw observation next is [-6.533333333333334, 75.0, 26.66666666666667, 0.0, 22.5, 21.54539727983754, -0.7258899660832988, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.28162511542012925, 0.75, 0.0888888888888889, 0.0, 0.375, 0.2954497733197951, 0.25803667797223373, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3443887], dtype=float32), 0.98751736]. 
=============================================
[2019-04-24 11:01:42,122] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [6.6827387e-01 1.3099061e-02 6.4501610e-15 1.5193548e-14 7.8166428e-15
 1.9806354e-16 8.1993017e-16 3.6219671e-16 3.1514971e-13 3.1862703e-01
 6.3750352e-16], sum to 1.0000
[2019-04-24 11:01:42,123] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.8636
[2019-04-24 11:01:42,225] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.4043767e-01 2.3094974e-03 3.3650356e-16 3.9286680e-15 1.2030263e-15
 3.0036745e-17 5.4698496e-17 1.8603980e-17 1.0284682e-13 5.7252891e-02
 2.5120022e-16], sum to 1.0000
[2019-04-24 11:01:42,228] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.0495
[2019-04-24 11:01:42,256] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.2, 46.33333333333334, 84.16666666666667, 144.8333333333333, 22.5, 23.48981979517395, -0.2056701926409709, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 746400.0000, 
sim time next is 747600.0000, 
raw observation next is [-0.4, 45.66666666666667, 82.16666666666667, 26.33333333333334, 22.5, 23.33263408543241, -0.3805937065217357, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.45152354570637127, 0.4566666666666667, 0.2738888888888889, 0.02909760589318601, 0.375, 0.4443861737860342, 0.37313543115942144, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.74349725], dtype=float32), 1.0763406]. 
=============================================
[2019-04-24 11:01:42,264] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.2, 75.0, 74.0, 0.0, 22.5, 23.12041506321543, -0.452866377589242, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 813600.0000, 
sim time next is 814800.0000, 
raw observation next is [-5.633333333333334, 73.66666666666667, 82.66666666666666, 0.0, 22.5, 23.06183713658654, -0.2885850061997646, 1.0, 1.0, 60.0, 81.18381331180017], 
processed observation next is [1.0, 0.43478260869565216, 0.30655586334256696, 0.7366666666666667, 0.2755555555555555, 0.0, 0.375, 0.42181976138221167, 0.4038049979334118, 1.0, 1.0, 0.9, 0.8118381331180017], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02731424], dtype=float32), -0.7697721]. 
=============================================
[2019-04-24 11:01:50,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3814228e-01 1.2521173e-02 1.3595449e-18 8.6263781e-19 4.1658962e-18
 1.7504171e-19 2.9212943e-19 2.9406578e-20 4.5156964e-17 1.4933659e-01
 1.1725055e-19], sum to 1.0000
[2019-04-24 11:01:50,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5709
[2019-04-24 11:01:50,092] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [11.43333333333333, 77.0, 0.0, 0.0, 19.0, 21.46965514601561, -0.3654602227170031, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1140000.0000, 
sim time next is 1141200.0000, 
raw observation next is [11.6, 77.0, 0.0, 0.0, 19.0, 21.42910261617023, -0.372961532224318, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.7839335180055402, 0.77, 0.0, 0.0, 0.08333333333333333, 0.28575855134751915, 0.37567948925856065, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.26626438], dtype=float32), 0.3451279]. 
=============================================
[2019-04-24 11:01:51,307] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.9133825e-01 5.0395081e-04 9.5532561e-18 1.3315097e-16 1.3010921e-16
 6.8584641e-19 1.9650062e-18 6.3434051e-19 1.5086673e-14 8.1578856e-03
 1.1927195e-17], sum to 1.0000
[2019-04-24 11:01:51,309] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7496
[2019-04-24 11:01:51,325] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 49.0, 116.0, 0.0, 22.5, 24.6265157403482, 0.3195065434306801, 1.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1090800.0000, 
sim time next is 1092000.0000, 
raw observation next is [19.4, 49.0, 100.0, 0.0, 22.5, 24.98884049784143, 0.3775791534716849, 1.0, 0.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.49, 0.3333333333333333, 0.0, 0.375, 0.5824033748201192, 0.625859717823895, 1.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.2753749], dtype=float32), 1.7816237]. 
=============================================
[2019-04-24 11:01:52,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.01513529e-01 1.37807317e-02 1.08939215e-17 1.52491523e-17
 3.58142074e-17 7.48450079e-19 1.33894743e-18 3.06393308e-19
 8.00869440e-16 2.84705758e-01 1.13998837e-18], sum to 1.0000
[2019-04-24 11:01:52,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0871
[2019-04-24 11:01:52,791] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 40.5, 0.0, 22.5, 23.04235151936838, -0.2358517775817904, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1329600.0000, 
sim time next is 1330800.0000, 
raw observation next is [0.5, 92.0, 54.5, 0.0, 22.5, 22.84577882682876, -0.2708422675320293, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.4764542936288089, 0.92, 0.18166666666666667, 0.0, 0.375, 0.40381490223572997, 0.40971924415599026, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.3379631], dtype=float32), 0.8580927]. 
=============================================
[2019-04-24 11:01:55,776] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7756982e-01 2.4326118e-03 1.9664872e-19 4.5067467e-19 1.0103634e-18
 1.5210386e-20 3.3736833e-20 5.2193437e-21 2.6466145e-17 1.9997595e-02
 5.5289450e-20], sum to 1.0000
[2019-04-24 11:01:55,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4543
[2019-04-24 11:01:55,797] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.4, 97.33333333333334, 96.0, 0.0, 19.0, 22.0648872833641, -0.1773300658650497, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1251600.0000, 
sim time next is 1252800.0000, 
raw observation next is [14.4, 96.0, 98.0, 0.0, 19.0, 22.06355189603623, -0.1768595726905871, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.8614958448753465, 0.96, 0.32666666666666666, 0.0, 0.08333333333333333, 0.33862932466968587, 0.44104680910313765, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6762016], dtype=float32), 0.1437993]. 
=============================================
[2019-04-24 11:01:56,791] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.5728538e-01 1.0147936e-02 1.6415647e-17 2.2159297e-17 2.2206600e-17
 4.6520736e-19 1.1692233e-18 5.0354087e-19 2.9817940e-15 1.3256671e-01
 1.0253929e-18], sum to 1.0000
[2019-04-24 11:01:56,792] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0610
[2019-04-24 11:01:56,806] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 0.0, 0.0, 19.0, 20.28298255140614, -0.678781384079629, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1321200.0000, 
sim time next is 1322400.0000, 
raw observation next is [1.1, 92.0, 0.0, 0.0, 22.5, 20.10118796433603, -0.7024597660770061, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.49307479224376743, 0.92, 0.0, 0.0, 0.375, 0.17509899702800258, 0.26584674464099795, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25844842], dtype=float32), -0.6864016]. 
=============================================
[2019-04-24 11:01:57,311] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8942846e-01 1.5976150e-03 4.4491660e-17 4.2042647e-16 4.5469517e-16
 2.0598246e-17 4.9599586e-17 2.7862979e-18 2.4069014e-14 8.9738797e-03
 3.6648294e-16], sum to 1.0000
[2019-04-24 11:01:57,311] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6505
[2019-04-24 11:01:57,320] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 65.0, 120.0, 0.0, 19.0, 22.75781558956472, -0.06958494970118151, 0.0, 0.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1176000.0000, 
sim time next is 1177200.0000, 
raw observation next is [18.3, 65.0, 104.0, 0.0, 19.0, 22.74103770248455, -0.06717240176893857, 0.0, 0.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.9695290858725764, 0.65, 0.3466666666666667, 0.0, 0.08333333333333333, 0.39508647520704593, 0.4776091994103538, 0.0, 0.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.3795431], dtype=float32), 0.03302587]. 
=============================================
[2019-04-24 11:01:58,281] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4291483e-01 1.3232674e-01 1.8469672e-12 2.9674648e-12 2.9430017e-12
 2.2338886e-12 1.8305012e-12 3.3799764e-13 3.0913144e-11 2.2475839e-01
 1.0458429e-12], sum to 1.0000
[2019-04-24 11:01:58,283] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1452
[2019-04-24 11:01:58,353] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.166666666666666, 45.33333333333333, 63.5, 683.6666666666667, 19.0, 19.196142489482, -1.215265638363719, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2454000.0000, 
sim time next is 2455200.0000, 
raw observation next is [-5.6, 43.0, 68.5, 721.0, 19.0, 18.57759639424681, -1.290507682562143, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.43, 0.22833333333333333, 0.7966850828729282, 0.08333333333333333, 0.048133032853900914, 0.06983077247928564, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.2863, 
noisyNet noise sample is [array([0.8380019], dtype=float32), -0.48244587]. 
=============================================
[2019-04-24 11:02:01,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8398930e-01 1.2622850e-03 6.7662421e-21 1.5296791e-19 9.3661984e-20
 3.3347546e-22 9.9842618e-22 3.6590342e-22 2.0435373e-17 1.4748498e-02
 3.9668795e-21], sum to 1.0000
[2019-04-24 11:02:01,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2542
[2019-04-24 11:02:01,763] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.46666666666667, 50.33333333333334, 73.33333333333333, 6.166666666666665, 22.5, 24.97560326282714, 0.2478924665027175, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1611600.0000, 
sim time next is 1612800.0000, 
raw observation next is [13.3, 51.0, 64.0, 18.5, 22.5, 24.6647444376869, 0.1935557658712157, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.8310249307479226, 0.51, 0.21333333333333335, 0.020441988950276244, 0.375, 0.5553953698072416, 0.5645185886237386, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.8865479], dtype=float32), -0.11226341]. 
=============================================
[2019-04-24 11:02:02,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6510690e-01 2.0906285e-03 4.5051022e-20 4.7347275e-19 3.4472333e-19
 3.7911986e-22 1.3925949e-20 2.4175957e-21 2.2855966e-17 3.2802351e-02
 2.5409565e-20], sum to 1.0000
[2019-04-24 11:02:02,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2449
[2019-04-24 11:02:02,220] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [10.86666666666667, 58.33333333333334, 204.8333333333333, 228.1666666666667, 22.5, 24.1067112728015, 0.05473928639780689, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1597200.0000, 
sim time next is 1598400.0000, 
raw observation next is [11.6, 57.0, 182.5, 186.5, 22.5, 24.23294319986182, 0.07230094325251014, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.7839335180055402, 0.57, 0.6083333333333333, 0.20607734806629835, 0.375, 0.5194119333218182, 0.5241003144175034, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.2720455], dtype=float32), 1.0748605]. 
=============================================
[2019-04-24 11:02:05,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1337365e-01 6.3938820e-03 6.0196398e-18 3.6670382e-17 3.6715457e-17
 1.5805749e-19 3.0855994e-18 8.3716691e-19 1.1430391e-14 8.0232397e-02
 1.1724711e-18], sum to 1.0000
[2019-04-24 11:02:05,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5752
[2019-04-24 11:02:05,182] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 0.0, 0.0, 22.5, 21.72156897623151, -0.4224092043947825, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 1712400.0000, 
sim time next is 1713600.0000, 
raw observation next is [1.1, 88.0, 0.0, 0.0, 22.5, 21.38880935713524, -0.4712466808705759, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.49307479224376743, 0.88, 0.0, 0.0, 0.375, 0.28240077976127004, 0.34291777304314136, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.57075655], dtype=float32), -0.06134408]. 
=============================================
[2019-04-24 11:02:08,520] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.8107347e-01 4.3268565e-02 2.3660598e-13 1.0439919e-13 4.2781178e-13
 2.1196273e-14 7.0610530e-14 2.5327232e-14 4.9968137e-12 4.7565791e-01
 4.1463178e-14], sum to 1.0000
[2019-04-24 11:02:08,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7385
[2019-04-24 11:02:08,632] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.966666666666667, 78.0, 143.3333333333333, 86.83333333333334, 19.0, 19.76124326999285, -1.100474092067554, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1849200.0000, 
sim time next is 1850400.0000, 
raw observation next is [-5.6, 78.0, 134.0, 72.5, 19.0, 19.51306444366026, -0.9387476367356976, 0.0, 1.0, 60.0, 87.89140558464524], 
processed observation next is [0.0, 0.43478260869565216, 0.30747922437673136, 0.78, 0.44666666666666666, 0.08011049723756906, 0.08333333333333333, 0.1260887036383549, 0.1870841210881008, 0.0, 1.0, 0.9, 0.8789140558464524], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4229414], dtype=float32), -0.43283004]. 
=============================================
[2019-04-24 11:02:08,764] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [9.8039675e-01 6.4303307e-04 1.5553753e-20 6.6605358e-20 1.5094729e-19
 5.9941473e-22 9.4076972e-22 1.9546458e-21 3.4240979e-17 1.8960262e-02
 5.4258710e-21], sum to 1.0000
[2019-04-24 11:02:08,774] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.9835
[2019-04-24 11:02:08,847] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [12.56666666666667, 53.0, 41.83333333333334, 30.83333333333334, 22.5, 24.86606663467658, 0.203510939956873, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1615200.0000, 
sim time next is 1616400.0000, 
raw observation next is [12.2, 54.0, 25.5, 18.5, 22.5, 25.34701741030752, 0.3291462034756939, 1.0, 1.0, 60.0, 86.13052969135771], 
processed observation next is [1.0, 0.7391304347826086, 0.8005540166204987, 0.54, 0.085, 0.020441988950276244, 0.375, 0.6122514508589599, 0.6097154011585646, 1.0, 1.0, 0.9, 0.861305296913577], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8600456], dtype=float32), -1.665483]. 
=============================================
[2019-04-24 11:02:13,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6996248e-01 3.1713811e-03 6.6399699e-18 1.8654251e-17 3.2109917e-17
 3.6884167e-19 5.0284263e-19 8.6605739e-20 1.9664541e-15 2.6866220e-02
 1.4792960e-18], sum to 1.0000
[2019-04-24 11:02:13,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9806
[2019-04-24 11:02:13,207] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [0.1666666666666667, 94.0, 0.0, 0.0, 19.0, 21.91415107226003, -0.4170204419508181, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 1725600.0000, 
sim time next is 1726800.0000, 
raw observation next is [0.3333333333333333, 93.0, 0.0, 0.0, 19.0, 21.83488521245035, -0.2384075277286999, 0.0, 1.0, 60.0, 86.77164669316392], 
processed observation next is [1.0, 1.0, 0.4718374884579871, 0.93, 0.0, 0.0, 0.08333333333333333, 0.3195737677041957, 0.42053082409043335, 0.0, 1.0, 0.9, 0.8677164669316392], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8805285], dtype=float32), -0.11141818]. 
=============================================
[2019-04-24 11:02:18,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6324856e-01 5.1905300e-02 3.8886995e-15 1.6639725e-14 1.3203867e-14
 3.4240092e-16 2.2554196e-15 4.2867967e-16 1.9137865e-13 1.8484607e-01
 1.0481315e-15], sum to 1.0000
[2019-04-24 11:02:18,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6486
[2019-04-24 11:02:18,414] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.199999999999999, 87.0, 0.0, 0.0, 19.0, 19.93516134455756, -1.043499118069152, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2007600.0000, 
sim time next is 2008800.0000, 
raw observation next is [-6.2, 87.0, 0.0, 0.0, 19.0, 19.26292231979491, -1.132466256013964, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2908587257617729, 0.87, 0.0, 0.0, 0.08333333333333333, 0.10524352664957586, 0.12251124799534534, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.4677578], dtype=float32), -0.45390305]. 
=============================================
[2019-04-24 11:02:23,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8344691e-01 1.4753670e-02 2.0484677e-14 1.3838813e-13 3.2075389e-14
 1.8010955e-15 4.8953994e-15 7.6744455e-15 3.4410131e-12 2.0179942e-01
 4.2416928e-15], sum to 1.0000
[2019-04-24 11:02:23,395] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5610
[2019-04-24 11:02:23,460] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-5.4, 68.0, 129.0, 0.0, 22.5, 21.75286738862738, -0.5610738520906485, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2125200.0000, 
sim time next is 2126400.0000, 
raw observation next is [-5.199999999999999, 68.0, 118.5, 0.0, 22.5, 21.72564555878017, -0.5750946415369106, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.31855955678670367, 0.68, 0.395, 0.0, 0.375, 0.31047046323168076, 0.30830178615436316, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.8590, 
noisyNet noise sample is [array([3.26484], dtype=float32), -0.4455678]. 
=============================================
[2019-04-24 11:02:35,107] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.5270810e-01 1.0297076e-02 3.3839824e-15 2.3188794e-14 2.7767476e-15
 7.7192210e-17 5.1423481e-16 4.8099920e-16 3.7009057e-13 1.3699484e-01
 7.2970221e-16], sum to 1.0000
[2019-04-24 11:02:35,107] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.7453
[2019-04-24 11:02:35,215] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.566666666666667, 67.0, 141.3333333333333, 0.0, 22.5, 22.74408667849013, -0.4264387132552896, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2208000.0000, 
sim time next is 2209200.0000, 
raw observation next is [-3.733333333333333, 69.0, 140.0, 0.0, 22.5, 22.53372256267108, -0.5442058849452517, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.35918744228993543, 0.69, 0.4666666666666667, 0.0, 0.375, 0.37781021355592337, 0.3185980383515828, 1.0, 1.0, 0.0, 0.0], 
reward next is 0.9511, 
noisyNet noise sample is [array([0.32873628], dtype=float32), 1.9718038]. 
=============================================
[2019-04-24 11:02:36,261] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7253509e-01 9.9899787e-03 2.6839811e-14 1.1397236e-13 5.6030159e-14
 8.3689837e-15 9.4503661e-15 2.6204504e-15 1.8843995e-12 2.1747483e-01
 2.2976799e-14], sum to 1.0000
[2019-04-24 11:02:36,261] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2795
[2019-04-24 11:02:36,290] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 47.0, 98.33333333333333, 284.1666666666667, 19.0, 20.32038930884444, -0.8903565055171915, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2388000.0000, 
sim time next is 2389200.0000, 
raw observation next is [0.0, 47.0, 84.83333333333334, 293.8333333333334, 19.0, 19.80009397352644, -0.9580326506277966, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.2827777777777778, 0.3246777163904237, 0.08333333333333333, 0.15000783112720337, 0.1806557831240678, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.7085793], dtype=float32), -1.3394519]. 
=============================================
[2019-04-24 11:02:38,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1350189e-01 3.2309726e-02 1.4758781e-13 7.5022745e-14 1.5014232e-13
 3.3712538e-15 1.6081329e-14 1.4909181e-14 2.8844871e-12 6.5418839e-01
 3.0486266e-15], sum to 1.0000
[2019-04-24 11:02:38,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6060
[2019-04-24 11:02:38,654] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 19.65168605102926, -1.085567768753661, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 2172000.0000, 
sim time next is 2173200.0000, 
raw observation next is [-6.700000000000001, 78.0, 0.0, 0.0, 19.0, 19.54778187814999, -0.8243690360009541, 0.0, 1.0, 60.0, 97.50750884798822], 
processed observation next is [1.0, 0.13043478260869565, 0.2770083102493075, 0.78, 0.0, 0.0, 0.08333333333333333, 0.12898182317916587, 0.2252103213330153, 0.0, 1.0, 0.9, 0.9750750884798822], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5231694], dtype=float32), -0.64554703]. 
=============================================
[2019-04-24 11:02:42,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8191372e-01 2.5804615e-02 3.1664833e-14 6.4902165e-14 5.7770784e-14
 5.2570376e-15 6.8053185e-15 5.0957426e-15 1.4900588e-12 9.2281654e-02
 3.3876293e-14], sum to 1.0000
[2019-04-24 11:02:42,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6838
[2019-04-24 11:02:42,695] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 47.0, 98.33333333333333, 284.1666666666667, 19.0, 20.28366963392841, -0.8912669857281128, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2388000.0000, 
sim time next is 2389200.0000, 
raw observation next is [0.0, 47.0, 84.83333333333334, 293.8333333333334, 19.0, 19.76224780976428, -0.9591837406605065, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.46260387811634357, 0.47, 0.2827777777777778, 0.3246777163904237, 0.08333333333333333, 0.14685398414702325, 0.18027208644649784, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.27268964], dtype=float32), 0.87319404]. 
=============================================
[2019-04-24 11:02:45,797] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-24 11:02:45,799] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation job starts!
[2019-04-24 11:02:45,799] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:02:45,801] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res1/Eplus-env-sub_run18
[2019-04-24 11:02:45,826] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation job starts!
[2019-04-24 11:02:45,828] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation job starts!
[2019-04-24 11:02:45,829] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:02:45,830] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:02:45,834] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v3-res1/Eplus-env-sub_run18
[2019-04-24 11:02:45,835] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Test-Repeat-v4-res1/Eplus-env-sub_run18
[2019-04-24 11:04:53,276] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v3 INFO:Evaluation: average rewards by now are 3439.4125 64536.4594 -180.5189
[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,309] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:04:53,480] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v3_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:06,927] A3C_EVAL-Part4-Light-Pit-Train-Repeat-v2 INFO:Evaluation: average rewards by now are 3183.4094 78582.5049 -473.7378
[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:06,963] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:07,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,651] A3C_EVAL-Part4-Light-Pit-Test-Repeat-v4 INFO:Evaluation: average rewards by now are 3144.4588 80930.5049 -517.4631
[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,687] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:20,885] EPLUS_ENV_Part4-Light-Pit-Test-Repeat-v4_MainThread-EPLUSPROCESS_EPI_0 ERROR:Aborted (core dumped)

[2019-04-24 11:05:21,689] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 850000, evaluation results [850000.0, 3183.40942142474, 78582.50492737434, -473.7378256215902, 3439.412514062269, 64536.459399229294, -180.51891361618192, 3144.458813207374, 80930.50488615382, -517.4631439576162]
[2019-04-24 11:05:23,247] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [9.6127385e-01 2.5515005e-03 4.0192319e-17 2.1695307e-15 3.8232455e-16
 1.9198460e-17 4.0945503e-17 2.6648829e-17 7.2508812e-14 3.6174621e-02
 4.6093908e-17], sum to 1.0000
[2019-04-24 11:05:23,252] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.1301
[2019-04-24 11:05:23,324] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [3.3, 29.0, 92.0, 256.5, 22.5, 23.83127338763431, -0.2620936892422703, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2563200.0000, 
sim time next is 2564400.0000, 
raw observation next is [3.1, 29.0, 77.33333333333333, 193.5, 22.5, 22.9858661348626, -0.2984795506384987, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.5484764542936289, 0.29, 0.2577777777777778, 0.2138121546961326, 0.375, 0.4154888445718834, 0.40050681645383374, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0070714], dtype=float32), 0.9977798]. 
=============================================
[2019-04-24 11:05:24,208] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [8.77890408e-01 4.29450814e-03 6.62944577e-16 1.18887647e-14
 4.38865685e-15 1.50312561e-16 7.29367048e-16 2.05449774e-16
 4.48205356e-13 1.17815055e-01 1.98868394e-16], sum to 1.0000
[2019-04-24 11:05:24,237] A3C_AGENT_WORKER-Thread-5 DEBUG:Softmax action selection sampled number: 0.6402
[2019-04-24 11:05:24,286] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 41.33333333333334, 0.0, 0.0, 22.5, 21.57786411954551, -0.5314514999706873, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2576400.0000, 
sim time next is 2577600.0000, 
raw observation next is [-1.7, 44.0, 0.0, 0.0, 22.5, 21.33562850586799, -0.5789707143626173, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4155124653739613, 0.44, 0.0, 0.0, 0.375, 0.2779690421556659, 0.3070097618791276, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0070714], dtype=float32), 0.9977798]. 
=============================================
[2019-04-24 11:05:37,141] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [5.76467693e-01 9.74451303e-02 1.00630279e-12 5.03722758e-12
 2.24446698e-12 1.86235372e-13 4.76018801e-13 6.17074805e-13
 4.26287686e-11 3.26087147e-01 1.12605536e-13], sum to 1.0000
[2019-04-24 11:05:37,142] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.1503
[2019-04-24 11:05:37,174] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 0.0, 0.0, 19.0, 18.79716904404548, -1.21883056529865, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2696400.0000, 
sim time next is 2697600.0000, 
raw observation next is [-15.33333333333334, 83.0, 0.0, 0.0, 19.0, 18.17588052138133, -1.316174743990597, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.03785780240073851, 0.83, 0.0, 0.0, 0.08333333333333333, 0.014656710115110863, 0.06127508533646764, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.914324], dtype=float32), 0.692851]. 
=============================================
[2019-04-24 11:05:47,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7082820e-01 4.4268887e-02 1.1392349e-13 5.2958159e-13 2.2036614e-13
 5.6940103e-14 5.4381972e-14 1.2097538e-14 5.5237893e-12 3.8490286e-01
 6.7293820e-14], sum to 1.0000
[2019-04-24 11:05:47,932] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4923
[2019-04-24 11:05:47,951] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 77.0, 0.0, 0.0, 19.0, 18.8385176174467, -1.006883662563143, 0.0, 1.0, 60.0, 89.48940733475763], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3034800.0000, 
sim time next is 3036000.0000, 
raw observation next is [-6.0, 77.0, 0.0, 0.0, 19.0, 19.47538525856906, -1.120062715112352, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.296398891966759, 0.77, 0.0, 0.0, 0.08333333333333333, 0.12294877154742156, 0.12664576162921604, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.6546296], dtype=float32), -0.6236588]. 
=============================================
[2019-04-24 11:05:52,696] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [9.6826708e-01 1.4854365e-03 4.2918225e-18 3.3445936e-17 2.4733748e-17
 4.5918921e-19 6.2281939e-19 3.0421025e-19 5.1226164e-15 3.0247483e-02
 2.5542632e-18], sum to 1.0000
[2019-04-24 11:05:52,697] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.8294
[2019-04-24 11:05:52,734] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 82.66666666666667, 0.0, 0.0, 19.0, 22.0394454233454, -0.1596650753250543, 0.0, 1.0, 60.0, 91.4777316894934], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 2925600.0000, 
sim time next is 2926800.0000, 
raw observation next is [-1.0, 85.0, 0.0, 0.0, 19.0, 22.69011059455372, -0.2825908857475178, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.85, 0.0, 0.0, 0.08333333333333333, 0.3908425495461432, 0.4058030380841607, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.6602292], dtype=float32), 0.18861543]. 
=============================================
[2019-04-24 11:05:52,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.9524294e-01 1.2694557e-02 6.8896007e-14 5.8314464e-14 7.4785061e-14
 1.4397136e-14 1.5999190e-14 1.5506347e-15 2.6062763e-12 2.9206255e-01
 6.2378203e-14], sum to 1.0000
[2019-04-24 11:05:52,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3872
[2019-04-24 11:05:52,952] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 104.0, 790.5, 19.0, 19.96117295163841, -0.8879009936006522, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3074400.0000, 
sim time next is 3075600.0000, 
raw observation next is [-0.6666666666666667, 41.0, 100.6666666666667, 780.1666666666667, 19.0, 19.72963309338585, -0.9183234317552124, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.44413665743305636, 0.41, 0.33555555555555566, 0.8620626151012892, 0.08333333333333333, 0.1441360911154875, 0.19389218941492922, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0101548], dtype=float32), -0.059827108]. 
=============================================
[2019-04-24 11:05:53,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4573575e-01 3.9918800e-03 9.5068445e-15 2.2139478e-14 2.4500931e-14
 3.4043097e-15 2.2888956e-15 2.5035329e-16 5.9866185e-13 5.0272334e-02
 1.9602521e-14], sum to 1.0000
[2019-04-24 11:05:53,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7914
[2019-04-24 11:05:53,131] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 39.33333333333334, 86.5, 690.0, 19.0, 21.15607570516039, -0.6636511976963116, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3079200.0000, 
sim time next is 3080400.0000, 
raw observation next is [0.6666666666666666, 39.66666666666666, 79.5, 641.8333333333334, 19.0, 20.83250154899999, -0.7342294376844952, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4810710987996307, 0.39666666666666656, 0.265, 0.7092081031307551, 0.08333333333333333, 0.2360417957499991, 0.25525685410516824, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0101548], dtype=float32), -0.059827108]. 
=============================================
[2019-04-24 11:05:54,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8508146e-01 3.9452359e-02 2.2837721e-13 4.0297691e-13 5.8741488e-13
 2.2148411e-14 7.3513502e-14 1.0984459e-14 1.6874211e-12 3.7546626e-01
 2.5887646e-14], sum to 1.0000
[2019-04-24 11:05:54,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5671
[2019-04-24 11:05:54,184] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 65.0, 0.0, 0.0, 19.0, 19.56661417031939, -1.089360912765751, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3018000.0000, 
sim time next is 3019200.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 19.0, 18.86258989346452, -1.190911127620991, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.3518005540166205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.07188249112204333, 0.10302962412633636, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.9245, 
noisyNet noise sample is [array([-2.2291732], dtype=float32), -0.52481925]. 
=============================================
[2019-04-24 11:05:55,353] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [8.6752415e-01 1.2973321e-02 3.2867674e-14 1.7277362e-13 1.4558962e-13
 7.5987919e-15 2.1014779e-14 5.2379709e-15 2.1694662e-12 1.1950256e-01
 1.5107217e-14], sum to 1.0000
[2019-04-24 11:05:55,355] A3C_AGENT_WORKER-Thread-4 DEBUG:Softmax action selection sampled number: 0.0274
[2019-04-24 11:05:55,388] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 68.33333333333333, 14.66666666666666, 118.1666666666667, 19.0, 19.68682420262887, -0.8781094903223, 0.0, 1.0, 60.0, 80.24299273983762], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3051600.0000, 
sim time next is 3052800.0000, 
raw observation next is [-6.0, 64.0, 42.0, 214.5, 19.0, 19.97494176881857, -0.9906102605083147, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.296398891966759, 0.64, 0.14, 0.23701657458563535, 0.08333333333333333, 0.1645784807348809, 0.16979657983056176, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-2.2240238], dtype=float32), 0.31685975]. 
=============================================
[2019-04-24 11:05:58,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.5768354e-01 1.4343674e-02 3.9447666e-14 1.9161643e-13 1.1419504e-13
 3.7959904e-14 1.7005269e-14 5.4268715e-15 2.2784340e-12 1.2797283e-01
 4.7432280e-14], sum to 1.0000
[2019-04-24 11:05:58,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4274
[2019-04-24 11:05:58,256] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-3.666666666666667, 54.33333333333334, 110.1666666666667, 797.3333333333334, 19.0, 20.90624674249163, -0.7789112218181646, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3064800.0000, 
sim time next is 3066000.0000, 
raw observation next is [-3.333333333333333, 54.66666666666667, 111.5, 807.0, 19.0, 20.29967462580364, -0.8593223064909722, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.37026777469990774, 0.5466666666666667, 0.37166666666666665, 0.8917127071823204, 0.08333333333333333, 0.1916395521503033, 0.21355923116967593, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.1607586], dtype=float32), -1.093349]. 
=============================================
[2019-04-24 11:06:07,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8283341e-01 2.9854003e-02 1.2194503e-16 1.4426963e-16 5.0090855e-16
 5.9661105e-18 5.3970944e-17 1.0892988e-17 2.2786699e-14 3.8731253e-01
 1.8942332e-17], sum to 1.0000
[2019-04-24 11:06:07,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1393
[2019-04-24 11:06:07,626] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [1.0, 67.0, 0.0, 0.0, 19.0, 20.21599416190455, -0.8322401773385252, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3470400.0000, 
sim time next is 3471600.0000, 
raw observation next is [0.6666666666666667, 68.66666666666667, 0.0, 0.0, 19.0, 19.95955792969473, -0.8757719301518102, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.4810710987996307, 0.6866666666666668, 0.0, 0.0, 0.08333333333333333, 0.16329649414122738, 0.20807602328272992, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.09451617], dtype=float32), -0.4889453]. 
=============================================
[2019-04-24 11:06:14,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5834780e-01 3.5479502e-03 2.2930337e-17 1.4298301e-16 8.1332951e-17
 1.7026921e-18 3.9996958e-18 1.0183270e-18 5.4941437e-15 3.8104214e-02
 5.3525927e-18], sum to 1.0000
[2019-04-24 11:06:14,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0318
[2019-04-24 11:06:14,309] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 0.0, 0.0, 19.0, 22.15470672641564, -0.2847031146141953, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3530400.0000, 
sim time next is 3531600.0000, 
raw observation next is [0.0, 72.0, 0.0, 0.0, 19.0, 22.03117276126003, -0.3084412452172137, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.46260387811634357, 0.72, 0.0, 0.0, 0.08333333333333333, 0.3359310634383359, 0.3971862515942621, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-1.6496732], dtype=float32), 0.6643426]. 
=============================================
[2019-04-24 11:06:17,279] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_12 ERROR:*** stack smashing detected ***: /home/zhiangz/Documents/HVAC-RL-Control/src/eplus-env/eplus_env/envs/EnergyPlus-8-3-0//energyplus terminated

[2019-04-24 11:06:17,452] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18-EPLUSPROCESS_EPI_12 ERROR:Aborted (core dumped)

[2019-04-24 11:06:18,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-24 11:06:18,277] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-24 11:06:18,281] EPLUS_ENV_Part4-Light-Pit-Train-Repeat-v2_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part4_pit_lightx/4/Eplus-env-Part4-Light-Pit-Train-Repeat-v2-res15/Eplus-env-sub_run14
[2019-04-24 11:06:25,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8695743e-01 9.3064073e-04 1.2023676e-17 1.1220994e-16 5.6296926e-17
 7.1528986e-19 2.7832119e-18 1.1762090e-18 5.3910903e-15 1.2111948e-02
 2.1077029e-17], sum to 1.0000
[2019-04-24 11:06:25,779] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3625
[2019-04-24 11:06:25,810] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333333, 57.0, 0.0, 0.0, 19.0, 23.0214060259427, -0.2200516420602686, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 3876000.0000, 
sim time next is 3877200.0000, 
raw observation next is [-1.0, 60.0, 0.0, 0.0, 19.0, 22.44768323023094, -0.3043010014442996, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.4349030470914128, 0.6, 0.0, 0.0, 0.08333333333333333, 0.37064026918591164, 0.3985663328519002, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2402476], dtype=float32), -0.7338312]. 
=============================================
[2019-04-24 11:06:27,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.07287407e-01 2.60385871e-02 9.86270129e-16 1.53106542e-15
 2.27640380e-15 1.04086625e-16 1.54577716e-16 7.16034207e-17
 4.34236895e-14 3.66673976e-01 6.50508267e-17], sum to 1.0000
[2019-04-24 11:06:27,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8810
[2019-04-24 11:06:27,406] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-5.0, 77.0, 48.0, 298.0, 22.5, 20.13520060163107, -0.788903083179215, 1.0, 1.0, 20.0, 54.47279278604967], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3830400.0000, 
sim time next is 3831600.0000, 
raw observation next is [-4.666666666666667, 75.0, 76.66666666666667, 397.3333333333333, 22.5, 20.53753593526626, -0.5798808792117013, 1.0, 1.0, 60.0, 71.61550501032858], 
processed observation next is [1.0, 0.34782608695652173, 0.3333333333333333, 0.75, 0.2555555555555556, 0.43904235727440144, 0.375, 0.21146132793885494, 0.3067063735960996, 1.0, 1.0, 0.9, 0.7161550501032857], 
reward next is 0.3994, 
noisyNet noise sample is [array([1.5822011], dtype=float32), -0.8853339]. 
=============================================
[2019-04-24 11:06:29,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5322361e-01 3.7132945e-02 1.8233299e-15 3.0296941e-15 7.0326778e-15
 1.0686056e-16 5.8588300e-16 8.7950733e-17 8.5904320e-14 4.0964344e-01
 1.5908151e-16], sum to 1.0000
[2019-04-24 11:06:29,355] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8348
[2019-04-24 11:06:29,436] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-2.0, 65.0, 0.0, 0.0, 19.0, 20.89916543820813, -0.7498415004212667, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 3897600.0000, 
sim time next is 3898800.0000, 
raw observation next is [-2.0, 65.0, 0.0, 0.0, 19.0, 20.88377494192481, -0.512306272776195, 0.0, 1.0, 60.0, 93.4829036881277], 
processed observation next is [1.0, 0.13043478260869565, 0.40720221606648205, 0.65, 0.0, 0.0, 0.08333333333333333, 0.24031457849373408, 0.329231242407935, 0.0, 1.0, 0.9, 0.934829036881277], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7901195], dtype=float32), -1.9659654]. 
=============================================
[2019-04-24 11:06:32,902] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5752734e-01 3.9530527e-03 1.2389698e-18 4.7300379e-18 1.2756545e-17
 3.9880458e-19 7.4267295e-19 1.1611367e-19 2.2921908e-16 3.8519558e-02
 3.2766751e-19], sum to 1.0000
[2019-04-24 11:06:32,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5448
[2019-04-24 11:06:32,925] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [4.300000000000001, 74.0, 0.0, 0.0, 19.0, 21.40130970650137, -0.6511836802789709, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4324800.0000, 
sim time next is 4326000.0000, 
raw observation next is [4.4, 73.0, 0.0, 0.0, 19.0, 21.27065346888232, -0.7335807345958202, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.5844875346260389, 0.73, 0.0, 0.0, 0.08333333333333333, 0.27255445574019327, 0.25547308846805994, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.8634477], dtype=float32), 0.80956644]. 
=============================================
[2019-04-24 11:06:36,468] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [6.4392471e-01 3.4588095e-02 3.2967058e-14 1.3438328e-14 1.9189067e-14
 5.1094937e-15 3.7655362e-15 7.9850886e-16 8.0899735e-13 3.2148725e-01
 9.4510776e-15], sum to 1.0000
[2019-04-24 11:06:36,477] A3C_AGENT_WORKER-Thread-7 DEBUG:Softmax action selection sampled number: 0.7802
[2019-04-24 11:06:36,548] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [1.0, 47.0, 0.0, 0.0, 19.0, 19.84762688389405, -0.9961264466592837, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4227600.0000, 
sim time next is 4228800.0000, 
raw observation next is [1.0, 47.0, 0.0, 0.0, 19.0, 20.12347837650698, -0.7103696626675554, 0.0, 1.0, 60.0, 93.54312069951192], 
processed observation next is [0.0, 0.9565217391304348, 0.4903047091412743, 0.47, 0.0, 0.0, 0.08333333333333333, 0.17695653137558173, 0.2632101124441482, 0.0, 1.0, 0.9, 0.9354312069951192], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0691364], dtype=float32), 0.6348227]. 
=============================================
[2019-04-24 11:06:44,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7631593e-01 5.5646837e-02 1.9986905e-12 8.5091214e-12 1.5183911e-11
 1.1155897e-12 2.2785784e-12 7.8773359e-13 1.0845457e-10 1.6803730e-01
 6.2495896e-13], sum to 1.0000
[2019-04-24 11:06:44,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7220
[2019-04-24 11:06:44,617] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-15.6, 73.0, 0.0, 0.0, 19.0, 17.65879954750446, -1.373042812190023, 0.0, 1.0, 60.0, 94.92260483463974], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 363600.0000, 
sim time next is 364800.0000, 
raw observation next is [-15.8, 74.66666666666667, 0.0, 0.0, 19.0, 17.94768051692971, -1.538449629474634, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.024930747922437636, 0.7466666666666667, 0.0, 0.0, 0.08333333333333333, -0.004359956922524037, -0.01281654315821131, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.9279933], dtype=float32), 0.19181441]. 
=============================================
[2019-04-24 11:06:45,110] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [3.42857331e-01 2.91145910e-02 1.24622184e-16 9.78626199e-17
 5.54118631e-16 5.21054385e-18 2.88098570e-17 7.05846286e-18
 1.40096327e-14 6.28028035e-01 1.16532965e-17], sum to 1.0000
[2019-04-24 11:06:45,120] A3C_AGENT_WORKER-Thread-6 DEBUG:Softmax action selection sampled number: 0.3873
[2019-04-24 11:06:45,332] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 9, 
current raw observation is [-0.8, 73.0, 55.5, 33.0, 22.5, 19.73922149664089, -0.9237076041684097, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [1, 60.0], 
sim time this is 4521600.0000, 
sim time next is 4522800.0000, 
raw observation next is [-0.5333333333333334, 72.66666666666667, 92.5, 55.0, 22.5, 20.63097041475552, -0.369963639834266, 1.0, 1.0, 60.0, 124.02848865742669], 
processed observation next is [1.0, 0.34782608695652173, 0.44783010156971376, 0.7266666666666667, 0.30833333333333335, 0.06077348066298342, 0.375, 0.21924753456296, 0.3766787867219113, 1.0, 1.0, 0.9, 1.2402848865742668], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02081478], dtype=float32), 0.6908199]. 
=============================================
[2019-04-24 11:06:47,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0511680e-01 7.0355167e-03 4.1152583e-15 8.9278933e-15 1.5325250e-14
 3.3857371e-16 1.4474157e-15 2.7497935e-16 2.7117547e-13 8.7847695e-02
 1.4309294e-15], sum to 1.0000
[2019-04-24 11:06:47,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5983
[2019-04-24 11:06:47,166] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 0.0, 0.0, 19.0, 19.77933763038785, -0.7083865451931742, 0.0, 1.0, 60.0, 92.15239877758927], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4759200.0000, 
sim time next is 4760400.0000, 
raw observation next is [-4.666666666666667, 78.0, 0.0, 0.0, 19.0, 20.47290800832993, -0.8257951320259177, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.3333333333333333, 0.78, 0.0, 0.0, 0.08333333333333333, 0.20607566736082758, 0.22473495599136076, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.2398132], dtype=float32), -0.9597711]. 
=============================================
[2019-04-24 11:06:47,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.82121468e-01 2.30598776e-03 5.06293933e-16 3.33736169e-15
 3.03198641e-15 5.73216153e-16 1.67662628e-16 1.19108039e-16
 4.71388404e-14 1.55725675e-02 5.22052663e-16], sum to 1.0000
[2019-04-24 11:06:47,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3957
[2019-04-24 11:06:47,440] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 56.66666666666667, 0.0, 0.0, 19.0, 20.44449767683929, -0.5629152531852354, 0.0, 1.0, 60.0, 94.88691436266001], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4836000.0000, 
sim time next is 4837200.0000, 
raw observation next is [-1.666666666666667, 58.33333333333334, 0.0, 0.0, 19.0, 21.38536689606031, -0.660428555547636, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 1.0, 0.4164358264081256, 0.5833333333333335, 0.0, 0.0, 0.08333333333333333, 0.28211390800502595, 0.279857148150788, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([1.0156903], dtype=float32), -0.50155467]. 
=============================================
[2019-04-24 11:06:47,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6440923e-01 2.3783611e-03 5.3778854e-18 3.3069834e-17 1.3811191e-17
 7.6553556e-20 1.1186516e-18 1.1117555e-18 1.1511862e-15 3.3212502e-02
 2.5278826e-18], sum to 1.0000
[2019-04-24 11:06:47,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4007
[2019-04-24 11:06:47,955] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 51.0, 227.0, 40.0, 22.5, 23.16472897366494, -0.1780214069289708, 1.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4540800.0000, 
sim time next is 4542000.0000, 
raw observation next is [2.666666666666667, 50.0, 249.8333333333333, 58.83333333333333, 22.5, 23.33220296456311, -0.2329687172007368, 1.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.5364727608494922, 0.5, 0.8327777777777776, 0.06500920810313075, 0.375, 0.4443502470469258, 0.42234376093308773, 1.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([-0.39360952], dtype=float32), 0.28521034]. 
=============================================
[2019-04-24 11:06:48,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.93394315e-01 7.62246375e-04 2.88173451e-18 1.50545217e-17
 9.84291162e-18 8.27591683e-20 1.00893203e-19 2.25764834e-19
 7.54429694e-16 5.84339024e-03 1.29021306e-18], sum to 1.0000
[2019-04-24 11:06:48,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9409
[2019-04-24 11:06:48,950] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 84.33333333333334, 0.0, 0.0, 19.0, 21.56298923569413, -0.2424516224532579, 0.0, 1.0, 60.0, 99.460163627885], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4743600.0000, 
sim time next is 4744800.0000, 
raw observation next is [-3.0, 84.0, 0.0, 0.0, 19.0, 22.50411614352845, -0.3330248127634623, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.3795013850415513, 0.84, 0.0, 0.0, 0.08333333333333333, 0.37534301196070413, 0.3889917290788459, 0.0, 1.0, 0.0, 0.0], 
reward next is 1.0000, 
noisyNet noise sample is [array([0.2752184], dtype=float32), -1.4164048]. 
=============================================
[2019-04-24 11:06:49,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2737267e-01 1.1200171e-02 5.8968858e-15 3.9904302e-14 3.6192529e-14
 3.8781154e-15 1.3756432e-14 1.8663134e-15 9.3397143e-13 1.6142718e-01
 9.3109978e-15], sum to 1.0000
[2019-04-24 11:06:49,350] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5684
[2019-04-24 11:06:49,375] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [-6.066666666666666, 92.33333333333334, 0.0, 0.0, 19.0, 19.27159511710247, -1.102254650049799, 0.0, 1.0, 15.0, 0.0], 
current ob forecast is [], 
actual action is [0, 15.0], 
sim time this is 4774800.0000, 
sim time next is 4776000.0000, 
raw observation next is [-6.133333333333333, 92.66666666666667, 0.0, 0.0, 19.0, 18.61918493490867, -1.197995060053574, 0.0, 1.0, 15.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.2927054478301016, 0.9266666666666667, 0.0, 0.0, 0.08333333333333333, 0.05159874457572252, 0.10066831331547532, 0.0, 1.0, 0.0, 0.0], 
reward next is 0.4199, 
noisyNet noise sample is [array([-0.895767], dtype=float32), 0.7237334]. 
=============================================
[2019-04-24 11:06:50,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.79634202e-01 7.18192570e-03 2.35060196e-17 4.36601313e-17
 3.93336524e-17 5.75646259e-19 2.13485638e-18 1.51024641e-18
 2.17568756e-15 1.13183886e-01 2.13523109e-18], sum to 1.0000
[2019-04-24 11:06:50,659] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7013
