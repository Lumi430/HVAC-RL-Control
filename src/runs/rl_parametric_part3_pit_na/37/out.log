Using TensorFlow backend.
[2019-03-23 07:18:41,165] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Pit-Train-v1', eval_act_func='part3_pit_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Pit-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'], test_mode='Multiple', train_act_func='part3_pit_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=21)
[2019-03-23 07:18:41,166] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 07:18:41.256066: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 07:19:11,693] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 07:19:11,693] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Pit-Train-v1', 'Part3-NA-Pit-Test-v1', 'Part3-NA-Pit-Test-v2', 'Part3-NA-Pit-Test-v3', 'Part3-NA-Pit-Test-v4'] ...
[2019-03-23 07:19:11,708] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 07:19:11,712] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 07:19:11,714] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 07:19:11,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 07:19:11,724] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 07:19:11,724] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:11,724] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 07:19:11,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:11,816] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 07:19:12,725] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:12,727] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 07:19:12,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:12,834] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 07:19:13,329] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 07:19:13,329] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:19:13,329] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:19:13,330] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:13,330] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:19:13,330] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:19:13,330] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:13,331] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:13,331] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:13,331] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:19:13,332] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:13,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 07:19:13,335] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 07:19:13,358] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 07:19:13,358] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 07:19:13,369] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 07:19:13,728] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:13,729] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 07:19:13,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:13,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 07:19:14,730] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:14,734] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 07:19:15,003] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:15,004] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 07:19:15,735] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:15,736] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 07:19:15,896] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:15,897] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 07:19:16,738] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:16,741] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 07:19:16,866] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:16,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 07:19:17,742] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:17,748] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 07:19:17,878] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:17,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 07:19:18,749] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:18,754] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 07:19:18,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:18,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 07:19:19,755] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:19,760] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 07:19:19,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:19,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 07:19:20,760] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:20,763] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 07:19:20,885] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:20,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 07:19:21,764] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:21,769] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 07:19:21,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:21,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 07:19:22,771] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:22,774] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 07:19:22,892] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:22,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 07:19:23,775] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:23,780] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 07:19:23,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:23,924] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 07:19:24,780] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:24,782] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 07:19:24,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:24,939] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 07:19:25,783] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:25,788] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 07:19:25,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:25,934] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 07:19:26,788] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 07:19:26,793] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 07:19:26,938] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:19:26,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 07:19:38,350] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 07:19:38,351] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.55, 68.83333333333333, 1.0, 2.0, 0.2707365653834838, 1.0, 1.0, 0.2707365653834838, 1.0, 2.0, 0.5484184819239275, 6.911199999999999, 6.9112, 95.55338769695034, 923283.044824926, 923283.0448249263, 254962.4022747339]
[2019-03-23 07:19:38,352] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:19:38,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.18689    0.22008006 0.18757519 0.21211994 0.19333477], sampled 0.90006167591888
[2019-03-23 07:19:52,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 07:19:52,312] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.33083248166667, 88.552910115, 1.0, 1.0, 0.246999184169913, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769694997, 268174.6590251059, 268174.6590251059, 83778.19859575073]
[2019-03-23 07:19:52,313] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:19:52,317] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.1913512  0.21732487 0.18872885 0.20726088 0.19533417], sampled 0.4975641400218406
[2019-03-23 07:20:16,969] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 07:20:16,970] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.29685253666667, 57.13252845666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7325791271609488, 7.300376042466477, 6.9112, 95.55223115249244, 576812.6871126855, 420628.8026038554, 134140.4387484555]
[2019-03-23 07:20:16,971] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:20:16,974] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [0.19102548 0.21252282 0.19027832 0.21206477 0.1941086 ], sampled 0.579767201429129
[2019-03-23 07:20:28,689] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 07:20:28,690] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.8, 63.0, 1.0, 2.0, 0.2, 1.0, 2.0, 0.2, 0.0, 1.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 257406.3767635882, 257406.3767635882, 109520.2123363112]
[2019-03-23 07:20:28,692] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:20:28,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [0.18953174 0.21687722 0.18432894 0.21571636 0.19354568], sampled 0.8212576653485402
[2019-03-23 07:20:33,436] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 07:20:33,436] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7276179968409434, 7.042034957946123, 6.9112, 77.32803731407651, 462333.9507579155, 419841.6666157332, 127774.7086061773]
[2019-03-23 07:20:33,437] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:20:33,438] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [0.1917679  0.21936087 0.18535328 0.20885727 0.19466072], sampled 0.8658530081639626
[2019-03-23 07:21:06,399] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 2377.7850 2010707406.7028 846.0000
[2019-03-23 07:21:06,447] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 2432.1842 2007648076.3389 890.0000
[2019-03-23 07:21:06,536] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 2443.1052 1996324358.0918 826.0000
[2019-03-23 07:21:06,692] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 2612.5480 2078662721.9044 693.0000
[2019-03-23 07:21:06,753] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 2388.0024 2025749901.1569 1089.0000
[2019-03-23 07:21:07,769] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 2612.5479760752355, 2078662721.9043822, 693.0, 2443.105158091609, 1996324358.09184, 826.0, 2432.1841957567526, 2007648076.338948, 890.0, 2388.0023866375905, 2025749901.1569154, 1089.0, 2377.7849738133887, 2010707406.7027888, 846.0]
[2019-03-23 07:21:16,361] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3207164e-17 1.0000000e+00 1.1035922e-25 2.2465714e-17 3.6952973e-21], sum to 1.0000
[2019-03-23 07:21:16,367] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-23 07:21:16,524] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 214431.4871091022, 214431.4871091022, 69751.98145993508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 103200.0000, 
sim time next is 103800.0000, 
raw observation next is [13.0, 83.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213905.7186742377, 213905.718674238, 69514.0047497881], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.83, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07922434024971767, 0.07922434024971778, 0.16954635304826365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5790937], dtype=float32), -0.567849]. 
=============================================
[2019-03-23 07:21:16,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4386353e-08 1.0000000e+00 2.5641503e-12 7.4056570e-09 2.4378297e-10], sum to 1.0000
[2019-03-23 07:21:16,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4120
[2019-03-23 07:21:16,972] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 81.16666666666667, 1.0, 2.0, 0.2091861501992497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227122.2344142996, 227122.2344142993, 73034.17273165524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 112200.0000, 
sim time next is 112800.0000, 
raw observation next is [14.66666666666667, 80.33333333333334, 1.0, 2.0, 0.2117416279528564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229897.4802037085, 229897.4802037088, 73873.53299780443], 
processed observation next is [1.0, 0.30434782608695654, 0.30303030303030315, 0.8033333333333335, 1.0, 1.0, 0.014677034941070477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0851472148902624, 0.08514721489026252, 0.18017934877513275], 
reward next is 0.8198, 
noisyNet noise sample is [array([-0.64162964], dtype=float32), 1.4390843]. 
=============================================
[2019-03-23 07:21:23,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.5078614e-10 2.9804607e-25 3.0376185e-20 1.1824533e-22], sum to 1.0000
[2019-03-23 07:21:23,427] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0504
[2019-03-23 07:21:23,583] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.66666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289234204407994, 6.911199999999999, 6.9112, 77.32846344354104, 307653.67948689, 307653.6794868903, 103872.4818261099], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 235200.0000, 
sim time next is 235800.0000, 
raw observation next is [18.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5290171247028502, 6.911199999999999, 6.9112, 77.32846344354104, 307708.2007657506, 307708.2007657509, 103639.1966996907], 
processed observation next is [0.0, 0.7391304347826086, 0.45454545454545453, 0.79, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.3271673210040718, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11396600028361134, 0.11396600028361144, 0.252778528535831], 
reward next is 0.7472, 
noisyNet noise sample is [array([1.8990247], dtype=float32), -1.0001813]. 
=============================================
[2019-03-23 07:21:25,047] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 07:21:25,055] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5203
[2019-03-23 07:21:25,066] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.5, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3996947168460712, 6.911200000000001, 6.9112, 77.32846344354104, 232468.5273561859, 232468.5273561856, 74338.9361518767], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 261000.0000, 
sim time next is 261600.0000, 
raw observation next is [13.33333333333333, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3910751193441473, 6.911200000000001, 6.9112, 77.32846344354104, 227454.066146922, 227454.0661469217, 72618.11582839211], 
processed observation next is [0.0, 0.0, 0.2424242424242423, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.13010731334878187, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08424224672108223, 0.0842422467210821, 0.17711735567900513], 
reward next is 0.8229, 
noisyNet noise sample is [array([0.6194779], dtype=float32), 0.15082234]. 
=============================================
[2019-03-23 07:21:25,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0904956e-14 0.0000000e+00 2.8998851e-29 1.7250360e-34], sum to 1.0000
[2019-03-23 07:21:25,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5477
[2019-03-23 07:21:26,133] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [14.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3937124638010283, 6.9112, 6.9112, 77.32846344354104, 228988.3389664508, 228988.3389664508, 74725.90865716527], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 279000.0000, 
sim time next is 279600.0000, 
raw observation next is [14.0, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3992408543769425, 6.911199999999999, 6.9112, 77.32846344354104, 232204.4910297713, 232204.4910297716, 75878.76239204628], 
processed observation next is [0.0, 0.21739130434782608, 0.2727272727272727, 0.98, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.1417726491099179, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08600166334435974, 0.08600166334435985, 0.18507015217572262], 
reward next is 0.8149, 
noisyNet noise sample is [array([0.3123214], dtype=float32), 0.6998364]. 
=============================================
[2019-03-23 07:21:26,977] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7879: loss 3.6679
[2019-03-23 07:21:27,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7879: learning rate 0.0010
[2019-03-23 07:21:27,108] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7914: loss 0.6553
[2019-03-23 07:21:27,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7915: learning rate 0.0010
[2019-03-23 07:21:27,167] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7946: loss 0.7095
[2019-03-23 07:21:27,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7946: learning rate 0.0010
[2019-03-23 07:21:27,182] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7952: loss 2.1030
[2019-03-23 07:21:27,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7952: learning rate 0.0010
[2019-03-23 07:21:27,188] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7956: loss 2.2741
[2019-03-23 07:21:27,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7956: learning rate 0.0010
[2019-03-23 07:21:27,203] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7958: loss 0.8597
[2019-03-23 07:21:27,204] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7958: loss 2.3940
[2019-03-23 07:21:27,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7958: learning rate 0.0010
[2019-03-23 07:21:27,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7958: learning rate 0.0010
[2019-03-23 07:21:27,220] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7969: loss 2.7436
[2019-03-23 07:21:27,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7969: learning rate 0.0010
[2019-03-23 07:21:27,250] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7985: loss 3.7487
[2019-03-23 07:21:27,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7985: learning rate 0.0010
[2019-03-23 07:21:27,300] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8013: loss 3.4497
[2019-03-23 07:21:27,304] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8014: learning rate 0.0010
[2019-03-23 07:21:27,305] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8016: loss 2.8246
[2019-03-23 07:21:27,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8017: learning rate 0.0010
[2019-03-23 07:21:27,314] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8020: loss 2.5867
[2019-03-23 07:21:27,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8022: learning rate 0.0010
[2019-03-23 07:21:27,327] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8026: loss 2.3436
[2019-03-23 07:21:27,331] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8028: learning rate 0.0010
[2019-03-23 07:21:27,404] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8064: loss 0.0045
[2019-03-23 07:21:27,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8064: learning rate 0.0010
[2019-03-23 07:21:27,429] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8080: loss 0.4588
[2019-03-23 07:21:27,430] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8080: learning rate 0.0010
[2019-03-23 07:21:27,446] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8088: loss 0.8720
[2019-03-23 07:21:27,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8089: learning rate 0.0010
[2019-03-23 07:21:27,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.0702339e-18 0.0000000e+00 3.3527873e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 07:21:27,624] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8957
[2019-03-23 07:21:27,794] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333333, 50.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4703658159874263, 6.911199999999999, 6.9112, 77.32846344354104, 273583.4738930539, 273583.4738930542, 86497.03628901526], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 305400.0000, 
sim time next is 306000.0000, 
raw observation next is [21.0, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4727784004412074, 6.911199999999999, 6.9112, 77.32846344354104, 274987.1257103356, 274987.1257103359, 86424.85563353752], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.49, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.246826286344582, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1018470835964206, 0.10184708359642071, 0.21079233081350615], 
reward next is 0.7892, 
noisyNet noise sample is [array([-0.2481669], dtype=float32), 1.3189535]. 
=============================================
[2019-03-23 07:21:27,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[116.58097 ]
 [116.6511  ]
 [116.69982 ]
 [116.75715 ]
 [116.788826]], R is [[116.16067505]
 [115.7881012 ]
 [115.41906738]
 [115.05369568]
 [114.692276  ]].
[2019-03-23 07:21:27,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9963975e-01 3.6023473e-04 7.1659455e-14 2.7603747e-10 6.2139768e-12], sum to 1.0000
[2019-03-23 07:21:27,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9344
[2019-03-23 07:21:28,067] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4727784004412074, 6.911199999999999, 6.9112, 77.32846344354104, 274987.1257103356, 274987.1257103359, 86424.85563353752], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 306000.0000, 
sim time next is 306600.0000, 
raw observation next is [21.0, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4741808758998343, 6.911200000000001, 6.9112, 77.32846344354104, 275803.0937131332, 275803.093713133, 85418.83177260471], 
processed observation next is [0.0, 0.5652173913043478, 0.5909090909090909, 0.48, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.24882982271404905, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10214929396782711, 0.10214929396782704, 0.20833861407952367], 
reward next is 0.7917, 
noisyNet noise sample is [array([0.31473163], dtype=float32), -0.7587002]. 
=============================================
[2019-03-23 07:21:34,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 07:21:34,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7289
[2019-03-23 07:21:34,349] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3619035645234916, 6.911199999999999, 6.9112, 77.32846344354104, 210483.862578051, 210483.8625780513, 68073.1083126395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 431400.0000, 
sim time next is 432000.0000, 
raw observation next is [13.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3619221962338537, 6.9112, 6.9112, 77.32846344354104, 210494.7011640503, 210494.7011640503, 68062.28237692382], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 1.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.08846028033407671, 0.0, 0.0, 0.5084288129206541, 0.07796100043112973, 0.07796100043112973, 0.16600556677298492], 
reward next is 0.8340, 
noisyNet noise sample is [array([0.16070336], dtype=float32), 0.6401628]. 
=============================================
[2019-03-23 07:21:34,394] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[1240.5968]
 [1239.2247]
 [1237.6133]
 [1236.2433]
 [1234.4586]], R is [[1226.62695312]
 [1215.19470215]
 [1203.87658691]
 [1192.67150879]
 [1181.57788086]].
[2019-03-23 07:21:34,406] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.0320468e-22 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 07:21:34,412] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2557
[2019-03-23 07:21:34,418] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [13.0, 99.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3624475626202622, 6.911199999999999, 6.9112, 77.32846344354104, 210800.3215554089, 210800.3215554092, 68007.46913136126], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 432600.0000, 
sim time next is 433200.0000, 
raw observation next is [13.0, 99.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3632683781386705, 6.911199999999999, 6.9112, 77.32846344354104, 211277.8133942387, 211277.813394239, 67981.12947589168], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 0.9966666666666667, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.0903833973409579, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07825104199786619, 0.0782510419978663, 0.1658076328680285], 
reward next is 0.8342, 
noisyNet noise sample is [array([-1.0254273], dtype=float32), -0.6411524]. 
=============================================
[2019-03-23 07:21:37,889] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.21651196e-04 9.99878049e-01 2.87260974e-07 1.49797041e-09
 2.99293300e-20], sum to 1.0000
[2019-03-23 07:21:37,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1876
[2019-03-23 07:21:38,061] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2345604325951616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254679.376816901, 254679.3768169013, 80254.30294790174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 508200.0000, 
sim time next is 508800.0000, 
raw observation next is [14.66666666666667, 90.0, 1.0, 2.0, 0.2310342188828885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 250849.7219662056, 250849.7219662053, 79585.74261782176], 
processed observation next is [1.0, 0.9130434782608695, 0.30303030303030315, 0.9, 1.0, 1.0, 0.03879277360361061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.092907304431928, 0.09290730443192789, 0.19411156736054086], 
reward next is 0.8059, 
noisyNet noise sample is [array([-0.41430223], dtype=float32), -0.70752805]. 
=============================================
[2019-03-23 07:21:38,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3469165e-10 1.0000000e+00 5.7770724e-18 3.3430829e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 07:21:38,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3132
[2019-03-23 07:21:38,298] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.257014727209969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279066.6374287125, 279066.6374287128, 86910.66605107415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 502800.0000, 
sim time next is 503400.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2565070594573681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278515.2538566207, 278515.253856621, 86852.3782982781], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07063382432171014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10315379772467433, 0.10315379772467444, 0.21183506902019048], 
reward next is 0.7882, 
noisyNet noise sample is [array([1.2938297], dtype=float32), 0.26378426]. 
=============================================
[2019-03-23 07:21:42,628] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15862: loss 1.3646
[2019-03-23 07:21:42,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15862: learning rate 0.0010
[2019-03-23 07:21:42,664] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15883: loss 3.8653
[2019-03-23 07:21:42,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15885: learning rate 0.0010
[2019-03-23 07:21:42,674] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15885: loss 6.2219
[2019-03-23 07:21:42,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15887: learning rate 0.0010
[2019-03-23 07:21:42,687] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15892: loss 21.6161
[2019-03-23 07:21:42,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15894: learning rate 0.0010
[2019-03-23 07:21:42,783] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15943: loss 0.3411
[2019-03-23 07:21:42,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15943: learning rate 0.0010
[2019-03-23 07:21:42,851] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15982: loss 0.0283
[2019-03-23 07:21:42,853] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15983: loss 0.0796
[2019-03-23 07:21:42,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15982: learning rate 0.0010
[2019-03-23 07:21:42,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15984: learning rate 0.0010
[2019-03-23 07:21:42,877] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15993: loss 0.5014
[2019-03-23 07:21:42,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15994: learning rate 0.0010
[2019-03-23 07:21:42,881] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15995: loss 0.6742
[2019-03-23 07:21:42,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15995: learning rate 0.0010
[2019-03-23 07:21:42,916] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16007: loss 0.9048
[2019-03-23 07:21:42,920] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16009: loss 0.9126
[2019-03-23 07:21:42,921] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16009: learning rate 0.0010
[2019-03-23 07:21:42,926] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16009: learning rate 0.0010
[2019-03-23 07:21:42,985] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16047: loss 1.3812
[2019-03-23 07:21:42,987] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16049: learning rate 0.0010
[2019-03-23 07:21:43,025] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16071: loss 0.8051
[2019-03-23 07:21:43,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16071: learning rate 0.0010
[2019-03-23 07:21:43,045] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16077: loss 0.5173
[2019-03-23 07:21:43,047] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16078: learning rate 0.0010
[2019-03-23 07:21:43,052] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16081: loss 0.8702
[2019-03-23 07:21:43,054] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16081: learning rate 0.0010
[2019-03-23 07:21:43,127] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16120: loss 0.0103
[2019-03-23 07:21:43,129] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16121: learning rate 0.0010
[2019-03-23 07:21:43,169] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7074035e-12 9.9997497e-01 2.4745848e-05 2.9019333e-07 1.4946605e-30], sum to 1.0000
[2019-03-23 07:21:43,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1960
[2019-03-23 07:21:43,189] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13080436156610675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12279838782017177, 0.1227983878201717, 0.27260793924764976], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.56596047], dtype=float32), -0.3965827]. 
=============================================
[2019-03-23 07:21:43,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[108.04899 ]
 [108.04955 ]
 [108.048836]
 [108.04858 ]
 [108.04919 ]], R is [[107.69639587]
 [107.34682465]
 [107.00065613]
 [106.65779114]
 [106.31816864]].
[2019-03-23 07:21:54,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2092515e-09 1.0000000e+00 5.9010180e-20 8.2914349e-11 7.4536293e-23], sum to 1.0000
[2019-03-23 07:21:54,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7822
[2019-03-23 07:21:54,721] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 58.66666666666667, 1.0, 2.0, 0.5191368056715381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591411.4342774831, 591411.4342774831, 145111.4108255627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 843000.0000, 
sim time next is 843600.0000, 
raw observation next is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.5170547677018729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 589107.6303274902, 589107.6303274904, 144794.8981014856], 
processed observation next is [0.0, 0.782608695652174, 0.8939393939393941, 0.5933333333333334, 1.0, 1.0, 0.396318459627341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21818801123240375, 0.21818801123240386, 0.3531582880524039], 
reward next is 0.6468, 
noisyNet noise sample is [array([0.5946715], dtype=float32), 0.4201727]. 
=============================================
[2019-03-23 07:21:57,542] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23822: loss 0.0439
[2019-03-23 07:21:57,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23822: learning rate 0.0010
[2019-03-23 07:21:57,614] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23865: loss 0.2001
[2019-03-23 07:21:57,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23865: learning rate 0.0010
[2019-03-23 07:21:57,631] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23870: loss 0.4245
[2019-03-23 07:21:57,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23873: learning rate 0.0010
[2019-03-23 07:21:57,684] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23896: loss 0.5871
[2019-03-23 07:21:57,688] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23897: learning rate 0.0010
[2019-03-23 07:21:57,761] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23943: loss 0.0072
[2019-03-23 07:21:57,764] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23943: learning rate 0.0010
[2019-03-23 07:21:57,813] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23967: loss 0.0034
[2019-03-23 07:21:57,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23967: learning rate 0.0010
[2019-03-23 07:21:57,832] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23977: loss 0.0963
[2019-03-23 07:21:57,833] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23977: loss 0.0215
[2019-03-23 07:21:57,834] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23977: learning rate 0.0010
[2019-03-23 07:21:57,836] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23977: learning rate 0.0010
[2019-03-23 07:21:57,896] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24012: loss 0.2842
[2019-03-23 07:21:57,897] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24012: learning rate 0.0010
[2019-03-23 07:21:57,921] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24026: loss 0.5402
[2019-03-23 07:21:57,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24026: learning rate 0.0010
[2019-03-23 07:21:57,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24031: loss 0.7365
[2019-03-23 07:21:57,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24032: learning rate 0.0010
[2019-03-23 07:21:57,967] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24046: loss 0.9720
[2019-03-23 07:21:57,972] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24047: learning rate 0.0010
[2019-03-23 07:21:58,026] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24077: loss 0.3094
[2019-03-23 07:21:58,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24077: learning rate 0.0010
[2019-03-23 07:21:58,027] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24077: loss 0.3235
[2019-03-23 07:21:58,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24078: learning rate 0.0010
[2019-03-23 07:21:58,054] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24092: loss 0.0891
[2019-03-23 07:21:58,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24093: learning rate 0.0010
[2019-03-23 07:21:58,117] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24125: loss 0.0030
[2019-03-23 07:21:58,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24125: learning rate 0.0010
[2019-03-23 07:21:58,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2695966e-07 9.9999940e-01 5.8469965e-18 3.8638187e-10 8.4594367e-25], sum to 1.0000
[2019-03-23 07:21:58,611] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6187
[2019-03-23 07:21:58,779] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 71.5, 1.0, 2.0, 0.4776291284786163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545015.3885296052, 545015.3885296052, 138332.0993825217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 909000.0000, 
sim time next is 909600.0000, 
raw observation next is [24.0, 73.66666666666667, 1.0, 2.0, 0.4721335233104463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538707.417727383, 538707.417727383, 137402.2939891863], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.7366666666666667, 1.0, 1.0, 0.34016690413805784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19952126582495666, 0.19952126582495666, 0.3351275463150885], 
reward next is 0.6649, 
noisyNet noise sample is [array([0.02690248], dtype=float32), 0.35597268]. 
=============================================
[2019-03-23 07:21:59,896] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 07:21:59,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:21:59,898] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:21:59,898] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:21:59,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:21:59,900] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:21:59,900] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:21:59,900] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:21:59,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:21:59,902] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:21:59,906] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:21:59,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 07:21:59,917] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 07:21:59,963] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 07:21:59,986] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 07:22:00,010] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 07:22:07,116] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52033556]
[2019-03-23 07:22:07,117] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.35023783, 95.28069101, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 189351.9091756295, 189351.9091756291, 70807.08128415]
[2019-03-23 07:22:07,118] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:22:07,120] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7215548e-08 1.0000000e+00 3.0762431e-18 2.4135193e-12 1.4346654e-22], sampled 0.6694404536566104
[2019-03-23 07:22:11,715] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52033556]
[2019-03-23 07:22:11,716] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.39762673166667, 73.48252447666667, 1.0, 2.0, 0.4841309381024385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 552370.3221894684, 552370.3221894684, 143627.966573161]
[2019-03-23 07:22:11,717] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:22:11,722] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7215548e-08 1.0000000e+00 3.0762431e-18 2.4135193e-12 1.4346654e-22], sampled 0.7022322568997389
[2019-03-23 07:23:01,632] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52033556]
[2019-03-23 07:23:01,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.14272441833333, 68.27151182333333, 1.0, 2.0, 0.2718107085669086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 295119.9126984873, 295119.9126984869, 93933.94473681034]
[2019-03-23 07:23:01,635] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:23:01,638] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7215548e-08 1.0000000e+00 3.0762431e-18 2.4135193e-12 1.4346654e-22], sampled 0.09267746882699102
[2019-03-23 07:23:45,587] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:23:46,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:23:46,250] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:23:46,271] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:23:46,298] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:23:47,312] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 25000, evaluation results [25000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:23:58,055] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.6973594e-09 5.7304797e-24 4.7837246e-12 8.0295385e-28], sum to 1.0000
[2019-03-23 07:23:58,065] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7320
[2019-03-23 07:23:58,070] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.673023516793308, 6.9112, 6.9112, 77.32846344354104, 388736.9538735235, 388736.9538735235, 121927.7510116058], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1139400.0000, 
sim time next is 1140000.0000, 
raw observation next is [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6657038810386325, 6.911199999999999, 6.9112, 77.32846344354104, 384502.2080792284, 384502.2080792287, 121231.5375825034], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 0.94, 0.0, 1.0, -0.25, 0.0, 1.0, -0.25, 1.0, 1.0, 0.5224341157694751, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14240822521452903, 0.14240822521452914, 0.2956866770304961], 
reward next is 0.7043, 
noisyNet noise sample is [array([1.2894396], dtype=float32), -0.5426328]. 
=============================================
[2019-03-23 07:23:58,085] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[57.952335]
 [57.34297 ]
 [56.838413]
 [55.958294]
 [55.943855]], R is [[58.42419052]
 [58.54256439]
 [58.66184998]
 [58.77851868]
 [58.89871216]].
[2019-03-23 07:24:00,823] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31744: loss 31789.9531
[2019-03-23 07:24:00,826] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31744: learning rate 0.0010
[2019-03-23 07:24:01,100] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31892: loss 78.8107
[2019-03-23 07:24:01,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31893: learning rate 0.0010
[2019-03-23 07:24:01,146] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31915: loss 12.5383
[2019-03-23 07:24:01,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31915: learning rate 0.0010
[2019-03-23 07:24:01,174] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31929: loss 6.2115
[2019-03-23 07:24:01,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31929: learning rate 0.0010
[2019-03-23 07:24:01,205] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31949: loss 1.5113
[2019-03-23 07:24:01,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31950: learning rate 0.0010
[2019-03-23 07:24:01,215] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31953: loss 0.0060
[2019-03-23 07:24:01,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31953: learning rate 0.0010
[2019-03-23 07:24:01,274] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31982: loss 1.9659
[2019-03-23 07:24:01,276] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31982: learning rate 0.0010
[2019-03-23 07:24:01,280] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31983: loss 1.5240
[2019-03-23 07:24:01,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31983: learning rate 0.0010
[2019-03-23 07:24:01,302] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31996: loss 2.2246
[2019-03-23 07:24:01,304] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31997: learning rate 0.0010
[2019-03-23 07:24:01,332] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32015: loss 2.9383
[2019-03-23 07:24:01,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32015: learning rate 0.0010
[2019-03-23 07:24:01,353] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32022: loss 4.1306
[2019-03-23 07:24:01,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32023: learning rate 0.0010
[2019-03-23 07:24:01,384] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32040: loss 3.2055
[2019-03-23 07:24:01,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32040: learning rate 0.0010
[2019-03-23 07:24:01,393] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32043: loss 3.9374
[2019-03-23 07:24:01,395] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32044: learning rate 0.0010
[2019-03-23 07:24:01,467] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32084: loss 1.0005
[2019-03-23 07:24:01,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32084: learning rate 0.0010
[2019-03-23 07:24:01,506] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32104: loss 0.3395
[2019-03-23 07:24:01,511] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32105: learning rate 0.0010
[2019-03-23 07:24:01,566] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32134: loss 2.0867
[2019-03-23 07:24:01,568] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32134: learning rate 0.0010
[2019-03-23 07:24:01,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 07:24:01,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7977
[2019-03-23 07:24:01,837] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 87.66666666666667, 1.0, 2.0, 0.517823430977297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589742.71216772, 589742.71216772, 145101.2583059449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1208400.0000, 
sim time next is 1209000.0000, 
raw observation next is [23.33333333333333, 87.33333333333333, 1.0, 2.0, 0.5183920591054026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590338.9022354229, 590338.9022354229, 145212.5665875805], 
processed observation next is [1.0, 1.0, 0.6969696969696968, 0.8733333333333333, 1.0, 1.0, 0.3979900738817533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21864403786497144, 0.21864403786497144, 0.35417699167702565], 
reward next is 0.6458, 
noisyNet noise sample is [array([1.2699136], dtype=float32), -1.3591341]. 
=============================================
[2019-03-23 07:24:01,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[271.44858]
 [271.10153]
 [270.85645]
 [270.41235]
 [270.0485 ]], R is [[269.56045532]
 [267.51095581]
 [265.48205566]
 [263.47372437]
 [261.48580933]].
[2019-03-23 07:24:09,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.01492185 0.01869857 0.02490827 0.9317387  0.00973253], sum to 1.0000
[2019-03-23 07:24:09,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8855
[2019-03-23 07:24:10,030] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.33333333333334, 84.66666666666667, 1.0, 2.0, 0.2327701808274874, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4691394581948168, 6.911200000000001, 6.9112, 77.32846344354104, 531204.357967501, 531204.3579675007, 172932.1632811616], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [22.16666666666667, 86.33333333333334, 1.0, 2.0, 0.233927706140425, 1.0, 1.0, 0.233927706140425, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 533813.967694544, 533813.9676945438, 175284.7922512162], 
processed observation next is [1.0, 0.782608695652174, 0.6439393939393941, 0.8633333333333334, 1.0, 1.0, 0.042409632675531224, 1.0, 0.5, 0.042409632675531224, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19770887692390518, 0.1977088769239051, 0.4275238835395517], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6174755], dtype=float32), -0.29244918]. 
=============================================
[2019-03-23 07:24:16,247] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39795: loss 0.0763
[2019-03-23 07:24:16,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39796: learning rate 0.0010
[2019-03-23 07:24:16,351] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39851: loss 0.0132
[2019-03-23 07:24:16,355] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39854: learning rate 0.0010
[2019-03-23 07:24:16,383] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39870: loss 0.0083
[2019-03-23 07:24:16,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39871: learning rate 0.0010
[2019-03-23 07:24:16,483] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39926: loss 0.1643
[2019-03-23 07:24:16,489] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39929: learning rate 0.0010
[2019-03-23 07:24:16,525] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39947: loss 0.7965
[2019-03-23 07:24:16,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39947: learning rate 0.0010
[2019-03-23 07:24:16,561] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39966: loss 0.4523
[2019-03-23 07:24:16,562] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39966: learning rate 0.0010
[2019-03-23 07:24:16,566] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39967: loss 0.2723
[2019-03-23 07:24:16,568] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39967: learning rate 0.0010
[2019-03-23 07:24:16,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5311340e-16 2.1836595e-11 3.5348538e-16 1.0000000e+00 6.2121026e-16], sum to 1.0000
[2019-03-23 07:24:16,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8905
[2019-03-23 07:24:16,581] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 91.5, 1.0, 2.0, 0.2783534460146833, 1.0, 2.0, 0.2783534460146833, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 625929.2756125516, 625929.2756125513, 188348.6649210624], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1499400.0000, 
sim time next is 1500000.0000, 
raw observation next is [24.33333333333333, 90.66666666666666, 1.0, 2.0, 0.2833709023399842, 1.0, 2.0, 0.2833709023399842, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 636839.5183675927, 636839.5183675925, 189336.3525330001], 
processed observation next is [0.0, 0.34782608695652173, 0.7424242424242422, 0.9066666666666666, 1.0, 1.0, 0.10421362792498022, 1.0, 1.0, 0.10421362792498022, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2358664882842936, 0.23586648828429352, 0.4617959817878052], 
reward next is 0.5382, 
noisyNet noise sample is [array([-0.82524943], dtype=float32), -0.42439696]. 
=============================================
[2019-03-23 07:24:16,596] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.170036]
 [63.170036]
 [63.170036]
 [63.170036]
 [63.170036]], R is [[63.07653809]
 [62.98638535]
 [62.90052032]
 [62.8188858 ]
 [62.74131775]].
[2019-03-23 07:24:16,596] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39982: loss 0.1056
[2019-03-23 07:24:16,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39984: learning rate 0.0010
[2019-03-23 07:24:16,647] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40009: loss 0.0060
[2019-03-23 07:24:16,649] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40009: learning rate 0.0010
[2019-03-23 07:24:16,687] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40028: loss 0.0709
[2019-03-23 07:24:16,688] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40028: learning rate 0.0010
[2019-03-23 07:24:16,699] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40035: loss 0.1931
[2019-03-23 07:24:16,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40037: learning rate 0.0010
[2019-03-23 07:24:16,745] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40059: loss 0.5292
[2019-03-23 07:24:16,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40059: learning rate 0.0010
[2019-03-23 07:24:16,759] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40065: loss 0.5739
[2019-03-23 07:24:16,762] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40065: learning rate 0.0010
[2019-03-23 07:24:16,777] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40071: loss 0.8690
[2019-03-23 07:24:16,779] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40074: learning rate 0.0010
[2019-03-23 07:24:16,806] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40089: loss 1.0401
[2019-03-23 07:24:16,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40089: learning rate 0.0010
[2019-03-23 07:24:16,828] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40102: loss 0.4845
[2019-03-23 07:24:16,829] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40102: learning rate 0.0010
[2019-03-23 07:24:18,228] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.6933773e-14 3.6212147e-12 1.3759256e-14 1.0000000e+00 1.6478221e-15], sum to 1.0000
[2019-03-23 07:24:18,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3216
[2019-03-23 07:24:18,239] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 83.0, 1.0, 2.0, 0.2754544954360515, 1.0, 2.0, 0.2754544954360515, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 621361.2825791346, 621361.2825791346, 187273.0233224707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1529400.0000, 
sim time next is 1530000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.2793836952382574, 1.0, 2.0, 0.2793836952382574, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 629184.3649028857, 629184.3649028854, 188274.9560381632], 
processed observation next is [0.0, 0.7391304347826086, 0.7727272727272727, 0.83, 1.0, 1.0, 0.09922961904782174, 1.0, 1.0, 0.09922961904782174, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23303124626032806, 0.23303124626032792, 0.4592072098491785], 
reward next is 0.5408, 
noisyNet noise sample is [array([-1.5753428], dtype=float32), -0.28202575]. 
=============================================
[2019-03-23 07:24:18,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.773636]
 [63.773636]
 [63.773636]
 [63.773636]
 [63.773636]], R is [[63.67670441]
 [63.58317184]
 [63.49303055]
 [63.4062233 ]
 [63.32259369]].
[2019-03-23 07:24:18,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6230859e-20 1.4718940e-13 2.1680598e-18 1.0000000e+00 1.3627607e-16], sum to 1.0000
[2019-03-23 07:24:18,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7434
[2019-03-23 07:24:18,666] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.33333333333334, 86.33333333333334, 1.0, 2.0, 0.2350837342027493, 1.0, 2.0, 0.2350837342027493, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 536265.2866483823, 536265.2866483821, 176161.8299438145], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1543200.0000, 
sim time next is 1543800.0000, 
raw observation next is [22.16666666666667, 87.16666666666667, 1.0, 2.0, 0.2338504846814722, 1.0, 2.0, 0.2338504846814722, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533504.07887594, 533504.07887594, 175821.5957909252], 
processed observation next is [0.0, 0.8695652173913043, 0.6439393939393941, 0.8716666666666667, 1.0, 1.0, 0.04231310585184025, 1.0, 1.0, 0.04231310585184025, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19759410328738516, 0.19759410328738516, 0.4288331604656712], 
reward next is 0.5712, 
noisyNet noise sample is [array([0.10787015], dtype=float32), 0.70294845]. 
=============================================
[2019-03-23 07:24:20,494] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8163994e-13 3.3095124e-10 5.2921115e-16 1.0000000e+00 4.5256284e-18], sum to 1.0000
[2019-03-23 07:24:20,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2522
[2019-03-23 07:24:20,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.16666666666667, 94.00000000000001, 1.0, 2.0, 0.2059489966700037, 1.0, 2.0, 0.2059489966700037, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 469285.8974811581, 469285.8974811579, 168230.9237778064], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1577400.0000, 
sim time next is 1578000.0000, 
raw observation next is [20.33333333333334, 94.0, 1.0, 2.0, 0.206052528647415, 1.0, 2.0, 0.206052528647415, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469758.9252341168, 469758.9252341168, 168719.0022315167], 
processed observation next is [1.0, 0.2608695652173913, 0.5606060606060609, 0.94, 1.0, 1.0, 0.00756566080926873, 1.0, 1.0, 0.00756566080926873, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17398478712374696, 0.17398478712374696, 0.4115097615402846], 
reward next is 0.5885, 
noisyNet noise sample is [array([-0.4448804], dtype=float32), -0.36429483]. 
=============================================
[2019-03-23 07:24:20,523] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[81.39226]
 [81.39226]
 [81.39226]
 [81.39226]
 [81.39226]], R is [[81.16683197]
 [80.94484711]
 [80.72716522]
 [80.51244354]
 [80.3004837 ]].
[2019-03-23 07:24:25,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0915471e-24 1.0000000e+00 4.2987003e-23 7.6670029e-16 9.0370508e-21], sum to 1.0000
[2019-03-23 07:24:25,208] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9461
[2019-03-23 07:24:25,213] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 84.83333333333333, 1.0, 2.0, 0.3690383257640581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 414741.6106613959, 414741.6106613957, 121537.2058769757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1669800.0000, 
sim time next is 1670400.0000, 
raw observation next is [20.0, 83.0, 1.0, 2.0, 0.3711555519667903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416834.1882585493, 416834.188258549, 121574.022784855], 
processed observation next is [1.0, 0.34782608695652173, 0.5454545454545454, 0.83, 1.0, 1.0, 0.21394443995848783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1543830326883516, 0.1543830326883515, 0.29652200679232926], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.3979822], dtype=float32), -2.4042294]. 
=============================================
[2019-03-23 07:24:25,661] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1979059e-17 1.0000000e+00 3.5630944e-16 4.4659074e-13 8.4295453e-18], sum to 1.0000
[2019-03-23 07:24:25,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7609
[2019-03-23 07:24:25,841] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 89.0, 1.0, 2.0, 0.5398251500079626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597180.2348087722, 597180.2348087722, 134086.7102312262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1677000.0000, 
sim time next is 1677600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.5540706203521216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611819.3862337598, 611819.3862337602, 135132.7563958416], 
processed observation next is [1.0, 0.43478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.442588275440152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2265997726791703, 0.22659977267917042, 0.32959208877034535], 
reward next is 0.6704, 
noisyNet noise sample is [array([-2.1248474], dtype=float32), 0.13607976]. 
=============================================
[2019-03-23 07:24:28,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.06491505 0.42926145 0.12286708 0.20845658 0.17449984], sum to 1.0000
[2019-03-23 07:24:28,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2118
[2019-03-23 07:24:28,715] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.333333333333334, 77.66666666666667, 1.0, 2.0, 0.3274377346125692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355559.9050240259, 355559.9050240259, 77100.2291493426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1737600.0000, 
sim time next is 1738200.0000, 
raw observation next is [8.166666666666666, 79.33333333333333, 1.0, 2.0, 0.32353569226281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351321.2029867803, 351321.20298678, 76748.45852599494], 
processed observation next is [1.0, 0.08695652173913043, 0.007575757575757549, 0.7933333333333333, 1.0, 1.0, 0.15441961532851245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1301189640691779, 0.13011896406917778, 0.18719136225852423], 
reward next is 0.8128, 
noisyNet noise sample is [array([0.26181823], dtype=float32), -0.46344697]. 
=============================================
[2019-03-23 07:24:31,390] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47763: loss 0.5574
[2019-03-23 07:24:31,392] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47763: learning rate 0.0010
[2019-03-23 07:24:31,594] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47870: loss 0.0117
[2019-03-23 07:24:31,596] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47871: learning rate 0.0010
[2019-03-23 07:24:31,638] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47897: loss 0.0540
[2019-03-23 07:24:31,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47899: learning rate 0.0010
[2019-03-23 07:24:31,724] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47942: loss 0.5969
[2019-03-23 07:24:31,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47942: learning rate 0.0010
[2019-03-23 07:24:31,806] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47987: loss 0.3065
[2019-03-23 07:24:31,807] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47987: learning rate 0.0010
[2019-03-23 07:24:31,810] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47988: loss 0.1019
[2019-03-23 07:24:31,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47988: learning rate 0.0010
[2019-03-23 07:24:31,837] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48000: loss 0.0591
[2019-03-23 07:24:31,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48002: learning rate 0.0010
[2019-03-23 07:24:31,842] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48002: loss 0.0046
[2019-03-23 07:24:31,844] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48002: learning rate 0.0010
[2019-03-23 07:24:31,855] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48010: loss 0.0106
[2019-03-23 07:24:31,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48010: learning rate 0.0010
[2019-03-23 07:24:31,871] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48018: loss 0.0047
[2019-03-23 07:24:31,871] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48018: learning rate 0.0010
[2019-03-23 07:24:31,889] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48026: loss 0.1045
[2019-03-23 07:24:31,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48027: learning rate 0.0010
[2019-03-23 07:24:31,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48044: loss 0.0968
[2019-03-23 07:24:31,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48044: learning rate 0.0010
[2019-03-23 07:24:31,930] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48048: loss 0.1097
[2019-03-23 07:24:31,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48048: learning rate 0.0010
[2019-03-23 07:24:31,953] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48059: loss 0.0992
[2019-03-23 07:24:31,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48059: learning rate 0.0010
[2019-03-23 07:24:31,962] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48061: loss 0.2884
[2019-03-23 07:24:31,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48063: learning rate 0.0010
[2019-03-23 07:24:32,059] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48114: loss 0.5175
[2019-03-23 07:24:32,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48114: learning rate 0.0010
[2019-03-23 07:24:33,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6563842e-22 1.0000000e+00 6.4865027e-24 6.8755079e-18 1.2014985e-25], sum to 1.0000
[2019-03-23 07:24:33,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2113
[2019-03-23 07:24:33,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.33333333333333, 97.0, 1.0, 2.0, 0.3882536384568917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421627.648267974, 421627.648267974, 86219.48470332305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1828200.0000, 
sim time next is 1828800.0000, 
raw observation next is [10.0, 100.0, 1.0, 2.0, 0.3879793923443604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 421329.6991118498, 421329.6991118498, 86096.15754941243], 
processed observation next is [1.0, 0.17391304347826086, 0.09090909090909091, 1.0, 1.0, 1.0, 0.23497424043045048, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15604803670809253, 0.15604803670809253, 0.2099906281692986], 
reward next is 0.7900, 
noisyNet noise sample is [array([0.01679317], dtype=float32), -0.73482215]. 
=============================================
[2019-03-23 07:24:33,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5351576e-24 1.0000000e+00 7.7646223e-26 1.2314968e-20 4.9948816e-30], sum to 1.0000
[2019-03-23 07:24:33,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2214
[2019-03-23 07:24:33,992] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 94.0, 1.0, 2.0, 0.4415996020932154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479587.7666672141, 479587.7666672141, 94227.09719353884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837200.0000, 
sim time next is 1837800.0000, 
raw observation next is [12.5, 91.0, 1.0, 2.0, 0.4384379172198824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476152.4194818587, 476152.4194818587, 94518.8340625178], 
processed observation next is [1.0, 0.2608695652173913, 0.20454545454545456, 0.91, 1.0, 1.0, 0.29804739652485296, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17635274795624398, 0.17635274795624398, 0.23053374161589707], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.18911189], dtype=float32), 0.3141131]. 
=============================================
[2019-03-23 07:24:35,741] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 07:24:35,745] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:24:35,745] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:24:35,746] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:35,747] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:35,746] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:24:35,749] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:24:35,751] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:35,748] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:24:35,751] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:35,752] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:24:35,762] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 07:24:35,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 07:24:35,785] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 07:24:35,829] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 07:24:35,851] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 07:24:40,116] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:24:40,118] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.33333333333333, 98.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 207267.0114820845, 207267.0114820842, 72347.23082735961]
[2019-03-23 07:24:40,119] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:24:40,122] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1794788e-24 1.0000000e+00 6.1156419e-27 4.4655996e-21 2.0205334e-30], sampled 0.990794282091097
[2019-03-23 07:24:44,009] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:24:44,009] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.49448643833333, 79.26287945166666, 1.0, 2.0, 0.3205267752337024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 349205.5322505267, 349205.5322505264, 117301.7733095271]
[2019-03-23 07:24:44,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:24:44,013] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1794788e-24 1.0000000e+00 6.1156419e-27 4.4655996e-21 2.0205334e-30], sampled 0.6427200487122186
[2019-03-23 07:25:16,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:25:16,912] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.72749979, 77.36134821, 1.0, 2.0, 0.4885729689037488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695031, 536622.3268641308, 536622.3268641308, 132083.1379946475]
[2019-03-23 07:25:16,913] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:25:16,915] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.1340392e-24 1.0000000e+00 3.3892152e-26 1.7343651e-20 1.4212385e-29], sampled 0.10736964480243172
[2019-03-23 07:25:18,983] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:25:18,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.4, 56.0, 1.0, 2.0, 0.3313284904937933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 364081.8334954871, 364081.8334954868, 119172.9390043311]
[2019-03-23 07:25:18,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:25:18,991] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1794878e-24 1.0000000e+00 6.1156888e-27 4.4656169e-21 2.0205334e-30], sampled 0.7422599256101439
[2019-03-23 07:25:22,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:25:22,323] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.63333333333334, 65.83333333333333, 1.0, 2.0, 0.5243441340170463, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8974906438929995, 7.028436037298619, 6.9112, 95.55295277190217, 1140278.819102437, 1093229.371054765, 262283.9859097644]
[2019-03-23 07:25:22,324] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:25:22,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8624035e-24 1.0000000e+00 1.5341328e-26 9.2615277e-21 5.7590827e-30], sampled 0.7613438052648274
[2019-03-23 07:25:22,329] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1140278.819102437 W.
[2019-03-23 07:26:12,694] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:26:12,695] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.5, 53.33333333333333, 1.0, 2.0, 0.2873672703150386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 312014.9161673737, 312014.9161673733, 95967.66033076854]
[2019-03-23 07:26:12,696] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:26:12,698] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1794878e-24 1.0000000e+00 6.1156888e-27 4.4656169e-21 2.0205334e-30], sampled 0.4069147567238387
[2019-03-23 07:26:15,501] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0903229]
[2019-03-23 07:26:15,502] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.96438615, 97.27631359166665, 1.0, 2.0, 0.3043219140007664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 330428.8294127822, 330428.8294127819, 114211.6930911757]
[2019-03-23 07:26:15,504] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:26:15,506] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1794788e-24 1.0000000e+00 6.1156419e-27 4.4655996e-21 2.0205334e-30], sampled 0.26638482977547784
[2019-03-23 07:26:21,693] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:26:22,135] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:26:22,141] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:26:22,189] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:26:22,189] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:26:23,203] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 50000, evaluation results [50000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:26:27,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0526834e-14 1.0000000e+00 1.0165457e-16 1.6451223e-14 1.8610509e-19], sum to 1.0000
[2019-03-23 07:26:27,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5590
[2019-03-23 07:26:27,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1148174.123478336 W.
[2019-03-23 07:26:27,288] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.5033390413687772, 1.0, 1.0, 0.5033390413687772, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1148174.123478336, 1148174.123478336, 229464.5102273498], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1950000.0000, 
sim time next is 1950600.0000, 
raw observation next is [26.0, 61.0, 1.0, 2.0, 0.5028529356253331, 1.0, 2.0, 0.5028529356253331, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1146479.687517617, 1146479.687517616, 229979.2955291639], 
processed observation next is [1.0, 0.5652173913043478, 0.8181818181818182, 0.61, 1.0, 1.0, 0.3785661695316663, 1.0, 1.0, 0.3785661695316663, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.42462210648800625, 0.4246221064880059, 0.5609251110467413], 
reward next is 0.4391, 
noisyNet noise sample is [array([-1.1133327], dtype=float32), 0.40668964]. 
=============================================
[2019-03-23 07:26:28,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2200842e-26 1.0000000e+00 1.5980215e-28 4.2427948e-20 3.4908073e-31], sum to 1.0000
[2019-03-23 07:26:28,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0020
[2019-03-23 07:26:28,674] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 62.0, 1.0, 2.0, 0.3182419799620467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346880.1961164483, 346880.196116448, 112885.2548457385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1981800.0000, 
sim time next is 1982400.0000, 
raw observation next is [21.0, 62.66666666666667, 1.0, 2.0, 0.3185895329045737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347899.4605713063, 347899.4605713063, 113135.4576459969], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.6266666666666667, 1.0, 1.0, 0.1482369161307171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1288516520634468, 0.1288516520634468, 0.27594014059999245], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.9537688], dtype=float32), 0.9105974]. 
=============================================
[2019-03-23 07:26:34,756] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55792: loss 0.0102
[2019-03-23 07:26:34,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55792: learning rate 0.0010
[2019-03-23 07:26:34,876] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55861: loss 0.0113
[2019-03-23 07:26:34,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55861: learning rate 0.0010
[2019-03-23 07:26:34,971] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55908: loss 0.2849
[2019-03-23 07:26:34,973] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55909: learning rate 0.0010
[2019-03-23 07:26:34,991] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55923: loss 0.3354
[2019-03-23 07:26:34,995] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55926: learning rate 0.0010
[2019-03-23 07:26:35,004] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55930: loss 0.3292
[2019-03-23 07:26:35,006] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55932: learning rate 0.0010
[2019-03-23 07:26:35,044] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55947: loss 0.1730
[2019-03-23 07:26:35,045] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55947: learning rate 0.0010
[2019-03-23 07:26:35,058] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55951: loss 0.1369
[2019-03-23 07:26:35,059] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55951: learning rate 0.0010
[2019-03-23 07:26:35,076] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55961: loss 0.1159
[2019-03-23 07:26:35,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55961: learning rate 0.0010
[2019-03-23 07:26:35,153] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56007: loss 0.0022
[2019-03-23 07:26:35,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56007: learning rate 0.0010
[2019-03-23 07:26:35,170] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56013: loss 0.0075
[2019-03-23 07:26:35,172] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56013: learning rate 0.0010
[2019-03-23 07:26:35,206] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56032: loss 0.0011
[2019-03-23 07:26:35,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56032: learning rate 0.0010
[2019-03-23 07:26:35,248] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56052: loss 0.0681
[2019-03-23 07:26:35,249] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56052: learning rate 0.0010
[2019-03-23 07:26:35,252] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56054: loss 0.0621
[2019-03-23 07:26:35,254] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56054: learning rate 0.0010
[2019-03-23 07:26:35,315] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56094: loss 0.3397
[2019-03-23 07:26:35,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56095: learning rate 0.0010
[2019-03-23 07:26:35,338] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56106: loss 0.1119
[2019-03-23 07:26:35,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56106: learning rate 0.0010
[2019-03-23 07:26:35,503] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56189: loss 0.0913
[2019-03-23 07:26:35,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56189: learning rate 0.0010
[2019-03-23 07:26:35,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8164286e-23 1.0000000e+00 7.6626403e-25 2.0373970e-24 3.1383298e-25], sum to 1.0000
[2019-03-23 07:26:35,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-23 07:26:35,668] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 55.0, 1.0, 2.0, 0.3441890060190133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 383727.1782935453, 383727.178293545, 118004.8629495912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2113200.0000, 
sim time next is 2113800.0000, 
raw observation next is [23.75, 54.83333333333334, 1.0, 2.0, 0.3454765855124801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385300.1233557811, 385300.1233557814, 118166.9439558582], 
processed observation next is [0.0, 0.4782608695652174, 0.7159090909090909, 0.5483333333333335, 1.0, 1.0, 0.18184573189060013, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14270374939103003, 0.14270374939103017, 0.28821205842892245], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.33008063], dtype=float32), 0.49098197]. 
=============================================
[2019-03-23 07:26:36,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6663421e-24 1.0000000e+00 1.4880269e-27 4.1477510e-21 1.6316403e-30], sum to 1.0000
[2019-03-23 07:26:36,967] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5998
[2019-03-23 07:26:37,141] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 50.0, 1.0, 2.0, 0.4066655698994431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462110.2125118079, 462110.2125118079, 127923.2914520652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2130600.0000, 
sim time next is 2131200.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.4134058443025251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470230.8706402871, 470230.8706402871, 128975.2174741372], 
processed observation next is [0.0, 0.6956521739130435, 0.8636363636363636, 0.51, 1.0, 1.0, 0.26675730537815634, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17415958171862486, 0.17415958171862486, 0.3145737011564322], 
reward next is 0.6854, 
noisyNet noise sample is [array([-1.6114792], dtype=float32), -0.2386115]. 
=============================================
[2019-03-23 07:26:38,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1846062e-23 1.0000000e+00 5.0793953e-27 9.1533432e-22 5.5097601e-28], sum to 1.0000
[2019-03-23 07:26:38,790] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3285
[2019-03-23 07:26:38,795] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3007812447936259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326604.2874073281, 326604.2874073279, 110096.4501295642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2166600.0000, 
sim time next is 2167200.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3004949835260868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326293.3454026976, 326293.3454026979, 110065.7114956442], 
processed observation next is [1.0, 0.08695652173913043, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12561872940760846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1208493871861843, 0.12084938718618442, 0.2684529548674249], 
reward next is 0.7315, 
noisyNet noise sample is [array([0.76892215], dtype=float32), -0.054582417]. 
=============================================
[2019-03-23 07:26:41,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4922473e-23 1.0000000e+00 1.0622012e-25 2.3578434e-20 6.9512259e-32], sum to 1.0000
[2019-03-23 07:26:41,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1395
[2019-03-23 07:26:41,791] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.0, 1.0, 2.0, 0.3563380626768728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394938.3102833663, 394938.3102833663, 118004.2577244148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2237400.0000, 
sim time next is 2238000.0000, 
raw observation next is [17.66666666666666, 92.0, 1.0, 2.0, 0.3497525336518233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 386267.0850263591, 386267.0850263588, 116951.1292446483], 
processed observation next is [1.0, 0.9130434782608695, 0.4393939393939391, 0.92, 1.0, 1.0, 0.1871906670647791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14306188334309597, 0.14306188334309583, 0.28524665669426413], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.31720716], dtype=float32), 1.4269929]. 
=============================================
[2019-03-23 07:26:41,809] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.762886]
 [77.762886]
 [77.762886]
 [77.762886]
 [77.762886]], R is [[77.70001221]
 [77.63519287]
 [77.56861877]
 [77.50066376]
 [77.43182373]].
[2019-03-23 07:26:49,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0649106e-21 1.0000000e+00 2.7579458e-19 1.3843669e-19 5.0850760e-27], sum to 1.0000
[2019-03-23 07:26:49,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0350
[2019-03-23 07:26:49,053] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 62.0, 1.0, 2.0, 0.3625764361215842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393731.9615209153, 393731.9615209153, 96518.7113140707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2364600.0000, 
sim time next is 2365200.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.3923335092997586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426060.163197749, 426060.1631977487, 99710.12918032902], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.6, 1.0, 1.0, 0.2404168866246982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15780006044361075, 0.15780006044361064, 0.24319543702519275], 
reward next is 0.7568, 
noisyNet noise sample is [array([-1.1637716], dtype=float32), -0.6322376]. 
=============================================
[2019-03-23 07:26:49,863] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63778: loss 0.2718
[2019-03-23 07:26:49,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63778: learning rate 0.0010
[2019-03-23 07:26:49,945] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63825: loss 0.4175
[2019-03-23 07:26:49,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63826: learning rate 0.0010
[2019-03-23 07:26:50,018] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63842: loss 0.2644
[2019-03-23 07:26:50,020] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63842: learning rate 0.0010
[2019-03-23 07:26:50,124] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63901: loss 0.1012
[2019-03-23 07:26:50,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63902: learning rate 0.0010
[2019-03-23 07:26:50,133] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63905: loss 0.0374
[2019-03-23 07:26:50,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63905: learning rate 0.0010
[2019-03-23 07:26:50,151] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63914: loss 0.0202
[2019-03-23 07:26:50,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63914: learning rate 0.0010
[2019-03-23 07:26:50,156] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63914: loss 0.0073
[2019-03-23 07:26:50,158] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63914: learning rate 0.0010
[2019-03-23 07:26:50,251] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63965: loss 0.0413
[2019-03-23 07:26:50,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63966: learning rate 0.0010
[2019-03-23 07:26:50,340] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64007: loss 0.0692
[2019-03-23 07:26:50,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64007: learning rate 0.0010
[2019-03-23 07:26:50,375] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64025: loss 0.0341
[2019-03-23 07:26:50,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64025: learning rate 0.0010
[2019-03-23 07:26:50,420] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64053: loss 0.0045
[2019-03-23 07:26:50,423] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64054: learning rate 0.0010
[2019-03-23 07:26:50,441] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64064: loss 0.0144
[2019-03-23 07:26:50,442] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64064: loss 0.0216
[2019-03-23 07:26:50,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64064: learning rate 0.0010
[2019-03-23 07:26:50,446] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64065: learning rate 0.0010
[2019-03-23 07:26:50,616] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64152: loss 0.1585
[2019-03-23 07:26:50,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64152: learning rate 0.0010
[2019-03-23 07:26:50,636] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64161: loss 0.0778
[2019-03-23 07:26:50,637] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64161: learning rate 0.0010
[2019-03-23 07:26:50,802] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64247: loss 0.0636
[2019-03-23 07:26:50,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64248: learning rate 0.0010
[2019-03-23 07:26:54,513] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0939380e-21 1.0000000e+00 8.4592930e-22 1.7531030e-20 5.9370425e-24], sum to 1.0000
[2019-03-23 07:26:54,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0525
[2019-03-23 07:26:54,519] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2325021487793105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252443.9679161886, 252443.9679161884, 78576.09603761355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2491200.0000, 
sim time next is 2491800.0000, 
raw observation next is [13.83333333333333, 95.0, 1.0, 2.0, 0.2312612725191012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251096.3133322887, 251096.3133322887, 78179.61089435662], 
processed observation next is [1.0, 0.8695652173913043, 0.265151515151515, 0.95, 1.0, 1.0, 0.03907659064887648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09299863456751434, 0.09299863456751434, 0.1906819777911137], 
reward next is 0.8093, 
noisyNet noise sample is [array([0.84546614], dtype=float32), 1.2053137]. 
=============================================
[2019-03-23 07:26:59,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5893458e-21 1.0000000e+00 4.3863135e-22 3.9820135e-20 1.3834817e-24], sum to 1.0000
[2019-03-23 07:26:59,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4975
[2019-03-23 07:27:00,146] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.81666666666667, 93.00000000000001, 1.0, 2.0, 0.3129092295128519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340723.7022249435, 340723.7022249432, 112393.5521589766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2599800.0000, 
sim time next is 2600400.0000, 
raw observation next is [16.73333333333333, 92.0, 1.0, 2.0, 0.3088586403924025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335378.1779925019, 335378.1779925022, 111789.6299509721], 
processed observation next is [0.0, 0.08695652173913043, 0.39696969696969686, 0.92, 1.0, 1.0, 0.13607330049050312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12421413999722292, 0.12421413999722304, 0.27265763402676124], 
reward next is 0.7273, 
noisyNet noise sample is [array([-1.5124397], dtype=float32), -1.107081]. 
=============================================
[2019-03-23 07:27:02,190] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3028353e-20 1.0000000e+00 7.3137937e-21 1.0708219e-18 2.7967787e-24], sum to 1.0000
[2019-03-23 07:27:02,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7393
[2019-03-23 07:27:02,199] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.357202136795307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400914.4232849589, 400914.4232849592, 120277.9387318202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2639400.0000, 
sim time next is 2640000.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.357666462567485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401450.3368464043, 401450.3368464043, 120323.7101464733], 
processed observation next is [0.0, 0.5652173913043478, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19708307820935625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14868530994311271, 0.14868530994311271, 0.29347246377188607], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.38615388], dtype=float32), -1.6207277]. 
=============================================
[2019-03-23 07:27:02,229] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.9048]
 [77.9048]
 [77.9048]
 [77.9048]
 [77.9048]], R is [[77.83229065]
 [77.76061249]
 [77.69036865]
 [77.62265778]
 [77.55728912]].
[2019-03-23 07:27:03,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3018450e-15 1.0000000e+00 8.5497864e-19 1.0111891e-16 8.4812004e-22], sum to 1.0000
[2019-03-23 07:27:03,153] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9195
[2019-03-23 07:27:03,158] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 38.0, 1.0, 2.0, 0.357279765614168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400913.8607385846, 400913.8607385849, 120241.3944883136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2647200.0000, 
sim time next is 2647800.0000, 
raw observation next is [28.0, 38.5, 1.0, 2.0, 0.3615693111518664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406199.5687030219, 406199.5687030221, 120832.1541437957], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.385, 1.0, 1.0, 0.201961638939833, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15044428470482293, 0.150444284704823, 0.29471257108242854], 
reward next is 0.7053, 
noisyNet noise sample is [array([-1.2880433], dtype=float32), 0.5523581]. 
=============================================
[2019-03-23 07:27:05,066] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71820: loss 0.0822
[2019-03-23 07:27:05,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71820: learning rate 0.0010
[2019-03-23 07:27:05,068] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71820: loss 0.0744
[2019-03-23 07:27:05,076] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71821: learning rate 0.0010
[2019-03-23 07:27:05,090] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71830: loss 0.0233
[2019-03-23 07:27:05,091] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71830: learning rate 0.0010
[2019-03-23 07:27:05,167] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71876: loss 0.0006
[2019-03-23 07:27:05,168] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71876: learning rate 0.0010
[2019-03-23 07:27:05,180] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71880: loss 0.0005
[2019-03-23 07:27:05,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71881: learning rate 0.0010
[2019-03-23 07:27:05,236] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71906: loss 0.0463
[2019-03-23 07:27:05,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71906: learning rate 0.0010
[2019-03-23 07:27:05,247] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71911: loss 0.0811
[2019-03-23 07:27:05,249] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71911: learning rate 0.0010
[2019-03-23 07:27:05,359] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71959: loss 0.0422
[2019-03-23 07:27:05,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71960: learning rate 0.0010
[2019-03-23 07:27:05,398] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71973: loss 0.0440
[2019-03-23 07:27:05,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71973: learning rate 0.0010
[2019-03-23 07:27:05,418] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71982: loss 0.0055
[2019-03-23 07:27:05,420] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71983: learning rate 0.0010
[2019-03-23 07:27:05,446] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71995: loss 0.0066
[2019-03-23 07:27:05,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71997: learning rate 0.0010
[2019-03-23 07:27:05,670] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72118: loss 0.0758
[2019-03-23 07:27:05,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72119: learning rate 0.0010
[2019-03-23 07:27:05,690] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72125: loss 0.1562
[2019-03-23 07:27:05,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72126: learning rate 0.0010
[2019-03-23 07:27:05,791] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72181: loss 0.0019
[2019-03-23 07:27:05,799] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72184: learning rate 0.0010
[2019-03-23 07:27:05,803] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72185: loss 0.0170
[2019-03-23 07:27:05,807] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72185: learning rate 0.0010
[2019-03-23 07:27:05,919] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72247: loss 0.1015
[2019-03-23 07:27:05,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72247: learning rate 0.0010
[2019-03-23 07:27:11,077] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 07:27:11,077] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:27:11,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:27:11,078] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:11,079] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:27:11,080] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:27:11,080] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:11,079] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:11,083] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:11,081] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:27:11,086] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:27:11,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 07:27:11,115] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 07:27:11,150] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 07:27:11,151] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 07:27:11,194] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 07:27:14,949] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.1138668]
[2019-03-23 07:27:14,952] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.919197935, 91.29494271, 1.0, 2.0, 0.2239560881051211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 243150.9959594016, 243150.9959594012, 81101.18299163967]
[2019-03-23 07:27:14,952] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:27:14,955] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.12004312e-11 1.00000000e+00 1.08331496e-13 1.29585925e-12
 3.53339942e-15], sampled 0.4420472432169107
[2019-03-23 07:27:16,165] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.1138668]
[2019-03-23 07:27:16,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.0, 76.0, 1.0, 2.0, 0.407040732724772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 61.18001451380767, 442091.996132585, 442091.9961325846, 78200.9542706201]
[2019-03-23 07:27:16,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:27:16,172] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1222200e-11 1.0000000e+00 1.0859050e-13 1.2986131e-12 3.5427528e-15], sampled 0.8877455653092033
[2019-03-23 07:27:35,585] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.1138668]
[2019-03-23 07:27:35,588] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.3, 63.00000000000001, 1.0, 2.0, 0.7042377179817807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 796573.9110125573, 796573.9110125573, 177283.4970696505]
[2019-03-23 07:27:35,589] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:27:35,592] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1222200e-11 1.0000000e+00 1.0859050e-13 1.2986131e-12 3.5427528e-15], sampled 0.600036045767838
[2019-03-23 07:27:47,043] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.1138668]
[2019-03-23 07:27:47,045] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.0, 44.0, 1.0, 2.0, 0.3889988813939187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 438366.9873257272, 438366.9873257272, 128200.009936189]
[2019-03-23 07:27:47,047] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:27:47,051] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1222200e-11 1.0000000e+00 1.0859050e-13 1.2986131e-12 3.5427528e-15], sampled 0.5903521396970106
[2019-03-23 07:28:57,011] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:28:57,186] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:28:57,429] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:28:57,516] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:28:57,609] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:28:58,624] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 75000, evaluation results [75000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:29:00,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1811427e-14 1.0000000e+00 2.1457295e-18 2.4322780e-15 1.4324739e-20], sum to 1.0000
[2019-03-23 07:29:00,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4673
[2019-03-23 07:29:00,115] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4908188279543259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559927.2144676483, 559927.2144676481, 140650.3126386991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2844000.0000, 
sim time next is 2844600.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4929341483793033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562348.9711435647, 562348.9711435647, 140875.0440997068], 
processed observation next is [1.0, 0.9565217391304348, 0.7196969696969695, 0.7883333333333333, 1.0, 1.0, 0.36616768547412915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20827739671983878, 0.20827739671983878, 0.34359766853587026], 
reward next is 0.6564, 
noisyNet noise sample is [array([-1.787749], dtype=float32), -0.21710527]. 
=============================================
[2019-03-23 07:29:07,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2768482e-18 1.0000000e+00 1.3978853e-23 2.8435880e-23 4.3249056e-29], sum to 1.0000
[2019-03-23 07:29:07,105] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8847
[2019-03-23 07:29:07,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1228980.093502237 W.
[2019-03-23 07:29:07,117] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 70.66666666666667, 1.0, 2.0, 0.3631971512024565, 1.0, 1.0, 0.3631971512024565, 1.0, 2.0, 0.7344587471520199, 6.911199999999999, 6.9112, 77.3421103, 1228980.093502237, 1228980.093502238, 288676.9754587417], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2973000.0000, 
sim time next is 2973600.0000, 
raw observation next is [26.0, 70.0, 1.0, 2.0, 0.5756273286066302, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9783318125786784, 6.9112, 6.9112, 77.32846344354104, 1201500.149563873, 1201500.149563873, 275073.8860185283], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.7, 1.0, 1.0, 0.46953416075828774, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9690454465409691, 0.0, 0.0, 0.5084288129206541, 0.44500005539402704, 0.44500005539402704, 0.6709119171183617], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09965926], dtype=float32), -0.91621673]. 
=============================================
[2019-03-23 07:29:08,284] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79803: loss 34.0286
[2019-03-23 07:29:08,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79803: learning rate 0.0010
[2019-03-23 07:29:08,439] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79813: loss -35.4726
[2019-03-23 07:29:08,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79813: learning rate 0.0010
[2019-03-23 07:29:08,588] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79833: loss 40.4050
[2019-03-23 07:29:08,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79834: learning rate 0.0010
[2019-03-23 07:29:08,765] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79856: loss 45.7860
[2019-03-23 07:29:08,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79856: learning rate 0.0010
[2019-03-23 07:29:08,910] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79873: loss -39.1396
[2019-03-23 07:29:08,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79874: learning rate 0.0010
[2019-03-23 07:29:09,082] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79905: loss -42.0793
[2019-03-23 07:29:09,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79906: learning rate 0.0010
[2019-03-23 07:29:09,312] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79958: loss 6.8164
[2019-03-23 07:29:09,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79958: learning rate 0.0010
[2019-03-23 07:29:09,495] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79994: loss 16.1537
[2019-03-23 07:29:09,496] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79994: loss -25.7474
[2019-03-23 07:29:09,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79994: learning rate 0.0010
[2019-03-23 07:29:09,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79994: learning rate 0.0010
[2019-03-23 07:29:09,503] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79997: loss -45.0559
[2019-03-23 07:29:09,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79997: learning rate 0.0010
[2019-03-23 07:29:09,763] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80004: loss -37.1173
[2019-03-23 07:29:09,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80004: learning rate 0.0010
[2019-03-23 07:29:10,097] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80050: loss 0.2296
[2019-03-23 07:29:10,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80052: learning rate 0.0010
[2019-03-23 07:29:10,403] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80149: loss 38.9219
[2019-03-23 07:29:10,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80151: learning rate 0.0010
[2019-03-23 07:29:10,561] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80169: loss 30.6924
[2019-03-23 07:29:10,562] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80169: loss -46.1741
[2019-03-23 07:29:10,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80169: learning rate 0.0010
[2019-03-23 07:29:10,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80169: learning rate 0.0010
[2019-03-23 07:29:10,966] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80253: loss 36.7133
[2019-03-23 07:29:10,968] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80253: learning rate 0.0010
[2019-03-23 07:29:11,536] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6560990e-15 1.0000000e+00 4.8041939e-21 9.6196381e-20 3.2483077e-24], sum to 1.0000
[2019-03-23 07:29:11,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3301
[2019-03-23 07:29:11,547] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.4157195898546904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470691.363906912, 470691.363906912, 127563.3650832239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3018600.0000, 
sim time next is 3019200.0000, 
raw observation next is [21.33333333333334, 78.0, 1.0, 2.0, 0.4099519296760499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463547.784594675, 463547.784594675, 126640.7765752782], 
processed observation next is [1.0, 0.9565217391304348, 0.6060606060606063, 0.78, 1.0, 1.0, 0.2624399120950623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17168436466469444, 0.17168436466469444, 0.3088799428665322], 
reward next is 0.6911, 
noisyNet noise sample is [array([0.20851791], dtype=float32), 1.2821076]. 
=============================================
[2019-03-23 07:29:13,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.52659637e-24 1.00000000e+00 1.08424704e-32 2.90344923e-29
 1.30334796e-34], sum to 1.0000
[2019-03-23 07:29:13,542] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3510
[2019-03-23 07:29:13,548] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3597528861852433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393812.3025365434, 393812.3025365437, 116455.3015228978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3052200.0000, 
sim time next is 3052800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3721002593587814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407365.7651369305, 407365.7651369307, 117410.8286625595], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.94, 1.0, 1.0, 0.21512532419847671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15087620930997425, 0.15087620930997434, 0.2863678747867305], 
reward next is 0.7136, 
noisyNet noise sample is [array([-0.796899], dtype=float32), 0.4570314]. 
=============================================
[2019-03-23 07:29:17,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4901300e-23 1.0000000e+00 2.7143030e-30 3.8971849e-26 5.1968963e-34], sum to 1.0000
[2019-03-23 07:29:17,026] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1146
[2019-03-23 07:29:17,030] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.531017499047291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605143.0008539871, 605143.0008539871, 142520.6537824201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3123000.0000, 
sim time next is 3123600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.5277554265218315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 601417.2218531423, 601417.2218531423, 142135.5435854192], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.40969428315228934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2227471192048675, 0.2227471192048675, 0.34667205752541264], 
reward next is 0.6533, 
noisyNet noise sample is [array([1.5950841], dtype=float32), 0.30654567]. 
=============================================
[2019-03-23 07:29:23,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5461768e-23 1.0000000e+00 2.8855492e-30 7.1984761e-30 9.2599780e-35], sum to 1.0000
[2019-03-23 07:29:23,278] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5546
[2019-03-23 07:29:23,283] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 48.0, 1.0, 2.0, 0.3233572216316043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 355955.6694184687, 355955.669418469, 114516.3313958128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247200.0000, 
sim time next is 3247800.0000, 
raw observation next is [24.08333333333334, 48.33333333333333, 1.0, 2.0, 0.3270025022724248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360239.6463580909, 360239.6463580909, 114885.6918565456], 
processed observation next is [0.0, 0.6086956521739131, 0.7310606060606063, 0.4833333333333333, 1.0, 1.0, 0.15875312784053094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13342209124373738, 0.13342209124373738, 0.28020900452816], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.2725189], dtype=float32), -0.4830005]. 
=============================================
[2019-03-23 07:29:25,368] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87807: loss 0.0053
[2019-03-23 07:29:25,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87807: learning rate 0.0010
[2019-03-23 07:29:25,403] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87820: loss 0.0296
[2019-03-23 07:29:25,405] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87821: learning rate 0.0010
[2019-03-23 07:29:25,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87829: loss 0.0558
[2019-03-23 07:29:25,423] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87830: learning rate 0.0010
[2019-03-23 07:29:25,473] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87859: loss 0.0681
[2019-03-23 07:29:25,474] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87859: learning rate 0.0010
[2019-03-23 07:29:25,519] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87877: loss 0.0777
[2019-03-23 07:29:25,520] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87877: learning rate 0.0010
[2019-03-23 07:29:25,532] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87887: loss 0.0649
[2019-03-23 07:29:25,534] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87887: learning rate 0.0010
[2019-03-23 07:29:25,609] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87930: loss 0.0191
[2019-03-23 07:29:25,610] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87930: learning rate 0.0010
[2019-03-23 07:29:25,750] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88003: loss 0.0157
[2019-03-23 07:29:25,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88003: learning rate 0.0010
[2019-03-23 07:29:25,779] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88021: loss 0.0871
[2019-03-23 07:29:25,783] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88021: loss 0.0460
[2019-03-23 07:29:25,785] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88021: learning rate 0.0010
[2019-03-23 07:29:25,785] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88022: learning rate 0.0010
[2019-03-23 07:29:25,795] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88026: loss 0.0953
[2019-03-23 07:29:25,796] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88026: learning rate 0.0010
[2019-03-23 07:29:25,899] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88084: loss 0.0250
[2019-03-23 07:29:25,905] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88087: loss 0.0043
[2019-03-23 07:29:25,906] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88087: learning rate 0.0010
[2019-03-23 07:29:25,906] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88085: learning rate 0.0010
[2019-03-23 07:29:25,956] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88111: loss 0.0024
[2019-03-23 07:29:25,959] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88111: learning rate 0.0010
[2019-03-23 07:29:26,126] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88200: loss 0.0189
[2019-03-23 07:29:26,127] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88200: learning rate 0.0010
[2019-03-23 07:29:26,264] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88274: loss 0.0110
[2019-03-23 07:29:26,270] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88276: learning rate 0.0010
[2019-03-23 07:29:30,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2961483e-19 1.0000000e+00 2.4740446e-28 3.9396355e-26 5.2684011e-32], sum to 1.0000
[2019-03-23 07:29:30,886] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7831
[2019-03-23 07:29:30,889] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.7794255317352076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 886376.0112022109, 886376.0112022109, 173529.7338044306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3405000.0000, 
sim time next is 3405600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.6933352404687284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 788313.4257211876, 788313.4257211876, 161244.0359396458], 
processed observation next is [1.0, 0.43478260869565216, 0.6363636363636364, 0.78, 1.0, 1.0, 0.6166690505859105, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2919679354522917, 0.2919679354522917, 0.3932781364381605], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.92837495], dtype=float32), -0.21631919]. 
=============================================
[2019-03-23 07:29:35,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8124753e-20 1.0000000e+00 1.4229216e-27 9.2565499e-28 9.4613013e-33], sum to 1.0000
[2019-03-23 07:29:35,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4166
[2019-03-23 07:29:35,290] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.5087810278590555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580346.5387782705, 580346.5387782705, 142926.5848628156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3483600.0000, 
sim time next is 3484200.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.5061850143396202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577336.5339282692, 577336.5339282692, 142710.1965997812], 
processed observation next is [1.0, 0.30434782608695654, 0.628787878787879, 0.95, 1.0, 1.0, 0.38273126792452516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21382834589935895, 0.21382834589935895, 0.3480736502433688], 
reward next is 0.6519, 
noisyNet noise sample is [array([-0.04570685], dtype=float32), -0.19229685]. 
=============================================
[2019-03-23 07:29:38,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2126461e-23 1.0000000e+00 1.5603385e-33 6.4732764e-32 7.0187614e-35], sum to 1.0000
[2019-03-23 07:29:38,334] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4804
[2019-03-23 07:29:38,338] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5782076744629056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 659423.6456932412, 659423.6456932414, 151765.8266083168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3554400.0000, 
sim time next is 3555000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5607156289406031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639472.1684570676, 639472.1684570676, 149519.5131171882], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.45089453617575387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.236841543872988, 0.236841543872988, 0.36468173931021514], 
reward next is 0.6353, 
noisyNet noise sample is [array([0.02882209], dtype=float32), 0.47057196]. 
=============================================
[2019-03-23 07:29:38,352] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.8006]
 [70.8006]
 [70.8006]
 [70.8006]
 [70.8006]], R is [[70.72790527]
 [70.65046692]
 [70.56150818]
 [70.48988342]
 [70.41539764]].
[2019-03-23 07:29:39,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1069802e-20 1.0000000e+00 1.8481029e-28 3.1650030e-28 3.2259820e-31], sum to 1.0000
[2019-03-23 07:29:39,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7252
[2019-03-23 07:29:39,083] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.5698595295222384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 650197.8013379236, 650197.8013379236, 150092.4990108091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3568200.0000, 
sim time next is 3568800.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.5602314989375704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639158.8218099365, 639158.8218099365, 149004.0014564943], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.98, 1.0, 1.0, 0.450289373671963, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23672548955923575, 0.23672548955923575, 0.36342439379632757], 
reward next is 0.6366, 
noisyNet noise sample is [array([1.8976426], dtype=float32), -0.61630744]. 
=============================================
[2019-03-23 07:29:40,394] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95754: loss -72.5447
[2019-03-23 07:29:40,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95755: learning rate 0.0010
[2019-03-23 07:29:40,561] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95841: loss -53.7168
[2019-03-23 07:29:40,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95842: learning rate 0.0010
[2019-03-23 07:29:40,577] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95850: loss -43.4547
[2019-03-23 07:29:40,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95850: learning rate 0.0010
[2019-03-23 07:29:40,631] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95876: loss -38.4735
[2019-03-23 07:29:40,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95876: learning rate 0.0010
[2019-03-23 07:29:40,665] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95893: loss -53.5383
[2019-03-23 07:29:40,666] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95893: learning rate 0.0010
[2019-03-23 07:29:40,705] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95916: loss -62.2107
[2019-03-23 07:29:40,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95917: learning rate 0.0010
[2019-03-23 07:29:40,782] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95957: loss -35.8404
[2019-03-23 07:29:40,785] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95957: learning rate 0.0010
[2019-03-23 07:29:40,790] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95961: loss -41.4980
[2019-03-23 07:29:40,791] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95961: learning rate 0.0010
[2019-03-23 07:29:40,809] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95969: loss -60.7168
[2019-03-23 07:29:40,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95970: learning rate 0.0010
[2019-03-23 07:29:40,874] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96000: loss -48.6105
[2019-03-23 07:29:40,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96000: learning rate 0.0010
[2019-03-23 07:29:41,013] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96073: loss -13.9771
[2019-03-23 07:29:41,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96073: learning rate 0.0010
[2019-03-23 07:29:41,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96121: loss -2.4165
[2019-03-23 07:29:41,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96123: learning rate 0.0010
[2019-03-23 07:29:41,116] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96128: loss 0.6637
[2019-03-23 07:29:41,117] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96129: learning rate 0.0010
[2019-03-23 07:29:41,122] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96133: loss -1.9043
[2019-03-23 07:29:41,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96134: learning rate 0.0010
[2019-03-23 07:29:41,224] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96194: loss -32.4180
[2019-03-23 07:29:41,226] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96194: learning rate 0.0010
[2019-03-23 07:29:41,344] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96249: loss -26.1040
[2019-03-23 07:29:41,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96251: learning rate 0.0010
[2019-03-23 07:29:48,472] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 07:29:48,473] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:29:48,474] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:29:48,474] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:48,475] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:48,476] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:29:48,476] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:29:48,477] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:48,478] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:48,479] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:29:48,480] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:29:48,489] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 07:29:48,516] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 07:29:48,516] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 07:29:48,539] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 07:29:48,560] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 07:29:54,354] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:29:54,355] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.16666666666667, 80.0, 1.0, 2.0, 0.3249867939943898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 352873.0782947569, 352873.0782947569, 117206.8754808997]
[2019-03-23 07:29:54,356] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:29:54,359] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.6809574024841943
[2019-03-23 07:30:27,584] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:30:27,587] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.4, 46.0, 1.0, 2.0, 0.4181062198188389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 474220.6299460431, 474220.6299460431, 132681.2334741478]
[2019-03-23 07:30:27,588] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:30:27,591] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.4644457102512538
[2019-03-23 07:30:37,156] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:30:37,158] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.5, 80.5, 1.0, 2.0, 0.493842713100986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563446.780811511, 563446.780811511, 140799.6447785561]
[2019-03-23 07:30:37,159] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:30:37,161] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.07087813864969317
[2019-03-23 07:31:03,102] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:31:03,102] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.95, 77.5, 1.0, 2.0, 0.474278823068618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 533951.5822022641, 533951.5822022638, 135980.3259985699]
[2019-03-23 07:31:03,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:31:03,108] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.6495063813834239
[2019-03-23 07:31:06,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:31:06,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.2, 79.0, 1.0, 2.0, 0.3130304952028314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 339887.1689850044, 339887.1689850044, 116379.7565424257]
[2019-03-23 07:31:06,452] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:31:06,455] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.24184482131429452
[2019-03-23 07:31:22,332] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:31:22,332] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.85996706, 73.17059017333332, 1.0, 2.0, 0.4338378276717272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 494578.4032606833, 494578.4032606829, 136662.4244931719]
[2019-03-23 07:31:22,335] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:31:22,339] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.5042513954412344
[2019-03-23 07:31:33,832] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:31:33,833] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.64133775, 78.70114824333334, 1.0, 2.0, 0.2480802669683236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 269348.6870804415, 269348.6870804415, 79530.50962069367]
[2019-03-23 07:31:33,835] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:31:33,837] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.6785949424975211
[2019-03-23 07:31:35,411] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.91149616]
[2019-03-23 07:31:35,412] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.620995075, 95.927233645, 1.0, 2.0, 0.4928984643340086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 562177.5649443658, 562177.5649443654, 143449.1582130878]
[2019-03-23 07:31:35,414] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:31:35,418] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.7531283e-21 1.0000000e+00 3.2616972e-29 4.3280933e-28 1.2245755e-31], sampled 0.3547995739306853
[2019-03-23 07:31:35,644] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:31:35,777] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:31:35,783] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:31:35,832] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:31:35,856] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:31:36,873] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 100000, evaluation results [100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:31:43,404] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0581131e-24 1.0000000e+00 2.5781409e-35 9.4797984e-33 5.3981374e-38], sum to 1.0000
[2019-03-23 07:31:43,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1616
[2019-03-23 07:31:43,415] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3163240048396642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346722.2761757778, 346722.2761757781, 113446.410177244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3874200.0000, 
sim time next is 3874800.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3157360944629611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346078.1780737575, 346078.1780737572, 113404.8863690952], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.14467011807870134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12817710299028057, 0.12817710299028046, 0.27659728382706145], 
reward next is 0.7234, 
noisyNet noise sample is [array([1.3841883], dtype=float32), -0.01231255]. 
=============================================
[2019-03-23 07:31:44,250] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103713: loss 0.0053
[2019-03-23 07:31:44,252] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103713: learning rate 0.0010
[2019-03-23 07:31:44,293] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103738: loss 0.0233
[2019-03-23 07:31:44,297] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103738: learning rate 0.0010
[2019-03-23 07:31:44,375] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103783: loss 0.0471
[2019-03-23 07:31:44,377] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103784: learning rate 0.0010
[2019-03-23 07:31:44,518] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103856: loss 0.0103
[2019-03-23 07:31:44,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103858: learning rate 0.0010
[2019-03-23 07:31:44,660] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103932: loss 0.0461
[2019-03-23 07:31:44,664] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103932: learning rate 0.0010
[2019-03-23 07:31:44,672] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103935: loss 0.0314
[2019-03-23 07:31:44,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103937: learning rate 0.0010
[2019-03-23 07:31:44,745] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103977: loss 0.0061
[2019-03-23 07:31:44,745] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103977: learning rate 0.0010
[2019-03-23 07:31:44,758] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103984: loss 0.0026
[2019-03-23 07:31:44,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103985: learning rate 0.0010
[2019-03-23 07:31:44,786] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103998: loss 0.0000
[2019-03-23 07:31:44,787] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103999: learning rate 0.0010
[2019-03-23 07:31:44,789] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104000: loss 0.0132
[2019-03-23 07:31:44,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104000: learning rate 0.0010
[2019-03-23 07:31:44,893] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104049: loss 0.0660
[2019-03-23 07:31:44,897] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104051: learning rate 0.0010
[2019-03-23 07:31:44,921] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104067: loss 0.0697
[2019-03-23 07:31:44,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104069: learning rate 0.0010
[2019-03-23 07:31:45,107] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104168: loss 0.0033
[2019-03-23 07:31:45,109] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104169: learning rate 0.0010
[2019-03-23 07:31:45,132] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104179: loss 0.0227
[2019-03-23 07:31:45,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104179: learning rate 0.0010
[2019-03-23 07:31:45,158] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104188: loss 0.0616
[2019-03-23 07:31:45,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104188: learning rate 0.0010
[2019-03-23 07:31:45,286] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104261: loss 0.0001
[2019-03-23 07:31:45,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104261: learning rate 0.0010
[2019-03-23 07:31:49,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.054907e-28 1.000000e+00 0.000000e+00 5.967520e-37 0.000000e+00], sum to 1.0000
[2019-03-23 07:31:49,602] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6451
[2019-03-23 07:31:49,608] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 88.0, 1.0, 2.0, 0.2742587225008197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297795.903061524, 297795.9030615243, 100619.1279047544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3998400.0000, 
sim time next is 3999000.0000, 
raw observation next is [16.83333333333334, 88.0, 1.0, 2.0, 0.2801182789601929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304160.3226122011, 304160.3226122011, 104399.9268194041], 
processed observation next is [1.0, 0.2608695652173913, 0.40151515151515177, 0.88, 1.0, 1.0, 0.10014784870024114, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11265197133785226, 0.11265197133785226, 0.25463396785220516], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.8043927], dtype=float32), -0.012326302]. 
=============================================
[2019-03-23 07:31:49,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[81.42342]
 [81.42342]
 [81.42342]
 [81.42342]
 [81.42342]], R is [[81.35456085]
 [81.29560089]
 [81.24508667]
 [81.20189667]
 [81.16478729]].
[2019-03-23 07:31:49,891] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.81874800e-23 1.00000000e+00 1.05871395e-33 5.40138515e-33
 2.40031423e-36], sum to 1.0000
[2019-03-23 07:31:49,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3516
[2019-03-23 07:31:49,901] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 84.66666666666666, 1.0, 2.0, 0.2991087726022633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 324787.6216207044, 324787.6216207047, 111133.3568406993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4002000.0000, 
sim time next is 4002600.0000, 
raw observation next is [17.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3010151345033466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326997.9012664288, 326997.9012664285, 111310.0383717411], 
processed observation next is [1.0, 0.30434782608695654, 0.44696969696969674, 0.8383333333333334, 1.0, 1.0, 0.12626891812918323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12111033380238104, 0.12111033380238094, 0.27148789846766125], 
reward next is 0.7285, 
noisyNet noise sample is [array([0.6346015], dtype=float32), 0.9172587]. 
=============================================
[2019-03-23 07:31:59,254] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111633: loss 0.1596
[2019-03-23 07:31:59,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111633: learning rate 0.0010
[2019-03-23 07:31:59,483] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111758: loss 0.0135
[2019-03-23 07:31:59,484] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111758: learning rate 0.0010
[2019-03-23 07:31:59,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9299353e-24 1.0000000e+00 2.4530534e-33 1.2379981e-33 3.0856980e-37], sum to 1.0000
[2019-03-23 07:31:59,515] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8288
[2019-03-23 07:31:59,521] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.8383459623049918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 949852.2137695564, 949852.2137695566, 179840.7500361243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4196400.0000, 
sim time next is 4197000.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.8294197682384932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 939714.5574870686, 939714.5574870683, 178478.0726506489], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.61, 1.0, 1.0, 0.7867747102981165, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3480424286989143, 0.3480424286989142, 0.4353123723186558], 
reward next is 0.5647, 
noisyNet noise sample is [array([0.07439267], dtype=float32), -0.9323916]. 
=============================================
[2019-03-23 07:31:59,538] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.476254]
 [58.476254]
 [58.476254]
 [58.476254]
 [58.476254]], R is [[58.45616913]
 [58.43297195]
 [58.40550232]
 [58.40601349]
 [58.4498558 ]].
[2019-03-23 07:31:59,596] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111815: loss 0.0259
[2019-03-23 07:31:59,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111816: learning rate 0.0010
[2019-03-23 07:31:59,600] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111817: loss 0.0308
[2019-03-23 07:31:59,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111817: learning rate 0.0010
[2019-03-23 07:31:59,713] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111876: loss 0.0434
[2019-03-23 07:31:59,714] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111876: learning rate 0.0010
[2019-03-23 07:31:59,797] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111920: loss 0.0226
[2019-03-23 07:31:59,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111920: learning rate 0.0010
[2019-03-23 07:31:59,859] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111955: loss 0.0097
[2019-03-23 07:31:59,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111955: learning rate 0.0010
[2019-03-23 07:31:59,908] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111978: loss 0.0027
[2019-03-23 07:31:59,910] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111980: learning rate 0.0010
[2019-03-23 07:31:59,932] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111991: loss 0.0008
[2019-03-23 07:31:59,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111991: learning rate 0.0010
[2019-03-23 07:31:59,977] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112014: loss 0.0025
[2019-03-23 07:31:59,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112014: learning rate 0.0010
[2019-03-23 07:32:00,091] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112074: loss 0.0002
[2019-03-23 07:32:00,094] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112075: learning rate 0.0010
[2019-03-23 07:32:00,131] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112094: loss 0.0001
[2019-03-23 07:32:00,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112097: learning rate 0.0010
[2019-03-23 07:32:00,192] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112130: loss 0.0001
[2019-03-23 07:32:00,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112131: learning rate 0.0010
[2019-03-23 07:32:00,255] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112159: loss 0.0002
[2019-03-23 07:32:00,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112160: learning rate 0.0010
[2019-03-23 07:32:00,373] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112226: loss 0.0001
[2019-03-23 07:32:00,377] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112227: learning rate 0.0010
[2019-03-23 07:32:00,635] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112364: loss 0.0052
[2019-03-23 07:32:00,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112365: learning rate 0.0010
[2019-03-23 07:32:10,326] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6292523e-21 1.0000000e+00 2.6526315e-29 1.3365511e-30 3.5134883e-33], sum to 1.0000
[2019-03-23 07:32:10,332] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8435
[2019-03-23 07:32:10,335] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 82.0, 1.0, 2.0, 0.4530928639284997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516435.3146668026, 516435.3146668029, 134117.2385285512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408200.0000, 
sim time next is 4408800.0000, 
raw observation next is [22.16666666666667, 82.33333333333333, 1.0, 2.0, 0.4519359174699271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515058.2956889392, 515058.2956889389, 133913.3874377168], 
processed observation next is [0.0, 0.0, 0.6439393939393941, 0.8233333333333333, 1.0, 1.0, 0.31491989683740884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19076233173664417, 0.19076233173664403, 0.3266180181407727], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.47122025], dtype=float32), -0.2518534]. 
=============================================
[2019-03-23 07:32:10,429] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3182015e-22 1.0000000e+00 3.8489788e-32 2.9168122e-31 4.3398137e-36], sum to 1.0000
[2019-03-23 07:32:10,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5669
[2019-03-23 07:32:10,442] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 77.0, 1.0, 2.0, 0.4642015620424051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 529440.0918875753, 529440.0918875751, 135877.0951133269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4398600.0000, 
sim time next is 4399200.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4644718511566894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529675.1871885792, 529675.1871885792, 135757.1749790475], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3305898139458617, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19617599525502935, 0.19617599525502935, 0.3311150609245061], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.24493067], dtype=float32), -0.31853855]. 
=============================================
[2019-03-23 07:32:10,476] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6454932e-23 1.0000000e+00 1.8814403e-31 6.4288399e-30 1.5558740e-34], sum to 1.0000
[2019-03-23 07:32:10,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6216
[2019-03-23 07:32:10,669] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 83.83333333333334, 1.0, 2.0, 0.4100424767217192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 464536.064994645, 464536.0649946447, 127206.9684275269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4421400.0000, 
sim time next is 4422000.0000, 
raw observation next is [20.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4074181758948127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 461352.2175142144, 461352.2175142147, 126822.8776492212], 
processed observation next is [0.0, 0.17391304347826086, 0.575757575757576, 0.8466666666666667, 1.0, 1.0, 0.25927271986851586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17087119167193127, 0.17087119167193138, 0.3093240918273688], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.74181974], dtype=float32), -0.17750376]. 
=============================================
[2019-03-23 07:32:10,691] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.86381]
 [64.86381]
 [64.86381]
 [64.86381]
 [64.86381]], R is [[64.90584564]
 [64.94652557]
 [64.98564911]
 [65.022789  ]
 [65.05793762]].
[2019-03-23 07:32:14,602] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119669: loss 0.0325
[2019-03-23 07:32:14,607] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119671: learning rate 0.0010
[2019-03-23 07:32:14,673] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119699: loss 0.0733
[2019-03-23 07:32:14,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119701: learning rate 0.0010
[2019-03-23 07:32:14,863] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119807: loss 0.0040
[2019-03-23 07:32:14,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119807: learning rate 0.0010
[2019-03-23 07:32:14,921] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119836: loss 0.0127
[2019-03-23 07:32:14,923] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119837: learning rate 0.0010
[2019-03-23 07:32:15,009] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119881: loss 0.0400
[2019-03-23 07:32:15,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119882: learning rate 0.0010
[2019-03-23 07:32:15,077] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119918: loss 0.0285
[2019-03-23 07:32:15,079] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119918: learning rate 0.0010
[2019-03-23 07:32:15,105] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119931: loss 0.0000
[2019-03-23 07:32:15,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119931: learning rate 0.0010
[2019-03-23 07:32:15,111] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119933: loss 0.0027
[2019-03-23 07:32:15,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119933: learning rate 0.0010
[2019-03-23 07:32:15,240] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120003: loss 0.0310
[2019-03-23 07:32:15,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120003: learning rate 0.0010
[2019-03-23 07:32:15,275] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120021: loss 0.0455
[2019-03-23 07:32:15,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120021: learning rate 0.0010
[2019-03-23 07:32:15,362] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120070: loss 0.0151
[2019-03-23 07:32:15,365] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120070: learning rate 0.0010
[2019-03-23 07:32:15,404] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120089: loss 0.0002
[2019-03-23 07:32:15,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120089: learning rate 0.0010
[2019-03-23 07:32:15,490] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120137: loss 0.0012
[2019-03-23 07:32:15,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120138: learning rate 0.0010
[2019-03-23 07:32:15,616] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120199: loss 0.0371
[2019-03-23 07:32:15,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120201: learning rate 0.0010
[2019-03-23 07:32:15,677] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120232: loss 0.0240
[2019-03-23 07:32:15,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120232: learning rate 0.0010
[2019-03-23 07:32:15,948] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120380: loss 0.0035
[2019-03-23 07:32:15,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120380: learning rate 0.0010
[2019-03-23 07:32:16,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.67492020e-24 1.00000000e+00 1.26983279e-35 1.40715545e-33
 4.47308191e-37], sum to 1.0000
[2019-03-23 07:32:16,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3948
[2019-03-23 07:32:16,773] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 73.0, 1.0, 2.0, 0.4111909817504058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466085.6192302086, 466085.6192302089, 127481.2326137172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4540800.0000, 
sim time next is 4541400.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.4014031981651237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453858.877119161, 453858.877119161, 125836.8434670079], 
processed observation next is [0.0, 0.5652173913043478, 0.6363636363636364, 0.73, 1.0, 1.0, 0.2517539977064046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16809588041450407, 0.16809588041450407, 0.3069191304073363], 
reward next is 0.6931, 
noisyNet noise sample is [array([0.40474185], dtype=float32), -1.8729652]. 
=============================================
[2019-03-23 07:32:19,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5519347e-26 1.0000000e+00 1.2205569e-36 1.9795384e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 07:32:19,372] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8113
[2019-03-23 07:32:19,377] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2388323585815924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259318.9550870409, 259318.9550870409, 82156.60981594167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4593600.0000, 
sim time next is 4594200.0000, 
raw observation next is [14.0, 99.00000000000001, 1.0, 2.0, 0.2435511185192685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 264443.8743637566, 264443.8743637569, 82068.40247287166], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.9900000000000001, 1.0, 1.0, 0.05443889814908561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09794217569028023, 0.09794217569028034, 0.20016683529968698], 
reward next is 0.7998, 
noisyNet noise sample is [array([-0.35363406], dtype=float32), 0.9993015]. 
=============================================
[2019-03-23 07:32:24,656] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 07:32:24,658] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:32:24,659] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:32:24,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:24,660] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:24,660] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:32:24,661] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:32:24,663] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:32:24,666] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:24,665] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:24,666] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:32:24,680] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 07:32:24,680] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 07:32:24,723] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 07:32:24,724] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 07:32:24,770] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 07:32:40,682] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:32:40,684] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.06666666666667, 87.0, 1.0, 2.0, 0.4555175113451062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518102.8454788899, 518102.8454788899, 137510.1208839744]
[2019-03-23 07:32:40,684] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:32:40,686] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.18846833118048623
[2019-03-23 07:32:51,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:32:51,789] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.15273443333334, 75.491546, 1.0, 2.0, 0.4174605161990976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 473358.4113147692, 473358.4113147692, 132528.2605893024]
[2019-03-23 07:32:51,791] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:32:51,795] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.5773757390615738
[2019-03-23 07:32:55,186] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:32:55,187] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 57.0, 1.0, 2.0, 0.3665575962917071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398056.9850856615, 398056.9850856618, 89790.30171607577]
[2019-03-23 07:32:55,188] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:32:55,191] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.29843370958803117
[2019-03-23 07:32:59,752] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:32:59,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.756776175, 59.62442898, 1.0, 2.0, 0.3859691111382431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 419111.2222886914, 419111.222288691, 121007.7869414864]
[2019-03-23 07:32:59,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:32:59,757] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.002971383566901964
[2019-03-23 07:33:00,032] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:33:00,034] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 37.5, 1.0, 2.0, 0.3554009396028049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398341.6981399563, 398341.6981399563, 119860.7068228203]
[2019-03-23 07:33:00,035] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:33:00,039] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.9493330132446178
[2019-03-23 07:33:20,588] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:33:20,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.74034917333334, 77.95396409, 1.0, 2.0, 0.4025839297401901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 452045.8713941192, 452045.8713941188, 128592.1835332952]
[2019-03-23 07:33:20,590] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:33:20,593] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.9064280585279341
[2019-03-23 07:33:21,747] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:33:21,748] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.8, 53.5, 1.0, 2.0, 0.5169359085479578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 588996.1774961877, 588996.1774961877, 148996.870775053]
[2019-03-23 07:33:21,749] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:33:21,753] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.32975246857368945
[2019-03-23 07:33:56,979] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:33:56,981] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.78333333333333, 65.5, 1.0, 2.0, 0.3857911892836798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 434358.2123366407, 434358.2123366404, 127706.3549719027]
[2019-03-23 07:33:56,982] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:33:56,985] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.49146959265584533
[2019-03-23 07:34:08,962] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9991985]
[2019-03-23 07:34:08,964] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.63333333333333, 69.0, 1.0, 2.0, 0.2123657065840318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 230564.8084355071, 230564.8084355071, 77608.23320496522]
[2019-03-23 07:34:08,966] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:34:08,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.2115267e-26 1.0000000e+00 1.0525506e-37 2.5144141e-36 0.0000000e+00], sampled 0.07775637797505242
[2019-03-23 07:34:11,528] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:34:12,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:34:12,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:34:12,158] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:34:12,228] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:34:13,241] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 125000, evaluation results [125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:34:13,768] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6432052e-25 1.0000000e+00 2.6835960e-34 2.7696036e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 07:34:13,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4638
[2019-03-23 07:34:13,788] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 72.83333333333333, 1.0, 2.0, 0.2363250227101606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 256595.826460557, 256595.8264605567, 80259.45643157132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4693800.0000, 
sim time next is 4694400.0000, 
raw observation next is [17.0, 72.0, 1.0, 2.0, 0.2336334996180063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253672.6755889918, 253672.6755889918, 81136.87205663043], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.72, 1.0, 1.0, 0.04204187452250787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09395284281073771, 0.09395284281073771, 0.19789480989422056], 
reward next is 0.8021, 
noisyNet noise sample is [array([-0.7592361], dtype=float32), -0.86924523]. 
=============================================
[2019-03-23 07:34:14,149] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0928948e-26 1.0000000e+00 1.8139684e-36 5.7509859e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 07:34:14,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9644
[2019-03-23 07:34:14,167] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 53.5, 1.0, 2.0, 0.7262460285156459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 815179.6159759137, 815179.6159759134, 159647.6278736354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4709400.0000, 
sim time next is 4710000.0000, 
raw observation next is [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.5797387606804305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651746.4719381328, 651746.4719381328, 142398.7586743468], 
processed observation next is [1.0, 0.5217391304347826, 0.7575757575757573, 0.53, 1.0, 1.0, 0.4746734508505381, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24138758219930845, 0.24138758219930845, 0.34731404554718737], 
reward next is 0.6527, 
noisyNet noise sample is [array([0.22373186], dtype=float32), -0.6996006]. 
=============================================
[2019-03-23 07:34:14,191] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.40477]
 [73.40477]
 [73.40477]
 [73.40477]
 [73.40477]], R is [[73.32341003]
 [73.20079803]
 [73.06890106]
 [72.97357178]
 [72.87876129]].
[2019-03-23 07:34:17,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3040261e-27 1.0000000e+00 1.3885158e-38 2.7425001e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 07:34:17,678] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6791
[2019-03-23 07:34:17,681] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 100.0, 1.0, 2.0, 0.3984293073020844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449525.6763099156, 449525.6763099158, 125004.3339971044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4775400.0000, 
sim time next is 4776000.0000, 
raw observation next is [18.66666666666667, 100.0, 1.0, 2.0, 0.4118820544589052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465457.7632660883, 465457.763266088, 126659.8216876749], 
processed observation next is [1.0, 0.2608695652173913, 0.4848484848484851, 1.0, 1.0, 1.0, 0.26485256807363144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1723917641726253, 0.17239176417262517, 0.3089263943601827], 
reward next is 0.6911, 
noisyNet noise sample is [array([1.6005131], dtype=float32), 1.5163711]. 
=============================================
[2019-03-23 07:34:17,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.11113]
 [70.11113]
 [70.11113]
 [70.11113]
 [70.11113]], R is [[70.10108948]
 [70.09519196]
 [70.0927887 ]
 [70.08525848]
 [70.08911896]].
[2019-03-23 07:34:18,617] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127663: loss 0.1210
[2019-03-23 07:34:18,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127663: learning rate 0.0010
[2019-03-23 07:34:18,705] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127709: loss 0.0405
[2019-03-23 07:34:18,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127709: learning rate 0.0010
[2019-03-23 07:34:18,909] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127812: loss 0.0042
[2019-03-23 07:34:18,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127812: learning rate 0.0010
[2019-03-23 07:34:18,920] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127819: loss 0.0035
[2019-03-23 07:34:18,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127820: learning rate 0.0010
[2019-03-23 07:34:18,995] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127855: loss 0.0055
[2019-03-23 07:34:19,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127855: learning rate 0.0010
[2019-03-23 07:34:19,029] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127871: loss 0.0105
[2019-03-23 07:34:19,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127873: learning rate 0.0010
[2019-03-23 07:34:19,206] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127968: loss 0.0052
[2019-03-23 07:34:19,207] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127969: loss 0.0067
[2019-03-23 07:34:19,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127970: learning rate 0.0010
[2019-03-23 07:34:19,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127970: learning rate 0.0010
[2019-03-23 07:34:19,247] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127991: loss 0.0385
[2019-03-23 07:34:19,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127991: learning rate 0.0010
[2019-03-23 07:34:19,370] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128059: loss 0.0374
[2019-03-23 07:34:19,373] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128060: learning rate 0.0010
[2019-03-23 07:34:19,393] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128068: loss 0.0145
[2019-03-23 07:34:19,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128069: learning rate 0.0010
[2019-03-23 07:34:19,412] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128077: loss 0.0354
[2019-03-23 07:34:19,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128077: learning rate 0.0010
[2019-03-23 07:34:19,548] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128146: loss 0.0439
[2019-03-23 07:34:19,549] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128146: learning rate 0.0010
[2019-03-23 07:34:19,598] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128167: loss 0.0746
[2019-03-23 07:34:19,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128167: learning rate 0.0010
[2019-03-23 07:34:19,619] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128178: loss 0.0936
[2019-03-23 07:34:19,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128178: learning rate 0.0010
[2019-03-23 07:34:19,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.74224374e-19 1.00000000e+00 3.77180961e-26 1.30605143e-25
 1.18885805e-29], sum to 1.0000
[2019-03-23 07:34:19,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9096
[2019-03-23 07:34:19,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1173495.185927337 W.
[2019-03-23 07:34:19,768] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 99.0, 1.0, 2.0, 0.346237222383204, 1.0, 1.0, 0.346237222383204, 1.0, 2.0, 0.7005682960953278, 6.9112, 6.9112, 77.3421103, 1173495.185927337, 1173495.185927337, 280797.7730337268], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4809000.0000, 
sim time next is 4809600.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3485813164263414, 1.0, 2.0, 0.3485813164263414, 1.0, 2.0, 0.7046665542053607, 6.911199999999999, 6.9112, 77.3421103, 1178428.538886729, 1178428.538886729, 282731.2970747737], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 1.0, 1.0, 1.0, 0.1857266455329267, 1.0, 1.0, 0.1857266455329267, 1.0, 1.0, 0.5780950774362297, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4364550144024922, 0.4364550144024922, 0.6895885294506675], 
reward next is 0.3104, 
noisyNet noise sample is [array([0.98239887], dtype=float32), -0.5796079]. 
=============================================
[2019-03-23 07:34:19,857] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128308: loss 0.1590
[2019-03-23 07:34:19,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128311: learning rate 0.0010
[2019-03-23 07:34:21,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0650741e-23 1.0000000e+00 3.4042206e-33 3.3500660e-31 7.9893970e-34], sum to 1.0000
[2019-03-23 07:34:21,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6413
[2019-03-23 07:34:21,641] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4441918628443092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506237.0057321845, 506237.0057321845, 133118.364897608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4842000.0000, 
sim time next is 4842600.0000, 
raw observation next is [20.0, 99.00000000000001, 1.0, 2.0, 0.4418789191733853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503457.4533027901, 503457.4533027901, 132687.2921347941], 
processed observation next is [1.0, 0.043478260869565216, 0.5454545454545454, 0.9900000000000001, 1.0, 1.0, 0.3023486489667316, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18646572344547782, 0.18646572344547782, 0.3236275417921807], 
reward next is 0.6764, 
noisyNet noise sample is [array([-2.2156053], dtype=float32), -0.15129599]. 
=============================================
[2019-03-23 07:34:25,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3895225e-23 1.0000000e+00 5.7301941e-32 1.0001417e-29 4.2297053e-35], sum to 1.0000
[2019-03-23 07:34:25,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4274
[2019-03-23 07:34:25,625] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.4253597505236951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473343.3839819187, 473343.3839819187, 124467.0701869344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4936200.0000, 
sim time next is 4936800.0000, 
raw observation next is [17.66666666666667, 96.0, 1.0, 2.0, 0.3875140015423765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430838.0097964984, 430838.0097964987, 121049.4728432002], 
processed observation next is [1.0, 0.13043478260869565, 0.4393939393939396, 0.96, 1.0, 1.0, 0.23439250192797056, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15956963325796236, 0.15956963325796247, 0.2952426166907322], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.02900754], dtype=float32), 1.8748798]. 
=============================================
[2019-03-23 07:34:29,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6293210e-30 1.0000000e+00 8.6565636e-37 3.2222013e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 07:34:29,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0539
[2019-03-23 07:34:29,591] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2806492166611334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 304737.0103567261, 304737.0103567261, 96215.29007976975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5007600.0000, 
sim time next is 5008200.0000, 
raw observation next is [17.0, 82.00000000000001, 1.0, 2.0, 0.2789452900537836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302886.2615718028, 302886.2615718031, 96000.95130887427], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.8200000000000002, 1.0, 1.0, 0.09868161256722949, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11218009687844548, 0.11218009687844559, 0.23414866172896162], 
reward next is 0.7659, 
noisyNet noise sample is [array([0.35900548], dtype=float32), 0.0531673]. 
=============================================
[2019-03-23 07:34:30,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8408403e-26 1.0000000e+00 1.8793481e-36 3.4737253e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 07:34:30,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3235
[2019-03-23 07:34:30,703] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 100.0, 1.0, 2.0, 0.2369617853710211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 257287.3903744289, 257287.3903744289, 84014.63501221985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5035200.0000, 
sim time next is 5035800.0000, 
raw observation next is [14.66666666666667, 100.0, 1.0, 2.0, 0.2479346898325014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269204.8026032164, 269204.8026032161, 88034.74109974889], 
processed observation next is [0.0, 0.2608695652173913, 0.30303030303030315, 1.0, 1.0, 1.0, 0.05991836229062672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0997054824456357, 0.09970548244563558, 0.21471888073109485], 
reward next is 0.7853, 
noisyNet noise sample is [array([-0.00968747], dtype=float32), 0.27637723]. 
=============================================
[2019-03-23 07:34:33,473] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135600: loss 0.0180
[2019-03-23 07:34:33,475] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135600: learning rate 0.0010
[2019-03-23 07:34:33,697] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135720: loss 0.0009
[2019-03-23 07:34:33,700] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135720: learning rate 0.0010
[2019-03-23 07:34:33,885] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135823: loss 0.0130
[2019-03-23 07:34:33,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135824: learning rate 0.0010
[2019-03-23 07:34:33,933] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135845: loss 0.0006
[2019-03-23 07:34:33,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135845: learning rate 0.0010
[2019-03-23 07:34:33,952] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135854: loss 0.0013
[2019-03-23 07:34:33,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135854: learning rate 0.0010
[2019-03-23 07:34:34,071] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135921: loss 0.0629
[2019-03-23 07:34:34,075] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135921: learning rate 0.0010
[2019-03-23 07:34:34,126] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135948: loss 0.0262
[2019-03-23 07:34:34,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135949: learning rate 0.0010
[2019-03-23 07:34:34,151] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135961: loss 0.0276
[2019-03-23 07:34:34,154] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135964: learning rate 0.0010
[2019-03-23 07:34:34,192] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135986: loss 0.0022
[2019-03-23 07:34:34,193] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135986: learning rate 0.0010
[2019-03-23 07:34:34,337] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136059: loss 0.0348
[2019-03-23 07:34:34,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136060: learning rate 0.0010
[2019-03-23 07:34:34,415] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136102: loss 0.0484
[2019-03-23 07:34:34,417] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136103: loss 0.0260
[2019-03-23 07:34:34,421] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136105: learning rate 0.0010
[2019-03-23 07:34:34,423] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136105: learning rate 0.0010
[2019-03-23 07:34:34,497] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136142: loss 0.0062
[2019-03-23 07:34:34,499] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136143: learning rate 0.0010
[2019-03-23 07:34:34,529] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136158: loss 0.0065
[2019-03-23 07:34:34,531] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136158: learning rate 0.0010
[2019-03-23 07:34:34,655] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136226: loss 0.0384
[2019-03-23 07:34:34,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136226: learning rate 0.0010
[2019-03-23 07:34:34,968] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136392: loss 0.0416
[2019-03-23 07:34:34,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136394: learning rate 0.0010
[2019-03-23 07:34:36,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.67544274e-23 1.00000000e+00 1.01464914e-35 8.63579336e-35
 5.51132984e-38], sum to 1.0000
[2019-03-23 07:34:36,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3035
[2019-03-23 07:34:36,098] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4380832557152411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499183.8046331533, 499183.8046331533, 132366.9780835424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5127000.0000, 
sim time next is 5127600.0000, 
raw observation next is [22.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4405094203863841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502031.8750374049, 502031.8750374049, 132728.6578790347], 
processed observation next is [0.0, 0.34782608695652173, 0.6515151515151518, 0.8133333333333335, 1.0, 1.0, 0.30063677548298007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18593773149533513, 0.18593773149533513, 0.3237284338513041], 
reward next is 0.6763, 
noisyNet noise sample is [array([-0.5346969], dtype=float32), 0.08135417]. 
=============================================
[2019-03-23 07:34:38,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6471547e-24 1.0000000e+00 2.2871579e-35 4.8075696e-35 9.2420718e-38], sum to 1.0000
[2019-03-23 07:34:38,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1702
[2019-03-23 07:34:38,246] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 82.16666666666667, 1.0, 2.0, 0.4705118056752835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536889.3191656884, 536889.3191656884, 137538.9808057231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5172600.0000, 
sim time next is 5173200.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.4743951721500702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541316.8193459377, 541316.8193459377, 138205.8681469843], 
processed observation next is [0.0, 0.9130434782608695, 0.6818181818181818, 0.83, 1.0, 1.0, 0.34299396518758773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2004877108688658, 0.2004877108688658, 0.3370874832853276], 
reward next is 0.6629, 
noisyNet noise sample is [array([0.5836292], dtype=float32), 0.24677294]. 
=============================================
[2019-03-23 07:34:40,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6022062e-23 1.0000000e+00 8.7223832e-32 1.8215460e-30 2.8302380e-35], sum to 1.0000
[2019-03-23 07:34:40,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4947
[2019-03-23 07:34:40,142] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 81.33333333333333, 1.0, 2.0, 0.4571885197673928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521411.1366617353, 521411.1366617353, 135070.4393905402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5211600.0000, 
sim time next is 5212200.0000, 
raw observation next is [22.83333333333334, 82.16666666666667, 1.0, 2.0, 0.4523018113033654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516041.2081376446, 516041.2081376446, 135121.4700703672], 
processed observation next is [1.0, 0.30434782608695654, 0.6742424242424245, 0.8216666666666668, 1.0, 1.0, 0.3153772641292067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1911263733843128, 0.1911263733843128, 0.3295645611472371], 
reward next is 0.6704, 
noisyNet noise sample is [array([-1.0067848], dtype=float32), 0.54167384]. 
=============================================
[2019-03-23 07:34:47,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1594067e-26 1.0000000e+00 4.7045221e-35 8.5900211e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 07:34:47,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4559
[2019-03-23 07:34:47,851] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.25, 87.0, 1.0, 2.0, 0.4171291847205296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471957.3311010795, 471957.3311010795, 127490.0651149099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5373000.0000, 
sim time next is 5373600.0000, 
raw observation next is [20.16666666666666, 87.0, 1.0, 2.0, 0.4305370603296604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486810.1205946115, 486810.1205946115, 128574.8485070652], 
processed observation next is [1.0, 0.17391304347826086, 0.5530303030303028, 0.87, 1.0, 1.0, 0.28817132541207546, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18030004466467092, 0.18030004466467092, 0.3135971914806468], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.59150577], dtype=float32), 0.7963782]. 
=============================================
[2019-03-23 07:34:48,515] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143623: loss -111.8311
[2019-03-23 07:34:48,516] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143623: learning rate 0.0010
[2019-03-23 07:34:48,722] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143732: loss -134.8096
[2019-03-23 07:34:48,724] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143733: learning rate 0.0010
[2019-03-23 07:34:48,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143826: loss -139.1049
[2019-03-23 07:34:48,903] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143826: learning rate 0.0010
[2019-03-23 07:34:48,937] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143847: loss -105.8187
[2019-03-23 07:34:48,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143848: learning rate 0.0010
[2019-03-23 07:34:48,950] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143853: loss -107.3956
[2019-03-23 07:34:48,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143853: learning rate 0.0010
[2019-03-23 07:34:49,109] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143943: loss -122.6359
[2019-03-23 07:34:49,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143943: learning rate 0.0010
[2019-03-23 07:34:49,114] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143947: loss -118.9973
[2019-03-23 07:34:49,120] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143949: learning rate 0.0010
[2019-03-23 07:34:49,134] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143956: loss -133.5979
[2019-03-23 07:34:49,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143957: learning rate 0.0010
[2019-03-23 07:34:49,163] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143971: loss -113.9032
[2019-03-23 07:34:49,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143973: learning rate 0.0010
[2019-03-23 07:34:49,276] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144036: loss -136.8978
[2019-03-23 07:34:49,277] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144036: learning rate 0.0010
[2019-03-23 07:34:49,317] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144054: loss -81.8150
[2019-03-23 07:34:49,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144055: learning rate 0.0010
[2019-03-23 07:34:49,521] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144173: loss -38.2280
[2019-03-23 07:34:49,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144173: learning rate 0.0010
[2019-03-23 07:34:49,573] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144201: loss -68.1359
[2019-03-23 07:34:49,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144202: learning rate 0.0010
[2019-03-23 07:34:49,589] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144210: loss -57.7057
[2019-03-23 07:34:49,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144211: learning rate 0.0010
[2019-03-23 07:34:49,620] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144225: loss -82.7276
[2019-03-23 07:34:49,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144225: learning rate 0.0010
[2019-03-23 07:34:49,747] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144298: loss -53.4448
[2019-03-23 07:34:49,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144298: learning rate 0.0010
[2019-03-23 07:34:50,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1033526e-17 1.0000000e+00 1.3714040e-28 1.6804349e-26 9.4508189e-30], sum to 1.0000
[2019-03-23 07:34:50,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7231
[2019-03-23 07:34:50,784] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 95.5, 1.0, 2.0, 0.3807775147533134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426969.6899207824, 426969.6899207824, 122073.7166518109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5435400.0000, 
sim time next is 5436000.0000, 
raw observation next is [18.3, 96.0, 1.0, 2.0, 0.3799543596220945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425902.8555158277, 425902.8555158277, 121935.4125104507], 
processed observation next is [1.0, 0.9565217391304348, 0.4681818181818182, 0.96, 1.0, 1.0, 0.22494294952761812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15774179833919544, 0.15774179833919544, 0.2974034451474407], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.79625154], dtype=float32), -1.05047]. 
=============================================
[2019-03-23 07:34:50,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[54.227562]
 [54.227562]
 [54.227562]
 [54.227562]
 [54.227562]], R is [[54.38788605]
 [54.54626846]
 [54.70265579]
 [54.85699844]
 [55.00925446]].
[2019-03-23 07:34:52,654] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3059667e-25 1.0000000e+00 5.4840481e-37 5.1304147e-35 2.8337879e-38], sum to 1.0000
[2019-03-23 07:34:52,661] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7726
[2019-03-23 07:34:52,664] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.71666666666667, 87.5, 1.0, 2.0, 0.6722292592057042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 757891.5324757396, 757891.5324757396, 154404.6700786077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5475000.0000, 
sim time next is 5475600.0000, 
raw observation next is [20.0, 87.0, 1.0, 2.0, 0.6766313800043374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 764466.075528817, 764466.075528817, 155817.1425392695], 
processed observation next is [1.0, 0.391304347826087, 0.5454545454545454, 0.87, 1.0, 1.0, 0.5957892250054218, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2831355835291915, 0.2831355835291915, 0.380041811071389], 
reward next is 0.6200, 
noisyNet noise sample is [array([0.2910647], dtype=float32), 0.5393781]. 
=============================================
[2019-03-23 07:34:55,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0336287e-24 1.0000000e+00 3.9609833e-36 1.0550049e-33 1.0890700e-36], sum to 1.0000
[2019-03-23 07:34:55,590] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1922
[2019-03-23 07:34:55,605] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333334, 85.0, 1.0, 2.0, 0.4352765804092056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 495334.3388219048, 495334.3388219045, 131344.7725281277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5530800.0000, 
sim time next is 5531400.0000, 
raw observation next is [21.35, 85.5, 1.0, 2.0, 0.4341929123115352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494058.7690488191, 494058.7690488191, 131194.5307691458], 
processed observation next is [1.0, 0.0, 0.6068181818181819, 0.855, 1.0, 1.0, 0.29274114038941895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1829847292773404, 0.1829847292773404, 0.3199866604125507], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.75495625], dtype=float32), 0.34305042]. 
=============================================
[2019-03-23 07:35:00,293] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:35:00,295] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:35:00,296] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:00,296] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:35:00,297] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:35:00,297] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:35:00,298] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:00,299] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:35:00,299] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:00,300] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:00,301] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:35:00,313] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 07:35:00,333] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 07:35:00,334] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 07:35:00,335] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 07:35:00,352] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 07:35:08,603] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8885763]
[2019-03-23 07:35:08,605] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.73333333333333, 70.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 187370.2531517064, 187370.2531517064, 50200.10242320924]
[2019-03-23 07:35:08,606] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:35:08,608] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1259781e-23 1.0000000e+00 1.6741266e-33 2.9210306e-32 2.8096150e-36], sampled 0.5099951887225838
[2019-03-23 07:35:08,660] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8885763]
[2019-03-23 07:35:08,662] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 83.0, 1.0, 2.0, 0.3060921251622884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 333142.4779044439, 333142.4779044439, 111871.2333116482]
[2019-03-23 07:35:08,663] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:35:08,665] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1259781e-23 1.0000000e+00 1.6741266e-33 2.9210306e-32 2.8096150e-36], sampled 0.4316930127935108
[2019-03-23 07:35:52,010] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8885763]
[2019-03-23 07:35:52,011] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.98333333333333, 54.5, 1.0, 2.0, 0.3725622647552514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416584.2325375142, 416584.2325375138, 125153.3296509848]
[2019-03-23 07:35:52,013] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:35:52,015] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1259781e-23 1.0000000e+00 1.6741266e-33 2.9210306e-32 2.8096150e-36], sampled 0.6787340012024711
[2019-03-23 07:36:15,386] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8885763]
[2019-03-23 07:36:15,387] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.33333333333333, 66.83333333333333, 1.0, 2.0, 0.6265764913782086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 715000.7104480093, 715000.710448009, 161065.1942131095]
[2019-03-23 07:36:15,388] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:36:15,391] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1259781e-23 1.0000000e+00 1.6741266e-33 2.9210306e-32 2.8096150e-36], sampled 0.5818857039391425
[2019-03-23 07:36:33,393] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8885763]
[2019-03-23 07:36:33,396] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.91666666666667, 55.33333333333333, 1.0, 2.0, 0.453162778938679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516826.6017550799, 516826.6017550799, 134660.3215789458]
[2019-03-23 07:36:33,397] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:36:33,399] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1259781e-23 1.0000000e+00 1.6741266e-33 2.9210306e-32 2.8096150e-36], sampled 0.3493500995792813
[2019-03-23 07:36:46,662] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8885763]
[2019-03-23 07:36:46,664] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.96666666666667, 67.66666666666667, 1.0, 2.0, 0.4272207724029048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 483290.7283693411, 483290.7283693407, 132730.9202721574]
[2019-03-23 07:36:46,665] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:36:46,667] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1259781e-23 1.0000000e+00 1.6741266e-33 2.9210306e-32 2.8096150e-36], sampled 0.26011464032951825
[2019-03-23 07:36:47,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:36:47,462] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:36:47,542] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:36:47,620] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:36:47,770] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:36:48,781] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 150000, evaluation results [150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:36:51,984] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151587: loss 7.7913
[2019-03-23 07:36:51,986] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151587: learning rate 0.0010
[2019-03-23 07:36:52,179] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151673: loss 7.9164
[2019-03-23 07:36:52,182] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151674: learning rate 0.0010
[2019-03-23 07:36:52,559] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151843: loss 8.3068
[2019-03-23 07:36:52,563] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151844: learning rate 0.0010
[2019-03-23 07:36:52,597] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151862: loss 7.9720
[2019-03-23 07:36:52,602] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151862: loss 7.7723
[2019-03-23 07:36:52,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151862: learning rate 0.0010
[2019-03-23 07:36:52,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151863: learning rate 0.0010
[2019-03-23 07:36:52,724] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151923: loss 7.6649
[2019-03-23 07:36:52,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151924: learning rate 0.0010
[2019-03-23 07:36:52,749] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151936: loss 7.6046
[2019-03-23 07:36:52,752] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151936: learning rate 0.0010
[2019-03-23 07:36:52,801] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151963: loss 7.6023
[2019-03-23 07:36:52,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151963: learning rate 0.0010
[2019-03-23 07:36:52,838] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151986: loss 7.2357
[2019-03-23 07:36:52,844] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151986: learning rate 0.0010
[2019-03-23 07:36:52,907] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152020: loss 6.7142
[2019-03-23 07:36:52,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152021: learning rate 0.0010
[2019-03-23 07:36:53,098] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152120: loss 5.3789
[2019-03-23 07:36:53,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152120: learning rate 0.0010
[2019-03-23 07:36:53,123] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152133: loss 4.8301
[2019-03-23 07:36:53,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152134: learning rate 0.0010
[2019-03-23 07:36:53,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152145: loss 5.0065
[2019-03-23 07:36:53,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152146: learning rate 0.0010
[2019-03-23 07:36:53,226] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152189: loss 4.2689
[2019-03-23 07:36:53,227] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152189: learning rate 0.0010
[2019-03-23 07:36:53,262] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152207: loss 4.1108
[2019-03-23 07:36:53,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152210: learning rate 0.0010
[2019-03-23 07:36:53,423] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4874180e-18 1.0000000e+00 9.1746937e-24 1.3703093e-23 1.9307187e-26], sum to 1.0000
[2019-03-23 07:36:53,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9018
[2019-03-23 07:36:53,439] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [10.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 148544.8360025151, 148544.8360025151, 57660.20423742197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5713200.0000, 
sim time next is 5713800.0000, 
raw observation next is [9.9, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 146734.0108160893, 146734.0108160891, 57422.32817367178], 
processed observation next is [0.0, 0.13043478260869565, 0.08636363636363638, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05434592993188493, 0.054345929931884855, 0.14005445896017507], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88757455], dtype=float32), 0.26379362]. 
=============================================
[2019-03-23 07:36:53,516] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152339: loss 2.9405
[2019-03-23 07:36:53,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152339: learning rate 0.0010
[2019-03-23 07:37:01,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1218531e-24 1.0000000e+00 9.9766505e-37 3.7719916e-36 2.1243854e-38], sum to 1.0000
[2019-03-23 07:37:01,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2165
[2019-03-23 07:37:01,598] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 83.0, 1.0, 2.0, 0.2859104537405453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 310451.6366956673, 310451.6366956671, 104089.6812381449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5884800.0000, 
sim time next is 5885400.0000, 
raw observation next is [17.28333333333333, 83.5, 1.0, 2.0, 0.284989204434354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309450.9935036004, 309450.9935036007, 103542.9294524099], 
processed observation next is [1.0, 0.08695652173913043, 0.4219696969696969, 0.835, 1.0, 1.0, 0.10623650554294248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11461147907540756, 0.11461147907540767, 0.25254373037173145], 
reward next is 0.7475, 
noisyNet noise sample is [array([1.6813812], dtype=float32), -1.2444241]. 
=============================================
[2019-03-23 07:37:05,585] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0263904e-24 1.0000000e+00 1.4859073e-32 2.7728442e-32 2.0142475e-36], sum to 1.0000
[2019-03-23 07:37:05,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7013
[2019-03-23 07:37:05,595] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 60.66666666666666, 1.0, 2.0, 0.4019553136051209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454425.5688252753, 454425.5688252753, 125853.6104141834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5947800.0000, 
sim time next is 5948400.0000, 
raw observation next is [23.9, 61.33333333333334, 1.0, 2.0, 0.3994145099784425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 451426.3158457608, 451426.3158457605, 125545.0899286074], 
processed observation next is [1.0, 0.8695652173913043, 0.7227272727272727, 0.6133333333333334, 1.0, 1.0, 0.24926813747305313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16719493179472622, 0.1671949317947261, 0.30620753641123755], 
reward next is 0.6938, 
noisyNet noise sample is [array([0.976437], dtype=float32), 0.5610941]. 
=============================================
[2019-03-23 07:37:07,243] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159601: loss 0.2661
[2019-03-23 07:37:07,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159603: learning rate 0.0010
[2019-03-23 07:37:07,299] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159628: loss 0.1799
[2019-03-23 07:37:07,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159628: learning rate 0.0010
[2019-03-23 07:37:07,645] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159806: loss 0.4318
[2019-03-23 07:37:07,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159806: learning rate 0.0010
[2019-03-23 07:37:07,677] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159822: loss 0.3406
[2019-03-23 07:37:07,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159823: learning rate 0.0010
[2019-03-23 07:37:07,760] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159868: loss 0.3631
[2019-03-23 07:37:07,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159869: learning rate 0.0010
[2019-03-23 07:37:07,878] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159928: loss 0.0961
[2019-03-23 07:37:07,881] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159928: learning rate 0.0010
[2019-03-23 07:37:07,928] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159954: loss 0.0388
[2019-03-23 07:37:07,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159955: learning rate 0.0010
[2019-03-23 07:37:07,976] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159979: loss 0.0654
[2019-03-23 07:37:07,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159980: learning rate 0.0010
[2019-03-23 07:37:08,042] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160010: loss 0.0867
[2019-03-23 07:37:08,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160011: learning rate 0.0010
[2019-03-23 07:37:08,104] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160045: loss 0.0563
[2019-03-23 07:37:08,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160045: learning rate 0.0010
[2019-03-23 07:37:08,234] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160115: loss 0.0035
[2019-03-23 07:37:08,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160116: learning rate 0.0010
[2019-03-23 07:37:08,272] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160134: loss 0.0013
[2019-03-23 07:37:08,273] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160134: learning rate 0.0010
[2019-03-23 07:37:08,275] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160136: loss 0.0013
[2019-03-23 07:37:08,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160136: learning rate 0.0010
[2019-03-23 07:37:08,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160141: loss 0.0019
[2019-03-23 07:37:08,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160142: learning rate 0.0010
[2019-03-23 07:37:08,444] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160222: loss 0.0072
[2019-03-23 07:37:08,445] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160222: learning rate 0.0010
[2019-03-23 07:37:08,577] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160294: loss 0.0256
[2019-03-23 07:37:08,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160294: learning rate 0.0010
[2019-03-23 07:37:12,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.8444561e-22 1.0000000e+00 6.3611768e-35 9.7053773e-34 1.3051975e-36], sum to 1.0000
[2019-03-23 07:37:12,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6557
[2019-03-23 07:37:12,417] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 58.0, 1.0, 2.0, 0.5560746390255966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 603987.6431468566, 603987.6431468562, 122819.358387111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6087600.0000, 
sim time next is 6088200.0000, 
raw observation next is [20.18333333333333, 57.5, 1.0, 2.0, 0.5665900822907719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615416.3587018935, 615416.3587018935, 124895.4581992903], 
processed observation next is [1.0, 0.4782608695652174, 0.5537878787878786, 0.575, 1.0, 1.0, 0.4582376028634648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22793198470440498, 0.22793198470440498, 0.30462306877875683], 
reward next is 0.6954, 
noisyNet noise sample is [array([-1.2722286], dtype=float32), 0.6314904]. 
=============================================
[2019-03-23 07:37:15,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.1370498e-23 1.0000000e+00 1.9525819e-35 1.7769334e-32 2.9424496e-38], sum to 1.0000
[2019-03-23 07:37:15,177] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2273
[2019-03-23 07:37:15,182] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.11666666666667, 76.5, 1.0, 2.0, 0.2887854142243096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313574.3764493893, 313574.376449389, 103374.7318834981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6138600.0000, 
sim time next is 6139200.0000, 
raw observation next is [17.93333333333333, 78.0, 1.0, 2.0, 0.2896972493711669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314564.8025507451, 314564.8025507451, 103590.630934603], 
processed observation next is [1.0, 0.043478260869565216, 0.45151515151515137, 0.78, 1.0, 1.0, 0.11212156171395864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11650548242620189, 0.11650548242620189, 0.2526600754502512], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.06139652], dtype=float32), 1.9317751]. 
=============================================
[2019-03-23 07:37:16,282] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8455300e-23 1.0000000e+00 5.6194724e-31 3.0748769e-29 7.8493733e-35], sum to 1.0000
[2019-03-23 07:37:16,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9016
[2019-03-23 07:37:16,295] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.06666666666667, 80.33333333333334, 1.0, 2.0, 0.2990273297846925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 324699.1573154685, 324699.1573154685, 111126.6782865152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6160800.0000, 
sim time next is 6161400.0000, 
raw observation next is [18.25, 80.0, 1.0, 2.0, 0.3014242118159126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327302.6901777003, 327302.6901777003, 111288.4951397671], 
processed observation next is [1.0, 0.30434782608695654, 0.4659090909090909, 0.8, 1.0, 1.0, 0.12678026476989074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12122321858433345, 0.12122321858433345, 0.2714353539994319], 
reward next is 0.7286, 
noisyNet noise sample is [array([-0.60007584], dtype=float32), -0.49209124]. 
=============================================
[2019-03-23 07:37:19,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2842857e-23 1.0000000e+00 4.5056191e-30 2.9842318e-29 3.3486792e-35], sum to 1.0000
[2019-03-23 07:37:19,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6320
[2019-03-23 07:37:19,221] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 90.5, 1.0, 2.0, 0.3823949536497465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430429.0025165689, 430429.0025165689, 123027.8987134748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6225000.0000, 
sim time next is 6225600.0000, 
raw observation next is [19.2, 91.0, 1.0, 2.0, 0.3838507793715504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431891.6737473012, 431891.6737473012, 123064.0112208737], 
processed observation next is [0.0, 0.043478260869565216, 0.509090909090909, 0.91, 1.0, 1.0, 0.22981347421443796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15995987916566712, 0.15995987916566712, 0.3001561249289602], 
reward next is 0.6998, 
noisyNet noise sample is [array([1.0955234], dtype=float32), -0.014199175]. 
=============================================
[2019-03-23 07:37:20,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2993194e-23 1.0000000e+00 4.9347804e-33 2.4397270e-33 4.4468814e-37], sum to 1.0000
[2019-03-23 07:37:20,743] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8135
[2019-03-23 07:37:20,747] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 85.33333333333334, 1.0, 2.0, 0.4260668150879681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485193.9588323939, 485193.9588323939, 130786.6972104229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6255600.0000, 
sim time next is 6256200.0000, 
raw observation next is [21.6, 86.16666666666666, 1.0, 2.0, 0.4306607693662755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490626.8687037581, 490626.8687037581, 131486.0143934283], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.8616666666666666, 1.0, 1.0, 0.28832596170784436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18171365507546597, 0.18171365507546597, 0.3206975960815325], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.821428], dtype=float32), -0.5597632]. 
=============================================
[2019-03-23 07:37:22,325] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167602: loss 0.0623
[2019-03-23 07:37:22,325] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167602: loss 0.0554
[2019-03-23 07:37:22,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167604: learning rate 0.0010
[2019-03-23 07:37:22,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167608: learning rate 0.0010
[2019-03-23 07:37:22,693] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167795: loss 0.0118
[2019-03-23 07:37:22,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167795: learning rate 0.0010
[2019-03-23 07:37:22,699] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167795: loss 0.0032
[2019-03-23 07:37:22,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167795: learning rate 0.0010
[2019-03-23 07:37:22,778] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167844: loss 0.0004
[2019-03-23 07:37:22,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167845: learning rate 0.0010
[2019-03-23 07:37:22,966] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167942: loss 0.0368
[2019-03-23 07:37:22,970] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167943: learning rate 0.0010
[2019-03-23 07:37:23,004] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167959: loss 0.0155
[2019-03-23 07:37:23,005] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167959: loss 0.0077
[2019-03-23 07:37:23,008] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167960: learning rate 0.0010
[2019-03-23 07:37:23,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167960: learning rate 0.0010
[2019-03-23 07:37:23,106] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168015: loss 0.0119
[2019-03-23 07:37:23,108] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168016: learning rate 0.0010
[2019-03-23 07:37:23,115] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168019: loss 0.0148
[2019-03-23 07:37:23,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168021: learning rate 0.0010
[2019-03-23 07:37:23,154] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168039: loss 0.0399
[2019-03-23 07:37:23,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168041: learning rate 0.0010
[2019-03-23 07:37:23,424] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168181: loss 0.0293
[2019-03-23 07:37:23,426] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168183: learning rate 0.0010
[2019-03-23 07:37:23,435] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168189: loss 0.0286
[2019-03-23 07:37:23,437] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168189: learning rate 0.0010
[2019-03-23 07:37:23,548] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168247: loss 0.0381
[2019-03-23 07:37:23,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168248: learning rate 0.0010
[2019-03-23 07:37:23,667] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168309: loss 0.0004
[2019-03-23 07:37:23,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168309: learning rate 0.0010
[2019-03-23 07:37:23,684] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168319: loss 0.0026
[2019-03-23 07:37:23,685] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168320: learning rate 0.0010
[2019-03-23 07:37:26,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8184990e-25 1.0000000e+00 3.3949466e-34 2.5760397e-33 3.0262693e-37], sum to 1.0000
[2019-03-23 07:37:26,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5934
[2019-03-23 07:37:26,095] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 67.66666666666667, 1.0, 2.0, 0.5630366839088845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 637517.8861412596, 637517.8861412593, 152618.1391463163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6374400.0000, 
sim time next is 6375000.0000, 
raw observation next is [27.28333333333333, 68.33333333333333, 1.0, 2.0, 0.5650570166577089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 639644.6460465697, 639644.6460465697, 152938.0159953811], 
processed observation next is [0.0, 0.782608695652174, 0.8765151515151515, 0.6833333333333332, 1.0, 1.0, 0.4563212708221361, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23690542446169247, 0.23690542446169247, 0.3730195512082466], 
reward next is 0.6270, 
noisyNet noise sample is [array([1.842041], dtype=float32), 0.17204645]. 
=============================================
[2019-03-23 07:37:26,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.059204]
 [66.059204]
 [66.059204]
 [66.059204]
 [66.059204]], R is [[66.02559662]
 [65.99310303]
 [65.96165466]
 [65.93118286]
 [65.90161896]].
[2019-03-23 07:37:31,751] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7147405e-28 1.0000000e+00 8.9699443e-35 3.5183513e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 07:37:31,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-23 07:37:31,759] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.6, 74.5, 1.0, 2.0, 0.221470124635531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240462.7608739539, 240462.7608739536, 75602.30725066227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6472200.0000, 
sim time next is 6472800.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.22006587242528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238937.7095639153, 238937.7095639156, 75342.88319929664], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.025082340531599988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08849544798663529, 0.0884954479866354, 0.18376312975438205], 
reward next is 0.8162, 
noisyNet noise sample is [array([0.04796817], dtype=float32), 0.7932336]. 
=============================================
[2019-03-23 07:37:32,785] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5422334e-22 1.0000000e+00 1.1122300e-34 9.0315501e-33 8.9028763e-38], sum to 1.0000
[2019-03-23 07:37:32,791] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-23 07:37:32,793] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.8, 89.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 200153.4940718499, 200153.4940718496, 67927.98393568805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6493800.0000, 
sim time next is 6494400.0000, 
raw observation next is [12.7, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 199428.5955407397, 199428.59554074, 67713.70698080146], 
processed observation next is [1.0, 0.17391304347826086, 0.2136363636363636, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07386244279286656, 0.07386244279286666, 0.16515538288000356], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5297775], dtype=float32), -0.6697805]. 
=============================================
[2019-03-23 07:37:35,216] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7025211e-25 1.0000000e+00 3.0451645e-32 6.2895472e-32 1.2465267e-35], sum to 1.0000
[2019-03-23 07:37:35,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6572
[2019-03-23 07:37:35,229] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 48.5, 1.0, 2.0, 0.562697743071198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 611185.9362566015, 611185.9362566015, 122212.1300585798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6540600.0000, 
sim time next is 6541200.0000, 
raw observation next is [21.6, 48.0, 1.0, 2.0, 0.5918044673325569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 642821.7224539116, 642821.7224539116, 126078.1651311931], 
processed observation next is [1.0, 0.7391304347826086, 0.6181818181818183, 0.48, 1.0, 1.0, 0.48975558416569603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23808211942737464, 0.23808211942737464, 0.3075077198321783], 
reward next is 0.6925, 
noisyNet noise sample is [array([-0.37530056], dtype=float32), -1.4485604]. 
=============================================
[2019-03-23 07:37:36,338] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 07:37:36,339] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:37:36,340] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:37:36,341] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:37:36,341] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:36,342] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:36,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:37:36,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:36,344] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:37:36,345] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:36,348] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:37:36,360] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 07:37:36,384] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 07:37:36,384] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 07:37:36,438] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 07:37:36,438] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 07:37:39,333] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:37:39,336] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.13333333333333, 48.66666666666666, 1.0, 2.0, 0.2361305826108607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 256371.7652736715, 256371.7652736715, 77736.78400282748]
[2019-03-23 07:37:39,337] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:37:39,343] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.5300354937270776
[2019-03-23 07:37:52,861] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:37:52,862] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.86495732, 95.00045955333334, 1.0, 2.0, 0.4110374904625971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 466690.7647103615, 466690.7647103615, 132370.8617640944]
[2019-03-23 07:37:52,865] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:37:52,869] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.49189648627860083
[2019-03-23 07:38:09,045] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:38:09,048] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.85005662, 79.91514625, 1.0, 2.0, 0.2225587233711257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 241633.5604473884, 241633.560447388, 83426.90101991313]
[2019-03-23 07:38:09,050] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:38:09,054] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.5374951677336789
[2019-03-23 07:38:19,963] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:38:19,966] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.67660135666667, 89.24243258666667, 1.0, 2.0, 0.3649149007421129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 406098.4463257473, 406098.4463257469, 123676.6729843886]
[2019-03-23 07:38:19,967] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:38:19,972] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.8952131174575326
[2019-03-23 07:38:42,021] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:38:42,022] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.56666666666667, 83.33333333333334, 1.0, 2.0, 0.3750205442727392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 419148.0201533997, 419148.0201533993, 125276.2996589608]
[2019-03-23 07:38:42,023] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:38:42,027] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.9289405045940731
[2019-03-23 07:38:57,681] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:38:57,681] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.5, 34.0, 1.0, 2.0, 0.3481739116221657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 378057.7424273549, 378057.7424273552, 103124.8748312562]
[2019-03-23 07:38:57,683] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:38:57,687] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.742653597227658
[2019-03-23 07:39:12,758] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:39:12,759] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.48259830833333, 79.51197458833335, 1.0, 2.0, 0.570372793507331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647593.6448959432, 647593.6448959429, 149325.7069510889]
[2019-03-23 07:39:12,761] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:39:12,766] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.6321632691378559
[2019-03-23 07:39:15,286] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:39:15,288] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.67154911, 50.93296419333333, 1.0, 2.0, 0.3501541172937682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390765.7518688781, 390765.7518688778, 122969.0026006906]
[2019-03-23 07:39:15,289] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:39:15,292] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.12255687243593061
[2019-03-23 07:39:20,772] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9374488]
[2019-03-23 07:39:20,773] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.44636637, 68.522998695, 1.0, 2.0, 0.7977687209443326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 907466.516438143, 907466.516438143, 190167.6499946808]
[2019-03-23 07:39:20,774] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:39:20,777] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.2504216e-25 1.0000000e+00 5.3992786e-35 1.0401553e-33 6.7268094e-38], sampled 0.720432356132881
[2019-03-23 07:39:23,754] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:39:23,998] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:39:24,107] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:39:24,124] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:39:24,303] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:39:25,318] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 175000, evaluation results [175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:39:26,075] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7381513e-26 1.0000000e+00 3.3728842e-35 1.4014510e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 07:39:26,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3149
[2019-03-23 07:39:26,094] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.9, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 208876.93978976, 208876.9397897603, 69499.98084102965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6577200.0000, 
sim time next is 6577800.0000, 
raw observation next is [12.68333333333333, 90.33333333333334, 1.0, 2.0, 0.2011937596011935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 218442.6099712379, 218442.6099712376, 70770.14969325058], 
processed observation next is [1.0, 0.13043478260869565, 0.21287878787878772, 0.9033333333333334, 1.0, 1.0, 0.0014921995014918754, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08090467035971774, 0.08090467035971763, 0.1726101212030502], 
reward next is 0.8274, 
noisyNet noise sample is [array([0.30663517], dtype=float32), 1.9661096]. 
=============================================
[2019-03-23 07:39:26,355] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175514: loss 0.0101
[2019-03-23 07:39:26,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175515: learning rate 0.0010
[2019-03-23 07:39:26,480] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175577: loss 0.0268
[2019-03-23 07:39:26,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175577: learning rate 0.0010
[2019-03-23 07:39:26,887] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175776: loss 0.1973
[2019-03-23 07:39:26,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175777: learning rate 0.0010
[2019-03-23 07:39:26,910] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175788: loss 0.2070
[2019-03-23 07:39:26,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175788: learning rate 0.0010
[2019-03-23 07:39:27,135] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175878: loss 0.3886
[2019-03-23 07:39:27,137] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175878: learning rate 0.0010
[2019-03-23 07:39:27,263] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175934: loss 0.4172
[2019-03-23 07:39:27,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175934: learning rate 0.0010
[2019-03-23 07:39:27,321] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175960: loss 0.3983
[2019-03-23 07:39:27,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175960: learning rate 0.0010
[2019-03-23 07:39:27,365] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175982: loss 0.4266
[2019-03-23 07:39:27,366] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175982: learning rate 0.0010
[2019-03-23 07:39:27,418] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176001: loss 0.3516
[2019-03-23 07:39:27,427] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176005: learning rate 0.0010
[2019-03-23 07:39:27,534] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176056: loss 0.3776
[2019-03-23 07:39:27,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176056: learning rate 0.0010
[2019-03-23 07:39:27,610] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176088: loss 0.3005
[2019-03-23 07:39:27,611] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176088: learning rate 0.0010
[2019-03-23 07:39:27,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176189: loss 0.1910
[2019-03-23 07:39:27,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176189: learning rate 0.0010
[2019-03-23 07:39:27,876] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176222: loss 0.1457
[2019-03-23 07:39:27,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176222: learning rate 0.0010
[2019-03-23 07:39:27,892] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176231: loss 0.1200
[2019-03-23 07:39:27,894] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176232: learning rate 0.0010
[2019-03-23 07:39:27,906] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176236: loss 0.1557
[2019-03-23 07:39:27,910] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176237: learning rate 0.0010
[2019-03-23 07:39:28,135] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176363: loss 0.0756
[2019-03-23 07:39:28,137] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176363: learning rate 0.0010
[2019-03-23 07:39:36,280] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0620778e-21 1.0000000e+00 6.9433056e-31 6.0849127e-31 1.0982709e-33], sum to 1.0000
[2019-03-23 07:39:36,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-23 07:39:36,294] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 72.66666666666667, 1.0, 2.0, 0.7284323009419592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830019.3567735439, 830019.3567735439, 167814.8154139588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6783600.0000, 
sim time next is 6784200.0000, 
raw observation next is [23.55, 71.0, 1.0, 2.0, 0.6077804945874214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 692370.3662848434, 692370.3662848434, 151458.3220791582], 
processed observation next is [1.0, 0.5217391304347826, 0.7068181818181819, 0.71, 1.0, 1.0, 0.5097256182342768, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25643346899438646, 0.25643346899438646, 0.36941054165648346], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.7182035], dtype=float32), -0.27480948]. 
=============================================
[2019-03-23 07:39:41,825] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183629: loss 0.0563
[2019-03-23 07:39:41,826] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183629: learning rate 0.0010
[2019-03-23 07:39:41,921] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183680: loss 0.0008
[2019-03-23 07:39:41,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183680: learning rate 0.0010
[2019-03-23 07:39:42,131] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183789: loss 0.0450
[2019-03-23 07:39:42,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183789: learning rate 0.0010
[2019-03-23 07:39:42,147] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183794: loss 0.0189
[2019-03-23 07:39:42,149] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183794: learning rate 0.0010
[2019-03-23 07:39:42,222] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183831: loss 0.0063
[2019-03-23 07:39:42,224] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183832: learning rate 0.0010
[2019-03-23 07:39:42,299] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183875: loss 0.0127
[2019-03-23 07:39:42,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183875: learning rate 0.0010
[2019-03-23 07:39:42,384] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183915: loss 0.0405
[2019-03-23 07:39:42,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183915: learning rate 0.0010
[2019-03-23 07:39:42,470] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183966: loss 0.0250
[2019-03-23 07:39:42,473] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183967: loss 0.0120
[2019-03-23 07:39:42,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183968: learning rate 0.0010
[2019-03-23 07:39:42,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183967: learning rate 0.0010
[2019-03-23 07:39:42,562] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184007: loss 0.0001
[2019-03-23 07:39:42,564] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184008: learning rate 0.0010
[2019-03-23 07:39:42,651] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184055: loss 0.0544
[2019-03-23 07:39:42,653] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184055: learning rate 0.0010
[2019-03-23 07:39:42,743] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184106: loss 0.0327
[2019-03-23 07:39:42,745] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184106: learning rate 0.0010
[2019-03-23 07:39:42,856] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184163: loss 0.0006
[2019-03-23 07:39:42,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184164: learning rate 0.0010
[2019-03-23 07:39:43,091] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184292: loss 0.0047
[2019-03-23 07:39:43,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184292: learning rate 0.0010
[2019-03-23 07:39:43,177] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184333: loss 0.0205
[2019-03-23 07:39:43,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184333: learning rate 0.0010
[2019-03-23 07:39:43,299] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184394: loss 0.0299
[2019-03-23 07:39:43,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184395: learning rate 0.0010
[2019-03-23 07:39:44,297] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5712028e-23 1.0000000e+00 9.1873550e-35 3.0002874e-32 4.6796737e-37], sum to 1.0000
[2019-03-23 07:39:44,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5841
[2019-03-23 07:39:44,310] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 81.0, 1.0, 2.0, 0.3720055504892781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418517.8648331414, 418517.8648331417, 122015.5946274798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6940800.0000, 
sim time next is 6941400.0000, 
raw observation next is [20.86666666666667, 79.66666666666667, 1.0, 2.0, 0.3771418263761422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425065.8046804197, 425065.80468042, 122865.0052621803], 
processed observation next is [0.0, 0.34782608695652173, 0.5848484848484851, 0.7966666666666667, 1.0, 1.0, 0.22142728297017772, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15743177951126655, 0.1574317795112667, 0.2996707445419032], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.54427993], dtype=float32), 1.5939753]. 
=============================================
[2019-03-23 07:39:52,277] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9999302e-26 1.0000000e+00 3.7186155e-36 4.6396689e-34 6.6999706e-38], sum to 1.0000
[2019-03-23 07:39:52,282] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2563
[2019-03-23 07:39:52,286] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3487361066442998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388234.856754711, 388234.856754711, 118122.4499008419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7095600.0000, 
sim time next is 7096200.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3521097095291766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391998.0071792626, 391998.0071792629, 118393.0162434722], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19013713691147072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1451844471034306, 0.1451844471034307, 0.2887634542523712], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.11136057], dtype=float32), -0.37934896]. 
=============================================
[2019-03-23 07:39:52,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4541206e-22 1.0000000e+00 2.1251793e-31 8.6201728e-32 3.4157682e-35], sum to 1.0000
[2019-03-23 07:39:52,711] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7624
[2019-03-23 07:39:52,717] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3934509836904135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438123.059599972, 438123.0595999717, 121826.5730418882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7103400.0000, 
sim time next is 7104000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3625652568207626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403721.6154413311, 403721.6154413308, 119266.0718398218], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.97, 1.0, 1.0, 0.20320657102595327, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14952652423753005, 0.14952652423752993, 0.2908928581459068], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.4652221], dtype=float32), 0.58592296]. 
=============================================
[2019-03-23 07:39:52,728] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.15523]
 [69.15523]
 [69.15523]
 [69.15523]
 [69.15523]], R is [[69.17279053]
 [69.18392944]
 [69.2041626 ]
 [69.22439575]
 [69.24438477]].
[2019-03-23 07:39:56,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4993944e-27 1.0000000e+00 3.9912842e-38 3.2011638e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 07:39:56,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9182
[2019-03-23 07:39:56,311] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.56666666666667, 85.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216908.490720934, 216908.490720934, 71435.10727947744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7180800.0000, 
sim time next is 7181400.0000, 
raw observation next is [13.43333333333333, 86.16666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214178.7397427159, 214178.7397427162, 70865.12861324496], 
processed observation next is [1.0, 0.08695652173913043, 0.2469696969696968, 0.8616666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07932545916396885, 0.07932545916396896, 0.17284177710547552], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5463432], dtype=float32), -0.25489792]. 
=============================================
[2019-03-23 07:39:56,976] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191624: loss 0.0696
[2019-03-23 07:39:56,983] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191625: learning rate 0.0010
[2019-03-23 07:39:57,053] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191668: loss 0.0825
[2019-03-23 07:39:57,055] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191668: learning rate 0.0010
[2019-03-23 07:39:57,209] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191748: loss 0.0796
[2019-03-23 07:39:57,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191748: learning rate 0.0010
[2019-03-23 07:39:57,224] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191755: loss 0.0842
[2019-03-23 07:39:57,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191755: learning rate 0.0010
[2019-03-23 07:39:57,269] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191773: loss 0.1130
[2019-03-23 07:39:57,271] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191773: learning rate 0.0010
[2019-03-23 07:39:57,502] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191904: loss 0.2264
[2019-03-23 07:39:57,505] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191904: learning rate 0.0010
[2019-03-23 07:39:57,537] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191921: loss 0.2570
[2019-03-23 07:39:57,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191922: learning rate 0.0010
[2019-03-23 07:39:57,547] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191922: loss 0.3317
[2019-03-23 07:39:57,548] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191922: loss 0.2580
[2019-03-23 07:39:57,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191923: learning rate 0.0010
[2019-03-23 07:39:57,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191923: learning rate 0.0010
[2019-03-23 07:39:57,948] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192134: loss 0.3408
[2019-03-23 07:39:57,949] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192134: learning rate 0.0010
[2019-03-23 07:39:57,991] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192155: loss 0.3307
[2019-03-23 07:39:57,994] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192156: learning rate 0.0010
[2019-03-23 07:39:57,996] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192156: loss 0.2682
[2019-03-23 07:39:57,999] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192158: learning rate 0.0010
[2019-03-23 07:39:58,023] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192170: loss 0.2558
[2019-03-23 07:39:58,025] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192170: learning rate 0.0010
[2019-03-23 07:39:58,049] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192182: loss 0.2274
[2019-03-23 07:39:58,051] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192184: learning rate 0.0010
[2019-03-23 07:39:58,240] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192293: loss 0.1486
[2019-03-23 07:39:58,245] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192293: learning rate 0.0010
[2019-03-23 07:39:58,519] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192440: loss 0.2794
[2019-03-23 07:39:58,520] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192440: learning rate 0.0010
[2019-03-23 07:40:09,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6778148e-19 1.0000000e+00 4.9271204e-27 2.9165111e-24 7.3790922e-28], sum to 1.0000
[2019-03-23 07:40:09,030] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3366
[2019-03-23 07:40:09,036] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3738268965374303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 418005.106400605, 418005.106400605, 120940.5628464397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7426200.0000, 
sim time next is 7426800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3714894370775202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415383.3110193208, 415383.3110193208, 120741.705924234], 
processed observation next is [1.0, 1.0, 0.49090909090909096, 0.9, 1.0, 1.0, 0.21436179634690022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1538456707478966, 0.1538456707478966, 0.29449196566886343], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.39910817], dtype=float32), 0.4741349]. 
=============================================
[2019-03-23 07:40:09,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1405076e-26 1.0000000e+00 1.6650627e-34 8.1364413e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 07:40:09,830] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2299
[2019-03-23 07:40:09,835] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3410077781717208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375983.4257648592, 375983.4257648595, 116044.4726157587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7441800.0000, 
sim time next is 7442400.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3430951339649508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378292.7015581892, 378292.7015581892, 116204.8883587778], 
processed observation next is [0.0, 0.13043478260869565, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17886891745618846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14010840798451452, 0.14010840798451452, 0.28342655697262875], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.33485147], dtype=float32), -1.105604]. 
=============================================
[2019-03-23 07:40:12,241] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199681: loss 0.0684
[2019-03-23 07:40:12,245] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199681: learning rate 0.0010
[2019-03-23 07:40:12,261] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199690: loss 0.0811
[2019-03-23 07:40:12,266] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199690: learning rate 0.0010
[2019-03-23 07:40:12,286] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199702: loss 0.0787
[2019-03-23 07:40:12,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199702: learning rate 0.0010
[2019-03-23 07:40:12,311] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199715: loss 0.0669
[2019-03-23 07:40:12,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199716: learning rate 0.0010
[2019-03-23 07:40:12,372] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199750: loss 0.0267
[2019-03-23 07:40:12,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199750: learning rate 0.0010
[2019-03-23 07:40:12,631] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199885: loss 0.0026
[2019-03-23 07:40:12,632] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199885: learning rate 0.0010
[2019-03-23 07:40:12,715] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199925: loss 0.0047
[2019-03-23 07:40:12,720] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199925: learning rate 0.0010
[2019-03-23 07:40:12,735] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199938: loss 0.0104
[2019-03-23 07:40:12,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199938: learning rate 0.0010
[2019-03-23 07:40:12,746] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199944: loss 0.0066
[2019-03-23 07:40:12,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199944: learning rate 0.0010
[2019-03-23 07:40:12,859] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 07:40:12,861] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:40:12,862] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:40:12,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:12,863] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:12,863] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:40:12,864] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:40:12,864] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:12,865] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:40:12,865] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:12,867] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:40:12,887] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 07:40:12,887] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 07:40:12,910] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 07:40:12,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 07:40:12,978] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 07:40:32,181] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:40:32,182] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.96666666666667, 67.33333333333334, 1.0, 2.0, 0.939315175885956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1070967.475668223, 1070967.475668222, 213037.5997583515]
[2019-03-23 07:40:32,183] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:40:32,187] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.7529364529579677
[2019-03-23 07:40:42,465] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:40:42,466] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.83333333333333, 51.5, 1.0, 2.0, 0.4163224914187657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473570.1898276295, 473570.1898276295, 129278.5511920785]
[2019-03-23 07:40:42,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:40:42,474] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.7842211210838711
[2019-03-23 07:40:44,810] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:40:44,812] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.05824533333333, 61.82922279333334, 1.0, 2.0, 0.2296536438806199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 249338.1628928707, 249338.1628928703, 78259.96592036344]
[2019-03-23 07:40:44,813] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:40:44,818] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.33627649705232754
[2019-03-23 07:40:50,056] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:40:50,057] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.75061555833333, 74.81128256166667, 1.0, 2.0, 0.3888114008390635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 441480.8136835911, 441480.8136835908, 130302.6504863121]
[2019-03-23 07:40:50,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:40:50,061] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.22789119440831618
[2019-03-23 07:41:01,934] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:41:01,935] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.16197363666667, 98.01670087833334, 1.0, 2.0, 0.6258147417770942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769689081, 710065.0470168642, 710065.0470168638, 155700.6824065736]
[2019-03-23 07:41:01,937] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:41:01,940] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.4927186652221812
[2019-03-23 07:41:04,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:41:04,113] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.88460627333334, 87.85309045666668, 1.0, 2.0, 0.5669835336777347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 642985.8539451684, 642985.8539451684, 157046.3866307694]
[2019-03-23 07:41:04,114] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:41:04,117] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.5923657525794236
[2019-03-23 07:41:47,451] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:41:47,454] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.9, 48.66666666666666, 1.0, 2.0, 0.3826966767024938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 431094.6289573672, 431094.6289573667, 127551.7741848242]
[2019-03-23 07:41:47,455] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:41:47,458] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.200661897080065
[2019-03-23 07:41:53,821] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.98600847]
[2019-03-23 07:41:53,822] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.85131788, 92.68524229666667, 1.0, 2.0, 0.4750915810342138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 541696.9076019853, 541696.9076019849, 141141.5027261421]
[2019-03-23 07:41:53,825] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:41:53,831] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.8146756e-23 1.0000000e+00 5.6635836e-33 9.4581668e-32 1.0728857e-35], sampled 0.49902676297581516
[2019-03-23 07:41:58,652] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:42:00,044] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:42:00,322] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:42:00,399] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:42:00,457] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:42:01,471] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 200000, evaluation results [200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:42:01,769] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200133: loss 0.0107
[2019-03-23 07:42:01,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200134: learning rate 0.0010
[2019-03-23 07:42:01,781] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200135: loss 0.0187
[2019-03-23 07:42:01,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200136: learning rate 0.0010
[2019-03-23 07:42:01,825] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200155: loss 0.0047
[2019-03-23 07:42:01,830] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200155: learning rate 0.0010
[2019-03-23 07:42:01,971] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200220: loss 0.0053
[2019-03-23 07:42:01,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200220: learning rate 0.0010
[2019-03-23 07:42:01,999] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200231: loss 0.0022
[2019-03-23 07:42:02,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200231: learning rate 0.0010
[2019-03-23 07:42:02,279] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200353: loss 0.0058
[2019-03-23 07:42:02,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200353: learning rate 0.0010
[2019-03-23 07:42:02,364] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200393: loss 0.0012
[2019-03-23 07:42:02,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200393: learning rate 0.0010
[2019-03-23 07:42:02,651] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1257846e-24 1.0000000e+00 2.9827364e-32 6.2666789e-31 2.1123976e-34], sum to 1.0000
[2019-03-23 07:42:02,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2633
[2019-03-23 07:42:02,660] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 94.16666666666666, 1.0, 2.0, 0.457272754421011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521494.2436956788, 521494.2436956788, 135051.8565328335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7531800.0000, 
sim time next is 7532400.0000, 
raw observation next is [20.73333333333333, 95.33333333333334, 1.0, 2.0, 0.455351687237387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519253.2373434082, 519253.2373434079, 134751.7706242601], 
processed observation next is [0.0, 0.17391304347826086, 0.5787878787878786, 0.9533333333333335, 1.0, 1.0, 0.3191896090467337, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19231601383089195, 0.1923160138308918, 0.3286628551811222], 
reward next is 0.6713, 
noisyNet noise sample is [array([0.44485378], dtype=float32), 1.3859365]. 
=============================================
[2019-03-23 07:42:03,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3711927e-24 1.0000000e+00 5.4167960e-34 1.1487536e-34 3.1031447e-37], sum to 1.0000
[2019-03-23 07:42:03,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0515
[2019-03-23 07:42:03,013] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 80.0, 1.0, 2.0, 0.4568326103833968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521042.2723172908, 521042.2723172908, 135111.5536505157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7518000.0000, 
sim time next is 7518600.0000, 
raw observation next is [22.8, 80.5, 1.0, 2.0, 0.4588383185998316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 523365.3408684222, 523365.3408684219, 135404.7971108455], 
processed observation next is [0.0, 0.0, 0.6727272727272727, 0.805, 1.0, 1.0, 0.32354789824978947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19383901513645266, 0.19383901513645255, 0.3302556027093793], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.14826988], dtype=float32), 0.19383304]. 
=============================================
[2019-03-23 07:42:09,736] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2095943e-15 1.0000000e+00 3.4960908e-20 2.9435864e-21 9.5691895e-23], sum to 1.0000
[2019-03-23 07:42:09,743] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8260
[2019-03-23 07:42:09,754] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1278359.803562196 W.
[2019-03-23 07:42:09,759] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.41666666666667, 66.16666666666667, 1.0, 2.0, 0.6422774434950771, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9768994228956925, 6.9112, 6.9112, 77.32846344354104, 1278359.803562196, 1278359.803562196, 283287.0159079249], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7645800.0000, 
sim time next is 7646400.0000, 
raw observation next is [26.6, 65.0, 1.0, 2.0, 0.6592163431197154, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9760210854632122, 6.911200000000001, 6.9112, 77.32846344354104, 1298268.203942676, 1298268.203942676, 284884.7362225447], 
processed observation next is [1.0, 0.5217391304347826, 0.8454545454545456, 0.65, 1.0, 1.0, 0.5740204288996442, 0.0, 1.0, -0.25, 1.0, 1.0, 0.965744407804589, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48084007553432445, 0.48084007553432445, 0.694840820054987], 
reward next is 0.3052, 
noisyNet noise sample is [array([-0.06345867], dtype=float32), -1.7275584]. 
=============================================
[2019-03-23 07:42:10,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4097852e-16 1.0000000e+00 8.4912634e-23 9.6444665e-22 4.7980145e-24], sum to 1.0000
[2019-03-23 07:42:10,198] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7440
[2019-03-23 07:42:10,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1292670.558260281 W.
[2019-03-23 07:42:10,213] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.3812778111014167, 1.0, 2.0, 0.3812778111014167, 1.0, 2.0, 0.7715215194190892, 6.911199999999999, 6.9112, 77.3421103, 1292670.558260281, 1292670.558260281, 295931.1972600654], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7653600.0000, 
sim time next is 7654200.0000, 
raw observation next is [28.71666666666667, 53.33333333333334, 1.0, 2.0, 0.3236306156317447, 1.0, 2.0, 0.3236306156317447, 1.0, 2.0, 0.6551332864434959, 6.911199999999999, 6.9112, 77.3421103, 1098530.958197399, 1098530.9581974, 270993.1018753186], 
processed observation next is [1.0, 0.6086956521739131, 0.9416666666666668, 0.5333333333333334, 1.0, 1.0, 0.1545382695396809, 1.0, 1.0, 0.1545382695396809, 1.0, 1.0, 0.5073332663478514, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.40686331785088853, 0.40686331785088886, 0.6609587850617528], 
reward next is 0.3390, 
noisyNet noise sample is [array([-0.05277494], dtype=float32), -2.3708208]. 
=============================================
[2019-03-23 07:42:10,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4097852e-16 1.0000000e+00 8.4912634e-23 9.6444665e-22 4.7980145e-24], sum to 1.0000
[2019-03-23 07:42:10,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3515
[2019-03-23 07:42:10,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1166128.853495666 W.
[2019-03-23 07:42:10,281] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.63333333333334, 53.66666666666667, 1.0, 2.0, 0.5430862313866038, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9681610702408074, 6.924402524699447, 6.9112, 77.32842944653878, 1166128.853495666, 1161840.945396769, 267074.9980307711], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7654800.0000, 
sim time next is 7655400.0000, 
raw observation next is [28.55, 54.0, 1.0, 2.0, 0.5469971551139315, 1.0, 1.0, 0.5469971551139315, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32845551003362, 1241064.541534706, 1241064.541534706, 244445.4587843296], 
processed observation next is [1.0, 0.6086956521739131, 0.9340909090909091, 0.54, 1.0, 1.0, 0.4337464438924144, 1.0, 0.5, 0.4337464438924144, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084287607584413, 0.45965353390174296, 0.45965353390174296, 0.5962084360593405], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05277494], dtype=float32), -2.3708208]. 
=============================================
[2019-03-23 07:42:12,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7723849e-26 1.0000000e+00 7.7429908e-36 8.8934964e-33 4.7565395e-38], sum to 1.0000
[2019-03-23 07:42:12,136] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-23 07:42:12,142] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 95.0, 1.0, 2.0, 0.4264849583175457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483052.1209969086, 483052.1209969086, 128697.8723592467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7698600.0000, 
sim time next is 7699200.0000, 
raw observation next is [19.2, 95.66666666666666, 1.0, 2.0, 0.4154318358419059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 470026.7970273319, 470026.7970273322, 127323.9551676681], 
processed observation next is [1.0, 0.08695652173913043, 0.509090909090909, 0.9566666666666666, 1.0, 1.0, 0.26928979480238235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1740839988990118, 0.1740839988990119, 0.31054623211626364], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.41131216], dtype=float32), -1.0318356]. 
=============================================
[2019-03-23 07:42:12,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9199702e-22 1.0000000e+00 1.5413484e-33 1.2779520e-29 3.4642574e-34], sum to 1.0000
[2019-03-23 07:42:12,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9479
[2019-03-23 07:42:12,869] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 64.16666666666666, 1.0, 2.0, 0.5693184755325924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619152.7825665998, 619152.7825665998, 133606.6788435992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7725000.0000, 
sim time next is 7725600.0000, 
raw observation next is [20.5, 63.0, 1.0, 2.0, 0.5725455457118394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 622777.9667844238, 622777.9667844238, 133958.6089821036], 
processed observation next is [1.0, 0.43478260869565216, 0.5681818181818182, 0.63, 1.0, 1.0, 0.46568193213979914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23065850621645326, 0.23065850621645326, 0.32672831459049656], 
reward next is 0.6733, 
noisyNet noise sample is [array([-1.0586096], dtype=float32), 0.78190744]. 
=============================================
[2019-03-23 07:42:13,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7987382e-23 1.0000000e+00 3.1418011e-34 2.3343912e-31 7.1262928e-37], sum to 1.0000
[2019-03-23 07:42:13,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7477
[2019-03-23 07:42:13,226] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.11666666666667, 72.33333333333333, 1.0, 2.0, 0.5643087907028782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613429.1033689589, 613429.1033689589, 133033.6351499319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7721400.0000, 
sim time next is 7722000.0000, 
raw observation next is [19.4, 70.0, 1.0, 2.0, 0.5941304244439362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645676.1668786333, 645676.1668786333, 135933.5250445987], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.7, 1.0, 1.0, 0.49266303055492017, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23913932106616048, 0.23913932106616048, 0.3315451830356066], 
reward next is 0.6685, 
noisyNet noise sample is [array([2.6000984], dtype=float32), 1.084528]. 
=============================================
[2019-03-23 07:42:13,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.426506]
 [72.426506]
 [72.426506]
 [72.426506]
 [72.426506]], R is [[72.37070465]
 [72.32252502]
 [72.28032684]
 [72.25210571]
 [72.23597717]].
[2019-03-23 07:42:16,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207701: loss 0.0119
[2019-03-23 07:42:16,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207703: learning rate 0.0010
[2019-03-23 07:42:16,173] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207715: loss 0.0237
[2019-03-23 07:42:16,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207715: learning rate 0.0010
[2019-03-23 07:42:16,186] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207717: loss 0.0070
[2019-03-23 07:42:16,188] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207717: learning rate 0.0010
[2019-03-23 07:42:16,288] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207772: loss 0.0004
[2019-03-23 07:42:16,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207773: learning rate 0.0010
[2019-03-23 07:42:16,331] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207798: loss 0.0002
[2019-03-23 07:42:16,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207798: learning rate 0.0010
[2019-03-23 07:42:16,384] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207820: loss 0.0016
[2019-03-23 07:42:16,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207820: learning rate 0.0010
[2019-03-23 07:42:16,473] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207872: loss 0.0001
[2019-03-23 07:42:16,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207873: learning rate 0.0010
[2019-03-23 07:42:16,522] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207894: loss 0.0044
[2019-03-23 07:42:16,523] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207894: learning rate 0.0010
[2019-03-23 07:42:16,617] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207949: loss 0.0636
[2019-03-23 07:42:16,620] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207950: learning rate 0.0010
[2019-03-23 07:42:16,828] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208057: loss 0.0189
[2019-03-23 07:42:16,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208058: learning rate 0.0010
[2019-03-23 07:42:16,936] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208118: loss 0.0412
[2019-03-23 07:42:16,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208118: learning rate 0.0010
[2019-03-23 07:42:17,111] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208207: loss 0.1049
[2019-03-23 07:42:17,113] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208209: learning rate 0.0010
[2019-03-23 07:42:17,138] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208224: loss 0.1823
[2019-03-23 07:42:17,140] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208224: learning rate 0.0010
[2019-03-23 07:42:17,161] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208234: loss 0.1974
[2019-03-23 07:42:17,163] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208234: learning rate 0.0010
[2019-03-23 07:42:17,273] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208293: loss 0.2589
[2019-03-23 07:42:17,275] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208294: learning rate 0.0010
[2019-03-23 07:42:17,627] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208480: loss 0.2755
[2019-03-23 07:42:17,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208480: learning rate 0.0010
[2019-03-23 07:42:24,554] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 07:42:24,727] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,728] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 07:42:24,751] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,752] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,752] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,752] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 07:42:24,776] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,777] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 07:42:24,802] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 07:42:24,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,869] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 07:42:24,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 07:42:24,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,950] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 07:42:24,982] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:24,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:24,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 07:42:25,070] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,070] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 07:42:25,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,108] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,109] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,109] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,110] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 07:42:25,161] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 07:42:25,221] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,222] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,223] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 07:42:25,293] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,294] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,295] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 07:42:25,365] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,365] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 07:42:25,367] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 07:42:25,497] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:25,498] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 07:42:36,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5355170e-23 1.0000000e+00 1.6964823e-30 6.5893558e-31 1.7561820e-35], sum to 1.0000
[2019-03-23 07:42:36,557] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3001
[2019-03-23 07:42:36,563] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.2499758384445095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271421.6780876688, 271421.6780876685, 86776.44864258174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 203400.0000, 
sim time next is 204000.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.2513264756367714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272888.6000950935, 272888.6000950933, 86929.7958615727], 
processed observation next is [0.0, 0.34782608695652173, 0.4090909090909091, 0.77, 1.0, 1.0, 0.06415809454596424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10106985188707165, 0.1010698518870716, 0.21202389234529925], 
reward next is 0.7880, 
noisyNet noise sample is [array([-0.21980356], dtype=float32), 0.15854593]. 
=============================================
[2019-03-23 07:42:36,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.199635]
 [62.199635]
 [62.199635]
 [62.199635]
 [62.199635]], R is [[62.36561203]
 [62.53030396]
 [62.69372559]
 [62.85583115]
 [63.01691818]].
[2019-03-23 07:42:40,657] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0331388e-21 1.0000000e+00 1.1123049e-29 3.0307047e-30 1.4731120e-33], sum to 1.0000
[2019-03-23 07:42:40,663] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1005
[2019-03-23 07:42:40,667] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2189057539484602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237677.7969037815, 237677.7969037818, 79930.363493674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 284400.0000, 
sim time next is 285000.0000, 
raw observation next is [14.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2196157404409852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238448.8565315725, 238448.8565315728, 80414.21268434114], 
processed observation next is [0.0, 0.30434782608695654, 0.28030303030303044, 0.9900000000000001, 1.0, 1.0, 0.024519675551231482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08831439130798982, 0.08831439130798992, 0.19613222605936864], 
reward next is 0.8039, 
noisyNet noise sample is [array([1.0665303], dtype=float32), 1.2884923]. 
=============================================
[2019-03-23 07:42:40,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.80908]
 [63.80908]
 [63.80908]
 [63.80908]
 [63.80908]], R is [[63.97485352]
 [64.14015198]
 [64.30377197]
 [64.46582031]
 [64.6264267 ]].
[2019-03-23 07:42:42,266] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8418287e-24 1.0000000e+00 2.0545548e-36 1.1828599e-36 1.4060412e-38], sum to 1.0000
[2019-03-23 07:42:42,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1000
[2019-03-23 07:42:42,281] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 43.0, 1.0, 2.0, 0.260004531536116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 282313.9097219817, 282313.9097219814, 83053.45254428119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 310800.0000, 
sim time next is 311400.0000, 
raw observation next is [21.5, 43.0, 1.0, 2.0, 0.2608244691046366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 283204.4602679595, 283204.4602679592, 83828.97087218608], 
processed observation next is [0.0, 0.6086956521739131, 0.6136363636363636, 0.43, 1.0, 1.0, 0.07603058638079571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.104890540839985, 0.10489054083998489, 0.20446090456630753], 
reward next is 0.7955, 
noisyNet noise sample is [array([-0.76146036], dtype=float32), -0.1218989]. 
=============================================
[2019-03-23 07:42:44,167] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7731452e-21 1.0000000e+00 3.3470260e-31 5.3124013e-30 1.2125483e-34], sum to 1.0000
[2019-03-23 07:42:44,173] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2399
[2019-03-23 07:42:44,180] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3950916741863985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429056.7532646986, 429056.7532646989, 86491.91495580578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 357000.0000, 
sim time next is 357600.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.3914037029598057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 425049.9853888366, 425049.9853888364, 86124.05385047401], 
processed observation next is [1.0, 0.13043478260869565, 0.18181818181818182, 0.76, 1.0, 1.0, 0.2392546286997571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15742592051438392, 0.15742592051438387, 0.2100586679279854], 
reward next is 0.7899, 
noisyNet noise sample is [array([-0.8951362], dtype=float32), -0.13366257]. 
=============================================
[2019-03-23 07:42:49,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4229550e-24 1.0000000e+00 3.3162665e-33 2.4482401e-32 6.9502043e-36], sum to 1.0000
[2019-03-23 07:42:49,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8353
[2019-03-23 07:42:49,352] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5601733521726513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 608442.2999250578, 608442.2999250581, 112547.1535646504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 453600.0000, 
sim time next is 454200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5083732393139604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552146.7237809993, 552146.7237809993, 106805.9773170322], 
processed observation next is [1.0, 0.2608695652173913, 0.22727272727272727, 1.0, 1.0, 1.0, 0.38546654914245043, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2044987865855553, 0.2044987865855553, 0.26050238370007855], 
reward next is 0.7395, 
noisyNet noise sample is [array([0.03751842], dtype=float32), 1.3173912]. 
=============================================
[2019-03-23 07:42:51,139] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 07:42:51,141] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:42:51,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:51,142] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:42:51,142] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:51,143] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:42:51,144] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:51,145] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:42:51,148] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:51,148] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:42:51,150] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:42:51,164] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 07:42:51,165] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 07:42:51,187] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 07:42:51,211] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 07:42:51,214] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 07:43:19,534] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0070091]
[2019-03-23 07:43:19,539] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.33333333333333, 44.5, 1.0, 2.0, 0.3252276175452764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 355518.6415746391, 355518.6415746387, 118050.2267770165]
[2019-03-23 07:43:19,541] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:43:19,542] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.724074e-26 1.000000e+00 1.387363e-36 2.840795e-35 0.000000e+00], sampled 0.8255861213169927
[2019-03-23 07:43:32,727] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0070091]
[2019-03-23 07:43:32,728] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 88.0, 1.0, 2.0, 0.3498075616041232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385426.3384592746, 385426.3384592746, 116614.0113400956]
[2019-03-23 07:43:32,731] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:43:32,735] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.724074e-26 1.000000e+00 1.387363e-36 2.840795e-35 0.000000e+00], sampled 0.40558020157429053
[2019-03-23 07:43:48,201] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0070091]
[2019-03-23 07:43:48,203] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.3, 69.0, 1.0, 2.0, 0.4871326867377794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 555725.9125747338, 555725.9125747338, 144338.187007416]
[2019-03-23 07:43:48,205] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:43:48,209] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.724074e-26 1.000000e+00 1.387363e-36 2.840795e-35 0.000000e+00], sampled 0.7167566300303359
[2019-03-23 07:43:49,984] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0070091]
[2019-03-23 07:43:49,986] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [30.51666666666667, 48.0, 1.0, 2.0, 0.7806402284599181, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9689186787663229, 6.924293848247109, 6.9112, 95.55332712874896, 1434165.840474572, 1428910.965261865, 308544.4533635656]
[2019-03-23 07:43:49,987] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:43:49,991] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.724074e-26 1.000000e+00 1.387363e-36 2.840795e-35 0.000000e+00], sampled 0.9992550609717314
[2019-03-23 07:43:49,993] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1434165.840474572 W.
[2019-03-23 07:43:52,230] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0070091]
[2019-03-23 07:43:52,230] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 78.83333333333333, 1.0, 2.0, 0.4704535848964257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536631.928861673, 536631.928861673, 136685.0097551586]
[2019-03-23 07:43:52,233] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:43:52,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.724074e-26 1.000000e+00 1.387363e-36 2.840795e-35 0.000000e+00], sampled 0.985736654842747
[2019-03-23 07:44:30,735] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 1.0070091]
[2019-03-23 07:44:30,736] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.0972208, 39.14212858, 1.0, 2.0, 0.7625460658921234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 843391.373062623, 843391.373062623, 163742.5077896626]
[2019-03-23 07:44:30,737] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:44:30,740] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.724074e-26 1.000000e+00 1.387363e-36 2.840795e-35 0.000000e+00], sampled 0.1419540933740573
[2019-03-23 07:44:38,958] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:44:39,199] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:44:39,269] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:44:39,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:44:39,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:44:40,394] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 225000, evaluation results [225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:44:45,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.428969e-23 1.000000e+00 6.201560e-33 2.058993e-31 6.205340e-35], sum to 1.0000
[2019-03-23 07:44:45,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3349
[2019-03-23 07:44:45,768] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 82.16666666666667, 1.0, 2.0, 0.3103504643966774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338356.0219154482, 338356.0219154485, 112365.5225816977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 593400.0000, 
sim time next is 594000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3083698778116065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335769.1110614021, 335769.1110614018, 112078.1152460705], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13546234726450812, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12435893002274151, 0.1243589300227414, 0.2733612566977329], 
reward next is 0.7266, 
noisyNet noise sample is [array([1.714568], dtype=float32), -0.0125739835]. 
=============================================
[2019-03-23 07:44:45,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.02818]
 [69.02818]
 [69.02818]
 [69.02818]
 [69.02818]], R is [[69.06453705]
 [69.09983063]
 [69.13404846]
 [69.1671524 ]
 [69.19906616]].
[2019-03-23 07:44:46,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5090491e-23 1.0000000e+00 4.0413303e-34 1.3261081e-32 5.0990744e-37], sum to 1.0000
[2019-03-23 07:44:46,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5145
[2019-03-23 07:44:46,146] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 82.5, 1.0, 2.0, 0.2921716766551349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317252.5105693174, 317252.5105693171, 106335.309973859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606600.0000, 
sim time next is 607200.0000, 
raw observation next is [17.33333333333333, 82.33333333333334, 1.0, 2.0, 0.2860197181972941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310570.3177734928, 310570.3177734931, 102181.2769859523], 
processed observation next is [1.0, 0.0, 0.42424242424242403, 0.8233333333333335, 1.0, 1.0, 0.10752464774661762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11502604361981214, 0.11502604361981227, 0.2492226267950056], 
reward next is 0.7508, 
noisyNet noise sample is [array([0.8908437], dtype=float32), 0.1756462]. 
=============================================
[2019-03-23 07:44:47,454] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1332513e-24 1.0000000e+00 3.3512862e-35 8.0933236e-34 1.4685082e-37], sum to 1.0000
[2019-03-23 07:44:47,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6956
[2019-03-23 07:44:47,467] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666666, 84.83333333333333, 1.0, 2.0, 0.3047875754848544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330956.0548651406, 330956.0548651409, 111514.887350176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 633000.0000, 
sim time next is 633600.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3064544531368768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333302.4123156639, 333302.4123156636, 111813.9846441367], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13306806642109598, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12344533789469032, 0.12344533789469021, 0.2727170357174066], 
reward next is 0.7273, 
noisyNet noise sample is [array([0.30860665], dtype=float32), 1.190225]. 
=============================================
[2019-03-23 07:44:47,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2188131e-25 1.0000000e+00 6.4648236e-36 1.7498653e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 07:44:47,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6788
[2019-03-23 07:44:47,835] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.5, 1.0, 2.0, 0.2888527293400111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313647.4933773316, 313647.4933773314, 110451.8874143725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 631800.0000, 
sim time next is 632400.0000, 
raw observation next is [17.33333333333334, 86.66666666666666, 1.0, 2.0, 0.2967219442719725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 322195.0226338727, 322195.0226338724, 110973.2058469576], 
processed observation next is [1.0, 0.30434782608695654, 0.42424242424242453, 0.8666666666666666, 1.0, 1.0, 0.12090243033996563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11933148986439729, 0.11933148986439719, 0.2706663557242868], 
reward next is 0.7293, 
noisyNet noise sample is [array([-0.45101517], dtype=float32), 1.1011363]. 
=============================================
[2019-03-23 07:44:50,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2208370e-26 1.0000000e+00 3.4668299e-37 3.6035614e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 07:44:50,118] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3062
[2019-03-23 07:44:50,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 87.16666666666667, 1.0, 2.0, 0.3356077588479955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369956.7823694117, 369956.7823694117, 115611.6456857898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 694200.0000, 
sim time next is 694800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3333330801523554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367016.7922733523, 367016.7922733523, 115277.9347688607], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.16666635019044423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13593214528642678, 0.13593214528642678, 0.2811656945581968], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.82816553], dtype=float32), 1.0632946]. 
=============================================
[2019-03-23 07:44:55,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4418443e-23 1.0000000e+00 3.6831278e-34 4.9511469e-33 1.4352565e-37], sum to 1.0000
[2019-03-23 07:44:55,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0975
[2019-03-23 07:44:55,885] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3857514582467097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434671.0595375159, 434671.0595375162, 123566.6399241136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 796800.0000, 
sim time next is 797400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3852390532974909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434092.5405698278, 434092.5405698278, 123520.8714049788], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.23154881662186363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16077501502586214, 0.16077501502586214, 0.3012704180609239], 
reward next is 0.6987, 
noisyNet noise sample is [array([0.6763585], dtype=float32), 0.7600412]. 
=============================================
[2019-03-23 07:44:58,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2323334e-21 1.0000000e+00 9.4475026e-30 8.1665313e-30 3.9352803e-33], sum to 1.0000
[2019-03-23 07:44:58,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4351
[2019-03-23 07:44:58,355] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5295304522705463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602306.627375944, 602306.627375944, 147078.8288643333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 838200.0000, 
sim time next is 838800.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5294879349153251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602258.2946211068, 602258.2946211066, 147073.5223574445], 
processed observation next is [0.0, 0.7391304347826086, 0.9545454545454546, 0.55, 1.0, 1.0, 0.41185991864415633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22305862763744697, 0.22305862763744688, 0.35871590818888904], 
reward next is 0.6413, 
noisyNet noise sample is [array([0.86395526], dtype=float32), -2.0968382]. 
=============================================
[2019-03-23 07:44:59,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.66242605e-20 1.00000000e+00 1.20168865e-29 2.23807248e-29
 8.39940452e-33], sum to 1.0000
[2019-03-23 07:44:59,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2881
[2019-03-23 07:44:59,827] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 92.0, 1.0, 2.0, 0.3971128665826482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 447894.8352455394, 447894.8352455397, 124804.7856132969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 868800.0000, 
sim time next is 869400.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.397842992404662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448927.8060381822, 448927.8060381825, 124986.4763372672], 
processed observation next is [0.0, 0.043478260869565216, 0.5227272727272727, 0.91, 1.0, 1.0, 0.24730374050582746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16626955779191935, 0.16626955779191946, 0.30484506423723706], 
reward next is 0.6952, 
noisyNet noise sample is [array([0.12266721], dtype=float32), 1.1155711]. 
=============================================
[2019-03-23 07:45:01,493] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.24962095e-20 1.00000000e+00 1.05637626e-29 4.18439727e-29
 4.90107029e-32], sum to 1.0000
[2019-03-23 07:45:01,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5567
[2019-03-23 07:45:01,504] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.83333333333333, 1.0, 2.0, 0.4667967128452942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532525.701771444, 532525.701771444, 136468.9970093922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 910200.0000, 
sim time next is 910800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4617241276751574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526581.2758948592, 526581.2758948592, 135543.42672837], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.78, 1.0, 1.0, 0.32715515959394675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1950301021832812, 0.1950301021832812, 0.33059372372773166], 
reward next is 0.6694, 
noisyNet noise sample is [array([0.56059337], dtype=float32), 0.23522478]. 
=============================================
[2019-03-23 07:45:06,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4458183e-22 1.0000000e+00 2.6823617e-31 3.2163345e-32 3.8697921e-34], sum to 1.0000
[2019-03-23 07:45:06,195] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2073
[2019-03-23 07:45:06,198] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 100.0, 1.0, 2.0, 0.521130918203559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566010.9703244931, 566010.9703244931, 121251.2974866804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1000800.0000, 
sim time next is 1001400.0000, 
raw observation next is [14.83333333333333, 100.0, 1.0, 2.0, 0.4836088715545594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525235.4883921443, 525235.4883921446, 115415.3816702253], 
processed observation next is [1.0, 0.6086956521739131, 0.3106060606060605, 1.0, 1.0, 1.0, 0.3545110894431992, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19453166236746086, 0.19453166236746094, 0.2815009309029885], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.87535405], dtype=float32), -0.30148187]. 
=============================================
[2019-03-23 07:45:07,070] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.4018935e-28 1.0000000e+00 1.5903873e-38 2.2193616e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 07:45:07,082] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5563
[2019-03-23 07:45:07,086] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2352096884191431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255384.5063155297, 255384.50631553, 78909.43176149808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1018800.0000, 
sim time next is 1019400.0000, 
raw observation next is [13.83333333333333, 95.0, 1.0, 2.0, 0.2321986358655192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252114.3371457989, 252114.3371457986, 78309.15633264196], 
processed observation next is [1.0, 0.8260869565217391, 0.265151515151515, 0.95, 1.0, 1.0, 0.040248294831898984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09337568042436996, 0.09337568042436986, 0.1909979422747365], 
reward next is 0.8090, 
noisyNet noise sample is [array([1.7320278], dtype=float32), 0.51753676]. 
=============================================
[2019-03-23 07:45:07,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0520156e-24 1.0000000e+00 1.3623674e-36 3.3667651e-35 1.1802857e-37], sum to 1.0000
[2019-03-23 07:45:07,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4120
[2019-03-23 07:45:07,418] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.213787089651615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232118.8605762545, 232118.8605762543, 74248.93105596786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1027800.0000, 
sim time next is 1028400.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2102306734810386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228256.5835378567, 228256.5835378567, 73638.5525125235], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 0.96, 1.0, 1.0, 0.012788341851298242, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08453947538439137, 0.08453947538439137, 0.1796062256403012], 
reward next is 0.8204, 
noisyNet noise sample is [array([-1.1048565], dtype=float32), -0.020136388]. 
=============================================
[2019-03-23 07:45:09,359] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4188817e-21 1.0000000e+00 3.4232888e-31 9.3690078e-31 6.1303587e-34], sum to 1.0000
[2019-03-23 07:45:09,368] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9349
[2019-03-23 07:45:09,375] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 99.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 189535.1636603689, 189535.1636603691, 66614.60605883678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [12.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 187160.2473436404, 187160.2473436404, 66059.97599449342], 
processed observation next is [1.0, 0.043478260869565216, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06931861012727422, 0.06931861012727422, 0.16112189266949614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01397335], dtype=float32), -2.5410492]. 
=============================================
[2019-03-23 07:45:12,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9450835e-24 1.0000000e+00 3.3363145e-33 3.9558361e-35 3.0903496e-38], sum to 1.0000
[2019-03-23 07:45:12,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0325
[2019-03-23 07:45:12,341] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 83.83333333333334, 1.0, 2.0, 0.3083737709370564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335329.7986994946, 335329.7986994943, 111923.1461851173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1123800.0000, 
sim time next is 1124400.0000, 
raw observation next is [17.66666666666667, 84.66666666666667, 1.0, 2.0, 0.3064795361858933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 332816.4106354548, 332816.4106354548, 111636.9025371925], 
processed observation next is [1.0, 0.0, 0.4393939393939396, 0.8466666666666667, 1.0, 1.0, 0.1330994202323666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12326533727239067, 0.12326533727239067, 0.2722851281394939], 
reward next is 0.7277, 
noisyNet noise sample is [array([0.26980397], dtype=float32), -0.44636706]. 
=============================================
[2019-03-23 07:45:16,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5395717e-24 1.0000000e+00 3.6526378e-35 5.8723954e-32 4.6288100e-36], sum to 1.0000
[2019-03-23 07:45:16,794] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9717
[2019-03-23 07:45:16,802] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 80.0, 1.0, 2.0, 0.5176845643423623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589615.4911892005, 589615.4911892005, 145058.6259036316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1197600.0000, 
sim time next is 1198200.0000, 
raw observation next is [24.16666666666666, 81.5, 1.0, 2.0, 0.520600073388944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592817.763401668, 592817.763401668, 145510.7850260354], 
processed observation next is [1.0, 0.8695652173913043, 0.7348484848484845, 0.815, 1.0, 1.0, 0.4007500917361799, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2195621345932104, 0.2195621345932104, 0.35490435372203755], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.13144593], dtype=float32), 0.58873624]. 
=============================================
[2019-03-23 07:45:27,837] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 07:45:27,839] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:45:27,841] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:45:27,843] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:45:27,843] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:27,843] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:45:27,844] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:27,844] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:45:27,845] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:27,846] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:27,844] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:45:27,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 07:45:27,886] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 07:45:27,887] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 07:45:27,910] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 07:45:27,933] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 07:46:07,890] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.97968316]
[2019-03-23 07:46:07,892] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.41666666666667, 68.83333333333334, 1.0, 2.0, 0.4791410608020306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 546381.5348674809, 546381.5348674809, 141709.7866760716]
[2019-03-23 07:46:07,894] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:46:07,897] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4963033e-21 1.0000000e+00 2.9999242e-30 3.9890953e-29 9.3241446e-33], sampled 0.5817611658899565
[2019-03-23 07:46:22,795] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.97968316]
[2019-03-23 07:46:22,796] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.01272971833333, 71.29992694333333, 1.0, 2.0, 0.4277789917699354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 487518.9393084889, 487518.9393084889, 135805.1792468549]
[2019-03-23 07:46:22,797] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:46:22,799] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4963033e-21 1.0000000e+00 2.9999242e-30 3.9890953e-29 9.3241446e-33], sampled 0.0046827528865730494
[2019-03-23 07:46:27,456] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.97968316]
[2019-03-23 07:46:27,457] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.12295165, 99.12364852166668, 1.0, 2.0, 0.3955639517434986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 448094.9585052692, 448094.9585052692, 130168.1571897392]
[2019-03-23 07:46:27,458] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:46:27,460] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4963033e-21 1.0000000e+00 2.9999242e-30 3.9890953e-29 9.3241446e-33], sampled 0.7841559065966378
[2019-03-23 07:46:52,942] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.97968316]
[2019-03-23 07:46:52,944] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.45333037, 62.20022321, 1.0, 2.0, 0.4915530371372586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 557973.1006750175, 557973.1006750175, 140408.9612308489]
[2019-03-23 07:46:52,944] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:46:52,947] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4963033e-21 1.0000000e+00 2.9999242e-30 3.9890953e-29 9.3241446e-33], sampled 0.4736274845588021
[2019-03-23 07:46:56,050] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.97968316]
[2019-03-23 07:46:56,052] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.4, 66.0, 1.0, 2.0, 0.4370855295728596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 495033.2388327268, 495033.2388327268, 134045.1787954934]
[2019-03-23 07:46:56,053] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:46:56,055] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4963033e-21 1.0000000e+00 2.9999242e-30 3.9890953e-29 9.3241446e-33], sampled 0.12361475706373481
[2019-03-23 07:47:10,931] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.97968316]
[2019-03-23 07:47:10,933] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.6, 83.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 216085.4360554462, 216085.4360554462, 77872.62827615521]
[2019-03-23 07:47:10,935] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:47:10,936] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4963033e-21 1.0000000e+00 2.9999242e-30 3.9890953e-29 9.3241446e-33], sampled 0.8384950469616245
[2019-03-23 07:47:16,041] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:47:16,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:47:16,082] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:47:16,106] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:47:16,166] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:47:17,182] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 250000, evaluation results [250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:47:22,102] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9814617e-21 1.0000000e+00 9.3058287e-29 5.0044991e-28 4.9455648e-31], sum to 1.0000
[2019-03-23 07:47:22,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4806
[2019-03-23 07:47:22,115] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524600.0000, 
sim time next is 1525200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3963906937578027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21802853509431813, 0.21802853509431813, 0.3541811690834739], 
reward next is 0.6458, 
noisyNet noise sample is [array([0.20423982], dtype=float32), -1.2652344]. 
=============================================
[2019-03-23 07:47:22,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6731008e-23 1.0000000e+00 3.0562331e-31 6.2030600e-30 5.8317796e-35], sum to 1.0000
[2019-03-23 07:47:22,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-23 07:47:22,350] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6119603859703205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 687686.9316760901, 687686.9316760901, 160575.2946647007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515600.0000, 
sim time next is 1516200.0000, 
raw observation next is [27.66666666666667, 71.66666666666666, 1.0, 2.0, 0.6060597401118228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681051.468577749, 681051.468577749, 159741.1430270525], 
processed observation next is [0.0, 0.5652173913043478, 0.8939393939393941, 0.7166666666666666, 1.0, 1.0, 0.5075746751397785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25224128465842555, 0.25224128465842555, 0.3896125439684207], 
reward next is 0.6104, 
noisyNet noise sample is [array([-0.14376841], dtype=float32), 0.2676454]. 
=============================================
[2019-03-23 07:47:25,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3285595e-16 1.0000000e+00 2.1976790e-25 5.4899843e-25 3.6645276e-28], sum to 1.0000
[2019-03-23 07:47:25,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5794
[2019-03-23 07:47:25,798] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 81.5, 1.0, 2.0, 0.9193565788553834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1048865.395600331, 1048865.395600331, 204457.8557709274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1593000.0000, 
sim time next is 1593600.0000, 
raw observation next is [23.66666666666667, 79.0, 1.0, 2.0, 0.9179364935938612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1047615.127208897, 1047615.127208897, 203505.6360775666], 
processed observation next is [1.0, 0.43478260869565216, 0.7121212121212124, 0.79, 1.0, 1.0, 0.8974206169923266, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38800560266996187, 0.38800560266996187, 0.49635520994528437], 
reward next is 0.5036, 
noisyNet noise sample is [array([0.00654275], dtype=float32), 1.3496957]. 
=============================================
[2019-03-23 07:47:26,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6517791e-17 1.0000000e+00 1.9547681e-25 3.2255768e-23 2.6585096e-27], sum to 1.0000
[2019-03-23 07:47:26,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2907
[2019-03-23 07:47:26,232] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 76.5, 1.0, 2.0, 0.9165465916872388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1046276.58883501, 1046276.58883501, 202512.8189226892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1594200.0000, 
sim time next is 1594800.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.9114804700463428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1040598.732407548, 1040598.732407548, 200822.969629477], 
processed observation next is [1.0, 0.4782608695652174, 0.7272727272727273, 0.74, 1.0, 1.0, 0.8893505875579285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3854069379287215, 0.3854069379287215, 0.4898121210475049], 
reward next is 0.5102, 
noisyNet noise sample is [array([-1.6314481], dtype=float32), -1.1294556]. 
=============================================
[2019-03-23 07:47:27,370] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5049985e-17 1.0000000e+00 2.3088933e-24 2.4892151e-24 1.2537000e-26], sum to 1.0000
[2019-03-23 07:47:27,375] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8454
[2019-03-23 07:47:27,378] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 70.66666666666667, 1.0, 2.0, 0.4797501099016096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 547437.3968954392, 547437.3968954389, 138585.7322448469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1621200.0000, 
sim time next is 1621800.0000, 
raw observation next is [24.5, 71.5, 1.0, 2.0, 0.4766412852606633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543885.4109316502, 543885.4109316502, 138171.5038825133], 
processed observation next is [1.0, 0.782608695652174, 0.75, 0.715, 1.0, 1.0, 0.3458016065758291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20143904108579638, 0.20143904108579638, 0.33700366800612996], 
reward next is 0.6630, 
noisyNet noise sample is [array([0.9316676], dtype=float32), 0.6917416]. 
=============================================
[2019-03-23 07:47:29,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2473763e-23 1.0000000e+00 7.4439590e-33 5.3615652e-31 1.2021853e-34], sum to 1.0000
[2019-03-23 07:47:29,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5027
[2019-03-23 07:47:29,381] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 84.83333333333334, 1.0, 2.0, 0.4001332460738994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448977.7616681538, 448977.7616681538, 123896.950465098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1671000.0000, 
sim time next is 1671600.0000, 
raw observation next is [19.33333333333334, 86.66666666666667, 1.0, 2.0, 0.5099413959795429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571837.7592976615, 571837.7592976615, 134209.6560856178], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.8666666666666667, 1.0, 1.0, 0.3874267449744286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2117917627028376, 0.2117917627028376, 0.3273406245990678], 
reward next is 0.6727, 
noisyNet noise sample is [array([0.7443694], dtype=float32), -0.371938]. 
=============================================
[2019-03-23 07:47:30,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3982694e-23 1.0000000e+00 2.8451792e-33 1.3759045e-29 4.2067591e-35], sum to 1.0000
[2019-03-23 07:47:30,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7235
[2019-03-23 07:47:30,759] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 50.16666666666667, 1.0, 2.0, 0.2567836095984893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278815.6179521171, 278815.6179521173, 77385.68872876599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1705800.0000, 
sim time next is 1706400.0000, 
raw observation next is [18.0, 49.0, 1.0, 2.0, 0.2534514697517722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275196.5572193616, 275196.5572193613, 76373.64643826109], 
processed observation next is [1.0, 0.782608695652174, 0.45454545454545453, 0.49, 1.0, 1.0, 0.06681433718971522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10192465082198578, 0.10192465082198567, 0.18627718643478314], 
reward next is 0.8137, 
noisyNet noise sample is [array([0.06331529], dtype=float32), 0.9209274]. 
=============================================
[2019-03-23 07:47:32,538] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.291263e-19 1.000000e+00 8.280538e-28 5.278533e-27 4.844879e-31], sum to 1.0000
[2019-03-23 07:47:32,549] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7691
[2019-03-23 07:47:32,563] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 149310.7694228525, 149310.7694228528, 57755.54756804362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1733400.0000, 
sim time next is 1734000.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 148761.7633045556, 148761.7633045556, 57692.69487715534], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.055096949372057634, 0.055096949372057634, 0.14071388994428133], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00023577], dtype=float32), 2.0876048]. 
=============================================
[2019-03-23 07:47:32,586] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[60.275608]
 [60.275608]
 [60.275608]
 [60.275608]
 [60.275608]], R is [[59.67285156]
 [59.07612228]
 [58.48536301]
 [57.90050888]
 [57.32150269]].
[2019-03-23 07:47:38,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00007226e-23 1.00000000e+00 1.97767305e-34 6.47283202e-32
 1.16068955e-36], sum to 1.0000
[2019-03-23 07:47:38,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4325
[2019-03-23 07:47:38,870] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 66.66666666666667, 1.0, 2.0, 0.2600611472438394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282375.4011188705, 282375.4011188705, 79730.74316151113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1844400.0000, 
sim time next is 1845000.0000, 
raw observation next is [17.0, 66.0, 1.0, 2.0, 0.3162382700061018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 343394.2742418167, 343394.274241817, 86193.61015776078], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.66, 1.0, 1.0, 0.1452978375076272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12718306453400618, 0.1271830645340063, 0.21022831745795312], 
reward next is 0.7898, 
noisyNet noise sample is [array([-0.26460537], dtype=float32), -1.3055242]. 
=============================================
[2019-03-23 07:47:38,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.821106]
 [71.821106]
 [71.821106]
 [71.821106]
 [71.821106]], R is [[71.89266968]
 [71.97927856]
 [72.07329559]
 [72.17371368]
 [72.27418518]].
[2019-03-23 07:47:44,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9698668e-16 1.0000000e+00 6.3419080e-22 6.6641575e-23 1.5135913e-24], sum to 1.0000
[2019-03-23 07:47:44,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8802
[2019-03-23 07:47:44,292] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 53.5, 1.0, 2.0, 0.3785693263495814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344287564, 426971.4815265925, 426971.4815265925, 123151.7365605396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1963800.0000, 
sim time next is 1964400.0000, 
raw observation next is [25.0, 52.33333333333333, 1.0, 2.0, 0.3769124789015837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344353692, 424200.25845928, 424200.2584592803, 122520.8896152459], 
processed observation next is [1.0, 0.7391304347826086, 0.7727272727272727, 0.5233333333333333, 1.0, 1.0, 0.2211405986269796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.508428812920627, 0.15711120683677038, 0.1571112068367705, 0.29883143808596563], 
reward next is 0.7012, 
noisyNet noise sample is [array([-0.819102], dtype=float32), 0.80158865]. 
=============================================
[2019-03-23 07:47:44,914] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6532541e-17 1.0000000e+00 1.7422259e-24 7.2619025e-25 9.8211979e-28], sum to 1.0000
[2019-03-23 07:47:44,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5117
[2019-03-23 07:47:44,928] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 59.0, 1.0, 2.0, 0.3474906085288084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384465.0267029443, 384465.0267029443, 117048.40958396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1972200.0000, 
sim time next is 1972800.0000, 
raw observation next is [22.0, 60.0, 1.0, 2.0, 0.3420001690986414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377475.0233026093, 377475.0233026093, 116270.6606603455], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.6, 1.0, 1.0, 0.17750021137330171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1398055641861516, 0.1398055641861516, 0.28358697722035486], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.67009246], dtype=float32), -0.046091426]. 
=============================================
[2019-03-23 07:47:47,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7870804e-27 1.0000000e+00 9.8592678e-34 4.9353400e-35 2.2529927e-38], sum to 1.0000
[2019-03-23 07:47:47,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7243
[2019-03-23 07:47:47,180] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 66.0, 1.0, 2.0, 0.2857289041529442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310254.4408793982, 310254.4408793985, 99806.5143336671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2020200.0000, 
sim time next is 2020800.0000, 
raw observation next is [19.66666666666667, 64.0, 1.0, 2.0, 0.285012412074524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309476.2011685559, 309476.2011685562, 100305.2473971312], 
processed observation next is [0.0, 0.391304347826087, 0.5303030303030305, 0.64, 1.0, 1.0, 0.10626551509315497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11462081524761329, 0.1146208152476134, 0.2446469448710517], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.91814584], dtype=float32), -0.41012233]. 
=============================================
[2019-03-23 07:47:55,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0361714e-22 1.0000000e+00 2.0233986e-34 4.8832827e-33 1.6619516e-36], sum to 1.0000
[2019-03-23 07:47:55,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6924
[2019-03-23 07:47:55,337] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3032969092368858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329336.8547555919, 329336.8547555922, 110322.604075456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2165400.0000, 
sim time next is 2166000.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3017394041185956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327645.0583012966, 327645.0583012966, 110185.898786017], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.1271742551482445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12135002159307282, 0.12135002159307282, 0.26874609460004145], 
reward next is 0.7313, 
noisyNet noise sample is [array([1.0159111], dtype=float32), -0.23941311]. 
=============================================
[2019-03-23 07:47:55,356] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.6194]
 [76.6194]
 [76.6194]
 [76.6194]
 [76.6194]], R is [[76.58446503]
 [76.54953766]
 [76.51474762]
 [76.48013306]
 [76.44475555]].
[2019-03-23 07:47:56,121] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1188065e-23 1.0000000e+00 2.7331360e-33 4.5508173e-33 2.4216515e-36], sum to 1.0000
[2019-03-23 07:47:56,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7255
[2019-03-23 07:47:56,134] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 77.0, 1.0, 2.0, 0.5116698336630561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555729.2181998958, 555729.2181998955, 121069.6865658928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2194800.0000, 
sim time next is 2195400.0000, 
raw observation next is [17.83333333333333, 77.0, 1.0, 2.0, 0.5289027207276912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574457.0724814228, 574457.0724814228, 124775.5323340388], 
processed observation next is [1.0, 0.391304347826087, 0.44696969696969674, 0.77, 1.0, 1.0, 0.41112840090961394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21276187869682325, 0.21276187869682325, 0.3043305666683873], 
reward next is 0.6957, 
noisyNet noise sample is [array([0.5453214], dtype=float32), 0.3890646]. 
=============================================
[2019-03-23 07:47:56,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0689006e-21 1.0000000e+00 1.4277703e-29 5.8475693e-29 2.9817122e-32], sum to 1.0000
[2019-03-23 07:47:56,811] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6974
[2019-03-23 07:47:56,814] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 73.83333333333334, 1.0, 2.0, 0.3967885856138174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 448144.2155155161, 448144.2155155163, 125121.6251958295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2225400.0000, 
sim time next is 2226000.0000, 
raw observation next is [21.66666666666667, 74.66666666666667, 1.0, 2.0, 0.3992086923730261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450710.357343027, 450710.3573430273, 125245.7208205449], 
processed observation next is [1.0, 0.782608695652174, 0.6212121212121214, 0.7466666666666667, 1.0, 1.0, 0.2490108654662826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1669297619788989, 0.166929761978899, 0.3054773678549876], 
reward next is 0.6945, 
noisyNet noise sample is [array([1.1884823], dtype=float32), -0.1166365]. 
=============================================
[2019-03-23 07:47:56,828] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.38685]
 [69.38685]
 [69.38685]
 [69.38685]
 [69.38685]], R is [[69.38749695]
 [69.38845062]
 [69.39002228]
 [69.39199829]
 [69.39414978]].
[2019-03-23 07:47:59,723] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.02119827e-23 1.00000000e+00 1.19923684e-32 1.29474664e-32
 1.93039971e-36], sum to 1.0000
[2019-03-23 07:47:59,730] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8361
[2019-03-23 07:47:59,735] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 80.33333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212884.5506741005, 212884.5506741002, 70011.9054292216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265600.0000, 
sim time next is 2266200.0000, 
raw observation next is [13.5, 79.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208184.6357216056, 208184.6357216054, 68781.07007607991], 
processed observation next is [1.0, 0.21739130434782608, 0.25, 0.795, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0771054206376317, 0.07710542063763162, 0.1677587075026339], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19373997], dtype=float32), 0.06968422]. 
=============================================
[2019-03-23 07:48:04,684] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 07:48:04,687] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:48:04,688] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:48:04,689] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:48:04,690] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:48:04,690] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:48:04,691] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:48:04,691] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:48:04,692] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:48:04,693] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:48:04,693] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:48:04,708] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 07:48:04,731] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 07:48:04,759] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 07:48:04,760] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 07:48:04,782] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 07:48:07,647] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:48:07,648] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.16207011, 64.21371978, 1.0, 2.0, 0.5861234435457698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 668229.9844059942, 668229.9844059942, 153903.9685720664]
[2019-03-23 07:48:07,650] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:48:07,654] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.37007969264813967
[2019-03-23 07:48:09,157] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:48:09,159] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.00511139, 95.13005018333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 206474.1227472216, 206474.1227472212, 75087.41024332918]
[2019-03-23 07:48:09,161] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:48:09,164] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.9996687828869707
[2019-03-23 07:48:17,779] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:48:17,781] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.53709145333333, 81.50942830166667, 1.0, 2.0, 0.2778470935851361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 301675.5944905689, 301675.5944905689, 95032.80762296684]
[2019-03-23 07:48:17,784] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:48:17,787] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.898172400008001
[2019-03-23 07:48:31,687] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:48:31,690] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.6005351, 82.40236060666668, 1.0, 2.0, 0.453474733971626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 515720.7692061999, 515720.7692061999, 137246.3942944276]
[2019-03-23 07:48:31,690] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:48:31,693] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.6533808696883294
[2019-03-23 07:48:39,998] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:48:39,999] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 88.33333333333334, 1.0, 2.0, 0.4787908278112724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519999.9328850247, 519999.9328850247, 114300.5358070388]
[2019-03-23 07:48:40,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:48:40,004] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.021102945209045765
[2019-03-23 07:49:06,175] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:49:06,176] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.35675076166667, 75.913217075, 1.0, 2.0, 0.6070478908372283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 682071.3708224163, 682071.3708224163, 164190.649089405]
[2019-03-23 07:49:06,178] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:49:06,182] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.1624596899733709
[2019-03-23 07:49:48,639] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78693616]
[2019-03-23 07:49:48,640] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.8, 47.0, 1.0, 2.0, 0.3258550513167676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 353816.1160782854, 353816.1160782851, 101553.8724102182]
[2019-03-23 07:49:48,641] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:49:48,643] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2570795e-24 1.0000000e+00 4.1092959e-34 7.1733279e-33 5.7950494e-37], sampled 0.6764712209491812
[2019-03-23 07:49:51,744] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:49:51,982] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:49:52,157] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:49:52,184] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:49:52,400] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:49:53,413] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 275000, evaluation results [275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:49:53,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8135053e-28 1.0000000e+00 4.8744510e-37 3.4522375e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 07:49:54,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5501
[2019-03-23 07:49:54,016] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 54.5, 1.0, 2.0, 0.4216438979034978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457905.186519222, 457905.186519222, 101157.2841484249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2367000.0000, 
sim time next is 2367600.0000, 
raw observation next is [19.66666666666666, 52.66666666666667, 1.0, 2.0, 0.4415562445152629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479540.6560732102, 479540.6560732105, 102540.8188234994], 
processed observation next is [1.0, 0.391304347826087, 0.53030303030303, 0.5266666666666667, 1.0, 1.0, 0.30194530564407857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17760765039748524, 0.17760765039748538, 0.2500995581060961], 
reward next is 0.7499, 
noisyNet noise sample is [array([0.3497622], dtype=float32), -0.02168151]. 
=============================================
[2019-03-23 07:49:55,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3585223e-24 1.0000000e+00 1.1207395e-34 6.1729065e-33 5.0522186e-37], sum to 1.0000
[2019-03-23 07:49:55,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7158
[2019-03-23 07:49:55,957] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 74.5, 1.0, 2.0, 0.2501152400782953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 271573.0814764421, 271573.0814764421, 84603.72091446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2417400.0000, 
sim time next is 2418000.0000, 
raw observation next is [17.0, 73.66666666666667, 1.0, 2.0, 0.2464109841329698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 267549.9243910878, 267549.9243910878, 83561.92161660483], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.7366666666666667, 1.0, 1.0, 0.05801373016621224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09909256458929178, 0.09909256458929178, 0.20380956491854837], 
reward next is 0.7962, 
noisyNet noise sample is [array([-0.31173578], dtype=float32), 0.33358517]. 
=============================================
[2019-03-23 07:49:55,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.03339]
 [75.03339]
 [75.03339]
 [75.03339]
 [75.03339]], R is [[75.07923889]
 [75.1220932 ]
 [75.16182709]
 [75.19850159]
 [75.23265076]].
[2019-03-23 07:49:56,892] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.8948066e-25 1.0000000e+00 8.2123309e-37 7.0599234e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 07:49:56,900] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3229
[2019-03-23 07:49:56,905] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 75.66666666666667, 1.0, 2.0, 0.2381321680646042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258558.501447915, 258558.5014479152, 81289.3398787324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2419800.0000, 
sim time next is 2420400.0000, 
raw observation next is [16.0, 79.33333333333334, 1.0, 2.0, 0.2370027166953086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257331.8443758678, 257331.8443758681, 80875.99130889362], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.7933333333333334, 1.0, 1.0, 0.046253395869135724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09530809050958067, 0.09530809050958078, 0.1972585153875454], 
reward next is 0.8027, 
noisyNet noise sample is [array([0.76234967], dtype=float32), -0.6559022]. 
=============================================
[2019-03-23 07:50:02,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5678173e-22 1.0000000e+00 6.2390986e-33 2.2452041e-29 2.5370392e-34], sum to 1.0000
[2019-03-23 07:50:02,834] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0743
[2019-03-23 07:50:02,838] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.3746367749407924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406834.1021425194, 406834.1021425194, 93277.92175636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2537400.0000, 
sim time next is 2538000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.3752311834292173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 407479.8662310964, 407479.8662310967, 93671.96221929854], 
processed observation next is [1.0, 0.391304347826087, 0.2727272727272727, 0.94, 1.0, 1.0, 0.2190389792865216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15091846897448014, 0.15091846897448025, 0.2284682005348745], 
reward next is 0.7715, 
noisyNet noise sample is [array([-2.2659018], dtype=float32), 0.8965961]. 
=============================================
[2019-03-23 07:50:02,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.95559]
 [69.95559]
 [69.95559]
 [69.95559]
 [69.95559]], R is [[70.02757263]
 [70.09979248]
 [70.1733017 ]
 [70.25157166]
 [70.34486389]].
[2019-03-23 07:50:03,310] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3443264e-21 1.0000000e+00 2.8738923e-31 1.1236834e-29 3.2451347e-33], sum to 1.0000
[2019-03-23 07:50:03,317] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9369
[2019-03-23 07:50:03,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 49.50000000000001, 1.0, 2.0, 0.6755542606895232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 738568.4130100884, 738568.4130100887, 145871.3030758315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2560200.0000, 
sim time next is 2560800.0000, 
raw observation next is [23.0, 49.0, 1.0, 2.0, 0.66783722568083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 729005.7919091202, 729005.7919091198, 144653.7262074559], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.49, 1.0, 1.0, 0.5847965321010375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.270002145151526, 0.2700021451515259, 0.35281396635964857], 
reward next is 0.6472, 
noisyNet noise sample is [array([0.08847608], dtype=float32), -0.54414606]. 
=============================================
[2019-03-23 07:50:05,839] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9830101e-23 1.0000000e+00 8.8408930e-34 8.0979030e-32 1.8385323e-36], sum to 1.0000
[2019-03-23 07:50:05,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9370
[2019-03-23 07:50:05,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.1, 91.0, 1.0, 2.0, 0.3099183865057968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337428.0480664338, 337428.048066434, 112174.8518073921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2597400.0000, 
sim time next is 2598000.0000, 
raw observation next is [17.03333333333333, 92.0, 1.0, 2.0, 0.312113081383623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340128.9895166467, 340128.9895166467, 112434.8797647207], 
processed observation next is [0.0, 0.043478260869565216, 0.41060606060606053, 0.92, 1.0, 1.0, 0.1401413517295287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12597369982098028, 0.12597369982098028, 0.2742314140602944], 
reward next is 0.7258, 
noisyNet noise sample is [array([1.4742699], dtype=float32), 0.83643454]. 
=============================================
[2019-03-23 07:50:05,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.91705]
 [75.91705]
 [75.91705]
 [75.91705]
 [75.91705]], R is [[75.88365173]
 [75.85121918]
 [75.81977844]
 [75.78943634]
 [75.76039124]].
[2019-03-23 07:50:22,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6663477e-19 1.0000000e+00 1.1707000e-27 1.0900636e-28 9.0748276e-32], sum to 1.0000
[2019-03-23 07:50:22,626] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9310
[2019-03-23 07:50:22,629] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.696267823034629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 792957.0610489188, 792957.0610489188, 169290.2718821724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2964600.0000, 
sim time next is 2965200.0000, 
raw observation next is [23.66666666666667, 85.0, 1.0, 2.0, 0.6772291068679657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 771163.4835082027, 771163.4835082025, 166562.6766363011], 
processed observation next is [1.0, 0.30434782608695654, 0.7121212121212124, 0.85, 1.0, 1.0, 0.5965363835849571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.285616105003038, 0.28561610500303797, 0.4062504308202466], 
reward next is 0.5937, 
noisyNet noise sample is [array([0.08914465], dtype=float32), 1.0764446]. 
=============================================
[2019-03-23 07:50:25,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5007927e-17 1.0000000e+00 4.8913617e-23 6.0413881e-22 2.3129143e-23], sum to 1.0000
[2019-03-23 07:50:25,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1765
[2019-03-23 07:50:25,782] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 65.66666666666667, 1.0, 2.0, 0.4881381749289896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556987.386039529, 556987.3860395286, 139911.5981204057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3006600.0000, 
sim time next is 3007200.0000, 
raw observation next is [25.33333333333334, 66.33333333333334, 1.0, 2.0, 0.4823361643167456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550388.8290669284, 550388.8290669284, 138837.6987784856], 
processed observation next is [1.0, 0.8260869565217391, 0.7878787878787882, 0.6633333333333334, 1.0, 1.0, 0.35292020539593194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20384771446923272, 0.20384771446923272, 0.33862853360606243], 
reward next is 0.6614, 
noisyNet noise sample is [array([-0.18463965], dtype=float32), 0.32834122]. 
=============================================
[2019-03-23 07:50:32,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4665433e-22 1.0000000e+00 9.6641675e-30 5.5916367e-29 1.4174146e-31], sum to 1.0000
[2019-03-23 07:50:32,741] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-23 07:50:32,747] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1292556.49780282 W.
[2019-03-23 07:50:32,751] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 71.33333333333333, 1.0, 2.0, 0.6530433893118571, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9737626102144827, 6.911199999999999, 6.9112, 77.32846343846036, 1292556.49780282, 1292556.49780282, 281810.8465504049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3160200.0000, 
sim time next is 3160800.0000, 
raw observation next is [25.0, 69.0, 1.0, 2.0, 0.5415730257328328, 1.0, 1.0, 0.5415730257328328, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344350959, 1232845.974166633, 1232845.974166633, 241018.5869064264], 
processed observation next is [1.0, 0.6086956521739131, 0.7727272727272727, 0.69, 1.0, 1.0, 0.426966282166041, 1.0, 0.5, 0.426966282166041, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129204473, 0.45660962006171596, 0.45660962006171596, 0.5878502119668937], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9930215], dtype=float32), 0.56360596]. 
=============================================
[2019-03-23 07:50:34,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0592512e-18 1.0000000e+00 2.0430831e-27 2.7934067e-26 2.4871219e-28], sum to 1.0000
[2019-03-23 07:50:34,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6782
[2019-03-23 07:50:34,957] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3931194976597872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442977.7030103136, 442977.7030103139, 124222.0725049065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3202800.0000, 
sim time next is 3203400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3924446634514218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442216.3133976456, 442216.3133976456, 124161.4311852257], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.24055582931427724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1637838197769058, 0.1637838197769058, 0.3028327589883554], 
reward next is 0.6972, 
noisyNet noise sample is [array([1.2524638], dtype=float32), 1.4030432]. 
=============================================
[2019-03-23 07:50:36,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8651468e-23 1.0000000e+00 6.0975930e-33 4.1476328e-32 5.0954021e-36], sum to 1.0000
[2019-03-23 07:50:36,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8750
[2019-03-23 07:50:36,860] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 81.33333333333334, 1.0, 2.0, 0.342507099184474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379922.3204154904, 379922.3204154907, 117056.193512522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3222600.0000, 
sim time next is 3223200.0000, 
raw observation next is [19.66666666666667, 79.66666666666667, 1.0, 2.0, 0.346075628026196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384551.010362335, 384551.010362335, 117608.1172950291], 
processed observation next is [0.0, 0.30434782608695654, 0.5303030303030305, 0.7966666666666667, 1.0, 1.0, 0.182594535032745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14242630013419816, 0.14242630013419816, 0.2868490665732417], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.48068035], dtype=float32), -0.45554826]. 
=============================================
[2019-03-23 07:50:38,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4610783e-24 1.0000000e+00 5.3760187e-33 4.2378032e-32 6.0690636e-36], sum to 1.0000
[2019-03-23 07:50:38,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8761
[2019-03-23 07:50:38,590] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 52.33333333333334, 1.0, 2.0, 0.3178173011996605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346597.7971566158, 346597.7971566155, 112918.9179350894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3266400.0000, 
sim time next is 3267000.0000, 
raw observation next is [22.5, 53.5, 1.0, 2.0, 0.3189548582893963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348114.5617824472, 348114.5617824474, 113095.806697717], 
processed observation next is [0.0, 0.8260869565217391, 0.6590909090909091, 0.535, 1.0, 1.0, 0.14869357286174534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12893131917868414, 0.12893131917868422, 0.27584343097004144], 
reward next is 0.7242, 
noisyNet noise sample is [array([-0.22091843], dtype=float32), 2.8078043]. 
=============================================
[2019-03-23 07:50:38,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.81027]
 [75.81027]
 [75.81027]
 [75.81027]
 [75.81027]], R is [[75.77632904]
 [75.74315643]
 [75.71087646]
 [75.67910767]
 [75.64685822]].
[2019-03-23 07:50:40,867] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:50:40,870] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:50:40,871] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:50:40,872] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:40,872] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:50:40,874] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:50:40,875] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:50:40,873] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:40,876] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:40,876] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:40,877] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:50:40,891] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 07:50:40,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 07:50:40,941] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 07:50:40,963] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 07:50:40,987] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 07:50:43,797] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.89277697]
[2019-03-23 07:50:43,798] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.65856357, 65.87544214, 1.0, 2.0, 0.405949743423364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445212.813582665, 445212.8135826646, 124674.8843031783]
[2019-03-23 07:50:43,801] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:50:43,804] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9181983e-25 1.0000000e+00 3.4389621e-35 6.3912188e-34 3.8600535e-38], sampled 0.3579611241336872
[2019-03-23 07:50:45,218] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.89277697]
[2019-03-23 07:50:45,222] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.945786225, 70.09645515, 1.0, 2.0, 0.2761576817545748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 299840.8391127944, 299840.839112794, 106206.795079544]
[2019-03-23 07:50:45,223] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:50:45,227] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.9181983e-25 1.0000000e+00 3.4389621e-35 6.3912188e-34 3.8600535e-38], sampled 0.797261374870754
[2019-03-23 07:51:13,089] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.89277697]
[2019-03-23 07:51:13,092] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.34140578333334, 35.67000352, 1.0, 2.0, 0.3235724687619892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 351336.9445393875, 351336.9445393872, 95960.76272631504]
[2019-03-23 07:51:13,094] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:51:13,099] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9181983e-25 1.0000000e+00 3.4389621e-35 6.3912188e-34 3.8600535e-38], sampled 0.5650591458704952
[2019-03-23 07:51:22,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.89277697]
[2019-03-23 07:51:22,855] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.69448036666667, 87.81945245, 1.0, 2.0, 0.3795798253844115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 427049.681421751, 427049.681421751, 126999.2004852546]
[2019-03-23 07:51:22,856] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:51:22,859] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.9181983e-25 1.0000000e+00 3.4389621e-35 6.3912188e-34 3.8600535e-38], sampled 0.6978981855391515
[2019-03-23 07:51:51,241] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.89277697]
[2019-03-23 07:51:51,243] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.73333333333333, 66.66666666666666, 1.0, 2.0, 0.3089086248070387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 339166.8995586936, 339166.8995586933, 117454.1941141673]
[2019-03-23 07:51:51,244] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:51:51,247] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.9181983e-25 1.0000000e+00 3.4389621e-35 6.3912188e-34 3.8600535e-38], sampled 0.1603152741957622
[2019-03-23 07:52:01,817] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.89277697]
[2019-03-23 07:52:01,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.2, 40.0, 1.0, 2.0, 0.3270310169450192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 355093.3665426189, 355093.3665426189, 101449.8441250989]
[2019-03-23 07:52:01,820] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:52:01,822] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.9181983e-25 1.0000000e+00 3.4389621e-35 6.3912188e-34 3.8600535e-38], sampled 0.12610716068838068
[2019-03-23 07:52:28,349] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:52:28,421] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:52:28,430] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:52:28,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:52:28,701] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:52:29,716] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 300000, evaluation results [300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:52:33,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.9553460e-22 1.0000000e+00 2.8065449e-33 1.8933796e-29 1.0898940e-34], sum to 1.0000
[2019-03-23 07:52:33,100] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8480
[2019-03-23 07:52:33,105] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 53.5, 1.0, 2.0, 0.3659478585980993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410448.2704785065, 410448.2704785065, 120870.7196840403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3346200.0000, 
sim time next is 3346800.0000, 
raw observation next is [24.33333333333334, 54.66666666666667, 1.0, 2.0, 0.3675222316295679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412449.1096275202, 412449.1096275199, 121116.6582295992], 
processed observation next is [0.0, 0.7391304347826086, 0.7424242424242427, 0.5466666666666667, 1.0, 1.0, 0.20940278953695982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15275892949167416, 0.15275892949167405, 0.2954064834868273], 
reward next is 0.7046, 
noisyNet noise sample is [array([1.5538217], dtype=float32), 0.14423549]. 
=============================================
[2019-03-23 07:52:34,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7382694e-24 1.0000000e+00 1.0070043e-32 1.7095905e-32 3.1524826e-36], sum to 1.0000
[2019-03-23 07:52:34,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2840
[2019-03-23 07:52:34,107] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 100.0, 1.0, 2.0, 0.3164152365354022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346719.2564076243, 346719.2564076246, 113415.3675595431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3389400.0000, 
sim time next is 3390000.0000, 
raw observation next is [16.66666666666666, 100.0, 1.0, 2.0, 0.3201195448826978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 351875.8661059612, 351875.8661059612, 114085.8576591071], 
processed observation next is [1.0, 0.21739130434782608, 0.39393939393939365, 1.0, 1.0, 1.0, 0.1501494311033722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1303243948540597, 0.1303243948540597, 0.27825818941245634], 
reward next is 0.7217, 
noisyNet noise sample is [array([0.10455316], dtype=float32), -0.68272746]. 
=============================================
[2019-03-23 07:52:34,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.86068]
 [72.86068]
 [72.86068]
 [72.86068]
 [72.86068]], R is [[72.8538208 ]
 [72.8486557 ]
 [72.84503174]
 [72.84222412]
 [72.84127045]].
[2019-03-23 07:52:35,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6433645e-17 1.0000000e+00 4.1840820e-27 2.4508079e-26 1.9548983e-29], sum to 1.0000
[2019-03-23 07:52:35,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3300595e-20 1.0000000e+00 2.3010115e-27 1.4695083e-26 5.8574116e-30], sum to 1.0000
[2019-03-23 07:52:35,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5771
[2019-03-23 07:52:35,753] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 78.0, 1.0, 2.0, 0.7032312671129247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 798555.7042171211, 798555.7042171208, 161803.8308857737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3401400.0000, 
sim time next is 3402000.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.7326722754445353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 832856.5561123712, 832856.5561123709, 166514.4028998267], 
processed observation next is [1.0, 0.391304347826087, 0.6363636363636364, 0.78, 1.0, 1.0, 0.665840344305669, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3084653911527301, 0.30846539115273, 0.4061326899995773], 
reward next is 0.5939, 
noisyNet noise sample is [array([1.067111], dtype=float32), -0.93249506]. 
=============================================
[2019-03-23 07:52:35,755] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3592
[2019-03-23 07:52:35,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1345862.891480195 W.
[2019-03-23 07:52:35,763] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[54.77764]
 [54.77764]
 [54.77764]
 [54.77764]
 [54.77764]], R is [[54.82373428]
 [54.88085556]
 [54.94313812]
 [55.01712036]
 [55.12551498]].
[2019-03-23 07:52:35,767] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.65, 57.0, 1.0, 2.0, 0.3962071143704931, 1.0, 2.0, 0.3962071143704931, 1.0, 2.0, 0.802157593364329, 6.911199999999999, 6.9112, 77.3421103, 1345862.891480195, 1345862.891480195, 301872.9029422717], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3421800.0000, 
sim time next is 3422400.0000, 
raw observation next is [27.7, 56.66666666666666, 1.0, 2.0, 0.3943254809600027, 1.0, 2.0, 0.3943254809600027, 1.0, 2.0, 0.7983646844369918, 6.911199999999999, 6.9112, 77.3421103, 1339576.665593113, 1339576.665593113, 300950.5585068458], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.5666666666666665, 1.0, 1.0, 0.24290685120000335, 1.0, 1.0, 0.24290685120000335, 1.0, 1.0, 0.7119495491957026, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.49613950577522703, 0.49613950577522703, 0.7340257524557214], 
reward next is 0.2660, 
noisyNet noise sample is [array([0.3708629], dtype=float32), -0.39568287]. 
=============================================
[2019-03-23 07:52:39,937] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3797926e-16 1.0000000e+00 1.0500911e-24 6.5570794e-25 3.9651893e-27], sum to 1.0000
[2019-03-23 07:52:39,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0311
[2019-03-23 07:52:39,954] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1513237.868934651 W.
[2019-03-23 07:52:39,958] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.8538021343637566, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9817494427873655, 6.9112, 6.9112, 77.32846344354104, 1513237.868934651, 1513237.868934651, 321675.3319305272], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3507600.0000, 
sim time next is 3508200.0000, 
raw observation next is [28.0, 62.0, 1.0, 2.0, 0.6814840267684983, 1.0, 1.0, 0.6814840267684983, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1532840.211062316, 1532840.211062316, 286014.2856621724], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.62, 1.0, 1.0, 0.6018550334606229, 1.0, 0.5, 0.6018550334606229, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5677185966897467, 0.5677185966897467, 0.6975958186882254], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9431541], dtype=float32), -0.4260816]. 
=============================================
[2019-03-23 07:52:43,538] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3847144e-21 1.0000000e+00 1.5040518e-27 6.2909755e-28 5.5213026e-31], sum to 1.0000
[2019-03-23 07:52:43,544] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6869
[2019-03-23 07:52:43,548] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5558705054222167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 633948.4382147196, 633948.4382147196, 148901.4920265753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3555600.0000, 
sim time next is 3556200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5512157317161007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628639.2317115108, 628639.2317115108, 148314.9625726976], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.94, 1.0, 1.0, 0.4390196646451259, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23282934507833733, 0.23282934507833733, 0.361743811152921], 
reward next is 0.6383, 
noisyNet noise sample is [array([-1.2600386], dtype=float32), -0.8635993]. 
=============================================
[2019-03-23 07:52:47,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7864352e-23 1.0000000e+00 2.8779736e-31 1.9628386e-32 3.8312038e-35], sum to 1.0000
[2019-03-23 07:52:47,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1996
[2019-03-23 07:52:47,192] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.503475310802977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574447.2328400918, 574447.2328400918, 141901.9906912884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3649800.0000, 
sim time next is 3650400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4920431996357769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561397.7327374378, 561397.7327374378, 140574.3244553651], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3650539995447211, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20792508619905103, 0.20792508619905103, 0.3428642059886954], 
reward next is 0.6571, 
noisyNet noise sample is [array([0.27117354], dtype=float32), -0.0713646]. 
=============================================
[2019-03-23 07:52:55,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7193332e-24 1.0000000e+00 1.6099726e-34 6.9381318e-34 3.5420915e-37], sum to 1.0000
[2019-03-23 07:52:55,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3186
[2019-03-23 07:52:55,585] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 90.0, 1.0, 2.0, 0.3016545085757489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327552.8430570332, 327552.8430570335, 111303.290389513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3828000.0000, 
sim time next is 3828600.0000, 
raw observation next is [17.0, 91.0, 1.0, 2.0, 0.3035894200521386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329664.7430723908, 329664.7430723908, 111437.9921957529], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.91, 1.0, 1.0, 0.12948677506517325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12209805298977437, 0.12209805298977437, 0.271799980965251], 
reward next is 0.7282, 
noisyNet noise sample is [array([-1.2394066], dtype=float32), -0.39502242]. 
=============================================
[2019-03-23 07:52:56,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8379107e-24 1.0000000e+00 7.2672104e-36 2.6743780e-34 8.4301028e-38], sum to 1.0000
[2019-03-23 07:52:56,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8679
[2019-03-23 07:52:56,148] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3305697046222101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361684.9367589866, 361684.9367589863, 114233.375117231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3806400.0000, 
sim time next is 3807000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3289831895895513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359947.9792539942, 359947.9792539942, 114118.7584787035], 
processed observation next is [0.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1612289869869391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13331406639036822, 0.13331406639036822, 0.278338435313911], 
reward next is 0.7217, 
noisyNet noise sample is [array([0.18363093], dtype=float32), 1.3757948]. 
=============================================
[2019-03-23 07:52:56,176] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.77971]
 [72.77971]
 [72.77971]
 [72.77971]
 [72.77971]], R is [[72.77357483]
 [72.76721954]
 [72.76120758]
 [72.75558472]
 [72.75017548]].
[2019-03-23 07:52:56,180] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2039078e-21 1.0000000e+00 4.8701120e-33 1.4102106e-29 3.8056586e-33], sum to 1.0000
[2019-03-23 07:52:56,192] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9288
[2019-03-23 07:52:56,197] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2982750101389878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323881.9781609855, 323881.9781609857, 111076.2838134219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3842400.0000, 
sim time next is 3843000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2975113223775083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323052.4522192201, 323052.4522192198, 111025.3536026662], 
processed observation next is [0.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.12188915297188539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11964905637748893, 0.11964905637748882, 0.2707935453723566], 
reward next is 0.7292, 
noisyNet noise sample is [array([-0.38236582], dtype=float32), -1.9590966]. 
=============================================
[2019-03-23 07:52:56,209] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.60587]
 [75.60587]
 [75.60587]
 [75.60587]
 [75.60587]], R is [[75.57902527]
 [75.55231476]
 [75.52558899]
 [75.49863434]
 [75.47088623]].
[2019-03-23 07:53:01,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4236512e-22 1.0000000e+00 1.1260680e-31 3.6004670e-29 2.0965276e-33], sum to 1.0000
[2019-03-23 07:53:01,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4768
[2019-03-23 07:53:01,346] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 44.33333333333334, 1.0, 2.0, 0.3376970503819751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374441.6210857527, 374441.6210857527, 116626.311863072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3944400.0000, 
sim time next is 3945000.0000, 
raw observation next is [25.16666666666667, 44.16666666666667, 1.0, 2.0, 0.333669476876838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369003.3699749171, 369003.3699749171, 115927.4836683038], 
processed observation next is [0.0, 0.6521739130434783, 0.7803030303030305, 0.4416666666666667, 1.0, 1.0, 0.1670868460960475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13666791480552484, 0.13666791480552484, 0.28274996016659465], 
reward next is 0.7173, 
noisyNet noise sample is [array([2.64686], dtype=float32), -0.7233341]. 
=============================================
[2019-03-23 07:53:01,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.41603]
 [69.41603]
 [69.41603]
 [69.41603]
 [69.41603]], R is [[69.43912506]
 [69.46028137]
 [69.47953033]
 [69.49678802]
 [69.51196289]].
[2019-03-23 07:53:10,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.36990265e-21 1.00000000e+00 1.32476455e-30 4.64325497e-30
 2.06682874e-33], sum to 1.0000
[2019-03-23 07:53:10,189] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-23 07:53:10,194] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 73.0, 1.0, 2.0, 0.6639599605686237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 754737.8000835426, 754737.8000835426, 157190.8967986075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4105200.0000, 
sim time next is 4105800.0000, 
raw observation next is [22.5, 73.0, 1.0, 2.0, 0.6024368604897045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683994.5051547574, 683994.5051547574, 148782.2769337842], 
processed observation next is [1.0, 0.5217391304347826, 0.6590909090909091, 0.73, 1.0, 1.0, 0.5030460756121305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2533312982054657, 0.2533312982054657, 0.3628836022775224], 
reward next is 0.6371, 
noisyNet noise sample is [array([0.56049675], dtype=float32), -1.3281928]. 
=============================================
[2019-03-23 07:53:17,205] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 07:53:17,207] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:53:17,208] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:53:17,209] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:53:17,210] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:53:17,210] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:17,210] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:17,212] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:17,211] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:53:17,212] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:17,215] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:53:17,226] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 07:53:17,251] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 07:53:17,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 07:53:17,300] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 07:53:17,300] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 07:53:20,665] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7642923]
[2019-03-23 07:53:20,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.18333333333333, 48.16666666666666, 1.0, 2.0, 0.246196650812866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 267303.1299668273, 267303.1299668273, 78691.43418224648]
[2019-03-23 07:53:20,668] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:53:20,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0439618e-21 1.0000000e+00 6.4571748e-31 8.9731499e-30 1.7043347e-33], sampled 0.6234719603187624
[2019-03-23 07:53:33,808] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7642923]
[2019-03-23 07:53:33,809] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.952552515, 71.998779165, 1.0, 2.0, 0.5383383373065588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 612934.4994477795, 612934.4994477795, 152021.7617936215]
[2019-03-23 07:53:33,810] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:53:33,814] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0439618e-21 1.0000000e+00 6.4571748e-31 8.9731499e-30 1.7043347e-33], sampled 0.38612582115570226
[2019-03-23 07:53:48,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7642923]
[2019-03-23 07:53:48,003] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 82.0, 1.0, 2.0, 0.248851462006533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270200.5004147225, 270200.5004147222, 83938.3458544673]
[2019-03-23 07:53:48,007] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:53:48,009] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0439618e-21 1.0000000e+00 6.4571748e-31 8.9731499e-30 1.7043347e-33], sampled 0.08926905440006849
[2019-03-23 07:53:54,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7642923]
[2019-03-23 07:53:54,482] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.03333333333333, 84.0, 1.0, 2.0, 0.3851017158185898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 433099.2424690587, 433099.2424690587, 127396.3763256021]
[2019-03-23 07:53:54,484] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:53:54,488] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0439618e-21 1.0000000e+00 6.4571748e-31 8.9731499e-30 1.7043347e-33], sampled 0.31678436161990653
[2019-03-23 07:54:15,217] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7642923]
[2019-03-23 07:54:15,219] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.96666666666667, 79.33333333333334, 1.0, 2.0, 0.4780980549208381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 545297.8292157293, 545297.8292157289, 141827.8493255955]
[2019-03-23 07:54:15,220] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 07:54:15,222] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0439618e-21 1.0000000e+00 6.4571748e-31 8.9731499e-30 1.7043347e-33], sampled 0.6949086548197296
[2019-03-23 07:55:04,135] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:55:04,236] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:55:04,411] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:55:04,440] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:55:04,487] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:55:05,500] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 325000, evaluation results [325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:55:11,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5361845e-20 1.0000000e+00 1.1453139e-27 1.5434882e-28 1.2588196e-31], sum to 1.0000
[2019-03-23 07:55:11,378] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8255
[2019-03-23 07:55:11,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1342865.627573166 W.
[2019-03-23 07:55:11,390] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.5906795224105014, 1.0, 2.0, 0.5906795224105014, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1342865.627573166, 1342865.627573166, 254927.551888982], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4363200.0000, 
sim time next is 4363800.0000, 
raw observation next is [27.16666666666666, 56.83333333333334, 1.0, 2.0, 0.5732854824089548, 1.0, 2.0, 0.5732854824089548, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1304179.23113184, 1304179.231131839, 249783.0284932016], 
processed observation next is [1.0, 0.5217391304347826, 0.871212121212121, 0.5683333333333335, 1.0, 1.0, 0.4666068530111935, 1.0, 1.0, 0.4666068530111935, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.48302934486364446, 0.48302934486364413, 0.6092268987639063], 
reward next is 0.3908, 
noisyNet noise sample is [array([0.76624227], dtype=float32), -0.058654204]. 
=============================================
[2019-03-23 07:55:14,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2876786e-21 1.0000000e+00 6.5876530e-29 9.7461763e-29 6.7982130e-31], sum to 1.0000
[2019-03-23 07:55:14,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2569
[2019-03-23 07:55:14,897] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 79.66666666666667, 1.0, 2.0, 0.4473064040502311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509923.7844131418, 509923.7844131418, 133643.9339369909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4437600.0000, 
sim time next is 4438200.0000, 
raw observation next is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4490454020754537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511970.8956891022, 511970.8956891022, 133929.7934511263], 
processed observation next is [0.0, 0.34782608695652173, 0.6742424242424245, 0.7883333333333333, 1.0, 1.0, 0.31130675259431706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18961885025522304, 0.18961885025522304, 0.32665803280762506], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.14802122], dtype=float32), 0.1957882]. 
=============================================
[2019-03-23 07:55:19,446] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3203367e-21 1.0000000e+00 1.4275680e-30 1.6830947e-29 4.0736213e-32], sum to 1.0000
[2019-03-23 07:55:19,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-23 07:55:19,457] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4528200.0000, 
sim time next is 4528800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011842725540635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 571569.7665009546, 571569.7665009544, 142225.7567633785], 
processed observation next is [0.0, 0.43478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37648034069257935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21169250611146467, 0.2116925061114646, 0.34689208966677687], 
reward next is 0.6531, 
noisyNet noise sample is [array([1.7030294], dtype=float32), 0.29979685]. 
=============================================
[2019-03-23 07:55:20,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9036604e-21 1.0000000e+00 6.6047418e-28 1.9260759e-27 9.7966790e-30], sum to 1.0000
[2019-03-23 07:55:20,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3980
[2019-03-23 07:55:20,296] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 73.0, 1.0, 2.0, 0.4111909817504058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466085.6192302086, 466085.6192302089, 127481.2326137172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4540800.0000, 
sim time next is 4541400.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.4014031981651237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453858.877119161, 453858.877119161, 125836.8434670079], 
processed observation next is [0.0, 0.5652173913043478, 0.6363636363636364, 0.73, 1.0, 1.0, 0.2517539977064046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16809588041450407, 0.16809588041450407, 0.3069191304073363], 
reward next is 0.6931, 
noisyNet noise sample is [array([2.1116478], dtype=float32), -0.6899257]. 
=============================================
[2019-03-23 07:55:23,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2532052e-25 1.0000000e+00 9.3428328e-34 6.3166694e-32 3.5668659e-36], sum to 1.0000
[2019-03-23 07:55:23,027] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5933
[2019-03-23 07:55:23,031] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 97.0, 1.0, 2.0, 0.229067287466122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 248713.5433739467, 248713.5433739464, 79565.55558575067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4595400.0000, 
sim time next is 4596000.0000, 
raw observation next is [14.0, 96.0, 1.0, 2.0, 0.2264923647800929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245917.0722921776, 245917.0722921773, 78807.71718214954], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.96, 1.0, 1.0, 0.03311545597511612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09108039714525096, 0.09108039714525085, 0.1922139443467062], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.0100012], dtype=float32), -0.3996336]. 
=============================================
[2019-03-23 07:55:23,063] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.404076]
 [79.404076]
 [79.404076]
 [79.404076]
 [79.404076]], R is [[79.41781616]
 [79.42958069]
 [79.43869019]
 [79.44413757]
 [79.44931793]].
[2019-03-23 07:55:24,496] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4707428e-21 1.0000000e+00 4.0575986e-33 8.8824529e-31 1.6514695e-33], sum to 1.0000
[2019-03-23 07:55:24,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3476
[2019-03-23 07:55:24,505] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 44.0, 1.0, 2.0, 0.3654362921210751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 396838.8269990796, 396838.8269990796, 107128.7522134045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4626000.0000, 
sim time next is 4626600.0000, 
raw observation next is [23.16666666666667, 44.50000000000001, 1.0, 2.0, 0.3781857059112713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 410689.6657538078, 410689.6657538078, 111417.7508996088], 
processed observation next is [1.0, 0.5652173913043478, 0.6893939393939396, 0.44500000000000006, 1.0, 1.0, 0.22273213238908912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1521072836125214, 0.1521072836125214, 0.27175061195026534], 
reward next is 0.7282, 
noisyNet noise sample is [array([-0.46435755], dtype=float32), -1.4838566]. 
=============================================
[2019-03-23 07:55:26,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6053427e-24 1.0000000e+00 2.6982455e-33 9.3974183e-33 5.2086008e-36], sum to 1.0000
[2019-03-23 07:55:26,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9741
[2019-03-23 07:55:26,898] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 61.33333333333333, 1.0, 2.0, 0.2676349600192724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290601.5333040308, 290601.5333040311, 90530.60205692104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4653600.0000, 
sim time next is 4654200.0000, 
raw observation next is [19.16666666666667, 62.66666666666667, 1.0, 2.0, 0.2664850252889014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289352.5477228661, 289352.5477228664, 90664.78679623497], 
processed observation next is [1.0, 0.8695652173913043, 0.5075757575757578, 0.6266666666666667, 1.0, 1.0, 0.08310628161112672, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1071676102677282, 0.1071676102677283, 0.22113362633228043], 
reward next is 0.7789, 
noisyNet noise sample is [array([-1.9190328], dtype=float32), -0.469247]. 
=============================================
[2019-03-23 07:55:27,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5595854e-24 1.0000000e+00 3.2766806e-33 7.3880826e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 07:55:27,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7208
[2019-03-23 07:55:27,363] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2625592744363857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285088.6723127135, 285088.6723127138, 90457.66656843868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4658400.0000, 
sim time next is 4659000.0000, 
raw observation next is [18.83333333333334, 65.5, 1.0, 2.0, 0.2657167379984697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288518.0849771106, 288518.0849771106, 91230.18957732597], 
processed observation next is [1.0, 0.9565217391304348, 0.4924242424242427, 0.655, 1.0, 1.0, 0.08214592249808708, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10685854999152244, 0.10685854999152244, 0.22251265750567312], 
reward next is 0.7775, 
noisyNet noise sample is [array([-0.8628035], dtype=float32), 1.9939406]. 
=============================================
[2019-03-23 07:55:27,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[81.80444]
 [81.80444]
 [81.80444]
 [81.80444]
 [81.80444]], R is [[81.7638855 ]
 [81.72562408]
 [81.68778229]
 [81.65032196]
 [81.61312103]].
[2019-03-23 07:55:32,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5292468e-22 1.0000000e+00 6.0411595e-29 1.5028982e-28 4.9170839e-31], sum to 1.0000
[2019-03-23 07:55:32,353] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7318
[2019-03-23 07:55:32,357] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.0, 1.0, 2.0, 0.8297784087676588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 945303.3328201764, 945303.332820176, 182718.845317171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4792800.0000, 
sim time next is 4793400.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.8248223202308465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 940201.4729500253, 940201.4729500253, 182602.5066246367], 
processed observation next is [1.0, 0.4782608695652174, 0.5681818181818182, 0.94, 1.0, 1.0, 0.7810279002885581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34822276775926864, 0.34822276775926864, 0.4453719673771627], 
reward next is 0.5546, 
noisyNet noise sample is [array([0.09749453], dtype=float32), 1.3762006]. 
=============================================
[2019-03-23 07:55:36,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2901897e-18 1.0000000e+00 1.2865966e-27 1.2123721e-27 1.5709351e-31], sum to 1.0000
[2019-03-23 07:55:36,132] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-23 07:55:36,138] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 96.0, 1.0, 2.0, 0.4745700535272598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541485.7520215359, 541485.7520215359, 137653.1586325135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4830000.0000, 
sim time next is 4830600.0000, 
raw observation next is [21.0, 95.0, 1.0, 2.0, 0.4691840358519569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535272.7155228277, 535272.7155228277, 136798.5318133464], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.95, 1.0, 1.0, 0.3364800448149461, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1982491538973436, 0.1982491538973436, 0.3336549556423083], 
reward next is 0.6663, 
noisyNet noise sample is [array([-0.7531786], dtype=float32), 0.28483546]. 
=============================================
[2019-03-23 07:55:37,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4770174e-22 1.0000000e+00 7.5058100e-32 5.8939012e-30 2.9398526e-34], sum to 1.0000
[2019-03-23 07:55:37,028] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5390
[2019-03-23 07:55:37,032] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4417414720324274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500846.0270205991, 500846.0270205993, 130519.1796274957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4866000.0000, 
sim time next is 4866600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4295115451170514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486946.9006414149, 486946.9006414149, 129299.3620227061], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.28688943139631423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1803507039412648, 0.1803507039412648, 0.31536429761635637], 
reward next is 0.6846, 
noisyNet noise sample is [array([0.69091916], dtype=float32), -1.7212977]. 
=============================================
[2019-03-23 07:55:38,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.50552866e-21 1.00000000e+00 2.71021460e-31 1.15334495e-29
 5.22789762e-33], sum to 1.0000
[2019-03-23 07:55:38,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4297
[2019-03-23 07:55:38,735] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 86.33333333333334, 1.0, 2.0, 0.4204481554206463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477722.2025554839, 477722.2025554839, 129209.6266244541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4912800.0000, 
sim time next is 4913400.0000, 
raw observation next is [21.0, 87.16666666666667, 1.0, 2.0, 0.4244758426815546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482586.0177770457, 482586.0177770457, 129844.5951417158], 
processed observation next is [1.0, 0.8695652173913043, 0.5909090909090909, 0.8716666666666667, 1.0, 1.0, 0.2805948033519432, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17873556213964656, 0.17873556213964656, 0.3166941344919898], 
reward next is 0.6833, 
noisyNet noise sample is [array([0.49124497], dtype=float32), 1.0463871]. 
=============================================
[2019-03-23 07:55:40,462] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9881054e-22 1.0000000e+00 2.4028293e-32 1.3338865e-31 1.3822613e-34], sum to 1.0000
[2019-03-23 07:55:40,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6606
[2019-03-23 07:55:40,470] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4260505502798739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484405.2937297414, 484405.2937297414, 130024.2489444241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4907400.0000, 
sim time next is 4908000.0000, 
raw observation next is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.422754148930917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480434.0143689322, 480434.0143689322, 129509.3809257295], 
processed observation next is [1.0, 0.8260869565217391, 0.6515151515151518, 0.7633333333333334, 1.0, 1.0, 0.2784426861636462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17793852384034528, 0.17793852384034528, 0.3158765388432427], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.5392064], dtype=float32), -1.7260791]. 
=============================================
[2019-03-23 07:55:40,490] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.551895]
 [69.551895]
 [69.551895]
 [69.551895]
 [69.551895]], R is [[69.5404892 ]
 [69.5279541 ]
 [69.51480865]
 [69.50193024]
 [69.48908997]].
[2019-03-23 07:55:43,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.22076462e-24 1.00000000e+00 3.01704408e-32 1.09975975e-32
 2.61810143e-35], sum to 1.0000
[2019-03-23 07:55:43,107] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2786
[2019-03-23 07:55:43,118] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 74.66666666666667, 1.0, 2.0, 0.5768978054191314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627895.3046842897, 627895.3046842897, 134504.7182481926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4963800.0000, 
sim time next is 4964400.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.5302694695999763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576339.0588510075, 576339.0588510075, 129762.0975925982], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.41283683699997037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21345891068555833, 0.21345891068555833, 0.3164929209575566], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.7838561], dtype=float32), -1.2121025]. 
=============================================
[2019-03-23 07:55:46,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3029429e-20 1.0000000e+00 1.0888324e-30 1.8131517e-29 1.9647864e-32], sum to 1.0000
[2019-03-23 07:55:46,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2904
[2019-03-23 07:55:46,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 51.5, 1.0, 2.0, 0.4161175248792196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473304.5104742421, 473304.5104742421, 129228.3884650239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.4177714993195757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475310.8212366672, 475310.8212366674, 129507.9764528291], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.51, 1.0, 1.0, 0.2722143741494696, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17604104490246933, 0.1760410449024694, 0.3158731132995832], 
reward next is 0.6841, 
noisyNet noise sample is [array([1.0619739], dtype=float32), -0.5883745]. 
=============================================
[2019-03-23 07:55:50,041] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2290577e-20 1.0000000e+00 7.1336889e-30 3.8738341e-29 1.5492306e-32], sum to 1.0000
[2019-03-23 07:55:50,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3883
[2019-03-23 07:55:50,059] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 66.66666666666666, 1.0, 2.0, 0.5685388362369502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 642269.2685259467, 642269.2685259467, 153797.1257965445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5147400.0000, 
sim time next is 5148000.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.569840193407648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 643488.9393767784, 643488.9393767788, 154039.1739219615], 
processed observation next is [0.0, 0.6086956521739131, 0.9090909090909091, 0.66, 1.0, 1.0, 0.46230024175955997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23832923680621423, 0.23832923680621437, 0.3757053022486866], 
reward next is 0.6243, 
noisyNet noise sample is [array([-1.5280765], dtype=float32), 0.73467875]. 
=============================================
[2019-03-23 07:55:50,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.680466]
 [64.680466]
 [64.680466]
 [64.680466]
 [64.680466]], R is [[64.65795898]
 [64.63626862]
 [64.61518097]
 [64.59469604]
 [64.57532501]].
[2019-03-23 07:55:51,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3278458e-20 1.0000000e+00 6.4972589e-29 2.7596171e-28 4.7759360e-32], sum to 1.0000
[2019-03-23 07:55:51,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2719
[2019-03-23 07:55:51,954] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 66.0, 1.0, 2.0, 0.5634315306619979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 637670.3211871426, 637670.3211871429, 152767.078307956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5152800.0000, 
sim time next is 5153400.0000, 
raw observation next is [27.5, 66.0, 1.0, 2.0, 0.557210321430326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 631381.979391829, 631381.9793918286, 151691.9381507922], 
processed observation next is [0.0, 0.6521739130434783, 0.8863636363636364, 0.66, 1.0, 1.0, 0.4465129017879075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23384517755252926, 0.23384517755252912, 0.36998033695315174], 
reward next is 0.6300, 
noisyNet noise sample is [array([-1.297899], dtype=float32), 0.10714992]. 
=============================================
[2019-03-23 07:55:52,611] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 07:55:52,614] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:55:52,615] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:52,615] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:55:52,616] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:55:52,617] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:52,617] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:52,617] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:55:52,618] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:55:52,620] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:52,621] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:55:52,637] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 07:55:52,661] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 07:55:52,699] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 07:55:52,722] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 07:55:52,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 07:56:56,009] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7913135]
[2019-03-23 07:56:56,011] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 45.0, 1.0, 2.0, 0.3828546905462714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415762.1038161949, 415762.1038161949, 111201.534304881]
[2019-03-23 07:56:56,013] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:56:56,016] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.42749826e-21 1.00000000e+00 8.79733954e-31 1.20703634e-29
 2.41246265e-33], sampled 0.31090057126844406
[2019-03-23 07:56:58,212] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7913135]
[2019-03-23 07:56:58,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.56852084, 95.51206711, 1.0, 2.0, 0.311906065091218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 339375.8859852789, 339375.8859852789, 116549.9208565943]
[2019-03-23 07:56:58,213] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:56:58,216] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.42749826e-21 1.00000000e+00 8.79733954e-31 1.20703634e-29
 2.41246265e-33], sampled 0.1470105442687577
[2019-03-23 07:57:04,532] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7913135]
[2019-03-23 07:57:04,533] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.28775995833334, 100.0, 1.0, 2.0, 0.6188369922666155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 705338.1852754197, 705338.1852754194, 161887.1495675196]
[2019-03-23 07:57:04,536] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:57:04,539] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.42749826e-21 1.00000000e+00 8.79733954e-31 1.20703634e-29
 2.41246265e-33], sampled 0.6361789576608569
[2019-03-23 07:57:25,609] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7913135]
[2019-03-23 07:57:25,612] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.7, 69.0, 1.0, 2.0, 0.3993178109450934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 451402.4850942664, 451402.4850942667, 125587.3869297538]
[2019-03-23 07:57:25,613] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 07:57:25,618] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.42749826e-21 1.00000000e+00 8.79733954e-31 1.20703634e-29
 2.41246265e-33], sampled 0.7594998380772529
[2019-03-23 07:57:31,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7913135]
[2019-03-23 07:57:31,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.76666666666667, 80.66666666666667, 1.0, 2.0, 0.2793269391353065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 303282.7587751945, 303282.7587751942, 89840.95974428006]
[2019-03-23 07:57:31,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:57:31,221] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.42749826e-21 1.00000000e+00 8.79733954e-31 1.20703634e-29
 2.41246265e-33], sampled 0.21920252111402605
[2019-03-23 07:57:39,415] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 07:57:39,774] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 07:57:39,792] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 07:57:39,860] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 07:57:39,974] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 07:57:40,990] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 350000, evaluation results [350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 07:57:50,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7068885e-23 1.0000000e+00 2.6031460e-33 1.5838172e-32 3.9610436e-36], sum to 1.0000
[2019-03-23 07:57:50,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6328
[2019-03-23 07:57:50,141] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 87.0, 1.0, 2.0, 0.4241676682863354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480257.9196881164, 480257.9196881164, 128367.0032555277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5372400.0000, 
sim time next is 5373000.0000, 
raw observation next is [20.25, 87.0, 1.0, 2.0, 0.4171291847205296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471957.3311010795, 471957.3311010795, 127490.0651149099], 
processed observation next is [1.0, 0.17391304347826086, 0.5568181818181818, 0.87, 1.0, 1.0, 0.27141148090066197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17479901151891833, 0.17479901151891833, 0.3109513783290485], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.3594539], dtype=float32), 0.054058854]. 
=============================================
[2019-03-23 07:57:50,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.97862]
 [69.97862]
 [69.97862]
 [69.97862]
 [69.97862]], R is [[69.96788788]
 [69.9551239 ]
 [69.93894196]
 [69.92136383]
 [69.90042114]].
[2019-03-23 07:57:55,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3569020e-23 1.0000000e+00 2.7861403e-32 1.2442922e-30 4.1791382e-34], sum to 1.0000
[2019-03-23 07:57:55,434] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9994
[2019-03-23 07:57:55,441] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.86666666666667, 89.0, 1.0, 2.0, 0.5299926556301009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592268.304087814, 592268.304087814, 135400.5792315545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5473200.0000, 
sim time next is 5473800.0000, 
raw observation next is [19.15, 88.5, 1.0, 2.0, 0.6065721203101838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 680207.5646992063, 680207.5646992065, 144681.3537992015], 
processed observation next is [1.0, 0.34782608695652173, 0.5068181818181817, 0.885, 1.0, 1.0, 0.5082151503877297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2519287276663727, 0.25192872766637275, 0.35288135072975974], 
reward next is 0.6471, 
noisyNet noise sample is [array([-0.59548587], dtype=float32), -1.5223739]. 
=============================================
[2019-03-23 07:57:56,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2590165e-18 1.0000000e+00 9.4487787e-27 7.4005519e-26 1.8289703e-28], sum to 1.0000
[2019-03-23 07:57:56,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8691
[2019-03-23 07:57:56,403] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1450786.705217036 W.
[2019-03-23 07:57:56,412] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 74.0, 1.0, 2.0, 0.6450506143794926, 1.0, 2.0, 0.6450506143794926, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1450786.705217036, 1450786.705217036, 275001.9242805571], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5500800.0000, 
sim time next is 5501400.0000, 
raw observation next is [26.6, 73.16666666666667, 1.0, 2.0, 0.982060339680447, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9849824830636335, 6.911199999999999, 6.9112, 82.18556208740144, 1652836.506529474, 1652836.506529474, 350576.7445227153], 
processed observation next is [1.0, 0.6956521739130435, 0.8454545454545456, 0.7316666666666667, 1.0, 1.0, 0.9775754246005588, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9785464043766193, -8.881784197001253e-17, 0.0, 0.5403638700492557, 0.6121616690849904, 0.6121616690849904, 0.855065230543208], 
reward next is 0.1449, 
noisyNet noise sample is [array([-0.5216967], dtype=float32), 1.4656339]. 
=============================================
[2019-03-23 07:57:59,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4205353e-20 1.0000000e+00 2.1709267e-30 8.3684906e-30 2.0776427e-33], sum to 1.0000
[2019-03-23 07:57:59,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9444
[2019-03-23 07:57:59,768] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1174415.068939021 W.
[2019-03-23 07:57:59,772] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 67.0, 1.0, 2.0, 0.3457794016979339, 1.0, 2.0, 0.3457794016979339, 1.0, 1.0, 0.7000659140766341, 6.9112, 6.9112, 77.3421103, 1174415.068939021, 1174415.068939021, 279664.0091649187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5567400.0000, 
sim time next is 5568000.0000, 
raw observation next is [26.1, 67.0, 1.0, 2.0, 0.5083981393239885, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9558103048433443, 6.945787266173966, 6.9112, 77.32837859542771, 1126612.175775491, 1115378.95147971, 260494.2453470208], 
processed observation next is [1.0, 0.43478260869565216, 0.8227272727272728, 0.67, 1.0, 1.0, 0.38549767415498554, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9368718640619206, 0.003458726617396568, 0.0, 0.5084282550507105, 0.4172637688057374, 0.41310331536285555, 0.635351817919563], 
reward next is 0.1917, 
noisyNet noise sample is [array([-1.2541385], dtype=float32), 0.88249135]. 
=============================================
[2019-03-23 07:57:59,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.733368]
 [63.733368]
 [63.733368]
 [63.733368]
 [63.733368]], R is [[63.28774261]
 [62.65486526]
 [62.44420242]
 [62.14358902]
 [61.84208298]].
[2019-03-23 07:58:06,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.03666723e-22 1.00000000e+00 7.71602280e-33 1.66648950e-30
 1.85689436e-35], sum to 1.0000
[2019-03-23 07:58:06,308] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5878
[2019-03-23 07:58:06,311] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.46666666666667, 75.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 188092.5681780491, 188092.5681780493, 63807.2267195419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5694600.0000, 
sim time next is 5695200.0000, 
raw observation next is [12.2, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 184565.4786423804, 184565.4786423801, 63129.63764594678], 
processed observation next is [0.0, 0.9565217391304348, 0.1909090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06835758468236311, 0.068357584682363, 0.15397472596572384], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04584603], dtype=float32), 0.093418755]. 
=============================================
[2019-03-23 07:58:07,040] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1410832e-20 1.0000000e+00 2.6669668e-30 4.5946692e-26 4.3043131e-30], sum to 1.0000
[2019-03-23 07:58:07,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-23 07:58:07,053] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.4, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 138852.1080439692, 138852.1080439689, 56399.41678450884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5716800.0000, 
sim time next is 5717400.0000, 
raw observation next is [9.3, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 137354.0834759081, 137354.0834759079, 56202.24929729267], 
processed observation next is [0.0, 0.17391304347826086, 0.059090909090909124, 0.8666666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05087188276885485, 0.05087188276885477, 0.13707865682266504], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.69550514], dtype=float32), 0.3843296]. 
=============================================
[2019-03-23 07:58:11,485] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5487276e-21 1.0000000e+00 1.0388408e-29 1.0226761e-30 1.8627137e-33], sum to 1.0000
[2019-03-23 07:58:11,492] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4780
[2019-03-23 07:58:11,497] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.6, 86.0, 1.0, 2.0, 0.3852732637807905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418389.690119029, 418389.6901190293, 86332.38850884326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5806800.0000, 
sim time next is 5807400.0000, 
raw observation next is [11.6, 86.0, 1.0, 2.0, 0.3878979225794706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 421241.1879645906, 421241.1879645909, 86571.13473144796], 
processed observation next is [1.0, 0.21739130434782608, 0.1636363636363636, 0.86, 1.0, 1.0, 0.23487240322433822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15601525480170023, 0.15601525480170034, 0.2111491091010926], 
reward next is 0.7889, 
noisyNet noise sample is [array([-0.19555701], dtype=float32), 0.77764726]. 
=============================================
[2019-03-23 07:58:15,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0899823e-21 1.0000000e+00 9.6976897e-32 2.3348466e-30 1.0637778e-34], sum to 1.0000
[2019-03-23 07:58:15,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6234
[2019-03-23 07:58:15,589] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 40.66666666666667, 1.0, 2.0, 0.3432932622945538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379379.0878351167, 379379.0878351167, 116552.9933833359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5851200.0000, 
sim time next is 5851800.0000, 
raw observation next is [25.8, 41.0, 1.0, 2.0, 0.3315624212703491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366085.0608838564, 366085.0608838561, 115538.019916763], 
processed observation next is [1.0, 0.7391304347826086, 0.8090909090909091, 0.41, 1.0, 1.0, 0.1644530265879363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13558705958661346, 0.13558705958661338, 0.28180004857747076], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.41642195], dtype=float32), 1.0746745]. 
=============================================
[2019-03-23 07:58:15,619] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8996887e-21 1.0000000e+00 2.8617057e-31 3.0562331e-31 7.0774810e-35], sum to 1.0000
[2019-03-23 07:58:15,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8939
[2019-03-23 07:58:15,634] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.46666666666667, 86.0, 1.0, 2.0, 0.2722627157717675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295627.938148035, 295627.938148035, 94429.1354195259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890800.0000, 
sim time next is 5891400.0000, 
raw observation next is [16.65, 84.0, 1.0, 2.0, 0.2680755004307636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291080.0209821147, 291080.0209821144, 93363.86196085908], 
processed observation next is [1.0, 0.17391304347826086, 0.39318181818181813, 0.84, 1.0, 1.0, 0.0850943755384545, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.107807415178561, 0.10780741517856089, 0.2277167364899002], 
reward next is 0.7723, 
noisyNet noise sample is [array([1.32048], dtype=float32), -0.13118666]. 
=============================================
[2019-03-23 07:58:18,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5068798e-22 1.0000000e+00 1.5864378e-29 2.6903460e-30 1.8066383e-32], sum to 1.0000
[2019-03-23 07:58:18,790] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6724
[2019-03-23 07:58:18,795] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 46.0, 1.0, 2.0, 0.866797246354908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 986053.5602475214, 986053.5602475214, 187175.6720445255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5927400.0000, 
sim time next is 5928000.0000, 
raw observation next is [27.7, 46.0, 1.0, 2.0, 0.8898224757092119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012271.283282066, 1012271.283282066, 190903.6903248019], 
processed observation next is [1.0, 0.6086956521739131, 0.8954545454545454, 0.46, 1.0, 1.0, 0.862278094636515, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3749152901044689, 0.3749152901044689, 0.46561875688976073], 
reward next is 0.5344, 
noisyNet noise sample is [array([-0.2622306], dtype=float32), 0.5192026]. 
=============================================
[2019-03-23 07:58:18,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.813156]
 [64.813156]
 [64.813156]
 [64.813156]
 [64.813156]], R is [[64.69940948]
 [64.59588623]
 [63.94992828]
 [63.31042862]
 [62.6773262 ]].
[2019-03-23 07:58:22,662] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5773110e-17 1.0000000e+00 6.4299251e-28 8.0886038e-26 1.8235781e-28], sum to 1.0000
[2019-03-23 07:58:22,673] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5682
[2019-03-23 07:58:22,679] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 78.0, 1.0, 2.0, 0.3887144320611828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437641.6957159674, 437641.6957159677, 123633.4444647453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6028800.0000, 
sim time next is 6029400.0000, 
raw observation next is [20.68333333333334, 78.0, 1.0, 2.0, 0.3824512694785925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 429764.3399916469, 429764.3399916466, 122661.9017050847], 
processed observation next is [1.0, 0.782608695652174, 0.5765151515151519, 0.78, 1.0, 1.0, 0.2280640868482406, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15917197777468403, 0.15917197777468392, 0.29917537001240174], 
reward next is 0.7008, 
noisyNet noise sample is [array([-0.31091473], dtype=float32), 0.50588435]. 
=============================================
[2019-03-23 07:58:24,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4383400e-22 1.0000000e+00 1.0537556e-30 1.9327866e-29 3.4203877e-33], sum to 1.0000
[2019-03-23 07:58:24,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2737
[2019-03-23 07:58:24,888] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 87.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 216430.5110841017, 216430.511084102, 72234.66050897082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6062400.0000, 
sim time next is 6063000.0000, 
raw observation next is [13.9, 86.33333333333333, 1.0, 2.0, 0.2155655147028347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234050.2462237542, 234050.246223754, 73839.09587765177], 
processed observation next is [1.0, 0.17391304347826086, 0.2681818181818182, 0.8633333333333333, 1.0, 1.0, 0.019456893378543352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08668527637916822, 0.08668527637916815, 0.18009535579915065], 
reward next is 0.8199, 
noisyNet noise sample is [array([0.4347515], dtype=float32), -0.0025023122]. 
=============================================
[2019-03-23 07:58:24,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[80.286896]
 [80.286896]
 [80.286896]
 [80.286896]
 [80.286896]], R is [[80.30393982]
 [79.50090027]
 [79.52812958]
 [79.55347443]
 [79.57682037]].
[2019-03-23 07:58:26,964] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.18431820e-21 1.00000000e+00 7.08082062e-30 7.73829022e-30
 1.19174345e-33], sum to 1.0000
[2019-03-23 07:58:26,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0326
[2019-03-23 07:58:26,978] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 44.5, 1.0, 2.0, 0.7655840836858431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 843756.9071680858, 843756.9071680856, 158704.7160967243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6102600.0000, 
sim time next is 6103200.0000, 
raw observation next is [24.6, 44.0, 1.0, 2.0, 0.7323847390892414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 806689.1620915818, 806689.1620915818, 154421.8460857491], 
processed observation next is [1.0, 0.6521739130434783, 0.7545454545454546, 0.44, 1.0, 1.0, 0.6654809238615517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.29877376373762293, 0.29877376373762293, 0.37663864898963195], 
reward next is 0.6234, 
noisyNet noise sample is [array([0.8689782], dtype=float32), 1.3928928]. 
=============================================
[2019-03-23 07:58:27,931] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 07:58:27,932] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 07:58:27,933] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 07:58:27,933] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:27,934] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:27,936] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 07:58:27,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 07:58:27,941] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:27,942] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:27,938] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 07:58:27,944] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 07:58:27,961] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 07:58:27,961] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 07:58:28,009] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 07:58:28,009] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 07:58:28,010] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 07:58:50,611] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7876649]
[2019-03-23 07:58:50,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.83333333333334, 45.16666666666666, 1.0, 2.0, 0.3708547366144315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409589.4401648606, 409589.4401648603, 122924.3921443788]
[2019-03-23 07:58:50,614] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 07:58:50,616] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2263895e-22 1.0000000e+00 1.3137977e-31 1.4264357e-30 1.2752655e-34], sampled 0.6005672500187909
[2019-03-23 07:58:51,548] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7876649]
[2019-03-23 07:58:51,552] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.8226211, 81.16195543, 1.0, 2.0, 0.2495687127899408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 270965.1046318597, 270965.1046318593, 87233.55443238361]
[2019-03-23 07:58:51,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 07:58:51,558] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.2263895e-22 1.0000000e+00 1.3137977e-31 1.4264357e-30 1.2752655e-34], sampled 0.061903566884746075
[2019-03-23 07:59:31,247] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7876649]
[2019-03-23 07:59:31,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.98296243, 41.23823696166667, 1.0, 2.0, 0.3566653409152844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 387280.963723822, 387280.9637238216, 105184.4327937937]
[2019-03-23 07:59:31,250] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 07:59:31,253] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.2263895e-22 1.0000000e+00 1.3137977e-31 1.4264357e-30 1.2752655e-34], sampled 0.5109786813153409
[2019-03-23 08:00:06,059] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7876649]
[2019-03-23 08:00:06,061] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.1, 67.0, 1.0, 2.0, 0.3388482579360163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 368873.7643792812, 368873.7643792809, 118502.9447052766]
[2019-03-23 08:00:06,063] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:00:06,066] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.2263895e-22 1.0000000e+00 1.3137977e-31 1.4264357e-30 1.2752655e-34], sampled 0.7713563322369299
[2019-03-23 08:00:14,814] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:00:14,971] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:00:15,004] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:00:15,048] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:00:15,077] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:00:16,090] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 375000, evaluation results [375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:00:20,170] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.9657129e-21 1.0000000e+00 9.5403921e-31 1.1142851e-27 1.5187327e-32], sum to 1.0000
[2019-03-23 08:00:20,177] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1755
[2019-03-23 08:00:20,183] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.18333333333333, 78.5, 1.0, 2.0, 0.607136479421419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 679379.2565546185, 679379.2565546185, 144112.2768819263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6173400.0000, 
sim time next is 6174000.0000, 
raw observation next is [20.0, 81.0, 1.0, 2.0, 0.641021882680691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718629.9731292045, 718629.9731292045, 148608.7376685615], 
processed observation next is [1.0, 0.4782608695652174, 0.5454545454545454, 0.81, 1.0, 1.0, 0.5512773533508638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26615924930711277, 0.26615924930711277, 0.3624603357769792], 
reward next is 0.6375, 
noisyNet noise sample is [array([-0.9419924], dtype=float32), -0.18760559]. 
=============================================
[2019-03-23 08:00:20,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.587555]
 [67.587555]
 [67.587555]
 [67.587555]
 [67.587555]], R is [[67.54922485]
 [67.52223969]
 [67.49389648]
 [67.4595871 ]
 [67.43408203]].
[2019-03-23 08:00:21,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0486465e-20 1.0000000e+00 1.2988452e-28 1.9339981e-27 2.0069892e-31], sum to 1.0000
[2019-03-23 08:00:21,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2486
[2019-03-23 08:00:21,106] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 86.0, 1.0, 2.0, 0.3697830543445019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414531.1607765463, 414531.1607765463, 121088.3189131088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6216600.0000, 
sim time next is 6217200.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3698578089028812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 414728.2337536541, 414728.2337536538, 121148.5741200161], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.87, 1.0, 1.0, 0.2123222611286015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1536030495383904, 0.1536030495383903, 0.29548432712199046], 
reward next is 0.7045, 
noisyNet noise sample is [array([-1.7650651], dtype=float32), -1.9402725]. 
=============================================
[2019-03-23 08:00:23,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2167714e-20 1.0000000e+00 5.1712385e-30 1.4659522e-27 7.1551104e-30], sum to 1.0000
[2019-03-23 08:00:24,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8071
[2019-03-23 08:00:24,010] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.56666666666667, 61.0, 1.0, 2.0, 0.5197404895094809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591727.4559257032, 591727.4559257032, 145491.4304904203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6291600.0000, 
sim time next is 6292200.0000, 
raw observation next is [27.38333333333333, 61.5, 1.0, 2.0, 0.516469535808542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588194.15718223, 588194.15718223, 144941.6268417915], 
processed observation next is [0.0, 0.8260869565217391, 0.8810606060606059, 0.615, 1.0, 1.0, 0.3955869197606775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2178496878452704, 0.2178496878452704, 0.35351616302875977], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.3937063], dtype=float32), 0.49223953]. 
=============================================
[2019-03-23 08:00:25,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5477162e-22 1.0000000e+00 6.1428655e-32 9.5686122e-29 1.0667896e-33], sum to 1.0000
[2019-03-23 08:00:25,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0835
[2019-03-23 08:00:25,869] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.4777361100270023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545131.0965589774, 545131.0965589777, 138579.9366812806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6321000.0000, 
sim time next is 6321600.0000, 
raw observation next is [22.7, 85.0, 1.0, 2.0, 0.4782250132856208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545689.2618589527, 545689.2618589527, 138634.9536247953], 
processed observation next is [0.0, 0.17391304347826086, 0.6681818181818181, 0.85, 1.0, 1.0, 0.34778126660702596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20210713402183433, 0.20210713402183433, 0.33813403323120805], 
reward next is 0.6619, 
noisyNet noise sample is [array([1.61277], dtype=float32), -1.0283275]. 
=============================================
[2019-03-23 08:00:31,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5912009e-18 1.0000000e+00 1.3631275e-27 7.6501108e-25 4.0040494e-30], sum to 1.0000
[2019-03-23 08:00:31,333] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8779
[2019-03-23 08:00:31,343] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 69.0, 1.0, 2.0, 0.4923908517642505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561840.4098331841, 561840.4098331841, 139698.3263816008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6412800.0000, 
sim time next is 6413400.0000, 
raw observation next is [24.7, 69.5, 1.0, 2.0, 0.4823267385159533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550341.9150289552, 550341.9150289549, 138518.8678782719], 
processed observation next is [1.0, 0.21739130434782608, 0.759090909090909, 0.695, 1.0, 1.0, 0.3529084231449416, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20383033889961305, 0.2038303388996129, 0.3378508972640778], 
reward next is 0.6621, 
noisyNet noise sample is [array([0.20653436], dtype=float32), -0.7403394]. 
=============================================
[2019-03-23 08:00:31,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7904712e-20 1.0000000e+00 1.2325022e-28 5.3437937e-26 1.4352343e-30], sum to 1.0000
[2019-03-23 08:00:31,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5137
[2019-03-23 08:00:31,606] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 71.0, 1.0, 2.0, 0.4996071057931144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570109.6660890097, 570109.6660890097, 140908.6479364231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6417000.0000, 
sim time next is 6417600.0000, 
raw observation next is [24.8, 71.0, 1.0, 2.0, 0.4880595761522142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556913.5545409712, 556913.5545409712, 139786.7202246134], 
processed observation next is [1.0, 0.2608695652173913, 0.7636363636363637, 0.71, 1.0, 1.0, 0.36007447019026767, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20626427945961895, 0.20626427945961895, 0.3409432200600327], 
reward next is 0.6591, 
noisyNet noise sample is [array([1.3157945], dtype=float32), 0.46325597]. 
=============================================
[2019-03-23 08:00:32,539] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0573578e-18 1.0000000e+00 1.4851219e-29 7.8846633e-28 5.2952794e-32], sum to 1.0000
[2019-03-23 08:00:32,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0023
[2019-03-23 08:00:32,552] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.5, 1.0, 2.0, 0.6877517811037676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 764562.1478641469, 764562.1478641466, 151647.6333088212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.6484053451344275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 721084.84347598, 721084.84347598, 147102.260026851], 
processed observation next is [1.0, 0.6086956521739131, 0.45909090909090916, 0.91, 1.0, 1.0, 0.5605066814180343, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2670684605466593, 0.2670684605466593, 0.3587860000654902], 
reward next is 0.6412, 
noisyNet noise sample is [array([-0.37590334], dtype=float32), 0.29829016]. 
=============================================
[2019-03-23 08:00:41,519] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3448833e-19 1.0000000e+00 4.1048433e-28 1.2402045e-27 1.2012068e-30], sum to 1.0000
[2019-03-23 08:00:41,525] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4643
[2019-03-23 08:00:41,538] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 65.33333333333334, 1.0, 2.0, 0.3653103193061307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396701.9733304573, 396701.9733304576, 101766.790070432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [19.11666666666667, 64.16666666666666, 1.0, 2.0, 0.3500878191217993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380164.9190648041, 380164.9190648038, 101024.6840278127], 
processed observation next is [1.0, 0.391304347826087, 0.5053030303030305, 0.6416666666666666, 1.0, 1.0, 0.18760977390224912, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14080182187585336, 0.14080182187585327, 0.2464016683605188], 
reward next is 0.7536, 
noisyNet noise sample is [array([-1.6556016], dtype=float32), 1.2437514]. 
=============================================
[2019-03-23 08:00:41,955] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1303529e-19 1.0000000e+00 7.1732880e-29 2.7793823e-29 3.0567461e-31], sum to 1.0000
[2019-03-23 08:00:41,962] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2806
[2019-03-23 08:00:41,967] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.11666666666667, 64.16666666666666, 1.0, 2.0, 0.3500878191217993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380164.9190648041, 380164.9190648038, 101024.6840278127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6601800.0000, 
sim time next is 6602400.0000, 
raw observation next is [19.4, 63.0, 1.0, 2.0, 0.3764471005033654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408800.8385666298, 408800.8385666301, 104562.6630565849], 
processed observation next is [1.0, 0.43478260869565216, 0.5181818181818181, 0.63, 1.0, 1.0, 0.2205588756292067, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15140771798764066, 0.15140771798764077, 0.2550308855038656], 
reward next is 0.7450, 
noisyNet noise sample is [array([1.1212361], dtype=float32), -1.017495]. 
=============================================
[2019-03-23 08:00:51,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8902032e-19 1.0000000e+00 5.7079034e-30 4.0703543e-27 2.7079617e-31], sum to 1.0000
[2019-03-23 08:00:51,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8793
[2019-03-23 08:00:51,329] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 75.5, 1.0, 2.0, 0.3890993787932143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438551.4411517213, 438551.4411517213, 123920.3018220047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6823800.0000, 
sim time next is 6824400.0000, 
raw observation next is [21.26666666666667, 75.33333333333334, 1.0, 2.0, 0.3856502247825531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434209.9446052766, 434209.9446052763, 123373.477355076], 
processed observation next is [1.0, 1.0, 0.6030303030303031, 0.7533333333333334, 1.0, 1.0, 0.23206278097819139, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1608184980019543, 0.1608184980019542, 0.30091092037823414], 
reward next is 0.6991, 
noisyNet noise sample is [array([-0.40778372], dtype=float32), 1.1642469]. 
=============================================
[2019-03-23 08:00:55,508] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4689103e-20 1.0000000e+00 6.8644032e-31 1.2160776e-27 3.8060401e-31], sum to 1.0000
[2019-03-23 08:00:55,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2121
[2019-03-23 08:00:55,523] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 92.5, 1.0, 2.0, 0.3797962723295398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426652.6900499956, 426652.6900499956, 122369.2273509117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6916200.0000, 
sim time next is 6916800.0000, 
raw observation next is [19.0, 92.0, 1.0, 2.0, 0.3798985508057527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426949.0120024701, 426949.0120024699, 122468.327602911], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.92, 1.0, 1.0, 0.22487318850719085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15812926370461855, 0.1581292637046185, 0.2987032380558805], 
reward next is 0.7013, 
noisyNet noise sample is [array([-1.1299943], dtype=float32), -1.6793551]. 
=============================================
[2019-03-23 08:01:03,649] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 08:01:03,652] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:01:03,653] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:01:03,653] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:01:03,654] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:01:03,655] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:01:03,654] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:01:03,656] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:01:03,656] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:01:03,655] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:01:03,662] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:01:03,673] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 08:01:03,674] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 08:01:03,722] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 08:01:03,723] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 08:01:03,782] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 08:01:18,001] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78689307]
[2019-03-23 08:01:18,005] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 100.0, 1.0, 2.0, 0.5059398224912555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551041.5014549637, 551041.5014549637, 127877.3690262953]
[2019-03-23 08:01:18,006] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:01:18,012] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.2417535e-20 1.0000000e+00 5.4507832e-29 5.6758181e-28 1.4769735e-31], sampled 0.681736199260181
[2019-03-23 08:01:46,373] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78689307]
[2019-03-23 08:01:46,375] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 90.0, 1.0, 2.0, 0.4555297149250495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 518972.9293901219, 518972.9293901219, 138423.415080414]
[2019-03-23 08:01:46,377] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:01:46,380] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.2417535e-20 1.0000000e+00 5.4507832e-29 5.6758181e-28 1.4769735e-31], sampled 0.5111497695108667
[2019-03-23 08:02:41,315] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78689307]
[2019-03-23 08:02:41,316] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.322953615, 52.49426958833333, 1.0, 2.0, 0.3074063445467252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 333778.7945281302, 333778.7945281298, 104212.0172403408]
[2019-03-23 08:02:41,317] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:02:41,319] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.2417535e-20 1.0000000e+00 5.4507832e-29 5.6758181e-28 1.4769735e-31], sampled 0.9754377059030324
[2019-03-23 08:02:47,789] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78689307]
[2019-03-23 08:02:47,792] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.98333333333333, 64.5, 1.0, 2.0, 0.2597973704069453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 282073.3065414714, 282073.306541471, 88287.48332485445]
[2019-03-23 08:02:47,792] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:02:47,797] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2417535e-20 1.0000000e+00 5.4507832e-29 5.6758181e-28 1.4769735e-31], sampled 0.3108369323469804
[2019-03-23 08:02:48,195] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.78689307]
[2019-03-23 08:02:48,199] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.05, 69.0, 1.0, 2.0, 0.313159158309577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 340026.9103554458, 340026.9103554455, 109068.8446373492]
[2019-03-23 08:02:48,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:02:48,203] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.2417535e-20 1.0000000e+00 5.4507832e-29 5.6758181e-28 1.4769735e-31], sampled 0.5481853524183797
[2019-03-23 08:02:50,466] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:02:50,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:02:50,525] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:02:50,581] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:02:50,712] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:02:51,728] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 400000, evaluation results [400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:02:54,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0477095e-20 1.0000000e+00 5.1329922e-30 3.5830971e-27 1.1561983e-31], sum to 1.0000
[2019-03-23 08:02:54,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8564
[2019-03-23 08:02:54,519] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.5, 1.0, 2.0, 0.3615684468836178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400648.5718287999, 400648.5718287999, 118383.5173765796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7111800.0000, 
sim time next is 7112400.0000, 
raw observation next is [18.1, 91.0, 1.0, 2.0, 0.3747073491734111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415492.404664038, 415492.404664038, 119546.6899491104], 
processed observation next is [1.0, 0.30434782608695654, 0.45909090909090916, 0.91, 1.0, 1.0, 0.21838418646676383, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15388607580149555, 0.15388607580149555, 0.2915772925588058], 
reward next is 0.7084, 
noisyNet noise sample is [array([1.0306466], dtype=float32), 1.9355137]. 
=============================================
[2019-03-23 08:03:02,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2307019e-22 1.0000000e+00 1.0584404e-31 6.9361506e-33 1.0559585e-34], sum to 1.0000
[2019-03-23 08:03:02,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3423
[2019-03-23 08:03:02,563] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 78.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213937.3225981067, 213937.322598107, 70172.33887510996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7279800.0000, 
sim time next is 7280400.0000, 
raw observation next is [14.0, 79.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 215220.4321727393, 215220.4321727393, 70643.14368429742], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.79, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07971127117508862, 0.07971127117508862, 0.1723003504495059], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18730365], dtype=float32), -0.06140291]. 
=============================================
[2019-03-23 08:03:08,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.7867069e-22 1.0000000e+00 1.7060669e-31 1.0358966e-29 9.4835192e-34], sum to 1.0000
[2019-03-23 08:03:08,236] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2077
[2019-03-23 08:03:08,242] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3547531767705037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387599.1478664508, 387599.1478664511, 115822.271239689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7355400.0000, 
sim time next is 7356000.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3474410204705829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379624.4318080782, 379624.4318080782, 115285.1861668952], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.1843012755882286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14060164141039933, 0.14060164141039933, 0.28118338089486633], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.30583465], dtype=float32), 1.5644163]. 
=============================================
[2019-03-23 08:03:08,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.701294]
 [66.701294]
 [66.701294]
 [66.701294]
 [66.701294]], R is [[66.7530899 ]
 [66.80306244]
 [66.85640717]
 [66.90830994]
 [66.95858002]].
[2019-03-23 08:03:17,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.122878e-19 1.000000e+00 2.984918e-27 5.734541e-26 4.288659e-31], sum to 1.0000
[2019-03-23 08:03:17,479] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1555
[2019-03-23 08:03:17,484] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 88.66666666666667, 1.0, 2.0, 0.4627581469059572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527898.2850271725, 527898.2850271729, 135979.9116971487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7526400.0000, 
sim time next is 7527000.0000, 
raw observation next is [21.68333333333334, 89.33333333333333, 1.0, 2.0, 0.4628072318083563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527955.8341804642, 527955.8341804642, 135989.5323255285], 
processed observation next is [0.0, 0.08695652173913043, 0.6219696969696973, 0.8933333333333333, 1.0, 1.0, 0.3285090397604454, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19553919784461635, 0.19553919784461635, 0.33168178615982563], 
reward next is 0.6683, 
noisyNet noise sample is [array([-1.0986304], dtype=float32), 1.6555138]. 
=============================================
[2019-03-23 08:03:17,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.60874]
 [66.60874]
 [66.60874]
 [66.60874]
 [66.60874]], R is [[66.61097717]
 [66.61321259]
 [66.61553192]
 [66.61793518]
 [66.6203537 ]].
[2019-03-23 08:03:23,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9843673e-18 1.0000000e+00 2.8507193e-26 7.2582155e-26 2.0281254e-29], sum to 1.0000
[2019-03-23 08:03:23,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0268
[2019-03-23 08:03:23,670] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.4548205132260611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518376.2376988184, 518376.2376988187, 134256.7242074315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7687800.0000, 
sim time next is 7688400.0000, 
raw observation next is [20.7, 93.0, 1.0, 2.0, 0.4503933636229362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513159.7977592946, 513159.7977592949, 133565.4960077753], 
processed observation next is [1.0, 1.0, 0.5772727272727273, 0.93, 1.0, 1.0, 0.3129917045286702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1900591843552943, 0.19005918435529442, 0.3257695024579885], 
reward next is 0.6742, 
noisyNet noise sample is [array([0.94404685], dtype=float32), -1.1157645]. 
=============================================
[2019-03-23 08:03:25,265] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5389279e-18 1.0000000e+00 2.4311185e-30 1.9363013e-27 1.1642572e-32], sum to 1.0000
[2019-03-23 08:03:25,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1666
[2019-03-23 08:03:25,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.36666666666667, 92.0, 1.0, 2.0, 0.3469651071611716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381095.3952477689, 381095.3952477689, 115955.5522849763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716000.0000, 
sim time next is 7716600.0000, 
raw observation next is [17.45, 90.0, 1.0, 2.0, 0.3346431868647288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366543.4347967065, 366543.4347967068, 114670.8520966414], 
processed observation next is [1.0, 0.30434782608695654, 0.4295454545454545, 0.9, 1.0, 1.0, 0.168303983580911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13575682770248387, 0.13575682770248398, 0.27968500511375954], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.59659976], dtype=float32), -0.97757983]. 
=============================================
[2019-03-23 08:03:31,035] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7850238e-22 1.0000000e+00 1.7698591e-30 5.1511001e-29 2.2915792e-33], sum to 1.0000
[2019-03-23 08:03:31,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7471
[2019-03-23 08:03:31,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 76.33333333333333, 1.0, 2.0, 0.632160765967864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 709381.9521154106, 709381.9521154104, 147867.8847833989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7811400.0000, 
sim time next is 7812000.0000, 
raw observation next is [21.1, 78.0, 1.0, 2.0, 0.6992608041949627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 788966.6708032249, 788966.6708032249, 158169.6690760519], 
processed observation next is [1.0, 0.43478260869565216, 0.5954545454545456, 0.78, 1.0, 1.0, 0.6240760052437033, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2922098780752685, 0.2922098780752685, 0.3857796806732973], 
reward next is 0.6142, 
noisyNet noise sample is [array([-0.34817], dtype=float32), -0.3467792]. 
=============================================
[2019-03-23 08:03:31,077] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.86372]
 [68.86372]
 [68.86372]
 [68.86372]
 [68.86372]], R is [[68.78929901]
 [68.74075317]
 [68.70205688]
 [68.66947937]
 [68.64903259]].
[2019-03-23 08:03:32,405] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8927181e-23 1.0000000e+00 1.9270128e-31 1.8564812e-30 5.9313695e-36], sum to 1.0000
[2019-03-23 08:03:32,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0977
[2019-03-23 08:03:32,432] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 44.0, 1.0, 2.0, 0.6658318052701703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 726453.9206971168, 726453.920697117, 144318.6525982331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7834800.0000, 
sim time next is 7835400.0000, 
raw observation next is [23.85, 45.0, 1.0, 2.0, 0.6805396577942406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 742921.5804463915, 742921.5804463915, 146083.943892935], 
processed observation next is [1.0, 0.6956521739130435, 0.7204545454545456, 0.45, 1.0, 1.0, 0.6006745722428007, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27515614090607093, 0.27515614090607093, 0.3563023021778902], 
reward next is 0.6437, 
noisyNet noise sample is [array([-0.9940634], dtype=float32), -1.7206291]. 
=============================================
[2019-03-23 08:03:33,363] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0019339e-19 1.0000000e+00 1.6880072e-29 3.9003933e-28 7.3820616e-32], sum to 1.0000
[2019-03-23 08:03:33,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-23 08:03:33,382] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 75.16666666666666, 1.0, 2.0, 0.3286547206120062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363217.3465753085, 363217.3465753088, 115456.8630611512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7887000.0000, 
sim time next is 7887600.0000, 
raw observation next is [20.0, 75.0, 1.0, 2.0, 0.3436344146293116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380259.2222732464, 380259.2222732467, 116776.6780924329], 
processed observation next is [1.0, 0.30434782608695654, 0.5454545454545454, 0.75, 1.0, 1.0, 0.1795430182866395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14083674899009124, 0.14083674899009135, 0.2848211660791046], 
reward next is 0.7152, 
noisyNet noise sample is [array([0.771959], dtype=float32), 0.31062588]. 
=============================================
[2019-03-23 08:03:36,794] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:36,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:36,834] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 08:03:37,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,231] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,232] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 08:03:37,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,254] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,264] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 08:03:37,289] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,290] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,294] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 08:03:37,440] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,441] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,442] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 08:03:37,463] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,463] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,465] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 08:03:37,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 08:03:37,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,860] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 08:03:37,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,888] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,890] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 08:03:37,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:37,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:37,927] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 08:03:38,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:38,049] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:38,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 08:03:38,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:38,101] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:38,103] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 08:03:38,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:38,193] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:38,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 08:03:38,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:38,239] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:38,240] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 08:03:38,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:38,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:38,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 08:03:38,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:03:38,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:38,355] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 08:03:41,132] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 08:03:41,137] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:03:41,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:41,139] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:03:41,139] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:41,140] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:03:41,140] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:03:41,142] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:03:41,142] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:41,145] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:41,144] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:03:41,157] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 08:03:41,183] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 08:03:41,183] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 08:03:41,230] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 08:03:41,231] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 08:04:31,495] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77310896]
[2019-03-23 08:04:31,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.0, 79.0, 1.0, 2.0, 0.8228814720053923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769671782, 939046.4346401166, 939046.434640117, 188946.442252606]
[2019-03-23 08:04:31,498] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:04:31,502] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3642292e-20 1.0000000e+00 4.2476662e-29 4.8738228e-28 1.5397868e-31], sampled 0.5491549263959743
[2019-03-23 08:04:31,891] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77310896]
[2019-03-23 08:04:31,891] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.5301341061760175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604587.7899913618, 604587.789991362, 145709.1961343667]
[2019-03-23 08:04:31,894] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:04:31,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3642292e-20 1.0000000e+00 4.2476662e-29 4.8738228e-28 1.5397868e-31], sampled 0.3682877701240532
[2019-03-23 08:04:32,923] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77310896]
[2019-03-23 08:04:32,924] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.48333333333333, 86.66666666666667, 1.0, 2.0, 0.5086770622484811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 579136.125081896, 579136.1250818956, 148400.2011640092]
[2019-03-23 08:04:32,926] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:04:32,929] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3642292e-20 1.0000000e+00 4.2476662e-29 4.8738228e-28 1.5397868e-31], sampled 0.5513996730436113
[2019-03-23 08:04:54,158] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77310896]
[2019-03-23 08:04:54,159] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.28333333333333, 49.83333333333334, 1.0, 2.0, 0.4918895719045538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 556986.9313430911, 556986.9313430907, 139523.5353119036]
[2019-03-23 08:04:54,160] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:04:54,163] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.3642292e-20 1.0000000e+00 4.2476662e-29 4.8738228e-28 1.5397868e-31], sampled 0.30661905647110443
[2019-03-23 08:05:13,306] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77310896]
[2019-03-23 08:05:13,310] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 90.5, 1.0, 2.0, 0.6169051775884146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 703929.898991399, 703929.898991399, 159272.9809944744]
[2019-03-23 08:05:13,311] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:05:13,314] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3642292e-20 1.0000000e+00 4.2476662e-29 4.8738228e-28 1.5397868e-31], sampled 0.05844450525795808
[2019-03-23 08:05:26,664] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:05:27,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:05:27,400] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:05:27,464] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:05:27,560] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:05:28,575] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 425000, evaluation results [425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:05:30,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4186774e-20 1.0000000e+00 6.0781704e-28 1.4830740e-27 1.6443049e-31], sum to 1.0000
[2019-03-23 08:05:30,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0059
[2019-03-23 08:05:30,061] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 77.0, 1.0, 2.0, 0.2031448404251347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220561.4421770214, 220561.4421770211, 70901.30757369564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 108000.0000, 
sim time next is 108600.0000, 
raw observation next is [14.0, 77.83333333333334, 1.0, 2.0, 0.2257638860057079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 245125.917542537, 245125.9175425367, 73095.08411322151], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.7783333333333334, 1.0, 1.0, 0.032204857507134865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0907873768676063, 0.09078737686760618, 0.17828069295907686], 
reward next is 0.8217, 
noisyNet noise sample is [array([-1.3408175], dtype=float32), 0.22243579]. 
=============================================
[2019-03-23 08:05:31,997] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7522468e-21 1.0000000e+00 1.3806200e-30 1.5496037e-31 4.0252673e-34], sum to 1.0000
[2019-03-23 08:05:32,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0250
[2019-03-23 08:05:32,012] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 74.83333333333334, 1.0, 2.0, 0.2562709801893092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 278258.845760281, 278258.8457602813, 81811.19727544353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 115800.0000, 
sim time next is 116400.0000, 
raw observation next is [16.66666666666667, 72.66666666666667, 1.0, 2.0, 0.3452893481345998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374952.1879471433, 374952.1879471436, 91139.18800610153], 
processed observation next is [1.0, 0.34782608695652173, 0.39393939393939414, 0.7266666666666667, 1.0, 1.0, 0.18161168516824977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13887118072116417, 0.1388711807211643, 0.22229070245390617], 
reward next is 0.7777, 
noisyNet noise sample is [array([0.25202394], dtype=float32), -0.6952542]. 
=============================================
[2019-03-23 08:05:32,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1080233e-22 1.0000000e+00 7.7710921e-31 3.8576717e-29 5.2232903e-34], sum to 1.0000
[2019-03-23 08:05:32,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7533
[2019-03-23 08:05:32,369] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 87.00000000000001, 1.0, 2.0, 0.2070469349687024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224799.0614036791, 224799.0614036794, 71286.06792038484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 101400.0000, 
sim time next is 102000.0000, 
raw observation next is [13.0, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215987.5512676287, 215987.5512676284, 70400.31529073832], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.079995389358381, 0.0799953893583809, 0.1717080860749715], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3261455], dtype=float32), -1.7236348]. 
=============================================
[2019-03-23 08:05:32,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.50999]
 [75.50999]
 [75.50999]
 [75.50999]
 [75.50999]], R is [[74.75489044]
 [74.83347321]
 [74.08513641]
 [73.34428406]
 [72.61083984]].
[2019-03-23 08:05:35,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5487981e-23 1.0000000e+00 2.0055025e-33 4.4967887e-32 3.4227597e-35], sum to 1.0000
[2019-03-23 08:05:35,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5197
[2019-03-23 08:05:35,133] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213865.8742959758, 213865.8742959755, 70959.16391505473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 174000.0000, 
sim time next is 174600.0000, 
raw observation next is [13.5, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215299.5504112877, 215299.5504112874, 71551.4058464802], 
processed observation next is [0.0, 0.0, 0.25, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07974057422640285, 0.07974057422640274, 0.17451562401580534], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8500999], dtype=float32), 1.2159985]. 
=============================================
[2019-03-23 08:05:40,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6982133e-19 1.0000000e+00 2.0082165e-29 2.2307954e-27 1.4594990e-31], sum to 1.0000
[2019-03-23 08:05:40,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0830
[2019-03-23 08:05:40,642] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 216077.4715789966, 216077.4715789963, 73476.71675681349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 263400.0000, 
sim time next is 264000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214087.4269661705, 214087.4269661702, 73120.03394991366], 
processed observation next is [0.0, 0.043478260869565216, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07929163961710019, 0.07929163961710008, 0.17834154621930162], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22703108], dtype=float32), 1.2180909]. 
=============================================
[2019-03-23 08:05:40,658] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.45423]
 [77.45423]
 [77.45423]
 [77.45423]
 [77.45423]], R is [[76.67967987]
 [75.91288757]
 [75.97366333]
 [76.03149414]
 [76.08622742]].
[2019-03-23 08:05:42,120] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0520850e-22 1.0000000e+00 5.7015432e-32 2.7642830e-29 2.2205568e-34], sum to 1.0000
[2019-03-23 08:05:42,129] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4298
[2019-03-23 08:05:42,132] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.2304661443550527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250232.7657622141, 250232.7657622141, 84112.44002442757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 294600.0000, 
sim time next is 295200.0000, 
raw observation next is [17.0, 77.0, 1.0, 2.0, 0.2325307112831407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 252474.9882886493, 252474.9882886496, 84834.08271490256], 
processed observation next is [0.0, 0.43478260869565216, 0.4090909090909091, 0.77, 1.0, 1.0, 0.04066338910392587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09350925492172196, 0.09350925492172207, 0.206912396865616], 
reward next is 0.7931, 
noisyNet noise sample is [array([-1.1627384], dtype=float32), -0.19324332]. 
=============================================
[2019-03-23 08:05:42,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4417105e-22 1.0000000e+00 2.1191169e-30 6.1551832e-31 1.2317036e-35], sum to 1.0000
[2019-03-23 08:05:42,569] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-23 08:05:42,574] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 57.83333333333334, 1.0, 2.0, 0.2131427318394664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 231419.08407271, 231419.08407271, 73272.85854145592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 334200.0000, 
sim time next is 334800.0000, 
raw observation next is [17.0, 59.0, 1.0, 2.0, 0.2111448690577643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229249.3993389895, 229249.3993389892, 73072.93832358073], 
processed observation next is [0.0, 0.9130434782608695, 0.4090909090909091, 0.59, 1.0, 1.0, 0.013931086322205369, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08490718494036648, 0.08490718494036636, 0.17822667883800178], 
reward next is 0.8218, 
noisyNet noise sample is [array([0.02194779], dtype=float32), -0.49259016]. 
=============================================
[2019-03-23 08:05:43,454] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9510526e-23 1.0000000e+00 2.2880678e-33 1.6669401e-31 2.2185225e-36], sum to 1.0000
[2019-03-23 08:05:43,462] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5085
[2019-03-23 08:05:43,465] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 42.33333333333333, 1.0, 2.0, 0.2667977207520466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289692.1772247163, 289692.1772247161, 84676.43148873048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 319200.0000, 
sim time next is 319800.0000, 
raw observation next is [21.33333333333333, 42.66666666666667, 1.0, 2.0, 0.2631046430422813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285681.0112302873, 285681.011230287, 83167.24853840575], 
processed observation next is [0.0, 0.6956521739130435, 0.6060606060606059, 0.4266666666666667, 1.0, 1.0, 0.07888080380285163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10580778193714345, 0.10580778193714334, 0.20284694765464817], 
reward next is 0.7972, 
noisyNet noise sample is [array([0.1682769], dtype=float32), 0.14864826]. 
=============================================
[2019-03-23 08:05:46,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.2470958e-23 1.0000000e+00 1.5729672e-32 6.2766726e-33 1.8955707e-35], sum to 1.0000
[2019-03-23 08:05:46,074] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9399
[2019-03-23 08:05:46,080] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214547.6509340604, 214547.6509340601, 73200.17948993316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 429000.0000, 
sim time next is 429600.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212313.4768847729, 212313.4768847729, 72810.04844572564], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07863462106843441, 0.07863462106843441, 0.17758548401396498], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9548492], dtype=float32), 1.0170547]. 
=============================================
[2019-03-23 08:05:57,229] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3416955e-22 1.0000000e+00 7.1166121e-32 1.5366198e-29 8.0178523e-34], sum to 1.0000
[2019-03-23 08:05:57,239] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7118
[2019-03-23 08:05:57,242] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3078670869670665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335100.3622964508, 335100.3622964508, 112001.2592022617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 594600.0000, 
sim time next is 595200.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.30829610845615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335555.948349335, 335555.948349335, 112026.558539967], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.83, 1.0, 1.0, 0.1353701355701875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12427998087012407, 0.12427998087012407, 0.2732355086340658], 
reward next is 0.7268, 
noisyNet noise sample is [array([1.2031255], dtype=float32), 0.49988794]. 
=============================================
[2019-03-23 08:06:02,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6165202e-20 1.0000000e+00 1.1872202e-32 5.9093706e-29 3.1084115e-33], sum to 1.0000
[2019-03-23 08:06:02,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0528
[2019-03-23 08:06:02,522] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3443339493553961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 378623.7305442077, 378623.730544208, 115912.6665346425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 716400.0000, 
sim time next is 717000.0000, 
raw observation next is [18.5, 85.50000000000001, 1.0, 2.0, 0.3661063907910506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404040.9476774669, 404040.9476774669, 118116.3188571738], 
processed observation next is [1.0, 0.30434782608695654, 0.4772727272727273, 0.8550000000000001, 1.0, 1.0, 0.20763298848881326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14964479543609885, 0.14964479543609885, 0.2880885825784727], 
reward next is 0.7119, 
noisyNet noise sample is [array([-0.61281526], dtype=float32), 0.52985597]. 
=============================================
[2019-03-23 08:06:02,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.384926]
 [73.384926]
 [73.384926]
 [73.384926]
 [73.384926]], R is [[73.36299896]
 [73.3466568 ]
 [73.33162689]
 [73.32142639]
 [73.31502533]].
[2019-03-23 08:06:06,924] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5034460e-21 1.0000000e+00 1.8353285e-30 5.0594308e-30 7.4535063e-33], sum to 1.0000
[2019-03-23 08:06:06,931] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4815
[2019-03-23 08:06:06,935] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3849685324820958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433786.9790718399, 433786.9790718399, 123496.6490426247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798000.0000, 
sim time next is 798600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3848651857781222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433670.330040581, 433670.330040581, 123487.4432987869], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.2310814822226527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16061864075577073, 0.16061864075577073, 0.3011888860946022], 
reward next is 0.6988, 
noisyNet noise sample is [array([-0.82027304], dtype=float32), -0.028345473]. 
=============================================
[2019-03-23 08:06:09,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9990864e-19 1.0000000e+00 1.3981720e-25 8.7438310e-26 1.3596583e-27], sum to 1.0000
[2019-03-23 08:06:09,109] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9758
[2019-03-23 08:06:09,115] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 64.5, 1.0, 2.0, 0.4980718649468754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 568167.5274747323, 568167.527474732, 141579.4455311811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 849000.0000, 
sim time next is 849600.0000, 
raw observation next is [26.0, 65.0, 1.0, 2.0, 0.4949603408797209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564675.9708159412, 564675.9708159412, 141071.1400197984], 
processed observation next is [0.0, 0.8695652173913043, 0.8181818181818182, 0.65, 1.0, 1.0, 0.3687004260996511, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2091392484503486, 0.2091392484503486, 0.34407595126780094], 
reward next is 0.6559, 
noisyNet noise sample is [array([-0.99994224], dtype=float32), 0.16294587]. 
=============================================
[2019-03-23 08:06:14,240] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5191076e-19 1.0000000e+00 2.8767567e-30 6.2734096e-28 9.6750026e-32], sum to 1.0000
[2019-03-23 08:06:14,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3873
[2019-03-23 08:06:14,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 79.66666666666667, 1.0, 2.0, 0.4217424828548736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479110.8966557969, 479110.8966557969, 129268.9304841232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 925800.0000, 
sim time next is 926400.0000, 
raw observation next is [21.66666666666667, 81.33333333333334, 1.0, 2.0, 0.4255865437965282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 483645.9776865123, 483645.9776865123, 129781.0824330139], 
processed observation next is [0.0, 0.7391304347826086, 0.6212121212121214, 0.8133333333333335, 1.0, 1.0, 0.28198317974566023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17912813988389345, 0.17912813988389345, 0.31653922544637536], 
reward next is 0.6835, 
noisyNet noise sample is [array([-0.19898623], dtype=float32), -1.6517975]. 
=============================================
[2019-03-23 08:06:16,429] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 08:06:16,431] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:06:16,432] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:16,432] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:06:16,434] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:06:16,435] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:06:16,436] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:06:16,437] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:16,438] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:16,439] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:16,441] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:06:16,461] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 08:06:16,484] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 08:06:16,511] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 08:06:16,531] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 08:06:16,554] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 08:06:24,107] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:06:24,110] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.33333333333333, 92.0, 1.0, 2.0, 0.223684686222919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242867.8371630927, 242867.8371630927, 78221.6641278843]
[2019-03-23 08:06:24,111] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:06:24,115] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.2271738110471505
[2019-03-23 08:06:36,224] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:06:36,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.4490835248102694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510397.62373745, 510397.6237374496, 136510.8769118975]
[2019-03-23 08:06:36,228] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:06:36,232] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.7443353370297462
[2019-03-23 08:06:55,922] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:06:55,923] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.230791865, 50.28482734666667, 1.0, 2.0, 0.4355234362495035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 495203.330282917, 495203.330282917, 135337.5432254217]
[2019-03-23 08:06:55,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:06:55,929] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.5272964209744323
[2019-03-23 08:07:04,266] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:07:04,267] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.93333333333333, 61.66666666666667, 1.0, 2.0, 0.7510458406516681, 1.0, 2.0, 0.7510458406516681, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1689536.882609931, 1689536.882609931, 308302.1962937382]
[2019-03-23 08:07:04,269] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:07:04,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.7616392595704307
[2019-03-23 08:07:04,273] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1689536.882609931 W.
[2019-03-23 08:07:21,462] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:07:21,465] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.98333333333333, 71.66666666666667, 1.0, 2.0, 0.2650841585623034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 287814.7767980809, 287814.7767980805, 95681.50194536641]
[2019-03-23 08:07:21,466] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:07:21,470] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.3786657428443745
[2019-03-23 08:07:42,356] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:07:42,360] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.3, 48.0, 1.0, 2.0, 0.343088620545609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 379304.0481854553, 379304.048185455, 120913.4324572513]
[2019-03-23 08:07:42,362] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:07:42,366] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.989650911941935
[2019-03-23 08:07:44,707] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:07:44,707] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.05, 70.0, 1.0, 2.0, 0.4503965243124412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 513348.6113925626, 513348.6113925626, 138199.7665695357]
[2019-03-23 08:07:44,709] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:07:44,712] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.6586323974636814
[2019-03-23 08:07:49,398] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9777966]
[2019-03-23 08:07:49,399] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.57196818833333, 40.9024027, 1.0, 2.0, 0.5519244408887498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 623060.3141730145, 623060.3141730145, 144964.2937209186]
[2019-03-23 08:07:49,401] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:07:49,404] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.9984811e-20 1.0000000e+00 2.4510299e-28 2.3622553e-27 9.1285440e-31], sampled 0.4435964774789588
[2019-03-23 08:08:02,145] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:08:02,647] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:08:02,735] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:08:02,830] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:08:02,885] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:08:03,902] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 450000, evaluation results [450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:08:05,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7350494e-22 1.0000000e+00 1.4083612e-29 4.1416920e-30 4.9305064e-34], sum to 1.0000
[2019-03-23 08:08:05,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7333
[2019-03-23 08:08:05,309] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2695241782047881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292653.4882705437, 292653.4882705435, 86160.11003200566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1012800.0000, 
sim time next is 1013400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.259269368958273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 281515.4363706367, 281515.436370637, 84518.53193451435], 
processed observation next is [1.0, 0.7391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.07408671119784126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10426497643356915, 0.10426497643356925, 0.20614276081588867], 
reward next is 0.7939, 
noisyNet noise sample is [array([0.65406376], dtype=float32), -0.25381216]. 
=============================================
[2019-03-23 08:08:11,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3216658e-22 1.0000000e+00 3.6165809e-32 1.5294784e-30 3.4523578e-34], sum to 1.0000
[2019-03-23 08:08:11,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8620
[2019-03-23 08:08:11,175] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.3725168728739916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 418465.3579584414, 418465.3579584417, 121740.6345256315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1103400.0000, 
sim time next is 1104000.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.371594799751403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 417426.0694625468, 417426.0694625468, 121660.4065066861], 
processed observation next is [1.0, 0.782608695652174, 0.6363636363636364, 0.69, 1.0, 1.0, 0.21449349968925377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15460224794909141, 0.15460224794909141, 0.29673269879679537], 
reward next is 0.7033, 
noisyNet noise sample is [array([1.4861083], dtype=float32), 1.1252042]. 
=============================================
[2019-03-23 08:08:11,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.542946]
 [70.542946]
 [70.542946]
 [70.542946]
 [70.542946]], R is [[70.54078674]
 [70.53845215]
 [70.53582764]
 [70.53302765]
 [70.53001404]].
[2019-03-23 08:08:21,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0611788e-21 1.0000000e+00 1.7600889e-31 3.3345036e-28 4.8225051e-34], sum to 1.0000
[2019-03-23 08:08:21,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5708
[2019-03-23 08:08:21,085] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3564545611689956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 396699.1692578292, 396699.1692578289, 118682.0535244918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1297200.0000, 
sim time next is 1297800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3574236301344509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397779.0933291152, 397779.0933291154, 118760.1605090711], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.19677953766806358, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1473255901218945, 0.1473255901218946, 0.2896589280709051], 
reward next is 0.7103, 
noisyNet noise sample is [array([1.3179547], dtype=float32), 0.34054205]. 
=============================================
[2019-03-23 08:08:26,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3358354e-22 1.0000000e+00 2.6363092e-29 7.3175034e-29 3.3455818e-32], sum to 1.0000
[2019-03-23 08:08:26,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-23 08:08:26,073] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.510736751637036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581893.1490161468, 581893.1490161468, 144045.7842508437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423200.0000, 
sim time next is 1423800.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.5063503778681593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577114.8536393715, 577114.8536393715, 143295.4240502509], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.38293797233519905, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21374624208865609, 0.21374624208865609, 0.34950103426890466], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.55249137], dtype=float32), -0.5528679]. 
=============================================
[2019-03-23 08:08:26,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7099801e-19 1.0000000e+00 2.8664967e-27 2.8657329e-26 2.5880812e-29], sum to 1.0000
[2019-03-23 08:08:26,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2799
[2019-03-23 08:08:26,331] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4861667195887431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554690.6103559606, 554690.6103559608, 139897.1356486845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1406400.0000, 
sim time next is 1407000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4858005534883408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554272.6958953524, 554272.6958953522, 139855.083125778], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35725069186042596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20528618366494533, 0.20528618366494525, 0.341109958843361], 
reward next is 0.6589, 
noisyNet noise sample is [array([0.65486014], dtype=float32), 2.036594]. 
=============================================
[2019-03-23 08:08:26,350] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.37822]
 [62.37822]
 [62.37822]
 [62.37822]
 [62.37822]], R is [[62.41332245]
 [62.44797516]
 [62.48211288]
 [62.51566696]
 [62.54868698]].
[2019-03-23 08:08:28,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8670769e-19 1.0000000e+00 3.3394824e-27 5.8802339e-27 9.6758561e-31], sum to 1.0000
[2019-03-23 08:08:28,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1274
[2019-03-23 08:08:28,104] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4459115402703866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508224.5579430277, 508224.5579430277, 133334.8105631761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458000.0000, 
sim time next is 1458600.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4484802221499329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511315.6321275934, 511315.6321275937, 133853.1173190414], 
processed observation next is [0.0, 0.9130434782608695, 0.5530303030303032, 1.0, 1.0, 1.0, 0.31060027768741605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1893761600472568, 0.1893761600472569, 0.3264710178513205], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.4611186], dtype=float32), -0.92666364]. 
=============================================
[2019-03-23 08:08:44,552] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.2310237e-22 1.0000000e+00 2.0319467e-33 8.0651709e-30 2.2556018e-35], sum to 1.0000
[2019-03-23 08:08:44,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1147
[2019-03-23 08:08:44,568] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.66666666666667, 63.66666666666666, 1.0, 2.0, 0.2678880894790642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 290876.4667697563, 290876.4667697563, 74623.30857664163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1759800.0000, 
sim time next is 1760400.0000, 
raw observation next is [14.0, 63.0, 1.0, 2.0, 0.272803572384921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 296215.3892012536, 296215.3892012536, 75390.42355554267], 
processed observation next is [1.0, 0.391304347826087, 0.2727272727272727, 0.63, 1.0, 1.0, 0.09100446548115121, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1097094034078717, 0.1097094034078717, 0.183879081842787], 
reward next is 0.8161, 
noisyNet noise sample is [array([1.108792], dtype=float32), 0.33243397]. 
=============================================
[2019-03-23 08:08:48,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0728121e-22 1.0000000e+00 4.1789234e-30 5.1012864e-32 2.2861635e-35], sum to 1.0000
[2019-03-23 08:08:48,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5881
[2019-03-23 08:08:48,180] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 49.33333333333334, 1.0, 2.0, 0.5096820821644218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553569.0740284125, 553569.0740284121, 120883.4745619219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1857000.0000, 
sim time next is 1857600.0000, 
raw observation next is [22.0, 50.0, 1.0, 2.0, 0.5244528134522539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569621.0629590045, 569621.0629590045, 125303.6763678705], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.5, 1.0, 1.0, 0.40556601681531734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21097076405889056, 0.21097076405889056, 0.30561872284846464], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.5501577], dtype=float32), 0.81674767]. 
=============================================
[2019-03-23 08:08:48,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5000159e-22 1.0000000e+00 7.8145195e-32 2.0023111e-29 1.3154815e-33], sum to 1.0000
[2019-03-23 08:08:48,705] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1136
[2019-03-23 08:08:48,714] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 47.33333333333334, 1.0, 2.0, 0.4496494231927278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488334.4564381369, 488334.4564381369, 107554.5642789815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1855200.0000, 
sim time next is 1855800.0000, 
raw observation next is [21.5, 48.0, 1.0, 2.0, 0.489386654290268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531514.0242655096, 531514.0242655096, 113827.4756770252], 
processed observation next is [1.0, 0.4782608695652174, 0.6136363636363636, 0.48, 1.0, 1.0, 0.36173331786283497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1968570460242628, 0.1968570460242628, 0.277627989456159], 
reward next is 0.7224, 
noisyNet noise sample is [array([0.23934066], dtype=float32), 0.6543492]. 
=============================================
[2019-03-23 08:08:51,915] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 08:08:51,918] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:08:51,918] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:08:51,920] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:51,920] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:08:51,921] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:08:51,922] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:08:51,925] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:51,925] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:51,926] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:51,924] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:08:51,936] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 08:08:51,961] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 08:08:51,986] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 08:08:52,011] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 08:08:52,014] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 08:09:01,082] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:09:01,083] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.33333333333333, 92.0, 1.0, 2.0, 0.2515824231235125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273166.5842026772, 273166.5842026775, 87293.9670408106]
[2019-03-23 08:09:01,084] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:09:01,087] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.09285173653357437
[2019-03-23 08:09:27,442] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:09:27,443] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.3, 59.0, 1.0, 2.0, 0.5644035570560312, 0.0, 2.0, 0.0, 1.0, 2.0, 0.902897540049102, 7.010382857731411, 6.9112, 95.5529978803722, 1191239.417621869, 1151435.096164638, 262904.461939701]
[2019-03-23 08:09:27,447] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:09:27,450] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.7623410892122012
[2019-03-23 08:09:27,451] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1191239.417621869 W.
[2019-03-23 08:09:32,231] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:09:32,233] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.21666666666667, 46.16666666666666, 1.0, 2.0, 0.5241270159780776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 596842.0998743885, 596842.0998743882, 145588.5597410892]
[2019-03-23 08:09:32,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:09:32,238] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.9827262051430655
[2019-03-23 08:09:57,558] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:09:57,559] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.81147856666667, 93.89209011666667, 1.0, 2.0, 0.2971553191993597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 322645.3439856221, 322645.3439856217, 104150.7098729374]
[2019-03-23 08:09:57,560] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:09:57,565] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.9809386980313969
[2019-03-23 08:10:27,804] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:10:27,805] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.27596330333333, 87.99183027000001, 1.0, 2.0, 0.6396943932146462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 729889.3896627708, 729889.3896627708, 163411.2532523553]
[2019-03-23 08:10:27,806] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:10:27,808] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.24577547010072698
[2019-03-23 08:10:30,281] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:10:30,282] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.95, 62.0, 1.0, 2.0, 0.4970158308508375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539804.5361689796, 539804.5361689796, 121503.5995117287]
[2019-03-23 08:10:30,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:10:30,286] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.4421503615225505
[2019-03-23 08:10:30,713] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:10:30,715] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.96666666666667, 79.83333333333334, 1.0, 2.0, 0.2019204905115522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 219222.4008322973, 219222.400832297, 75777.13198710099]
[2019-03-23 08:10:30,716] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:10:30,719] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.4842805780771864
[2019-03-23 08:10:31,727] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.94891196]
[2019-03-23 08:10:31,730] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.56650711, 84.78820616, 1.0, 2.0, 0.2881753255086733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 312892.5070757737, 312892.5070757737, 100182.0023513217]
[2019-03-23 08:10:31,731] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:10:31,733] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5383629e-20 1.0000000e+00 2.1020254e-29 2.4809815e-28 6.5882714e-32], sampled 0.3172770098726121
[2019-03-23 08:10:37,639] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:10:37,751] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:10:37,824] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:10:37,875] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:10:38,055] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:10:39,071] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:10:43,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0447586e-21 1.0000000e+00 5.4129774e-33 5.9457046e-30 2.4821856e-34], sum to 1.0000
[2019-03-23 08:10:43,971] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3698
[2019-03-23 08:10:43,976] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.2657255221651049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288527.6257487519, 288527.6257487519, 93000.2557368444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2016000.0000, 
sim time next is 2016600.0000, 
raw observation next is [18.16666666666667, 72.16666666666667, 1.0, 2.0, 0.2702577328018329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293450.2334101836, 293450.2334101836, 94147.93219154251], 
processed observation next is [0.0, 0.34782608695652173, 0.4621212121212123, 0.7216666666666667, 1.0, 1.0, 0.08782216600229112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10868527163340132, 0.10868527163340132, 0.22962910290620125], 
reward next is 0.7704, 
noisyNet noise sample is [array([1.2320693], dtype=float32), 1.271145]. 
=============================================
[2019-03-23 08:10:45,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8103066e-20 1.0000000e+00 2.0060860e-31 1.0823189e-29 1.9402964e-32], sum to 1.0000
[2019-03-23 08:10:45,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4145
[2019-03-23 08:10:45,935] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 51.5, 1.0, 2.0, 0.302540847628208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328515.6032048526, 328515.6032048526, 101857.8654947354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2057400.0000, 
sim time next is 2058000.0000, 
raw observation next is [21.46666666666667, 52.0, 1.0, 2.0, 0.2989033880609099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324564.5301464162, 324564.530146416, 99710.21119717359], 
processed observation next is [0.0, 0.8260869565217391, 0.6121212121212122, 0.52, 1.0, 1.0, 0.12362923507613734, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12020908523941341, 0.12020908523941333, 0.24319563706627703], 
reward next is 0.7568, 
noisyNet noise sample is [array([0.78709286], dtype=float32), 0.27112612]. 
=============================================
[2019-03-23 08:10:45,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.92354]
 [72.92354]
 [72.92354]
 [72.92354]
 [72.92354]], R is [[72.95111847]
 [72.97317505]
 [72.98953247]
 [73.00000763]
 [73.0039978 ]].
[2019-03-23 08:10:57,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4113202e-21 1.0000000e+00 2.2454000e-30 4.3959823e-28 1.4610907e-33], sum to 1.0000
[2019-03-23 08:10:57,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9305
[2019-03-23 08:10:57,023] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 88.00000000000001, 1.0, 2.0, 0.2687942848003443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291860.7210048871, 291860.7210048871, 89865.63892751886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2247000.0000, 
sim time next is 2247600.0000, 
raw observation next is [15.66666666666667, 88.0, 1.0, 2.0, 0.2629898698525951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285556.3530469997, 285556.3530469994, 87853.07801256808], 
processed observation next is [1.0, 0.0, 0.3484848484848486, 0.88, 1.0, 1.0, 0.07873733731574385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10576161223962953, 0.10576161223962939, 0.21427580003065386], 
reward next is 0.7857, 
noisyNet noise sample is [array([-0.49306175], dtype=float32), 0.66982645]. 
=============================================
[2019-03-23 08:10:59,254] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1138211e-22 1.0000000e+00 4.1801311e-32 3.0217333e-31 4.3311190e-34], sum to 1.0000
[2019-03-23 08:10:59,259] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8148
[2019-03-23 08:10:59,262] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 55.0, 1.0, 2.0, 0.2368082397470803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 257120.6301724479, 257120.6301724476, 74503.58937104588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2322000.0000, 
sim time next is 2322600.0000, 
raw observation next is [17.0, 55.0, 1.0, 2.0, 0.2356084196837737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 255817.5521124321, 255817.5521124324, 74376.27694622122], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.55, 1.0, 1.0, 0.0445105246047171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.094747241523123, 0.09474724152312311, 0.1814055535273688], 
reward next is 0.8186, 
noisyNet noise sample is [array([2.072854], dtype=float32), 0.9146587]. 
=============================================
[2019-03-23 08:11:07,440] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2007325e-19 1.0000000e+00 1.2791518e-29 3.2508068e-27 2.7301169e-31], sum to 1.0000
[2019-03-23 08:11:07,449] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7752
[2019-03-23 08:11:07,454] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 94.0, 1.0, 2.0, 0.2739100969535493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297417.2423416916, 297417.2423416916, 86558.18688821569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2486400.0000, 
sim time next is 2487000.0000, 
raw observation next is [14.33333333333333, 94.0, 1.0, 2.0, 0.2640255382399083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286681.2209082358, 286681.2209082355, 83609.436088512], 
processed observation next is [1.0, 0.782608695652174, 0.28787878787878773, 0.94, 1.0, 1.0, 0.08003192279988539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10617822996601327, 0.10617822996601316, 0.20392545387441952], 
reward next is 0.7961, 
noisyNet noise sample is [array([0.00378621], dtype=float32), 0.58551365]. 
=============================================
[2019-03-23 08:11:07,469] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.94008]
 [68.94008]
 [68.94008]
 [68.94008]
 [68.94008]], R is [[69.04675293]
 [69.14516449]
 [69.23486328]
 [69.31469727]
 [69.3828125 ]].
[2019-03-23 08:11:10,486] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0076012e-22 1.0000000e+00 1.7066657e-31 3.8450495e-30 1.7818597e-34], sum to 1.0000
[2019-03-23 08:11:10,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9147
[2019-03-23 08:11:10,502] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.5351016913234503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581193.9853807174, 581193.9853807174, 130092.0002906071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2548800.0000, 
sim time next is 2549400.0000, 
raw observation next is [20.16666666666667, 63.33333333333334, 1.0, 2.0, 0.5344091093298036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 580441.2969757767, 580441.296975777, 130027.5009342043], 
processed observation next is [1.0, 0.5217391304347826, 0.5530303030303032, 0.6333333333333334, 1.0, 1.0, 0.4180113866622544, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21497825813917654, 0.21497825813917668, 0.31714024618098613], 
reward next is 0.6829, 
noisyNet noise sample is [array([-0.5509792], dtype=float32), 1.5966638]. 
=============================================
[2019-03-23 08:11:14,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9755721e-23 1.0000000e+00 1.4262507e-30 3.6714360e-30 3.2006893e-34], sum to 1.0000
[2019-03-23 08:11:14,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2574
[2019-03-23 08:11:14,694] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 71.0, 1.0, 2.0, 0.3842191887820897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434165.8187564478, 434165.8187564478, 124120.9165182527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2625000.0000, 
sim time next is 2625600.0000, 
raw observation next is [22.66666666666667, 69.0, 1.0, 2.0, 0.3851146315969883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435291.9959306064, 435291.9959306067, 124269.1705529561], 
processed observation next is [0.0, 0.391304347826087, 0.6666666666666669, 0.69, 1.0, 1.0, 0.23139328949623533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16121925775207643, 0.16121925775207654, 0.30309553793403926], 
reward next is 0.6969, 
noisyNet noise sample is [array([0.56475985], dtype=float32), 0.72797316]. 
=============================================
[2019-03-23 08:11:19,748] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.9755264e-23 1.0000000e+00 4.6066642e-30 4.5341591e-28 2.6604811e-32], sum to 1.0000
[2019-03-23 08:11:19,755] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1582
[2019-03-23 08:11:19,760] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.75, 99.83333333333334, 1.0, 2.0, 0.3300053771294053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 363412.8142403244, 363412.8142403247, 115055.3755422898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2699400.0000, 
sim time next is 2700000.0000, 
raw observation next is [16.8, 100.0, 1.0, 2.0, 0.3313047244367166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365277.1143717992, 365277.1143717992, 115316.5295712463], 
processed observation next is [0.0, 0.2608695652173913, 0.4, 1.0, 1.0, 1.0, 0.16413090554589574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1352878201377034, 0.1352878201377034, 0.28125982822255197], 
reward next is 0.7187, 
noisyNet noise sample is [array([1.2920628], dtype=float32), -1.9751846]. 
=============================================
[2019-03-23 08:11:19,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.67568]
 [70.67568]
 [70.67568]
 [70.67568]
 [70.67568]], R is [[70.68766785]
 [70.70016479]
 [70.71311188]
 [70.72646332]
 [70.74025726]].
[2019-03-23 08:11:20,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4479772e-21 1.0000000e+00 6.4747301e-33 2.5105797e-29 5.3945254e-34], sum to 1.0000
[2019-03-23 08:11:20,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2156
[2019-03-23 08:11:20,846] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 64.5, 1.0, 2.0, 0.4772014830458878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544388.909976281, 544388.909976281, 139085.5003722696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2722200.0000, 
sim time next is 2722800.0000, 
raw observation next is [26.33333333333334, 64.0, 1.0, 2.0, 0.481628235056627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549378.0742460991, 549378.0742460993, 139734.9555216949], 
processed observation next is [0.0, 0.5217391304347826, 0.8333333333333336, 0.64, 1.0, 1.0, 0.3520352938207837, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20347336083188855, 0.20347336083188863, 0.34081696468706074], 
reward next is 0.6592, 
noisyNet noise sample is [array([0.5286954], dtype=float32), -1.1677796]. 
=============================================
[2019-03-23 08:11:24,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7531307e-19 1.0000000e+00 5.2150466e-27 2.9242030e-28 3.1890688e-30], sum to 1.0000
[2019-03-23 08:11:24,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9683
[2019-03-23 08:11:24,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1452927.335237599 W.
[2019-03-23 08:11:24,374] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 61.33333333333334, 1.0, 2.0, 0.7956901880438952, 0.0, 1.0, 0.0, 1.0, 2.0, 0.976774183890749, 6.9112, 6.9112, 84.98723577453217, 1452927.335237599, 1452927.335237599, 309212.8431465462], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2808600.0000, 
sim time next is 2809200.0000, 
raw observation next is [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.4881952770405243, 1.0, 1.0, 0.4881952770405243, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1106631.849954437, 1106631.849954437, 230124.607706847], 
processed observation next is [1.0, 0.5217391304347826, 0.878787878787879, 0.6066666666666667, 1.0, 1.0, 0.36024409630065535, 1.0, 0.5, 0.36024409630065535, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.40986364813127296, 0.40986364813127296, 0.5612795309923098], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9320413], dtype=float32), -1.3948333]. 
=============================================
[2019-03-23 08:11:25,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.840651e-15 1.000000e+00 6.810515e-24 8.422971e-22 2.330449e-24], sum to 1.0000
[2019-03-23 08:11:25,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4333
[2019-03-23 08:11:25,215] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 51.33333333333334, 1.0, 2.0, 0.4550418008658094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519225.6145549754, 519225.6145549756, 136015.5153272133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2828400.0000, 
sim time next is 2829000.0000, 
raw observation next is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.4541453496142772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518189.8476544875, 518189.8476544878, 135564.4638184418], 
processed observation next is [1.0, 0.7391304347826086, 0.9166666666666669, 0.5116666666666666, 1.0, 1.0, 0.3176816870178465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19192216579795832, 0.19192216579795845, 0.3306450337035166], 
reward next is 0.6694, 
noisyNet noise sample is [array([-0.6359488], dtype=float32), 1.0977224]. 
=============================================
[2019-03-23 08:11:25,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[48.794907]
 [48.794907]
 [48.794907]
 [48.794907]
 [48.794907]], R is [[48.97631073]
 [49.15480423]
 [49.33020782]
 [48.83690643]
 [48.34853745]].
[2019-03-23 08:11:26,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3674782e-20 1.0000000e+00 5.3089020e-28 6.3522996e-28 2.1775286e-30], sum to 1.0000
[2019-03-23 08:11:26,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6420
[2019-03-23 08:11:26,623] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 63.83333333333334, 1.0, 2.0, 0.4617208446161577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526798.1428257277, 526798.1428257277, 136156.1590223736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2841000.0000, 
sim time next is 2841600.0000, 
raw observation next is [25.33333333333334, 66.66666666666667, 1.0, 2.0, 0.4670432020286377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532922.5857140784, 532922.5857140784, 137043.9148341972], 
processed observation next is [1.0, 0.9130434782608695, 0.7878787878787882, 0.6666666666666667, 1.0, 1.0, 0.33380400253579706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19737873544965867, 0.19737873544965867, 0.33425345081511515], 
reward next is 0.6657, 
noisyNet noise sample is [array([0.79175705], dtype=float32), 0.40210986]. 
=============================================
[2019-03-23 08:11:26,763] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 08:11:26,764] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:11:26,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:26,766] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:11:26,766] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:11:26,767] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:11:26,768] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:26,767] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:11:26,768] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:26,768] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:26,768] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:11:26,774] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 08:11:26,800] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 08:11:26,801] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 08:11:26,801] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 08:11:26,802] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 08:11:45,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:11:45,555] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.40974341666667, 89.44113584666667, 1.0, 2.0, 0.6961386531933998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 782237.8192929794, 782237.8192929791, 177337.4567158492]
[2019-03-23 08:11:45,555] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:11:45,557] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.3499850000523984
[2019-03-23 08:12:09,932] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:12:09,933] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.85, 83.16666666666666, 1.0, 2.0, 0.3956327727433181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 447899.6484970525, 447899.6484970521, 129994.0337486564]
[2019-03-23 08:12:09,935] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:12:09,938] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.7176326293836311
[2019-03-23 08:12:31,482] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:12:31,483] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.83333333333334, 50.5, 1.0, 2.0, 0.3183980733292153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346604.7742359259, 346604.7742359262, 112740.5389013591]
[2019-03-23 08:12:31,485] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:12:31,488] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.09460042872138608
[2019-03-23 08:12:41,788] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:12:41,789] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.8, 61.66666666666667, 1.0, 2.0, 0.7434835497828737, 1.0, 1.0, 0.7434835497828737, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32845464776828, 1672499.776647452, 1672499.776647452, 305799.8979360064]
[2019-03-23 08:12:41,791] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:12:41,794] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.5627143869062514
[2019-03-23 08:12:41,796] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1672499.776647452 W.
[2019-03-23 08:12:49,830] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:12:49,831] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.98333333333333, 53.0, 1.0, 2.0, 0.4203440461425114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 456452.0162941773, 456452.0162941773, 124381.7489631802]
[2019-03-23 08:12:49,834] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:12:49,836] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.3261665520463951
[2019-03-23 08:12:53,020] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:12:53,022] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 90.0, 1.0, 2.0, 0.3620430723948012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 404722.6778506636, 404722.6778506633, 124236.4021633499]
[2019-03-23 08:12:53,023] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:12:53,025] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.1618364259787145
[2019-03-23 08:13:05,410] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.93012637]
[2019-03-23 08:13:05,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.96593679, 91.21796921, 1.0, 2.0, 0.2598892730419378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 282173.1126531141, 282173.1126531141, 98214.49634847308]
[2019-03-23 08:13:05,411] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:13:05,413] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.1455280e-20 1.0000000e+00 1.4521760e-28 1.9717742e-27 3.2710140e-31], sampled 0.5578417606997554
[2019-03-23 08:13:13,279] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:13:13,298] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:13:13,416] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:13:13,417] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:13:13,425] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:13:14,440] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 500000, evaluation results [500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:13:20,585] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0953981e-15 1.0000000e+00 1.4946269e-26 2.0519513e-24 6.7284862e-28], sum to 1.0000
[2019-03-23 08:13:20,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3705
[2019-03-23 08:13:20,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1479811.965538581 W.
[2019-03-23 08:13:20,602] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.8192289382612197, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9768652888462334, 6.911199999999999, 6.9112, 77.32846344354104, 1479811.965538581, 1479811.965538581, 310774.5505341412], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2980800.0000, 
sim time next is 2981400.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4047672588465072, 1.0, 1.0, 0.4047672588465072, 1.0, 2.0, 0.8188127261393553, 6.9112, 6.9112, 77.3421103, 1371184.112672754, 1371184.112672754, 307283.8037006289], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.25595907355813396, 1.0, 0.5, 0.25595907355813396, 1.0, 1.0, 0.7411610373419363, 0.0, 0.0, 0.5085185399722538, 0.5078459676565756, 0.5078459676565756, 0.7494726919527535], 
reward next is 0.2505, 
noisyNet noise sample is [array([-0.11842999], dtype=float32), -2.470074]. 
=============================================
[2019-03-23 08:13:30,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2978590e-14 1.0000000e+00 4.8683557e-22 3.1573207e-21 5.6180134e-24], sum to 1.0000
[2019-03-23 08:13:30,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5162
[2019-03-23 08:13:30,208] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.00000000000001, 1.0, 2.0, 0.3937545346943053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443693.2636043526, 443693.2636043529, 124278.6975674859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3204600.0000, 
sim time next is 3205200.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3963021259727251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446570.3620346176, 446570.3620346179, 124509.8346364786], 
processed observation next is [0.0, 0.08695652173913043, 0.5, 0.94, 1.0, 1.0, 0.2453776574659063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16539643038319168, 0.16539643038319182, 0.30368252350360636], 
reward next is 0.6963, 
noisyNet noise sample is [array([-0.20195559], dtype=float32), -0.12796757]. 
=============================================
[2019-03-23 08:13:37,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7455472e-22 1.0000000e+00 3.1843281e-30 6.7313616e-28 7.0944096e-33], sum to 1.0000
[2019-03-23 08:13:37,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8383
[2019-03-23 08:13:37,427] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 62.5, 1.0, 2.0, 0.2918493521509614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316902.4027919875, 316902.4027919878, 110649.7960178242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3317400.0000, 
sim time next is 3318000.0000, 
raw observation next is [21.0, 60.66666666666667, 1.0, 2.0, 0.2977506984289284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323312.4649341456, 323312.4649341456, 111043.0680099474], 
processed observation next is [0.0, 0.391304347826087, 0.5909090909090909, 0.6066666666666667, 1.0, 1.0, 0.12218837303616045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11974535738301689, 0.11974535738301689, 0.27083675124377415], 
reward next is 0.7292, 
noisyNet noise sample is [array([-0.21260114], dtype=float32), 0.93328065]. 
=============================================
[2019-03-23 08:13:37,438] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.513756]
 [78.513756]
 [78.513756]
 [78.513756]
 [78.513756]], R is [[78.45778656]
 [78.40333557]
 [78.35812378]
 [78.32510376]
 [78.30197906]].
[2019-03-23 08:13:46,825] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.7442086e-21 1.0000000e+00 1.1685457e-26 2.0209384e-26 1.9089867e-29], sum to 1.0000
[2019-03-23 08:13:46,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1538
[2019-03-23 08:13:46,840] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4741548808687108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 540979.6525292372, 540979.6525292372, 138534.2214290929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3476400.0000, 
sim time next is 3477000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4744171683529863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541279.4947560871, 541279.4947560871, 138562.0723861099], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34302146044123283, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20047388694669893, 0.20047388694669893, 0.3379562741124632], 
reward next is 0.6620, 
noisyNet noise sample is [array([-1.2186238], dtype=float32), 0.098206915]. 
=============================================
[2019-03-23 08:13:46,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[61.693214]
 [61.693214]
 [61.693214]
 [61.693214]
 [61.693214]], R is [[61.73832703]
 [61.78305817]
 [61.8266449 ]
 [61.86459732]
 [61.88589096]].
[2019-03-23 08:13:47,870] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0721143e-14 1.0000000e+00 2.4331323e-22 2.1456443e-21 1.6957313e-23], sum to 1.0000
[2019-03-23 08:13:47,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6505
[2019-03-23 08:13:47,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1749650.080099608 W.
[2019-03-23 08:13:47,895] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 62.0, 1.0, 2.0, 0.7777265746802438, 1.0, 2.0, 0.7777265746802438, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1749650.080099608, 1749650.080099607, 317279.7896858595], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3513600.0000, 
sim time next is 3514200.0000, 
raw observation next is [28.93333333333333, 61.66666666666667, 1.0, 2.0, 0.7510456816717594, 1.0, 2.0, 0.7510456816717594, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1689536.524438259, 1689536.524438259, 308302.1689357107], 
processed observation next is [1.0, 0.6956521739130435, 0.9515151515151513, 0.6166666666666667, 1.0, 1.0, 0.6888071020896993, 1.0, 1.0, 0.6888071020896993, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.6257542683104663, 0.6257542683104663, 0.7519565095992944], 
reward next is 0.2480, 
noisyNet noise sample is [array([-1.7160145], dtype=float32), 1.6815826]. 
=============================================
[2019-03-23 08:14:01,867] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2156849e-17 1.0000000e+00 1.3900572e-24 9.5594480e-23 6.4826586e-27], sum to 1.0000
[2019-03-23 08:14:01,877] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0607
[2019-03-23 08:14:01,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1273767.09877356 W.
[2019-03-23 08:14:01,889] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 61.5, 1.0, 2.0, 0.5580913670210184, 1.0, 1.0, 0.5580913670210184, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1273767.09877356, 1273767.098773559, 242205.1604992747], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3756600.0000, 
sim time next is 3757200.0000, 
raw observation next is [25.66666666666666, 60.33333333333333, 1.0, 2.0, 0.3542099594916222, 1.0, 2.0, 0.3542099594916222, 1.0, 1.0, 0.7167471810190906, 6.9112, 6.9112, 77.3421103, 1211881.582104183, 1211881.582104183, 277254.430730307], 
processed observation next is [1.0, 0.4782608695652174, 0.8030303030303028, 0.6033333333333333, 1.0, 1.0, 0.19276244936452774, 1.0, 1.0, 0.19276244936452774, 1.0, 0.5, 0.5953531157415581, 0.0, 0.0, 0.5085185399722538, 0.4488450304089567, 0.4488450304089567, 0.6762303188544073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6698117], dtype=float32), -0.040575713]. 
=============================================
[2019-03-23 08:14:02,709] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 08:14:02,711] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:14:02,712] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:14:02,712] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:14:02,712] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:14:02,713] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:14:02,714] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:14:02,714] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:14:02,713] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:14:02,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:14:02,719] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:14:02,732] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 08:14:02,757] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 08:14:02,758] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 08:14:02,759] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 08:14:02,828] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 08:14:11,549] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9098356]
[2019-03-23 08:14:11,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.71248104333333, 79.25321096666667, 1.0, 2.0, 0.3241801376338652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 354408.6124206561, 354408.6124206561, 117988.3455013858]
[2019-03-23 08:14:11,554] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:14:11,556] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.2003817e-20 1.0000000e+00 2.1589622e-28 3.0115898e-27 5.0528512e-31], sampled 0.35608774216018924
[2019-03-23 08:14:20,226] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9098356]
[2019-03-23 08:14:20,226] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.16666666666667, 84.83333333333334, 1.0, 2.0, 0.5084948449902209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 579744.979881936, 579744.9798819356, 143327.6887083662]
[2019-03-23 08:14:20,228] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:14:20,230] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.2003817e-20 1.0000000e+00 2.1589622e-28 3.0115898e-27 5.0528512e-31], sampled 0.8784352874391551
[2019-03-23 08:14:51,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9098356]
[2019-03-23 08:14:51,062] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.63446124, 74.35747847, 1.0, 2.0, 0.5802501534957177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 655114.46531055, 655114.46531055, 159756.4970684016]
[2019-03-23 08:14:51,063] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:14:51,066] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.2003817e-20 1.0000000e+00 2.1589622e-28 3.0115898e-27 5.0528512e-31], sampled 0.6781487457909341
[2019-03-23 08:15:50,757] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:15:51,194] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:15:51,287] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:15:51,405] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:15:51,440] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:15:52,454] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 525000, evaluation results [525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:15:54,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6645009e-22 1.0000000e+00 4.2656392e-30 3.7990070e-30 4.9595235e-32], sum to 1.0000
[2019-03-23 08:15:54,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1809
[2019-03-23 08:15:54,636] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3027770488037801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328772.1702185383, 328772.1702185383, 110306.6089348219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3816000.0000, 
sim time next is 3816600.0000, 
raw observation next is [17.0, 88.00000000000001, 1.0, 2.0, 0.3002865741871277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326066.9676520651, 326066.9676520648, 109939.1674121107], 
processed observation next is [0.0, 0.17391304347826086, 0.4090909090909091, 0.8800000000000001, 1.0, 1.0, 0.12535821773390957, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12076554357483893, 0.12076554357483882, 0.2681443107612456], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.45418957], dtype=float32), 1.5877564]. 
=============================================
[2019-03-23 08:15:56,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5760460e-20 1.0000000e+00 1.3375144e-31 9.5250561e-29 9.3203757e-33], sum to 1.0000
[2019-03-23 08:15:56,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6467
[2019-03-23 08:15:56,092] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2964071129821765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321853.0504820234, 321853.0504820234, 110951.8393626031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3846600.0000, 
sim time next is 3847200.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.296289153159825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321724.921683866, 321724.9216838657, 110943.9941979883], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.12036144144978125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11915737840143185, 0.11915737840143174, 0.2705951077999715], 
reward next is 0.7294, 
noisyNet noise sample is [array([1.6110934], dtype=float32), 0.50660884]. 
=============================================
[2019-03-23 08:15:56,100] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6444870e-21 1.0000000e+00 9.7646345e-29 2.8359542e-28 4.5984775e-32], sum to 1.0000
[2019-03-23 08:15:56,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0128
[2019-03-23 08:15:56,119] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 64.0, 1.0, 2.0, 0.3167161718566301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 347126.3430999584, 347126.3430999581, 113464.7442119694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3873600.0000, 
sim time next is 3874200.0000, 
raw observation next is [21.0, 64.0, 1.0, 2.0, 0.3163240048396642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346722.2761757778, 346722.2761757781, 113446.410177244], 
processed observation next is [0.0, 0.8695652173913043, 0.5909090909090909, 0.64, 1.0, 1.0, 0.14540500604958026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12841565784288067, 0.12841565784288078, 0.2766985614079122], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.47700977], dtype=float32), -0.26546264]. 
=============================================
[2019-03-23 08:15:56,732] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4600012e-21 1.0000000e+00 1.6181278e-30 6.7383721e-29 4.7117829e-33], sum to 1.0000
[2019-03-23 08:15:56,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9923
[2019-03-23 08:15:56,748] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 77.5, 1.0, 2.0, 0.2899462196539432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314835.2319008688, 314835.2319008691, 110525.2755667827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3915000.0000, 
sim time next is 3915600.0000, 
raw observation next is [19.0, 76.0, 1.0, 2.0, 0.2991425147240658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325648.8856382114, 325648.8856382117, 111426.9981805767], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.76, 1.0, 1.0, 0.12392814340508221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12061069838452274, 0.12061069838452285, 0.27177316629408954], 
reward next is 0.7282, 
noisyNet noise sample is [array([1.2227457], dtype=float32), -0.87983453]. 
=============================================
[2019-03-23 08:16:00,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1688853e-24 1.0000000e+00 4.6623327e-31 5.3726209e-31 1.3450959e-33], sum to 1.0000
[2019-03-23 08:16:00,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0600
[2019-03-23 08:16:00,727] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.0, 1.0, 2.0, 0.3148298319767245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344395.8012812598, 344395.8012812595, 113088.575545918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3963600.0000, 
sim time next is 3964200.0000, 
raw observation next is [21.83333333333334, 57.5, 1.0, 2.0, 0.3136367859907409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342667.4926453785, 342667.4926453782, 112851.9773138679], 
processed observation next is [0.0, 0.9130434782608695, 0.628787878787879, 0.575, 1.0, 1.0, 0.14204598248842612, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.126913886164955, 0.1269138861649549, 0.27524872515577536], 
reward next is 0.7248, 
noisyNet noise sample is [array([-2.225192], dtype=float32), -1.6423502]. 
=============================================
[2019-03-23 08:16:02,671] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5059767e-21 1.0000000e+00 8.2683808e-29 1.2481401e-27 1.2337334e-30], sum to 1.0000
[2019-03-23 08:16:02,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6220
[2019-03-23 08:16:02,686] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 94.0, 1.0, 2.0, 0.3625333764933286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401890.6257552498, 401890.6257552495, 118527.8610583792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4036800.0000, 
sim time next is 4037400.0000, 
raw observation next is [17.5, 94.0, 1.0, 2.0, 0.3502312029572296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387083.2220995162, 387083.2220995162, 117098.7535242938], 
processed observation next is [1.0, 0.7391304347826086, 0.4318181818181818, 0.94, 1.0, 1.0, 0.18778900369653698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14336415633315414, 0.14336415633315414, 0.2856067159129117], 
reward next is 0.7144, 
noisyNet noise sample is [array([0.13270724], dtype=float32), 0.05783745]. 
=============================================
[2019-03-23 08:16:05,047] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.51187517e-21 1.00000000e+00 3.69641206e-28 1.11634064e-26
 7.44370689e-32], sum to 1.0000
[2019-03-23 08:16:05,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6309
[2019-03-23 08:16:05,060] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056600.0000, 
sim time next is 4057200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3175327869473207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347386.1100369328, 347386.1100369328, 113290.9632149848], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14691598368415082, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12866152223590105, 0.12866152223590105, 0.2763194224755727], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.37637287], dtype=float32), -0.6121085]. 
=============================================
[2019-03-23 08:16:05,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1209052e-21 1.0000000e+00 5.1873603e-30 7.9516502e-30 3.9671912e-32], sum to 1.0000
[2019-03-23 08:16:05,310] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-23 08:16:05,316] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3133050832299477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341677.9826587222, 341677.9826587222, 112605.1747615214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4059000.0000, 
sim time next is 4059600.0000, 
raw observation next is [16.33333333333333, 98.0, 1.0, 2.0, 0.3110415445670778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 338781.8358430249, 338781.8358430249, 112297.5721544979], 
processed observation next is [1.0, 1.0, 0.37878787878787856, 0.98, 1.0, 1.0, 0.1388019307088472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12547475401593514, 0.12547475401593514, 0.2738965174499949], 
reward next is 0.7261, 
noisyNet noise sample is [array([-0.03979202], dtype=float32), 0.99439687]. 
=============================================
[2019-03-23 08:16:08,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2845042e-17 1.0000000e+00 2.5473095e-26 1.6614998e-23 4.8709416e-28], sum to 1.0000
[2019-03-23 08:16:08,541] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7725
[2019-03-23 08:16:08,545] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.05, 93.5, 1.0, 2.0, 0.386659997405606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435644.7209368874, 435644.7209368874, 123619.9834467794], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4131000.0000, 
sim time next is 4131600.0000, 
raw observation next is [19.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3858669302594047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434760.1323010832, 434760.1323010835, 123554.8339795395], 
processed observation next is [1.0, 0.8260869565217391, 0.5015151515151515, 0.9366666666666668, 1.0, 1.0, 0.23233366282425588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16102227122262341, 0.1610222712226235, 0.3013532536086329], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.60336286], dtype=float32), -0.08638121]. 
=============================================
[2019-03-23 08:16:09,598] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5830247e-19 1.0000000e+00 6.6895337e-28 2.0143105e-27 1.7513019e-31], sum to 1.0000
[2019-03-23 08:16:09,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3627
[2019-03-23 08:16:09,609] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3704134249196332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 415816.2505319021, 415816.2505319018, 121420.2799917087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4150800.0000, 
sim time next is 4151400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3701281449105355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415495.1782371624, 415495.1782371627, 121395.7309645575], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2126601811381693, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1538871030508009, 0.153887103050801, 0.2960871486940427], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.34313455], dtype=float32), 0.9338533]. 
=============================================
[2019-03-23 08:16:11,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6574453e-19 1.0000000e+00 9.4577936e-27 9.2513952e-28 1.8684536e-29], sum to 1.0000
[2019-03-23 08:16:11,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0097
[2019-03-23 08:16:11,798] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.8383459623049918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 949852.2137695564, 949852.2137695566, 179840.7500361243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4196400.0000, 
sim time next is 4197000.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.8294197682384932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 939714.5574870686, 939714.5574870683, 178478.0726506489], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.61, 1.0, 1.0, 0.7867747102981165, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3480424286989143, 0.3480424286989142, 0.4353123723186558], 
reward next is 0.5647, 
noisyNet noise sample is [array([-1.4978287], dtype=float32), -1.3711468]. 
=============================================
[2019-03-23 08:16:11,824] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.709724]
 [64.709724]
 [64.709724]
 [64.709724]
 [64.709724]], R is [[64.62731934]
 [64.5424118 ]
 [64.45384979]
 [64.39387512]
 [64.37783813]].
[2019-03-23 08:16:13,363] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5902994e-19 1.0000000e+00 1.2767011e-27 4.2274963e-27 1.9933163e-31], sum to 1.0000
[2019-03-23 08:16:13,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6229
[2019-03-23 08:16:13,371] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.00000000000001, 1.0, 2.0, 0.3658487507797512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408856.89922977, 408856.8992297697, 120174.7788646552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4230600.0000, 
sim time next is 4231200.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3663709583762091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 409443.1887203194, 409443.1887203197, 120219.0619601315], 
processed observation next is [1.0, 1.0, 0.5, 0.88, 1.0, 1.0, 0.20796369797026135, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15164562545197016, 0.15164562545197027, 0.2932172242930037], 
reward next is 0.7068, 
noisyNet noise sample is [array([2.7367694], dtype=float32), 0.19679788]. 
=============================================
[2019-03-23 08:16:18,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2773932e-19 1.0000000e+00 2.4552383e-30 1.5712312e-28 1.7044592e-32], sum to 1.0000
[2019-03-23 08:16:18,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9944
[2019-03-23 08:16:18,465] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 78.0, 1.0, 2.0, 0.3920761827223053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 441921.7606203331, 441921.7606203328, 124193.1507297933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312800.0000, 
sim time next is 4313400.0000, 
raw observation next is [21.0, 78.0, 1.0, 2.0, 0.38958136698379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438990.6494278092, 438990.6494278092, 123907.3926885854], 
processed observation next is [1.0, 0.9565217391304348, 0.5909090909090909, 0.78, 1.0, 1.0, 0.23697670872973745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16258912941770712, 0.16258912941770712, 0.30221315289898876], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.47565848], dtype=float32), 0.36761022]. 
=============================================
[2019-03-23 08:16:22,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7712613e-18 1.0000000e+00 2.4112003e-27 7.3366291e-27 4.3839059e-29], sum to 1.0000
[2019-03-23 08:16:22,325] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2369
[2019-03-23 08:16:22,332] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4478938443046057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 510324.6174290707, 510324.6174290704, 133323.5993367192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4410000.0000, 
sim time next is 4410600.0000, 
raw observation next is [21.91666666666667, 83.5, 1.0, 2.0, 0.4460674692660279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508204.1451412248, 508204.1451412248, 133085.0279992657], 
processed observation next is [0.0, 0.043478260869565216, 0.6325757575757578, 0.835, 1.0, 1.0, 0.30758433658253487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18822375745971287, 0.18822375745971287, 0.3245976292665017], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.56713533], dtype=float32), 1.9411563]. 
=============================================
[2019-03-23 08:16:27,147] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.5215243e-20 1.0000000e+00 2.0812892e-28 2.3367491e-26 2.5035872e-30], sum to 1.0000
[2019-03-23 08:16:27,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8784
[2019-03-23 08:16:27,166] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4984969799084182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568504.6540156854, 568504.6540156854, 141909.1799212786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4527600.0000, 
sim time next is 4528200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5000855555840359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570316.6669871402, 570316.6669871402, 142096.0399269016], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37510694448004483, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2112283951804223, 0.2112283951804223, 0.3465757071387844], 
reward next is 0.6534, 
noisyNet noise sample is [array([0.22389956], dtype=float32), 1.1472903]. 
=============================================
[2019-03-23 08:16:33,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1366143e-20 1.0000000e+00 1.0060618e-28 3.8134595e-27 4.9158464e-31], sum to 1.0000
[2019-03-23 08:16:33,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-23 08:16:33,056] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 48.0, 1.0, 2.0, 0.4815633115062282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523468.1698106312, 523468.1698106312, 125371.9344960197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4623600.0000, 
sim time next is 4624200.0000, 
raw observation next is [23.0, 47.0, 1.0, 2.0, 0.4274483592661205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 464211.8398600881, 464211.8398600884, 120651.1240179076], 
processed observation next is [1.0, 0.5217391304347826, 0.6818181818181818, 0.47, 1.0, 1.0, 0.28431044908265063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17193031105929188, 0.17193031105929202, 0.29427103419001854], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.08460063], dtype=float32), -0.16197464]. 
=============================================
[2019-03-23 08:16:33,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.7363945e-21 1.0000000e+00 8.8879816e-30 4.6101144e-28 2.0034552e-31], sum to 1.0000
[2019-03-23 08:16:33,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0315
[2019-03-23 08:16:33,559] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 47.0, 1.0, 2.0, 0.6977566962580021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 759917.7962141768, 759917.7962141768, 147467.9836825842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4632600.0000, 
sim time next is 4633200.0000, 
raw observation next is [23.0, 47.0, 1.0, 2.0, 0.6959289613914286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 756010.3821761305, 756010.3821761305, 146673.2700168135], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.47, 1.0, 1.0, 0.6199112017392857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2800038452504187, 0.2800038452504187, 0.3577396829678378], 
reward next is 0.6423, 
noisyNet noise sample is [array([-1.276531], dtype=float32), 0.2781548]. 
=============================================
[2019-03-23 08:16:36,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3668375e-23 1.0000000e+00 6.3924934e-32 8.5131257e-30 4.6474629e-34], sum to 1.0000
[2019-03-23 08:16:36,217] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5412
[2019-03-23 08:16:36,222] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 53.5, 1.0, 2.0, 0.7262460285156459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 815179.6159759137, 815179.6159759134, 159647.6278736354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4709400.0000, 
sim time next is 4710000.0000, 
raw observation next is [24.66666666666666, 53.00000000000001, 1.0, 2.0, 0.5797387606804305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651746.4719381328, 651746.4719381328, 142398.7586743468], 
processed observation next is [1.0, 0.5217391304347826, 0.7575757575757573, 0.53, 1.0, 1.0, 0.4746734508505381, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24138758219930845, 0.24138758219930845, 0.34731404554718737], 
reward next is 0.6527, 
noisyNet noise sample is [array([-1.7740256], dtype=float32), -1.8823197]. 
=============================================
[2019-03-23 08:16:36,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.7347]
 [75.7347]
 [75.7347]
 [75.7347]
 [75.7347]], R is [[75.63004303]
 [75.48435974]
 [75.32962799]
 [75.21169281]
 [75.09450531]].
[2019-03-23 08:16:38,023] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 08:16:38,024] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:16:38,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:38,026] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:16:38,026] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:38,027] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:16:38,027] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:38,029] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:16:38,030] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:38,030] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:16:38,031] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:16:38,047] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 08:16:38,071] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 08:16:38,072] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 08:16:38,073] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 08:16:38,141] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 08:17:01,934] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9236329]
[2019-03-23 08:17:01,936] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.750407095, 59.81366096999999, 1.0, 2.0, 0.2081627859235477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 226000.8522934811, 226000.8522934807, 73254.61412541853]
[2019-03-23 08:17:01,938] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:17:01,941] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4330462e-19 1.0000000e+00 3.4882586e-27 4.7873691e-26 1.3724029e-29], sampled 0.7166902348693492
[2019-03-23 08:17:32,369] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9236329]
[2019-03-23 08:17:32,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.66666666666667, 98.0, 1.0, 2.0, 0.2570073020544248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279058.5728804859, 279058.5728804859, 87505.01544641057]
[2019-03-23 08:17:32,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:17:32,374] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.4330462e-19 1.0000000e+00 3.4882586e-27 4.7873691e-26 1.3724029e-29], sampled 0.9804183780151879
[2019-03-23 08:17:51,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9236329]
[2019-03-23 08:17:51,307] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.13333333333333, 69.33333333333334, 1.0, 2.0, 0.590104095217237, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9727329853231568, 6.911200000000001, 6.9112, 77.32846344354104, 1221159.018978676, 1221159.018978676, 272034.2242733501]
[2019-03-23 08:17:51,309] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:17:51,312] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.4330462e-19 1.0000000e+00 3.4882586e-27 4.7873691e-26 1.3724029e-29], sampled 0.33580895500550056
[2019-03-23 08:17:51,314] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1221159.018978676 W.
[2019-03-23 08:17:53,612] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9236329]
[2019-03-23 08:17:53,613] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.63942838, 76.932604605, 1.0, 2.0, 0.7593827961488475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 853354.5601592717, 853354.5601592714, 187396.5766375246]
[2019-03-23 08:17:53,614] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:17:53,616] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.4330462e-19 1.0000000e+00 3.4882586e-27 4.7873691e-26 1.3724029e-29], sampled 0.8871180248554686
[2019-03-23 08:17:58,519] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.9236329]
[2019-03-23 08:17:58,521] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.96272195333333, 79.57003642333333, 1.0, 2.0, 0.2732217181501542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 296652.3018932422, 296652.3018932419, 96215.61248380117]
[2019-03-23 08:17:58,522] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:17:58,524] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.4330462e-19 1.0000000e+00 3.4882586e-27 4.7873691e-26 1.3724029e-29], sampled 0.7404896754340884
[2019-03-23 08:18:21,262] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:18:21,382] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:18:21,568] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:18:21,631] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:18:21,752] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:18:22,765] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 550000, evaluation results [550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:18:23,846] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.5552636e-20 1.0000000e+00 3.0575671e-28 1.0855204e-27 5.5105294e-31], sum to 1.0000
[2019-03-23 08:18:23,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1360
[2019-03-23 08:18:23,859] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 88.0, 1.0, 2.0, 0.4164245419857624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465663.3848090976, 465663.3848090976, 124630.8229082895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4760400.0000, 
sim time next is 4761000.0000, 
raw observation next is [19.0, 88.0, 1.0, 2.0, 0.3913498612772036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437522.8580516707, 437522.8580516704, 122392.2566251646], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.88, 1.0, 1.0, 0.2391873265965045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16204550298210027, 0.16204550298210016, 0.2985176990857673], 
reward next is 0.7015, 
noisyNet noise sample is [array([-1.9414009], dtype=float32), 0.54535604]. 
=============================================
[2019-03-23 08:18:23,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.91667]
 [65.91667]
 [65.91667]
 [65.91667]
 [65.91667]], R is [[65.95899963]
 [65.99542999]
 [66.01996613]
 [66.06723785]
 [66.11407471]].
[2019-03-23 08:18:29,843] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4686886e-22 1.0000000e+00 3.7179179e-30 2.1964782e-27 3.3896073e-31], sum to 1.0000
[2019-03-23 08:18:29,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8160
[2019-03-23 08:18:29,866] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.8002580497404439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908620.9661537859, 908620.9661537859, 175481.9706051185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4881600.0000, 
sim time next is 4882200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.7316552364568514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 830420.0758636708, 830420.0758636708, 165405.5122401708], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.6645690455710642, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3075629910606188, 0.3075629910606188, 0.4034280786345629], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.75552255], dtype=float32), 0.07090086]. 
=============================================
[2019-03-23 08:18:42,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7366021e-17 1.0000000e+00 8.4519813e-27 1.5298266e-25 7.6698481e-29], sum to 1.0000
[2019-03-23 08:18:42,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1260
[2019-03-23 08:18:42,019] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4011371537172969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454573.9876997858, 454573.9876997858, 126460.4284567002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5116800.0000, 
sim time next is 5117400.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4008228578027078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454217.4592052199, 454217.4592052199, 126430.9753722641], 
processed observation next is [0.0, 0.21739130434782608, 0.5909090909090909, 0.83, 1.0, 1.0, 0.25102857225338476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1682286885945259, 0.1682286885945259, 0.3083682326152783], 
reward next is 0.6916, 
noisyNet noise sample is [array([-0.67729807], dtype=float32), -0.9518467]. 
=============================================
[2019-03-23 08:18:48,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4941889e-17 1.0000000e+00 4.4008861e-26 1.6541820e-24 4.7904176e-27], sum to 1.0000
[2019-03-23 08:18:48,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4159
[2019-03-23 08:18:48,635] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.8801399664237312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1003901.593755828, 1003901.593755828, 197787.7695448395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5241000.0000, 
sim time next is 5241600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8497387080667528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 969199.05327811, 969199.05327811, 192544.8841218628], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8121733850834408, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3589626123252259, 0.3589626123252259, 0.4696216685899092], 
reward next is 0.5304, 
noisyNet noise sample is [array([-1.0246111], dtype=float32), 0.050580986]. 
=============================================
[2019-03-23 08:18:49,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0582227e-19 1.0000000e+00 2.1103996e-27 9.2316187e-28 3.6946018e-31], sum to 1.0000
[2019-03-23 08:18:49,560] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2113
[2019-03-23 08:18:49,570] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.499413028936955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569548.0433155935, 569548.0433155939, 142019.3406056792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5259600.0000, 
sim time next is 5260200.0000, 
raw observation next is [21.91666666666667, 95.0, 1.0, 2.0, 0.499887806152467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570051.3910742293, 570051.3910742295, 142135.8116814718], 
processed observation next is [1.0, 0.9130434782608695, 0.6325757575757578, 0.95, 1.0, 1.0, 0.37485975769058366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21113014484230713, 0.21113014484230722, 0.34667271141822387], 
reward next is 0.6533, 
noisyNet noise sample is [array([-1.5378641], dtype=float32), 1.3156395]. 
=============================================
[2019-03-23 08:18:55,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4590242e-18 1.0000000e+00 8.8395131e-26 4.2280467e-26 1.3473134e-27], sum to 1.0000
[2019-03-23 08:18:56,005] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6116
[2019-03-23 08:18:56,008] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 95.0, 1.0, 2.0, 0.3979735967784411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449418.4144784815, 449418.4144784812, 125192.2559948009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427000.0000, 
sim time next is 5427600.0000, 
raw observation next is [19.0, 95.66666666666666, 1.0, 2.0, 0.3970694942735168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448296.2640756891, 448296.2640756891, 125052.4173724242], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.9566666666666666, 1.0, 1.0, 0.24633686784189596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16603565336136633, 0.16603565336136633, 0.3050058960303029], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.29464954], dtype=float32), 0.110091366]. 
=============================================
[2019-03-23 08:19:01,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9976857e-16 1.0000000e+00 3.1368592e-24 9.2858166e-24 5.2142508e-27], sum to 1.0000
[2019-03-23 08:19:01,140] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5803
[2019-03-23 08:19:01,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1478335.379128742 W.
[2019-03-23 08:19:01,156] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 69.0, 1.0, 2.0, 0.8221067261319492, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9810439638684625, 6.911199999999999, 6.9112, 77.32846344337865, 1478335.379128742, 1478335.379128742, 315452.2449790942], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5494200.0000, 
sim time next is 5494800.0000, 
raw observation next is [26.8, 69.0, 1.0, 2.0, 0.8599883175404295, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9810098883245721, 6.9112, 6.9112, 77.32846344354003, 1521294.376974409, 1521294.376974409, 322056.997378469], 
processed observation next is [1.0, 0.6086956521739131, 0.8545454545454546, 0.69, 1.0, 1.0, 0.8249853969255369, 0.0, 1.0, -0.25, 1.0, 1.0, 0.972871269035103, 0.0, 0.0, 0.5084288129206475, 0.5634423618423737, 0.5634423618423737, 0.7855048716548024], 
reward next is 0.2145, 
noisyNet noise sample is [array([1.5262504], dtype=float32), -0.48898873]. 
=============================================
[2019-03-23 08:19:01,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9279529e-17 1.0000000e+00 7.6215939e-25 9.3507241e-24 2.3335946e-27], sum to 1.0000
[2019-03-23 08:19:01,462] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5027
[2019-03-23 08:19:01,465] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 73.5, 1.0, 2.0, 0.4908056786238945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560006.6908933712, 560006.6908933712, 140347.4541045233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5518200.0000, 
sim time next is 5518800.0000, 
raw observation next is [24.4, 74.0, 1.0, 2.0, 0.4891154148558473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558086.8110545768, 558086.811054577, 140110.039574587], 
processed observation next is [1.0, 0.9130434782608695, 0.7454545454545454, 0.74, 1.0, 1.0, 0.3613942685698091, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2066988189091025, 0.2066988189091026, 0.3417318038404561], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.19790007], dtype=float32), 0.21896096]. 
=============================================
[2019-03-23 08:19:04,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9971676e-18 1.0000000e+00 2.6748378e-26 7.9132325e-27 3.2313800e-29], sum to 1.0000
[2019-03-23 08:19:04,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1330
[2019-03-23 08:19:04,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 87.0, 1.0, 2.0, 0.4245287692309417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481669.434549061, 481669.434549061, 129077.6790264887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5598000.0000, 
sim time next is 5598600.0000, 
raw observation next is [20.41666666666667, 88.0, 1.0, 2.0, 0.4176813680756883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473539.5587739285, 473539.5587739285, 128164.2143107628], 
processed observation next is [1.0, 0.8260869565217391, 0.5643939393939396, 0.88, 1.0, 1.0, 0.2721017100946103, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17538502176812165, 0.17538502176812165, 0.3125956446603971], 
reward next is 0.6874, 
noisyNet noise sample is [array([0.51310015], dtype=float32), 0.9692771]. 
=============================================
[2019-03-23 08:19:05,950] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1456352e-16 1.0000000e+00 1.1048618e-22 4.0108839e-22 5.3071659e-26], sum to 1.0000
[2019-03-23 08:19:05,955] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7314
[2019-03-23 08:19:05,972] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1293926.226445267 W.
[2019-03-23 08:19:05,980] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 58.0, 1.0, 2.0, 0.3790274920683068, 1.0, 2.0, 0.3790274920683068, 1.0, 1.0, 0.767733707720402, 6.9112, 6.9112, 77.3421103, 1293926.226445267, 1293926.226445267, 290548.9122763189], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5587200.0000, 
sim time next is 5587800.0000, 
raw observation next is [26.88333333333333, 57.5, 1.0, 2.0, 0.4140691088233555, 1.0, 2.0, 0.4140691088233555, 1.0, 2.0, 0.838778433484416, 6.9112, 6.9112, 77.88841317985447, 1412355.372110895, 1412355.372110895, 307829.9365103365], 
processed observation next is [1.0, 0.6956521739130435, 0.8583333333333332, 0.575, 1.0, 1.0, 0.2675863860291944, 1.0, 1.0, 0.2675863860291944, 1.0, 1.0, 0.7696834764063087, 0.0, 0.0, 0.512110440190242, 0.5230945822632945, 0.5230945822632945, 0.7508047231959427], 
reward next is 0.2492, 
noisyNet noise sample is [array([2.4535692], dtype=float32), -0.6029975]. 
=============================================
[2019-03-23 08:19:10,075] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 08:19:10,076] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:19:10,077] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:19:10,077] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:19:10,078] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:19:10,078] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:19:10,079] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:19:10,080] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:19:10,081] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:19:10,081] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:19:10,083] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:19:10,093] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 08:19:10,093] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 08:19:10,139] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 08:19:10,163] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 08:19:10,165] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 08:19:11,544] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:19:11,547] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.76666666666667, 84.5, 1.0, 2.0, 0.7272589110168323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 825105.3458794056, 825105.3458794056, 164570.571435739]
[2019-03-23 08:19:11,549] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:19:11,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.44468748462255314
[2019-03-23 08:19:19,601] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:19:19,602] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666666, 84.83333333333333, 1.0, 2.0, 0.3047875754848544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330956.0548651406, 330956.0548651409, 111514.887350176]
[2019-03-23 08:19:19,604] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:19:19,607] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.8438968041082481
[2019-03-23 08:19:21,927] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:19:21,928] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.05, 48.16666666666666, 1.0, 2.0, 0.3653454402021329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 407717.8785718844, 407717.878571884, 124198.4003025193]
[2019-03-23 08:19:21,929] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:19:21,932] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.2931700381807586
[2019-03-23 08:19:26,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:19:26,057] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.46666666666667, 70.66666666666667, 1.0, 2.0, 0.6294021518031757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 717455.3563389287, 717455.3563389287, 163253.1667262286]
[2019-03-23 08:19:26,058] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:19:26,061] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.3456248449863154
[2019-03-23 08:19:33,213] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:19:33,213] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.8226211, 81.16195543, 1.0, 2.0, 0.4380508419037806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 475687.454606052, 475687.4546060516, 106087.9655989347]
[2019-03-23 08:19:33,215] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:19:33,220] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.5527235804729077
[2019-03-23 08:19:40,489] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:19:40,490] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 77.0, 1.0, 2.0, 0.474858598095481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515726.9941796882, 515726.9941796882, 111073.215508328]
[2019-03-23 08:19:40,491] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:19:40,495] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.30055917226063256
[2019-03-23 08:20:48,253] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:20:48,253] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.11666666666667, 84.5, 1.0, 2.0, 0.4271445400128229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468020.4962022584, 468020.4962022584, 121963.5328921492]
[2019-03-23 08:20:48,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:20:48,255] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.8431234848440526
[2019-03-23 08:20:50,196] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7966417]
[2019-03-23 08:20:50,197] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.08843956666667, 87.17900412333333, 1.0, 2.0, 0.4152884041535196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 471834.3825386136, 471834.3825386136, 133033.0566236318]
[2019-03-23 08:20:50,199] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:20:50,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.6874399e-21 1.0000000e+00 1.9602066e-30 3.5973645e-29 3.9116926e-33], sampled 0.08555884807118797
[2019-03-23 08:20:53,213] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:20:53,712] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:20:53,876] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:20:53,957] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:20:54,133] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:20:55,147] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 575000, evaluation results [575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:20:59,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0093008e-15 1.0000000e+00 5.0601435e-23 3.9000948e-21 1.9741017e-25], sum to 1.0000
[2019-03-23 08:20:59,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5374
[2019-03-23 08:20:59,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.46666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 154874.2432830594, 154874.2432830592, 58486.96171161805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5728200.0000, 
sim time next is 5728800.0000, 
raw observation next is [11.83333333333333, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 159234.0501139188, 159234.050113919, 59058.72735495125], 
processed observation next is [0.0, 0.30434782608695654, 0.17424242424242412, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.05897557411626623, 0.05897557411626629, 0.14404567647549085], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4877652], dtype=float32), 0.38961378]. 
=============================================
[2019-03-23 08:21:02,699] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9313530e-19 1.0000000e+00 2.6444705e-27 3.3801107e-27 2.9931671e-31], sum to 1.0000
[2019-03-23 08:21:02,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7666
[2019-03-23 08:21:02,708] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.98333333333333, 51.16666666666666, 1.0, 2.0, 0.5530233878750175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604831.3214859593, 604831.3214859596, 133083.654160529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5829000.0000, 
sim time next is 5829600.0000, 
raw observation next is [23.26666666666667, 51.33333333333334, 1.0, 2.0, 0.5249002176578421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577044.7951857757, 577044.7951857757, 131347.0450825013], 
processed observation next is [1.0, 0.4782608695652174, 0.6939393939393941, 0.5133333333333334, 1.0, 1.0, 0.4061252720723026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21372029451325028, 0.21372029451325028, 0.32035864654268614], 
reward next is 0.6796, 
noisyNet noise sample is [array([0.9397765], dtype=float32), -0.9015232]. 
=============================================
[2019-03-23 08:21:03,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3362279e-18 1.0000000e+00 5.5764119e-27 2.5150518e-25 8.5528375e-30], sum to 1.0000
[2019-03-23 08:21:03,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7158
[2019-03-23 08:21:03,830] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 45.0, 1.0, 2.0, 0.5994846926131147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 664648.9315506041, 664648.9315506043, 140823.0208481328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5839200.0000, 
sim time next is 5839800.0000, 
raw observation next is [25.08333333333334, 45.0, 1.0, 2.0, 0.6382271289113015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 708166.8375686449, 708166.8375686452, 145326.9676180422], 
processed observation next is [1.0, 0.6086956521739131, 0.7765151515151518, 0.45, 1.0, 1.0, 0.5477839111391268, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26228401391431294, 0.26228401391431305, 0.3544560185805907], 
reward next is 0.6455, 
noisyNet noise sample is [array([0.29899618], dtype=float32), 1.2169518]. 
=============================================
[2019-03-23 08:21:04,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7090389e-20 1.0000000e+00 3.8975631e-30 1.0887254e-28 6.9541435e-32], sum to 1.0000
[2019-03-23 08:21:04,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-23 08:21:04,878] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 73.0, 1.0, 2.0, 0.3311848735262123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 365055.2965525914, 365055.2965525914, 115273.0562226224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5871600.0000, 
sim time next is 5872200.0000, 
raw observation next is [19.83333333333334, 74.0, 1.0, 2.0, 0.3316592252081729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365432.0908376015, 365432.0908376017, 115252.3874303373], 
processed observation next is [1.0, 1.0, 0.5378787878787882, 0.74, 1.0, 1.0, 0.16457403151021613, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13534521882874131, 0.13534521882874137, 0.2811033839764324], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.61143935], dtype=float32), -0.1495683]. 
=============================================
[2019-03-23 08:21:08,314] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.3693637e-20 1.0000000e+00 4.2570746e-29 3.9329943e-28 5.8742580e-31], sum to 1.0000
[2019-03-23 08:21:08,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5811
[2019-03-23 08:21:08,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 58.66666666666667, 1.0, 2.0, 0.4053076080809293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 459023.2580743763, 459023.258074376, 126665.615599095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5946000.0000, 
sim time next is 5946600.0000, 
raw observation next is [24.41666666666667, 59.33333333333333, 1.0, 2.0, 0.4047890097975452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458129.6519723332, 458129.6519723335, 126421.1713785489], 
processed observation next is [1.0, 0.8260869565217391, 0.7462121212121214, 0.5933333333333333, 1.0, 1.0, 0.25598626224693144, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16967764887864192, 0.16967764887864203, 0.3083443204354851], 
reward next is 0.6917, 
noisyNet noise sample is [array([-1.5185598], dtype=float32), -0.6214969]. 
=============================================
[2019-03-23 08:21:11,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5065467e-19 1.0000000e+00 1.6723645e-26 8.5092187e-25 2.3950246e-31], sum to 1.0000
[2019-03-23 08:21:11,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4365
[2019-03-23 08:21:11,912] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 73.5, 1.0, 2.0, 0.6727169408303043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 754541.0401853174, 754541.0401853172, 152605.0408732859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [21.23333333333333, 72.66666666666666, 1.0, 2.0, 0.696261420215147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 781838.3346676693, 781838.3346676693, 155941.6953197869], 
processed observation next is [1.0, 0.34782608695652173, 0.6015151515151514, 0.7266666666666666, 1.0, 1.0, 0.6203267752689338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28956975358061826, 0.28956975358061826, 0.38034559834094367], 
reward next is 0.6197, 
noisyNet noise sample is [array([0.23632371], dtype=float32), -1.5722682]. 
=============================================
[2019-03-23 08:21:11,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0030185e-17 1.0000000e+00 2.2730429e-26 1.1694202e-25 1.7533760e-29], sum to 1.0000
[2019-03-23 08:21:11,933] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6414
[2019-03-23 08:21:11,942] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1302753.273312735 W.
[2019-03-23 08:21:11,946] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.5, 72.0, 1.0, 2.0, 0.3845015765021159, 1.0, 2.0, 0.3845015765021159, 1.0, 1.0, 0.7778775194206221, 6.911200000000001, 6.9112, 77.3421103, 1302753.273312735, 1302753.273312734, 297694.0231817508], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6019200.0000, 
sim time next is 6019800.0000, 
raw observation next is [25.03333333333333, 73.16666666666667, 1.0, 2.0, 0.6969539502030994, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9764024662309162, 6.9112, 6.9112, 77.32846344354104, 1340974.395713193, 1340974.395713193, 290797.968695627], 
processed observation next is [1.0, 0.6956521739130435, 0.7742424242424242, 0.7316666666666667, 1.0, 1.0, 0.6211924377538741, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9662892374727375, 0.0, 0.0, 0.5084288129206541, 0.4966571835974789, 0.4966571835974789, 0.709263338282017], 
reward next is 0.2907, 
noisyNet noise sample is [array([-1.6560644], dtype=float32), -0.4805182]. 
=============================================
[2019-03-23 08:21:14,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7538371e-19 1.0000000e+00 1.0472762e-29 5.4006364e-28 1.2423233e-31], sum to 1.0000
[2019-03-23 08:21:14,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1537
[2019-03-23 08:21:14,238] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1257523.729032521 W.
[2019-03-23 08:21:14,242] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.1, 75.5, 1.0, 2.0, 0.3689054110175526, 1.0, 1.0, 0.3689054110175526, 1.0, 2.0, 0.7472903246431953, 6.911199999999999, 6.9112, 77.3421103, 1257523.729032521, 1257523.729032522, 287338.7980632896], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6021000.0000, 
sim time next is 6021600.0000, 
raw observation next is [23.63333333333333, 76.66666666666667, 1.0, 2.0, 0.3593338823069098, 1.0, 2.0, 0.3593338823069098, 1.0, 2.0, 0.727894333092478, 6.9112, 6.9112, 77.3421103, 1225769.571734563, 1225769.571734563, 282670.4996034904], 
processed observation next is [1.0, 0.6956521739130435, 0.7106060606060605, 0.7666666666666667, 1.0, 1.0, 0.19916735288363727, 1.0, 1.0, 0.19916735288363727, 1.0, 1.0, 0.61127761870354, 0.0, 0.0, 0.5085185399722538, 0.4539887302720604, 0.4539887302720604, 0.6894402429353425], 
reward next is 0.3106, 
noisyNet noise sample is [array([-0.5187372], dtype=float32), -0.63770103]. 
=============================================
[2019-03-23 08:21:20,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5275779e-17 1.0000000e+00 2.7229279e-25 4.0096387e-25 3.7479353e-30], sum to 1.0000
[2019-03-23 08:21:20,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3895
[2019-03-23 08:21:20,132] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 76.5, 1.0, 2.0, 0.5816832752466051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 640557.0406077611, 640557.0406077608, 137375.8803880771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6166200.0000, 
sim time next is 6166800.0000, 
raw observation next is [19.4, 76.0, 1.0, 2.0, 0.5876781916664858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 647588.889055846, 647588.8890558457, 138146.2834196305], 
processed observation next is [1.0, 0.391304347826087, 0.5181818181818181, 0.76, 1.0, 1.0, 0.48459773958310726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23984773668735038, 0.23984773668735024, 0.3369421546820256], 
reward next is 0.6631, 
noisyNet noise sample is [array([0.38504758], dtype=float32), -0.96834254]. 
=============================================
[2019-03-23 08:21:23,351] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1627380e-20 1.0000000e+00 2.0237511e-29 3.2658481e-26 4.8385623e-31], sum to 1.0000
[2019-03-23 08:21:23,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4705
[2019-03-23 08:21:23,366] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.3695353964967726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414133.271136394, 414133.271136394, 121010.538943725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6216000.0000, 
sim time next is 6216600.0000, 
raw observation next is [19.5, 86.0, 1.0, 2.0, 0.3697830543445019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414531.1607765463, 414531.1607765463, 121088.3189131088], 
processed observation next is [1.0, 0.9565217391304348, 0.5227272727272727, 0.86, 1.0, 1.0, 0.2122288179306274, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.153530059546869, 0.153530059546869, 0.2953373632027044], 
reward next is 0.7047, 
noisyNet noise sample is [array([2.1868813], dtype=float32), 0.0016520497]. 
=============================================
[2019-03-23 08:21:31,599] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8318306e-18 1.0000000e+00 7.1068134e-26 7.1966782e-26 2.5861484e-28], sum to 1.0000
[2019-03-23 08:21:31,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-23 08:21:31,612] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 68.0, 1.0, 2.0, 0.5204646933839095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593906.8940531802, 593906.8940531802, 143024.4536397927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6410400.0000, 
sim time next is 6411000.0000, 
raw observation next is [25.0, 68.0, 1.0, 2.0, 0.504577065410287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575764.5352624675, 575764.5352624675, 141161.0257724954], 
processed observation next is [1.0, 0.17391304347826086, 0.7727272727272727, 0.68, 1.0, 1.0, 0.3807213317628587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21324612417128425, 0.21324612417128425, 0.3442951848109644], 
reward next is 0.6557, 
noisyNet noise sample is [array([-0.6568476], dtype=float32), 0.9379909]. 
=============================================
[2019-03-23 08:21:31,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[60.03327]
 [60.03327]
 [60.03327]
 [60.03327]
 [60.03327]], R is [[60.08865356]
 [60.13892746]
 [60.18095398]
 [60.22243118]
 [60.2597847 ]].
[2019-03-23 08:21:33,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1254087e-20 1.0000000e+00 7.7324627e-26 7.5345202e-26 1.2413623e-30], sum to 1.0000
[2019-03-23 08:21:33,500] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8475
[2019-03-23 08:21:33,504] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 89.5, 1.0, 2.0, 0.6769397418954228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 753432.6652133652, 753432.6652133656, 150695.1659110348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6448200.0000, 
sim time next is 6448800.0000, 
raw observation next is [18.3, 89.0, 1.0, 2.0, 0.646039650909571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 718375.9740513447, 718375.9740513447, 146798.5213958317], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.89, 1.0, 1.0, 0.5575495636369637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2660651755745721, 0.2660651755745721, 0.35804517413617487], 
reward next is 0.6420, 
noisyNet noise sample is [array([-0.37468243], dtype=float32), -0.017223023]. 
=============================================
[2019-03-23 08:21:35,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1699849e-21 1.0000000e+00 1.5811884e-28 1.8481241e-28 1.6582638e-31], sum to 1.0000
[2019-03-23 08:21:35,121] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1973
[2019-03-23 08:21:35,124] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.86666666666667, 83.66666666666667, 1.0, 2.0, 0.2037913462035061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221263.5357140165, 221263.5357140162, 72135.38737912604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6489600.0000, 
sim time next is 6490200.0000, 
raw observation next is [13.58333333333333, 85.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 216157.9581074132, 216157.9581074132, 71347.53201714577], 
processed observation next is [1.0, 0.08695652173913043, 0.2537878787878787, 0.8533333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08005850300274563, 0.08005850300274563, 0.17401837077352628], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39087874], dtype=float32), 1.2715095]. 
=============================================
[2019-03-23 08:21:42,609] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 08:21:42,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:21:42,611] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:21:42,611] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:42,613] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:42,613] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:21:42,615] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:21:42,616] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:21:42,618] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:42,616] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:42,619] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:21:42,634] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 08:21:42,659] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 08:21:42,661] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 08:21:42,661] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 08:21:42,734] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 08:22:10,040] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7837017]
[2019-03-23 08:22:10,041] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.66065345, 61.27538395, 1.0, 2.0, 0.4209685320197198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 477907.8579756206, 477907.8579756202, 133281.864317337]
[2019-03-23 08:22:10,045] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:22:10,048] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0439056e-19 1.0000000e+00 1.5820278e-27 1.9480749e-26 6.5731658e-30], sampled 0.8868784858419244
[2019-03-23 08:22:59,763] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7837017]
[2019-03-23 08:22:59,764] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.08333333333334, 84.0, 1.0, 2.0, 0.2499361675437997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 271364.1526191747, 271364.1526191747, 90693.52488397104]
[2019-03-23 08:22:59,765] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:22:59,767] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.0439056e-19 1.0000000e+00 1.5820278e-27 1.9480749e-26 6.5731658e-30], sampled 0.5157756091078154
[2019-03-23 08:23:26,587] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:23:26,667] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:23:26,691] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:23:26,704] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:23:26,803] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:23:27,817] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 600000, evaluation results [600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:23:27,864] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8968677e-21 1.0000000e+00 4.6356649e-29 7.2547200e-28 9.4987758e-31], sum to 1.0000
[2019-03-23 08:23:27,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5806
[2019-03-23 08:23:27,879] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 62.66666666666667, 1.0, 2.0, 0.7105119316920181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 799059.9364315035, 799059.9364315035, 158333.3388080461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6619200.0000, 
sim time next is 6619800.0000, 
raw observation next is [22.8, 63.33333333333334, 1.0, 2.0, 0.723493459314343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 813816.0619275635, 813816.0619275633, 160099.8452062545], 
processed observation next is [1.0, 0.6086956521739131, 0.6727272727272727, 0.6333333333333334, 1.0, 1.0, 0.6543668241429287, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30141335626946797, 0.30141335626946786, 0.39048742733232805], 
reward next is 0.6095, 
noisyNet noise sample is [array([-0.19218625], dtype=float32), 1.6022649]. 
=============================================
[2019-03-23 08:23:36,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.0704829e-21 1.0000000e+00 3.6733572e-29 1.5593979e-26 2.1019431e-31], sum to 1.0000
[2019-03-23 08:23:36,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8711
[2019-03-23 08:23:36,610] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.13333333333333, 88.0, 1.0, 2.0, 0.2986826663400237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 324324.7793338061, 324324.7793338058, 111103.646914126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6758400.0000, 
sim time next is 6759000.0000, 
raw observation next is [17.1, 87.0, 1.0, 2.0, 0.292139223283444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 317217.2598162385, 317217.2598162388, 109213.3539172924], 
processed observation next is [1.0, 0.21739130434782608, 0.4136363636363637, 0.87, 1.0, 1.0, 0.11517402910430498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11748787400601425, 0.11748787400601436, 0.2663740339446156], 
reward next is 0.7336, 
noisyNet noise sample is [array([0.32467473], dtype=float32), -0.5013687]. 
=============================================
[2019-03-23 08:23:36,630] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.111404]
 [68.111404]
 [68.111404]
 [68.111404]
 [68.111404]], R is [[68.16392517]
 [68.21130371]
 [68.25522614]
 [68.29608917]
 [68.33553314]].
[2019-03-23 08:23:37,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9193897e-21 1.0000000e+00 1.4932796e-29 4.8536042e-26 9.9744739e-31], sum to 1.0000
[2019-03-23 08:23:37,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6797
[2019-03-23 08:23:37,542] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 76.0, 1.0, 2.0, 0.2666268941673011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289506.6364545133, 289506.6364545133, 94071.21785882427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6765600.0000, 
sim time next is 6766200.0000, 
raw observation next is [17.7, 76.5, 1.0, 2.0, 0.2693123685302059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292423.4329327657, 292423.4329327655, 95112.60975720838], 
processed observation next is [1.0, 0.30434782608695654, 0.44090909090909086, 0.765, 1.0, 1.0, 0.08664046066275737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10830497516028359, 0.10830497516028352, 0.23198197501758142], 
reward next is 0.7680, 
noisyNet noise sample is [array([0.91295826], dtype=float32), -0.9150837]. 
=============================================
[2019-03-23 08:23:39,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5355672e-20 1.0000000e+00 1.0624139e-29 2.3081249e-26 5.0155022e-30], sum to 1.0000
[2019-03-23 08:23:39,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4112
[2019-03-23 08:23:39,973] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 71.0, 1.0, 2.0, 0.4121772863371967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467055.9438285808, 467055.9438285808, 127475.5586050027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6811200.0000, 
sim time next is 6811800.0000, 
raw observation next is [22.7, 70.5, 1.0, 2.0, 0.4108706466870886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 465432.7633700073, 465432.7633700073, 127257.4598515804], 
processed observation next is [1.0, 0.8695652173913043, 0.6681818181818181, 0.705, 1.0, 1.0, 0.2635883083588607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17238250495185456, 0.17238250495185456, 0.31038404841848877], 
reward next is 0.6896, 
noisyNet noise sample is [array([1.2456157], dtype=float32), 2.1183033]. 
=============================================
[2019-03-23 08:23:46,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1619317e-18 1.0000000e+00 4.3101012e-28 1.1055774e-24 2.3252571e-29], sum to 1.0000
[2019-03-23 08:23:46,035] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7316
[2019-03-23 08:23:46,039] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5080079215323373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578906.5867699528, 578906.5867699528, 143597.655143547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6964200.0000, 
sim time next is 6964800.0000, 
raw observation next is [28.3, 56.0, 1.0, 2.0, 0.5081465758516105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579064.7920513038, 579064.792051304, 143614.0761174029], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.56, 1.0, 1.0, 0.3851832198145131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2144684415004829, 0.21446844150048297, 0.35027823443269], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.5106805], dtype=float32), -0.18317243]. 
=============================================
[2019-03-23 08:23:46,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4099401e-19 1.0000000e+00 5.7372737e-27 2.8667717e-26 2.5402122e-29], sum to 1.0000
[2019-03-23 08:23:46,978] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4205
[2019-03-23 08:23:46,984] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 58.0, 1.0, 2.0, 0.4972360187250106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566917.837599674, 566917.837599674, 141980.2583644099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957000.0000, 
sim time next is 6957600.0000, 
raw observation next is [27.7, 58.0, 1.0, 2.0, 0.4979496732111359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 567731.652745638, 567731.652745638, 142064.205959798], 
processed observation next is [0.0, 0.5217391304347826, 0.8954545454545454, 0.58, 1.0, 1.0, 0.37243709151391985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21027098249838447, 0.21027098249838447, 0.3464980633165805], 
reward next is 0.6535, 
noisyNet noise sample is [array([-1.2227877], dtype=float32), -0.16057263]. 
=============================================
[2019-03-23 08:23:48,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9639728e-17 1.0000000e+00 1.8890341e-24 2.2268137e-22 6.3898034e-27], sum to 1.0000
[2019-03-23 08:23:48,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9293
[2019-03-23 08:23:48,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 96.66666666666666, 1.0, 2.0, 0.3933801514655965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 444641.5683675889, 444641.5683675889, 125017.2855263154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7022400.0000, 
sim time next is 7023000.0000, 
raw observation next is [18.9, 96.83333333333334, 1.0, 2.0, 0.3905057512176012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 441064.8015273482, 441064.8015273482, 124564.1423951298], 
processed observation next is [1.0, 0.2608695652173913, 0.49545454545454537, 0.9683333333333334, 1.0, 1.0, 0.2381321890220015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16335733389901785, 0.16335733389901785, 0.3038149814515361], 
reward next is 0.6962, 
noisyNet noise sample is [array([0.5326108], dtype=float32), -0.19853409]. 
=============================================
[2019-03-23 08:23:48,210] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[61.914944]
 [61.914944]
 [61.914944]
 [61.914944]
 [61.914944]], R is [[61.99197388]
 [62.06713486]
 [62.14045715]
 [62.2116127 ]
 [62.27837753]].
[2019-03-23 08:23:48,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4687673e-18 1.0000000e+00 9.3224710e-26 2.7349411e-25 9.9852203e-29], sum to 1.0000
[2019-03-23 08:23:48,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9868
[2019-03-23 08:23:48,567] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 96.16666666666666, 1.0, 2.0, 0.4143946617976223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 469377.3114757981, 469377.3114757978, 127558.6720745941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7020600.0000, 
sim time next is 7021200.0000, 
raw observation next is [19.2, 96.33333333333333, 1.0, 2.0, 0.400390416878474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 453208.6510685413, 453208.6510685413, 126050.6941320844], 
processed observation next is [1.0, 0.2608695652173913, 0.509090909090909, 0.9633333333333333, 1.0, 1.0, 0.25048802109809243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1678550559513116, 0.1678550559513116, 0.3074407173953278], 
reward next is 0.6926, 
noisyNet noise sample is [array([0.4772466], dtype=float32), -0.9971287]. 
=============================================
[2019-03-23 08:23:53,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7949633e-21 1.0000000e+00 1.8298618e-30 5.7621869e-28 6.0575838e-31], sum to 1.0000
[2019-03-23 08:23:53,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8520
[2019-03-23 08:23:53,215] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3459509416531273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385125.0405190943, 385125.0405190943, 117898.8272986615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7106400.0000, 
sim time next is 7107000.0000, 
raw observation next is [17.7, 96.33333333333334, 1.0, 2.0, 0.3529078109244196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392580.289784138, 392580.2897841383, 118326.8678711814], 
processed observation next is [1.0, 0.2608695652173913, 0.44090909090909086, 0.9633333333333334, 1.0, 1.0, 0.19113476365552445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1454001073274585, 0.14540010732745864, 0.288602116758979], 
reward next is 0.7114, 
noisyNet noise sample is [array([-0.7206277], dtype=float32), -2.107138]. 
=============================================
[2019-03-23 08:23:53,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.41054]
 [71.41054]
 [71.41054]
 [71.41054]
 [71.41054]], R is [[71.40782928]
 [71.40618896]
 [71.40446472]
 [71.40254974]
 [71.4002533 ]].
[2019-03-23 08:23:53,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3148482e-19 1.0000000e+00 2.2692297e-27 3.1578154e-28 3.6964346e-31], sum to 1.0000
[2019-03-23 08:23:53,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2253
[2019-03-23 08:23:53,934] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 93.66666666666666, 1.0, 2.0, 0.3395164942281296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375731.2785551307, 375731.2785551307, 116473.5832607809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7085400.0000, 
sim time next is 7086000.0000, 
raw observation next is [17.7, 94.33333333333334, 1.0, 2.0, 0.3404686333190651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377212.6909169267, 377212.690916927, 116717.0988637323], 
processed observation next is [1.0, 0.0, 0.44090909090909086, 0.9433333333333335, 1.0, 1.0, 0.1755857916488313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1397084040433062, 0.1397084040433063, 0.28467585088715197], 
reward next is 0.7153, 
noisyNet noise sample is [array([2.7630773], dtype=float32), -0.7312001]. 
=============================================
[2019-03-23 08:23:53,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.97853]
 [69.97853]
 [69.97853]
 [69.97853]
 [69.97853]], R is [[69.99407196]
 [70.01004791]
 [70.02609253]
 [70.04140472]
 [70.05606079]].
[2019-03-23 08:24:00,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0228644e-22 1.0000000e+00 6.6106770e-32 4.0911336e-28 2.7528915e-33], sum to 1.0000
[2019-03-23 08:24:00,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8460
[2019-03-23 08:24:00,813] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.1, 87.5, 1.0, 2.0, 0.230136520758147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249874.7790733079, 249874.7790733082, 76504.61601633501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7266600.0000, 
sim time next is 7267200.0000, 
raw observation next is [14.0, 87.33333333333334, 1.0, 2.0, 0.2202738954924813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 239163.6272624306, 239163.6272624306, 75086.30499824932], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.8733333333333334, 1.0, 1.0, 0.025342369365601615, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08857912120830762, 0.08857912120830762, 0.18313732926402274], 
reward next is 0.8169, 
noisyNet noise sample is [array([-0.9040153], dtype=float32), -0.27244684]. 
=============================================
[2019-03-23 08:24:08,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6203421e-18 1.0000000e+00 1.6263423e-27 5.3105278e-26 1.1226171e-28], sum to 1.0000
[2019-03-23 08:24:08,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6755
[2019-03-23 08:24:08,217] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3787247859620684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423747.4802369588, 423747.4802369591, 121471.2324256049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7423200.0000, 
sim time next is 7423800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.377723096949508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 422394.8925786822, 422394.8925786825, 121282.3332381376], 
processed observation next is [1.0, 0.9565217391304348, 0.49090909090909096, 0.9, 1.0, 1.0, 0.22215387118688498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15644255280691935, 0.15644255280691946, 0.2958105688735063], 
reward next is 0.7042, 
noisyNet noise sample is [array([-1.6769505], dtype=float32), 1.1604631]. 
=============================================
[2019-03-23 08:24:14,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5191610e-20 1.0000000e+00 2.9816388e-28 1.1616123e-26 1.2548935e-30], sum to 1.0000
[2019-03-23 08:24:14,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1020
[2019-03-23 08:24:14,231] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 58.0, 1.0, 2.0, 0.4216108854384388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479008.4413910455, 479008.4413910455, 129294.2394377149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7500000.0000, 
sim time next is 7500600.0000, 
raw observation next is [25.25, 59.0, 1.0, 2.0, 0.4230292373238199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480864.2224840181, 480864.2224840181, 129636.0155751212], 
processed observation next is [0.0, 0.8260869565217391, 0.7840909090909091, 0.59, 1.0, 1.0, 0.27878654665477487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17809786017926596, 0.17809786017926596, 0.316185403841759], 
reward next is 0.6838, 
noisyNet noise sample is [array([0.53525144], dtype=float32), 0.43505117]. 
=============================================
[2019-03-23 08:24:15,452] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 08:24:15,454] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:24:15,455] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:24:15,456] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:15,456] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:24:15,457] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:24:15,456] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:15,458] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:15,458] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:24:15,459] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:15,463] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:24:15,471] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 08:24:15,472] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 08:24:15,521] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 08:24:15,521] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 08:24:15,522] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 08:24:28,585] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.75621104]
[2019-03-23 08:24:28,587] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.0, 78.83333333333333, 1.0, 2.0, 0.4542270752342902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518061.9530783548, 518061.9530783548, 134818.6013138615]
[2019-03-23 08:24:28,589] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:24:28,591] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.0582657e-18 1.0000000e+00 6.8187450e-27 6.6235461e-26 3.5456479e-29], sampled 0.20888240564092508
[2019-03-23 08:24:45,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.75621104]
[2019-03-23 08:24:45,011] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.25876513, 51.862769985, 1.0, 2.0, 0.38964613482758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 441487.600903387, 441487.6009033867, 129691.0793766381]
[2019-03-23 08:24:45,013] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:24:45,017] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0582657e-18 1.0000000e+00 6.8187450e-27 6.6235461e-26 3.5456479e-29], sampled 0.8485438193330421
[2019-03-23 08:25:21,677] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.75621104]
[2019-03-23 08:25:21,678] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.0, 55.5, 1.0, 2.0, 0.7725974986999795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 881573.0726852164, 881573.0726852161, 180880.4032954533]
[2019-03-23 08:25:21,679] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:25:21,683] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0582657e-18 1.0000000e+00 6.8187450e-27 6.6235461e-26 3.5456479e-29], sampled 0.2638144498319833
[2019-03-23 08:25:45,426] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.75621104]
[2019-03-23 08:25:45,427] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.5902646, 100.0, 1.0, 2.0, 0.3645815490493598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 407524.5588773973, 407524.5588773973, 124428.4755904107]
[2019-03-23 08:25:45,428] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:25:45,430] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.0582657e-18 1.0000000e+00 6.8187450e-27 6.6235461e-26 3.5456479e-29], sampled 0.227869911330287
[2019-03-23 08:25:59,297] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:25:59,449] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:25:59,545] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:25:59,556] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:25:59,560] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:26:00,576] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 625000, evaluation results [625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:26:04,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2997048e-19 1.0000000e+00 1.4433466e-26 1.2910769e-25 2.1046892e-29], sum to 1.0000
[2019-03-23 08:26:04,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6103
[2019-03-23 08:26:04,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1200567.074455293 W.
[2019-03-23 08:26:04,403] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 72.0, 1.0, 2.0, 0.3537432003939006, 1.0, 1.0, 0.3537432003939006, 1.0, 2.0, 0.7160441935864916, 6.911199999999999, 6.9112, 77.3421103, 1200567.074455293, 1200567.074455293, 283365.6037609009], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7642800.0000, 
sim time next is 7643400.0000, 
raw observation next is [25.68333333333333, 70.83333333333333, 1.0, 2.0, 0.5542509251114722, 1.0, 2.0, 0.5542509251114722, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846340789337, 1253992.250701469, 1253992.250701469, 247559.3063256526], 
processed observation next is [1.0, 0.4782608695652174, 0.8037878787878786, 0.7083333333333333, 1.0, 1.0, 0.4428136563893402, 1.0, 1.0, 0.4428136563893402, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288126862734, 0.4644415743338774, 0.4644415743338774, 0.6038031861601283], 
reward next is 0.3962, 
noisyNet noise sample is [array([0.30485797], dtype=float32), -1.4991508]. 
=============================================
[2019-03-23 08:26:04,850] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6816858e-18 1.0000000e+00 6.9650193e-27 8.0220461e-26 2.2970803e-29], sum to 1.0000
[2019-03-23 08:26:04,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8856
[2019-03-23 08:26:04,862] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1256970.763632785 W.
[2019-03-23 08:26:04,866] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.86666666666667, 69.66666666666667, 1.0, 2.0, 0.6231126392938463, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9762869678428272, 6.9112, 6.9112, 77.32846344354002, 1256970.763632785, 1256970.763632785, 280031.3675104429], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7644000.0000, 
sim time next is 7644600.0000, 
raw observation next is [26.05, 68.5, 1.0, 2.0, 0.6417350581485115, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9762482612688806, 6.911199999999999, 6.9112, 77.32846344354104, 1278203.167902794, 1278203.167902794, 282603.9243416867], 
processed observation next is [1.0, 0.4782608695652174, 0.8204545454545454, 0.685, 1.0, 1.0, 0.5521688226856394, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9660689446698296, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4734085807047385, 0.4734085807047385, 0.6892778642480164], 
reward next is 0.3107, 
noisyNet noise sample is [array([1.1748945], dtype=float32), -0.8898649]. 
=============================================
[2019-03-23 08:26:10,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5878225e-16 1.0000000e+00 5.9900839e-27 3.6886122e-26 2.5105055e-27], sum to 1.0000
[2019-03-23 08:26:10,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6556
[2019-03-23 08:26:10,330] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 57.0, 1.0, 2.0, 0.593021334852634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644144.3675489045, 644144.3675489045, 135721.3449797172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7732800.0000, 
sim time next is 7733400.0000, 
raw observation next is [21.36666666666667, 56.0, 1.0, 2.0, 0.720101335904501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 782290.7631577996, 782290.7631577996, 149420.9837736617], 
processed observation next is [1.0, 0.5217391304347826, 0.6075757575757578, 0.56, 1.0, 1.0, 0.6501266698806263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2897373196880739, 0.2897373196880739, 0.3644414238381992], 
reward next is 0.6356, 
noisyNet noise sample is [array([0.02496984], dtype=float32), 0.5823724]. 
=============================================
[2019-03-23 08:26:13,521] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.1380536e-20 1.0000000e+00 1.3455502e-29 1.7679581e-28 2.3237550e-32], sum to 1.0000
[2019-03-23 08:26:13,528] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8756
[2019-03-23 08:26:13,535] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666666, 70.33333333333333, 1.0, 2.0, 0.4729330119715943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513634.5788824979, 513634.5788824979, 118141.8521598151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7807200.0000, 
sim time next is 7807800.0000, 
raw observation next is [19.03333333333333, 69.16666666666667, 1.0, 2.0, 0.4838147584736224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525459.2178772574, 525459.2178772574, 121792.8132015129], 
processed observation next is [1.0, 0.34782608695652173, 0.5015151515151515, 0.6916666666666668, 1.0, 1.0, 0.35476844809202795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19461452513972496, 0.19461452513972496, 0.2970556419549095], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.8235503], dtype=float32), -0.15062734]. 
=============================================
[2019-03-23 08:26:15,939] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9918939e-20 1.0000000e+00 3.0106218e-29 1.6602094e-28 4.5340679e-30], sum to 1.0000
[2019-03-23 08:26:15,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4187
[2019-03-23 08:26:15,954] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 75.0, 1.0, 2.0, 0.3436344146293116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380259.2222732464, 380259.2222732467, 116776.6780924329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7887600.0000, 
sim time next is 7888200.0000, 
raw observation next is [20.08333333333334, 75.5, 1.0, 2.0, 0.3864351949308923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 428594.0763605628, 428594.0763605625, 120543.7832865763], 
processed observation next is [1.0, 0.30434782608695654, 0.5492424242424245, 0.755, 1.0, 1.0, 0.23304399366361533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15873854680020846, 0.15873854680020835, 0.2940092275282349], 
reward next is 0.7060, 
noisyNet noise sample is [array([0.9298181], dtype=float32), -0.6330378]. 
=============================================
[2019-03-23 08:26:18,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2715597e-18 1.0000000e+00 2.7203918e-27 1.5923306e-22 5.7467549e-28], sum to 1.0000
[2019-03-23 08:26:18,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2082
[2019-03-23 08:26:18,699] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 87.5, 1.0, 2.0, 0.8826518137016123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1006955.87645901, 1006955.87645901, 193130.7586909633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [21.43333333333334, 88.0, 1.0, 2.0, 0.8733974492204999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 996346.8347847409, 996346.8347847413, 191512.4735966635], 
processed observation next is [1.0, 0.6956521739130435, 0.6106060606060609, 0.88, 1.0, 1.0, 0.8417468115256249, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36901734621657073, 0.36901734621657084, 0.4671035941382037], 
reward next is 0.5329, 
noisyNet noise sample is [array([0.4891346], dtype=float32), -0.785493]. 
=============================================
[2019-03-23 08:26:20,005] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:20,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:20,024] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 08:26:20,786] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:20,787] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:20,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 08:26:20,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:20,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:20,862] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 08:26:20,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:20,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:20,974] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 08:26:20,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:20,996] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,009] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 08:26:21,336] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:21,337] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 08:26:21,406] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:21,406] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,408] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 08:26:21,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:21,513] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 08:26:21,555] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:21,556] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 08:26:21,589] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:21,590] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,592] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 08:26:21,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:21,681] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:21,682] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 08:26:22,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:22,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:22,095] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 08:26:22,134] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:22,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:22,136] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 08:26:22,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:22,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:22,269] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 08:26:22,324] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:22,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:22,327] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 08:26:22,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:26:22,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:22,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 08:26:26,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0737462e-17 1.0000000e+00 8.5153690e-22 3.8905509e-23 1.6856151e-27], sum to 1.0000
[2019-03-23 08:26:26,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3812
[2019-03-23 08:26:26,111] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 73.66666666666667, 1.0, 2.0, 0.3144831358267037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341487.7540462222, 341487.7540462222, 106673.2232230525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 76200.0000, 
sim time next is 76800.0000, 
raw observation next is [18.0, 74.33333333333334, 1.0, 2.0, 0.3037962725112994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329879.2754178653, 329879.2754178656, 99311.67459121472], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.7433333333333334, 1.0, 1.0, 0.12974534063912427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1221775094140242, 0.12217750941402429, 0.24222359656393833], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.7134556], dtype=float32), -0.37242517]. 
=============================================
[2019-03-23 08:26:32,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1265096e-19 1.0000000e+00 2.5409514e-27 4.7390888e-27 1.4568019e-30], sum to 1.0000
[2019-03-23 08:26:32,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1190
[2019-03-23 08:26:32,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 201274.0864340625, 201274.0864340622, 69363.45538772807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 193200.0000, 
sim time next is 193800.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 200859.5592877699, 200859.5592877699, 69291.2638765656], 
processed observation next is [0.0, 0.21739130434782608, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0743924293658407, 0.0743924293658407, 0.16900308262576977], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17442214], dtype=float32), -1.5040838]. 
=============================================
[2019-03-23 08:26:41,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.644009e-20 1.000000e+00 8.853234e-29 8.817512e-28 4.152984e-32], sum to 1.0000
[2019-03-23 08:26:41,710] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7875
[2019-03-23 08:26:41,717] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 62.66666666666667, 1.0, 2.0, 0.2955363642879061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 320907.2378513027, 320907.2378513027, 84091.03618055861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 382800.0000, 
sim time next is 383400.0000, 
raw observation next is [17.5, 60.0, 1.0, 2.0, 0.3023002732548105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328254.2860647654, 328254.2860647654, 84037.21170550282], 
processed observation next is [1.0, 0.43478260869565216, 0.4318181818181818, 0.6, 1.0, 1.0, 0.12787534156851313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12157566150546867, 0.12157566150546867, 0.20496880903781176], 
reward next is 0.7950, 
noisyNet noise sample is [array([-2.5699444], dtype=float32), -0.6090112]. 
=============================================
[2019-03-23 08:26:49,697] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 08:26:49,699] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:26:49,701] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:26:49,702] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:26:49,703] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:49,704] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:49,705] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:49,705] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:26:49,708] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:26:49,710] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:49,712] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:26:49,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 08:26:49,729] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 08:26:49,752] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 08:26:49,777] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 08:26:49,822] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 08:26:51,180] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:26:51,182] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.11882334, 100.0, 1.0, 2.0, 0.3611996053491441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 405369.669995666, 405369.6699956657, 124918.0872820465]
[2019-03-23 08:26:51,183] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:26:51,186] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.47707698014381494
[2019-03-23 08:27:10,265] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:27:10,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.83333333333333, 100.0, 1.0, 2.0, 0.4633529876063499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528715.7522405231, 528715.7522405231, 136890.8430658874]
[2019-03-23 08:27:10,272] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:27:10,275] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.05747587755328576
[2019-03-23 08:27:13,565] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:27:13,568] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.52583457666667, 80.61569273333333, 1.0, 2.0, 0.472666411586911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 527768.6934090507, 527768.6934090503, 133837.1453720104]
[2019-03-23 08:27:13,571] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:27:13,573] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.6261308103947714
[2019-03-23 08:27:28,095] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:27:28,098] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.11666666666667, 43.33333333333333, 1.0, 2.0, 0.4062800983666371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 457947.6916055417, 457947.6916055417, 129809.2413726198]
[2019-03-23 08:27:28,100] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:27:28,103] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.19660102281853487
[2019-03-23 08:27:52,471] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:27:52,472] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.0220858, 50.84493072333334, 1.0, 2.0, 0.3406578003104949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 372506.5935418724, 372506.593541872, 119206.2796590866]
[2019-03-23 08:27:52,473] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:27:52,475] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.008649310372422447
[2019-03-23 08:28:15,069] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:28:15,070] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.23333333333333, 80.33333333333334, 1.0, 2.0, 0.2733246888950533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 296764.1306678791, 296764.1306678791, 100078.9591941446]
[2019-03-23 08:28:15,070] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:28:15,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.571854227129229
[2019-03-23 08:28:24,491] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:28:24,492] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [26.9, 66.0, 1.0, 2.0, 0.9171529226775801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 1042849.026007523, 1042849.026007523, 211270.832252128]
[2019-03-23 08:28:24,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:28:24,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.3405314275830298
[2019-03-23 08:28:27,439] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:28:27,440] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.31218328333333, 54.25722067, 1.0, 2.0, 0.3033641106694917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 329388.5738518795, 329388.5738518795, 107680.1007412041]
[2019-03-23 08:28:27,442] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:28:27,444] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.29299425204719987
[2019-03-23 08:28:27,552] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6761269]
[2019-03-23 08:28:27,553] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.66666666666667, 52.33333333333334, 1.0, 2.0, 0.3027956180044886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 328771.1435076721, 328771.1435076725, 97726.09720817264]
[2019-03-23 08:28:27,556] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:28:27,559] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.8144391e-21 1.0000000e+00 4.1323314e-31 8.0779799e-30 8.9479732e-34], sampled 0.06814898904563904
[2019-03-23 08:28:33,098] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:28:33,453] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:28:33,551] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:28:33,730] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:28:33,796] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:28:34,811] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 650000, evaluation results [650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:28:38,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6083089e-19 1.0000000e+00 7.6958774e-28 1.1761477e-27 3.2426383e-31], sum to 1.0000
[2019-03-23 08:28:38,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9453
[2019-03-23 08:28:38,875] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3086342552996358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 335923.9249730486, 335923.9249730483, 112049.6278514918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 595800.0000, 
sim time next is 596400.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3086686106252736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 335961.9516013134, 335961.9516013134, 112052.1965592737], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.83, 1.0, 1.0, 0.135835763281592, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1244303524449309, 0.1244303524449309, 0.27329804038847244], 
reward next is 0.7267, 
noisyNet noise sample is [array([1.8573403], dtype=float32), -1.445883]. 
=============================================
[2019-03-23 08:28:41,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0814585e-18 1.0000000e+00 7.2096171e-27 4.0980594e-25 2.5035134e-28], sum to 1.0000
[2019-03-23 08:28:41,653] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6004
[2019-03-23 08:28:41,657] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 48.0, 1.0, 2.0, 0.9150479321614733, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1036011.662151827, 1036011.662151827, 191374.3566935584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 666000.0000, 
sim time next is 666600.0000, 
raw observation next is [25.83333333333334, 48.33333333333333, 1.0, 2.0, 0.542507289082416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 611663.8793437905, 611663.8793437902, 139177.8982353066], 
processed observation next is [1.0, 0.7391304347826086, 0.8106060606060609, 0.4833333333333333, 1.0, 1.0, 0.42813411135301993, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2265421775347372, 0.22654217753473713, 0.3394582883787966], 
reward next is 0.6605, 
noisyNet noise sample is [array([-0.6997203], dtype=float32), -0.71204877]. 
=============================================
[2019-03-23 08:28:41,854] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.5936924e-20 1.0000000e+00 2.8077194e-28 9.0214195e-27 4.0357614e-30], sum to 1.0000
[2019-03-23 08:28:41,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8324
[2019-03-23 08:28:41,862] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.358493091165803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 400406.3172751041, 400406.3172751044, 119468.2654590628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 673200.0000, 
sim time next is 673800.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3571542381233087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 398855.5712839062, 398855.5712839062, 119334.8425518479], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.19644279765413586, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.147724285660706, 0.147724285660706, 0.29106059158987296], 
reward next is 0.7089, 
noisyNet noise sample is [array([1.8398225], dtype=float32), 0.6341319]. 
=============================================
[2019-03-23 08:28:48,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3598590e-19 1.0000000e+00 3.0263801e-25 2.7812732e-27 1.5544668e-28], sum to 1.0000
[2019-03-23 08:28:48,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4805
[2019-03-23 08:28:48,119] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 89.0, 1.0, 2.0, 0.4161237759954886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472736.6435995237, 472736.6435995237, 128732.1036215485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 802200.0000, 
sim time next is 802800.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4232138994983671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 481346.8756731279, 481346.8756731282, 129896.0416569622], 
processed observation next is [0.0, 0.30434782608695654, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2790173743729588, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.178276620619677, 0.1782766206196771, 0.3168196137974688], 
reward next is 0.6832, 
noisyNet noise sample is [array([-0.99094474], dtype=float32), 0.45560807]. 
=============================================
[2019-03-23 08:28:48,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1232305e-19 1.0000000e+00 1.2947591e-28 2.2309900e-28 4.1310393e-31], sum to 1.0000
[2019-03-23 08:28:48,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1033
[2019-03-23 08:28:48,317] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3849685324820958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433786.9790718399, 433786.9790718399, 123496.6490426247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798000.0000, 
sim time next is 798600.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3848651857781222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433670.330040581, 433670.330040581, 123487.4432987869], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.2310814822226527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16061864075577073, 0.16061864075577073, 0.3011888860946022], 
reward next is 0.6988, 
noisyNet noise sample is [array([0.39493993], dtype=float32), 0.4036262]. 
=============================================
[2019-03-23 08:28:54,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3298096e-16 1.0000000e+00 1.5067639e-25 2.5981593e-23 1.1781504e-27], sum to 1.0000
[2019-03-23 08:28:54,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5168
[2019-03-23 08:28:54,157] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4881343267555268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 556894.8919247905, 556894.8919247901, 140256.09526002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [25.5, 67.16666666666667, 1.0, 2.0, 0.4856384270775086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554101.0813451242, 554101.0813451242, 139784.6981616789], 
processed observation next is [0.0, 0.5217391304347826, 0.7954545454545454, 0.6716666666666667, 1.0, 1.0, 0.3570480338468857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20522262272041636, 0.20522262272041636, 0.34093828819921684], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.5675357], dtype=float32), 0.7841471]. 
=============================================
[2019-03-23 08:28:54,233] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8790061e-17 1.0000000e+00 8.6310287e-25 3.8442858e-23 2.4401998e-27], sum to 1.0000
[2019-03-23 08:28:54,239] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3337
[2019-03-23 08:28:54,244] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 77.0, 1.0, 2.0, 0.482141022460379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550105.1647301076, 550105.1647301076, 139401.2589666729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 904800.0000, 
sim time next is 905400.0000, 
raw observation next is [24.5, 74.0, 1.0, 2.0, 0.4856818304281775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554119.1458103271, 554119.1458103274, 139903.5195097997], 
processed observation next is [0.0, 0.4782608695652174, 0.75, 0.74, 1.0, 1.0, 0.3571022880352218, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20522931326308413, 0.20522931326308422, 0.3412280963653651], 
reward next is 0.6588, 
noisyNet noise sample is [array([-1.4215404], dtype=float32), -1.97937]. 
=============================================
[2019-03-23 08:28:59,684] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0646761e-17 1.0000000e+00 4.7737078e-27 6.4360948e-25 2.3246020e-28], sum to 1.0000
[2019-03-23 08:28:59,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3263
[2019-03-23 08:28:59,697] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 208716.2536055604, 208716.2536055601, 70671.10559673765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1031400.0000, 
sim time next is 1032000.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 207881.1245233392, 207881.1245233392, 70509.96661878553], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07699300908271822, 0.07699300908271822, 0.1719755283385013], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6892498], dtype=float32), 0.9502352]. 
=============================================
[2019-03-23 08:28:59,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.10977]
 [73.10977]
 [73.10977]
 [73.10977]
 [73.10977]], R is [[72.378685  ]
 [71.6548996 ]
 [70.93835449]
 [70.22897339]
 [70.35054016]].
[2019-03-23 08:29:05,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5391911e-20 1.0000000e+00 2.2710223e-27 1.2250505e-26 8.9650752e-30], sum to 1.0000
[2019-03-23 08:29:05,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2307
[2019-03-23 08:29:05,412] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 88.0, 1.0, 2.0, 0.3106013851691072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339395.8679246999, 339395.8679247002, 112657.4582900665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1129200.0000, 
sim time next is 1129800.0000, 
raw observation next is [17.83333333333333, 88.0, 1.0, 2.0, 0.3148409526506644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345112.2186367241, 345112.2186367241, 113347.5799630947], 
processed observation next is [1.0, 0.043478260869565216, 0.44696969696969674, 0.88, 1.0, 1.0, 0.1435511908133305, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12781934023582375, 0.12781934023582375, 0.27645751210510905], 
reward next is 0.7235, 
noisyNet noise sample is [array([1.3076582], dtype=float32), 0.24551417]. 
=============================================
[2019-03-23 08:29:06,089] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1603220e-18 1.0000000e+00 1.0457887e-26 3.0803303e-25 1.1317882e-29], sum to 1.0000
[2019-03-23 08:29:06,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5874
[2019-03-23 08:29:06,100] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 88.0, 1.0, 2.0, 0.3148409526506644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345112.2186367241, 345112.2186367241, 113347.5799630947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1129800.0000, 
sim time next is 1130400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3187681011604869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350472.040807142, 350472.040807142, 114019.5130803875], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.14846012645060863, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12980445955820075, 0.12980445955820075, 0.2780963733667988], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.03382926], dtype=float32), -0.56154954]. 
=============================================
[2019-03-23 08:29:22,404] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 08:29:22,405] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:29:22,406] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:22,408] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:29:22,409] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:29:22,409] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:22,409] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:29:22,411] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:22,410] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:29:22,415] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:22,415] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:29:22,430] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 08:29:22,453] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 08:29:22,454] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 08:29:22,500] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 08:29:22,500] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 08:29:48,688] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:29:48,689] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.66520707333333, 40.79285825166667, 1.0, 2.0, 0.3201303262702334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 347598.3645108884, 347598.364510888, 106602.599978431]
[2019-03-23 08:29:48,690] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:29:48,693] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.5367077811501015
[2019-03-23 08:30:34,042] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:30:34,042] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.2, 66.66666666666667, 1.0, 2.0, 0.4368917384143966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497329.0418507463, 497329.0418507463, 131665.7377747785]
[2019-03-23 08:30:34,045] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:30:34,048] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.5282452729072986
[2019-03-23 08:30:49,785] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:30:49,786] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.46583819, 96.03671494, 1.0, 2.0, 0.5513442848580733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 627622.1840057074, 627622.184005707, 153750.0181636749]
[2019-03-23 08:30:49,787] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:30:49,790] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.39555041519946965
[2019-03-23 08:30:53,899] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:30:53,901] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.3, 48.0, 1.0, 2.0, 0.4493208445019893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512309.9027078074, 512309.9027078074, 134000.5928734972]
[2019-03-23 08:30:53,901] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:30:53,904] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.09555053957084703
[2019-03-23 08:30:55,043] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:30:55,044] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.67800192333334, 98.51307021666668, 1.0, 2.0, 0.4604261250792758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 525257.4467700708, 525257.4467700705, 140285.2926440293]
[2019-03-23 08:30:55,044] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:30:55,047] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.24014586772079982
[2019-03-23 08:30:58,947] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:30:58,948] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.73333333333333, 70.33333333333334, 1.0, 2.0, 0.3487040961512775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386491.0120990074, 386491.0120990074, 117413.457650272]
[2019-03-23 08:30:58,949] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:30:58,952] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.5563801486070481
[2019-03-23 08:31:04,286] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.71197206]
[2019-03-23 08:31:04,287] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.0, 86.0, 1.0, 2.0, 0.2350729599977528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 255223.2391478159, 255223.2391478159, 84117.16727516621]
[2019-03-23 08:31:04,288] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:31:04,290] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.0825334e-18 1.0000000e+00 4.0149476e-26 4.0996386e-25 2.2903876e-28], sampled 0.877640285353691
[2019-03-23 08:31:05,725] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:31:05,751] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:31:05,961] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:31:06,005] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:31:06,153] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:31:07,169] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 675000, evaluation results [675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:31:08,001] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0474949e-16 1.0000000e+00 4.8485313e-27 1.4252590e-25 3.6615373e-28], sum to 1.0000
[2019-03-23 08:31:08,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3601
[2019-03-23 08:31:08,019] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4431047736784595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505180.1768465665, 505180.1768465665, 133285.0875437339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1487400.0000, 
sim time next is 1488000.0000, 
raw observation next is [20.33333333333334, 100.0, 1.0, 2.0, 0.4470509132291686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509873.6873860505, 509873.6873860505, 134060.5077544042], 
processed observation next is [0.0, 0.21739130434782608, 0.5606060606060609, 1.0, 1.0, 1.0, 0.30881364153646074, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18884210643927796, 0.18884210643927796, 0.3269768481814737], 
reward next is 0.6730, 
noisyNet noise sample is [array([1.6774539], dtype=float32), -1.3457643]. 
=============================================
[2019-03-23 08:31:08,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.51116]
 [71.51116]
 [71.51116]
 [71.51116]
 [71.51116]], R is [[71.46907043]
 [71.42929077]
 [71.39133453]
 [71.35397339]
 [71.3170166 ]].
[2019-03-23 08:31:09,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5659125e-15 1.0000000e+00 3.2286051e-23 9.0240150e-24 1.6472285e-26], sum to 1.0000
[2019-03-23 08:31:09,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9145
[2019-03-23 08:31:09,773] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 74.5, 1.0, 2.0, 0.6191868178795072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695813.4065992214, 695813.4065992214, 161599.2810034892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510200.0000, 
sim time next is 1510800.0000, 
raw observation next is [27.66666666666666, 73.0, 1.0, 2.0, 0.6147844078796242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 690862.6657883872, 690862.6657883872, 160973.3350896789], 
processed observation next is [0.0, 0.4782608695652174, 0.8939393939393937, 0.73, 1.0, 1.0, 0.5184805098495302, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25587506140310634, 0.25587506140310634, 0.39261789046263146], 
reward next is 0.6074, 
noisyNet noise sample is [array([-2.4637423], dtype=float32), -0.50634694]. 
=============================================
[2019-03-23 08:31:13,308] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1920089e-15 1.0000000e+00 3.0145843e-23 2.5119859e-23 7.4657650e-27], sum to 1.0000
[2019-03-23 08:31:13,311] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9099
[2019-03-23 08:31:13,313] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 94.0, 1.0, 2.0, 0.4128746363218472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469758.9252341168, 469758.9252341168, 129049.9719225623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1578000.0000, 
sim time next is 1578600.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.4177042163579555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475609.6802628671, 475609.6802628671, 129889.2120875308], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.94, 1.0, 1.0, 0.27213027044744437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17615173343069154, 0.17615173343069154, 0.31680295631105077], 
reward next is 0.6832, 
noisyNet noise sample is [array([-0.07224535], dtype=float32), -1.0033687]. 
=============================================
[2019-03-23 08:31:15,163] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3510234e-15 1.0000000e+00 7.2189059e-23 3.8506889e-21 2.7455406e-25], sum to 1.0000
[2019-03-23 08:31:15,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2711
[2019-03-23 08:31:15,173] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4246618138523653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482499.4537468406, 482499.4537468406, 129611.089637459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1627200.0000, 
sim time next is 1627800.0000, 
raw observation next is [21.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4192625442658814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476083.8609599624, 476083.8609599624, 128862.2811553196], 
processed observation next is [1.0, 0.8695652173913043, 0.628787878787879, 0.7883333333333333, 1.0, 1.0, 0.2740781803323517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1763273559110972, 0.1763273559110972, 0.3142982467202917], 
reward next is 0.6857, 
noisyNet noise sample is [array([-2.656422], dtype=float32), -1.0542096]. 
=============================================
[2019-03-23 08:31:19,737] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.13798165e-17 1.00000000e+00 3.55715881e-24 3.11417168e-23
 8.13966750e-28], sum to 1.0000
[2019-03-23 08:31:19,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1969
[2019-03-23 08:31:19,756] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 41.0, 1.0, 2.0, 0.43548986285746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472949.2156477051, 472949.2156477051, 94320.78793338496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1787400.0000, 
sim time next is 1788000.0000, 
raw observation next is [19.13333333333333, 41.33333333333334, 1.0, 2.0, 0.4184257361666913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454408.6302365446, 454408.6302365446, 92781.05536625537], 
processed observation next is [1.0, 0.6956521739130435, 0.5060606060606059, 0.41333333333333344, 1.0, 1.0, 0.2730321702083641, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1682994926802017, 0.1682994926802017, 0.22629525699086675], 
reward next is 0.7737, 
noisyNet noise sample is [array([1.2732402], dtype=float32), -0.33619595]. 
=============================================
[2019-03-23 08:31:19,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.01389]
 [71.01389]
 [71.01389]
 [71.01389]
 [71.01389]], R is [[71.07745361]
 [71.1366272 ]
 [71.19532013]
 [71.2498703 ]
 [71.30910492]].
[2019-03-23 08:31:20,136] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5461022e-21 1.0000000e+00 3.5430671e-28 2.1691999e-27 2.0703119e-30], sum to 1.0000
[2019-03-23 08:31:20,146] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3140
[2019-03-23 08:31:20,153] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.0, 66.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 177329.9556810639, 177329.9556810642, 61435.55347793527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1728000.0000, 
sim time next is 1728600.0000, 
raw observation next is [10.66666666666667, 66.83333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 174352.5427461658, 174352.5427461656, 61041.17873077469], 
processed observation next is [1.0, 0.0, 0.12121212121212134, 0.6683333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.06457501583191326, 0.06457501583191318, 0.14888092373359682], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.82975346], dtype=float32), 0.38014314]. 
=============================================
[2019-03-23 08:31:21,108] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5248285e-17 1.0000000e+00 6.6671003e-25 3.4780992e-24 1.0647159e-26], sum to 1.0000
[2019-03-23 08:31:21,117] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5532
[2019-03-23 08:31:21,123] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 63.0, 1.0, 2.0, 0.2039200223960056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221403.2758436803, 221403.2758436801, 70055.96774573112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1812600.0000, 
sim time next is 1813200.0000, 
raw observation next is [14.66666666666667, 64.33333333333333, 1.0, 2.0, 0.200303200491539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217475.4848199889, 217475.4848199886, 69516.88564728231], 
processed observation next is [1.0, 1.0, 0.30303030303030315, 0.6433333333333333, 1.0, 1.0, 0.00037900061442372457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08054647585925515, 0.08054647585925503, 0.16955337962751782], 
reward next is 0.8304, 
noisyNet noise sample is [array([-1.167684], dtype=float32), 0.8817813]. 
=============================================
[2019-03-23 08:31:21,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4406099e-19 1.0000000e+00 6.6838490e-27 1.4475552e-24 2.3048494e-28], sum to 1.0000
[2019-03-23 08:31:21,403] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4522
[2019-03-23 08:31:21,411] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3270730601561735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355163.7656872332, 355163.7656872332, 77005.1165548944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1739400.0000, 
sim time next is 1740000.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.3290618638575187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357324.1714810968, 357324.1714810965, 77200.29902041587], 
processed observation next is [1.0, 0.13043478260869565, 0.0, 0.81, 1.0, 1.0, 0.16132732982189832, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13234228573373957, 0.13234228573373943, 0.18829341224491675], 
reward next is 0.8117, 
noisyNet noise sample is [array([1.5587296], dtype=float32), -0.6740804]. 
=============================================
[2019-03-23 08:31:21,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.1436]
 [68.1436]
 [68.1436]
 [68.1436]
 [68.1436]], R is [[68.27387238]
 [68.40331268]
 [68.53279877]
 [68.66027832]
 [68.78562927]].
[2019-03-23 08:31:25,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.24157957e-16 1.00000000e+00 1.04798162e-25 3.80282972e-25
 1.06013565e-27], sum to 1.0000
[2019-03-23 08:31:25,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0216
[2019-03-23 08:31:25,435] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 66.0, 1.0, 2.0, 0.2533093382478716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275042.1877832446, 275042.1877832449, 87616.41466289067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1899000.0000, 
sim time next is 1899600.0000, 
raw observation next is [18.33333333333334, 66.66666666666666, 1.0, 2.0, 0.2513901466447849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272957.7530481738, 272957.7530481738, 86855.3437010372], 
processed observation next is [1.0, 1.0, 0.46969696969696995, 0.6666666666666665, 1.0, 1.0, 0.06423768330598108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10109546409191622, 0.10109546409191622, 0.21184230170984683], 
reward next is 0.7882, 
noisyNet noise sample is [array([-0.942986], dtype=float32), -0.4804617]. 
=============================================
[2019-03-23 08:31:29,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6734326e-22 1.0000000e+00 1.3747758e-30 1.3376688e-29 4.5262525e-32], sum to 1.0000
[2019-03-23 08:31:29,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6164
[2019-03-23 08:31:29,099] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 66.66666666666666, 1.0, 2.0, 0.2513901466447849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 272957.7530481738, 272957.7530481738, 86855.3437010372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1899600.0000, 
sim time next is 1900200.0000, 
raw observation next is [18.16666666666666, 67.33333333333334, 1.0, 2.0, 0.2496456877704642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271063.103347244, 271063.1033472437, 86128.79769977194], 
processed observation next is [1.0, 1.0, 0.4621212121212119, 0.6733333333333335, 1.0, 1.0, 0.06205710971308023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10039374198046074, 0.10039374198046062, 0.21007023829212668], 
reward next is 0.7899, 
noisyNet noise sample is [array([-0.16302152], dtype=float32), -1.1913166]. 
=============================================
[2019-03-23 08:31:31,627] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0896879e-15 1.0000000e+00 4.9897383e-23 1.6204137e-22 3.4525728e-24], sum to 1.0000
[2019-03-23 08:31:31,636] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3104
[2019-03-23 08:31:31,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1281245.585563743 W.
[2019-03-23 08:31:31,654] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.83333333333334, 61.0, 1.0, 2.0, 0.374837710929851, 1.0, 2.0, 0.374837710929851, 1.0, 1.0, 0.7589788945951255, 6.9112, 6.9112, 77.3421103, 1281245.585563743, 1281245.585563743, 287346.5340003377], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1951800.0000, 
sim time next is 1952400.0000, 
raw observation next is [25.66666666666667, 61.0, 1.0, 2.0, 0.5932015237196808, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9690812245904994, 6.911199999999999, 6.9112, 77.32846344354104, 1225509.452332562, 1225509.452332563, 268854.5011579172], 
processed observation next is [1.0, 0.6086956521739131, 0.8030303030303032, 0.61, 1.0, 1.0, 0.491501904649601, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9558303208435706, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4538923897528008, 0.4538923897528011, 0.6557426857510176], 
reward next is 0.3443, 
noisyNet noise sample is [array([-1.9931084], dtype=float32), -0.047898967]. 
=============================================
[2019-03-23 08:31:32,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4665843e-15 1.0000000e+00 5.0352515e-21 4.4267617e-20 2.1495736e-24], sum to 1.0000
[2019-03-23 08:31:32,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3912
[2019-03-23 08:31:32,665] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 60.0, 1.0, 2.0, 0.3281450021759595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359318.3571911933, 359318.3571911933, 114161.313310633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1978200.0000, 
sim time next is 1978800.0000, 
raw observation next is [21.33333333333334, 60.0, 1.0, 2.0, 0.3235392025787905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353270.011074937, 353270.0110749367, 113471.6830907771], 
processed observation next is [1.0, 0.9130434782608695, 0.6060606060606063, 0.6, 1.0, 1.0, 0.1544240032234881, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13084074484256927, 0.13084074484256916, 0.27676020266043194], 
reward next is 0.7232, 
noisyNet noise sample is [array([1.2477936], dtype=float32), 0.99535185]. 
=============================================
[2019-03-23 08:31:35,223] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7512855e-21 1.0000000e+00 9.9290707e-31 4.7329774e-29 1.1288329e-32], sum to 1.0000
[2019-03-23 08:31:35,232] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9544
[2019-03-23 08:31:35,236] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 64.0, 1.0, 2.0, 0.285012412074524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309476.2011685559, 309476.2011685562, 100305.2473971312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2020800.0000, 
sim time next is 2021400.0000, 
raw observation next is [20.0, 62.0, 1.0, 2.0, 0.2849071779369726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 309361.8980072344, 309361.8980072347, 100735.7487526605], 
processed observation next is [0.0, 0.391304347826087, 0.5454545454545454, 0.62, 1.0, 1.0, 0.10613397242121576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11457848074342014, 0.11457848074342025, 0.24569694817722074], 
reward next is 0.7543, 
noisyNet noise sample is [array([-0.23274218], dtype=float32), -1.74617]. 
=============================================
[2019-03-23 08:31:41,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0439957e-17 1.0000000e+00 9.7227176e-27 1.1498768e-25 1.8675211e-28], sum to 1.0000
[2019-03-23 08:31:41,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0526
[2019-03-23 08:31:41,138] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 88.0, 1.0, 2.0, 0.3175128460409741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 345448.437326455, 345448.4373264547, 112612.1051221414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2162400.0000, 
sim time next is 2163000.0000, 
raw observation next is [17.16666666666667, 88.0, 1.0, 2.0, 0.3125530162570411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 339391.164032442, 339391.164032442, 112041.2472996097], 
processed observation next is [1.0, 0.0, 0.4166666666666669, 0.88, 1.0, 1.0, 0.14069127032130138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12570043112312665, 0.12570043112312665, 0.2732713348770968], 
reward next is 0.7267, 
noisyNet noise sample is [array([0.40927708], dtype=float32), 0.72213167]. 
=============================================
[2019-03-23 08:31:41,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.56903]
 [67.56903]
 [67.56903]
 [67.56903]
 [67.56903]], R is [[67.62007141]
 [67.66920471]
 [67.71620178]
 [67.76126862]
 [67.80474091]].
[2019-03-23 08:31:42,561] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1281521e-18 1.0000000e+00 1.9169326e-30 7.2595647e-28 8.1331062e-31], sum to 1.0000
[2019-03-23 08:31:42,568] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7360
[2019-03-23 08:31:42,572] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3017394041185956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327645.0583012966, 327645.0583012966, 110185.898786017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2166000.0000, 
sim time next is 2166600.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3007812447936259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 326604.2874073281, 326604.2874073279, 110096.4501295642], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.12597655599203234, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12096455089160299, 0.12096455089160293, 0.2685279271452785], 
reward next is 0.7315, 
noisyNet noise sample is [array([-0.4757131], dtype=float32), -0.7787271]. 
=============================================
[2019-03-23 08:31:46,312] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1935734e-19 1.0000000e+00 8.3534765e-28 3.6385231e-27 3.6470639e-30], sum to 1.0000
[2019-03-23 08:31:46,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8101
[2019-03-23 08:31:46,326] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.00000000000001, 1.0, 2.0, 0.2006765332637619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217880.9147363368, 217880.9147363365, 71647.95569754955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2261400.0000, 
sim time next is 2262000.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214542.5944051744, 214542.5944051741, 71187.86457226946], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0794602201500646, 0.07946022015006449, 0.17362893798114504], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31325936], dtype=float32), -0.3026581]. 
=============================================
[2019-03-23 08:31:46,349] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.147385]
 [72.147385]
 [72.147385]
 [72.147385]
 [72.147385]], R is [[71.42590332]
 [71.53689575]
 [70.82152557]
 [70.11331177]
 [70.23487091]].
[2019-03-23 08:31:47,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.783880e-19 1.000000e+00 6.136621e-29 8.776040e-27 3.101805e-31], sum to 1.0000
[2019-03-23 08:31:47,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3989
[2019-03-23 08:31:47,286] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215326.2861729199, 215326.2861729202, 71776.16138737391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2260200.0000, 
sim time next is 2260800.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 214749.3301330721, 214749.3301330721, 71201.19041427225], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07953678893817485, 0.07953678893817485, 0.17366144003481035], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7165883], dtype=float32), -2.543545]. 
=============================================
[2019-03-23 08:31:48,832] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2605080e-20 1.0000000e+00 1.6608230e-29 1.5808333e-27 5.8715698e-31], sum to 1.0000
[2019-03-23 08:31:48,840] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1703
[2019-03-23 08:31:48,845] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 52.0, 1.0, 2.0, 0.4078560937789581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442924.8133421099, 442924.8133421099, 92942.21833493933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2289600.0000, 
sim time next is 2290200.0000, 
raw observation next is [18.33333333333333, 51.5, 1.0, 2.0, 0.5116119819602232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555666.3490291903, 555666.3490291903, 104560.4697650059], 
processed observation next is [1.0, 0.5217391304347826, 0.4696969696969695, 0.515, 1.0, 1.0, 0.3895149774502789, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2058023514922927, 0.2058023514922927, 0.2550255360122095], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.47080916], dtype=float32), -0.15477379]. 
=============================================
[2019-03-23 08:31:54,691] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 08:31:54,691] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:31:54,691] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:31:54,692] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:54,693] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:31:54,693] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:54,695] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:54,696] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:31:54,697] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:54,697] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:31:54,699] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:31:54,715] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 08:31:54,741] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 08:31:54,765] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 08:31:54,768] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 08:31:54,814] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 08:32:08,226] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.63508654]
[2019-03-23 08:32:08,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.10853289666667, 98.09791137, 1.0, 2.0, 0.4559763058166461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 519746.004203747, 519746.0042037466, 138838.831442883]
[2019-03-23 08:32:08,228] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:32:08,234] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3445618e-20 1.0000000e+00 1.4167194e-28 1.7768025e-27 4.8053057e-31], sampled 0.23321738553097193
[2019-03-23 08:32:24,187] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.63508654]
[2019-03-23 08:32:24,189] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.12258903, 54.77473174000001, 1.0, 2.0, 0.3998161398346907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 451901.4126035347, 451901.4126035347, 129924.641912373]
[2019-03-23 08:32:24,190] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:32:24,194] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.3445618e-20 1.0000000e+00 1.4167194e-28 1.7768025e-27 4.8053057e-31], sampled 0.32911973109119474
[2019-03-23 08:32:53,108] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.63508654]
[2019-03-23 08:32:53,109] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.32350095166667, 40.16936906333333, 1.0, 2.0, 0.307128624662431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 333477.1653392562, 333477.1653392562, 94431.1538841019]
[2019-03-23 08:32:53,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:32:53,115] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.3445618e-20 1.0000000e+00 1.4167194e-28 1.7768025e-27 4.8053057e-31], sampled 0.07624401294361771
[2019-03-23 08:32:59,858] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.63508654]
[2019-03-23 08:32:59,859] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.18333333333334, 55.66666666666667, 1.0, 2.0, 0.3763571373571976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 422597.3371726249, 422597.3371726249, 126302.4650198459]
[2019-03-23 08:32:59,860] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:32:59,864] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.3445618e-20 1.0000000e+00 1.4167194e-28 1.7768025e-27 4.8053057e-31], sampled 0.09130030605559669
[2019-03-23 08:33:08,105] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.63508654]
[2019-03-23 08:33:08,106] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.1, 78.0, 1.0, 2.0, 0.4002956038534516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 451314.3304914178, 451314.3304914175, 129327.6298222979]
[2019-03-23 08:33:08,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:33:08,111] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.3445618e-20 1.0000000e+00 1.4167194e-28 1.7768025e-27 4.8053057e-31], sampled 0.7732399492919197
[2019-03-23 08:33:37,899] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:33:38,183] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:33:38,253] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:33:38,253] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:33:38,403] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:33:39,414] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 700000, evaluation results [700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:33:39,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6008113e-21 1.0000000e+00 4.7243755e-28 2.6798600e-28 6.6751213e-31], sum to 1.0000
[2019-03-23 08:33:39,424] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6930
[2019-03-23 08:33:39,435] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 75.66666666666667, 1.0, 2.0, 0.2381321680646042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 258558.501447915, 258558.5014479152, 81289.3398787324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2419800.0000, 
sim time next is 2420400.0000, 
raw observation next is [16.0, 79.33333333333334, 1.0, 2.0, 0.2370027166953086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257331.8443758678, 257331.8443758681, 80875.99130889362], 
processed observation next is [1.0, 0.0, 0.36363636363636365, 0.7933333333333334, 1.0, 1.0, 0.046253395869135724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09530809050958067, 0.09530809050958078, 0.1972585153875454], 
reward next is 0.8027, 
noisyNet noise sample is [array([-0.2946034], dtype=float32), 1.0108956]. 
=============================================
[2019-03-23 08:33:39,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3919643e-21 1.0000000e+00 1.1571260e-29 1.7882737e-27 6.9361807e-32], sum to 1.0000
[2019-03-23 08:33:39,686] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3572
[2019-03-23 08:33:39,692] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 45.0, 1.0, 2.0, 0.5961418675233071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 647536.1724759445, 647536.1724759445, 128952.4893959363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2392200.0000, 
sim time next is 2392800.0000, 
raw observation next is [22.33333333333334, 45.33333333333333, 1.0, 2.0, 0.5792525677624555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629178.9449847443, 629178.9449847443, 126206.825576432], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.4533333333333333, 1.0, 1.0, 0.4740657097030693, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23302923888323862, 0.23302923888323862, 0.3078215257961756], 
reward next is 0.6922, 
noisyNet noise sample is [array([-1.6751038], dtype=float32), -0.2035731]. 
=============================================
[2019-03-23 08:33:43,737] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3824378e-20 1.0000000e+00 8.7076778e-27 2.3665950e-26 8.6015236e-30], sum to 1.0000
[2019-03-23 08:33:43,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6568
[2019-03-23 08:33:43,749] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.5270857854279821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572482.4825111068, 572482.4825111068, 122157.3992862479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2462400.0000, 
sim time next is 2463000.0000, 
raw observation next is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.7217736557406981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 784108.9739954432, 784108.9739954435, 145325.3740618487], 
processed observation next is [1.0, 0.5217391304347826, 0.4166666666666669, 0.8116666666666668, 1.0, 1.0, 0.6522170696758725, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2904107311094234, 0.29041073110942356, 0.3544521318581676], 
reward next is 0.6455, 
noisyNet noise sample is [array([0.0345823], dtype=float32), -1.4994174]. 
=============================================
[2019-03-23 08:33:43,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.17486]
 [71.17486]
 [71.17486]
 [71.17486]
 [71.17486]], R is [[71.10866547]
 [71.09963989]
 [71.08730316]
 [71.0728302 ]
 [71.05731201]].
[2019-03-23 08:33:48,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5297858e-20 1.0000000e+00 2.3337472e-26 1.8324701e-27 1.8058960e-30], sum to 1.0000
[2019-03-23 08:33:48,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6829
[2019-03-23 08:33:48,944] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 48.0, 1.0, 2.0, 0.6164520044749802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 669950.0294147659, 669950.0294147659, 138212.0244558161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2564400.0000, 
sim time next is 2565000.0000, 
raw observation next is [23.0, 48.5, 1.0, 2.0, 0.6010740533553034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 653960.14794074, 653960.14794074, 136858.7166031023], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.485, 1.0, 1.0, 0.5013425666941292, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24220746220027406, 0.24220746220027406, 0.33380174781244465], 
reward next is 0.6662, 
noisyNet noise sample is [array([1.2786025], dtype=float32), 0.44195023]. 
=============================================
[2019-03-23 08:33:48,960] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.02818]
 [75.02818]
 [75.02818]
 [75.02818]
 [75.02818]], R is [[74.94408417]
 [74.85753632]
 [74.75267792]
 [74.6574707 ]
 [74.56742096]].
[2019-03-23 08:33:51,637] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1037044e-19 1.0000000e+00 2.9524310e-25 1.1391192e-25 1.1384528e-28], sum to 1.0000
[2019-03-23 08:33:51,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0117
[2019-03-23 08:33:51,652] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 70.5, 1.0, 2.0, 0.4367162570357824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497552.0326954854, 497552.0326954854, 132131.2208959222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2717400.0000, 
sim time next is 2718000.0000, 
raw observation next is [24.0, 69.0, 1.0, 2.0, 0.4356837801980808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496314.6683561517, 496314.6683561517, 131950.1399587951], 
processed observation next is [0.0, 0.4782608695652174, 0.7272727272727273, 0.69, 1.0, 1.0, 0.29460472524760095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18382024753931545, 0.18382024753931545, 0.3218296096555978], 
reward next is 0.6782, 
noisyNet noise sample is [array([0.26083016], dtype=float32), 1.1248231]. 
=============================================
[2019-03-23 08:33:51,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.01758]
 [69.01758]
 [69.01758]
 [69.01758]
 [69.01758]], R is [[69.00556183]
 [68.99323273]
 [68.98049164]
 [68.96730042]
 [68.95391846]].
[2019-03-23 08:33:52,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0047702e-16 1.0000000e+00 2.2052634e-24 5.6488511e-24 5.4738526e-28], sum to 1.0000
[2019-03-23 08:33:52,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7813
[2019-03-23 08:33:52,205] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 48.0, 1.0, 2.0, 0.3779604253469032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425639.2004706733, 425639.2004706733, 122748.3348016729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2660400.0000, 
sim time next is 2661000.0000, 
raw observation next is [25.66666666666667, 49.0, 1.0, 2.0, 0.3753663728365512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422320.3423818612, 422320.3423818612, 122314.8975680365], 
processed observation next is [0.0, 0.8260869565217391, 0.8030303030303032, 0.49, 1.0, 1.0, 0.219207966045689, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15641494162291156, 0.15641494162291156, 0.2983290184586256], 
reward next is 0.7017, 
noisyNet noise sample is [array([1.4453276], dtype=float32), 0.07035185]. 
=============================================
[2019-03-23 08:33:52,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.191895]
 [67.191895]
 [67.191895]
 [67.191895]
 [67.191895]], R is [[67.22164917]
 [67.25004578]
 [67.27745819]
 [67.30384064]
 [67.32918549]].
[2019-03-23 08:33:52,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8740115e-16 1.0000000e+00 2.2322682e-27 1.1658225e-23 1.4385582e-27], sum to 1.0000
[2019-03-23 08:33:52,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1276
[2019-03-23 08:33:52,586] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 82.0, 1.0, 2.0, 0.3522753489609249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392063.5171252995, 392063.5171252993, 118355.4410452336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683800.0000, 
sim time next is 2684400.0000, 
raw observation next is [19.2, 82.66666666666667, 1.0, 2.0, 0.3492200549221448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388021.9511124334, 388021.9511124331, 117844.3393186619], 
processed observation next is [0.0, 0.043478260869565216, 0.509090909090909, 0.8266666666666667, 1.0, 1.0, 0.18652506865268098, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1437118337453457, 0.1437118337453456, 0.2874252178503949], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.26319027], dtype=float32), 0.8072209]. 
=============================================
[2019-03-23 08:33:56,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1128586e-18 1.0000000e+00 9.6489368e-26 1.1350419e-25 2.6742317e-29], sum to 1.0000
[2019-03-23 08:33:56,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1054
[2019-03-23 08:33:56,105] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 52.66666666666666, 1.0, 2.0, 0.4366209719422482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497230.5490192752, 497230.5490192752, 131865.859725251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2739000.0000, 
sim time next is 2739600.0000, 
raw observation next is [27.0, 51.0, 1.0, 2.0, 0.4308005656366702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490280.2320820219, 490280.2320820219, 130935.9473491644], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.51, 1.0, 1.0, 0.2885007070458377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1815852711414896, 0.1815852711414896, 0.3193559691443034], 
reward next is 0.6806, 
noisyNet noise sample is [array([0.979053], dtype=float32), 1.0401182]. 
=============================================
[2019-03-23 08:33:56,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3896813e-18 1.0000000e+00 2.3077650e-25 5.9899959e-26 3.3677406e-28], sum to 1.0000
[2019-03-23 08:33:56,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3264
[2019-03-23 08:33:56,695] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.5, 1.0, 2.0, 0.4912278242624681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560473.5922546089, 560473.5922546089, 140455.4077142469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2752200.0000, 
sim time next is 2752800.0000, 
raw observation next is [23.0, 81.66666666666667, 1.0, 2.0, 0.4832878716545278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551477.0909765237, 551477.0909765237, 139033.3886383498], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.8166666666666668, 1.0, 1.0, 0.3541098395681597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20425077443574952, 0.20425077443574952, 0.33910582594719463], 
reward next is 0.6609, 
noisyNet noise sample is [array([1.178768], dtype=float32), -1.2832477]. 
=============================================
[2019-03-23 08:34:07,781] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4989461e-18 1.0000000e+00 1.0582227e-23 1.2153236e-24 6.8163750e-28], sum to 1.0000
[2019-03-23 08:34:07,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5833
[2019-03-23 08:34:07,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1371133.083223806 W.
[2019-03-23 08:34:07,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.7243467327477091, 0.0, 1.0, 0.0, 1.0, 1.0, 0.977639130103666, 6.911199999999999, 6.9112, 77.32846344354104, 1371133.083223806, 1371133.083223806, 296173.7252958094], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2981400.0000, 
sim time next is 2982000.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5715828108237652, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9763991766055604, 6.911199999999999, 6.9112, 77.32846344354104, 1198227.335317989, 1198227.335317989, 272804.7885877286], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.4644785135297064, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9662845380079434, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4437879019696256, 0.4437879019696256, 0.6653775331408014], 
reward next is 0.3346, 
noisyNet noise sample is [array([0.39744145], dtype=float32), -0.10198966]. 
=============================================
[2019-03-23 08:34:07,818] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.17942]
 [62.17942]
 [62.17942]
 [62.17942]
 [62.17942]], R is [[61.89225006]
 [61.55095291]
 [61.26081467]
 [60.64820862]
 [60.04172897]].
[2019-03-23 08:34:14,329] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.316328e-16 1.000000e+00 3.860451e-23 6.643224e-21 1.504204e-23], sum to 1.0000
[2019-03-23 08:34:14,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3749
[2019-03-23 08:34:14,340] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.0, 1.0, 2.0, 0.5606068560693143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635721.4004185386, 635721.4004185386, 151950.2901601857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3100200.0000, 
sim time next is 3100800.0000, 
raw observation next is [23.66666666666666, 89.0, 1.0, 2.0, 0.557216742769953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632568.8070958337, 632568.8070958339, 151217.8319461324], 
processed observation next is [1.0, 0.9130434782608695, 0.7121212121212118, 0.89, 1.0, 1.0, 0.44652092846244124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2342847433688273, 0.23428474336882738, 0.3688239803564205], 
reward next is 0.6312, 
noisyNet noise sample is [array([0.4685721], dtype=float32), -0.17342287]. 
=============================================
[2019-03-23 08:34:21,270] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2965697e-18 1.0000000e+00 1.3640904e-26 6.1766002e-27 1.2720129e-30], sum to 1.0000
[2019-03-23 08:34:21,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-23 08:34:21,280] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 62.33333333333334, 1.0, 2.0, 0.3541741490093308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 394441.8248444024, 394441.8248444021, 118619.4412687104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3233400.0000, 
sim time next is 3234000.0000, 
raw observation next is [22.66666666666667, 60.66666666666667, 1.0, 2.0, 0.3569015039206597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 397754.1568018686, 397754.1568018689, 118955.4727513297], 
processed observation next is [0.0, 0.43478260869565216, 0.6666666666666669, 0.6066666666666667, 1.0, 1.0, 0.19612687990082464, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14731635437106244, 0.14731635437106258, 0.2901352993934871], 
reward next is 0.7099, 
noisyNet noise sample is [array([-0.22446103], dtype=float32), -0.17776272]. 
=============================================
[2019-03-23 08:34:21,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.03942]
 [74.03942]
 [74.03942]
 [74.03942]
 [74.03942]], R is [[74.00888062]
 [73.97947693]
 [73.95052338]
 [73.92047882]
 [73.88929749]].
[2019-03-23 08:34:22,116] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4144217e-19 1.0000000e+00 5.2122450e-26 2.2562844e-25 1.1102495e-28], sum to 1.0000
[2019-03-23 08:34:22,123] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8674
[2019-03-23 08:34:22,128] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 51.0, 1.0, 2.0, 0.3258741531320996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357919.1322603018, 357919.1322603015, 114396.5106941386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3241200.0000, 
sim time next is 3241800.0000, 
raw observation next is [23.5, 50.0, 1.0, 2.0, 0.3245620669776415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356336.0876313992, 356336.0876313995, 114248.8038025487], 
processed observation next is [0.0, 0.5217391304347826, 0.7045454545454546, 0.5, 1.0, 1.0, 0.15570258372205187, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1319763287523701, 0.1319763287523702, 0.2786556190306066], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.3541194], dtype=float32), -0.20001571]. 
=============================================
[2019-03-23 08:34:27,044] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 08:34:27,048] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:34:27,049] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:34:27,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:27,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:27,050] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:34:27,052] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:27,053] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:34:27,054] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:34:27,054] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:27,055] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:34:27,067] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 08:34:27,091] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 08:34:27,118] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 08:34:27,142] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 08:34:27,142] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 08:34:33,631] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:34:33,631] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.23064692, 70.22315323666666, 1.0, 2.0, 0.2431136142972663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 263955.0492225881, 263955.0492225881, 86758.6906911043]
[2019-03-23 08:34:33,633] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:34:33,636] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.8794019264670598
[2019-03-23 08:34:33,842] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:34:33,844] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.84052714333333, 97.59504670666668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 188795.9056833539, 188795.9056833535, 70191.76400348287]
[2019-03-23 08:34:33,845] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:34:33,849] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.4962497497213041
[2019-03-23 08:34:34,471] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:34:34,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.83333333333334, 61.66666666666666, 1.0, 2.0, 0.2509707736548534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 272487.714105003, 272487.714105003, 82095.41914198195]
[2019-03-23 08:34:34,472] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:34:34,476] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.12038106170919305
[2019-03-23 08:34:34,488] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:34:34,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.33556218, 100.0, 1.0, 2.0, 0.3598323231210492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399477.4666414491, 399477.4666414488, 122867.9313469982]
[2019-03-23 08:34:34,490] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:34:34,493] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.15804406316994257
[2019-03-23 08:34:57,984] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:34:57,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.63378493166667, 91.68046989499999, 1.0, 2.0, 0.2420504773929746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 262800.5202874343, 262800.5202874343, 85934.49183838487]
[2019-03-23 08:34:57,987] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:34:57,989] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.09026006430853395
[2019-03-23 08:34:59,398] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:34:59,398] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.6590973, 89.21511099666667, 1.0, 2.0, 0.2529172086653302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 274601.5091800158, 274601.5091800158, 85888.93169382562]
[2019-03-23 08:34:59,399] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:34:59,404] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.8596513283374325
[2019-03-23 08:35:07,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:35:07,521] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.75, 50.83333333333333, 1.0, 2.0, 0.8103244556225532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 922036.5810790319, 922036.5810790319, 192073.1649392572]
[2019-03-23 08:35:07,522] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:35:07,526] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.5627124205061338
[2019-03-23 08:35:30,767] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:35:30,770] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.06666666666667, 54.33333333333334, 1.0, 2.0, 0.4188066504495999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 462992.3785879486, 462992.3785879486, 127035.3030181536]
[2019-03-23 08:35:30,771] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:35:30,775] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.3340596392812851
[2019-03-23 08:35:48,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.6081294]
[2019-03-23 08:35:48,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.4, 66.33333333333334, 1.0, 2.0, 0.476854505591589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 517843.2247825994, 517843.2247825994, 110317.0751339666]
[2019-03-23 08:35:48,408] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:35:48,412] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.0822011e-18 1.0000000e+00 8.4994123e-27 7.1452235e-26 4.1004279e-29], sampled 0.9909032192824636
[2019-03-23 08:36:10,148] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:36:10,245] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:36:10,393] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:36:10,441] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:36:10,579] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:36:11,595] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 725000, evaluation results [725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:36:12,989] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7158019e-17 1.0000000e+00 3.5457865e-27 2.5155507e-25 2.7255529e-28], sum to 1.0000
[2019-03-23 08:36:12,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5807
[2019-03-23 08:36:13,000] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3432350709536945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380844.2549156288, 380844.2549156288, 117158.8811133222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3362400.0000, 
sim time next is 3363000.0000, 
raw observation next is [20.83333333333333, 70.5, 1.0, 2.0, 0.3435429116650154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381392.8482276765, 381392.8482276762, 117267.8187986091], 
processed observation next is [0.0, 0.9565217391304348, 0.5833333333333331, 0.705, 1.0, 1.0, 0.1794286395812692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141256610454695, 0.14125661045469487, 0.28601907024051004], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.5927795], dtype=float32), -1.8519139]. 
=============================================
[2019-03-23 08:36:13,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.19959]
 [67.19959]
 [67.19959]
 [67.19959]
 [67.19959]], R is [[67.24156952]
 [67.28340149]
 [67.32474518]
 [67.36564636]
 [67.40615082]].
[2019-03-23 08:36:16,521] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6757578e-16 1.0000000e+00 1.0940459e-21 4.5396617e-21 1.1393464e-23], sum to 1.0000
[2019-03-23 08:36:16,529] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7961
[2019-03-23 08:36:16,536] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5503410781952361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 624346.4566765664, 624346.4566765662, 150510.2378849368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3437400.0000, 
sim time next is 3438000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5501976549067102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 624184.7722412533, 624184.7722412535, 150491.3334313382], 
processed observation next is [1.0, 0.8260869565217391, 0.8181818181818182, 0.74, 1.0, 1.0, 0.43774706863338775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23117954527453827, 0.23117954527453835, 0.36705203275936144], 
reward next is 0.6329, 
noisyNet noise sample is [array([-0.14118443], dtype=float32), 0.7970028]. 
=============================================
[2019-03-23 08:36:16,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[53.4146]
 [53.4146]
 [53.4146]
 [53.4146]
 [53.4146]], R is [[53.51341248]
 [53.61117935]
 [53.70745087]
 [53.80166245]
 [53.89487457]].
[2019-03-23 08:36:17,219] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3027094e-18 1.0000000e+00 2.3129473e-25 4.9400576e-24 2.0939854e-26], sum to 1.0000
[2019-03-23 08:36:17,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8688
[2019-03-23 08:36:17,231] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5019756331196162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572469.1336670852, 572469.1336670852, 142324.483396341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3457800.0000, 
sim time next is 3458400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5014228965138228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 571838.610453881, 571838.6104538813, 142259.3354059913], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3767786206422784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21179207794588184, 0.21179207794588198, 0.3469739887951007], 
reward next is 0.6530, 
noisyNet noise sample is [array([-0.49323872], dtype=float32), 0.3629909]. 
=============================================
[2019-03-23 08:36:17,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6287036e-17 1.0000000e+00 1.0519343e-26 1.0412234e-25 1.8952233e-28], sum to 1.0000
[2019-03-23 08:36:17,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9375
[2019-03-23 08:36:17,473] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5226768147357338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 595452.1720357812, 595452.1720357814, 145536.5327135283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3447000.0000, 
sim time next is 3447600.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5230000472129046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 595820.8925987399, 595820.8925987399, 145575.649634238], 
processed observation next is [1.0, 0.9130434782608695, 0.6818181818181818, 0.89, 1.0, 1.0, 0.4037500590161307, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22067440466619997, 0.22067440466619997, 0.35506256008350734], 
reward next is 0.6449, 
noisyNet noise sample is [array([0.20160756], dtype=float32), 0.31718528]. 
=============================================
[2019-03-23 08:36:21,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1099513e-13 1.0000000e+00 2.2055383e-19 6.3630729e-19 1.2831793e-21], sum to 1.0000
[2019-03-23 08:36:21,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9286
[2019-03-23 08:36:21,222] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 59.33333333333334, 1.0, 2.0, 0.5508375210770027, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 624616.4274386595, 624616.4274386592, 150689.157388282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3518400.0000, 
sim time next is 3519000.0000, 
raw observation next is [28.3, 59.0, 1.0, 2.0, 0.5263815927325264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 598256.9217213627, 598256.9217213627, 146954.0112673588], 
processed observation next is [1.0, 0.7391304347826086, 0.9227272727272727, 0.59, 1.0, 1.0, 0.4079769909156579, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2215766376745788, 0.2215766376745788, 0.35842441772526534], 
reward next is 0.6416, 
noisyNet noise sample is [array([-1.6503093], dtype=float32), -0.012798908]. 
=============================================
[2019-03-23 08:36:21,245] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[44.380054]
 [44.380054]
 [44.380054]
 [44.380054]
 [44.380054]], R is [[44.57782745]
 [44.76451492]
 [44.80357742]
 [44.67365646]
 [44.22692108]].
[2019-03-23 08:36:33,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8244521e-16 1.0000000e+00 1.9797446e-23 9.1586428e-24 9.1210440e-27], sum to 1.0000
[2019-03-23 08:36:33,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6094
[2019-03-23 08:36:33,996] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3379488013791066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 371942.4573141031, 371942.4573141028, 115562.3432420118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3793800.0000, 
sim time next is 3794400.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3388313370163005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372917.021498926, 372917.021498926, 115629.3178840739], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17353917127037563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13811741536997257, 0.13811741536997257, 0.2820227265465217], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.6752028], dtype=float32), 0.29033488]. 
=============================================
[2019-03-23 08:36:38,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7642081e-21 1.0000000e+00 7.9696892e-30 6.9499070e-30 1.0196755e-32], sum to 1.0000
[2019-03-23 08:36:38,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8966
[2019-03-23 08:36:38,309] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 64.0, 1.0, 2.0, 0.3098770186712216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337995.1174186108, 337995.1174186111, 112387.8916355331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3878400.0000, 
sim time next is 3879000.0000, 
raw observation next is [20.5, 64.0, 1.0, 2.0, 0.305817314806615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332556.8072765109, 332556.8072765106, 111751.7193300212], 
processed observation next is [0.0, 0.9130434782608695, 0.5681818181818182, 0.64, 1.0, 1.0, 0.13227164350826873, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12316918788018923, 0.1231691878801891, 0.2725651690976127], 
reward next is 0.7274, 
noisyNet noise sample is [array([-1.3419031], dtype=float32), -1.5651906]. 
=============================================
[2019-03-23 08:36:38,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.39826]
 [75.39826]
 [75.39826]
 [75.39826]
 [75.39826]], R is [[75.3717041 ]
 [75.34387207]
 [75.31476593]
 [75.28466797]
 [75.25445557]].
[2019-03-23 08:36:48,374] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7867098e-20 1.0000000e+00 1.2428330e-27 5.4532247e-26 8.5953993e-28], sum to 1.0000
[2019-03-23 08:36:48,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7546
[2019-03-23 08:36:48,386] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3133050832299477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341677.9826587222, 341677.9826587222, 112605.1747615214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4059000.0000, 
sim time next is 4059600.0000, 
raw observation next is [16.33333333333333, 98.0, 1.0, 2.0, 0.3110415445670778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 338781.8358430249, 338781.8358430249, 112297.5721544979], 
processed observation next is [1.0, 1.0, 0.37878787878787856, 0.98, 1.0, 1.0, 0.1388019307088472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12547475401593514, 0.12547475401593514, 0.2738965174499949], 
reward next is 0.7261, 
noisyNet noise sample is [array([0.5458231], dtype=float32), -1.0429442]. 
=============================================
[2019-03-23 08:36:56,955] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9844771e-19 1.0000000e+00 3.0581287e-27 3.7203493e-27 2.5648972e-28], sum to 1.0000
[2019-03-23 08:36:56,962] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2252
[2019-03-23 08:36:56,971] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333334, 93.0, 1.0, 2.0, 0.3349405211174055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368459.9452427315, 368459.9452427315, 115274.1144001512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4236600.0000, 
sim time next is 4237200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3286586992050778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360074.726781866, 360074.726781866, 114268.0607977568], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.16082337400634722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13336100991920963, 0.13336100991920963, 0.27870258731160197], 
reward next is 0.7213, 
noisyNet noise sample is [array([1.9935464], dtype=float32), 2.0694013]. 
=============================================
[2019-03-23 08:36:59,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1150552e-18 1.0000000e+00 2.6439977e-26 6.4845944e-25 3.4512359e-28], sum to 1.0000
[2019-03-23 08:36:59,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9610
[2019-03-23 08:36:59,087] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.5, 1.0, 2.0, 0.7245563919212711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 819936.0885354925, 819936.0885354929, 162858.1175812762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4281000.0000, 
sim time next is 4281600.0000, 
raw observation next is [27.0, 46.0, 1.0, 2.0, 0.8308776648142282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 941355.6993216401, 941355.6993216401, 178690.8179187132], 
processed observation next is [1.0, 0.5652173913043478, 0.8636363636363636, 0.46, 1.0, 1.0, 0.7885970810177853, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34865025900801483, 0.34865025900801483, 0.43583126321637367], 
reward next is 0.5642, 
noisyNet noise sample is [array([0.62000084], dtype=float32), -1.4052528]. 
=============================================
[2019-03-23 08:36:59,359] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 08:36:59,362] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:36:59,362] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:36:59,362] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:59,363] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:59,363] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:36:59,364] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:36:59,365] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:36:59,367] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:59,365] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:59,369] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:36:59,383] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 08:36:59,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 08:36:59,427] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 08:36:59,428] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 08:36:59,473] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 08:37:01,543] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:37:01,544] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.764236365, 81.99686466333334, 1.0, 2.0, 0.2502311658686306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 271684.5146691944, 271684.5146691939, 87365.92674738077]
[2019-03-23 08:37:01,547] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:37:01,550] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.4353532173606668
[2019-03-23 08:37:08,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:37:08,984] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.38021332666667, 88.88333758666667, 1.0, 2.0, 0.3275398074651344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362980.7180230111, 362980.7180230108, 120091.9702656886]
[2019-03-23 08:37:08,985] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:37:08,987] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.5676680327305876
[2019-03-23 08:37:17,253] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:37:17,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 60.66666666666667, 1.0, 2.0, 0.9584537764740289, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9800217017066978, 6.911199999999999, 6.9112, 77.32846344354104, 1634335.997706274, 1634335.997706275, 339305.2333853014]
[2019-03-23 08:37:17,256] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:37:17,260] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.4795523126298059
[2019-03-23 08:37:17,260] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1634335.997706274 W.
[2019-03-23 08:37:25,728] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:37:25,730] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.3, 69.0, 1.0, 2.0, 0.4935717690808917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 563065.7288237761, 563065.7288237758, 145107.1538620937]
[2019-03-23 08:37:25,731] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:37:25,732] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.05489437054520763
[2019-03-23 08:37:38,853] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:37:38,855] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.63243415166666, 78.35567216833334, 1.0, 2.0, 0.4697339854239545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 535940.5796947214, 535940.579694721, 141971.5031561778]
[2019-03-23 08:37:38,856] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:37:38,861] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.1588259754562944
[2019-03-23 08:38:11,802] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:38:11,803] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.35, 54.0, 1.0, 2.0, 0.380173907625346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 426271.8670697813, 426271.8670697813, 126335.4099198002]
[2019-03-23 08:38:11,806] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:38:11,810] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.08436236743521897
[2019-03-23 08:38:24,056] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.64768755]
[2019-03-23 08:38:24,057] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.13333333333333, 88.33333333333334, 1.0, 2.0, 0.3613488631563535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 404593.6127891645, 404593.6127891645, 124477.2231240158]
[2019-03-23 08:38:24,061] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:38:24,063] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.6738533e-18 1.0000000e+00 2.1729787e-25 1.5879979e-24 1.3129738e-27], sampled 0.7596810214784616
[2019-03-23 08:38:42,967] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:38:43,024] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:38:43,070] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:38:43,077] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:38:43,140] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:38:44,156] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 750000, evaluation results [750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:38:49,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.6430988e-15 1.0000000e+00 4.2585536e-21 1.4229857e-21 5.5159541e-24], sum to 1.0000
[2019-03-23 08:38:49,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3264
[2019-03-23 08:38:49,031] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 53.33333333333334, 1.0, 2.0, 0.9266775994131081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1057968.209781732, 1057968.209781732, 203230.5635381326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4365600.0000, 
sim time next is 4366200.0000, 
raw observation next is [27.83333333333334, 52.16666666666666, 1.0, 2.0, 0.9950931871659663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.915470339671163, 6.9112, 77.32844038129379, 1137535.811930545, 1136148.893362533, 215509.123428568], 
processed observation next is [1.0, 0.5217391304347826, 0.9015151515151518, 0.5216666666666666, 1.0, 1.0, 0.9938664839574579, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.00042703396711631927, 0.0, 0.5084286612881184, 0.4213095599742759, 0.4207958864305678, 0.525632008362361], 
reward next is 0.4530, 
noisyNet noise sample is [array([0.0380982], dtype=float32), -0.16315731]. 
=============================================
[2019-03-23 08:38:56,644] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7227699e-19 1.0000000e+00 1.6726634e-27 1.4406521e-25 5.7109775e-29], sum to 1.0000
[2019-03-23 08:38:56,650] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5230
[2019-03-23 08:38:56,654] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4616921921069952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526592.998960892, 526592.998960892, 135643.5213956959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4495200.0000, 
sim time next is 4495800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4622335744862021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527210.8604073273, 527210.8604073273, 135701.8450041212], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32779196810775263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19526328163234344, 0.19526328163234344, 0.3309801097661492], 
reward next is 0.6690, 
noisyNet noise sample is [array([-0.07763444], dtype=float32), 1.7901411]. 
=============================================
[2019-03-23 08:39:02,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4600603e-20 1.0000000e+00 2.9821150e-29 1.3759059e-27 7.2044574e-32], sum to 1.0000
[2019-03-23 08:39:02,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7339
[2019-03-23 08:39:02,215] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 49.5, 1.0, 2.0, 0.5945319167907074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 651379.8308408065, 651379.8308408065, 137617.5136349936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6643276404652619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 727293.9938021059, 727293.9938021061, 144940.5289095514], 
processed observation next is [1.0, 0.7391304347826086, 0.6818181818181818, 0.5, 1.0, 1.0, 0.5804095505815774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2693681458526318, 0.2693681458526319, 0.3535134851452473], 
reward next is 0.6465, 
noisyNet noise sample is [array([1.1154661], dtype=float32), -1.3052108]. 
=============================================
[2019-03-23 08:39:10,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0350961e-18 1.0000000e+00 1.8164783e-25 2.5155423e-24 2.1974577e-28], sum to 1.0000
[2019-03-23 08:39:10,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4326
[2019-03-23 08:39:10,620] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 94.0, 1.0, 2.0, 0.372120939750711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 416863.1667457073, 416863.166745707, 121149.3287977327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4764600.0000, 
sim time next is 4765200.0000, 
raw observation next is [18.33333333333334, 96.0, 1.0, 2.0, 0.3710201836070098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415917.7623458111, 415917.7623458111, 121192.3668193623], 
processed observation next is [1.0, 0.13043478260869565, 0.46969696969696995, 0.96, 1.0, 1.0, 0.2137752295087622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15404361568363376, 0.15404361568363376, 0.2955911385838105], 
reward next is 0.7044, 
noisyNet noise sample is [array([0.41791826], dtype=float32), -2.49278]. 
=============================================
[2019-03-23 08:39:12,041] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8355297e-17 1.0000000e+00 3.2669479e-24 3.9046311e-23 4.7969849e-26], sum to 1.0000
[2019-03-23 08:39:12,048] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7797
[2019-03-23 08:39:12,054] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 73.0, 1.0, 2.0, 0.4277093871034928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 486440.8749313, 486440.8749312997, 130321.4303653947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4903800.0000, 
sim time next is 4904400.0000, 
raw observation next is [23.0, 73.0, 1.0, 2.0, 0.4311468391099496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490357.2730642143, 490357.2730642143, 130668.4053248661], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.73, 1.0, 1.0, 0.288933548887437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1816138048385979, 0.1816138048385979, 0.3187034276216246], 
reward next is 0.6813, 
noisyNet noise sample is [array([0.5036055], dtype=float32), 2.1950877]. 
=============================================
[2019-03-23 08:39:13,177] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6890935e-17 1.0000000e+00 2.4456818e-25 2.5303914e-25 5.9702769e-29], sum to 1.0000
[2019-03-23 08:39:13,183] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2728
[2019-03-23 08:39:13,190] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.4966455097342165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 566522.3056705081, 566522.3056705083, 141451.3514663382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4815000.0000, 
sim time next is 4815600.0000, 
raw observation next is [21.33333333333334, 98.0, 1.0, 2.0, 0.4982464224910452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568396.6669100837, 568396.6669100837, 141530.0224262888], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.98, 1.0, 1.0, 0.3728080281138065, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21051728404077175, 0.21051728404077175, 0.3451951766494849], 
reward next is 0.6548, 
noisyNet noise sample is [array([-0.20429218], dtype=float32), 0.34443322]. 
=============================================
[2019-03-23 08:39:28,906] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2243974e-17 1.0000000e+00 2.8724984e-25 2.1938439e-24 2.3821273e-27], sum to 1.0000
[2019-03-23 08:39:28,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4569
[2019-03-23 08:39:28,919] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 74.0, 1.0, 2.0, 0.4667924187861602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532635.7434217234, 532635.7434217231, 137374.8339301947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5134800.0000, 
sim time next is 5135400.0000, 
raw observation next is [24.5, 74.0, 1.0, 2.0, 0.4724875340695124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539081.1735908537, 539081.1735908537, 138329.5580680249], 
processed observation next is [0.0, 0.43478260869565216, 0.75, 0.74, 1.0, 1.0, 0.34060941758689045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1996596939225384, 0.1996596939225384, 0.3373891660195729], 
reward next is 0.6626, 
noisyNet noise sample is [array([-0.78580236], dtype=float32), -0.45797834]. 
=============================================
[2019-03-23 08:39:32,708] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 08:39:32,709] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:39:32,710] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:32,715] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:39:32,717] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:39:32,719] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:32,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:39:32,720] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:32,721] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:32,723] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:39:32,724] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:39:32,744] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 08:39:32,745] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 08:39:32,796] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 08:39:32,796] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 08:39:32,817] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 08:39:36,832] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:39:36,833] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.29317868, 49.36300951166667, 1.0, 2.0, 0.2568061453884599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 278824.8501005388, 278824.8501005385, 84199.13337155843]
[2019-03-23 08:39:36,834] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:39:36,839] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.24001016961124577
[2019-03-23 08:39:41,345] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:39:41,347] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 64.0, 1.0, 2.0, 0.6234998885324239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 695786.7774494581, 695786.7774494584, 145198.9147932624]
[2019-03-23 08:39:41,348] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:39:41,351] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.6396193790213317
[2019-03-23 08:39:41,484] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:39:41,486] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [11.65, 87.5, 1.0, 2.0, 0.3914219651029258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 425034.3919952416, 425034.3919952412, 91096.49286651504]
[2019-03-23 08:39:41,487] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:39:41,491] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.5737814327686803
[2019-03-23 08:40:30,183] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:40:30,185] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.373549335, 92.158810765, 1.0, 2.0, 0.4086447007115914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464220.9027575412, 464220.9027575409, 132340.0793273213]
[2019-03-23 08:40:30,186] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:40:30,190] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.5931833976521945
[2019-03-23 08:40:35,979] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:40:35,980] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.33333333333334, 54.0, 1.0, 2.0, 0.293625615652791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318831.7772835158, 318831.7772835158, 102411.9699491726]
[2019-03-23 08:40:35,981] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:40:35,983] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.5871380185622684
[2019-03-23 08:40:36,223] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:40:36,226] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2536636150107132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275426.9688878052, 275426.9688878055, 86317.61658419481]
[2019-03-23 08:40:36,229] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:40:36,233] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.47505153993566396
[2019-03-23 08:40:51,892] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:40:51,895] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.1, 90.0, 1.0, 2.0, 0.6241805418222443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 677923.1595242113, 677923.1595242113, 137786.6664482566]
[2019-03-23 08:40:51,896] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:40:51,901] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.8129276466617249
[2019-03-23 08:41:03,750] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7233105]
[2019-03-23 08:41:03,752] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.68941948833334, 59.88447914166667, 1.0, 2.0, 0.7291391740853282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 832098.5950662292, 832098.5950662292, 175793.8471591335]
[2019-03-23 08:41:03,754] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:41:03,757] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7974612e-17 1.0000000e+00 5.3936244e-25 3.7004826e-24 3.3828971e-27], sampled 0.5810892757458946
[2019-03-23 08:41:15,993] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:41:16,081] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:41:16,260] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:41:16,278] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:41:16,305] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:41:17,317] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 775000, evaluation results [775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:41:17,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2391979e-18 1.0000000e+00 8.1691694e-25 2.5996339e-25 1.6030104e-27], sum to 1.0000
[2019-03-23 08:41:17,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9072
[2019-03-23 08:41:17,531] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4378336890909922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498831.1369946161, 498831.1369946161, 132252.5528133897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5190600.0000, 
sim time next is 5191200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4374253869066658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498365.5747741654, 498365.5747741654, 132210.5413427456], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29678173363333227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18457984250895015, 0.18457984250895015, 0.3224647349823063], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.42198697], dtype=float32), -0.46914372]. 
=============================================
[2019-03-23 08:41:19,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5409620e-16 1.0000000e+00 5.0024314e-23 1.8334607e-22 6.3950286e-25], sum to 1.0000
[2019-03-23 08:41:19,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8139
[2019-03-23 08:41:19,563] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.18333333333334, 60.66666666666667, 1.0, 2.0, 0.4331541555387679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492932.8891798135, 492932.8891798135, 131145.9178005725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5349000.0000, 
sim time next is 5349600.0000, 
raw observation next is [25.0, 62.0, 1.0, 2.0, 0.4336098688320354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493562.7194732146, 493562.7194732146, 131304.0426478358], 
processed observation next is [1.0, 0.9565217391304348, 0.7727272727272727, 0.62, 1.0, 1.0, 0.29201233604004423, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1828010072123017, 0.1828010072123017, 0.3202537625556971], 
reward next is 0.6797, 
noisyNet noise sample is [array([-1.9385952], dtype=float32), 0.10759694]. 
=============================================
[2019-03-23 08:41:19,830] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.55535691e-17 1.00000000e+00 8.64189603e-26 8.83557346e-25
 1.00188825e-26], sum to 1.0000
[2019-03-23 08:41:19,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9005
[2019-03-23 08:41:19,841] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.63333333333333, 73.83333333333334, 1.0, 2.0, 0.3988471332096779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437909.4764870738, 437909.4764870735, 119947.011794926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5278200.0000, 
sim time next is 5278800.0000, 
raw observation next is [19.56666666666667, 74.66666666666667, 1.0, 2.0, 0.3511863345112454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385869.638345396, 385869.6383453963, 116323.5313904748], 
processed observation next is [1.0, 0.08695652173913043, 0.5257575757575759, 0.7466666666666667, 1.0, 1.0, 0.18898291813905677, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14291468086866518, 0.1429146808686653, 0.28371593022067026], 
reward next is 0.7163, 
noisyNet noise sample is [array([0.48441967], dtype=float32), 1.0618893]. 
=============================================
[2019-03-23 08:41:21,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3345869e-19 1.0000000e+00 2.1803497e-27 1.4641926e-26 7.2498196e-29], sum to 1.0000
[2019-03-23 08:41:21,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0512
[2019-03-23 08:41:21,353] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.88333333333333, 88.0, 1.0, 2.0, 0.3484003826088249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388459.8887767025, 388459.8887767025, 118355.0857303219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5284200.0000, 
sim time next is 5284800.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3528414850324553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394233.7926373002, 394233.7926373002, 119074.022075164], 
processed observation next is [1.0, 0.17391304347826086, 0.49090909090909096, 0.9, 1.0, 1.0, 0.19105185629056914, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14601251579159266, 0.14601251579159266, 0.29042444408576584], 
reward next is 0.7096, 
noisyNet noise sample is [array([-0.6370386], dtype=float32), 0.6013535]. 
=============================================
[2019-03-23 08:41:24,041] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1266782e-16 1.0000000e+00 7.8980113e-25 9.1899001e-23 5.0352579e-26], sum to 1.0000
[2019-03-23 08:41:24,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0331
[2019-03-23 08:41:24,051] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.4926066603311825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561504.4036327151, 561504.4036327151, 141605.5734105273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5335200.0000, 
sim time next is 5335800.0000, 
raw observation next is [28.71666666666667, 51.83333333333334, 1.0, 2.0, 0.4853596150398335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553570.4216004944, 553570.4216004944, 140289.431760844], 
processed observation next is [1.0, 0.782608695652174, 0.9416666666666668, 0.5183333333333334, 1.0, 1.0, 0.35669951879979184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20502608207425718, 0.20502608207425718, 0.34216934575815605], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.1457812], dtype=float32), -0.337195]. 
=============================================
[2019-03-23 08:41:32,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.7803685e-16 1.0000000e+00 3.4771174e-24 8.3561436e-23 3.3389765e-25], sum to 1.0000
[2019-03-23 08:41:32,759] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2822
[2019-03-23 08:41:32,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1485480.098130829 W.
[2019-03-23 08:41:32,769] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 69.0, 1.0, 2.0, 0.6604558252381744, 1.0, 1.0, 0.6604558252381744, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1485480.098130829, 1485480.098130829, 279605.2421632285], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5497200.0000, 
sim time next is 5497800.0000, 
raw observation next is [27.1, 69.83333333333333, 1.0, 2.0, 0.7774676824338885, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9842619026853225, 6.911199999999999, 6.9112, 77.32846344354104, 1423272.945951216, 1423272.945951217, 310823.819306376], 
processed observation next is [1.0, 0.6521739130434783, 0.8681818181818183, 0.6983333333333333, 1.0, 1.0, 0.7218346030423606, 0.0, 0.5, -0.25, 1.0, 0.5, 0.977517003836175, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.52713812813008, 0.5271381281300804, 0.7581068763570146], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17562942], dtype=float32), 1.139012]. 
=============================================
[2019-03-23 08:41:38,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3912870e-18 1.0000000e+00 2.9033016e-24 7.7744112e-24 1.5422824e-27], sum to 1.0000
[2019-03-23 08:41:38,353] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3990
[2019-03-23 08:41:38,360] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3886723808667638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437650.51898156, 437650.5189815597, 123659.5267534586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5611200.0000, 
sim time next is 5611800.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3884526892854072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437402.4063683909, 437402.4063683907, 123639.756875798], 
processed observation next is [1.0, 0.9565217391304348, 0.5181818181818181, 0.9, 1.0, 1.0, 0.235565861606759, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16200089124755218, 0.16200089124755213, 0.30156038262389756], 
reward next is 0.6984, 
noisyNet noise sample is [array([-0.13280876], dtype=float32), -0.9059791]. 
=============================================
[2019-03-23 08:41:44,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4969382e-16 1.0000000e+00 4.3821660e-22 2.0942201e-23 3.1585310e-25], sum to 1.0000
[2019-03-23 08:41:44,479] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7414
[2019-03-23 08:41:44,487] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 43.33333333333334, 1.0, 2.0, 0.6137031151895298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683239.1108491528, 683239.1108491528, 143445.1455991582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5844000.0000, 
sim time next is 5844600.0000, 
raw observation next is [25.8, 42.5, 1.0, 2.0, 0.6544226918267559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 728038.8868096862, 728038.8868096858, 147902.1196094098], 
processed observation next is [1.0, 0.6521739130434783, 0.8090909090909091, 0.425, 1.0, 1.0, 0.5680283647834449, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2696440321517356, 0.2696440321517355, 0.36073687709612146], 
reward next is 0.6393, 
noisyNet noise sample is [array([-0.19166937], dtype=float32), 0.5376051]. 
=============================================
[2019-03-23 08:41:48,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6958103e-18 1.0000000e+00 3.6707152e-26 1.2291189e-25 1.7665423e-28], sum to 1.0000
[2019-03-23 08:41:48,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-23 08:41:48,742] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 50.66666666666666, 1.0, 2.0, 0.397616373747309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 443031.8429439754, 443031.8429439754, 122292.1612617641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5834400.0000, 
sim time next is 5835000.0000, 
raw observation next is [24.4, 50.33333333333334, 1.0, 2.0, 0.393207877060344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437742.9023046792, 437742.9023046794, 121760.6737569876], 
processed observation next is [1.0, 0.5217391304347826, 0.7454545454545454, 0.5033333333333334, 1.0, 1.0, 0.24150984632542996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1621270008535849, 0.16212700085358495, 0.2969772530658234], 
reward next is 0.7030, 
noisyNet noise sample is [array([-1.0959715], dtype=float32), -0.6711834]. 
=============================================
[2019-03-23 08:41:48,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.55452]
 [67.55452]
 [67.55452]
 [67.55452]
 [67.55452]], R is [[67.58200073]
 [67.60791016]
 [67.63070679]
 [67.64646912]
 [67.64522552]].
[2019-03-23 08:41:49,478] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0197138e-18 1.0000000e+00 1.5298542e-27 1.0454901e-25 1.5699610e-28], sum to 1.0000
[2019-03-23 08:41:49,487] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0978
[2019-03-23 08:41:49,491] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333334, 44.0, 1.0, 2.0, 0.3261512033963524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359995.9481449901, 359995.9481449901, 115091.7298249946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5854800.0000, 
sim time next is 5855400.0000, 
raw observation next is [24.95, 45.0, 1.0, 2.0, 0.3243691672406637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358190.1355610468, 358190.1355610468, 115023.6785871752], 
processed observation next is [1.0, 0.782608695652174, 0.7704545454545454, 0.45, 1.0, 1.0, 0.15546145905082964, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13266301317075807, 0.13266301317075807, 0.2805455575296956], 
reward next is 0.7195, 
noisyNet noise sample is [array([1.0288154], dtype=float32), -1.0735354]. 
=============================================
[2019-03-23 08:41:54,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7798939e-18 1.0000000e+00 1.5795260e-26 6.3227187e-25 2.6480629e-28], sum to 1.0000
[2019-03-23 08:41:54,610] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9842
[2019-03-23 08:41:54,614] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 56.0, 1.0, 2.0, 0.4071572537975403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462098.4573836072, 462098.4573836069, 127519.9532000864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5943600.0000, 
sim time next is 5944200.0000, 
raw observation next is [25.28333333333333, 56.66666666666667, 1.0, 2.0, 0.4078633486036445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462729.0388737402, 462729.0388737402, 127460.8093400755], 
processed observation next is [1.0, 0.8260869565217391, 0.7856060606060605, 0.5666666666666668, 1.0, 1.0, 0.25982918575455555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17138112550879267, 0.17138112550879267, 0.31088002278067195], 
reward next is 0.6891, 
noisyNet noise sample is [array([0.6526295], dtype=float32), -0.92923003]. 
=============================================
[2019-03-23 08:41:55,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7856406e-17 1.0000000e+00 7.0910021e-25 1.2877391e-22 2.1974264e-26], sum to 1.0000
[2019-03-23 08:41:55,159] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-23 08:41:55,163] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 88.5, 1.0, 2.0, 0.3488439666094151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387775.162488241, 387775.1624882413, 117886.2060541687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5974200.0000, 
sim time next is 5974800.0000, 
raw observation next is [18.46666666666667, 89.0, 1.0, 2.0, 0.3471084912727267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385690.008483331, 385690.008483331, 117684.9476603124], 
processed observation next is [1.0, 0.13043478260869565, 0.4757575757575758, 0.89, 1.0, 1.0, 0.18388561409090834, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1428481512901226, 0.1428481512901226, 0.28703645770807906], 
reward next is 0.7130, 
noisyNet noise sample is [array([-0.6895058], dtype=float32), -0.3940452]. 
=============================================
[2019-03-23 08:41:56,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9675873e-18 1.0000000e+00 4.5865635e-25 4.8696091e-26 2.9084722e-28], sum to 1.0000
[2019-03-23 08:41:56,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-23 08:41:56,644] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 82.0, 1.0, 2.0, 0.4952731980663151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 78.72246871471147, 550547.4561512301, 550547.4561512301, 131264.8615531445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5969400.0000, 
sim time next is 5970000.0000, 
raw observation next is [19.2, 83.0, 1.0, 2.0, 0.4101853473064085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456113.2868604549, 456113.2868604549, 123001.0110024935], 
processed observation next is [1.0, 0.08695652173913043, 0.509090909090909, 0.83, 1.0, 1.0, 0.26273168413301057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16893084698535366, 0.16893084698535366, 0.3000024658597402], 
reward next is 0.7000, 
noisyNet noise sample is [array([2.038724], dtype=float32), -0.20426993]. 
=============================================
[2019-03-23 08:41:56,658] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.28275]
 [70.28275]
 [70.28275]
 [70.28275]
 [70.28275]], R is [[70.27993011]
 [70.25697327]
 [70.26634979]
 [70.2746048 ]
 [70.28161621]].
[2019-03-23 08:42:05,030] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 08:42:05,031] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:42:05,033] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:42:05,034] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:42:05,035] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:42:05,035] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:42:05,036] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:42:05,036] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:42:05,038] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:42:05,040] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:42:05,040] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:42:05,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 08:42:05,081] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 08:42:05,105] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 08:42:05,129] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 08:42:05,151] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 08:42:29,894] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:42:29,895] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [10.66666666666667, 72.66666666666667, 1.0, 2.0, 0.37696121111989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409359.3694310055, 409359.3694310055, 82930.52817413629]
[2019-03-23 08:42:29,897] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:42:29,902] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.9872176115588053
[2019-03-23 08:42:49,953] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:42:49,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.33333333333334, 51.0, 1.0, 2.0, 0.3258741531320996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357919.1322603018, 357919.1322603015, 114396.5106941386]
[2019-03-23 08:42:49,957] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:42:49,962] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.8090853797022856
[2019-03-23 08:42:50,361] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:42:50,363] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.6, 52.00000000000001, 1.0, 2.0, 0.2866438536550209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 311229.2482942679, 311229.2482942676, 104562.6933207831]
[2019-03-23 08:42:50,364] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:42:50,367] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.8353716543230234
[2019-03-23 08:42:50,579] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:42:50,581] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.65, 59.83333333333334, 1.0, 2.0, 0.2700631743538601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 293222.0553518995, 293222.0553518995, 95858.28841329495]
[2019-03-23 08:42:50,582] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:42:50,586] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.9931915835345062
[2019-03-23 08:42:55,203] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:42:55,204] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 84.0, 1.0, 2.0, 0.4898142280313163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 558864.9427921253, 558864.9427921249, 144171.5294876012]
[2019-03-23 08:42:55,205] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:42:55,209] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.04483465373561135
[2019-03-23 08:43:00,957] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:43:00,957] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.70030863, 89.59518031, 1.0, 2.0, 0.3122100902016737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 338996.1255168323, 338996.1255168323, 113244.1097408528]
[2019-03-23 08:43:00,958] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:43:00,961] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.9652595433582296
[2019-03-23 08:43:01,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:43:01,621] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [31.6, 47.0, 1.0, 2.0, 0.9067100007438496, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9828933827800735, 6.911199999999998, 6.9112, 95.55338769684306, 1570867.997114739, 1570867.99711474, 336723.6467956386]
[2019-03-23 08:43:01,622] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:43:01,626] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.36616354042704424
[2019-03-23 08:43:01,627] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1570867.997114739 W.
[2019-03-23 08:43:08,599] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:43:08,600] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 47.0, 1.0, 2.0, 0.693560764043533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 759820.3176344706, 759820.3176344703, 148413.582494202]
[2019-03-23 08:43:08,601] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:43:08,602] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.30673317939121636
[2019-03-23 08:43:17,743] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.65689254]
[2019-03-23 08:43:17,744] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.83333333333334, 49.33333333333334, 1.0, 2.0, 0.8732917710453632, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 95.55332331412944, 996225.3718793967, 996225.3718793971, 196173.736838589]
[2019-03-23 08:43:17,745] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:43:17,747] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1161743e-19 1.0000000e+00 3.6579077e-28 3.1849766e-27 1.2454319e-30], sampled 0.46747821172058357
[2019-03-23 08:43:47,589] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:43:47,912] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:43:47,945] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:43:48,175] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:43:48,284] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:43:49,295] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 800000, evaluation results [800000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:43:57,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.3630218e-17 1.0000000e+00 2.8576126e-25 2.2516952e-23 1.7380820e-26], sum to 1.0000
[2019-03-23 08:43:57,458] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1269
[2019-03-23 08:43:57,464] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4872099139079955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555844.1490525753, 555844.1490525751, 140137.3135162688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303600.0000, 
sim time next is 6304200.0000, 
raw observation next is [24.8, 72.33333333333334, 1.0, 2.0, 0.4867345592215527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555299.8411493308, 555299.8411493308, 140088.0443538267], 
processed observation next is [0.0, 1.0, 0.7636363636363637, 0.7233333333333334, 1.0, 1.0, 0.35841819902694083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2056666078330855, 0.2056666078330855, 0.3416781569605529], 
reward next is 0.6583, 
noisyNet noise sample is [array([-0.76523334], dtype=float32), -0.49430272]. 
=============================================
[2019-03-23 08:43:59,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6804289e-18 1.0000000e+00 1.4008139e-26 1.8213632e-25 7.3530161e-28], sum to 1.0000
[2019-03-23 08:43:59,738] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3277
[2019-03-23 08:43:59,746] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 71.83333333333334, 1.0, 2.0, 0.5280715502532416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 600630.2522531241, 600630.2522531241, 146907.9557748096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6346200.0000, 
sim time next is 6346800.0000, 
raw observation next is [26.1, 71.0, 1.0, 2.0, 0.5294534198319703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 602065.8190468749, 602065.8190468745, 147160.6283897794], 
processed observation next is [0.0, 0.4782608695652174, 0.8227272727272728, 0.71, 1.0, 1.0, 0.41181677478996276, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22298734038773144, 0.2229873403877313, 0.3589283619262912], 
reward next is 0.6411, 
noisyNet noise sample is [array([-0.2082837], dtype=float32), 0.15059374]. 
=============================================
[2019-03-23 08:43:59,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1020227e-18 1.0000000e+00 3.2669448e-26 6.4217725e-25 1.9394272e-28], sum to 1.0000
[2019-03-23 08:43:59,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2804
[2019-03-23 08:43:59,835] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 68.33333333333333, 1.0, 2.0, 0.5390747731570722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612097.7350352504, 612097.7350352504, 148835.205609796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6349200.0000, 
sim time next is 6349800.0000, 
raw observation next is [27.01666666666667, 67.66666666666667, 1.0, 2.0, 0.5429131957459202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 616208.409796734, 616208.409796734, 149434.3629328134], 
processed observation next is [0.0, 0.4782608695652174, 0.8643939393939395, 0.6766666666666667, 1.0, 1.0, 0.42864149468240026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22822533696175332, 0.22822533696175332, 0.36447405593369125], 
reward next is 0.6355, 
noisyNet noise sample is [array([-0.16895834], dtype=float32), -0.29991293]. 
=============================================
[2019-03-23 08:44:00,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9510970e-17 1.0000000e+00 1.7050848e-23 8.2661352e-23 3.5958058e-26], sum to 1.0000
[2019-03-23 08:44:00,064] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0299
[2019-03-23 08:44:00,070] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.556558022395505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630813.1571080239, 630813.1571080239, 151544.7132050181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [27.61666666666667, 65.66666666666667, 1.0, 2.0, 0.5581300983310046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632447.2977915723, 632447.2977915725, 151804.1144464445], 
processed observation next is [0.0, 0.782608695652174, 0.8916666666666668, 0.6566666666666667, 1.0, 1.0, 0.4476626229137557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23423973992280456, 0.23423973992280464, 0.37025393767425485], 
reward next is 0.6297, 
noisyNet noise sample is [array([0.23041265], dtype=float32), 1.4118438]. 
=============================================
[2019-03-23 08:44:04,247] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.0023820e-18 1.0000000e+00 2.8407226e-25 1.7453200e-23 6.6610651e-28], sum to 1.0000
[2019-03-23 08:44:04,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6330
[2019-03-23 08:44:04,258] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.21666666666667, 94.16666666666666, 1.0, 2.0, 0.8855408630413278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1008823.176343749, 1008823.176343749, 191625.5917649764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6437400.0000, 
sim time next is 6438000.0000, 
raw observation next is [19.93333333333333, 95.33333333333334, 1.0, 2.0, 0.7560319797272058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 860548.0195438527, 860548.0195438529, 170823.6723032492], 
processed observation next is [1.0, 0.5217391304347826, 0.5424242424242423, 0.9533333333333335, 1.0, 1.0, 0.6950399746590071, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31872148871994543, 0.3187214887199455, 0.41664310317865655], 
reward next is 0.5834, 
noisyNet noise sample is [array([1.4445587], dtype=float32), 0.27720034]. 
=============================================
[2019-03-23 08:44:04,289] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.387764]
 [64.387764]
 [64.387764]
 [64.387764]
 [64.387764]], R is [[64.32724762]
 [64.21659851]
 [64.13022614]
 [64.04133606]
 [63.96266174]].
[2019-03-23 08:44:05,524] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3741711e-16 1.0000000e+00 1.7479092e-26 5.7796969e-25 3.2121340e-29], sum to 1.0000
[2019-03-23 08:44:05,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9147
[2019-03-23 08:44:05,534] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.2, 87.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 209353.0914853647, 209353.0914853647, 69848.1970238826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6491400.0000, 
sim time next is 6492000.0000, 
raw observation next is [13.1, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205156.1253947009, 205156.1253947012, 69063.11974416862], 
processed observation next is [1.0, 0.13043478260869565, 0.2318181818181818, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07598375014618552, 0.07598375014618564, 0.1684466335223625], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7267892], dtype=float32), 0.04119802]. 
=============================================
[2019-03-23 08:44:05,550] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.9949]
 [70.9949]
 [70.9949]
 [70.9949]
 [70.9949]], R is [[70.28495789]
 [69.58210754]
 [68.88628387]
 [68.19741821]
 [68.33950043]].
[2019-03-23 08:44:18,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1121697e-21 1.0000000e+00 1.0654543e-28 8.2191341e-29 2.2245027e-31], sum to 1.0000
[2019-03-23 08:44:18,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9938
[2019-03-23 08:44:18,622] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3607778753960784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401691.1616291107, 401691.161629111, 119104.7849469463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6725400.0000, 
sim time next is 6726000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3587634829212312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399440.0396319373, 399440.0396319376, 118939.185961492], 
processed observation next is [1.0, 0.8695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.19845435365153902, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14794075541923604, 0.14794075541923613, 0.29009557551583415], 
reward next is 0.7099, 
noisyNet noise sample is [array([-0.1647414], dtype=float32), -0.3206048]. 
=============================================
[2019-03-23 08:44:18,634] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.73089]
 [71.73089]
 [71.73089]
 [71.73089]
 [71.73089]], R is [[71.72348785]
 [71.71575928]
 [71.70796967]
 [71.70032501]
 [71.69257355]].
[2019-03-23 08:44:20,778] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5794468e-21 1.0000000e+00 6.4521896e-27 1.0388271e-25 6.7832405e-31], sum to 1.0000
[2019-03-23 08:44:20,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0884
[2019-03-23 08:44:20,787] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 84.0, 1.0, 2.0, 0.277957259508419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301813.0986630188, 301813.0986630185, 99053.11240594226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6760800.0000, 
sim time next is 6761400.0000, 
raw observation next is [17.11666666666667, 82.5, 1.0, 2.0, 0.2911575093750212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316150.926379014, 316150.926379014, 99410.6947002079], 
processed observation next is [1.0, 0.2608695652173913, 0.4143939393939396, 0.825, 1.0, 1.0, 0.11394688671877651, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1170929356959311, 0.1170929356959311, 0.24246510902489732], 
reward next is 0.7575, 
noisyNet noise sample is [array([0.53520036], dtype=float32), 1.7228031]. 
=============================================
[2019-03-23 08:44:23,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0250696e-16 1.0000000e+00 2.5565116e-24 4.0881154e-24 2.7830986e-27], sum to 1.0000
[2019-03-23 08:44:23,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2903
[2019-03-23 08:44:23,214] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 88.0, 1.0, 2.0, 0.3603749863647621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401752.8538482962, 401752.8538482962, 119290.2267775082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6928800.0000, 
sim time next is 6929400.0000, 
raw observation next is [18.8, 87.5, 1.0, 2.0, 0.357530157235121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398244.8675624959, 398244.8675624962, 118915.7953453471], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.875, 1.0, 1.0, 0.19691269654390123, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14749809909722073, 0.1474980990972208, 0.2900385252325539], 
reward next is 0.7100, 
noisyNet noise sample is [array([-2.418906], dtype=float32), 0.8442923]. 
=============================================
[2019-03-23 08:44:24,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5695567e-17 1.0000000e+00 6.9207932e-26 2.6302989e-24 9.3564542e-27], sum to 1.0000
[2019-03-23 08:44:24,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7469
[2019-03-23 08:44:24,581] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3643242209615317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407375.2116061769, 407375.2116061769, 120149.3297011645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6832800.0000, 
sim time next is 6833400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3645833174941722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407635.7258040743, 407635.7258040743, 120157.5184335035], 
processed observation next is [0.0, 0.08695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.20572914686771526, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15097619474224974, 0.15097619474224974, 0.29306711813049635], 
reward next is 0.7069, 
noisyNet noise sample is [array([0.70736665], dtype=float32), 1.2451117]. 
=============================================
[2019-03-23 08:44:29,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6357791e-18 1.0000000e+00 1.8834946e-23 8.1906726e-24 1.0676687e-26], sum to 1.0000
[2019-03-23 08:44:29,285] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6553
[2019-03-23 08:44:29,289] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 65.66666666666667, 1.0, 2.0, 0.4652477136605942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 530876.6389695948, 530876.6389695945, 136900.9211760252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [25.81666666666667, 64.83333333333333, 1.0, 2.0, 0.469734087371272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 535997.4278812034, 535997.427881203, 137660.1394850064], 
processed observation next is [0.0, 0.43478260869565216, 0.809848484848485, 0.6483333333333333, 1.0, 1.0, 0.33716760921408995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19851756588192718, 0.19851756588192704, 0.33575643776830827], 
reward next is 0.6642, 
noisyNet noise sample is [array([0.2506629], dtype=float32), 0.4446178]. 
=============================================
[2019-03-23 08:44:29,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.32583]
 [66.32583]
 [66.32583]
 [66.32583]
 [66.32583]], R is [[66.32681274]
 [66.32963562]
 [66.33438873]
 [66.34130096]
 [66.35062408]].
[2019-03-23 08:44:30,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2689470e-17 1.0000000e+00 5.7766554e-25 3.9027804e-25 2.7584594e-28], sum to 1.0000
[2019-03-23 08:44:30,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9118
[2019-03-23 08:44:30,391] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 75.0, 1.0, 2.0, 0.4837751262018976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552028.5932928325, 552028.5932928325, 139224.581876403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6989400.0000, 
sim time next is 6990000.0000, 
raw observation next is [24.0, 75.33333333333333, 1.0, 2.0, 0.4806731770994638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 548491.4040324783, 548491.4040324786, 138775.5500872448], 
processed observation next is [0.0, 0.9130434782608695, 0.7272727272727273, 0.7533333333333333, 1.0, 1.0, 0.3508414713743297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20314496445647345, 0.20314496445647354, 0.3384769514323044], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.18594368], dtype=float32), -0.74596393]. 
=============================================
[2019-03-23 08:44:30,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.73177]
 [66.73177]
 [66.73177]
 [66.73177]
 [66.73177]], R is [[66.72596741]
 [66.7191391 ]
 [66.71160889]
 [66.70380402]
 [66.69562531]].
[2019-03-23 08:44:30,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7153848e-19 1.0000000e+00 3.8706770e-27 1.5747439e-25 3.9545204e-29], sum to 1.0000
[2019-03-23 08:44:30,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7906
[2019-03-23 08:44:30,972] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 63.0, 1.0, 2.0, 0.4782813559206197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545673.291154663, 545673.291154663, 139057.5702528056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6952200.0000, 
sim time next is 6952800.0000, 
raw observation next is [26.63333333333333, 62.0, 1.0, 2.0, 0.4818229280298399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549661.2003516847, 549661.2003516845, 139616.1442525584], 
processed observation next is [0.0, 0.4782608695652174, 0.8469696969696968, 0.62, 1.0, 1.0, 0.35227866003729985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20357822235247583, 0.20357822235247572, 0.34052718110380104], 
reward next is 0.6595, 
noisyNet noise sample is [array([-1.9701486], dtype=float32), 0.7528388]. 
=============================================
[2019-03-23 08:44:36,936] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 08:44:36,938] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:44:36,938] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:36,940] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:44:36,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:36,941] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:44:36,942] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:44:36,946] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:36,946] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:36,947] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:44:36,949] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:44:36,961] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 08:44:36,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 08:44:36,984] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 08:44:37,047] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 08:44:37,080] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 08:45:08,805] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.61321586]
[2019-03-23 08:45:08,806] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.19858721833334, 61.298754825, 1.0, 2.0, 0.3504875148715369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 381966.7092132793, 381966.7092132793, 119490.5581086256]
[2019-03-23 08:45:08,807] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:45:08,810] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.0480977e-19 1.0000000e+00 6.5400359e-27 4.9347789e-26 2.6665917e-29], sampled 0.5190438215582701
[2019-03-23 08:45:09,605] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.61321586]
[2019-03-23 08:45:09,606] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.84945172, 44.02996050333333, 1.0, 2.0, 0.4196381011208367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 455685.1392105132, 455685.1392105132, 107554.7631505961]
[2019-03-23 08:45:09,607] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:45:09,610] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0480977e-19 1.0000000e+00 6.5400359e-27 4.9347789e-26 2.6665917e-29], sampled 0.3076855311069545
[2019-03-23 08:45:09,699] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.61321586]
[2019-03-23 08:45:09,701] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.27198131, 36.454457875, 1.0, 2.0, 0.4098630164380327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 445066.4406124449, 445066.4406124449, 98561.33229202298]
[2019-03-23 08:45:09,704] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:45:09,707] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0480977e-19 1.0000000e+00 6.5400359e-27 4.9347789e-26 2.6665917e-29], sampled 0.12140895632982296
[2019-03-23 08:45:27,531] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.61321586]
[2019-03-23 08:45:27,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.22241879666667, 92.06680351333333, 1.0, 2.0, 0.3984613885314583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 449223.8136684375, 449223.8136684372, 129148.9777908234]
[2019-03-23 08:45:27,532] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:45:27,535] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0480977e-19 1.0000000e+00 6.5400359e-27 4.9347789e-26 2.6665917e-29], sampled 0.5465169498256894
[2019-03-23 08:45:48,115] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.61321586]
[2019-03-23 08:45:48,116] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.99108173666667, 97.55861092333333, 1.0, 2.0, 0.4478568480471269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 510027.7081834814, 510027.7081834811, 137377.2501251963]
[2019-03-23 08:45:48,118] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:45:48,121] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.0480977e-19 1.0000000e+00 6.5400359e-27 4.9347789e-26 2.6665917e-29], sampled 0.6672580270691176
[2019-03-23 08:46:19,743] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:46:20,047] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:46:20,112] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:46:20,242] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:46:20,350] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:46:21,365] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 825000, evaluation results [825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:46:26,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3539455e-18 1.0000000e+00 4.9145390e-29 2.0028414e-26 1.2627111e-30], sum to 1.0000
[2019-03-23 08:46:26,239] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3201
[2019-03-23 08:46:26,244] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.01666666666667, 49.66666666666667, 1.0, 2.0, 0.5816595094198276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631795.0427880342, 631795.0427880342, 130738.1655610496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7210200.0000, 
sim time next is 7210800.0000, 
raw observation next is [22.2, 49.0, 1.0, 2.0, 0.5971529052385458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 648635.1061869533, 648635.1061869536, 133081.9333102131], 
processed observation next is [1.0, 0.4782608695652174, 0.6454545454545454, 0.49, 1.0, 1.0, 0.4964411315481822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2402352245136864, 0.2402352245136865, 0.3245900812444222], 
reward next is 0.6754, 
noisyNet noise sample is [array([1.3671572], dtype=float32), -0.72366035]. 
=============================================
[2019-03-23 08:46:28,994] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.1414324e-17 1.0000000e+00 2.0954246e-25 9.6748150e-25 5.7617444e-29], sum to 1.0000
[2019-03-23 08:46:29,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-23 08:46:29,009] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 44.5, 1.0, 2.0, 0.6563142727797485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 714547.6334710442, 714547.6334710442, 142803.6173637808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7219800.0000, 
sim time next is 7220400.0000, 
raw observation next is [24.03333333333333, 44.0, 1.0, 2.0, 0.676701797931941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 738133.78187827, 738133.78187827, 145467.0359306653], 
processed observation next is [1.0, 0.5652173913043478, 0.7287878787878787, 0.44, 1.0, 1.0, 0.5958772474149262, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.273382882177137, 0.273382882177137, 0.35479764861137875], 
reward next is 0.6452, 
noisyNet noise sample is [array([-0.96647507], dtype=float32), -0.96266854]. 
=============================================
[2019-03-23 08:46:30,199] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4233056e-21 1.0000000e+00 5.1723828e-30 1.1560722e-28 6.5400656e-33], sum to 1.0000
[2019-03-23 08:46:30,205] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5279
[2019-03-23 08:46:30,211] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 45.0, 1.0, 2.0, 0.8100081966237735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 892182.0018925531, 892182.0018925531, 164231.8794847278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7228800.0000, 
sim time next is 7229400.0000, 
raw observation next is [24.3, 45.16666666666666, 1.0, 2.0, 0.7350119294773526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 809253.9654518678, 809253.9654518678, 154628.7765619297], 
processed observation next is [1.0, 0.6956521739130435, 0.740909090909091, 0.45166666666666655, 1.0, 1.0, 0.6687649118466906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2997236909080992, 0.2997236909080992, 0.3771433574681212], 
reward next is 0.6229, 
noisyNet noise sample is [array([0.6202211], dtype=float32), 1.4980562]. 
=============================================
[2019-03-23 08:46:30,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8930363e-18 1.0000000e+00 7.8616394e-25 2.9891498e-24 3.8726985e-28], sum to 1.0000
[2019-03-23 08:46:30,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8572
[2019-03-23 08:46:30,611] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 77.16666666666667, 1.0, 2.0, 0.3926755863182845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438423.6939049736, 438423.6939049736, 122252.8598219087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7373400.0000, 
sim time next is 7374000.0000, 
raw observation next is [20.73333333333333, 76.33333333333334, 1.0, 2.0, 0.5972479222359642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 669574.1100178406, 669574.1100178406, 143541.0645005209], 
processed observation next is [1.0, 0.34782608695652173, 0.5787878787878786, 0.7633333333333334, 1.0, 1.0, 0.49655990279495527, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24799041111771875, 0.24799041111771875, 0.35010015731834365], 
reward next is 0.6499, 
noisyNet noise sample is [array([0.18031064], dtype=float32), 1.5024447]. 
=============================================
[2019-03-23 08:46:30,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.66232]
 [74.66232]
 [74.66232]
 [74.66232]
 [74.66232]], R is [[74.56560516]
 [74.52176666]
 [74.48480225]
 [74.44908142]
 [74.41657257]].
[2019-03-23 08:46:31,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1151101e-18 1.0000000e+00 3.7692614e-27 4.4552430e-26 3.7996901e-29], sum to 1.0000
[2019-03-23 08:46:31,373] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1269
[2019-03-23 08:46:31,378] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.8, 83.0, 1.0, 2.0, 0.2035226322512675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220971.7171177323, 220971.7171177323, 71745.167878156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7276200.0000, 
sim time next is 7276800.0000, 
raw observation next is [13.8, 82.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 216246.0960884101, 216246.0960884104, 71093.86450073431], 
processed observation next is [1.0, 0.21739130434782608, 0.26363636363636367, 0.82, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08009114669941114, 0.08009114669941127, 0.17339966951398614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2298442], dtype=float32), 0.50159603]. 
=============================================
[2019-03-23 08:46:34,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7504115e-17 1.0000000e+00 2.3301111e-24 5.3569434e-24 6.8289493e-27], sum to 1.0000
[2019-03-23 08:46:34,068] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6047
[2019-03-23 08:46:34,073] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 83.5, 1.0, 2.0, 0.3270519445584236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 358512.8753445192, 358512.8753445194, 114224.7501328862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7350600.0000, 
sim time next is 7351200.0000, 
raw observation next is [18.2, 84.0, 1.0, 2.0, 0.3254962055730878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356549.4765200301, 356549.4765200301, 114018.8652687374], 
processed observation next is [1.0, 0.08695652173913043, 0.4636363636363636, 0.84, 1.0, 1.0, 0.1568702569663597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13205536167408524, 0.13205536167408524, 0.2780947933383839], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.45978567], dtype=float32), -1.6674]. 
=============================================
[2019-03-23 08:46:39,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2535393e-18 1.0000000e+00 6.8881596e-26 5.8669946e-26 4.1474039e-28], sum to 1.0000
[2019-03-23 08:46:39,066] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-23 08:46:39,073] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 91.5, 1.0, 2.0, 0.3981917204501785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 448043.4859158302, 448043.4859158299, 124337.2473524661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7421400.0000, 
sim time next is 7422000.0000, 
raw observation next is [19.0, 91.0, 1.0, 2.0, 0.390762997126118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438907.2565999628, 438907.2565999625, 123289.2908145222], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.91, 1.0, 1.0, 0.2384537464076475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16255824318517142, 0.1625582431851713, 0.3007055873524932], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.2829131], dtype=float32), 0.41847506]. 
=============================================
[2019-03-23 08:46:39,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.31177]
 [67.31177]
 [67.31177]
 [67.31177]
 [67.31177]], R is [[67.33794403]
 [67.36130524]
 [67.38233185]
 [67.40166473]
 [67.41912842]].
[2019-03-23 08:46:41,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5535812e-16 1.0000000e+00 1.6315200e-25 2.9448398e-24 7.1267366e-27], sum to 1.0000
[2019-03-23 08:46:41,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5571
[2019-03-23 08:46:41,487] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 75.33333333333333, 1.0, 2.0, 0.4558046326783651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 519845.1659122034, 519845.1659122037, 134949.5495685618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7512000.0000, 
sim time next is 7512600.0000, 
raw observation next is [23.38333333333333, 75.66666666666667, 1.0, 2.0, 0.4546851471718855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518533.9149166708, 518533.9149166711, 134760.7886444542], 
processed observation next is [0.0, 0.9565217391304348, 0.6992424242424241, 0.7566666666666667, 1.0, 1.0, 0.31835643396485686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1920495981172855, 0.19204959811728559, 0.32868485035232736], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.36714646], dtype=float32), 0.913896]. 
=============================================
[2019-03-23 08:46:43,345] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.5223896e-19 1.0000000e+00 4.1196677e-28 1.1352572e-27 4.3128598e-30], sum to 1.0000
[2019-03-23 08:46:43,346] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4079
[2019-03-23 08:46:43,350] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 93.0, 1.0, 2.0, 0.4361862569653774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 496546.618543735, 496546.618543735, 131616.0956428344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7538400.0000, 
sim time next is 7539000.0000, 
raw observation next is [20.41666666666667, 93.5, 1.0, 2.0, 0.4348207613553599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 494921.3629572942, 494921.3629572945, 131405.2690699933], 
processed observation next is [0.0, 0.2608695652173913, 0.5643939393939396, 0.935, 1.0, 1.0, 0.29352595169419987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18330420850270157, 0.18330420850270168, 0.3205006562682763], 
reward next is 0.6795, 
noisyNet noise sample is [array([1.1384982], dtype=float32), 0.81555235]. 
=============================================
[2019-03-23 08:46:43,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.61985]
 [71.61985]
 [71.61985]
 [71.61985]
 [71.61985]], R is [[71.58315277]
 [71.54631042]
 [71.50889587]
 [71.47101593]
 [71.43278503]].
[2019-03-23 08:46:44,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1213445e-19 1.0000000e+00 4.4441249e-26 2.4821605e-24 1.2810674e-27], sum to 1.0000
[2019-03-23 08:46:44,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-23 08:46:44,021] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 81.5, 1.0, 2.0, 0.4616163800450581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526595.6844217133, 526595.6844217133, 135858.3859175732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7519800.0000, 
sim time next is 7520400.0000, 
raw observation next is [22.7, 82.0, 1.0, 2.0, 0.4620696854628064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527138.5004883284, 527138.5004883284, 135982.7562774552], 
processed observation next is [0.0, 0.043478260869565216, 0.6681818181818181, 0.82, 1.0, 1.0, 0.327587106828508, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19523648166234386, 0.19523648166234386, 0.33166525921330536], 
reward next is 0.6683, 
noisyNet noise sample is [array([-1.8443637], dtype=float32), -1.2369624]. 
=============================================
[2019-03-23 08:46:44,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5931899e-18 1.0000000e+00 1.8126850e-25 1.7094671e-24 1.2055973e-27], sum to 1.0000
[2019-03-23 08:46:44,783] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3049
[2019-03-23 08:46:44,788] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 61.83333333333334, 1.0, 2.0, 0.479080943323461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546660.2509918964, 546660.2509918964, 138793.5463987878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7578600.0000, 
sim time next is 7579200.0000, 
raw observation next is [25.7, 67.66666666666667, 1.0, 2.0, 0.4878007413277032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556471.1049699124, 556471.1049699124, 140332.0326201703], 
processed observation next is [0.0, 0.7391304347826086, 0.8045454545454546, 0.6766666666666667, 1.0, 1.0, 0.35975092665962893, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2061004092481157, 0.2061004092481157, 0.3422732502930983], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.61144614], dtype=float32), -0.36479175]. 
=============================================
[2019-03-23 08:46:53,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9183205e-17 1.0000000e+00 3.3936396e-26 7.7567810e-25 3.6872718e-28], sum to 1.0000
[2019-03-23 08:46:53,282] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6673
[2019-03-23 08:46:53,284] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.45, 90.0, 1.0, 2.0, 0.3346431868647288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366543.4347967065, 366543.4347967068, 114670.8520966414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716600.0000, 
sim time next is 7717200.0000, 
raw observation next is [17.53333333333333, 88.0, 1.0, 2.0, 0.3367588664696569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367842.942318078, 367842.9423180783, 114465.6681057331], 
processed observation next is [1.0, 0.30434782608695654, 0.43333333333333324, 0.88, 1.0, 1.0, 0.17094858308707112, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13623812678447333, 0.13623812678447345, 0.2791845563554466], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.32578653], dtype=float32), -1.0781488]. 
=============================================
[2019-03-23 08:46:56,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1284222e-20 1.0000000e+00 7.2931470e-29 7.3187076e-28 2.8536075e-30], sum to 1.0000
[2019-03-23 08:46:56,453] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-23 08:46:56,457] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 52.33333333333334, 1.0, 2.0, 0.4061371802031266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441057.2555764594, 441057.2555764597, 105662.9530100608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7751400.0000, 
sim time next is 7752000.0000, 
raw observation next is [20.86666666666667, 51.66666666666667, 1.0, 2.0, 0.3018710109262165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 327788.0122943914, 327788.0122943917, 94608.05619037594], 
processed observation next is [1.0, 0.7391304347826086, 0.5848484848484851, 0.5166666666666667, 1.0, 1.0, 0.12733876365777058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12140296751644127, 0.12140296751644136, 0.23075135656189252], 
reward next is 0.7692, 
noisyNet noise sample is [array([-2.8514585], dtype=float32), 1.6899797]. 
=============================================
[2019-03-23 08:46:56,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.982704]
 [78.982704]
 [78.982704]
 [78.982704]
 [78.982704]], R is [[78.96212769]
 [78.91479492]
 [78.81111145]
 [78.71055603]
 [78.59875488]].
[2019-03-23 08:46:59,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4301889e-18 1.0000000e+00 1.5045289e-26 7.8413928e-25 4.0420209e-28], sum to 1.0000
[2019-03-23 08:46:59,048] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0013
[2019-03-23 08:46:59,052] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 63.0, 1.0, 2.0, 0.2907687224831483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315728.6283707261, 315728.6283707264, 110579.0774119911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7848000.0000, 
sim time next is 7848600.0000, 
raw observation next is [20.41666666666667, 63.0, 1.0, 2.0, 0.2952012468427277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 320543.2316946902, 320543.2316946905, 110871.5361170397], 
processed observation next is [1.0, 0.8695652173913043, 0.5643939393939396, 0.63, 1.0, 1.0, 0.1190015585534096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11871971544247785, 0.11871971544247796, 0.2704183807732675], 
reward next is 0.7296, 
noisyNet noise sample is [array([0.53241163], dtype=float32), 0.25121617]. 
=============================================
[2019-03-23 08:47:00,599] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:00,600] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:00,635] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 08:47:01,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0918676e-17 1.0000000e+00 6.5075133e-26 7.7300443e-26 6.3046183e-29], sum to 1.0000
[2019-03-23 08:47:01,050] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2079
[2019-03-23 08:47:01,056] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 74.0, 1.0, 2.0, 0.313364249481512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 342518.3748168727, 342518.3748168724, 112886.7975668904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7881600.0000, 
sim time next is 7882200.0000, 
raw observation next is [19.4, 74.5, 1.0, 2.0, 0.3120343957169957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341456.094521573, 341456.094521573, 112936.1576806376], 
processed observation next is [1.0, 0.21739130434782608, 0.5181818181818181, 0.745, 1.0, 1.0, 0.14004299464624462, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1264652201931752, 0.1264652201931752, 0.27545404312350635], 
reward next is 0.7245, 
noisyNet noise sample is [array([1.2700151], dtype=float32), 0.886111]. 
=============================================
[2019-03-23 08:47:03,593] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1541064e-15 1.0000000e+00 9.1270889e-22 4.9208033e-22 1.7833512e-24], sum to 1.0000
[2019-03-23 08:47:03,604] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5504
[2019-03-23 08:47:03,610] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 87.0, 1.0, 2.0, 0.888707886842873, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344353815, 1014566.54829386, 1014566.54829386, 197023.0681166103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7917600.0000, 
sim time next is 7918200.0000, 
raw observation next is [21.9, 87.0, 1.0, 2.0, 0.9047991951491757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354103, 1032834.911628852, 1032834.911628852, 198379.1570405586], 
processed observation next is [1.0, 0.6521739130434783, 0.6318181818181817, 0.87, 1.0, 1.0, 0.8809989939364695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.508428812920654, 0.3825314487514267, 0.3825314487514267, 0.48385160253794784], 
reward next is 0.5161, 
noisyNet noise sample is [array([0.9064911], dtype=float32), 0.6143078]. 
=============================================
[2019-03-23 08:47:04,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:04,374] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:04,409] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 08:47:04,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:04,824] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:04,835] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 08:47:05,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 08:47:05,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,056] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 08:47:05,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,229] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 08:47:05,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,257] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,259] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 08:47:05,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 08:47:05,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,660] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,661] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 08:47:05,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,769] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 08:47:05,837] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,837] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,841] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 08:47:05,879] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 08:47:05,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,916] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,917] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 08:47:05,943] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,944] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,945] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 08:47:05,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:05,997] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:05,999] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 08:47:06,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 08:47:06,141] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:06,142] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 08:47:10,231] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 08:47:10,240] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:47:10,241] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:10,242] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:47:10,243] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:47:10,244] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:10,245] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:47:10,245] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:47:10,244] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:10,246] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:10,247] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:47:10,268] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 08:47:10,268] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 08:47:10,314] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 08:47:10,338] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 08:47:10,338] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 08:47:12,072] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:47:12,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.4, 38.33333333333334, 1.0, 2.0, 0.2814068703801856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 305541.6444827132, 305541.6444827128, 84422.07286140323]
[2019-03-23 08:47:12,073] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:47:12,081] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.5234531319243538
[2019-03-23 08:47:15,369] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:47:15,371] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.0, 83.0, 1.0, 2.0, 0.3432330224326523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 380088.0746910503, 380088.0746910499, 121171.9402209363]
[2019-03-23 08:47:15,372] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:47:15,375] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.08195435009876517
[2019-03-23 08:47:34,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:47:34,818] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.81331321333333, 51.33709402666666, 1.0, 2.0, 0.3506512306415834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 380748.5423576394, 380748.542357639, 86348.51284532816]
[2019-03-23 08:47:34,820] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:47:34,824] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.6238917815942014
[2019-03-23 08:47:54,747] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:47:54,748] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.74908000333333, 58.05385558833333, 1.0, 2.0, 0.3373022835506494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 373824.2760154414, 373824.276015441, 120841.3480691499]
[2019-03-23 08:47:54,750] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:47:54,754] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.4620625811664669
[2019-03-23 08:47:56,596] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:47:56,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.17056842666667, 85.31942077666668, 1.0, 2.0, 0.2903623045441597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 315267.6890278414, 315267.689027841, 110535.7154408955]
[2019-03-23 08:47:56,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:47:56,599] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.4023552990169956
[2019-03-23 08:47:58,914] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:47:58,917] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.26666666666667, 65.33333333333334, 1.0, 2.0, 0.5703638148663042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 647791.8161182926, 647791.8161182923, 157065.8002439039]
[2019-03-23 08:47:58,919] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:47:58,921] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.7176451601266035
[2019-03-23 08:48:02,850] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:48:02,851] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.36666666666667, 66.66666666666667, 1.0, 2.0, 0.3581352617265889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 397471.694877233, 397471.6948772326, 122682.3460123075]
[2019-03-23 08:48:02,854] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:48:02,859] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.4267047310056342
[2019-03-23 08:48:08,082] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:48:08,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.05, 63.0, 1.0, 2.0, 0.5185891259684358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 590702.6284525342, 590702.6284525339, 149366.1990004578]
[2019-03-23 08:48:08,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:48:08,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.16654048410198796
[2019-03-23 08:48:27,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:48:27,489] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [10.415012612, 96.51043092166668, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 149366.5069785986, 149366.5069785986, 62157.82398719423]
[2019-03-23 08:48:27,492] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:48:27,496] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.4756615547713696
[2019-03-23 08:48:31,981] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:48:31,982] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.74606610333333, 68.96515096333333, 1.0, 2.0, 0.7735261750322991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 881617.3660556297, 881617.3660556293, 184844.0822072263]
[2019-03-23 08:48:31,983] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:48:31,984] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.7289180734968392
[2019-03-23 08:48:47,903] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:48:47,903] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.76666666666667, 78.0, 1.0, 2.0, 0.2183651082312506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237079.6252838262, 237079.6252838259, 81724.7944045809]
[2019-03-23 08:48:47,904] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:48:47,906] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.07539700874767108
[2019-03-23 08:48:48,199] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5266608]
[2019-03-23 08:48:48,200] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.7, 67.0, 1.0, 2.0, 0.2253943203660472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 244712.8146058638, 244712.8146058634, 81046.41265759771]
[2019-03-23 08:48:48,202] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:48:48,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2813009e-17 1.0000000e+00 2.0409362e-24 1.2668988e-23 1.3313887e-26], sampled 0.27767794064390017
[2019-03-23 08:48:52,815] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:48:52,927] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:48:53,073] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:48:53,076] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:48:53,160] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:48:54,171] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 850000, evaluation results [850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:48:56,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5275045e-19 1.0000000e+00 6.7413095e-27 4.2937400e-28 1.8887484e-29], sum to 1.0000
[2019-03-23 08:48:56,479] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7091
[2019-03-23 08:48:56,485] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.4863712073543966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528237.2222320747, 528237.222232075, 114591.623811374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 126000.0000, 
sim time next is 126600.0000, 
raw observation next is [19.33333333333334, 61.0, 1.0, 2.0, 0.558385320047562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 606498.9851044539, 606498.9851044535, 121430.8318941774], 
processed observation next is [1.0, 0.4782608695652174, 0.5151515151515155, 0.61, 1.0, 1.0, 0.4479816500594525, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22462925374239032, 0.22462925374239018, 0.29617276071750587], 
reward next is 0.7038, 
noisyNet noise sample is [array([1.6333761], dtype=float32), -0.19654669]. 
=============================================
[2019-03-23 08:49:02,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9972511e-20 1.0000000e+00 3.6397969e-29 2.0226813e-26 4.0791302e-30], sum to 1.0000
[2019-03-23 08:49:02,188] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9789
[2019-03-23 08:49:02,194] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 100.0, 1.0, 2.0, 0.2141090642779309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 232468.5273561856, 232468.5273561853, 76989.1322726228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 261000.0000, 
sim time next is 261600.0000, 
raw observation next is [13.33333333333333, 100.0, 1.0, 2.0, 0.2094917053842429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 227454.0661469217, 227454.066146922, 75828.84403107874], 
processed observation next is [0.0, 0.0, 0.2424242424242423, 1.0, 1.0, 1.0, 0.011864631730303596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0842422467210821, 0.08424224672108223, 0.1849484000758018], 
reward next is 0.8151, 
noisyNet noise sample is [array([0.44100434], dtype=float32), 0.25753358]. 
=============================================
[2019-03-23 08:49:04,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2135203e-19 1.0000000e+00 1.6227418e-27 1.1243239e-26 2.4881822e-30], sum to 1.0000
[2019-03-23 08:49:04,546] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4818
[2019-03-23 08:49:04,551] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 88.0, 1.0, 2.0, 0.2280876620801318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247649.6283457391, 247649.6283457394, 82697.49885366068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 289800.0000, 
sim time next is 290400.0000, 
raw observation next is [15.66666666666667, 86.0, 1.0, 2.0, 0.2270151247657403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 246484.8096619715, 246484.8096619712, 82239.03433749685], 
processed observation next is [0.0, 0.34782608695652173, 0.3484848484848486, 0.86, 1.0, 1.0, 0.03376890595717535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09129067024517462, 0.09129067024517452, 0.20058301057926062], 
reward next is 0.7994, 
noisyNet noise sample is [array([-0.31070843], dtype=float32), 0.0076674735]. 
=============================================
[2019-03-23 08:49:05,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4877670e-19 1.0000000e+00 5.6185588e-28 2.1786465e-26 2.2038955e-29], sum to 1.0000
[2019-03-23 08:49:05,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1847
[2019-03-23 08:49:05,284] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.2165895910683857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235162.4058737841, 235162.4058737838, 79659.84258211734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 280800.0000, 
sim time next is 281400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2169722606118499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235577.990402669, 235577.9904026687, 79709.69966938853], 
processed observation next is [0.0, 0.2608695652173913, 0.2727272727272727, 1.0, 1.0, 1.0, 0.021215325764812366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08725110755654408, 0.08725110755654397, 0.19441390163265496], 
reward next is 0.8056, 
noisyNet noise sample is [array([1.6295531], dtype=float32), 1.0132052]. 
=============================================
[2019-03-23 08:49:09,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1073952e-19 1.0000000e+00 2.0768011e-27 2.6234107e-27 3.0720833e-31], sum to 1.0000
[2019-03-23 08:49:09,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9960
[2019-03-23 08:49:09,978] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 54.0, 1.0, 2.0, 0.3695359946919348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401292.6608356214, 401292.6608356217, 96224.27224611287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 397200.0000, 
sim time next is 397800.0000, 
raw observation next is [19.5, 54.5, 1.0, 2.0, 0.3659175130040233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397361.6135062339, 397361.6135062339, 95298.96062061051], 
processed observation next is [1.0, 0.6086956521739131, 0.5227272727272727, 0.545, 1.0, 1.0, 0.2073968912550291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14717096796527182, 0.14717096796527182, 0.23243648931856223], 
reward next is 0.7676, 
noisyNet noise sample is [array([-0.17456636], dtype=float32), 0.5088007]. 
=============================================
[2019-03-23 08:49:10,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5501903e-19 1.0000000e+00 1.1116565e-28 1.8595470e-26 2.7246146e-30], sum to 1.0000
[2019-03-23 08:49:10,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6632
[2019-03-23 08:49:10,801] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 51.33333333333333, 1.0, 2.0, 0.2875128916877409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 312192.1787301422, 312192.1787301419, 86893.15696555613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391200.0000, 
sim time next is 391800.0000, 
raw observation next is [20.0, 50.16666666666667, 1.0, 2.0, 0.2896070239679668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314466.8005416808, 314466.8005416805, 86195.34662635415], 
processed observation next is [1.0, 0.5217391304347826, 0.5454545454545454, 0.5016666666666667, 1.0, 1.0, 0.11200877995995846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1164691853858077, 0.11646918538580758, 0.21023255274720523], 
reward next is 0.7898, 
noisyNet noise sample is [array([-1.6855556], dtype=float32), 0.16473976]. 
=============================================
[2019-03-23 08:49:13,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.19018576e-17 1.00000000e+00 1.30878595e-23 4.98001894e-24
 5.09466749e-27], sum to 1.0000
[2019-03-23 08:49:13,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8416
[2019-03-23 08:49:13,538] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5413880446710931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588025.959408652, 588025.9594086523, 110355.5558684427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 451200.0000, 
sim time next is 451800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5445110284602955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591420.0366120822, 591420.0366120822, 110709.4428936758], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.4306387855753694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21904445800447486, 0.21904445800447486, 0.2700230314479898], 
reward next is 0.7300, 
noisyNet noise sample is [array([-2.4910305], dtype=float32), -0.4775313]. 
=============================================
[2019-03-23 08:49:17,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6663797e-20 1.0000000e+00 4.6361799e-28 1.3865022e-26 2.3496708e-29], sum to 1.0000
[2019-03-23 08:49:17,205] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-23 08:49:17,208] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2165381204461804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235106.5080782091, 235106.5080782094, 76878.8384773578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 513600.0000, 
sim time next is 514200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.216125504380616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234658.401652722, 234658.4016527217, 76834.72318053324], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.020156880475769995, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08691051913063778, 0.08691051913063766, 0.18740176385495913], 
reward next is 0.8126, 
noisyNet noise sample is [array([-0.30026612], dtype=float32), -0.9114999]. 
=============================================
[2019-03-23 08:49:18,614] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5126134e-20 1.0000000e+00 3.6783492e-29 1.9975155e-26 2.4246250e-31], sum to 1.0000
[2019-03-23 08:49:18,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6817
[2019-03-23 08:49:18,626] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 88.0, 1.0, 2.0, 0.4241029503332979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460576.9819328307, 460576.981932831, 111446.0586217144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 552000.0000, 
sim time next is 552600.0000, 
raw observation next is [16.5, 88.0, 1.0, 2.0, 0.4299272329027731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466905.2062952202, 466905.2062952202, 114015.6787312583], 
processed observation next is [1.0, 0.391304347826087, 0.38636363636363635, 0.88, 1.0, 1.0, 0.2874090411284664, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1729278541834149, 0.1729278541834149, 0.27808702129575197], 
reward next is 0.7219, 
noisyNet noise sample is [array([1.3106105], dtype=float32), 1.0015783]. 
=============================================
[2019-03-23 08:49:20,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3490616e-18 1.0000000e+00 4.2089431e-27 4.0266833e-25 2.0630069e-27], sum to 1.0000
[2019-03-23 08:49:20,067] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7882
[2019-03-23 08:49:20,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 65.66666666666667, 1.0, 2.0, 0.3582030313652469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 398580.7992647154, 398580.7992647151, 118794.7365647494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 580800.0000, 
sim time next is 581400.0000, 
raw observation next is [21.5, 66.5, 1.0, 2.0, 0.3520946606349395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391445.5950382671, 391445.5950382668, 118166.0545838847], 
processed observation next is [1.0, 0.7391304347826086, 0.6136363636363636, 0.665, 1.0, 1.0, 0.19011832579367435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.144979850014173, 0.14497985001417288, 0.2882098892289871], 
reward next is 0.7118, 
noisyNet noise sample is [array([-1.5568383], dtype=float32), 0.17967713]. 
=============================================
[2019-03-23 08:49:20,515] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2835236e-19 1.0000000e+00 4.9565668e-27 3.3278230e-26 5.4124102e-29], sum to 1.0000
[2019-03-23 08:49:20,523] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4594
[2019-03-23 08:49:20,528] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 64.0, 1.0, 2.0, 0.6501533228637135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 722101.8920581787, 722101.8920581787, 146953.0130491272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 574800.0000, 
sim time next is 575400.0000, 
raw observation next is [21.83333333333334, 64.0, 1.0, 2.0, 0.665265001974441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 740635.1209281655, 740635.1209281655, 149382.8284909505], 
processed observation next is [1.0, 0.6521739130434783, 0.628787878787879, 0.64, 1.0, 1.0, 0.5815812524680513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2743093040474687, 0.2743093040474687, 0.36434836217304994], 
reward next is 0.6357, 
noisyNet noise sample is [array([-0.76340485], dtype=float32), 0.5275326]. 
=============================================
[2019-03-23 08:49:22,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.82233366e-20 1.00000000e+00 1.17768305e-27 2.23828805e-27
 2.97406195e-28], sum to 1.0000
[2019-03-23 08:49:22,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3327
[2019-03-23 08:49:22,147] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 48.0, 1.0, 2.0, 0.3045336865957674, 1.0, 1.0, 0.3045336865957674, 1.0, 2.0, 0.6081506349685005, 6.911199999999999, 6.9112, 77.3421103, 1040010.671206242, 1040010.671206242, 248054.141663114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 666000.0000, 
sim time next is 666600.0000, 
raw observation next is [25.83333333333334, 48.33333333333333, 1.0, 2.0, 0.5415584897357322, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846329803726, 612134.407749883, 612134.407749883, 139899.3377539045], 
processed observation next is [1.0, 0.7391304347826086, 0.8106060606060609, 0.4833333333333333, 1.0, 1.0, 0.42694811216966516, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288119639777, 0.22671644731477147, 0.22671644731477147, 0.3412178969607427], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6301657], dtype=float32), -0.0046225768]. 
=============================================
[2019-03-23 08:49:23,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2235202e-17 1.0000000e+00 3.3573812e-25 3.4328064e-25 1.3280852e-28], sum to 1.0000
[2019-03-23 08:49:23,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9387
[2019-03-23 08:49:23,024] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 94.0, 1.0, 2.0, 0.2708770643544401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294122.9170138562, 294122.9170138559, 93136.68457836729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 628200.0000, 
sim time next is 628800.0000, 
raw observation next is [15.66666666666667, 94.0, 1.0, 2.0, 0.2734251764158167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 296890.5448853461, 296890.5448853464, 95360.93956748018], 
processed observation next is [1.0, 0.2608695652173913, 0.3484848484848486, 0.94, 1.0, 1.0, 0.09178147051977087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1099594610686467, 0.1099594610686468, 0.23258765748165897], 
reward next is 0.7674, 
noisyNet noise sample is [array([1.0353988], dtype=float32), 1.1113892]. 
=============================================
[2019-03-23 08:49:23,659] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8644236e-17 1.0000000e+00 6.1390221e-25 3.1592163e-26 2.6645404e-27], sum to 1.0000
[2019-03-23 08:49:23,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1922
[2019-03-23 08:49:23,677] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3635778339680675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 406033.5831947328, 406033.5831947331, 119860.4790022997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 675600.0000, 
sim time next is 676200.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.362072172462746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 404351.3307281333, 404351.3307281333, 119736.9114774441], 
processed observation next is [1.0, 0.8260869565217391, 0.7272727272727273, 0.54, 1.0, 1.0, 0.20259021557843246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14975975212153086, 0.14975975212153086, 0.2920412475059612], 
reward next is 0.7080, 
noisyNet noise sample is [array([-1.842632], dtype=float32), 2.3403618]. 
=============================================
[2019-03-23 08:49:26,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.5380786e-16 1.0000000e+00 9.1189960e-26 1.2775452e-25 2.8075386e-27], sum to 1.0000
[2019-03-23 08:49:26,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2258
[2019-03-23 08:49:26,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1087965.766691367 W.
[2019-03-23 08:49:26,573] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 65.0, 1.0, 2.0, 0.9532888843496798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1087965.766691367, 1087965.766691368, 206066.7423186017], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 729000.0000, 
sim time next is 729600.0000, 
raw observation next is [25.33333333333333, 63.66666666666667, 1.0, 2.0, 0.5006177431307667, 1.0, 1.0, 0.5006177431307667, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1142549.500869624, 1142549.500869624, 227969.0679106938], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.6366666666666667, 1.0, 1.0, 0.3757721789134583, 1.0, 0.5, 0.3757721789134583, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4231664818035645, 0.4231664818035645, 0.5560221168553507], 
reward next is 0.4440, 
noisyNet noise sample is [array([1.9754813], dtype=float32), -0.70976484]. 
=============================================
[2019-03-23 08:49:30,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5792553e-18 1.0000000e+00 4.8855176e-26 6.2593839e-26 2.4141166e-28], sum to 1.0000
[2019-03-23 08:49:30,849] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3531
[2019-03-23 08:49:30,852] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 55.0, 1.0, 2.0, 0.5304245394254601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 603323.349542184, 603323.349542184, 147190.2729774513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 832800.0000, 
sim time next is 833400.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.5319597032333537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 605069.797326178, 605069.7973261783, 147381.4753436833], 
processed observation next is [0.0, 0.6521739130434783, 0.9545454545454546, 0.55, 1.0, 1.0, 0.41494962904169214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2240999249356215, 0.22409992493562159, 0.3594670130333739], 
reward next is 0.6405, 
noisyNet noise sample is [array([1.2582744], dtype=float32), 0.6987001]. 
=============================================
[2019-03-23 08:49:31,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2943177e-16 1.0000000e+00 6.2814410e-25 5.7075073e-24 3.5095070e-27], sum to 1.0000
[2019-03-23 08:49:31,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0399
[2019-03-23 08:49:31,179] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 100.0, 1.0, 2.0, 0.5757099653407326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 645141.7391754069, 645141.7391754072, 141006.2566381372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 984000.0000, 
sim time next is 984600.0000, 
raw observation next is [17.5, 100.0, 1.0, 2.0, 0.5599322728657555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626050.1418875958, 626050.1418875958, 138679.8344521419], 
processed observation next is [1.0, 0.391304347826087, 0.4318181818181818, 1.0, 1.0, 1.0, 0.4499153410821944, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23187042292133175, 0.23187042292133175, 0.3382434986637607], 
reward next is 0.6618, 
noisyNet noise sample is [array([0.61239886], dtype=float32), 0.045187205]. 
=============================================
[2019-03-23 08:49:34,232] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2968774e-17 1.0000000e+00 9.0960356e-25 4.2298580e-24 2.3024691e-27], sum to 1.0000
[2019-03-23 08:49:34,241] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5586
[2019-03-23 08:49:34,246] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 89.0, 1.0, 2.0, 0.3992217219054573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450875.9167420417, 450875.9167420414, 125333.3896089848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 870600.0000, 
sim time next is 871200.0000, 
raw observation next is [20.0, 88.0, 1.0, 2.0, 0.4003156790788086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452293.7361755186, 452293.7361755186, 125538.7022840369], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.88, 1.0, 1.0, 0.25039459884851073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1675161985835254, 0.1675161985835254, 0.3061919567903339], 
reward next is 0.6938, 
noisyNet noise sample is [array([-1.0969605], dtype=float32), -1.7297226]. 
=============================================
[2019-03-23 08:49:35,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3217766e-19 1.0000000e+00 1.2000008e-25 4.6155210e-26 8.5957883e-29], sum to 1.0000
[2019-03-23 08:49:35,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4977
[2019-03-23 08:49:35,022] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 99.0, 1.0, 2.0, 0.4056525109581427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459342.9425656614, 459342.9425656614, 126652.207006888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 885000.0000, 
sim time next is 885600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4082754412370198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 462712.5906913566, 462712.5906913569, 127160.9736332841], 
processed observation next is [0.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.26034430154627475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17137503358939135, 0.17137503358939146, 0.3101487161787417], 
reward next is 0.6899, 
noisyNet noise sample is [array([1.9994218], dtype=float32), -0.40238526]. 
=============================================
[2019-03-23 08:49:37,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.4700762e-17 1.0000000e+00 3.0923998e-24 3.0480838e-23 7.2497165e-27], sum to 1.0000
[2019-03-23 08:49:37,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1571
[2019-03-23 08:49:37,450] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 76.0, 1.0, 2.0, 0.4613726802786369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526304.1811756205, 526304.1811756205, 135795.2033838622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 912600.0000, 
sim time next is 913200.0000, 
raw observation next is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4631074320004282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528331.2901753379, 528331.2901753379, 136121.3455981406], 
processed observation next is [0.0, 0.5652173913043478, 0.7121212121212124, 0.7533333333333333, 1.0, 1.0, 0.3288842900005352, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19567825562049554, 0.19567825562049554, 0.3320032819466844], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.64574057], dtype=float32), -0.9089694]. 
=============================================
[2019-03-23 08:49:38,977] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4031032e-18 1.0000000e+00 2.0452810e-28 1.8054606e-24 1.4621244e-30], sum to 1.0000
[2019-03-23 08:49:38,985] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7178
[2019-03-23 08:49:38,994] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 96.0, 1.0, 2.0, 0.3896496873913392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 440171.8588354897, 440171.85883549, 124530.3305446481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 967200.0000, 
sim time next is 967800.0000, 
raw observation next is [19.0, 95.0, 1.0, 2.0, 0.3842218363539589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433571.9657439627, 433571.9657439627, 123775.303331653], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 0.95, 1.0, 1.0, 0.2302772954424486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16058220953480098, 0.16058220953480098, 0.301890983735739], 
reward next is 0.6981, 
noisyNet noise sample is [array([1.1899521], dtype=float32), -0.49677253]. 
=============================================
[2019-03-23 08:49:41,896] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 08:49:41,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:49:41,899] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:49:41,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:41,900] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:41,901] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:49:41,901] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:49:41,902] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:41,902] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:49:41,902] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:41,903] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:49:41,925] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 08:49:41,949] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 08:49:41,976] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 08:49:41,976] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 08:49:42,016] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 08:50:09,092] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:50:09,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.96666666666667, 87.0, 1.0, 2.0, 0.7895962869033637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 900171.8950118388, 900171.8950118388, 187170.0913992117]
[2019-03-23 08:50:09,095] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:50:09,096] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.6522336031695368
[2019-03-23 08:50:13,495] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:50:13,496] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [13.47834707666667, 67.25588656833332, 1.0, 2.0, 0.3124301769540281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 339235.1620371611, 339235.1620371614, 82889.59000790218]
[2019-03-23 08:50:13,497] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:50:13,500] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.5962594176055984
[2019-03-23 08:50:55,348] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:50:55,350] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.1, 78.0, 1.0, 2.0, 0.391205963864222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 441040.9075537305, 441040.9075537305, 128497.4150031142]
[2019-03-23 08:50:55,352] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:50:55,354] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.6579930067456213
[2019-03-23 08:51:10,124] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:51:10,125] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 87.0, 1.0, 2.0, 0.3522656330513716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391934.4890670407, 391934.4890670404, 118304.9712200769]
[2019-03-23 08:51:10,126] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:51:10,128] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.27566914752531446
[2019-03-23 08:51:18,522] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:51:18,524] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.83333333333333, 52.66666666666667, 1.0, 2.0, 0.3172519520767325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 344472.1223988774, 344472.1223988771, 101018.2484747491]
[2019-03-23 08:51:18,525] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:51:18,527] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.7287514924269327
[2019-03-23 08:51:19,007] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:51:19,008] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.09671639166667, 91.787378845, 1.0, 2.0, 0.364696897899121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 404652.4150772723, 404652.4150772716, 123165.074562458]
[2019-03-23 08:51:19,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:51:19,012] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.9754672898348595
[2019-03-23 08:51:19,837] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46418294]
[2019-03-23 08:51:19,837] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 94.0, 1.0, 2.0, 0.4342958257997349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 494269.1722669603, 494269.1722669603, 131297.0844213456]
[2019-03-23 08:51:19,839] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:51:19,841] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9225100e-18 1.0000000e+00 2.7967119e-26 1.8270276e-25 1.1316463e-28], sampled 0.7330698549922617
[2019-03-23 08:51:24,333] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:51:24,506] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:51:24,614] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:51:24,668] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:51:24,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:51:25,684] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 875000, evaluation results [875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:51:27,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2346267e-17 1.0000000e+00 3.0839250e-27 4.6672561e-26 6.2237758e-30], sum to 1.0000
[2019-03-23 08:51:27,042] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7809
[2019-03-23 08:51:27,045] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2195410165067563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238367.7047767395, 238367.7047767395, 75686.24152454188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1023600.0000, 
sim time next is 1024200.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2194719503185628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238292.6974644286, 238292.6974644288, 75660.99988802029], 
processed observation next is [1.0, 0.8695652173913043, 0.22727272727272727, 1.0, 1.0, 1.0, 0.02433993789820347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08825655461645504, 0.08825655461645511, 0.18453902411712267], 
reward next is 0.8155, 
noisyNet noise sample is [array([1.1386079], dtype=float32), 1.1943526]. 
=============================================
[2019-03-23 08:51:27,959] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9093452e-20 1.0000000e+00 2.4343689e-28 3.0483351e-26 4.7966824e-30], sum to 1.0000
[2019-03-23 08:51:27,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2066
[2019-03-23 08:51:27,978] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2103041611653223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228336.3910402417, 228336.3910402417, 74853.6741052901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1049400.0000, 
sim time next is 1050000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2103458055161532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228381.616741498, 228381.616741498, 74711.9384266465], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.012932256895191487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.0845857839783326, 0.0845857839783326, 0.18222424006499147], 
reward next is 0.8178, 
noisyNet noise sample is [array([-1.3340166], dtype=float32), -0.07411937]. 
=============================================
[2019-03-23 08:51:27,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.3546]
 [73.3546]
 [73.3546]
 [73.3546]
 [73.3546]], R is [[73.43883514]
 [73.52187347]
 [73.59960938]
 [73.66801453]
 [73.75151825]].
[2019-03-23 08:51:28,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4818503e-18 1.0000000e+00 2.1706671e-25 1.6492916e-25 1.5614373e-29], sum to 1.0000
[2019-03-23 08:51:28,480] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-23 08:51:28,487] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 99.00000000000001, 1.0, 2.0, 0.2118153835544574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229977.5789340951, 229977.5789340951, 74560.4582327297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1051800.0000, 
sim time next is 1052400.0000, 
raw observation next is [13.0, 98.0, 1.0, 2.0, 0.2068281151010548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224561.4251596724, 224561.4251596727, 73825.85479829431], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.98, 1.0, 1.0, 0.008535143876318499, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08317089820728607, 0.0831708982072862, 0.18006306048364468], 
reward next is 0.8199, 
noisyNet noise sample is [array([0.27128133], dtype=float32), -0.7070948]. 
=============================================
[2019-03-23 08:51:29,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0970153e-16 1.0000000e+00 1.8571395e-23 5.5059265e-24 2.1560239e-28], sum to 1.0000
[2019-03-23 08:51:29,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3665
[2019-03-23 08:51:29,951] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 73.83333333333334, 1.0, 2.0, 0.357559324975247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399014.3422017279, 399014.3422017282, 119237.2258075907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1109400.0000, 
sim time next is 1110000.0000, 
raw observation next is [20.33333333333334, 74.66666666666667, 1.0, 2.0, 0.3513190030692458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390939.5533225648, 390939.5533225648, 118254.1040292983], 
processed observation next is [1.0, 0.8695652173913043, 0.5606060606060609, 0.7466666666666667, 1.0, 1.0, 0.18914875383655722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14479242715650548, 0.14479242715650548, 0.2884246439738983], 
reward next is 0.7116, 
noisyNet noise sample is [array([1.1282265], dtype=float32), -0.86173916]. 
=============================================
[2019-03-23 08:51:29,992] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.59307]
 [68.59307]
 [68.59307]
 [68.59307]
 [68.59307]], R is [[68.61871338]
 [68.64170074]
 [68.66239166]
 [68.68138123]
 [68.69916534]].
[2019-03-23 08:51:39,604] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0183586e-16 1.0000000e+00 6.1372722e-23 1.5472724e-21 3.3408622e-25], sum to 1.0000
[2019-03-23 08:51:39,611] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5276
[2019-03-23 08:51:39,616] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 96.0, 1.0, 2.0, 0.3725725530435011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 416158.528658566, 416158.5286585663, 120637.4910260988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1291200.0000, 
sim time next is 1291800.0000, 
raw observation next is [18.0, 95.0, 1.0, 2.0, 0.3697370018377243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412366.4136113096, 412366.4136113093, 120129.3299510223], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.95, 1.0, 1.0, 0.21217125229715533, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15272830133752208, 0.15272830133752197, 0.29299836573420074], 
reward next is 0.7070, 
noisyNet noise sample is [array([0.8465548], dtype=float32), 1.4008827]. 
=============================================
[2019-03-23 08:51:47,066] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0016666e-17 1.0000000e+00 1.7628897e-25 6.1049062e-24 4.7275713e-26], sum to 1.0000
[2019-03-23 08:51:47,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4068
[2019-03-23 08:51:47,076] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 100.0, 1.0, 2.0, 0.4565495442557985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520634.1256041912, 520634.1256041912, 134905.6492087091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1468200.0000, 
sim time next is 1468800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4504728830951305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513477.1154204404, 513477.1154204407, 133885.5646368802], 
processed observation next is [0.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.3130911038689131, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1901767094149779, 0.19017670941497802, 0.3265501576509273], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.8139088], dtype=float32), -0.015821638]. 
=============================================
[2019-03-23 08:51:50,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3939445e-16 1.0000000e+00 2.3489946e-25 1.4156696e-23 3.3261711e-27], sum to 1.0000
[2019-03-23 08:51:50,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3977
[2019-03-23 08:51:50,725] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 87.33333333333334, 1.0, 2.0, 0.5944374711981047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667982.1241704371, 667982.1241704371, 158120.8115708238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1501800.0000, 
sim time next is 1502400.0000, 
raw observation next is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5985415441717993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 672597.1504609854, 672597.1504609854, 158689.2184594903], 
processed observation next is [0.0, 0.391304347826087, 0.7878787878787882, 0.8566666666666667, 1.0, 1.0, 0.49817693021474907, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24911005572629089, 0.24911005572629089, 0.3870468742914398], 
reward next is 0.6130, 
noisyNet noise sample is [array([-0.6695446], dtype=float32), -0.2844386]. 
=============================================
[2019-03-23 08:51:52,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1622676e-18 1.0000000e+00 6.4096791e-26 1.3048072e-24 8.0450261e-27], sum to 1.0000
[2019-03-23 08:51:52,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7385
[2019-03-23 08:51:52,957] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 99.0, 1.0, 2.0, 0.4000487186854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 453715.7527065011, 453715.7527065013, 126619.8989452013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1565400.0000, 
sim time next is 1566000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.3976391974216755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 450795.6747357529, 450795.6747357529, 126263.4612949874], 
processed observation next is [1.0, 0.13043478260869565, 0.5, 1.0, 1.0, 1.0, 0.24704899677709438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16696136101324183, 0.16696136101324183, 0.3079596616950912], 
reward next is 0.6920, 
noisyNet noise sample is [array([-0.3247884], dtype=float32), 0.31145602]. 
=============================================
[2019-03-23 08:51:52,975] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.92735]
 [66.92735]
 [66.92735]
 [66.92735]
 [66.92735]], R is [[66.95011902]
 [66.9717865 ]
 [66.99214172]
 [67.01048279]
 [67.01957703]].
[2019-03-23 08:51:53,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5593354e-15 1.0000000e+00 1.5781199e-22 5.5359436e-22 9.2470300e-26], sum to 1.0000
[2019-03-23 08:51:53,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6477
[2019-03-23 08:51:53,753] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 86.0, 1.0, 2.0, 0.3238855607788561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351701.2558859973, 351701.255885997, 76995.69228984448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1745400.0000, 
sim time next is 1746000.0000, 
raw observation next is [8.0, 87.0, 1.0, 2.0, 0.3257584154827705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353735.6933803581, 353735.6933803578, 77212.81902376145], 
processed observation next is [1.0, 0.21739130434782608, 0.0, 0.87, 1.0, 1.0, 0.15719801935346311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.131013219770503, 0.1310132197705029, 0.18832394883844256], 
reward next is 0.8117, 
noisyNet noise sample is [array([0.5483163], dtype=float32), 0.33727175]. 
=============================================
[2019-03-23 08:51:53,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.960175]
 [65.960175]
 [65.960175]
 [65.960175]
 [65.960175]], R is [[66.11224365]
 [66.26332092]
 [66.41330719]
 [66.5615387 ]
 [66.70763397]].
[2019-03-23 08:51:57,584] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2143679e-18 1.0000000e+00 6.2697763e-27 6.4416883e-27 2.4632902e-28], sum to 1.0000
[2019-03-23 08:51:57,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6724
[2019-03-23 08:51:57,592] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 80.5, 1.0, 2.0, 0.4136935165446195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469435.4921605631, 469435.4921605634, 128081.3044368737], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1629000.0000, 
sim time next is 1629600.0000, 
raw observation next is [21.33333333333334, 81.33333333333333, 1.0, 2.0, 0.4108320661413583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466019.2832181829, 466019.2832181831, 127685.9572803277], 
processed observation next is [1.0, 0.8695652173913043, 0.6060606060606063, 0.8133333333333332, 1.0, 1.0, 0.2635400826766979, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17259973452525293, 0.17259973452525298, 0.31142916409836024], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.41893524], dtype=float32), 2.3894966]. 
=============================================
[2019-03-23 08:51:59,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1936067e-19 1.0000000e+00 2.3814913e-27 1.6777200e-25 4.7023834e-29], sum to 1.0000
[2019-03-23 08:51:59,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-23 08:51:59,217] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 59.33333333333333, 1.0, 2.0, 0.6490152505821387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 706187.5934585525, 706187.5934585525, 141888.9989484504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1692600.0000, 
sim time next is 1693200.0000, 
raw observation next is [21.0, 58.66666666666667, 1.0, 2.0, 0.6180135238112139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 671316.9912768434, 671316.9912768431, 138273.3118625591], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.5866666666666667, 1.0, 1.0, 0.5225169047640174, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24863592269512716, 0.24863592269512708, 0.3372519801525831], 
reward next is 0.6627, 
noisyNet noise sample is [array([-1.4562559], dtype=float32), 0.6579777]. 
=============================================
[2019-03-23 08:51:59,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7475765e-17 1.0000000e+00 2.3534600e-26 2.8893017e-25 7.3643812e-29], sum to 1.0000
[2019-03-23 08:51:59,751] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2219
[2019-03-23 08:51:59,756] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 84.66666666666667, 1.0, 2.0, 0.6193339202309823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683617.8652383463, 683617.8652383463, 141915.2472381672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1678800.0000, 
sim time next is 1679400.0000, 
raw observation next is [18.5, 83.0, 1.0, 2.0, 0.6470200401942398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 713791.1280329049, 713791.1280329049, 144848.2073124284], 
processed observation next is [1.0, 0.43478260869565216, 0.4772727272727273, 0.83, 1.0, 1.0, 0.5587750502427996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26436708445663143, 0.26436708445663143, 0.35328831051811804], 
reward next is 0.6467, 
noisyNet noise sample is [array([0.19188352], dtype=float32), -1.2278526]. 
=============================================
[2019-03-23 08:52:10,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5258159e-22 1.0000000e+00 3.0807339e-30 5.7490104e-29 7.8859108e-32], sum to 1.0000
[2019-03-23 08:52:10,381] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5879
[2019-03-23 08:52:10,387] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 53.0, 1.0, 2.0, 0.2918050100993005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316854.2386263991, 316854.2386263988, 95863.75379539249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059200.0000, 
sim time next is 2059800.0000, 
raw observation next is [20.83333333333333, 53.5, 1.0, 2.0, 0.2891996545530016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314024.3198489147, 314024.3198489144, 94823.98857258345], 
processed observation next is [0.0, 0.8695652173913043, 0.5833333333333331, 0.535, 1.0, 1.0, 0.11149956819125201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11630530364774617, 0.11630530364774608, 0.2312780209087401], 
reward next is 0.7687, 
noisyNet noise sample is [array([-1.2190577], dtype=float32), 0.041174617]. 
=============================================
[2019-03-23 08:52:13,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3774352e-18 1.0000000e+00 1.5842821e-25 3.0507677e-25 1.9633283e-29], sum to 1.0000
[2019-03-23 08:52:13,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7863
[2019-03-23 08:52:13,182] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 92.0, 1.0, 2.0, 0.6679082081652064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 760668.8413801303, 760668.8413801306, 159026.1215569436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1930800.0000, 
sim time next is 1931400.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.7907212507568819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 901537.3552347525, 901537.3552347528, 177641.6208388781], 
processed observation next is [1.0, 0.34782608695652173, 0.5909090909090909, 0.91, 1.0, 1.0, 0.7384015634461024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33390272416101946, 0.3339027241610195, 0.4332722459484832], 
reward next is 0.5667, 
noisyNet noise sample is [array([0.8325417], dtype=float32), -0.24279235]. 
=============================================
[2019-03-23 08:52:13,297] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 08:52:13,300] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:52:13,303] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:52:13,303] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:52:13,304] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:52:13,304] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:52:13,305] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:52:13,303] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:52:13,305] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:52:13,306] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:52:13,306] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:52:13,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 08:52:13,348] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 08:52:13,371] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 08:52:13,371] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 08:52:13,420] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 08:52:18,994] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:52:18,995] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.38333333333333, 80.66666666666667, 1.0, 2.0, 0.3441358987188806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 381792.0924577687, 381792.0924577684, 121525.3833863151]
[2019-03-23 08:52:18,998] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:52:19,010] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.9327245629507143
[2019-03-23 08:52:27,801] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:52:27,801] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.40743673, 96.84911079, 1.0, 2.0, 0.3854004926486255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 431841.4002538351, 431841.4002538347, 126649.7119334875]
[2019-03-23 08:52:27,802] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:52:27,805] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.15125795631751737
[2019-03-23 08:52:29,116] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:52:29,116] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.7, 84.0, 1.0, 2.0, 0.4500419880027504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 512397.6625108387, 512397.6625108384, 137470.3534091254]
[2019-03-23 08:52:29,117] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:52:29,120] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.664275160793855
[2019-03-23 08:52:30,182] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:52:30,182] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.445357745, 63.88914187500001, 1.0, 2.0, 0.6316285823691086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 718233.6420385807, 718233.6420385807, 164950.8235149951]
[2019-03-23 08:52:30,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 08:52:30,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.9692324053922172
[2019-03-23 08:53:15,535] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:53:15,536] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.0, 90.0, 1.0, 2.0, 0.4119258403797247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 466358.3818976044, 466358.3818976041, 131516.0265934814]
[2019-03-23 08:53:15,537] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:53:15,540] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.7921953405582953
[2019-03-23 08:53:23,662] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:53:23,664] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.36666666666667, 52.33333333333334, 1.0, 2.0, 0.3818455634668929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 430885.9628388885, 430885.9628388888, 127889.7303406112]
[2019-03-23 08:53:23,665] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:53:23,670] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.6652128875759203
[2019-03-23 08:53:32,184] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:53:32,185] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.45, 78.5, 1.0, 2.0, 0.3953789558434639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 443237.2453285358, 443237.2453285358, 127611.9271602958]
[2019-03-23 08:53:32,185] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:53:32,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.1256390388451325
[2019-03-23 08:53:38,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:53:38,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.5, 79.0, 1.0, 2.0, 0.5680139854327776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643140.6616727517, 643140.6616727517, 153279.1389862543]
[2019-03-23 08:53:38,304] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:53:38,307] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.8624471970358953
[2019-03-23 08:53:54,818] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41912764]
[2019-03-23 08:53:54,819] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.06824752333333, 66.21238696, 1.0, 2.0, 0.2293868129798214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 249048.4008457072, 249048.4008457072, 82162.58792684112]
[2019-03-23 08:53:54,821] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:53:54,823] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.4108447e-17 1.0000000e+00 1.0339057e-24 6.3952023e-24 5.3709514e-27], sampled 0.18229862345522574
[2019-03-23 08:53:55,439] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:53:55,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:53:55,932] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:53:56,046] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:53:56,048] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:53:57,064] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 900000, evaluation results [900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:54:01,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0880224e-19 1.0000000e+00 4.9920724e-26 5.6497475e-27 1.3374589e-30], sum to 1.0000
[2019-03-23 08:54:01,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3644
[2019-03-23 08:54:01,061] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 53.0, 1.0, 2.0, 0.3143436045967196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 345086.9297547494, 345086.9297547491, 113505.9301298272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2037600.0000, 
sim time next is 2038200.0000, 
raw observation next is [23.16666666666667, 52.00000000000001, 1.0, 2.0, 0.3182086578092556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 349544.7285746667, 349544.7285746664, 113861.2125548191], 
processed observation next is [0.0, 0.6086956521739131, 0.6893939393939396, 0.52, 1.0, 1.0, 0.1477608222615695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12946101058320988, 0.1294610105832098, 0.27771027452394903], 
reward next is 0.7223, 
noisyNet noise sample is [array([1.3666618], dtype=float32), 0.50631315]. 
=============================================
[2019-03-23 08:54:02,898] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5109415e-19 1.0000000e+00 6.3849095e-26 7.3087273e-26 2.1118862e-30], sum to 1.0000
[2019-03-23 08:54:02,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2492
[2019-03-23 08:54:02,908] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 62.0, 1.0, 2.0, 0.2644885912613343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287184.1563457995, 287184.1563457995, 88203.91022268523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2068200.0000, 
sim time next is 2068800.0000, 
raw observation next is [19.0, 61.33333333333334, 1.0, 2.0, 0.2640895725558325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286750.7704217014, 286750.7704217017, 87476.38076381951], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 0.6133333333333334, 1.0, 1.0, 0.0801119656947906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1062039890450746, 0.1062039890450747, 0.21335702625321834], 
reward next is 0.7866, 
noisyNet noise sample is [array([-0.81814706], dtype=float32), -0.31970513]. 
=============================================
[2019-03-23 08:54:18,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3247080e-18 1.0000000e+00 4.6137034e-28 1.0559634e-25 9.5598874e-30], sum to 1.0000
[2019-03-23 08:54:18,708] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3421
[2019-03-23 08:54:18,712] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 50.83333333333334, 1.0, 2.0, 0.4533216062327108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 492324.5906537792, 492324.5906537795, 103254.4169552511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2368200.0000, 
sim time next is 2368800.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4547020240802316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493824.5386486088, 493824.5386486088, 102837.9469488493], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 1.0, 0.31837753010028946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1828979772772625, 0.1828979772772625, 0.25082426085085197], 
reward next is 0.7492, 
noisyNet noise sample is [array([1.7180111], dtype=float32), -0.9113737]. 
=============================================
[2019-03-23 08:54:20,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6106605e-19 1.0000000e+00 3.8781979e-28 3.7821831e-26 1.3230329e-29], sum to 1.0000
[2019-03-23 08:54:20,364] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-23 08:54:20,372] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 54.0, 1.0, 2.0, 0.2852095021566372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309690.2764447038, 309690.2764447038, 93465.43076386549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2402400.0000, 
sim time next is 2403000.0000, 
raw observation next is [20.5, 54.5, 1.0, 2.0, 0.2836398291846589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307985.3319022534, 307985.3319022531, 92610.06024857673], 
processed observation next is [1.0, 0.8260869565217391, 0.5681818181818182, 0.545, 1.0, 1.0, 0.10454978648082362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11406864144527903, 0.11406864144527892, 0.22587819572823592], 
reward next is 0.7741, 
noisyNet noise sample is [array([-0.01534467], dtype=float32), 0.8330063]. 
=============================================
[2019-03-23 08:54:20,383] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.63458]
 [78.63458]
 [78.63458]
 [78.63458]
 [78.63458]], R is [[78.62236023]
 [78.60816956]
 [78.59195709]
 [78.57374573]
 [78.55548859]].
[2019-03-23 08:54:23,151] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6153139e-19 1.0000000e+00 8.6920509e-26 3.9384953e-25 7.5581464e-28], sum to 1.0000
[2019-03-23 08:54:23,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9452
[2019-03-23 08:54:23,164] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333334, 84.0, 1.0, 2.0, 0.5063763630426966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 549976.679484333, 549976.6794843328, 115989.9841904259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2456400.0000, 
sim time next is 2457000.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.5107542704587484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554734.2493160967, 554734.2493160967, 118852.9575844881], 
processed observation next is [1.0, 0.43478260869565216, 0.38636363636363635, 0.85, 1.0, 1.0, 0.3884428380734355, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2054571293763321, 0.2054571293763321, 0.2898852624011905], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.70027065], dtype=float32), -0.6116461]. 
=============================================
[2019-03-23 08:54:23,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.79267]
 [71.79267]
 [71.79267]
 [71.79267]
 [71.79267]], R is [[71.78485107]
 [71.78409576]
 [71.78474426]
 [71.80118561]
 [71.81663513]].
[2019-03-23 08:54:24,767] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5379069e-20 1.0000000e+00 1.2185242e-28 6.8873943e-27 2.9508922e-30], sum to 1.0000
[2019-03-23 08:54:24,770] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1006
[2019-03-23 08:54:24,773] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 65.66666666666667, 1.0, 2.0, 0.7064636004481782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 782754.51855059, 782754.51855059, 152943.88373817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2475600.0000, 
sim time next is 2476200.0000, 
raw observation next is [21.16666666666667, 64.83333333333333, 1.0, 2.0, 0.716131221390328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 792529.7014747402, 792529.7014747402, 153779.8156764897], 
processed observation next is [1.0, 0.6521739130434783, 0.5984848484848487, 0.6483333333333333, 1.0, 1.0, 0.64516402673791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2935295190647186, 0.2935295190647186, 0.37507272116217], 
reward next is 0.6249, 
noisyNet noise sample is [array([-0.90950274], dtype=float32), -1.9311743]. 
=============================================
[2019-03-23 08:54:27,552] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4030115e-19 1.0000000e+00 4.9569614e-28 3.8873703e-26 1.4043270e-29], sum to 1.0000
[2019-03-23 08:54:27,562] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9342
[2019-03-23 08:54:27,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2087625751082085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 226662.2339009699, 226662.2339009699, 74529.20109226811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2530800.0000, 
sim time next is 2531400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2540419024360783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275837.8283843974, 275837.8283843971, 78912.57696661883], 
processed observation next is [1.0, 0.30434782608695654, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0675523780450979, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10216215866088792, 0.1021621586608878, 0.1924696999185825], 
reward next is 0.8075, 
noisyNet noise sample is [array([-0.5479393], dtype=float32), -0.020733336]. 
=============================================
[2019-03-23 08:54:27,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6188974e-18 1.0000000e+00 3.4011824e-26 5.3975527e-26 9.7837247e-29], sum to 1.0000
[2019-03-23 08:54:27,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4392
[2019-03-23 08:54:27,828] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 60.66666666666666, 1.0, 2.0, 0.475152046355885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516045.8670383243, 516045.8670383243, 124672.7901416243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2551800.0000, 
sim time next is 2552400.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.4411395788840875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 479180.5530418289, 479180.5530418291, 121808.9940024942], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.6, 1.0, 1.0, 0.3014244736051093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17747427890438108, 0.17747427890438114, 0.2970951073231566], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.7744366], dtype=float32), -1.342294]. 
=============================================
[2019-03-23 08:54:32,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3258312e-18 1.0000000e+00 8.4863610e-26 1.6781578e-22 2.1677356e-27], sum to 1.0000
[2019-03-23 08:54:32,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1336
[2019-03-23 08:54:32,030] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 42.83333333333333, 1.0, 2.0, 0.3350908498769229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 372220.5069471602, 372220.5069471599, 116704.5814312473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2634600.0000, 
sim time next is 2635200.0000, 
raw observation next is [26.0, 42.0, 1.0, 2.0, 0.3351112174123981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372142.7993548064, 372142.7993548064, 116664.1676386782], 
processed observation next is [0.0, 0.5217391304347826, 0.8181818181818182, 0.42, 1.0, 1.0, 0.16888902176549758, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13783066642770608, 0.13783066642770608, 0.2845467503382395], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.8890174], dtype=float32), 0.24448317]. 
=============================================
[2019-03-23 08:54:39,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9326204e-18 1.0000000e+00 2.6884547e-25 6.4468080e-25 4.3186263e-28], sum to 1.0000
[2019-03-23 08:54:39,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5896
[2019-03-23 08:54:39,217] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 81.33333333333333, 1.0, 2.0, 0.3798900532086876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 427161.1984018616, 427161.1984018616, 122579.0453969613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [20.16666666666667, 82.16666666666667, 1.0, 2.0, 0.3775236999719042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424233.878948661, 424233.8789486613, 122240.3701069593], 
processed observation next is [1.0, 0.0, 0.5530303030303032, 0.8216666666666668, 1.0, 1.0, 0.22190462496488025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15712365886987442, 0.15712365886987456, 0.29814724416331534], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.8039706], dtype=float32), 0.54154587]. 
=============================================
[2019-03-23 08:54:41,562] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1034463e-15 1.0000000e+00 1.1540099e-21 3.2332038e-22 1.0906315e-24], sum to 1.0000
[2019-03-23 08:54:41,571] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7870
[2019-03-23 08:54:41,580] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.0, 1.0, 2.0, 0.8950193600253519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1020047.124145468, 1020047.124145468, 193686.9769807416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2799000.0000, 
sim time next is 2799600.0000, 
raw observation next is [23.66666666666667, 70.33333333333334, 1.0, 2.0, 0.8545573430584206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974085.9132189885, 974085.9132189885, 187291.6801772783], 
processed observation next is [1.0, 0.391304347826087, 0.7121212121212124, 0.7033333333333335, 1.0, 1.0, 0.8181966788230257, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3607725604514772, 0.3607725604514772, 0.45680897604214216], 
reward next is 0.5432, 
noisyNet noise sample is [array([-0.53741497], dtype=float32), -0.9189503]. 
=============================================
[2019-03-23 08:54:41,909] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2188118e-14 1.0000000e+00 6.3983600e-21 5.6970312e-21 7.7916650e-23], sum to 1.0000
[2019-03-23 08:54:41,921] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8018
[2019-03-23 08:54:41,923] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 63.83333333333334, 1.0, 2.0, 0.4617208446161577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526798.1428257277, 526798.1428257277, 136156.1590223736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2841000.0000, 
sim time next is 2841600.0000, 
raw observation next is [25.33333333333334, 66.66666666666667, 1.0, 2.0, 0.4670432020286377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532922.5857140784, 532922.5857140784, 137043.9148341972], 
processed observation next is [1.0, 0.9130434782608695, 0.7878787878787882, 0.6666666666666667, 1.0, 1.0, 0.33380400253579706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19737873544965867, 0.19737873544965867, 0.33425345081511515], 
reward next is 0.6657, 
noisyNet noise sample is [array([-0.8095368], dtype=float32), -0.18521826]. 
=============================================
[2019-03-23 08:54:44,727] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 08:54:44,728] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:54:44,729] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:54:44,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:44,731] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:44,737] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:54:44,739] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:54:44,740] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:44,741] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:44,737] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:54:44,742] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:54:44,761] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 08:54:44,784] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 08:54:44,786] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 08:54:44,810] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 08:54:44,857] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 08:54:55,947] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39139003]
[2019-03-23 08:54:55,948] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3848428711523958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 433645.3271837288, 433645.3271837285, 123485.5546690331]
[2019-03-23 08:54:55,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:54:55,955] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9846929e-17 1.0000000e+00 3.9046142e-24 2.2209505e-23 2.7639393e-26], sampled 0.2577734429770875
[2019-03-23 08:55:30,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39139003]
[2019-03-23 08:55:30,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.1, 62.0, 1.0, 2.0, 0.2619769217629455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 284440.3002219984, 284440.300221998, 93187.07436127638]
[2019-03-23 08:55:30,631] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:55:30,635] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9846929e-17 1.0000000e+00 3.9046142e-24 2.2209505e-23 2.7639393e-26], sampled 0.2832022988059889
[2019-03-23 08:55:33,556] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39139003]
[2019-03-23 08:55:33,558] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 82.16666666666667, 1.0, 2.0, 0.5181408430522045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590086.3562937574, 590086.3562937574, 145154.2159857251]
[2019-03-23 08:55:33,560] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 08:55:33,563] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9846929e-17 1.0000000e+00 3.9046142e-24 2.2209505e-23 2.7639393e-26], sampled 0.6054148634501985
[2019-03-23 08:55:43,714] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39139003]
[2019-03-23 08:55:43,716] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.56228976333333, 92.13688396, 1.0, 2.0, 0.3646966781951017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 407924.5836216589, 407924.5836216589, 124561.5638889485]
[2019-03-23 08:55:43,717] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:55:43,722] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.9846929e-17 1.0000000e+00 3.9046142e-24 2.2209505e-23 2.7639393e-26], sampled 0.14640862444597313
[2019-03-23 08:55:47,948] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39139003]
[2019-03-23 08:55:47,950] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.43333333333333, 75.83333333333334, 1.0, 2.0, 0.5912204643020513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 671973.1682510121, 671973.1682510116, 152348.8486188553]
[2019-03-23 08:55:47,951] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:55:47,954] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9846929e-17 1.0000000e+00 3.9046142e-24 2.2209505e-23 2.7639393e-26], sampled 0.545523459119521
[2019-03-23 08:56:25,599] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39139003]
[2019-03-23 08:56:25,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.31666666666666, 62.5, 1.0, 2.0, 0.2658578416219499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288655.0038823665, 288655.0038823662, 89109.39946013001]
[2019-03-23 08:56:25,601] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:56:25,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9846929e-17 1.0000000e+00 3.9046142e-24 2.2209505e-23 2.7639393e-26], sampled 0.29888102930731997
[2019-03-23 08:56:27,183] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:56:27,254] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:56:27,338] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:56:27,389] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:56:27,560] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:56:28,574] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 925000, evaluation results [925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:56:29,667] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6599836e-15 1.0000000e+00 7.4243232e-21 4.2265924e-20 2.0745420e-22], sum to 1.0000
[2019-03-23 08:56:29,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8317
[2019-03-23 08:56:29,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1510148.055511898 W.
[2019-03-23 08:56:29,692] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 69.33333333333334, 1.0, 2.0, 0.447605958536852, 1.0, 2.0, 0.447605958536852, 1.0, 2.0, 0.9056766908398795, 6.9112, 6.9112, 77.3421103, 1510148.055511898, 1510148.055511898, 331423.6919036576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2895000.0000, 
sim time next is 2895600.0000, 
raw observation next is [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6559052938848369, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.32846344354104, 1285718.679173975, 1285718.679173975, 293072.0799591984], 
processed observation next is [1.0, 0.5217391304347826, 0.9242424242424245, 0.6866666666666668, 1.0, 1.0, 0.569881617356046, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4761921033977685, 0.4761921033977685, 0.7148099511199961], 
reward next is 0.2852, 
noisyNet noise sample is [array([0.5828412], dtype=float32), -0.002114123]. 
=============================================
[2019-03-23 08:56:31,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5115100e-17 1.0000000e+00 2.4234788e-23 5.5061628e-22 5.2830858e-27], sum to 1.0000
[2019-03-23 08:56:31,815] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0928
[2019-03-23 08:56:31,820] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5368896564870119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610658.2539682906, 610658.2539682906, 148010.0756522485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2938800.0000, 
sim time next is 2939400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5368245901335799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 610584.4720048042, 610584.4720048045, 148001.7708976557], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.4210307376669748, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22614239703881636, 0.2261423970388165, 0.36097992901867243], 
reward next is 0.6390, 
noisyNet noise sample is [array([1.5342513], dtype=float32), -0.49679255]. 
=============================================
[2019-03-23 08:56:32,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9435442e-17 1.0000000e+00 4.6907322e-24 1.8115749e-22 1.9914821e-26], sum to 1.0000
[2019-03-23 08:56:32,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1646
[2019-03-23 08:56:32,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1230666.872590486 W.
[2019-03-23 08:56:32,329] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.6030584123166912, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9806278839506688, 6.9112, 6.9112, 77.32846342295205, 1230666.872590486, 1230666.872590486, 281021.0950544], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2970000.0000, 
sim time next is 2970600.0000, 
raw observation next is [26.0, 73.33333333333334, 1.0, 2.0, 0.3704693136616134, 1.0, 1.0, 0.3704693136616134, 1.0, 2.0, 0.7485348513819453, 6.911199999999999, 6.9112, 77.3421103, 1249614.746518695, 1249614.746518695, 293131.4806407483], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.7333333333333334, 1.0, 1.0, 0.21308664207701672, 1.0, 0.5, 0.21308664207701672, 1.0, 1.0, 0.6407640734027791, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.46282027648840557, 0.46282027648840557, 0.7149548308310933], 
reward next is 0.2850, 
noisyNet noise sample is [array([-0.34529388], dtype=float32), -0.6437123]. 
=============================================
[2019-03-23 08:56:36,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1823418e-20 1.0000000e+00 1.1925475e-27 1.3916634e-26 2.5227253e-28], sum to 1.0000
[2019-03-23 08:56:36,269] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5006
[2019-03-23 08:56:36,274] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 91.0, 1.0, 2.0, 0.4174499643451193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473305.1940171187, 473305.1940171187, 128160.9330689963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3198600.0000, 
sim time next is 3199200.0000, 
raw observation next is [19.66666666666667, 92.0, 1.0, 2.0, 0.4105259577973157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 464697.4587932472, 464697.4587932475, 127002.3627719381], 
processed observation next is [0.0, 0.0, 0.5303030303030305, 0.92, 1.0, 1.0, 0.2631574472466446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17211016992342487, 0.172110169923425, 0.3097618604193612], 
reward next is 0.6902, 
noisyNet noise sample is [array([-0.4301015], dtype=float32), 0.2154808]. 
=============================================
[2019-03-23 08:56:37,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8743014e-21 1.0000000e+00 4.0588006e-28 5.1907756e-26 3.7602389e-29], sum to 1.0000
[2019-03-23 08:56:37,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8522
[2019-03-23 08:56:37,296] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3364365306332043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366739.0508003049, 366739.0508003049, 114182.580398934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3047400.0000, 
sim time next is 3048000.0000, 
raw observation next is [16.66666666666666, 96.0, 1.0, 2.0, 0.3282981438991203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 358295.8443483799, 358295.8443483799, 113750.5509893167], 
processed observation next is [1.0, 0.2608695652173913, 0.39393939393939365, 0.96, 1.0, 1.0, 0.1603726798739004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13270216457347403, 0.13270216457347403, 0.2774403682666261], 
reward next is 0.7226, 
noisyNet noise sample is [array([-2.0118072], dtype=float32), 1.8017352]. 
=============================================
[2019-03-23 08:56:37,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.82545]
 [69.82545]
 [69.82545]
 [69.82545]
 [69.82545]], R is [[69.8497467 ]
 [69.87275696]
 [69.89733887]
 [69.92294312]
 [69.95058441]].
[2019-03-23 08:56:40,116] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2181651e-14 1.0000000e+00 3.3578876e-21 1.4567489e-19 2.3196749e-22], sum to 1.0000
[2019-03-23 08:56:40,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0018
[2019-03-23 08:56:40,126] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 70.66666666666667, 1.0, 2.0, 0.5661216134393615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 640961.8498153294, 640961.8498153297, 153041.0582000663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3089400.0000, 
sim time next is 3090000.0000, 
raw observation next is [26.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5703529946265101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646001.2123879084, 646001.2123879084, 153516.4354572145], 
processed observation next is [1.0, 0.782608695652174, 0.8484848484848487, 0.7133333333333334, 1.0, 1.0, 0.4629412432831376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23925970829181792, 0.23925970829181792, 0.37443033038345], 
reward next is 0.6256, 
noisyNet noise sample is [array([0.31701288], dtype=float32), 0.38266367]. 
=============================================
[2019-03-23 08:56:40,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.934277]
 [63.934277]
 [63.934277]
 [63.934277]
 [63.934277]], R is [[63.92050171]
 [63.90802383]
 [63.89776611]
 [63.8896904 ]
 [63.88356781]].
[2019-03-23 08:56:45,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0692370e-16 1.0000000e+00 2.3283608e-24 1.2226487e-22 6.9685575e-26], sum to 1.0000
[2019-03-23 08:56:45,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2521
[2019-03-23 08:56:45,277] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3931194976597872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442977.7030103136, 442977.7030103139, 124222.0725049065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3202800.0000, 
sim time next is 3203400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3924446634514218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442216.3133976456, 442216.3133976456, 124161.4311852257], 
processed observation next is [0.0, 0.043478260869565216, 0.5, 0.94, 1.0, 1.0, 0.24055582931427724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1637838197769058, 0.1637838197769058, 0.3028327589883554], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.860084], dtype=float32), -0.48349038]. 
=============================================
[2019-03-23 08:56:46,361] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1283846e-18 1.0000000e+00 1.4981652e-27 1.5024599e-24 1.0670813e-28], sum to 1.0000
[2019-03-23 08:56:46,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8461
[2019-03-23 08:56:46,381] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.3351726012929923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370557.0261069332, 370557.0261069332, 115998.2899956653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3250800.0000, 
sim time next is 3251400.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3363041132401989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 371879.0548919595, 371879.0548919595, 116111.553489664], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17038014155024858, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13773298329331832, 0.13773298329331832, 0.2831989109504], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.55058414], dtype=float32), 0.53257567]. 
=============================================
[2019-03-23 08:56:46,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0786530e-17 1.0000000e+00 3.1416629e-23 2.8200600e-23 1.7377438e-26], sum to 1.0000
[2019-03-23 08:56:46,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7963
[2019-03-23 08:56:46,666] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 68.16666666666667, 1.0, 2.0, 0.3715100087356061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416889.7411415201, 416889.7411415201, 121436.1547574995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3229800.0000, 
sim time next is 3230400.0000, 
raw observation next is [22.0, 67.33333333333334, 1.0, 2.0, 0.368468427421434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 412913.094394092, 412913.094394092, 120909.2017762512], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.6733333333333335, 1.0, 1.0, 0.21058553427679247, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15293077570151556, 0.15293077570151556, 0.29490049213719804], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.67641383], dtype=float32), -1.3518038]. 
=============================================
[2019-03-23 08:56:48,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3924883e-16 1.0000000e+00 3.4494940e-23 4.4934977e-24 4.8496808e-26], sum to 1.0000
[2019-03-23 08:56:48,413] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3501
[2019-03-23 08:56:48,416] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 51.16666666666667, 1.0, 2.0, 0.3158947072017468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 344222.188300196, 344222.1883001957, 112686.8061637561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3265800.0000, 
sim time next is 3266400.0000, 
raw observation next is [22.66666666666667, 52.33333333333334, 1.0, 2.0, 0.3178173011996605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346597.7971566158, 346597.7971566155, 112918.9179350894], 
processed observation next is [0.0, 0.8260869565217391, 0.6666666666666669, 0.5233333333333334, 1.0, 1.0, 0.14727162649957562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1283695545024503, 0.12836955450245016, 0.27541199496363267], 
reward next is 0.7246, 
noisyNet noise sample is [array([-0.45861295], dtype=float32), 0.25810966]. 
=============================================
[2019-03-23 08:56:54,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6184970e-18 1.0000000e+00 1.9584935e-24 3.2026842e-24 6.4087468e-27], sum to 1.0000
[2019-03-23 08:56:54,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3932
[2019-03-23 08:56:54,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 63.0, 1.0, 2.0, 0.6831748190357325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.3284634435398, 779603.7597190662, 779603.7597190662, 165344.7366741041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3415200.0000, 
sim time next is 3415800.0000, 
raw observation next is [26.66666666666666, 62.5, 1.0, 2.0, 0.7214427980217165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823002.3294513595, 823002.3294513595, 171607.4324045001], 
processed observation next is [1.0, 0.5217391304347826, 0.8484848484848482, 0.625, 1.0, 1.0, 0.6518034975271455, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30481567757457756, 0.30481567757457756, 0.4185547131817076], 
reward next is 0.5814, 
noisyNet noise sample is [array([-2.0210629], dtype=float32), 0.29567656]. 
=============================================
[2019-03-23 08:56:56,886] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1347147e-15 1.0000000e+00 2.7997049e-23 1.6661221e-21 1.0563784e-25], sum to 1.0000
[2019-03-23 08:56:56,897] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3717
[2019-03-23 08:56:56,902] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.4980080500263036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 568032.7883128755, 568032.7883128755, 141699.8888096119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460800.0000, 
sim time next is 3461400.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.4958405848366844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 565606.7083883323, 565606.7083883319, 141351.3570486048], 
processed observation next is [1.0, 0.043478260869565216, 0.6136363636363636, 0.97, 1.0, 1.0, 0.3698007310458555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2094839660697527, 0.20948396606975256, 0.3447594074356215], 
reward next is 0.6552, 
noisyNet noise sample is [array([-1.453129], dtype=float32), -1.0593319]. 
=============================================
[2019-03-23 08:56:57,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3014732e-14 1.0000000e+00 1.0190546e-22 8.3997445e-21 1.2455837e-23], sum to 1.0000
[2019-03-23 08:56:57,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3470
[2019-03-23 08:56:57,155] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5186241936909024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591733.669610122, 591733.669610122, 143712.1589968544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3468000.0000, 
sim time next is 3468600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4992922392917673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569669.4179543223, 569669.4179543223, 141424.1341576327], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3741152991147091, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21098867331641566, 0.21098867331641566, 0.34493691257959197], 
reward next is 0.6551, 
noisyNet noise sample is [array([0.30241996], dtype=float32), -1.1719041]. 
=============================================
[2019-03-23 08:56:57,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6859938e-16 1.0000000e+00 3.8873759e-23 2.0016472e-21 2.6546931e-24], sum to 1.0000
[2019-03-23 08:56:57,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7376
[2019-03-23 08:56:57,991] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.5165608527787297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 588795.9921515848, 588795.9921515845, 144475.0221884463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3454200.0000, 
sim time next is 3454800.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5118049001019255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 583475.8445311356, 583475.8445311356, 143780.8218008438], 
processed observation next is [1.0, 1.0, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.3897561251274068, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21610216464116136, 0.21610216464116136, 0.3506849312215703], 
reward next is 0.6493, 
noisyNet noise sample is [array([0.13305397], dtype=float32), 2.2363331]. 
=============================================
[2019-03-23 08:57:00,760] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5818928e-13 1.0000000e+00 5.3533614e-19 8.6925838e-18 2.9546804e-20], sum to 1.0000
[2019-03-23 08:57:00,768] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3132
[2019-03-23 08:57:00,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1485371.856032555 W.
[2019-03-23 08:57:00,778] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.6, 60.0, 1.0, 2.0, 0.4402719437862873, 1.0, 1.0, 0.4402719437862873, 1.0, 2.0, 0.8908371962282019, 6.911199999999998, 6.9112, 77.3421103, 1485371.856032555, 1485371.856032555, 327556.1599475964], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3517200.0000, 
sim time next is 3517800.0000, 
raw observation next is [28.5, 59.66666666666666, 1.0, 2.0, 0.3914111397526543, 1.0, 2.0, 0.3914111397526543, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 879865.8541245639, 879865.8541245636, 210445.3007428202], 
processed observation next is [1.0, 0.7391304347826086, 0.9318181818181818, 0.5966666666666666, 1.0, 1.0, 0.23926392469081784, 1.0, 1.0, 0.23926392469081784, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.325876242268357, 0.3258762422683569, 0.5132812213239517], 
reward next is 0.4867, 
noisyNet noise sample is [array([-0.24510631], dtype=float32), -1.2444376]. 
=============================================
[2019-03-23 08:57:00,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6434491e-14 1.0000000e+00 5.5322757e-20 1.9014380e-19 1.9422994e-21], sum to 1.0000
[2019-03-23 08:57:00,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0808
[2019-03-23 08:57:00,967] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5376979978505355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612097.368831308, 612097.368831308, 147768.2578412048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3535200.0000, 
sim time next is 3535800.0000, 
raw observation next is [23.83333333333333, 84.0, 1.0, 2.0, 0.5354382466764868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609605.8564289903, 609605.8564289903, 147426.1408526001], 
processed observation next is [1.0, 0.9565217391304348, 0.7196969696969695, 0.84, 1.0, 1.0, 0.4192978083456084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22577994682555194, 0.22577994682555194, 0.35957595329902464], 
reward next is 0.6404, 
noisyNet noise sample is [array([1.1943562], dtype=float32), -0.16600943]. 
=============================================
[2019-03-23 08:57:08,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2137836e-16 1.0000000e+00 1.1300488e-23 1.1837350e-22 2.0646454e-26], sum to 1.0000
[2019-03-23 08:57:08,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1651
[2019-03-23 08:57:08,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1632453.118292983 W.
[2019-03-23 08:57:08,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 55.5, 1.0, 2.0, 0.9567553017499596, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9799909700264208, 6.911199999999999, 6.9112, 77.32846344354104, 1632453.118292983, 1632453.118292983, 338943.4606163636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3682200.0000, 
sim time next is 3682800.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.4450814755604428, 1.0, 1.0, 0.4450814755604428, 1.0, 2.0, 0.8991571304218227, 6.9112, 6.9112, 77.3421103, 1501619.576459919, 1501619.576459919, 329354.9874943679], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.55, 1.0, 1.0, 0.30635184445055347, 1.0, 0.5, 0.30635184445055347, 1.0, 1.0, 0.8559387577454609, 0.0, 0.0, 0.5085185399722538, 0.5561553986888589, 0.5561553986888589, 0.8033048475472387], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.82537466], dtype=float32), -0.87463295]. 
=============================================
[2019-03-23 08:57:16,701] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 08:57:16,701] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:57:16,702] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:57:16,702] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:57:16,704] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:57:16,706] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:57:16,704] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:57:16,710] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:57:16,711] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:57:16,712] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:57:16,716] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:57:16,734] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 08:57:16,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 08:57:16,735] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 08:57:16,818] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 08:57:16,840] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 08:57:36,795] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42235804]
[2019-03-23 08:57:36,798] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.30729886, 94.45118775, 1.0, 2.0, 0.4621115449587894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 526441.8694419669, 526441.8694419665, 139074.0114683668]
[2019-03-23 08:57:36,800] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 08:57:36,803] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.8455913e-19 1.0000000e+00 1.3102326e-26 2.0739217e-25 8.7390829e-29], sampled 0.5713341410998448
[2019-03-23 08:57:39,995] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42235804]
[2019-03-23 08:57:39,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.08333333333333, 78.0, 1.0, 2.0, 0.2419325726009336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 262672.4800056797, 262672.4800056797, 81984.51585010048]
[2019-03-23 08:57:39,999] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:57:40,002] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.8455913e-19 1.0000000e+00 1.3102326e-26 2.0739217e-25 8.7390829e-29], sampled 0.5004435423632679
[2019-03-23 08:57:57,598] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42235804]
[2019-03-23 08:57:57,599] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.28333333333333, 65.66666666666667, 1.0, 2.0, 0.6427038604111402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 733352.2944461874, 733352.2944461874, 162526.8438775666]
[2019-03-23 08:57:57,600] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:57:57,603] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8455913e-19 1.0000000e+00 1.3102326e-26 2.0739217e-25 8.7390829e-29], sampled 0.12342922627247332
[2019-03-23 08:58:58,166] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42235804]
[2019-03-23 08:58:58,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.81666666666667, 67.5, 1.0, 2.0, 0.3656822187518555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 408878.3531993814, 408878.353199381, 124575.7040198077]
[2019-03-23 08:58:58,167] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 08:58:58,170] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.8455913e-19 1.0000000e+00 1.3102326e-26 2.0739217e-25 8.7390829e-29], sampled 0.512501382087183
[2019-03-23 08:58:59,282] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 08:58:59,528] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 08:58:59,534] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 08:58:59,536] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 08:58:59,544] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 08:59:00,558] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 950000, evaluation results [950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 08:59:02,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0811006e-18 1.0000000e+00 1.4748716e-26 3.9244338e-22 1.9040224e-26], sum to 1.0000
[2019-03-23 08:59:02,611] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0832
[2019-03-23 08:59:02,619] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2969447164753981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322436.9996481845, 322436.9996481848, 110987.6143730141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3844200.0000, 
sim time next is 3844800.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2963511782409556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 321792.2937640036, 321792.2937640033, 110948.1201615307], 
processed observation next is [0.0, 0.5217391304347826, 0.5, 0.73, 1.0, 1.0, 0.12043897280119446, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11918233102370504, 0.11918233102370493, 0.27060517112568466], 
reward next is 0.7294, 
noisyNet noise sample is [array([-0.73997617], dtype=float32), -1.4777329]. 
=============================================
[2019-03-23 08:59:08,187] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0005223e-19 1.0000000e+00 4.5735974e-26 1.0618823e-23 2.9881306e-27], sum to 1.0000
[2019-03-23 08:59:08,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3001
[2019-03-23 08:59:08,202] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2698080768100163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 292961.8425787327, 292961.8425787325, 94891.25627448899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3985200.0000, 
sim time next is 3985800.0000, 
raw observation next is [16.83333333333334, 84.00000000000001, 1.0, 2.0, 0.2705047038021016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 293718.4795098461, 293718.4795098461, 95810.52537360147], 
processed observation next is [1.0, 0.13043478260869565, 0.40151515151515177, 0.8400000000000002, 1.0, 1.0, 0.08813087975262701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10878462204068373, 0.10878462204068373, 0.23368420822829628], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.46791476], dtype=float32), 1.5424457]. 
=============================================
[2019-03-23 08:59:13,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5705277e-18 1.0000000e+00 1.4222983e-26 1.3733753e-24 5.1925752e-27], sum to 1.0000
[2019-03-23 08:59:13,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-23 08:59:13,978] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 81.33333333333334, 1.0, 2.0, 0.7602140683213003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862411.5124458702, 862411.5124458702, 169126.5195634704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4110600.0000, 
sim time next is 4111200.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.7209779027254604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 818119.9863140483, 818119.9863140483, 163805.3428323831], 
processed observation next is [1.0, 0.6086956521739131, 0.5909090909090909, 0.83, 1.0, 1.0, 0.6512223784068255, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3030074023385364, 0.3030074023385364, 0.3995252264204466], 
reward next is 0.6005, 
noisyNet noise sample is [array([-0.3554435], dtype=float32), -0.5647021]. 
=============================================
[2019-03-23 08:59:19,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7909412e-18 1.0000000e+00 4.4157036e-25 1.8533249e-23 1.7014047e-26], sum to 1.0000
[2019-03-23 08:59:19,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5571
[2019-03-23 08:59:19,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1434587.918657426 W.
[2019-03-23 08:59:19,371] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.4207294380746485, 1.0, 1.0, 0.4207294380746485, 1.0, 2.0, 0.8522721243485947, 6.911199999999999, 6.9112, 77.3421103, 1434587.918657426, 1434587.918657426, 311050.7220804263], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4371600.0000, 
sim time next is 4372200.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.6417455632354665, 1.0, 2.0, 0.6417455632354665, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1459108.42626688, 1459108.42626688, 269209.8209473974], 
processed observation next is [1.0, 0.6086956521739131, 0.9545454545454546, 0.48, 1.0, 1.0, 0.5521819540443331, 1.0, 1.0, 0.5521819540443331, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5404105282469926, 0.5404105282469926, 0.6566093193838961], 
reward next is 0.3434, 
noisyNet noise sample is [array([0.19466384], dtype=float32), 0.6943795]. 
=============================================
[2019-03-23 08:59:23,216] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1516897e-17 1.0000000e+00 2.9307754e-24 2.3974737e-24 8.1591013e-27], sum to 1.0000
[2019-03-23 08:59:23,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5170
[2019-03-23 08:59:23,225] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 50.0, 1.0, 2.0, 0.8188080572357047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 919917.3795571381, 919917.3795571381, 172655.2521739741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4276800.0000, 
sim time next is 4277400.0000, 
raw observation next is [25.33333333333334, 49.16666666666667, 1.0, 2.0, 0.8234647081319498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 926099.497715344, 926099.497715344, 173781.5721530285], 
processed observation next is [1.0, 0.5217391304347826, 0.7878787878787882, 0.4916666666666667, 1.0, 1.0, 0.7793308851649372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34299981396864593, 0.34299981396864593, 0.4238574930561671], 
reward next is 0.5761, 
noisyNet noise sample is [array([-0.9758168], dtype=float32), -0.8880762]. 
=============================================
[2019-03-23 08:59:27,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3856687e-17 1.0000000e+00 6.8533795e-26 1.2291764e-23 6.6430262e-27], sum to 1.0000
[2019-03-23 08:59:27,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1051
[2019-03-23 08:59:27,848] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 88.5, 1.0, 2.0, 0.4074401858708781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460515.8393843946, 460515.8393843949, 126293.9109314966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4347000.0000, 
sim time next is 4347600.0000, 
raw observation next is [20.33333333333334, 86.66666666666666, 1.0, 2.0, 0.4463050372864881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 504969.9791474392, 504969.9791474395, 130298.5686258074], 
processed observation next is [1.0, 0.30434782608695654, 0.5606060606060609, 0.8666666666666666, 1.0, 1.0, 0.30788129660811014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18702591820275524, 0.18702591820275535, 0.31780138689221316], 
reward next is 0.6822, 
noisyNet noise sample is [array([0.64290285], dtype=float32), -0.91798407]. 
=============================================
[2019-03-23 08:59:30,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.03736329e-18 1.00000000e+00 1.07260824e-26 6.50645533e-23
 1.23006919e-28], sum to 1.0000
[2019-03-23 08:59:30,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4663
[2019-03-23 08:59:30,976] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4087186382945818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463165.9880251599, 463165.9880251599, 127169.3618762332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4431000.0000, 
sim time next is 4431600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4088284952640122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463291.4408245033, 463291.4408245033, 127180.332662438], 
processed observation next is [0.0, 0.30434782608695654, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2610356190800152, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17158942252759382, 0.17158942252759382, 0.31019593332301953], 
reward next is 0.6898, 
noisyNet noise sample is [array([0.3213359], dtype=float32), -0.455325]. 
=============================================
[2019-03-23 08:59:31,327] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.1886914e-19 1.0000000e+00 1.2146735e-26 7.8968063e-25 1.6560798e-27], sum to 1.0000
[2019-03-23 08:59:31,336] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1665
[2019-03-23 08:59:31,338] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.05770175e-16 1.00000000e+00 5.21823292e-26 4.42590608e-25
 3.29584584e-27], sum to 1.0000
[2019-03-23 08:59:31,343] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 82.33333333333333, 1.0, 2.0, 0.4519359174699271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515058.2956889392, 515058.2956889389, 133913.3874377168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408800.0000, 
sim time next is 4409400.0000, 
raw observation next is [22.08333333333334, 82.66666666666667, 1.0, 2.0, 0.4501315958248431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512940.0684763797, 512940.0684763797, 133641.2210744674], 
processed observation next is [0.0, 0.0, 0.6401515151515155, 0.8266666666666667, 1.0, 1.0, 0.3126644947810538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18997780313939988, 0.18997780313939988, 0.3259541977426034], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.13830921], dtype=float32), -0.06776159]. 
=============================================
[2019-03-23 08:59:31,346] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2983
[2019-03-23 08:59:31,350] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4490454020754537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511970.8956891022, 511970.8956891022, 133929.7934511263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438200.0000, 
sim time next is 4438800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.31340868109437897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1903506049783854, 0.19035060497838552, 0.32733399357352955], 
reward next is 0.6727, 
noisyNet noise sample is [array([0.26962757], dtype=float32), 1.9775633]. 
=============================================
[2019-03-23 08:59:34,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2266707e-15 1.0000000e+00 1.9787008e-25 1.3571692e-22 4.5183799e-27], sum to 1.0000
[2019-03-23 08:59:34,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7229
[2019-03-23 08:59:34,969] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4990114829135422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569257.9987416415, 569257.9987416415, 141647.7115418785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4469400.0000, 
sim time next is 4470000.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4988073380605132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569025.0611186991, 569025.0611186995, 141623.7874745956], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.78, 1.0, 1.0, 0.3735091725756415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21075002263655523, 0.21075002263655537, 0.34542387188925755], 
reward next is 0.6546, 
noisyNet noise sample is [array([0.8240436], dtype=float32), 0.62944496]. 
=============================================
[2019-03-23 08:59:34,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.874626]
 [69.874626]
 [69.874626]
 [69.874626]
 [69.874626]], R is [[69.83045197]
 [69.78666687]
 [69.74326324]
 [69.70014191]
 [69.6566925 ]].
[2019-03-23 08:59:36,934] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.7236959e-18 1.0000000e+00 4.0281582e-25 2.5042827e-24 1.1098949e-26], sum to 1.0000
[2019-03-23 08:59:36,941] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6104
[2019-03-23 08:59:36,945] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4115835389797709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466568.9707149618, 466568.9707149621, 127545.2985791925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4510800.0000, 
sim time next is 4511400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4113768146016772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466334.5678638094, 466334.5678638094, 127525.714095674], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 1.0, 1.0, 1.0, 0.26422101825209643, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1727165066162257, 0.1727165066162257, 0.3110383270626195], 
reward next is 0.6890, 
noisyNet noise sample is [array([-0.6000046], dtype=float32), 0.08329331]. 
=============================================
[2019-03-23 08:59:38,298] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5014004e-16 1.0000000e+00 1.7985727e-24 5.0907147e-23 2.3340065e-25], sum to 1.0000
[2019-03-23 08:59:38,309] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4667
[2019-03-23 08:59:38,316] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2893673611639841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 314206.481088374, 314206.4810883737, 101704.4216097403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4572600.0000, 
sim time next is 4573200.0000, 
raw observation next is [17.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2861341519145913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310694.6136397364, 310694.6136397367, 100397.4058265174], 
processed observation next is [0.0, 0.9565217391304348, 0.4393939393939396, 0.7866666666666667, 1.0, 1.0, 0.1076676898932391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11507207912582829, 0.11507207912582841, 0.2448717215280912], 
reward next is 0.7551, 
noisyNet noise sample is [array([-1.9967779], dtype=float32), 0.5980773]. 
=============================================
[2019-03-23 08:59:49,232] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 08:59:49,235] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 08:59:49,237] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 08:59:49,238] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:49,239] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:49,242] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 08:59:49,244] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 08:59:49,244] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:49,245] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:49,245] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 08:59:49,248] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 08:59:49,264] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 08:59:49,288] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 08:59:49,290] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 08:59:49,325] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 08:59:49,345] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 08:59:51,124] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41258875]
[2019-03-23 08:59:51,126] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.6, 36.0, 1.0, 2.0, 0.3110447009779847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 337730.3962844802, 337730.3962844802, 88997.03764319184]
[2019-03-23 08:59:51,128] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 08:59:51,131] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9449208e-17 1.0000000e+00 4.6614603e-24 4.6875683e-23 4.1132807e-26], sampled 0.07162659158721829
[2019-03-23 09:00:26,146] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41258875]
[2019-03-23 09:00:26,149] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.96666666666667, 64.0, 1.0, 2.0, 0.4207096161978914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 477288.9011098914, 477288.9011098914, 133014.3731261725]
[2019-03-23 09:00:26,151] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:00:26,156] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.9449208e-17 1.0000000e+00 4.6614603e-24 4.6875683e-23 4.1132807e-26], sampled 0.8958386696067626
[2019-03-23 09:00:40,679] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41258875]
[2019-03-23 09:00:40,680] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.33333333333333, 92.0, 1.0, 2.0, 0.3335091822995002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 365792.3634065549, 365792.3634065552, 114765.8611823734]
[2019-03-23 09:00:40,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:00:40,683] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.9449208e-17 1.0000000e+00 4.6614603e-24 4.6875683e-23 4.1132807e-26], sampled 0.9068629588978321
[2019-03-23 09:01:03,721] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41258875]
[2019-03-23 09:01:03,723] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.82700667, 60.88080346666666, 1.0, 2.0, 0.6211956401059276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 708649.1820843528, 708649.1820843528, 161260.347067449]
[2019-03-23 09:01:03,723] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:01:03,726] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9449208e-17 1.0000000e+00 4.6614603e-24 4.6875683e-23 4.1132807e-26], sampled 0.86578214322752
[2019-03-23 09:01:08,910] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41258875]
[2019-03-23 09:01:08,911] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.27584826, 74.86667207666667, 1.0, 2.0, 0.3397395699213452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 372799.4953989501, 372799.4953989497, 119600.9432138506]
[2019-03-23 09:01:08,912] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:01:08,916] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.9449208e-17 1.0000000e+00 4.6614603e-24 4.6875683e-23 4.1132807e-26], sampled 0.20855514125275199
[2019-03-23 09:01:15,951] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41258875]
[2019-03-23 09:01:15,952] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.46666666666667, 71.0, 1.0, 2.0, 0.4504808174200621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 512737.0507374328, 512737.0507374324, 137345.5224570418]
[2019-03-23 09:01:15,953] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:01:15,957] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.9449208e-17 1.0000000e+00 4.6614603e-24 4.6875683e-23 4.1132807e-26], sampled 0.8816143450700609
[2019-03-23 09:01:31,135] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:01:31,740] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:01:31,973] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:01:32,017] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:01:32,017] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:01:33,030] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 975000, evaluation results [975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:01:35,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7509586e-17 1.0000000e+00 3.3664826e-20 6.5580150e-22 1.0931640e-24], sum to 1.0000
[2019-03-23 09:01:35,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5431
[2019-03-23 09:01:35,681] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 99.33333333333334, 1.0, 2.0, 0.4915709455537983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560865.4797255356, 560865.4797255356, 140494.844203334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4821600.0000, 
sim time next is 4822200.0000, 
raw observation next is [21.05, 99.5, 1.0, 2.0, 0.4919122644723248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561253.7516029003, 561253.7516029003, 140539.1896962316], 
processed observation next is [1.0, 0.8260869565217391, 0.5931818181818183, 0.995, 1.0, 1.0, 0.36489033059040593, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20787175985292605, 0.20787175985292605, 0.3427785114542234], 
reward next is 0.6572, 
noisyNet noise sample is [array([-1.522125], dtype=float32), -0.9433087]. 
=============================================
[2019-03-23 09:01:35,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7644702e-16 1.0000000e+00 1.4309356e-25 3.0605739e-23 1.2740217e-25], sum to 1.0000
[2019-03-23 09:01:35,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0049
[2019-03-23 09:01:35,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1158125.024331625 W.
[2019-03-23 09:01:35,739] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3405986288575217, 1.0, 2.0, 0.3405986288575217, 1.0, 2.0, 0.6897520900842636, 6.9112, 6.9112, 77.3421103, 1158125.024331625, 1158125.024331625, 276959.0670106521], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4803000.0000, 
sim time next is 4803600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3313476744835857, 1.0, 2.0, 0.3313476744835857, 1.0, 2.0, 0.6710390232886718, 6.9112, 6.9112, 77.3421103, 1126825.442980752, 1126825.442980752, 273152.8336464649], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.94, 1.0, 1.0, 0.1641845931044821, 1.0, 1.0, 0.1641845931044821, 1.0, 1.0, 0.5300557475552455, 0.0, 0.0, 0.5085185399722538, 0.4173427566595378, 0.4173427566595378, 0.6662264235279632], 
reward next is 0.3338, 
noisyNet noise sample is [array([-0.19264607], dtype=float32), -2.467793]. 
=============================================
[2019-03-23 09:01:39,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6863440e-17 1.0000000e+00 1.3271610e-24 9.5276291e-23 6.7237974e-26], sum to 1.0000
[2019-03-23 09:01:39,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8740
[2019-03-23 09:01:39,936] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.5456204096366291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 618777.3097087234, 618777.3097087234, 141605.753382579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4883400.0000, 
sim time next is 4884000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4882824570463674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 553605.0396298217, 553605.039629822, 135254.3116956667], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.83, 1.0, 1.0, 0.36035307130795924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20503890356660062, 0.20503890356660073, 0.3298885651113822], 
reward next is 0.6701, 
noisyNet noise sample is [array([-1.2447208], dtype=float32), 0.079543225]. 
=============================================
[2019-03-23 09:01:39,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.29599]
 [64.29599]
 [64.29599]
 [64.29599]
 [64.29599]], R is [[64.32314301]
 [64.33453369]
 [64.33089447]
 [64.2841568 ]
 [64.21331024]].
[2019-03-23 09:01:43,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0173914e-16 1.0000000e+00 5.7236197e-24 2.0134081e-23 2.8087198e-25], sum to 1.0000
[2019-03-23 09:01:43,624] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7556
[2019-03-23 09:01:43,632] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 61.33333333333333, 1.0, 2.0, 0.2846737634569524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 309108.3680834337, 309108.3680834337, 97238.65684229421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4990200.0000, 
sim time next is 4990800.0000, 
raw observation next is [19.66666666666667, 62.66666666666667, 1.0, 2.0, 0.2858214888301165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310355.0046395057, 310355.0046395057, 97793.48697073608], 
processed observation next is [1.0, 0.782608695652174, 0.5303030303030305, 0.6266666666666667, 1.0, 1.0, 0.1072768610376456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11494629801463174, 0.11494629801463174, 0.23852069992862457], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.34426838], dtype=float32), -0.41785693]. 
=============================================
[2019-03-23 09:01:45,725] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1252897e-18 1.0000000e+00 2.0022236e-25 4.1270374e-24 4.7281980e-28], sum to 1.0000
[2019-03-23 09:01:45,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4035
[2019-03-23 09:01:45,741] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.242438318971712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263235.2875975668, 263235.2875975668, 82534.31862297104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5020800.0000, 
sim time next is 5021400.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.2421877146109248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262963.1122056925, 262963.1122056922, 82511.7667425834], 
processed observation next is [0.0, 0.08695652173913043, 0.2727272727272727, 1.0, 1.0, 1.0, 0.052734643263656, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0973937452613676, 0.09739374526136749, 0.20124821156727657], 
reward next is 0.7988, 
noisyNet noise sample is [array([-0.04121814], dtype=float32), -0.75919586]. 
=============================================
[2019-03-23 09:01:47,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4538396e-18 1.0000000e+00 1.3626973e-25 8.7803729e-24 4.7394478e-28], sum to 1.0000
[2019-03-23 09:01:47,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6566
[2019-03-23 09:01:47,291] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.33333333333334, 1.0, 2.0, 0.3387716141533434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377153.0071728948, 377153.0071728951, 117346.2289990227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5044800.0000, 
sim time next is 5045400.0000, 
raw observation next is [20.5, 76.0, 1.0, 2.0, 0.3442268022277549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 384194.7212725778, 384194.7212725775, 118196.520655419], 
processed observation next is [0.0, 0.391304347826087, 0.5681818181818182, 0.76, 1.0, 1.0, 0.18028350278469363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14229434121206586, 0.14229434121206574, 0.2882841967205341], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.21821149], dtype=float32), -1.3048927]. 
=============================================
[2019-03-23 09:01:50,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8918040e-18 1.0000000e+00 1.9137383e-24 1.3912098e-22 2.4342600e-26], sum to 1.0000
[2019-03-23 09:01:50,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0897
[2019-03-23 09:01:50,686] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.83333333333333, 1.0, 2.0, 0.4222681988924745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479958.2522027525, 479958.2522027525, 129526.2586143676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5097000.0000, 
sim time next is 5097600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4198812988407658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476935.7398152747, 476935.739815275, 129039.0891290468], 
processed observation next is [0.0, 0.0, 0.6363636363636364, 0.78, 1.0, 1.0, 0.2748516235509572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1766428665982499, 0.17664286659825001, 0.31472948568060194], 
reward next is 0.6853, 
noisyNet noise sample is [array([-0.9970621], dtype=float32), -0.18522152]. 
=============================================
[2019-03-23 09:01:54,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5778718e-18 1.0000000e+00 1.9098648e-25 1.7901262e-24 5.9112256e-27], sum to 1.0000
[2019-03-23 09:01:54,632] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7668
[2019-03-23 09:01:54,637] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 83.66666666666667, 1.0, 2.0, 0.4555483154006109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519554.9521824036, 519554.9521824033, 134926.8970514923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5181600.0000, 
sim time next is 5182200.0000, 
raw observation next is [22.2, 83.5, 1.0, 2.0, 0.4521153938412061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515541.1381919884, 515541.1381919884, 134372.1136720981], 
processed observation next is [0.0, 1.0, 0.6454545454545454, 0.835, 1.0, 1.0, 0.31514424230150756, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19094116229332903, 0.19094116229332903, 0.3277368626148734], 
reward next is 0.6723, 
noisyNet noise sample is [array([1.3694648], dtype=float32), 1.2432232]. 
=============================================
[2019-03-23 09:01:55,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.25702163e-16 1.00000000e+00 1.33825027e-22 1.00710546e-22
 3.70080381e-26], sum to 1.0000
[2019-03-23 09:01:55,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1807
[2019-03-23 09:01:55,038] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 83.33333333333333, 1.0, 2.0, 0.4486650658899898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 511493.3803934556, 511493.3803934553, 133817.5174325322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5182800.0000, 
sim time next is 5183400.0000, 
raw observation next is [22.06666666666667, 83.16666666666667, 1.0, 2.0, 0.4456340102347146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507910.2025580572, 507910.2025580572, 133308.8842268771], 
processed observation next is [0.0, 1.0, 0.6393939393939395, 0.8316666666666667, 1.0, 1.0, 0.30704251279339323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1881148898363175, 0.1881148898363175, 0.3251436200655539], 
reward next is 0.6749, 
noisyNet noise sample is [array([-0.62796545], dtype=float32), 1.0425019]. 
=============================================
[2019-03-23 09:01:57,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3628918e-17 1.0000000e+00 2.4637029e-21 1.3054116e-21 2.7052044e-24], sum to 1.0000
[2019-03-23 09:01:57,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7176
[2019-03-23 09:01:57,728] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5004321766112256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570709.9738494479, 570709.9738494479, 142140.2296532245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5257200.0000, 
sim time next is 5257800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.499038169451421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569119.9796836253, 569119.9796836256, 141976.0305143243], 
processed observation next is [1.0, 0.8695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3737977118142762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21078517766060195, 0.2107851776606021, 0.3462830012544495], 
reward next is 0.6537, 
noisyNet noise sample is [array([-0.83299947], dtype=float32), 0.8884771]. 
=============================================
[2019-03-23 09:02:01,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.04031104e-16 1.00000000e+00 3.52193325e-23 9.77693153e-22
 1.06386442e-24], sum to 1.0000
[2019-03-23 09:02:01,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3270
[2019-03-23 09:02:01,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1159334.520632731 W.
[2019-03-23 09:02:01,025] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.7, 51.0, 1.0, 2.0, 0.5352841184591154, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9580473279287763, 6.928079222625725, 6.9112, 77.32840789849385, 1159334.520632731, 1153852.498301442, 258130.5874169956], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5310000.0000, 
sim time next is 5310600.0000, 
raw observation next is [27.8, 51.66666666666666, 1.0, 2.0, 0.3208897973832265, 1.0, 1.0, 0.3208897973832265, 1.0, 2.0, 0.6493754916073312, 6.911199999999999, 6.9112, 77.3421103, 1097672.233008571, 1097672.233008571, 264375.5180800845], 
processed observation next is [1.0, 0.4782608695652174, 0.9, 0.5166666666666666, 1.0, 1.0, 0.1511122467290331, 1.0, 0.5, 0.1511122467290331, 1.0, 1.0, 0.49910784515333034, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4065452714846559, 0.4065452714846559, 0.644818336780694], 
reward next is 0.3552, 
noisyNet noise sample is [array([1.4861879], dtype=float32), -0.62584025]. 
=============================================
[2019-03-23 09:02:06,347] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2440420e-13 1.0000000e+00 9.5514429e-20 7.8892086e-20 2.4852718e-21], sum to 1.0000
[2019-03-23 09:02:06,356] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6963
[2019-03-23 09:02:06,368] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4008838219828563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452965.4090535752, 452965.4090535752, 125607.9082780798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5424000.0000, 
sim time next is 5424600.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.400849191544525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452925.1149949055, 452925.1149949055, 125604.0615844941], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.2510614894306562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16775004259070572, 0.16775004259070572, 0.3063513697182783], 
reward next is 0.6936, 
noisyNet noise sample is [array([-0.720653], dtype=float32), -0.54010665]. 
=============================================
[2019-03-23 09:02:15,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3433055e-17 1.0000000e+00 3.9739213e-22 4.9720704e-22 2.0786026e-25], sum to 1.0000
[2019-03-23 09:02:15,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5847
[2019-03-23 09:02:15,562] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 90.0, 1.0, 2.0, 0.3884526892854072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437402.4063683909, 437402.4063683907, 123639.756875798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5611800.0000, 
sim time next is 5612400.0000, 
raw observation next is [19.4, 90.0, 1.0, 2.0, 0.3881734238682161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 437087.1885394402, 437087.1885394399, 123614.7267434905], 
processed observation next is [1.0, 1.0, 0.5181818181818181, 0.9, 1.0, 1.0, 0.23521677983527015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16188414390349637, 0.16188414390349626, 0.3014993335207085], 
reward next is 0.6985, 
noisyNet noise sample is [array([0.13471816], dtype=float32), -0.22795263]. 
=============================================
[2019-03-23 09:02:21,091] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 09:02:21,094] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:02:21,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:02:21,095] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:02:21,096] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:02:21,098] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:02:21,099] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:02:21,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:02:21,101] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:02:21,104] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:02:21,105] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:02:21,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 09:02:21,143] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 09:02:21,144] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 09:02:21,144] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 09:02:21,211] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 09:02:27,379] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:02:27,381] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 55.33333333333334, 1.0, 2.0, 0.2744387963179728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 297991.4909122052, 297991.4909122052, 98688.31999837127]
[2019-03-23 09:02:27,382] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:02:27,388] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.9410994135383709
[2019-03-23 09:02:44,618] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:02:44,618] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.71666666666667, 76.83333333333333, 1.0, 2.0, 0.4401158484455047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 501082.7491764357, 501082.7491764353, 136439.6817444291]
[2019-03-23 09:02:44,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:02:44,622] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.84000020038871
[2019-03-23 09:02:59,517] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:02:59,519] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.1951343, 100.0, 1.0, 2.0, 0.268934811072066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 291996.6332893186, 291996.6332893186, 91297.84830307761]
[2019-03-23 09:02:59,520] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:02:59,523] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.8667560986150027
[2019-03-23 09:03:30,570] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:03:30,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.9, 88.0, 1.0, 2.0, 0.4234161337282691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 481453.4635040916, 481453.4635040916, 134150.8360052799]
[2019-03-23 09:03:30,572] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:03:30,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.7597535707604048
[2019-03-23 09:03:38,593] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:03:38,595] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.90890091, 63.25562671, 1.0, 2.0, 0.4863461040836121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 554901.9989527983, 554901.998952798, 143515.3184023318]
[2019-03-23 09:03:38,597] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:03:38,600] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.2234727860480341
[2019-03-23 09:03:56,649] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:03:56,650] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.7, 85.0, 1.0, 2.0, 0.937868776421969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1070409.236806852, 1070409.236806852, 210701.7004120373]
[2019-03-23 09:03:56,652] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:03:56,657] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.6832757701943291
[2019-03-23 09:04:01,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44420424]
[2019-03-23 09:04:01,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.51666666666667, 69.0, 1.0, 2.0, 0.4947407544040256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 564276.5114173501, 564276.5114173504, 141371.4560089671]
[2019-03-23 09:04:01,471] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:04:01,476] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7258163e-18 1.0000000e+00 8.6090258e-26 1.0263412e-24 4.6442871e-28], sampled 0.951288914097367
[2019-03-23 09:04:05,042] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:04:05,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:04:05,414] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:04:05,473] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:04:05,592] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:04:06,606] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1000000, evaluation results [1000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:04:10,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0413121e-15 1.0000000e+00 2.7572446e-24 1.8527028e-23 2.8324016e-25], sum to 1.0000
[2019-03-23 09:04:10,186] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5138895e-17 1.0000000e+00 9.7649944e-24 2.5654335e-22 4.8166969e-26], sum to 1.0000
[2019-03-23 09:04:10,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5555
[2019-03-23 09:04:10,259] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9682
[2019-03-23 09:04:10,262] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333334, 41.66666666666666, 1.0, 2.0, 0.2692200206801771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292323.1301082714, 292323.1301082714, 84665.1407759049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5760600.0000, 
sim time next is 5761200.0000, 
raw observation next is [21.96666666666667, 41.33333333333334, 1.0, 2.0, 0.2715961972156596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294904.0004345046, 294904.0004345049, 85426.4514199147], 
processed observation next is [0.0, 0.6956521739130435, 0.6348484848484849, 0.41333333333333344, 1.0, 1.0, 0.08949524651957447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10922370386463133, 0.10922370386463144, 0.2083571985851578], 
reward next is 0.7916, 
noisyNet noise sample is [array([-0.44621098], dtype=float32), 0.5997791]. 
=============================================
[2019-03-23 09:04:10,264] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 44.83333333333334, 1.0, 2.0, 0.2366562883156189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 256955.601420025, 256955.601420025, 76248.07145167266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5746200.0000, 
sim time next is 5746800.0000, 
raw observation next is [19.76666666666667, 44.66666666666667, 1.0, 2.0, 0.2390566829260998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 259562.586550296, 259562.586550296, 76845.63981501023], 
processed observation next is [0.0, 0.5217391304347826, 0.534848484848485, 0.4466666666666667, 1.0, 1.0, 0.04882085365762474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09613429131492444, 0.09613429131492444, 0.18742838979270787], 
reward next is 0.8126, 
noisyNet noise sample is [array([-1.0946131], dtype=float32), 0.70412356]. 
=============================================
[2019-03-23 09:04:15,135] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0006480e-19 1.0000000e+00 2.6173530e-27 4.5140430e-25 7.1222996e-29], sum to 1.0000
[2019-03-23 09:04:15,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6796
[2019-03-23 09:04:15,153] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.1, 90.0, 1.0, 2.0, 0.2704270258393386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293634.110031416, 293634.1100314162, 95114.70163007456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5889600.0000, 
sim time next is 5890200.0000, 
raw observation next is [16.28333333333333, 88.0, 1.0, 2.0, 0.2834803553319216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307812.1152165395, 307812.1152165392, 95970.07545702365], 
processed observation next is [1.0, 0.17391304347826086, 0.3765151515151514, 0.88, 1.0, 1.0, 0.10435044416490201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11400448711723685, 0.11400448711723674, 0.2340733547732284], 
reward next is 0.7659, 
noisyNet noise sample is [array([1.4439106], dtype=float32), 1.2153534]. 
=============================================
[2019-03-23 09:04:22,838] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2750276e-16 1.0000000e+00 9.7551756e-22 5.2370315e-21 9.5274015e-25], sum to 1.0000
[2019-03-23 09:04:22,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7016
[2019-03-23 09:04:22,851] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 89.5, 1.0, 2.0, 0.3462922666434518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384637.4116694953, 384637.4116694956, 117560.6710494995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5975400.0000, 
sim time next is 5976000.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.3452596873042789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383344.676788314, 383344.6767883142, 117419.8922196493], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 0.9, 1.0, 1.0, 0.18157460913034862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14197950992159777, 0.14197950992159786, 0.28638998102353486], 
reward next is 0.7136, 
noisyNet noise sample is [array([-0.76317024], dtype=float32), 1.2234862]. 
=============================================
[2019-03-23 09:04:22,866] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.674393]
 [62.674393]
 [62.674393]
 [62.674393]
 [62.674393]], R is [[62.76125336]
 [62.84690857]
 [62.93140411]
 [63.0145607 ]
 [63.0949173 ]].
[2019-03-23 09:04:22,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0001750e-16 1.0000000e+00 6.5069239e-24 9.8906699e-22 1.2228893e-25], sum to 1.0000
[2019-03-23 09:04:22,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8263
[2019-03-23 09:04:23,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1231569.283250834 W.
[2019-03-23 09:04:23,004] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 60.0, 1.0, 2.0, 0.5984855659017736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9687597371742659, 6.911199999999999, 6.9112, 77.32844403910838, 1231569.283250834, 1231569.283250834, 269272.6412271776], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6012000.0000, 
sim time next is 6012600.0000, 
raw observation next is [26.0, 61.5, 1.0, 2.0, 0.5622817830555892, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9693714923292354, 6.911412846515438, 6.9112, 77.3284628012399, 1190132.459187091, 1190063.330992916, 264983.4052327426], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.615, 1.0, 1.0, 0.45285222881948645, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9562449890417648, 2.1284651543762578e-05, 0.0, 0.5084288086975726, 0.4407897996989226, 0.44076419666404293, 0.6463009883725429], 
reward next is 0.3526, 
noisyNet noise sample is [array([1.2081609], dtype=float32), 1.4828945]. 
=============================================
[2019-03-23 09:04:26,546] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.6965092e-19 1.0000000e+00 3.6203896e-25 2.2891595e-25 3.0786106e-28], sum to 1.0000
[2019-03-23 09:04:26,552] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-23 09:04:26,556] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.7887595336647338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 869341.4077063374, 869341.4077063374, 161671.9660799584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6108600.0000, 
sim time next is 6109200.0000, 
raw observation next is [23.8, 48.0, 1.0, 2.0, 0.7694260557865182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 848043.0778443447, 848043.0778443447, 159207.9247897657], 
processed observation next is [1.0, 0.7391304347826086, 0.7181818181818183, 0.48, 1.0, 1.0, 0.7117825697331478, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31409002883123877, 0.31409002883123877, 0.38831201168235535], 
reward next is 0.6117, 
noisyNet noise sample is [array([0.52105397], dtype=float32), 0.80963427]. 
=============================================
[2019-03-23 09:04:31,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.9330106e-17 1.0000000e+00 5.6589480e-23 1.3299796e-23 7.3045179e-26], sum to 1.0000
[2019-03-23 09:04:31,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4748
[2019-03-23 09:04:31,409] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 80.0, 1.0, 2.0, 0.2963509934153077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 321792.0930050683, 321792.0930050685, 101864.5587610781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6144000.0000, 
sim time next is 6144600.0000, 
raw observation next is [17.61666666666667, 79.0, 1.0, 2.0, 0.2911164983773168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316106.3804600625, 316106.3804600622, 100654.4384353624], 
processed observation next is [1.0, 0.08695652173913043, 0.4371212121212123, 0.79, 1.0, 1.0, 0.11389562297164597, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11707643720743055, 0.11707643720743044, 0.2454986303301522], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.31322083], dtype=float32), 0.40847674]. 
=============================================
[2019-03-23 09:04:34,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7988623e-15 1.0000000e+00 6.3681386e-22 1.9046884e-21 6.0450446e-25], sum to 1.0000
[2019-03-23 09:04:34,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9709
[2019-03-23 09:04:34,010] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 83.0, 1.0, 2.0, 0.3694428937832023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413769.6284489585, 413769.6284489582, 120880.8145226314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6214800.0000, 
sim time next is 6215400.0000, 
raw observation next is [19.7, 84.0, 1.0, 2.0, 0.3692361831677211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413671.2604859472, 413671.2604859475, 120925.7919278994], 
processed observation next is [1.0, 0.9565217391304348, 0.5318181818181817, 0.84, 1.0, 1.0, 0.21154522895965136, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15321157795775822, 0.15321157795775833, 0.2949409559217058], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.73606557], dtype=float32), -0.9319714]. 
=============================================
[2019-03-23 09:04:37,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9793702e-17 1.0000000e+00 1.7999934e-24 4.3140291e-22 6.7201019e-27], sum to 1.0000
[2019-03-23 09:04:37,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4176
[2019-03-23 09:04:37,648] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 73.66666666666667, 1.0, 2.0, 0.4865633542124346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555097.8028887861, 555097.8028887863, 140087.4278973403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6304800.0000, 
sim time next is 6305400.0000, 
raw observation next is [24.4, 75.0, 1.0, 2.0, 0.4865634296742667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555093.126277018, 555093.1262770178, 140100.7429755303], 
processed observation next is [0.0, 1.0, 0.7454545454545454, 0.75, 1.0, 1.0, 0.3582042870928333, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20559004676926593, 0.20559004676926584, 0.3417091292086105], 
reward next is 0.6583, 
noisyNet noise sample is [array([0.20308611], dtype=float32), 1.6944221]. 
=============================================
[2019-03-23 09:04:39,295] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9556278e-17 1.0000000e+00 2.9158419e-25 7.2332913e-24 3.2330124e-26], sum to 1.0000
[2019-03-23 09:04:39,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7288
[2019-03-23 09:04:39,307] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 87.0, 1.0, 2.0, 0.4752226648918837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542262.5349517616, 542262.5349517616, 138286.3049746159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6330600.0000, 
sim time next is 6331200.0000, 
raw observation next is [22.53333333333333, 87.0, 1.0, 2.0, 0.4778411014963833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545231.0239863064, 545231.0239863064, 138750.6113231829], 
processed observation next is [0.0, 0.2608695652173913, 0.6606060606060605, 0.87, 1.0, 1.0, 0.34730137687047913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20193741629122458, 0.20193741629122458, 0.3384161251784949], 
reward next is 0.6616, 
noisyNet noise sample is [array([0.7518503], dtype=float32), -1.7831426]. 
=============================================
[2019-03-23 09:04:39,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9384543e-17 1.0000000e+00 3.9276197e-24 2.0278529e-23 1.2448698e-25], sum to 1.0000
[2019-03-23 09:04:39,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4029
[2019-03-23 09:04:39,773] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 63.0, 1.0, 2.0, 0.5566576726741328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 631169.8408765283, 631169.8408765281, 151464.6630192412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6363000.0000, 
sim time next is 6363600.0000, 
raw observation next is [28.1, 62.33333333333333, 1.0, 2.0, 0.5550341871386186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 629433.2856455931, 629433.2856455933, 151212.7632846793], 
processed observation next is [0.0, 0.6521739130434783, 0.9136363636363637, 0.6233333333333333, 1.0, 1.0, 0.44379273392327323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23312343912799743, 0.23312343912799752, 0.3688116177675105], 
reward next is 0.6312, 
noisyNet noise sample is [array([1.2205652], dtype=float32), -0.31396303]. 
=============================================
[2019-03-23 09:04:46,213] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5122289e-17 1.0000000e+00 3.9037334e-25 4.8585899e-25 5.8960859e-29], sum to 1.0000
[2019-03-23 09:04:46,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5274
[2019-03-23 09:04:46,224] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 77.5, 1.0, 2.0, 0.2096920975652179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 227671.6913925117, 227671.691392512, 73716.60724919777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6483000.0000, 
sim time next is 6483600.0000, 
raw observation next is [15.0, 77.0, 1.0, 2.0, 0.2089846072095739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 226903.3596417985, 226903.3596417988, 73502.7778649017], 
processed observation next is [1.0, 0.043478260869565216, 0.3181818181818182, 0.77, 1.0, 1.0, 0.011230759011967364, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08403828134881426, 0.08403828134881437, 0.17927506796317488], 
reward next is 0.8207, 
noisyNet noise sample is [array([1.5269433], dtype=float32), 0.17864464]. 
=============================================
[2019-03-23 09:04:48,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2851057e-19 1.0000000e+00 3.9605632e-27 1.5501945e-24 2.1484707e-28], sum to 1.0000
[2019-03-23 09:04:48,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8385
[2019-03-23 09:04:48,178] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.7, 86.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 204954.198409153, 204954.1984091528, 68135.9823536559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6497400.0000, 
sim time next is 6498000.0000, 
raw observation next is [12.7, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 201621.741473303, 201621.7414733028, 67489.94097986154], 
processed observation next is [1.0, 0.21739130434782608, 0.2136363636363636, 0.86, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0746747190641863, 0.07467471906418623, 0.16460961214600375], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54152185], dtype=float32), -0.47008297]. 
=============================================
[2019-03-23 09:04:48,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.96603]
 [72.96603]
 [72.96603]
 [72.96603]
 [72.96603]], R is [[72.23636627]
 [71.51399994]
 [70.79885864]
 [70.09087372]
 [69.38996887]].
[2019-03-23 09:04:48,600] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.1965819e-18 1.0000000e+00 3.6636210e-27 1.2584353e-24 9.5473192e-29], sum to 1.0000
[2019-03-23 09:04:48,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8730
[2019-03-23 09:04:48,620] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.86666666666667, 76.16666666666667, 1.0, 2.0, 0.2313265723437689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251167.2321622811, 251167.2321622813, 77985.92676397352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [16.23333333333333, 74.33333333333334, 1.0, 2.0, 0.3047623738166435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330928.6801185993, 330928.6801185996, 85953.0659444408], 
processed observation next is [1.0, 0.34782608695652173, 0.3742424242424241, 0.7433333333333334, 1.0, 1.0, 0.13095296727080435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12256617782170345, 0.12256617782170356, 0.20964162425473365], 
reward next is 0.7904, 
noisyNet noise sample is [array([-0.21209615], dtype=float32), 1.0088165]. 
=============================================
[2019-03-23 09:04:48,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.57753]
 [73.57753]
 [73.57753]
 [73.57753]
 [73.57753]], R is [[73.63211823]
 [73.70558929]
 [73.78360748]
 [73.86380005]
 [73.94480133]].
[2019-03-23 09:04:54,698] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 09:04:54,698] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:04:54,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:54,699] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:04:54,701] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:54,703] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:04:54,704] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:04:54,704] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:54,704] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:04:54,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:54,706] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:04:54,725] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 09:04:54,750] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 09:04:54,772] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 09:04:54,773] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 09:04:54,821] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 09:05:04,579] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4797683]
[2019-03-23 09:05:04,580] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.33333333333334, 52.66666666666667, 1.0, 2.0, 0.3621480520857626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404852.1033700682, 404852.1033700685, 119929.474359164]
[2019-03-23 09:05:04,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:05:04,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9237653e-17 1.0000000e+00 1.1310876e-24 1.0130503e-23 7.0737042e-27], sampled 0.1958173172630907
[2019-03-23 09:05:29,637] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4797683]
[2019-03-23 09:05:29,640] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.21666666666667, 78.0, 1.0, 2.0, 0.3516793525754138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 392535.0661768382, 392535.0661768382, 123120.568244616]
[2019-03-23 09:05:29,640] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:05:29,644] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9237653e-17 1.0000000e+00 1.1310876e-24 1.0130503e-23 7.0737042e-27], sampled 0.7654809332651481
[2019-03-23 09:05:39,828] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4797683]
[2019-03-23 09:05:39,832] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 88.0, 1.0, 2.0, 0.2316225571566402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 251488.6863958585, 251488.6863958585, 80164.03905036951]
[2019-03-23 09:05:39,833] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:05:39,836] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.9237653e-17 1.0000000e+00 1.1310876e-24 1.0130503e-23 7.0737042e-27], sampled 0.8283436638094631
[2019-03-23 09:06:16,860] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4797683]
[2019-03-23 09:06:16,862] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.68565864666667, 64.19034344333333, 1.0, 2.0, 0.4213489572243028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 472047.7013532628, 472047.7013532628, 129788.535008969]
[2019-03-23 09:06:16,865] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:06:16,867] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.9237653e-17 1.0000000e+00 1.1310876e-24 1.0130503e-23 7.0737042e-27], sampled 0.12157519528730376
[2019-03-23 09:06:23,912] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4797683]
[2019-03-23 09:06:23,912] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.85, 86.0, 1.0, 2.0, 0.9091915734601645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1033600.685674299, 1033600.685674299, 209922.0821356233]
[2019-03-23 09:06:23,916] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:06:23,919] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9237653e-17 1.0000000e+00 1.1310876e-24 1.0130503e-23 7.0737042e-27], sampled 0.22235222642661656
[2019-03-23 09:06:28,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4797683]
[2019-03-23 09:06:28,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.95, 89.0, 1.0, 2.0, 0.4779838498411969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 545343.354153567, 545343.3541535666, 142453.1774672053]
[2019-03-23 09:06:28,138] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:06:28,141] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.9237653e-17 1.0000000e+00 1.1310876e-24 1.0130503e-23 7.0737042e-27], sampled 0.12821382496524247
[2019-03-23 09:06:36,393] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:06:36,512] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:06:36,593] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:06:36,628] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:06:36,732] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:06:37,745] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1025000, evaluation results [1025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:06:45,422] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6377638e-17 1.0000000e+00 1.1651633e-25 3.1179516e-23 8.5883607e-26], sum to 1.0000
[2019-03-23 09:06:45,426] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9632
[2019-03-23 09:06:45,432] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.5, 1.0, 2.0, 0.4039127999122641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 457033.8553883689, 457033.8553883686, 126274.767800558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6813000.0000, 
sim time next is 6813600.0000, 
raw observation next is [22.7, 69.0, 1.0, 2.0, 0.4021821297798428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454801.1626765824, 454801.1626765827, 125946.167351568], 
processed observation next is [1.0, 0.8695652173913043, 0.6681818181818181, 0.69, 1.0, 1.0, 0.2527276622248035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1684448750654009, 0.168444875065401, 0.3071857740282146], 
reward next is 0.6928, 
noisyNet noise sample is [array([0.655746], dtype=float32), 0.26784483]. 
=============================================
[2019-03-23 09:06:48,914] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8717237e-17 1.0000000e+00 2.3185756e-24 3.7680061e-22 3.9799361e-26], sum to 1.0000
[2019-03-23 09:06:48,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9827
[2019-03-23 09:06:48,928] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 90.0, 1.0, 2.0, 0.3529567390262237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 392500.4300626648, 392500.4300626646, 118274.4092657538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6839400.0000, 
sim time next is 6840000.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.3501396307889356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 388883.6315345434, 388883.6315345431, 117850.5372294501], 
processed observation next is [0.0, 0.17391304347826086, 0.4681818181818182, 0.9, 1.0, 1.0, 0.1876745384861695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14403097464242348, 0.14403097464242337, 0.28744033470597585], 
reward next is 0.7126, 
noisyNet noise sample is [array([0.6823947], dtype=float32), -1.0276792]. 
=============================================
[2019-03-23 09:06:48,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.54693]
 [68.54693]
 [68.54693]
 [68.54693]
 [68.54693]], R is [[68.57402039]
 [68.59980774]
 [68.62426758]
 [68.64735413]
 [68.66902924]].
[2019-03-23 09:06:50,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5705745e-16 1.0000000e+00 1.8655393e-23 1.4533062e-21 1.0864163e-25], sum to 1.0000
[2019-03-23 09:06:50,495] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5361
[2019-03-23 09:06:50,500] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 50.66666666666667, 1.0, 2.0, 0.4390606965433383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 500302.7274022779, 500302.7274022776, 132473.6095330245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6888000.0000, 
sim time next is 6888600.0000, 
raw observation next is [27.45, 51.5, 1.0, 2.0, 0.4414883443326786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 503197.8019844111, 503197.8019844108, 132901.1039938683], 
processed observation next is [0.0, 0.7391304347826086, 0.884090909090909, 0.515, 1.0, 1.0, 0.3018604304158482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18636955629052263, 0.18636955629052251, 0.3241490341313861], 
reward next is 0.6759, 
noisyNet noise sample is [array([0.14567101], dtype=float32), 2.325187]. 
=============================================
[2019-03-23 09:07:00,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7578240e-17 1.0000000e+00 1.3225872e-24 3.0267410e-23 1.5906708e-25], sum to 1.0000
[2019-03-23 09:07:00,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5319
[2019-03-23 09:07:00,079] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3529386959973586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392929.1302116007, 392929.1302116007, 118462.4390451685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7090200.0000, 
sim time next is 7090800.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3518750695451879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391742.7350336031, 391742.7350336034, 118376.8984243431], 
processed observation next is [1.0, 0.043478260869565216, 0.44090909090909086, 0.97, 1.0, 1.0, 0.18984383693148482, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14508990186429743, 0.14508990186429754, 0.28872414249839784], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.1619964], dtype=float32), -1.0737154]. 
=============================================
[2019-03-23 09:07:03,294] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5252389e-16 1.0000000e+00 5.2739923e-24 9.2982542e-25 1.3521024e-26], sum to 1.0000
[2019-03-23 09:07:03,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9338
[2019-03-23 09:07:03,305] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.25, 81.16666666666667, 1.0, 2.0, 0.2034577860410507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220901.2953073437, 220901.2953073434, 72303.91293998313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7177800.0000, 
sim time next is 7178400.0000, 
raw observation next is [14.1, 82.0, 1.0, 2.0, 0.2013972326395417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218663.5769246769, 218663.5769246772, 71970.20524146855], 
processed observation next is [1.0, 0.08695652173913043, 0.2772727272727273, 0.82, 1.0, 1.0, 0.0017465407994271195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08098650997210255, 0.08098650997210267, 0.17553708595480133], 
reward next is 0.8245, 
noisyNet noise sample is [array([-0.6437525], dtype=float32), -0.09158091]. 
=============================================
[2019-03-23 09:07:03,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4761537e-20 1.0000000e+00 6.2562024e-28 2.8593573e-25 1.6113467e-29], sum to 1.0000
[2019-03-23 09:07:03,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2720
[2019-03-23 09:07:03,547] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.8, 70.0, 1.0, 2.0, 0.2369399373775547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 257263.6620763142, 257263.6620763145, 79383.76766861684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7166400.0000, 
sim time next is 7167000.0000, 
raw observation next is [16.7, 70.0, 1.0, 2.0, 0.2351140444747502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255280.6313778691, 255280.6313778688, 78806.1039423071], 
processed observation next is [1.0, 0.9565217391304348, 0.39545454545454545, 0.7, 1.0, 1.0, 0.04389255559343774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09454838199180338, 0.09454838199180325, 0.19221000961538318], 
reward next is 0.8078, 
noisyNet noise sample is [array([-0.49335703], dtype=float32), -0.17338386]. 
=============================================
[2019-03-23 09:07:03,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.411026]
 [70.411026]
 [70.411026]
 [70.411026]
 [70.411026]], R is [[70.51470947]
 [70.61594391]
 [70.71466064]
 [70.81069946]
 [70.90368652]].
[2019-03-23 09:07:13,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9771161e-17 1.0000000e+00 6.0412176e-25 2.1752046e-22 2.7795125e-27], sum to 1.0000
[2019-03-23 09:07:13,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-23 09:07:13,086] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 50.83333333333334, 1.0, 2.0, 0.3375019180883098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372081.0086395355, 372081.0086395358, 115767.0609762941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7326600.0000, 
sim time next is 7327200.0000, 
raw observation next is [23.43333333333334, 51.66666666666667, 1.0, 2.0, 0.33555306800632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369795.3191392713, 369795.3191392713, 115569.1403332706], 
processed observation next is [1.0, 0.8260869565217391, 0.7015151515151519, 0.5166666666666667, 1.0, 1.0, 0.16944133500789998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1369612293108412, 0.1369612293108412, 0.2818759520323673], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.7121944], dtype=float32), 1.8518629]. 
=============================================
[2019-03-23 09:07:18,715] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.12216579e-16 1.00000000e+00 1.06464742e-25 1.02469466e-23
 1.25924071e-26], sum to 1.0000
[2019-03-23 09:07:18,727] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0666
[2019-03-23 09:07:18,733] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3393626129807908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 374165.9413086928, 374165.9413086925, 115919.3836371882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7440600.0000, 
sim time next is 7441200.0000, 
raw observation next is [17.2, 96.0, 1.0, 2.0, 0.3395223638903103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374341.7184020106, 374341.7184020106, 115931.2477452976], 
processed observation next is [0.0, 0.13043478260869565, 0.41818181818181815, 0.96, 1.0, 1.0, 0.17440295486288787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13864508088963357, 0.13864508088963357, 0.2827591408421893], 
reward next is 0.7172, 
noisyNet noise sample is [array([0.16028005], dtype=float32), -0.89120716]. 
=============================================
[2019-03-23 09:07:23,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4441847e-18 1.0000000e+00 6.8413900e-26 7.5133420e-25 1.4428772e-28], sum to 1.0000
[2019-03-23 09:07:23,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9987
[2019-03-23 09:07:23,688] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 84.66666666666666, 1.0, 2.0, 0.4645670242969571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529972.7370450175, 529972.7370450175, 136203.8193842671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7522800.0000, 
sim time next is 7523400.0000, 
raw observation next is [22.2, 85.33333333333334, 1.0, 2.0, 0.4636382518621056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528904.5795342015, 528904.5795342015, 136080.0168502551], 
processed observation next is [0.0, 0.043478260869565216, 0.6454545454545454, 0.8533333333333334, 1.0, 1.0, 0.32954781482763196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19589058501266723, 0.19589058501266723, 0.33190248012257345], 
reward next is 0.6681, 
noisyNet noise sample is [array([-0.10510501], dtype=float32), 1.4933789]. 
=============================================
[2019-03-23 09:07:25,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8815652e-17 1.0000000e+00 9.2808239e-24 9.1292777e-23 4.2666568e-26], sum to 1.0000
[2019-03-23 09:07:25,073] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7768
[2019-03-23 09:07:25,077] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 53.5, 1.0, 2.0, 0.4839869728450779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 552254.1875012004, 552254.1875012004, 139400.9191811579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7576200.0000, 
sim time next is 7576800.0000, 
raw observation next is [27.73333333333333, 54.33333333333333, 1.0, 2.0, 0.48075579710067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548582.3700444466, 548582.3700444466, 138868.5784635812], 
processed observation next is [0.0, 0.6956521739130435, 0.8969696969696969, 0.5433333333333333, 1.0, 1.0, 0.3509447463758375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20317865557201725, 0.20317865557201725, 0.33870384991117364], 
reward next is 0.6613, 
noisyNet noise sample is [array([0.8209347], dtype=float32), -0.49738315]. 
=============================================
[2019-03-23 09:07:25,792] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 09:07:25,794] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:07:25,795] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:25,796] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:07:25,798] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:25,798] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:07:25,799] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:25,799] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:07:25,800] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:07:25,801] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:25,801] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:07:25,823] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 09:07:25,847] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 09:07:25,874] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 09:07:25,896] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 09:07:25,919] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 09:07:56,796] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4471114]
[2019-03-23 09:07:56,798] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.77371476666667, 77.568876995, 1.0, 2.0, 0.3720161593212972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 417180.9728873696, 417180.9728873693, 125669.8627261728]
[2019-03-23 09:07:56,802] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:07:56,806] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3051536e-16 1.0000000e+00 2.9819535e-23 2.1488624e-22 2.4432760e-25], sampled 0.6885839525572431
[2019-03-23 09:08:40,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4471114]
[2019-03-23 09:08:40,900] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.96666666666667, 51.83333333333334, 1.0, 2.0, 0.4858064324082091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 554248.998298397, 554248.9982983967, 143186.9266127788]
[2019-03-23 09:08:40,901] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:08:40,904] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3051536e-16 1.0000000e+00 2.9819535e-23 2.1488624e-22 2.4432760e-25], sampled 0.7169275336935554
[2019-03-23 09:08:56,315] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4471114]
[2019-03-23 09:08:56,317] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.61427044, 86.60781694666667, 1.0, 2.0, 0.317070506111247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 344787.2999798676, 344787.2999798676, 116834.8668565768]
[2019-03-23 09:08:56,318] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:08:56,320] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3051536e-16 1.0000000e+00 2.9819535e-23 2.1488624e-22 2.4432760e-25], sampled 0.3424811186712383
[2019-03-23 09:09:07,705] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:09:07,720] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:09:07,991] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:09:08,111] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:09:08,113] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:09:09,127] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1050000, evaluation results [1050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:09:11,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0897109e-16 1.0000000e+00 2.7670558e-23 4.8067789e-21 1.0131425e-24], sum to 1.0000
[2019-03-23 09:09:11,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-23 09:09:11,139] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 91.0, 1.0, 2.0, 0.4950602386115943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564907.62761187, 564907.62761187, 140573.3972594918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7583400.0000, 
sim time next is 7584000.0000, 
raw observation next is [21.56666666666667, 91.0, 1.0, 2.0, 0.4851597577378554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 553576.3664824173, 553576.3664824171, 138835.3771851413], 
processed observation next is [0.0, 0.782608695652174, 0.6166666666666668, 0.91, 1.0, 1.0, 0.3564496971723192, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2050282838823768, 0.2050282838823767, 0.33862287118327145], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.62785304], dtype=float32), -0.012454965]. 
=============================================
[2019-03-23 09:09:11,153] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.39323]
 [65.39323]
 [65.39323]
 [65.39323]
 [65.39323]], R is [[65.40067291]
 [65.40380096]
 [65.40291595]
 [65.39844513]
 [65.3919754 ]].
[2019-03-23 09:09:15,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1759466e-18 1.0000000e+00 3.4148328e-26 1.2199872e-24 1.9742429e-27], sum to 1.0000
[2019-03-23 09:09:15,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9102
[2019-03-23 09:09:15,589] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.351498519588883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391273.9124199155, 391273.9124199152, 118325.9488404835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7711200.0000, 
sim time next is 7711800.0000, 
raw observation next is [17.61666666666667, 96.83333333333334, 1.0, 2.0, 0.3734280505161777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 415332.7577665207, 415332.7577665207, 119950.142007505], 
processed observation next is [1.0, 0.2608695652173913, 0.4371212121212123, 0.9683333333333334, 1.0, 1.0, 0.21678506314522214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1538269473209336, 0.1538269473209336, 0.2925613219695244], 
reward next is 0.7074, 
noisyNet noise sample is [array([-2.859924], dtype=float32), -1.0351368]. 
=============================================
[2019-03-23 09:09:19,366] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:19,366] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:19,398] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 09:09:24,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5363887e-17 1.0000000e+00 3.9903210e-25 2.5381956e-23 2.4995463e-26], sum to 1.0000
[2019-03-23 09:09:24,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0419
[2019-03-23 09:09:24,936] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 67.0, 1.0, 2.0, 0.3039404171940671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 330035.8490276772, 330035.8490276775, 111457.6238579082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7876800.0000, 
sim time next is 7877400.0000, 
raw observation next is [19.9, 68.0, 1.0, 2.0, 0.3227009948749562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350542.7580171526, 350542.7580171529, 112785.5744589098], 
processed observation next is [1.0, 0.17391304347826086, 0.5409090909090909, 0.68, 1.0, 1.0, 0.1533762435936952, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12983065111746392, 0.12983065111746403, 0.27508676697295076], 
reward next is 0.7249, 
noisyNet noise sample is [array([-0.530856], dtype=float32), 0.16859894]. 
=============================================
[2019-03-23 09:09:27,348] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:27,349] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:27,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:27,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:27,382] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 09:09:27,453] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 09:09:27,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3135151e-15 1.0000000e+00 2.2779867e-22 3.3415316e-21 1.4470426e-23], sum to 1.0000
[2019-03-23 09:09:27,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8922
[2019-03-23 09:09:27,732] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 79.5, 1.0, 2.0, 0.3364177068271973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370945.6715920239, 370945.6715920242, 115708.5361232433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7947000.0000, 
sim time next is 7947600.0000, 
raw observation next is [19.0, 79.0, 1.0, 2.0, 0.3303783341629866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363272.1848208921, 363272.1848208921, 114874.7233844291], 
processed observation next is [1.0, 1.0, 0.5, 0.79, 1.0, 1.0, 0.16297291770373326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13454525363736744, 0.13454525363736744, 0.28018225215714415], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.24395625], dtype=float32), -2.2539628]. 
=============================================
[2019-03-23 09:09:27,738] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1059893: loss 0.1834
[2019-03-23 09:09:27,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1059895: learning rate 0.0010
[2019-03-23 09:09:27,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:27,881] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:27,891] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 09:09:28,124] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:28,124] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:28,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:28,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:28,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 09:09:28,168] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 09:09:28,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:28,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:28,389] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 09:09:28,441] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:28,441] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:28,446] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 09:09:28,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:28,786] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:28,791] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 09:09:28,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:28,971] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:28,977] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 09:09:29,003] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:29,006] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:29,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:29,007] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:29,019] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 09:09:29,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:29,054] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:29,057] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 09:09:29,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:29,123] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:29,125] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 09:09:29,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 09:09:29,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:29,291] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:29,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 09:09:29,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:09:29,621] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:29,624] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 09:09:34,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1691494e-19 1.0000000e+00 1.4748708e-27 9.3189864e-26 1.1379356e-29], sum to 1.0000
[2019-03-23 09:09:34,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6101
[2019-03-23 09:09:34,721] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 46.0, 1.0, 2.0, 0.5650249047042086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613715.2275185897, 613715.2275185897, 117693.7134728364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 129600.0000, 
sim time next is 130200.0000, 
raw observation next is [21.16666666666667, 46.0, 1.0, 2.0, 0.5361207434845346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582301.479107803, 582301.479107803, 115138.4907082736], 
processed observation next is [1.0, 0.5217391304347826, 0.5984848484848487, 0.46, 1.0, 1.0, 0.4201509293556683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21566721448437146, 0.21566721448437146, 0.28082558709335026], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.1245446], dtype=float32), -0.3815818]. 
=============================================
[2019-03-23 09:09:36,047] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1063585: loss 0.0737
[2019-03-23 09:09:36,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1063585: learning rate 0.0010
[2019-03-23 09:09:36,236] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1063678: loss 0.0412
[2019-03-23 09:09:36,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1063680: learning rate 0.0010
[2019-03-23 09:09:37,040] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064084: loss 0.0854
[2019-03-23 09:09:37,042] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064084: learning rate 0.0010
[2019-03-23 09:09:37,225] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064179: loss 0.0428
[2019-03-23 09:09:37,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064179: learning rate 0.0010
[2019-03-23 09:09:37,272] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064196: loss 0.0480
[2019-03-23 09:09:37,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064196: learning rate 0.0010
[2019-03-23 09:09:37,304] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064213: loss 0.0616
[2019-03-23 09:09:37,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064214: learning rate 0.0010
[2019-03-23 09:09:37,397] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064261: loss 0.0566
[2019-03-23 09:09:37,399] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064262: learning rate 0.0010
[2019-03-23 09:09:37,583] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064352: loss 0.0563
[2019-03-23 09:09:37,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064355: learning rate 0.0010
[2019-03-23 09:09:38,132] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064627: loss 0.0327
[2019-03-23 09:09:38,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064628: learning rate 0.0010
[2019-03-23 09:09:38,190] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1064657: loss 0.0461
[2019-03-23 09:09:38,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1064657: learning rate 0.0010
[2019-03-23 09:09:38,236] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064680: loss 0.0445
[2019-03-23 09:09:38,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064680: learning rate 0.0010
[2019-03-23 09:09:38,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064701: loss 0.0250
[2019-03-23 09:09:38,284] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064702: learning rate 0.0010
[2019-03-23 09:09:38,527] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064819: loss 0.0074
[2019-03-23 09:09:38,530] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064821: learning rate 0.0010
[2019-03-23 09:09:38,767] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064941: loss 0.0025
[2019-03-23 09:09:38,777] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064941: learning rate 0.0010
[2019-03-23 09:09:38,822] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064968: loss 0.0013
[2019-03-23 09:09:38,823] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064968: learning rate 0.0010
[2019-03-23 09:09:39,342] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0444220e-17 1.0000000e+00 3.2185185e-25 1.2439068e-24 2.6475491e-27], sum to 1.0000
[2019-03-23 09:09:39,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3643
[2019-03-23 09:09:39,352] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 72.83333333333333, 1.0, 2.0, 0.2301865061602909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249929.065547906, 249929.0655479063, 76610.74501965156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 166200.0000, 
sim time next is 166800.0000, 
raw observation next is [15.66666666666667, 73.66666666666667, 1.0, 2.0, 0.2277916466247236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247328.1433703965, 247328.1433703962, 76174.38677514039], 
processed observation next is [1.0, 0.9565217391304348, 0.3484848484848486, 0.7366666666666667, 1.0, 1.0, 0.03473955828090448, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0916030160631098, 0.09160301606310971, 0.18579118725643998], 
reward next is 0.8142, 
noisyNet noise sample is [array([2.0779958], dtype=float32), 0.04294294]. 
=============================================
[2019-03-23 09:09:40,618] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1065880: loss 0.0081
[2019-03-23 09:09:40,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1065880: learning rate 0.0010
[2019-03-23 09:09:43,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5976408e-19 1.0000000e+00 9.7070838e-26 2.9824039e-26 1.3795158e-28], sum to 1.0000
[2019-03-23 09:09:43,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5161
[2019-03-23 09:09:43,155] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 92.00000000000001, 1.0, 2.0, 0.2288371706699391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248463.6264913591, 248463.6264913594, 83416.57125840562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 288600.0000, 
sim time next is 289200.0000, 
raw observation next is [15.33333333333334, 90.0, 1.0, 2.0, 0.2286529506899946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 248263.555646622, 248263.5556466223, 83086.90606624982], 
processed observation next is [0.0, 0.34782608695652173, 0.3333333333333336, 0.9, 1.0, 1.0, 0.03581618836249325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09194946505430444, 0.09194946505430455, 0.20265099040548737], 
reward next is 0.7973, 
noisyNet noise sample is [array([-0.3653905], dtype=float32), -1.6782696]. 
=============================================
[2019-03-23 09:09:46,154] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5542576e-18 1.0000000e+00 8.0979624e-25 3.2876996e-25 3.7418108e-28], sum to 1.0000
[2019-03-23 09:09:46,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0809
[2019-03-23 09:09:46,165] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 41.33333333333334, 1.0, 2.0, 0.2761803158064278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299883.0528836349, 299883.0528836349, 89969.1218817681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 317400.0000, 
sim time next is 318000.0000, 
raw observation next is [22.33333333333334, 41.66666666666667, 1.0, 2.0, 0.2735728022063413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297050.8888861133, 297050.8888861136, 88080.07464487173], 
processed observation next is [0.0, 0.6956521739130435, 0.6515151515151518, 0.41666666666666674, 1.0, 1.0, 0.09196600275792659, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11001884773559752, 0.11001884773559763, 0.21482945035334566], 
reward next is 0.7852, 
noisyNet noise sample is [array([-0.11278562], dtype=float32), -0.97925085]. 
=============================================
[2019-03-23 09:09:46,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[77.877884]
 [77.877884]
 [77.877884]
 [77.877884]
 [77.877884]], R is [[77.88427734]
 [77.88600159]
 [77.88299561]
 [77.88231659]
 [77.88387299]].
[2019-03-23 09:09:51,877] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1071585: loss 0.0009
[2019-03-23 09:09:51,879] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1071586: learning rate 0.0010
[2019-03-23 09:09:51,986] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1071642: loss 0.0010
[2019-03-23 09:09:51,988] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1071642: learning rate 0.0010
[2019-03-23 09:09:52,707] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072013: loss 0.0003
[2019-03-23 09:09:52,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072014: learning rate 0.0010
[2019-03-23 09:09:53,040] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072180: loss 0.0109
[2019-03-23 09:09:53,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072184: learning rate 0.0010
[2019-03-23 09:09:53,078] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072200: loss 0.0085
[2019-03-23 09:09:53,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072200: learning rate 0.0010
[2019-03-23 09:09:53,154] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072234: loss 0.0071
[2019-03-23 09:09:53,157] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072234: learning rate 0.0010
[2019-03-23 09:09:53,216] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072271: loss 0.0116
[2019-03-23 09:09:53,218] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072271: learning rate 0.0010
[2019-03-23 09:09:53,339] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072333: loss 0.0173
[2019-03-23 09:09:53,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072333: learning rate 0.0010
[2019-03-23 09:09:53,930] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072631: loss 0.0003
[2019-03-23 09:09:53,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072632: learning rate 0.0010
[2019-03-23 09:09:53,945] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072640: loss 0.0019
[2019-03-23 09:09:53,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072640: learning rate 0.0010
[2019-03-23 09:09:54,015] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072670: loss 0.0023
[2019-03-23 09:09:54,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072670: learning rate 0.0010
[2019-03-23 09:09:54,120] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1072728: loss 0.0012
[2019-03-23 09:09:54,123] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1072728: learning rate 0.0010
[2019-03-23 09:09:54,367] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072845: loss 0.0010
[2019-03-23 09:09:54,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072845: learning rate 0.0010
[2019-03-23 09:09:54,497] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072911: loss 0.0038
[2019-03-23 09:09:54,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072911: learning rate 0.0010
[2019-03-23 09:09:54,677] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1073004: loss 0.0003
[2019-03-23 09:09:54,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1073004: learning rate 0.0010
[2019-03-23 09:09:56,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6017243e-19 1.0000000e+00 4.7567139e-26 1.6679374e-25 7.5874929e-29], sum to 1.0000
[2019-03-23 09:09:56,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4925
[2019-03-23 09:09:56,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2771369400343586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300922.0992305593, 300922.099230559, 91809.17160593925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 497400.0000, 
sim time next is 498000.0000, 
raw observation next is [15.66666666666667, 90.0, 1.0, 2.0, 0.2744412541140082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297994.1604571152, 297994.1604571149, 90970.34847804789], 
processed observation next is [1.0, 0.782608695652174, 0.3484848484848486, 0.9, 1.0, 1.0, 0.09305156764251026, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11036820757670934, 0.11036820757670923, 0.22187889872694608], 
reward next is 0.7781, 
noisyNet noise sample is [array([1.096446], dtype=float32), 1.4593071]. 
=============================================
[2019-03-23 09:09:56,161] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.616]
 [77.616]
 [77.616]
 [77.616]
 [77.616]], R is [[77.61795807]
 [77.61785889]
 [77.6159668 ]
 [77.61402893]
 [77.61183167]].
[2019-03-23 09:09:56,756] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1074061: loss 0.5492
[2019-03-23 09:09:56,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1074062: learning rate 0.0010
[2019-03-23 09:09:57,900] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6661429e-19 1.0000000e+00 3.2075927e-28 1.6248858e-26 1.7519184e-29], sum to 1.0000
[2019-03-23 09:09:57,905] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6463
[2019-03-23 09:09:57,910] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2229732166457651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242095.1598568237, 242095.1598568234, 78530.87562635085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 542400.0000, 
sim time next is 543000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2015758133604072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218857.5114871263, 218857.5114871266, 75505.5842151246], 
processed observation next is [1.0, 0.2608695652173913, 0.2727272727272727, 0.94, 1.0, 1.0, 0.001969766700508982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08105833758782455, 0.08105833758782467, 0.18415996150030392], 
reward next is 0.8158, 
noisyNet noise sample is [array([-0.77405435], dtype=float32), 2.541377]. 
=============================================
[2019-03-23 09:09:57,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[78.61328]
 [78.61328]
 [78.61328]
 [78.61328]
 [78.61328]], R is [[78.64299011]
 [78.6650238 ]
 [78.66060638]
 [78.62854004]
 [78.57730103]].
[2019-03-23 09:09:57,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6011486e-18 1.0000000e+00 4.6895978e-27 3.5742936e-26 4.9037310e-30], sum to 1.0000
[2019-03-23 09:09:57,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0472
[2019-03-23 09:09:57,969] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2138965708898807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 232237.7579670328, 232237.7579670328, 76616.4481239043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531000.0000, 
sim time next is 531600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2128959175531676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231151.042523119, 231151.0425231193, 76493.48431687053], 
processed observation next is [1.0, 0.13043478260869565, 0.2727272727272727, 0.94, 1.0, 1.0, 0.016119896941459502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08561149723078482, 0.08561149723078493, 0.18656947394358664], 
reward next is 0.8134, 
noisyNet noise sample is [array([-0.359196], dtype=float32), 3.74793]. 
=============================================
[2019-03-23 09:09:58,626] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 09:09:58,628] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:09:58,628] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:58,629] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:09:58,629] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:58,630] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:09:58,631] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:58,632] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:09:58,632] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:58,632] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:09:58,632] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:09:58,651] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 09:09:58,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 09:09:58,699] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 09:09:58,723] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 09:09:58,748] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 09:10:07,608] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44947603]
[2019-03-23 09:10:07,609] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 83.0, 1.0, 2.0, 0.3053011844579351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 332273.9157875156, 332273.9157875153, 111814.7644030474]
[2019-03-23 09:10:07,612] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:10:07,614] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7040887e-17 1.0000000e+00 8.0604244e-25 6.1942352e-24 4.4998718e-27], sampled 0.41864149346610857
[2019-03-23 09:10:40,870] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44947603]
[2019-03-23 09:10:40,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.33333333333334, 77.0, 1.0, 2.0, 0.5578802341351622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 633590.8453979105, 633590.8453979102, 151180.1795388743]
[2019-03-23 09:10:40,873] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:10:40,876] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7040887e-17 1.0000000e+00 8.0604244e-25 6.1942352e-24 4.4998718e-27], sampled 0.13193490853567424
[2019-03-23 09:10:57,629] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44947603]
[2019-03-23 09:10:57,630] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.31332647, 93.12476678499999, 1.0, 2.0, 0.3931847560129175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 444196.0342643949, 444196.0342643949, 129195.3825308966]
[2019-03-23 09:10:57,630] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:10:57,632] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7040887e-17 1.0000000e+00 8.0604244e-25 6.1942352e-24 4.4998718e-27], sampled 0.19584313012590493
[2019-03-23 09:11:32,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44947603]
[2019-03-23 09:11:32,578] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.5, 45.0, 1.0, 2.0, 0.3158687855430411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 342969.8518380201, 342969.8518380205, 102792.3737220165]
[2019-03-23 09:11:32,579] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:11:32,581] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7040887e-17 1.0000000e+00 8.0604244e-25 6.1942352e-24 4.4998718e-27], sampled 0.731806577615248
[2019-03-23 09:11:37,235] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44947603]
[2019-03-23 09:11:37,236] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.0, 48.0, 1.0, 2.0, 0.3628336351406131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 393980.9307667798, 393980.9307667794, 101448.0820709301]
[2019-03-23 09:11:37,238] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:11:37,242] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7040887e-17 1.0000000e+00 8.0604244e-25 6.1942352e-24 4.4998718e-27], sampled 0.3373031964902452
[2019-03-23 09:11:37,736] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.44947603]
[2019-03-23 09:11:37,737] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.9, 65.0, 1.0, 2.0, 0.2536372012908675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 275383.4107199392, 275383.4107199389, 87627.60040283829]
[2019-03-23 09:11:37,738] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:11:37,741] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7040887e-17 1.0000000e+00 8.0604244e-25 6.1942352e-24 4.4998718e-27], sampled 0.8707107596665247
[2019-03-23 09:11:39,891] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:11:39,976] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:11:40,022] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:11:40,026] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:11:40,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:11:41,141] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1075000, evaluation results [1075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:11:44,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0756023e-19 1.0000000e+00 8.6952261e-28 1.2165422e-26 3.2099291e-29], sum to 1.0000
[2019-03-23 09:11:44,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6624
[2019-03-23 09:11:44,741] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 91.0, 1.0, 2.0, 0.2536548773680596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 275417.4789030215, 275417.4789030215, 88046.58776882825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 617400.0000, 
sim time next is 618000.0000, 
raw observation next is [15.33333333333333, 92.0, 1.0, 2.0, 0.2515824231235125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273166.5842026772, 273166.5842026775, 87293.9670408106], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333332, 0.92, 1.0, 1.0, 0.06447802890439058, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10117280896395452, 0.10117280896395463, 0.2129121147336844], 
reward next is 0.7871, 
noisyNet noise sample is [array([-0.21472727], dtype=float32), 0.28473505]. 
=============================================
[2019-03-23 09:11:44,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.742775]
 [75.742775]
 [75.742775]
 [75.742775]
 [75.742775]], R is [[75.77243805]
 [75.79997253]
 [75.82527924]
 [75.84792328]
 [75.86989594]].
[2019-03-23 09:11:48,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1710221e-16 1.0000000e+00 1.4303749e-23 4.2058220e-23 1.6613333e-25], sum to 1.0000
[2019-03-23 09:11:48,185] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9407
[2019-03-23 09:11:48,190] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 56.0, 1.0, 2.0, 0.3492236493022419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 388684.3046509746, 388684.3046509749, 118121.1073178294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 679200.0000, 
sim time next is 679800.0000, 
raw observation next is [23.16666666666667, 56.5, 1.0, 2.0, 0.3471248248355241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385969.9181482865, 385969.9181482865, 117795.481864375], 
processed observation next is [1.0, 0.8695652173913043, 0.6893939393939396, 0.565, 1.0, 1.0, 0.1839060310444051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14295182153640243, 0.14295182153640243, 0.2873060533277439], 
reward next is 0.7127, 
noisyNet noise sample is [array([-0.24447896], dtype=float32), -1.3952008]. 
=============================================
[2019-03-23 09:11:50,148] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1079660: loss 0.0100
[2019-03-23 09:11:50,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1079660: learning rate 0.0010
[2019-03-23 09:11:50,207] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1079686: loss 0.1512
[2019-03-23 09:11:50,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1079687: learning rate 0.0010
[2019-03-23 09:11:50,827] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080015: loss 0.0721
[2019-03-23 09:11:50,828] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080015: learning rate 0.0010
[2019-03-23 09:11:51,141] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080181: loss 0.0618
[2019-03-23 09:11:51,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080181: learning rate 0.0010
[2019-03-23 09:11:51,166] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080190: loss 0.0624
[2019-03-23 09:11:51,168] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080190: learning rate 0.0010
[2019-03-23 09:11:51,255] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080241: loss 0.0873
[2019-03-23 09:11:51,257] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080241: learning rate 0.0010
[2019-03-23 09:11:51,310] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080265: loss 0.0748
[2019-03-23 09:11:51,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080268: learning rate 0.0010
[2019-03-23 09:11:51,617] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080432: loss 0.0702
[2019-03-23 09:11:51,618] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080432: learning rate 0.0010
[2019-03-23 09:11:51,964] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080617: loss 0.0619
[2019-03-23 09:11:51,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080617: learning rate 0.0010
[2019-03-23 09:11:52,007] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080641: loss 0.0589
[2019-03-23 09:11:52,011] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080642: learning rate 0.0010
[2019-03-23 09:11:52,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080780: loss 0.0256
[2019-03-23 09:11:52,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080780: learning rate 0.0010
[2019-03-23 09:11:52,310] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080801: loss 0.0004
[2019-03-23 09:11:52,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080801: learning rate 0.0010
[2019-03-23 09:11:52,334] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1080807: loss 0.0055
[2019-03-23 09:11:52,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1080807: learning rate 0.0010
[2019-03-23 09:11:52,444] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080875: loss 0.0038
[2019-03-23 09:11:52,446] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080877: learning rate 0.0010
[2019-03-23 09:11:52,788] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1081054: loss 0.0035
[2019-03-23 09:11:52,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1081055: learning rate 0.0010
[2019-03-23 09:11:54,323] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5125528e-16 1.0000000e+00 2.2108239e-23 1.0541056e-22 1.4274572e-25], sum to 1.0000
[2019-03-23 09:11:54,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8085
[2019-03-23 09:11:54,333] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3865278008094295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435546.4345235295, 435546.4345235295, 123635.4395580438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 795600.0000, 
sim time next is 796200.0000, 
raw observation next is [19.0, 94.00000000000001, 1.0, 2.0, 0.3863486345789148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435344.8144455772, 435344.8144455772, 123619.7698330344], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.9400000000000002, 1.0, 1.0, 0.23293579322364344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1612388201650286, 0.1612388201650286, 0.3015116337391083], 
reward next is 0.6985, 
noisyNet noise sample is [array([-0.635826], dtype=float32), -0.658312]. 
=============================================
[2019-03-23 09:11:54,426] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1081922: loss 1.1488
[2019-03-23 09:11:54,427] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1081923: learning rate 0.0010
[2019-03-23 09:11:54,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2301443e-16 1.0000000e+00 2.5741947e-24 1.1738922e-21 3.9605371e-25], sum to 1.0000
[2019-03-23 09:11:54,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6485
[2019-03-23 09:11:54,464] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3857514582467097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434671.0595375159, 434671.0595375162, 123566.6399241136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 796800.0000, 
sim time next is 797400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3852390532974909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434092.5405698278, 434092.5405698278, 123520.8714049788], 
processed observation next is [0.0, 0.21739130434782608, 0.5, 0.94, 1.0, 1.0, 0.23154881662186363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16077501502586214, 0.16077501502586214, 0.3012704180609239], 
reward next is 0.6987, 
noisyNet noise sample is [array([-0.5372658], dtype=float32), 1.0757073]. 
=============================================
[2019-03-23 09:11:59,740] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2524982e-15 1.0000000e+00 1.7745445e-22 3.4182694e-21 4.2051118e-25], sum to 1.0000
[2019-03-23 09:11:59,754] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9693
[2019-03-23 09:11:59,761] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 77.0, 1.0, 2.0, 0.482141022460379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550105.1647301076, 550105.1647301076, 139401.2589666729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 904800.0000, 
sim time next is 905400.0000, 
raw observation next is [24.5, 74.0, 1.0, 2.0, 0.4856818304281775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 554119.1458103271, 554119.1458103274, 139903.5195097997], 
processed observation next is [0.0, 0.4782608695652174, 0.75, 0.74, 1.0, 1.0, 0.3571022880352218, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20522931326308413, 0.20522931326308422, 0.3412280963653651], 
reward next is 0.6588, 
noisyNet noise sample is [array([-0.11221756], dtype=float32), 0.8942075]. 
=============================================
[2019-03-23 09:12:00,343] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5039887e-16 1.0000000e+00 9.1520771e-24 6.1282451e-22 9.8073185e-26], sum to 1.0000
[2019-03-23 09:12:00,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8754
[2019-03-23 09:12:00,356] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4140426407735532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 469369.780052537, 469369.780052537, 127787.2413997982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 937800.0000, 
sim time next is 938400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4133659533014566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468601.4986273446, 468601.4986273449, 127722.2545548099], 
processed observation next is [0.0, 0.8695652173913043, 0.5, 1.0, 1.0, 1.0, 0.2667074416268207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17355611060272022, 0.17355611060272033, 0.31151769403612173], 
reward next is 0.6885, 
noisyNet noise sample is [array([1.217816], dtype=float32), 0.92675394]. 
=============================================
[2019-03-23 09:12:01,543] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2560688e-15 1.0000000e+00 3.0956134e-22 9.0373957e-21 4.5446967e-24], sum to 1.0000
[2019-03-23 09:12:01,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8651
[2019-03-23 09:12:01,559] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4037840598119037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457721.0301406559, 457721.0301406559, 126807.5164927755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 964200.0000, 
sim time next is 964800.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4035722058976944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457478.0937093977, 457478.0937093977, 126785.8008715732], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.25446525737211795, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16943633100348063, 0.16943633100348063, 0.3092336606623737], 
reward next is 0.6908, 
noisyNet noise sample is [array([1.0140388], dtype=float32), 0.13472073]. 
=============================================
[2019-03-23 09:12:02,614] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6030778e-17 1.0000000e+00 4.7425705e-23 5.0720673e-23 1.1488853e-26], sum to 1.0000
[2019-03-23 09:12:02,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9594
[2019-03-23 09:12:02,626] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4040093494183495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 458001.9105675718, 458001.910567572, 126846.1318947644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 959400.0000, 
sim time next is 960000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.400181967986472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453634.0124375402, 453634.0124375399, 126469.0468759002], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 1.0, 1.0, 1.0, 0.25022745998308993, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16801259719908898, 0.16801259719908884, 0.30846108994122], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.87888247], dtype=float32), 1.7713363]. 
=============================================
[2019-03-23 09:12:02,638] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.46092]
 [67.46092]
 [67.46092]
 [67.46092]
 [67.46092]], R is [[67.4778595 ]
 [67.49370575]
 [67.50176239]
 [67.49610901]
 [67.51282501]].
[2019-03-23 09:12:03,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5470572e-17 1.0000000e+00 5.4782268e-25 1.8891927e-24 1.1432151e-26], sum to 1.0000
[2019-03-23 09:12:03,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0171844e-17 1.0000000e+00 3.1990333e-24 1.2081733e-23 1.3033874e-27], sum to 1.0000
[2019-03-23 09:12:03,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8610
[2019-03-23 09:12:03,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7110
[2019-03-23 09:12:03,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4743055223745832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515126.0000928305, 515126.0000928305, 107718.6016077012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1011000.0000, 
sim time next is 1011600.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4805942637165215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521959.6404912574, 521959.6404912574, 108365.3801896379], 
processed observation next is [1.0, 0.7391304347826086, 0.2727272727272727, 1.0, 1.0, 1.0, 0.3507428296456518, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1933183853671324, 0.1933183853671324, 0.26430580534058024], 
reward next is 0.7357, 
noisyNet noise sample is [array([-0.9071458], dtype=float32), 0.14363731]. 
=============================================
[2019-03-23 09:12:03,831] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.4893622590020345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531487.5144979542, 531487.5144979545, 109488.8432863826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1009200.0000, 
sim time next is 1009800.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4842278031282397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525908.0581059431, 525908.0581059431, 108840.2288272988], 
processed observation next is [1.0, 0.6956521739130435, 0.2727272727272727, 1.0, 1.0, 1.0, 0.3552847539102996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19478076226146043, 0.19478076226146043, 0.2654639727495092], 
reward next is 0.7345, 
noisyNet noise sample is [array([1.9369444], dtype=float32), 0.30055633]. 
=============================================
[2019-03-23 09:12:04,783] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1087541: loss 1.6900
[2019-03-23 09:12:04,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1087541: learning rate 0.0010
[2019-03-23 09:12:04,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0614700e-18 1.0000000e+00 8.8271078e-27 1.3006583e-23 3.1187407e-28], sum to 1.0000
[2019-03-23 09:12:04,897] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0472
[2019-03-23 09:12:04,900] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 99.00000000000001, 1.0, 2.0, 0.2544552948523932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276286.8159499725, 276286.8159499723, 83346.77965551271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1015800.0000, 
sim time next is 1016400.0000, 
raw observation next is [14.0, 98.0, 1.0, 2.0, 0.2497246155963872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271148.8263791167, 271148.8263791164, 82320.99427396923], 
processed observation next is [1.0, 0.782608695652174, 0.2727272727272727, 0.98, 1.0, 1.0, 0.06215576949548399, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1004254912515247, 0.10042549125152458, 0.2007829128633396], 
reward next is 0.7992, 
noisyNet noise sample is [array([0.42831016], dtype=float32), 0.43255937]. 
=============================================
[2019-03-23 09:12:05,163] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1087735: loss 1.7033
[2019-03-23 09:12:05,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1087735: learning rate 0.0010
[2019-03-23 09:12:05,521] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1087913: loss 1.6880
[2019-03-23 09:12:05,523] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1087913: learning rate 0.0010
[2019-03-23 09:12:05,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9283712e-18 1.0000000e+00 4.1053507e-25 5.8321457e-24 7.3310338e-27], sum to 1.0000
[2019-03-23 09:12:05,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0877
[2019-03-23 09:12:05,553] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 94.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 214758.466735268, 214758.4667352683, 71717.11296587366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1030200.0000, 
sim time next is 1030800.0000, 
raw observation next is [13.0, 94.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211502.767524597, 211502.7675245973, 71156.00197572543], 
processed observation next is [1.0, 0.9565217391304348, 0.22727272727272727, 0.94, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07833435834244333, 0.07833435834244344, 0.17355122433103765], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2588457], dtype=float32), -0.77815855]. 
=============================================
[2019-03-23 09:12:05,857] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088080: loss 1.8405
[2019-03-23 09:12:05,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088082: learning rate 0.0010
[2019-03-23 09:12:05,949] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088124: loss 1.9907
[2019-03-23 09:12:05,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088125: learning rate 0.0010
[2019-03-23 09:12:06,056] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1088175: loss 1.9707
[2019-03-23 09:12:06,057] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1088175: learning rate 0.0010
[2019-03-23 09:12:06,324] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088308: loss 1.6779
[2019-03-23 09:12:06,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088308: learning rate 0.0010
[2019-03-23 09:12:06,450] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088371: loss 1.5512
[2019-03-23 09:12:06,451] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088371: learning rate 0.0010
[2019-03-23 09:12:06,895] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088593: loss 1.2548
[2019-03-23 09:12:06,897] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088593: learning rate 0.0010
[2019-03-23 09:12:07,017] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088658: loss 1.3405
[2019-03-23 09:12:07,019] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088658: learning rate 0.0010
[2019-03-23 09:12:07,253] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1088770: loss 1.2570
[2019-03-23 09:12:07,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1088770: learning rate 0.0010
[2019-03-23 09:12:07,294] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088795: loss 1.4079
[2019-03-23 09:12:07,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088795: learning rate 0.0010
[2019-03-23 09:12:07,360] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088834: loss 1.5099
[2019-03-23 09:12:07,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088834: learning rate 0.0010
[2019-03-23 09:12:07,436] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088865: loss 1.4700
[2019-03-23 09:12:07,438] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088867: learning rate 0.0010
[2019-03-23 09:12:07,813] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1089058: loss 1.3345
[2019-03-23 09:12:07,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1089058: learning rate 0.0010
[2019-03-23 09:12:08,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4642858e-17 1.0000000e+00 5.0131649e-24 1.0477429e-23 7.2732066e-27], sum to 1.0000
[2019-03-23 09:12:08,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0699
[2019-03-23 09:12:08,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1278174.215031378 W.
[2019-03-23 09:12:08,477] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 87.33333333333334, 1.0, 2.0, 0.3789267072251867, 1.0, 1.0, 0.3789267072251867, 1.0, 2.0, 0.7667125062239403, 6.9112, 6.9112, 77.3421103, 1278174.215031378, 1278174.215031378, 297460.5191846123], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1332600.0000, 
sim time next is 1333200.0000, 
raw observation next is [24.66666666666666, 85.66666666666667, 1.0, 2.0, 0.5483372600554004, 1.0, 2.0, 0.5483372600554004, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1233031.390872481, 1233031.390872481, 247887.0247805183], 
processed observation next is [1.0, 0.43478260869565216, 0.7575757575757573, 0.8566666666666667, 1.0, 1.0, 0.43542157506925044, 1.0, 1.0, 0.43542157506925044, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4566782929157337, 0.4566782929157337, 0.6046024994646787], 
reward next is 0.3954, 
noisyNet noise sample is [array([1.6615112], dtype=float32), 2.3589413]. 
=============================================
[2019-03-23 09:12:09,897] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1090101: loss -121.3473
[2019-03-23 09:12:09,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1090102: learning rate 0.0010
[2019-03-23 09:12:11,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.1296533e-17 1.0000000e+00 1.1102469e-25 1.1811808e-24 1.0126276e-26], sum to 1.0000
[2019-03-23 09:12:11,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6430
[2019-03-23 09:12:11,395] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.340871290103793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379285.2379451407, 379285.2379451407, 117421.4266142759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141200.0000, 
sim time next is 1141800.0000, 
raw observation next is [18.0, 94.00000000000001, 1.0, 2.0, 0.3484668726925741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387751.167507653, 387751.1675076532, 118022.9166758465], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.9400000000000002, 1.0, 1.0, 0.1855835908657176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14361154352135297, 0.14361154352135302, 0.2878607723801134], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.21201462], dtype=float32), 0.34437677]. 
=============================================
[2019-03-23 09:12:16,187] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1625658e-16 1.0000000e+00 4.4158092e-23 1.3762776e-21 1.0649967e-25], sum to 1.0000
[2019-03-23 09:12:16,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3045
[2019-03-23 09:12:16,203] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 88.5, 1.0, 2.0, 0.4726254261312315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539054.171994824, 539054.1719948243, 136791.0029858685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215000.0000, 
sim time next is 1215600.0000, 
raw observation next is [20.66666666666666, 90.33333333333334, 1.0, 2.0, 0.4527535463168793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515420.719629058, 515420.719629058, 133318.3911050434], 
processed observation next is [1.0, 0.043478260869565216, 0.5757575757575755, 0.9033333333333334, 1.0, 1.0, 0.3159419328960991, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19089656282557702, 0.19089656282557702, 0.3251668075732766], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.45446843], dtype=float32), 1.1166439]. 
=============================================
[2019-03-23 09:12:20,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1178526e-20 1.0000000e+00 5.4975260e-26 1.2998081e-26 5.6417917e-30], sum to 1.0000
[2019-03-23 09:12:20,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3327
[2019-03-23 09:12:20,397] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4576426502659379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521877.094473053, 521877.094473053, 135015.5531217089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1323000.0000, 
sim time next is 1323600.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.4680682329977731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534050.0855259651, 534050.0855259651, 136874.7935010906], 
processed observation next is [1.0, 0.30434782608695654, 0.6060606060606063, 0.94, 1.0, 1.0, 0.33508529124721637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19779632797257965, 0.19779632797257965, 0.3338409597587576], 
reward next is 0.6662, 
noisyNet noise sample is [array([2.786812], dtype=float32), -0.27078268]. 
=============================================
[2019-03-23 09:12:20,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3725805e-17 1.0000000e+00 1.4309760e-22 6.3216877e-23 1.1758708e-25], sum to 1.0000
[2019-03-23 09:12:20,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-23 09:12:20,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1659103.782566941 W.
[2019-03-23 09:12:20,527] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 75.66666666666666, 1.0, 2.0, 0.4958064282624762, 1.0, 2.0, 0.4916916510728455, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1659103.782566941, 1659103.782566941, 354963.1949050265], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1338000.0000, 
sim time next is 1338600.0000, 
raw observation next is [26.83333333333333, 74.83333333333334, 1.0, 2.0, 0.7403643872610014, 1.0, 2.0, 0.7403643872610014, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1665472.755788802, 1665472.755788802, 304778.7064086363], 
processed observation next is [1.0, 0.4782608695652174, 0.8560606060606059, 0.7483333333333334, 1.0, 1.0, 0.6754554840762517, 1.0, 1.0, 0.6754554840762517, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.61684176140326, 0.61684176140326, 0.7433626985576495], 
reward next is 0.2566, 
noisyNet noise sample is [array([0.19598284], dtype=float32), -0.050034866]. 
=============================================
[2019-03-23 09:12:20,820] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1095638: loss -133.4332
[2019-03-23 09:12:20,822] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1095639: learning rate 0.0010
[2019-03-23 09:12:21,262] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1095855: loss -111.7844
[2019-03-23 09:12:21,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1095856: learning rate 0.0010
[2019-03-23 09:12:21,579] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096013: loss -131.4923
[2019-03-23 09:12:21,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096013: learning rate 0.0010
[2019-03-23 09:12:21,807] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096124: loss -126.6528
[2019-03-23 09:12:21,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096124: learning rate 0.0010
[2019-03-23 09:12:21,862] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096154: loss -87.1735
[2019-03-23 09:12:21,863] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096154: learning rate 0.0010
[2019-03-23 09:12:21,887] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1096165: loss -59.7364
[2019-03-23 09:12:21,889] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1096165: learning rate 0.0010
[2019-03-23 09:12:22,247] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096346: loss -114.3436
[2019-03-23 09:12:22,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096346: learning rate 0.0010
[2019-03-23 09:12:22,306] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096378: loss -111.6012
[2019-03-23 09:12:22,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096378: learning rate 0.0010
[2019-03-23 09:12:22,757] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096600: loss -110.4037
[2019-03-23 09:12:22,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096602: learning rate 0.0010
[2019-03-23 09:12:22,889] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096665: loss -44.2293
[2019-03-23 09:12:22,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096665: learning rate 0.0010
[2019-03-23 09:12:23,184] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096817: loss -107.9819
[2019-03-23 09:12:23,189] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096818: learning rate 0.0010
[2019-03-23 09:12:23,190] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1096818: loss -46.5791
[2019-03-23 09:12:23,197] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1096819: learning rate 0.0010
[2019-03-23 09:12:23,381] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096910: loss -84.3608
[2019-03-23 09:12:23,383] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096911: learning rate 0.0010
[2019-03-23 09:12:23,444] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096940: loss -74.7267
[2019-03-23 09:12:23,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096940: learning rate 0.0010
[2019-03-23 09:12:23,751] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1097098: loss -83.6940
[2019-03-23 09:12:23,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1097098: learning rate 0.0010
[2019-03-23 09:12:25,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0544850e-17 1.0000000e+00 3.0632808e-25 3.8569480e-23 1.3424915e-26], sum to 1.0000
[2019-03-23 09:12:25,010] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1929
[2019-03-23 09:12:25,015] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 97.0, 1.0, 2.0, 0.4900244048897847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558994.3929380787, 558994.3929380787, 140621.804668209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1409400.0000, 
sim time next is 1410000.0000, 
raw observation next is [21.66666666666667, 96.0, 1.0, 2.0, 0.4916316129795459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560784.0707178062, 560784.0707178062, 140904.2710894223], 
processed observation next is [0.0, 0.30434782608695654, 0.6212121212121214, 0.96, 1.0, 1.0, 0.3645395162244323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20769780396955786, 0.20769780396955786, 0.34366895387663976], 
reward next is 0.6563, 
noisyNet noise sample is [array([-0.0781593], dtype=float32), -0.49658585]. 
=============================================
[2019-03-23 09:12:25,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.36045]
 [62.36045]
 [62.36045]
 [62.36045]
 [62.36045]], R is [[62.39318085]
 [62.42626953]
 [62.45975876]
 [62.49364853]
 [62.52767181]].
[2019-03-23 09:12:25,175] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1097813: loss 0.0382
[2019-03-23 09:12:25,177] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1097815: learning rate 0.0010
[2019-03-23 09:12:26,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7650776e-17 1.0000000e+00 3.9763325e-22 2.9581736e-22 1.3232073e-25], sum to 1.0000
[2019-03-23 09:12:26,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6907
[2019-03-23 09:12:26,221] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5428640247439193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615708.6832837347, 615708.6832837347, 149614.6593726249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1429800.0000, 
sim time next is 1430400.0000, 
raw observation next is [26.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5477072817372917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 620947.9421305477, 620947.9421305477, 150335.3972151533], 
processed observation next is [0.0, 0.5652173913043478, 0.8333333333333336, 0.7266666666666667, 1.0, 1.0, 0.4346341021716145, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22998071930761027, 0.22998071930761027, 0.3666717005247641], 
reward next is 0.6333, 
noisyNet noise sample is [array([-0.55838597], dtype=float32), 0.6245964]. 
=============================================
[2019-03-23 09:12:29,531] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 09:12:29,533] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:12:29,533] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:29,534] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:12:29,534] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:12:29,535] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:29,535] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:29,535] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:12:29,536] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:12:29,537] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:29,538] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:12:29,553] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 09:12:29,553] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 09:12:29,601] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 09:12:29,603] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 09:12:29,628] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 09:12:44,751] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:12:44,752] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.2, 50.0, 1.0, 2.0, 0.6368737739695775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 726199.7908392807, 726199.7908392804, 163996.5389330013]
[2019-03-23 09:12:44,753] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:44,757] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.9715501265678855
[2019-03-23 09:12:45,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:12:45,031] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.324410955, 87.06003395333335, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 205517.6480049494, 205517.6480049494, 73795.16564530651]
[2019-03-23 09:12:45,032] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:12:45,036] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.19260701708535577
[2019-03-23 09:12:45,343] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:12:45,344] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 78.0, 1.0, 2.0, 0.3227652345154455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353801.4466445787, 353801.4466445787, 113912.164928925]
[2019-03-23 09:12:45,346] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:12:45,350] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.10218255344224725
[2019-03-23 09:13:23,338] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:13:23,339] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.16666666666666, 59.5, 1.0, 2.0, 0.3053537517314089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 331660.3918914433, 331660.3918914436, 111583.9326994097]
[2019-03-23 09:13:23,340] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:13:23,343] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.0317557170557653
[2019-03-23 09:13:26,493] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:13:26,494] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.25973593666667, 66.17142391333333, 1.0, 2.0, 0.7137153449896927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 813736.5958867148, 813736.5958867148, 175214.7053761137]
[2019-03-23 09:13:26,495] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:13:26,498] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.1038375402990298
[2019-03-23 09:13:46,111] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:13:46,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.26046396, 89.52695381333334, 1.0, 2.0, 0.3239484929388217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 357767.4327460307, 357767.4327460303, 119327.0852646708]
[2019-03-23 09:13:46,114] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:13:46,117] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.9763599372375403
[2019-03-23 09:14:06,599] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:14:06,600] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.59234178, 100.0, 1.0, 2.0, 0.4808226498047856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 548594.7029150189, 548594.7029150189, 142866.1252116242]
[2019-03-23 09:14:06,601] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:14:06,604] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.9824424323980289
[2019-03-23 09:14:07,573] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4287756]
[2019-03-23 09:14:07,574] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.23333333333333, 62.00000000000001, 1.0, 2.0, 0.2728991125894857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 296301.9444135093, 296301.9444135089, 95411.45879529924]
[2019-03-23 09:14:07,575] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:14:07,577] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3405333e-16 1.0000000e+00 3.9859132e-23 2.2356144e-22 2.9975410e-25], sampled 0.21438994758566288
[2019-03-23 09:14:10,834] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:14:10,980] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:14:10,990] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:14:11,068] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:14:11,145] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:14:12,159] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1100000, evaluation results [1100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:14:18,898] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1103593: loss 0.1091
[2019-03-23 09:14:18,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1103594: learning rate 0.0010
[2019-03-23 09:14:19,265] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1103785: loss 0.0231
[2019-03-23 09:14:19,266] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1103785: learning rate 0.0010
[2019-03-23 09:14:19,654] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1103993: loss 0.0013
[2019-03-23 09:14:19,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1103994: learning rate 0.0010
[2019-03-23 09:14:19,698] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1104011: loss 0.0003
[2019-03-23 09:14:19,701] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104011: loss 0.0027
[2019-03-23 09:14:19,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1104011: learning rate 0.0010
[2019-03-23 09:14:19,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104011: learning rate 0.0010
[2019-03-23 09:14:19,793] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104066: loss 0.0019
[2019-03-23 09:14:19,794] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104066: learning rate 0.0010
[2019-03-23 09:14:20,301] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104336: loss 0.0002
[2019-03-23 09:14:20,302] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104337: learning rate 0.0010
[2019-03-23 09:14:20,477] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104433: loss 0.0019
[2019-03-23 09:14:20,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104433: learning rate 0.0010
[2019-03-23 09:14:20,763] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104586: loss 0.0011
[2019-03-23 09:14:20,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104586: learning rate 0.0010
[2019-03-23 09:14:20,780] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104595: loss 0.0025
[2019-03-23 09:14:20,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104595: learning rate 0.0010
[2019-03-23 09:14:21,287] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104860: loss 0.0001
[2019-03-23 09:14:21,288] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104860: learning rate 0.0010
[2019-03-23 09:14:21,431] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1104938: loss 0.0011
[2019-03-23 09:14:21,434] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1104938: learning rate 0.0010
[2019-03-23 09:14:21,449] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104945: loss 0.0000
[2019-03-23 09:14:21,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104945: learning rate 0.0010
[2019-03-23 09:14:21,470] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104955: loss 0.0003
[2019-03-23 09:14:21,472] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104955: learning rate 0.0010
[2019-03-23 09:14:21,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4277797e-17 1.0000000e+00 7.1998398e-25 6.4556464e-24 5.7645645e-27], sum to 1.0000
[2019-03-23 09:14:21,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6156
[2019-03-23 09:14:21,673] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 57.5, 1.0, 2.0, 0.2254228707224281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244755.5628411933, 244755.5628411935, 71815.77111115107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1711800.0000, 
sim time next is 1712400.0000, 
raw observation next is [15.0, 59.33333333333334, 1.0, 2.0, 0.2188923870762505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237663.2802231181, 237663.2802231178, 70911.46701467507], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.5933333333333334, 1.0, 1.0, 0.02361548384531311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08802343711967338, 0.08802343711967325, 0.17295479759676846], 
reward next is 0.8270, 
noisyNet noise sample is [array([-0.59536695], dtype=float32), 0.73745173]. 
=============================================
[2019-03-23 09:14:21,748] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1105106: loss 0.0062
[2019-03-23 09:14:21,750] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1105106: learning rate 0.0010
[2019-03-23 09:14:21,837] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.20222094e-16 1.00000000e+00 2.74839493e-22 6.67066840e-23
 1.02634064e-25], sum to 1.0000
[2019-03-23 09:14:21,840] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5402097e-16 1.0000000e+00 4.4636192e-23 2.0530954e-23 3.6608009e-26], sum to 1.0000
[2019-03-23 09:14:21,845] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4306
[2019-03-23 09:14:21,848] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1080
[2019-03-23 09:14:21,849] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.5, 65.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214811.3725296514, 214811.3725296512, 67997.83009947637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1715400.0000, 
sim time next is 1716000.0000, 
raw observation next is [13.33333333333333, 65.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212037.4920110467, 212037.4920110464, 67469.52954700399], 
processed observation next is [1.0, 0.8695652173913043, 0.2424242424242423, 0.6566666666666667, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07853240444853582, 0.0785324044485357, 0.16455982816342435], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20317356], dtype=float32), 1.1168797]. 
=============================================
[2019-03-23 09:14:21,854] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 90.0, 1.0, 2.0, 0.5569430480895754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 617337.9318874725, 617337.9318874725, 136264.49852985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1676400.0000, 
sim time next is 1677000.0000, 
raw observation next is [18.0, 89.0, 1.0, 2.0, 0.5398251500079626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597180.2348087722, 597180.2348087722, 134086.7102312262], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.89, 1.0, 1.0, 0.42478143750995323, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2211778647439897, 0.2211778647439897, 0.3270407566615273], 
reward next is 0.6730, 
noisyNet noise sample is [array([-1.2602565], dtype=float32), 2.193034]. 
=============================================
[2019-03-23 09:14:21,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.68214]
 [67.68214]
 [67.68214]
 [67.68214]
 [67.68214]], R is [[67.00531769]
 [66.33526611]
 [66.50473785]
 [66.67154694]
 [66.83547974]].
[2019-03-23 09:14:21,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.59002]
 [67.59002]
 [67.59002]
 [67.59002]
 [67.59002]], R is [[67.58707428]
 [67.57884979]
 [67.56256104]
 [67.54567719]
 [67.52227783]].
[2019-03-23 09:14:22,915] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1105730: loss -134.7866
[2019-03-23 09:14:22,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1105731: learning rate 0.0010
[2019-03-23 09:14:26,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6848322e-18 1.0000000e+00 4.8194721e-26 6.1500324e-27 3.2797778e-28], sum to 1.0000
[2019-03-23 09:14:26,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9658
[2019-03-23 09:14:26,172] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 40.0, 1.0, 2.0, 0.4838806423513903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525530.8114034265, 525530.8114034268, 101184.7788317587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1782000.0000, 
sim time next is 1782600.0000, 
raw observation next is [19.83333333333334, 40.0, 1.0, 2.0, 0.4515040989851178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490349.7128199452, 490349.7128199452, 97369.25736715167], 
processed observation next is [1.0, 0.6521739130434783, 0.5378787878787882, 0.4, 1.0, 1.0, 0.3143801237313972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18161100474812786, 0.18161100474812786, 0.2374859935784187], 
reward next is 0.7625, 
noisyNet noise sample is [array([-1.2355775], dtype=float32), -0.274978]. 
=============================================
[2019-03-23 09:14:27,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7302163e-17 1.0000000e+00 2.7143644e-23 1.6866229e-22 5.3253951e-27], sum to 1.0000
[2019-03-23 09:14:27,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3250
[2019-03-23 09:14:27,971] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 67.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 206863.7607797788, 206863.7607797788, 67508.37352786963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1815000.0000, 
sim time next is 1815600.0000, 
raw observation next is [14.0, 68.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 205950.4678071888, 205950.4678071891, 67458.34130381701], 
processed observation next is [1.0, 0.0, 0.2727272727272727, 0.6866666666666668, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07627795103969956, 0.07627795103969967, 0.16453253976540735], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37854317], dtype=float32), -0.04725945]. 
=============================================
[2019-03-23 09:14:28,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5694900e-18 1.0000000e+00 3.3096431e-26 3.7705310e-25 3.3147553e-29], sum to 1.0000
[2019-03-23 09:14:28,159] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3733
[2019-03-23 09:14:28,168] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 50.5, 1.0, 2.0, 0.3071762419653729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333550.6972202148, 333550.6972202145, 106447.0471757043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2056200.0000, 
sim time next is 2056800.0000, 
raw observation next is [21.93333333333333, 51.0, 1.0, 2.0, 0.3054671879731668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331694.2692604144, 331694.2692604141, 104105.2712949781], 
processed observation next is [0.0, 0.8260869565217391, 0.6333333333333332, 0.51, 1.0, 1.0, 0.13183398496645848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12284972935570904, 0.12284972935570894, 0.25391529584141], 
reward next is 0.7461, 
noisyNet noise sample is [array([-0.13054289], dtype=float32), 1.6622127]. 
=============================================
[2019-03-23 09:14:33,941] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1111539: loss -122.8021
[2019-03-23 09:14:33,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1111539: learning rate 0.0010
[2019-03-23 09:14:34,297] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1111733: loss -141.5802
[2019-03-23 09:14:34,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1111734: learning rate 0.0010
[2019-03-23 09:14:34,718] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1111977: loss -157.7992
[2019-03-23 09:14:34,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1111977: learning rate 0.0010
[2019-03-23 09:14:34,789] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112015: loss -112.2749
[2019-03-23 09:14:34,790] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112015: learning rate 0.0010
[2019-03-23 09:14:34,833] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112035: loss -159.8336
[2019-03-23 09:14:34,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112036: learning rate 0.0010
[2019-03-23 09:14:34,900] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112085: loss -79.2829
[2019-03-23 09:14:34,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112085: learning rate 0.0010
[2019-03-23 09:14:35,341] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112353: loss -66.1800
[2019-03-23 09:14:35,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112353: learning rate 0.0010
[2019-03-23 09:14:35,638] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112503: loss -155.5900
[2019-03-23 09:14:35,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112504: learning rate 0.0010
[2019-03-23 09:14:35,646] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112507: loss -71.7048
[2019-03-23 09:14:35,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112507: learning rate 0.0010
[2019-03-23 09:14:36,121] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112743: loss -58.3261
[2019-03-23 09:14:36,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112744: learning rate 0.0010
[2019-03-23 09:14:36,334] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112846: loss -93.5396
[2019-03-23 09:14:36,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112846: learning rate 0.0010
[2019-03-23 09:14:36,406] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112887: loss -59.8727
[2019-03-23 09:14:36,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112887: learning rate 0.0010
[2019-03-23 09:14:36,421] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112896: loss -158.9931
[2019-03-23 09:14:36,423] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112897: learning rate 0.0010
[2019-03-23 09:14:36,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1112899: loss -126.8951
[2019-03-23 09:14:36,430] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1112900: learning rate 0.0010
[2019-03-23 09:14:36,995] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1113175: loss -176.1015
[2019-03-23 09:14:36,997] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1113175: learning rate 0.0010
[2019-03-23 09:14:37,963] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1113671: loss 0.0380
[2019-03-23 09:14:37,965] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1113672: learning rate 0.0010
[2019-03-23 09:14:39,719] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.5680415e-18 1.0000000e+00 9.3605650e-26 5.3443265e-25 2.1538302e-27], sum to 1.0000
[2019-03-23 09:14:39,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5275
[2019-03-23 09:14:39,736] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 56.0, 1.0, 2.0, 0.2850558452971071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 309523.3774517219, 309523.3774517216, 101299.1847112216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2023200.0000, 
sim time next is 2023800.0000, 
raw observation next is [21.16666666666667, 55.0, 1.0, 2.0, 0.2843621303854298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308769.8789683639, 308769.8789683636, 101192.2631576244], 
processed observation next is [0.0, 0.43478260869565216, 0.5984848484848487, 0.55, 1.0, 1.0, 0.10545266298178722, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11435921443272738, 0.11435921443272727, 0.24681039794542536], 
reward next is 0.7532, 
noisyNet noise sample is [array([0.6391171], dtype=float32), -0.30433312]. 
=============================================
[2019-03-23 09:14:39,887] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4346192e-18 1.0000000e+00 4.8071907e-25 6.5079881e-25 7.2950153e-28], sum to 1.0000
[2019-03-23 09:14:39,894] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7117
[2019-03-23 09:14:39,899] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3062407257859033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333129.9888656656, 333129.9888656659, 111820.5866665606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [23.0, 51.0, 1.0, 2.0, 0.3055668565939638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 333443.2306736806, 333443.2306736803, 112146.1514458017], 
processed observation next is [0.0, 0.5652173913043478, 0.6818181818181818, 0.51, 1.0, 1.0, 0.13195857074245476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12349749284210393, 0.12349749284210382, 0.27352719864829683], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.5364525], dtype=float32), 1.1549661]. 
=============================================
[2019-03-23 09:14:44,056] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.5860514e-20 1.0000000e+00 4.5871735e-26 9.7387954e-26 5.4640265e-28], sum to 1.0000
[2019-03-23 09:14:44,064] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8683
[2019-03-23 09:14:44,069] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 72.5, 1.0, 2.0, 0.2421362708272823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262907.240363693, 262907.2403636927, 85276.68233046256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2100600.0000, 
sim time next is 2101200.0000, 
raw observation next is [18.0, 71.0, 1.0, 2.0, 0.2510262606431582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272562.5373299517, 272562.5373299519, 88689.63269968626], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.71, 1.0, 1.0, 0.06378282580394773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10094908789998211, 0.10094908789998218, 0.21631617731630795], 
reward next is 0.7837, 
noisyNet noise sample is [array([0.98921555], dtype=float32), 0.66523045]. 
=============================================
[2019-03-23 09:14:47,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9880349e-15 1.0000000e+00 5.2600685e-24 5.4681298e-22 3.9738851e-25], sum to 1.0000
[2019-03-23 09:14:47,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8090
[2019-03-23 09:14:47,674] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2210568962936415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 240013.9845666857, 240013.9845666857, 77335.22249163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2436600.0000, 
sim time next is 2437200.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2283671514438529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 247953.1654999482, 247953.1654999485, 78045.98377071111], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.94, 1.0, 1.0, 0.0354589393048161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09183450574072155, 0.09183450574072166, 0.19035605797734417], 
reward next is 0.8096, 
noisyNet noise sample is [array([-0.9219813], dtype=float32), 0.5898387]. 
=============================================
[2019-03-23 09:14:49,475] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1119504: loss 0.1474
[2019-03-23 09:14:49,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1119505: learning rate 0.0010
[2019-03-23 09:14:49,691] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1119618: loss 0.2109
[2019-03-23 09:14:49,693] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1119619: learning rate 0.0010
[2019-03-23 09:14:50,371] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1119964: loss 0.1995
[2019-03-23 09:14:50,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1119964: learning rate 0.0010
[2019-03-23 09:14:50,387] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1119969: loss 0.2355
[2019-03-23 09:14:50,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1119969: learning rate 0.0010
[2019-03-23 09:14:50,547] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120050: loss 0.1696
[2019-03-23 09:14:50,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120050: learning rate 0.0010
[2019-03-23 09:14:50,612] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120080: loss 0.1302
[2019-03-23 09:14:50,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120081: learning rate 0.0010
[2019-03-23 09:14:51,013] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120290: loss 0.0628
[2019-03-23 09:14:51,017] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120291: learning rate 0.0010
[2019-03-23 09:14:51,383] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120476: loss 0.1483
[2019-03-23 09:14:51,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120478: learning rate 0.0010
[2019-03-23 09:14:51,470] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120520: loss 0.1378
[2019-03-23 09:14:51,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120523: learning rate 0.0010
[2019-03-23 09:14:51,811] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120691: loss 0.0251
[2019-03-23 09:14:51,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120692: learning rate 0.0010
[2019-03-23 09:14:52,198] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120889: loss 0.0234
[2019-03-23 09:14:52,199] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120889: learning rate 0.0010
[2019-03-23 09:14:52,221] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120905: loss 0.0203
[2019-03-23 09:14:52,224] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120905: learning rate 0.0010
[2019-03-23 09:14:52,253] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1120921: loss 0.0067
[2019-03-23 09:14:52,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1120921: learning rate 0.0010
[2019-03-23 09:14:52,405] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120999: loss 0.0116
[2019-03-23 09:14:52,408] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1121000: learning rate 0.0010
[2019-03-23 09:14:52,798] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1121203: loss 0.0060
[2019-03-23 09:14:52,799] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1121203: learning rate 0.0010
[2019-03-23 09:14:53,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1901994e-17 1.0000000e+00 1.3550255e-25 6.0511554e-26 4.0745443e-29], sum to 1.0000
[2019-03-23 09:14:53,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5357
[2019-03-23 09:14:53,498] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 54.66666666666667, 1.0, 2.0, 0.2323951017976444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252327.7093150843, 252327.709315084, 73700.11144601363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2329800.0000, 
sim time next is 2330400.0000, 
raw observation next is [16.66666666666667, 57.33333333333334, 1.0, 2.0, 0.2306215019485998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 250401.4914880013, 250401.4914880013, 73898.15897462922], 
processed observation next is [1.0, 1.0, 0.39393939393939414, 0.5733333333333335, 1.0, 1.0, 0.03827687743574972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09274129314370419, 0.09274129314370419, 0.180239412133242], 
reward next is 0.8198, 
noisyNet noise sample is [array([1.0889542], dtype=float32), -0.490105]. 
=============================================
[2019-03-23 09:14:53,883] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1121748: loss 0.1833
[2019-03-23 09:14:53,884] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1121748: learning rate 0.0010
[2019-03-23 09:14:54,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9069923e-18 1.0000000e+00 3.5901607e-25 3.0834844e-23 8.9674100e-28], sum to 1.0000
[2019-03-23 09:14:54,076] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3798
[2019-03-23 09:14:54,085] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 59.0, 1.0, 2.0, 0.3464108248327966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376170.4786248282, 376170.4786248282, 86303.48410092053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2278200.0000, 
sim time next is 2278800.0000, 
raw observation next is [17.0, 59.0, 1.0, 2.0, 0.3542915745754088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384731.6377721534, 384731.6377721537, 87495.91989985197], 
processed observation next is [1.0, 0.391304347826087, 0.4090909090909091, 0.59, 1.0, 1.0, 0.19286446821926095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14249319917487163, 0.14249319917487174, 0.2134046826825658], 
reward next is 0.7866, 
noisyNet noise sample is [array([-0.26044804], dtype=float32), -0.8050568]. 
=============================================
[2019-03-23 09:14:54,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6581654e-20 1.0000000e+00 1.2624433e-27 4.7371367e-27 8.2328427e-30], sum to 1.0000
[2019-03-23 09:14:54,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0214
[2019-03-23 09:14:54,448] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 67.83333333333334, 1.0, 2.0, 0.2186108599945439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237357.5364908737, 237357.5364908734, 73831.94150852397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2333400.0000, 
sim time next is 2334000.0000, 
raw observation next is [15.66666666666667, 67.66666666666667, 1.0, 2.0, 0.2166278798551651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 235203.9880210163, 235203.988021016, 73242.09776223404], 
processed observation next is [1.0, 0.0, 0.3484848484848486, 0.6766666666666667, 1.0, 1.0, 0.020784849818956362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08711258815593197, 0.08711258815593186, 0.17863926283471718], 
reward next is 0.8214, 
noisyNet noise sample is [array([0.41759393], dtype=float32), 0.20883459]. 
=============================================
[2019-03-23 09:14:54,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.31724]
 [77.31724]
 [77.31724]
 [77.31724]
 [77.31724]], R is [[77.36542511]
 [77.41169739]
 [77.45597839]
 [77.50027466]
 [77.54447937]].
[2019-03-23 09:14:56,916] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8919267e-17 1.0000000e+00 2.5734978e-24 6.2811536e-25 1.1882245e-27], sum to 1.0000
[2019-03-23 09:14:56,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8316
[2019-03-23 09:14:56,927] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.0, 1.0, 2.0, 0.4600270761299203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 499610.7294136912, 499610.7294136915, 103469.0741318445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2371200.0000, 
sim time next is 2371800.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.4570293561638016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496353.4045015313, 496353.4045015316, 103112.0627637181], 
processed observation next is [1.0, 0.43478260869565216, 0.5454545454545454, 0.49, 1.0, 1.0, 0.32128669520475195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1838345942598264, 0.18383459425982654, 0.2514928360090685], 
reward next is 0.7485, 
noisyNet noise sample is [array([2.1463928], dtype=float32), 0.85209537]. 
=============================================
[2019-03-23 09:15:00,295] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 09:15:00,298] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:15:00,298] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:15:00,301] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:15:00,303] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:15:00,303] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:15:00,303] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:15:00,304] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:15:00,305] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:15:00,304] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:15:00,308] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:15:00,325] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 09:15:00,348] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 09:15:00,375] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 09:15:00,375] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 09:15:00,421] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 09:15:03,296] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:15:03,299] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.15404489333334, 50.94038720499999, 1.0, 2.0, 0.7368876323765178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 830557.4121775611, 830557.4121775611, 167077.2465894765]
[2019-03-23 09:15:03,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:15:03,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.7711407311801104
[2019-03-23 09:15:15,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:15:15,184] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 82.5, 1.0, 2.0, 0.2073930949867069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225174.9880472295, 225174.9880472292, 75214.36070351583]
[2019-03-23 09:15:15,185] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:15:15,187] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.34632119223418645
[2019-03-23 09:15:17,363] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:15:17,366] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.45227023, 56.67698386666667, 1.0, 2.0, 0.6345099679108896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769668934, 721727.8570016151, 721727.8570016155, 158181.539792603]
[2019-03-23 09:15:17,367] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:15:17,369] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.389098636116458
[2019-03-23 09:15:35,399] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:15:35,402] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.106915, 45.04776452, 1.0, 2.0, 0.3462200567543966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 376873.5843620698, 376873.5843620701, 119028.6953156348]
[2019-03-23 09:15:35,403] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:15:35,407] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.45722272692187504
[2019-03-23 09:15:54,565] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:15:54,566] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.5, 81.0, 1.0, 2.0, 0.6399049898511123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 713603.8132411018, 713603.8132411015, 151239.9907739687]
[2019-03-23 09:15:54,567] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:15:54,568] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.9709070253939083
[2019-03-23 09:16:36,588] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:16:36,589] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.42479187, 65.06171566, 1.0, 2.0, 0.5381947066691966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 611212.6981382524, 611212.6981382524, 152942.2064008634]
[2019-03-23 09:16:36,590] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:16:36,592] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.5957327187608548
[2019-03-23 09:16:36,954] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39924148]
[2019-03-23 09:16:36,955] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.758739205, 100.0, 1.0, 2.0, 0.2733061851948591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 296744.03519048, 296744.0351904797, 96351.3333302117]
[2019-03-23 09:16:36,955] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:16:36,958] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4006379e-18 1.0000000e+00 2.0633621e-26 1.1454594e-25 6.4349033e-29], sampled 0.7397467534845477
[2019-03-23 09:16:41,811] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:16:41,814] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:16:41,928] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:16:41,939] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:16:42,077] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:16:43,092] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1125000, evaluation results [1125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:16:43,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.200058e-18 1.000000e+00 7.763649e-25 6.237526e-26 1.414473e-28], sum to 1.0000
[2019-03-23 09:16:43,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3066
[2019-03-23 09:16:43,680] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 77.0, 1.0, 2.0, 0.259028703786805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281254.0458667957, 281254.0458667957, 87685.01118951743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2415600.0000, 
sim time next is 2416200.0000, 
raw observation next is [17.0, 76.16666666666667, 1.0, 2.0, 0.2576306340543195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279735.5815171089, 279735.5815171092, 86801.78106687662], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.7616666666666667, 1.0, 1.0, 0.07203829256789938, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10360577093226256, 0.10360577093226266, 0.21171166113872344], 
reward next is 0.7883, 
noisyNet noise sample is [array([-0.56213856], dtype=float32), 1.3194563]. 
=============================================
[2019-03-23 09:16:44,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0372039e-17 1.0000000e+00 3.3928276e-24 2.5046839e-24 5.0765207e-30], sum to 1.0000
[2019-03-23 09:16:44,967] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4914
[2019-03-23 09:16:44,976] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333334, 90.0, 1.0, 2.0, 0.4527829673008661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 491739.3123234236, 491739.3123234233, 107503.4173661545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2452800.0000, 
sim time next is 2453400.0000, 
raw observation next is [15.5, 88.0, 1.0, 2.0, 0.4493777437305366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 488039.2552654138, 488039.2552654136, 106677.6194062777], 
processed observation next is [1.0, 0.391304347826087, 0.3409090909090909, 0.88, 1.0, 1.0, 0.31172217966317073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18075527972793104, 0.18075527972793096, 0.2601893156250676], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.5956671], dtype=float32), -0.12258972]. 
=============================================
[2019-03-23 09:16:47,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.7815517e-18 1.0000000e+00 8.4176497e-27 8.5829244e-26 3.1473735e-30], sum to 1.0000
[2019-03-23 09:16:47,302] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8450
[2019-03-23 09:16:47,307] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2377534444961131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258147.1828682377, 258147.1828682374, 79191.94463458599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2488800.0000, 
sim time next is 2489400.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2349145027109725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255063.917381247, 255063.9173812467, 78855.94837509532], 
processed observation next is [1.0, 0.8260869565217391, 0.2727272727272727, 0.94, 1.0, 1.0, 0.04364312838871561, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09446811754861001, 0.09446811754860988, 0.1923315814026715], 
reward next is 0.8077, 
noisyNet noise sample is [array([0.6629673], dtype=float32), -3.3128867]. 
=============================================
[2019-03-23 09:16:47,850] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1127531: loss 0.3265
[2019-03-23 09:16:47,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1127532: learning rate 0.0010
[2019-03-23 09:16:47,863] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1127539: loss 0.3199
[2019-03-23 09:16:47,864] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1127539: learning rate 0.0010
[2019-03-23 09:16:48,672] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1127971: loss 0.1788
[2019-03-23 09:16:48,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1127972: learning rate 0.0010
[2019-03-23 09:16:48,708] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1127993: loss 0.1782
[2019-03-23 09:16:48,710] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1127994: learning rate 0.0010
[2019-03-23 09:16:48,717] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1127996: loss 0.1847
[2019-03-23 09:16:48,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1127996: learning rate 0.0010
[2019-03-23 09:16:48,958] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128123: loss 0.1203
[2019-03-23 09:16:48,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128124: learning rate 0.0010
[2019-03-23 09:16:49,046] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128169: loss 0.1260
[2019-03-23 09:16:49,049] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128171: learning rate 0.0010
[2019-03-23 09:16:49,342] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.4002978e-19 1.0000000e+00 1.8676513e-26 1.7112408e-25 4.5973246e-30], sum to 1.0000
[2019-03-23 09:16:49,350] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2539
[2019-03-23 09:16:49,356] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.51666666666667, 65.5, 1.0, 2.0, 0.2571666422873856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 279231.6341993417, 279231.634199342, 87574.52548397925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [18.43333333333334, 67.0, 1.0, 2.0, 0.2582193695727457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280375.0153503875, 280375.0153503872, 88648.38994952949], 
processed observation next is [1.0, 0.9565217391304348, 0.4742424242424246, 0.67, 1.0, 1.0, 0.07277421196593213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10384259827792129, 0.10384259827792118, 0.21621558524275486], 
reward next is 0.7838, 
noisyNet noise sample is [array([0.22528931], dtype=float32), 1.1210732]. 
=============================================
[2019-03-23 09:16:49,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[76.44365]
 [76.44365]
 [76.44365]
 [76.44365]
 [76.44365]], R is [[76.46299744]
 [76.48477173]
 [76.50823212]
 [76.53024292]
 [76.55065918]].
[2019-03-23 09:16:49,586] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128454: loss 0.0819
[2019-03-23 09:16:49,588] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128454: learning rate 0.0010
[2019-03-23 09:16:49,707] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128513: loss 0.0782
[2019-03-23 09:16:49,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128515: learning rate 0.0010
[2019-03-23 09:16:50,221] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128785: loss 0.0542
[2019-03-23 09:16:50,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128785: learning rate 0.0010
[2019-03-23 09:16:50,248] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128800: loss 0.0428
[2019-03-23 09:16:50,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128800: learning rate 0.0010
[2019-03-23 09:16:50,580] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128972: loss 0.0476
[2019-03-23 09:16:50,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128972: learning rate 0.0010
[2019-03-23 09:16:50,590] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128974: loss 0.0448
[2019-03-23 09:16:50,593] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128975: learning rate 0.0010
[2019-03-23 09:16:50,660] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1129013: loss 0.0632
[2019-03-23 09:16:50,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1129013: learning rate 0.0010
[2019-03-23 09:16:51,090] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1129247: loss 0.0219
[2019-03-23 09:16:51,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1129247: learning rate 0.0010
[2019-03-23 09:16:52,091] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.998358e-20 1.000000e+00 8.669260e-28 6.100177e-25 2.922941e-29], sum to 1.0000
[2019-03-23 09:16:52,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7363
[2019-03-23 09:16:52,109] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.56666666666667, 77.33333333333334, 1.0, 2.0, 0.2688400641379572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291910.4437895531, 291910.4437895531, 94747.91039717304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2593200.0000, 
sim time next is 2593800.0000, 
raw observation next is [17.5, 80.0, 1.0, 2.0, 0.2757249109181012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 299388.4113873739, 299388.4113873739, 99116.31722033325], 
processed observation next is [0.0, 0.0, 0.4318181818181818, 0.8, 1.0, 1.0, 0.09465613864762648, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11088459681013849, 0.11088459681013849, 0.2417471151715445], 
reward next is 0.7583, 
noisyNet noise sample is [array([-0.0307283], dtype=float32), -0.018334724]. 
=============================================
[2019-03-23 09:16:52,285] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1129876: loss 0.0242
[2019-03-23 09:16:52,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1129876: learning rate 0.0010
[2019-03-23 09:17:00,925] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4566599e-17 1.0000000e+00 3.4413698e-24 1.3051073e-22 2.8740767e-25], sum to 1.0000
[2019-03-23 09:17:00,935] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0431
[2019-03-23 09:17:00,938] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5055037260594669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575962.3934859725, 575962.3934859725, 143388.2993714984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2750400.0000, 
sim time next is 2751000.0000, 
raw observation next is [23.0, 87.16666666666667, 1.0, 2.0, 0.5043152424414096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574879.0405564978, 574879.0405564978, 142956.1291753127], 
processed observation next is [0.0, 0.8695652173913043, 0.6818181818181818, 0.8716666666666667, 1.0, 1.0, 0.38039405305176194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21291816316907325, 0.21291816316907325, 0.3486734857934456], 
reward next is 0.6513, 
noisyNet noise sample is [array([-0.41348228], dtype=float32), 0.7866176]. 
=============================================
[2019-03-23 09:17:00,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.47453]
 [67.47453]
 [67.47453]
 [67.47453]
 [67.47453]], R is [[67.45111084]
 [67.42687988]
 [67.40571594]
 [67.38816833]
 [67.37464905]].
[2019-03-23 09:17:02,836] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1135489: loss 0.0019
[2019-03-23 09:17:02,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1135489: learning rate 0.0010
[2019-03-23 09:17:02,990] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1135569: loss 0.0014
[2019-03-23 09:17:02,993] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1135569: learning rate 0.0010
[2019-03-23 09:17:03,557] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1135870: loss 0.0250
[2019-03-23 09:17:03,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1135870: learning rate 0.0010
[2019-03-23 09:17:03,579] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1135884: loss 0.0320
[2019-03-23 09:17:03,580] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1135884: learning rate 0.0010
[2019-03-23 09:17:03,608] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1135897: loss 0.0373
[2019-03-23 09:17:03,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1135898: learning rate 0.0010
[2019-03-23 09:17:03,799] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1135997: loss 0.0180
[2019-03-23 09:17:03,800] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1135997: learning rate 0.0010
[2019-03-23 09:17:04,080] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136144: loss 0.0024
[2019-03-23 09:17:04,083] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136144: learning rate 0.0010
[2019-03-23 09:17:04,746] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136516: loss 0.0003
[2019-03-23 09:17:04,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136516: learning rate 0.0010
[2019-03-23 09:17:04,875] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136590: loss 0.0000
[2019-03-23 09:17:04,878] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136591: learning rate 0.0010
[2019-03-23 09:17:04,908] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136608: loss 0.0006
[2019-03-23 09:17:04,910] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136610: learning rate 0.0010
[2019-03-23 09:17:05,024] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136675: loss 0.0108
[2019-03-23 09:17:05,025] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136675: learning rate 0.0010
[2019-03-23 09:17:05,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9459515e-14 1.0000000e+00 1.9538690e-22 2.4693201e-21 1.0069897e-23], sum to 1.0000
[2019-03-23 09:17:05,289] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-23 09:17:05,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1462813.903956533 W.
[2019-03-23 09:17:05,298] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.4335942744296939, 1.0, 1.0, 0.4335942744296939, 1.0, 2.0, 0.8773257373879945, 6.911199999999999, 6.9112, 77.3421103, 1462813.903956533, 1462813.903956534, 324084.7653701074], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2886600.0000, 
sim time next is 2887200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.4060305808743901, 1.0, 2.0, 0.4060305808743901, 1.0, 2.0, 0.8215539267353961, 6.911199999999999, 6.9112, 77.3421103, 1369710.015159413, 1369710.015159414, 310260.6349608028], 
processed observation next is [1.0, 0.43478260869565216, 0.8181818181818182, 0.74, 1.0, 1.0, 0.2575382260929876, 1.0, 1.0, 0.2575382260929876, 1.0, 1.0, 0.7450770381934231, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5073000056145974, 0.5073000056145978, 0.7567332560019581], 
reward next is 0.2433, 
noisyNet noise sample is [array([-0.10466547], dtype=float32), 1.6284596]. 
=============================================
[2019-03-23 09:17:05,587] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1137011: loss 0.0049
[2019-03-23 09:17:05,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1137012: learning rate 0.0010
[2019-03-23 09:17:05,599] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1137018: loss 0.0024
[2019-03-23 09:17:05,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1137018: learning rate 0.0010
[2019-03-23 09:17:05,684] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1137061: loss 0.0048
[2019-03-23 09:17:05,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1137063: learning rate 0.0010
[2019-03-23 09:17:06,086] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1137260: loss 0.0263
[2019-03-23 09:17:06,088] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1137260: learning rate 0.0010
[2019-03-23 09:17:07,654] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1138035: loss -102.8409
[2019-03-23 09:17:07,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1138035: learning rate 0.0010
[2019-03-23 09:17:08,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7930027e-14 1.0000000e+00 5.0190278e-21 7.7302120e-21 6.7729767e-23], sum to 1.0000
[2019-03-23 09:17:08,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7371
[2019-03-23 09:17:08,089] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5158001102376367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588236.5818487263, 588236.5818487263, 143973.1482679496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2958000.0000, 
sim time next is 2958600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4973143798641649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 567152.2124550556, 567152.2124550559, 141776.0252924425], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.94, 1.0, 1.0, 0.3716429748302061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21005637498335392, 0.21005637498335403, 0.34579518364010364], 
reward next is 0.6542, 
noisyNet noise sample is [array([-0.01061282], dtype=float32), -0.12269849]. 
=============================================
[2019-03-23 09:17:09,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1941213e-14 1.0000000e+00 2.0056830e-21 2.1095367e-21 1.2103460e-23], sum to 1.0000
[2019-03-23 09:17:09,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8116
[2019-03-23 09:17:09,372] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5401199511035526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614332.0240173658, 614332.0240173658, 148416.6972068253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2936400.0000, 
sim time next is 2937000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5394483386077624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 613567.9252095437, 613567.925209544, 148332.1945976917], 
processed observation next is [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.424310423259703, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2272473797072384, 0.22724737970723852, 0.3617858404821749], 
reward next is 0.6382, 
noisyNet noise sample is [array([-1.8644283], dtype=float32), 0.2857166]. 
=============================================
[2019-03-23 09:17:09,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[62.631653]
 [62.631653]
 [62.631653]
 [62.631653]
 [62.631653]], R is [[62.64355087]
 [62.65512466]
 [62.66664505]
 [62.67815399]
 [62.68954086]].
[2019-03-23 09:17:10,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3897353e-14 1.0000000e+00 6.1432515e-21 6.3373162e-21 5.2375259e-23], sum to 1.0000
[2019-03-23 09:17:10,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7484
[2019-03-23 09:17:10,678] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.4815104593593226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 549282.6165900171, 549282.6165900175, 139634.2678887253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3002400.0000, 
sim time next is 3003000.0000, 
raw observation next is [27.66666666666667, 56.66666666666667, 1.0, 2.0, 0.4868106246400328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555327.6493070796, 555327.6493070796, 140249.583029811], 
processed observation next is [1.0, 0.782608695652174, 0.8939393939393941, 0.5666666666666668, 1.0, 1.0, 0.3585132808000409, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20567690715077022, 0.20567690715077022, 0.3420721537312464], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.9145682], dtype=float32), -0.02408772]. 
=============================================
[2019-03-23 09:17:10,699] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[60.685707]
 [60.685707]
 [60.685707]
 [60.685707]
 [60.685707]], R is [[60.73677826]
 [60.78883743]
 [60.84158325]
 [60.89499664]
 [60.94941711]].
[2019-03-23 09:17:18,585] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1143511: loss -53.9482
[2019-03-23 09:17:18,586] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1143511: learning rate 0.0010
[2019-03-23 09:17:18,824] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1143642: loss -45.7403
[2019-03-23 09:17:18,826] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1143642: learning rate 0.0010
[2019-03-23 09:17:19,261] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1143857: loss -49.9631
[2019-03-23 09:17:19,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1143857: learning rate 0.0010
[2019-03-23 09:17:19,285] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1143866: loss -94.3642
[2019-03-23 09:17:19,286] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1143866: learning rate 0.0010
[2019-03-23 09:17:19,389] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1143921: loss -104.2962
[2019-03-23 09:17:19,392] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1143921: learning rate 0.0010
[2019-03-23 09:17:19,737] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144098: loss -94.9596
[2019-03-23 09:17:19,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144099: learning rate 0.0010
[2019-03-23 09:17:19,846] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144150: loss -45.4630
[2019-03-23 09:17:19,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144150: learning rate 0.0010
[2019-03-23 09:17:20,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144441: loss -93.2657
[2019-03-23 09:17:20,423] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144441: learning rate 0.0010
[2019-03-23 09:17:20,636] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144547: loss -70.2744
[2019-03-23 09:17:20,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144547: learning rate 0.0010
[2019-03-23 09:17:20,755] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144609: loss -72.2905
[2019-03-23 09:17:20,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144610: learning rate 0.0010
[2019-03-23 09:17:20,988] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144720: loss -104.1931
[2019-03-23 09:17:20,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144720: learning rate 0.0010
[2019-03-23 09:17:21,603] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1145032: loss -51.6452
[2019-03-23 09:17:21,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1145032: learning rate 0.0010
[2019-03-23 09:17:21,705] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1145085: loss -63.3464
[2019-03-23 09:17:21,706] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1145085: learning rate 0.0010
[2019-03-23 09:17:21,765] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1145114: loss -59.9584
[2019-03-23 09:17:21,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1145114: learning rate 0.0010
[2019-03-23 09:17:22,101] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1145284: loss -37.7168
[2019-03-23 09:17:22,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1145284: learning rate 0.0010
[2019-03-23 09:17:23,215] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1145841: loss 0.0263
[2019-03-23 09:17:23,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1145842: learning rate 0.0010
[2019-03-23 09:17:31,430] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 09:17:31,432] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:17:31,433] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:17:31,433] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:17:31,434] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:31,435] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:31,436] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:17:31,435] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:17:31,438] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:31,439] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:31,436] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:17:31,456] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 09:17:31,480] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 09:17:31,507] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 09:17:31,533] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 09:17:31,533] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 09:18:07,556] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:18:07,559] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3690767607350459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415256.2614509038, 415256.261450904, 121782.3721510205]
[2019-03-23 09:18:07,561] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:18:07,565] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.9692435742902002
[2019-03-23 09:18:13,225] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:18:13,226] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.0, 68.66666666666666, 1.0, 2.0, 0.4910237371343796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 560247.6345246689, 560247.6345246686, 144172.6313566139]
[2019-03-23 09:18:13,227] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:18:13,230] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.5762621994776176
[2019-03-23 09:18:14,889] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:18:14,891] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.434360165, 93.01588248166668, 1.0, 2.0, 0.903345526475539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1022204.505421648, 1022204.505421648, 210882.2041037642]
[2019-03-23 09:18:14,892] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:18:14,896] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.7825356828679587
[2019-03-23 09:18:15,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:18:15,264] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.96763706, 75.727820355, 1.0, 2.0, 0.4211454543579479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 476306.2952129475, 476306.2952129471, 132086.1599512572]
[2019-03-23 09:18:15,266] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:18:15,269] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.45367792641828997
[2019-03-23 09:18:18,350] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:18:18,353] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.5516401981720185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625835.2626028797, 625835.2626028797, 150671.6049237603]
[2019-03-23 09:18:18,355] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:18:18,358] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.7081604354101987
[2019-03-23 09:18:40,109] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:18:40,112] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [13.26666666666667, 89.66666666666667, 1.0, 2.0, 0.2002960067111285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 217458.4012745224, 217458.401274522, 76289.91415069027]
[2019-03-23 09:18:40,112] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:18:40,116] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.2006582842737913
[2019-03-23 09:19:10,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28966776]
[2019-03-23 09:19:11,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.02917426333333, 100.0, 1.0, 2.0, 0.3242851336538062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 352431.6963547609, 352431.6963547602, 117267.285681727]
[2019-03-23 09:19:11,002] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:19:11,008] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.8068715e-17 1.0000000e+00 5.7170079e-24 2.9364956e-23 3.2656860e-26], sampled 0.15951767729401212
[2019-03-23 09:19:13,096] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:19:13,229] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:19:13,240] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:19:13,251] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:19:13,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:19:14,393] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1150000, evaluation results [1150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:19:14,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7317127e-16 1.0000000e+00 7.3669006e-24 3.5024793e-23 7.2533126e-27], sum to 1.0000
[2019-03-23 09:19:14,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0572
[2019-03-23 09:19:14,665] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666666, 68.16666666666666, 1.0, 2.0, 0.3497858254075567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388435.5357205032, 388435.5357205032, 117800.1788910011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3358200.0000, 
sim time next is 3358800.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.3467190427306611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384795.8494077041, 384795.8494077044, 117464.1342442892], 
processed observation next is [0.0, 0.9130434782608695, 0.5909090909090909, 0.69, 1.0, 1.0, 0.18339880341332637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14251698126211262, 0.14251698126211274, 0.2864978884007054], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.7394749], dtype=float32), 1.0647242]. 
=============================================
[2019-03-23 09:19:15,594] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4172098e-15 1.0000000e+00 1.1117484e-23 3.7147288e-22 2.7918207e-25], sum to 1.0000
[2019-03-23 09:19:15,600] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5571
[2019-03-23 09:19:15,602] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 73.5, 1.0, 2.0, 0.3455922700764403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384178.9211306509, 384178.9211306512, 117639.1280642268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3364200.0000, 
sim time next is 3364800.0000, 
raw observation next is [20.33333333333333, 75.0, 1.0, 2.0, 0.3472172150835837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386216.1277709068, 386216.1277709068, 117863.378883192], 
processed observation next is [0.0, 0.9565217391304348, 0.5606060606060604, 0.75, 1.0, 1.0, 0.18402151885447962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14304301028552102, 0.14304301028552102, 0.28747165581266343], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.10569834], dtype=float32), -0.15848574]. 
=============================================
[2019-03-23 09:19:15,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.04460530e-17 1.00000000e+00 8.82557765e-23 1.15959966e-23
 1.26687820e-25], sum to 1.0000
[2019-03-23 09:19:15,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3794
[2019-03-23 09:19:15,957] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 69.0, 1.0, 2.0, 0.3432350709536945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380844.2549156288, 380844.2549156288, 117158.8811133222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3362400.0000, 
sim time next is 3363000.0000, 
raw observation next is [20.83333333333333, 70.5, 1.0, 2.0, 0.3435429116650154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381392.8482276765, 381392.8482276762, 117267.8187986091], 
processed observation next is [0.0, 0.9565217391304348, 0.5833333333333331, 0.705, 1.0, 1.0, 0.1794286395812692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.141256610454695, 0.14125661045469487, 0.28601907024051004], 
reward next is 0.7140, 
noisyNet noise sample is [array([1.587199], dtype=float32), -0.18699232]. 
=============================================
[2019-03-23 09:19:15,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.44021]
 [70.44021]
 [70.44021]
 [70.44021]
 [70.44021]], R is [[70.44978333]
 [70.45953369]
 [70.46911621]
 [70.47857666]
 [70.48794556]].
[2019-03-23 09:19:17,119] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1151455: loss 0.0024
[2019-03-23 09:19:17,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1151457: learning rate 0.0010
[2019-03-23 09:19:17,498] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151659: loss 0.0027
[2019-03-23 09:19:17,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151659: learning rate 0.0010
[2019-03-23 09:19:17,793] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1151814: loss 0.0085
[2019-03-23 09:19:17,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1151815: learning rate 0.0010
[2019-03-23 09:19:17,867] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1151853: loss 0.0096
[2019-03-23 09:19:17,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1151854: learning rate 0.0010
[2019-03-23 09:19:17,979] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1151910: loss 0.0131
[2019-03-23 09:19:17,981] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1151910: learning rate 0.0010
[2019-03-23 09:19:18,356] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152112: loss 0.0055
[2019-03-23 09:19:18,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152113: learning rate 0.0010
[2019-03-23 09:19:18,364] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152116: loss 0.0026
[2019-03-23 09:19:18,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152116: learning rate 0.0010
[2019-03-23 09:19:18,941] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152418: loss 0.0045
[2019-03-23 09:19:18,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152421: learning rate 0.0010
[2019-03-23 09:19:19,150] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152525: loss 0.0031
[2019-03-23 09:19:19,152] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152525: learning rate 0.0010
[2019-03-23 09:19:19,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152542: loss 0.0020
[2019-03-23 09:19:19,189] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152542: learning rate 0.0010
[2019-03-23 09:19:19,433] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152678: loss 0.0001
[2019-03-23 09:19:19,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152679: learning rate 0.0010
[2019-03-23 09:19:19,642] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5360288e-15 1.0000000e+00 8.9702683e-24 1.4048623e-22 3.0949962e-24], sum to 1.0000
[2019-03-23 09:19:19,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1451
[2019-03-23 09:19:19,654] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5159455340966725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.4253613873, 588677.4253613873, 143388.2715794155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3465600.0000, 
sim time next is 3466200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5092313253943408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 581015.4342845341, 581015.4342845341, 142585.7481271915], 
processed observation next is [1.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.38653915674292594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21519090158686446, 0.21519090158686446, 0.3477701173833939], 
reward next is 0.6522, 
noisyNet noise sample is [array([-0.85028064], dtype=float32), -1.4852601]. 
=============================================
[2019-03-23 09:19:20,136] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1153049: loss 0.0030
[2019-03-23 09:19:20,137] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1153049: learning rate 0.0010
[2019-03-23 09:19:20,225] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1153091: loss 0.0036
[2019-03-23 09:19:20,226] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1153092: learning rate 0.0010
[2019-03-23 09:19:20,274] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1153121: loss 0.0092
[2019-03-23 09:19:20,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1153123: learning rate 0.0010
[2019-03-23 09:19:20,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1153267: loss 0.0038
[2019-03-23 09:19:20,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1153268: learning rate 0.0010
[2019-03-23 09:19:22,150] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1154106: loss -74.2446
[2019-03-23 09:19:22,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1154107: learning rate 0.0010
[2019-03-23 09:19:27,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2782787e-14 1.0000000e+00 2.5621793e-20 1.8204449e-19 1.5511662e-22], sum to 1.0000
[2019-03-23 09:19:27,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9093
[2019-03-23 09:19:27,565] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4920431996357769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561397.7327374378, 561397.7327374378, 140574.3244553651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3650400.0000, 
sim time next is 3651000.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.6068920639501834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 692512.2736871514, 692512.273687151, 154783.9908583995], 
processed observation next is [1.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.5086150799377291, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2564860272915375, 0.2564860272915374, 0.37752192892292563], 
reward next is 0.6225, 
noisyNet noise sample is [array([0.09825668], dtype=float32), 1.7276862]. 
=============================================
[2019-03-23 09:19:27,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.54481]
 [63.54481]
 [63.54481]
 [63.54481]
 [63.54481]], R is [[63.53184128]
 [63.55365753]
 [63.57201767]
 [63.58926773]
 [63.60470963]].
[2019-03-23 09:19:32,328] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1159482: loss -118.3731
[2019-03-23 09:19:32,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1159482: learning rate 0.0010
[2019-03-23 09:19:32,750] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1159712: loss -79.5439
[2019-03-23 09:19:32,753] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1159713: learning rate 0.0010
[2019-03-23 09:19:32,952] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1159814: loss -126.0739
[2019-03-23 09:19:32,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1159814: learning rate 0.0010
[2019-03-23 09:19:32,983] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1159832: loss -109.4322
[2019-03-23 09:19:32,987] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1159833: learning rate 0.0010
[2019-03-23 09:19:33,268] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1159979: loss -149.6450
[2019-03-23 09:19:33,269] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1159980: learning rate 0.0010
[2019-03-23 09:19:33,500] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160107: loss -102.6116
[2019-03-23 09:19:33,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160107: learning rate 0.0010
[2019-03-23 09:19:33,510] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160109: loss -159.5899
[2019-03-23 09:19:33,512] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160111: learning rate 0.0010
[2019-03-23 09:19:34,123] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160437: loss -86.8982
[2019-03-23 09:19:34,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160439: learning rate 0.0010
[2019-03-23 09:19:34,196] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160472: loss -89.6255
[2019-03-23 09:19:34,199] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160473: learning rate 0.0010
[2019-03-23 09:19:34,280] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160525: loss -93.5182
[2019-03-23 09:19:34,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160525: learning rate 0.0010
[2019-03-23 09:19:34,770] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160780: loss -79.7860
[2019-03-23 09:19:34,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160782: learning rate 0.0010
[2019-03-23 09:19:34,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1005392e-16 1.0000000e+00 7.8754546e-23 3.1946585e-22 1.2149806e-24], sum to 1.0000
[2019-03-23 09:19:34,782] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0403
[2019-03-23 09:19:34,789] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 73.33333333333333, 1.0, 2.0, 0.9215869320267507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1048406.341581432, 1048406.341581432, 196138.5930107475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3764400.0000, 
sim time next is 3765000.0000, 
raw observation next is [21.83333333333333, 78.16666666666667, 1.0, 2.0, 0.9343486238696095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1062363.665334082, 1062363.665334082, 197787.2983314371], 
processed observation next is [1.0, 0.5652173913043478, 0.6287878787878786, 0.7816666666666667, 1.0, 1.0, 0.9179357798370119, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.39346802419780813, 0.39346802419780813, 0.4824080447108222], 
reward next is 0.5176, 
noisyNet noise sample is [array([0.7019653], dtype=float32), 0.2606736]. 
=============================================
[2019-03-23 09:19:34,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.70848]
 [65.70848]
 [65.70848]
 [65.70848]
 [65.70848]], R is [[65.56899261]
 [65.43491364]
 [65.32743835]
 [65.23468781]
 [65.18226624]].
[2019-03-23 09:19:35,309] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1161074: loss -132.8204
[2019-03-23 09:19:35,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1161075: learning rate 0.0010
[2019-03-23 09:19:35,403] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1161136: loss -116.8340
[2019-03-23 09:19:35,406] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1161137: learning rate 0.0010
[2019-03-23 09:19:35,583] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1161236: loss -114.0071
[2019-03-23 09:19:35,584] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1161236: learning rate 0.0010
[2019-03-23 09:19:35,769] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1161356: loss -93.5757
[2019-03-23 09:19:35,770] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1161356: learning rate 0.0010
[2019-03-23 09:19:36,579] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1161790: loss 0.0002
[2019-03-23 09:19:36,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1161791: learning rate 0.0010
[2019-03-23 09:19:40,593] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.8055907e-18 1.0000000e+00 4.6015098e-26 4.9487690e-25 1.7254953e-28], sum to 1.0000
[2019-03-23 09:19:40,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1511
[2019-03-23 09:19:40,603] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 72.33333333333334, 1.0, 2.0, 0.3188533753651672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 352271.2083186514, 352271.2083186514, 114687.7752148493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3917400.0000, 
sim time next is 3918000.0000, 
raw observation next is [20.66666666666667, 71.66666666666667, 1.0, 2.0, 0.325255616702296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360654.1802099556, 360654.1802099556, 115688.3961814225], 
processed observation next is [0.0, 0.34782608695652173, 0.575757575757576, 0.7166666666666667, 1.0, 1.0, 0.15656952087787002, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13357562229998357, 0.13357562229998357, 0.282166819954689], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.3971149], dtype=float32), -0.43869835]. 
=============================================
[2019-03-23 09:19:40,630] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.07534]
 [73.07534]
 [73.07534]
 [73.07534]
 [73.07534]], R is [[73.06242371]
 [73.05207825]
 [73.04441833]
 [73.0395813 ]
 [73.03741455]].
[2019-03-23 09:19:47,207] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6466596e-17 1.0000000e+00 1.6701549e-23 1.5295372e-22 2.0283914e-26], sum to 1.0000
[2019-03-23 09:19:47,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1690
[2019-03-23 09:19:47,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.00000000000001, 1.0, 2.0, 0.6243931698091039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 696419.3434587806, 696419.3434587806, 145154.6080312092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4032600.0000, 
sim time next is 4033200.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.6122883517428549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 682997.7578337253, 682997.757833725, 143813.6139207881], 
processed observation next is [1.0, 0.6956521739130435, 0.45454545454545453, 0.94, 1.0, 1.0, 0.5153604396785686, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25296213253100935, 0.25296213253100924, 0.3507649120019222], 
reward next is 0.6492, 
noisyNet noise sample is [array([-0.80297756], dtype=float32), 1.0475725]. 
=============================================
[2019-03-23 09:19:47,912] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1167537: loss 0.0036
[2019-03-23 09:19:47,913] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1167537: learning rate 0.0010
[2019-03-23 09:19:48,075] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1167619: loss 0.0000
[2019-03-23 09:19:48,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1167619: learning rate 0.0010
[2019-03-23 09:19:48,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1167789: loss 0.0029
[2019-03-23 09:19:48,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1167789: learning rate 0.0010
[2019-03-23 09:19:48,499] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1167832: loss 0.0015
[2019-03-23 09:19:48,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1167832: learning rate 0.0010
[2019-03-23 09:19:48,837] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1167961: loss 0.0014
[2019-03-23 09:19:48,840] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1167962: learning rate 0.0010
[2019-03-23 09:19:49,010] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168056: loss 0.0010
[2019-03-23 09:19:49,013] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168056: learning rate 0.0010
[2019-03-23 09:19:49,033] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168067: loss 0.0002
[2019-03-23 09:19:49,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168067: learning rate 0.0010
[2019-03-23 09:19:49,670] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168382: loss 0.0021
[2019-03-23 09:19:49,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168383: learning rate 0.0010
[2019-03-23 09:19:49,842] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168468: loss 0.0003
[2019-03-23 09:19:49,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168468: learning rate 0.0010
[2019-03-23 09:19:49,996] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168550: loss 0.0012
[2019-03-23 09:19:49,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168550: learning rate 0.0010
[2019-03-23 09:19:50,491] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168790: loss 0.0000
[2019-03-23 09:19:50,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168791: learning rate 0.0010
[2019-03-23 09:19:50,925] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1169010: loss 0.0147
[2019-03-23 09:19:50,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1169013: learning rate 0.0010
[2019-03-23 09:19:51,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8083387e-14 1.0000000e+00 6.1511511e-22 7.6144892e-21 1.0364453e-23], sum to 1.0000
[2019-03-23 09:19:51,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0580
[2019-03-23 09:19:51,075] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 97.0, 1.0, 2.0, 0.3364978791643826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370611.886268155, 370611.8862681552, 115554.324117872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4051800.0000, 
sim time next is 4052400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3336270685226059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366746.3156904154, 366746.3156904157, 115077.1808452933], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 0.96, 1.0, 1.0, 0.16703383565325733, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13583196877422793, 0.13583196877422804, 0.2806760508421788], 
reward next is 0.7193, 
noisyNet noise sample is [array([-1.55843], dtype=float32), -0.66262937]. 
=============================================
[2019-03-23 09:19:51,272] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1169186: loss 0.0016
[2019-03-23 09:19:51,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1169186: learning rate 0.0010
[2019-03-23 09:19:51,366] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1169237: loss 0.0045
[2019-03-23 09:19:51,369] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1169238: learning rate 0.0010
[2019-03-23 09:19:51,796] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1169455: loss 0.0077
[2019-03-23 09:19:51,798] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1169455: learning rate 0.0010
[2019-03-23 09:19:52,673] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1169894: loss -18.3349
[2019-03-23 09:19:52,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1169894: learning rate 0.0010
[2019-03-23 09:19:59,756] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5421183e-16 1.0000000e+00 1.8877447e-24 3.4315790e-23 2.7269803e-26], sum to 1.0000
[2019-03-23 09:19:59,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7828
[2019-03-23 09:19:59,771] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 69.0, 1.0, 2.0, 0.7525142289943096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 852176.7567784578, 852176.7567784581, 167060.9037183096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4267200.0000, 
sim time next is 4267800.0000, 
raw observation next is [23.0, 67.0, 1.0, 2.0, 0.7621733888361939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 863244.364102593, 863244.364102593, 168496.2769590297], 
processed observation next is [1.0, 0.391304347826087, 0.6818181818181818, 0.67, 1.0, 1.0, 0.7027167360452424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31972013485281225, 0.31972013485281225, 0.4109665291683651], 
reward next is 0.5890, 
noisyNet noise sample is [array([-0.22115779], dtype=float32), -0.28479052]. 
=============================================
[2019-03-23 09:20:02,760] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 09:20:02,763] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:20:02,764] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:20:02,765] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:20:02,767] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:20:02,767] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:20:02,769] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:20:02,768] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:20:02,769] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:20:02,769] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:20:02,772] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:20:02,791] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 09:20:02,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 09:20:02,838] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 09:20:02,862] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 09:20:02,884] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 09:20:22,566] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:20:22,567] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.2, 90.0, 1.0, 2.0, 0.3590424282946235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398074.3067851159, 398074.3067851156, 122591.7688217475]
[2019-03-23 09:20:22,568] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:20:22,572] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.6050036673356819
[2019-03-23 09:20:34,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:20:34,066] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.5, 59.0, 1.0, 2.0, 0.3371336967876314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366092.5736023607, 366092.573602361, 84378.46451245506]
[2019-03-23 09:20:34,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:20:34,072] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.5471283072796232
[2019-03-23 09:20:36,320] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:20:36,321] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.08333333333334, 68.66666666666667, 1.0, 2.0, 0.218324349777392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 237035.3649880924, 237035.364988092, 79139.70604054272]
[2019-03-23 09:20:36,322] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:20:36,326] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.8938531177727415
[2019-03-23 09:20:52,740] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:20:52,741] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.97158278666667, 82.85626560500002, 1.0, 2.0, 0.7145083268404164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 802893.2724661834, 802893.272466183, 180194.9835605219]
[2019-03-23 09:20:52,743] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:20:52,746] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.1341985095555308
[2019-03-23 09:21:29,265] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:21:29,265] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.9, 54.0, 1.0, 2.0, 0.3623429489085427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 404289.8229382763, 404289.8229382766, 123919.0004579105]
[2019-03-23 09:21:29,268] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:21:29,272] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.9410788726114573
[2019-03-23 09:21:37,372] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:21:37,373] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.4, 59.5, 1.0, 2.0, 0.3159915212704819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 343103.1561478091, 343103.1561478087, 98392.33292879512]
[2019-03-23 09:21:37,374] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:21:37,377] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.7875386911720194
[2019-03-23 09:21:38,662] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.26799273]
[2019-03-23 09:21:38,663] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.09954413, 88.25402072, 1.0, 2.0, 0.4900320083253155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 558526.6297924725, 558526.6297924725, 145591.1776258141]
[2019-03-23 09:21:38,664] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:21:38,665] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7068875e-16 1.0000000e+00 2.3746924e-23 1.2195649e-22 1.6155477e-25], sampled 0.5007417715290441
[2019-03-23 09:21:44,084] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:21:44,479] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:21:44,604] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:21:44,644] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:21:44,720] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:21:45,733] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1175000, evaluation results [1175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:21:46,711] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1175523: loss -29.8069
[2019-03-23 09:21:46,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1175524: learning rate 0.0010
[2019-03-23 09:21:46,881] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175612: loss -17.5221
[2019-03-23 09:21:46,882] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175612: learning rate 0.0010
[2019-03-23 09:21:47,283] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1175823: loss -29.5478
[2019-03-23 09:21:47,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1175823: learning rate 0.0010
[2019-03-23 09:21:47,314] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1175842: loss -18.6615
[2019-03-23 09:21:47,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1175843: learning rate 0.0010
[2019-03-23 09:21:47,599] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1175996: loss -18.9194
[2019-03-23 09:21:47,607] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1175999: learning rate 0.0010
[2019-03-23 09:21:47,657] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176025: loss -29.8203
[2019-03-23 09:21:47,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176026: learning rate 0.0010
[2019-03-23 09:21:47,673] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176032: loss -18.9966
[2019-03-23 09:21:47,676] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176033: learning rate 0.0010
[2019-03-23 09:21:48,295] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176358: loss -18.3185
[2019-03-23 09:21:48,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176358: learning rate 0.0010
[2019-03-23 09:21:48,465] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176450: loss -15.9193
[2019-03-23 09:21:48,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176450: learning rate 0.0010
[2019-03-23 09:21:48,551] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176491: loss -28.9157
[2019-03-23 09:21:48,552] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176491: learning rate 0.0010
[2019-03-23 09:21:48,838] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176643: loss -28.2063
[2019-03-23 09:21:48,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176643: learning rate 0.0010
[2019-03-23 09:21:49,372] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176929: loss -26.8023
[2019-03-23 09:21:49,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176930: learning rate 0.0010
[2019-03-23 09:21:49,684] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177094: loss -28.6626
[2019-03-23 09:21:49,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177094: learning rate 0.0010
[2019-03-23 09:21:49,773] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1177146: loss -17.8171
[2019-03-23 09:21:49,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1177146: learning rate 0.0010
[2019-03-23 09:21:50,403] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1177474: loss -28.1812
[2019-03-23 09:21:50,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1177477: learning rate 0.0010
[2019-03-23 09:21:51,288] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1177937: loss 0.1107
[2019-03-23 09:21:51,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1177937: learning rate 0.0010
[2019-03-23 09:21:52,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9333607e-15 1.0000000e+00 3.3055383e-21 7.2216947e-21 3.2356948e-23], sum to 1.0000
[2019-03-23 09:21:52,605] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0623
[2019-03-23 09:21:52,615] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4078241235968862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462148.5021010289, 462148.5021010286, 127082.7944508396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4429200.0000, 
sim time next is 4429800.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4079080130636096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 462244.7672001362, 462244.7672001359, 127091.4748585817], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 0.83, 1.0, 1.0, 0.25988501632951194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17120176562968006, 0.17120176562967998, 0.3099792069721505], 
reward next is 0.6900, 
noisyNet noise sample is [array([-0.14591128], dtype=float32), -0.6582087]. 
=============================================
[2019-03-23 09:21:52,759] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5719670e-15 1.0000000e+00 8.2821023e-24 2.1575033e-22 5.9436306e-26], sum to 1.0000
[2019-03-23 09:21:52,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1519
[2019-03-23 09:21:52,769] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4490454020754537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511970.8956891022, 511970.8956891022, 133929.7934511263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4438200.0000, 
sim time next is 4438800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4507269448755032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513946.6334416406, 513946.6334416409, 134206.9373651471], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.31340868109437897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1903506049783854, 0.19035060497838552, 0.32733399357352955], 
reward next is 0.6727, 
noisyNet noise sample is [array([-0.21378703], dtype=float32), 2.5738983]. 
=============================================
[2019-03-23 09:21:54,993] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7272246e-15 1.0000000e+00 6.6577102e-21 1.5766826e-21 1.1149373e-24], sum to 1.0000
[2019-03-23 09:21:55,002] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1992
[2019-03-23 09:21:55,009] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 71.0, 1.0, 2.0, 0.5076439520748703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 578809.8663326061, 578809.8663326061, 143180.5651244081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4458000.0000, 
sim time next is 4458600.0000, 
raw observation next is [25.5, 69.5, 1.0, 2.0, 0.5045709278500302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 575405.9876583479, 575405.9876583479, 142668.4061757458], 
processed observation next is [0.0, 0.6086956521739131, 0.7954545454545454, 0.695, 1.0, 1.0, 0.38071365981253774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2131133287623511, 0.2131133287623511, 0.3479717223798678], 
reward next is 0.6520, 
noisyNet noise sample is [array([0.3935421], dtype=float32), -0.46989322]. 
=============================================
[2019-03-23 09:21:58,404] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7429060e-15 1.0000000e+00 3.1049950e-20 8.7525305e-21 4.1630888e-24], sum to 1.0000
[2019-03-23 09:21:58,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7476
[2019-03-23 09:21:58,421] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3927955181827669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 444075.3252049162, 444075.3252049159, 125021.3483500547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4557000.0000, 
sim time next is 4557600.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.394285823898136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445763.2176520425, 445763.2176520422, 125158.3583429876], 
processed observation next is [0.0, 0.782608695652174, 0.7272727272727273, 0.61, 1.0, 1.0, 0.24285727987266997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.165097488019275, 0.1650974880192749, 0.3052642886414332], 
reward next is 0.6947, 
noisyNet noise sample is [array([-0.47611514], dtype=float32), -0.9369853]. 
=============================================
[2019-03-23 09:22:01,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1183503: loss 0.0323
[2019-03-23 09:22:01,728] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1183504: learning rate 0.0010
[2019-03-23 09:22:01,808] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1183552: loss 0.0326
[2019-03-23 09:22:01,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1183554: learning rate 0.0010
[2019-03-23 09:22:02,273] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1183795: loss 0.0216
[2019-03-23 09:22:02,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1183795: learning rate 0.0010
[2019-03-23 09:22:02,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0898214e-17 1.0000000e+00 1.9891238e-23 2.6850241e-23 1.5151032e-26], sum to 1.0000
[2019-03-23 09:22:02,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8626
[2019-03-23 09:22:02,290] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.2559361851779284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 277895.221721975, 277895.221721975, 87053.60592672617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4666200.0000, 
sim time next is 4666800.0000, 
raw observation next is [16.66666666666667, 78.66666666666667, 1.0, 2.0, 0.2536636150107132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275426.9688878052, 275426.9688878055, 86317.61658419481], 
processed observation next is [1.0, 0.0, 0.39393939393939414, 0.7866666666666667, 1.0, 1.0, 0.06707951876339151, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10200998847696488, 0.10200998847696499, 0.2105307721565727], 
reward next is 0.7895, 
noisyNet noise sample is [array([-0.78727233], dtype=float32), 0.04680297]. 
=============================================
[2019-03-23 09:22:02,426] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1183878: loss 0.0062
[2019-03-23 09:22:02,428] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1183878: learning rate 0.0010
[2019-03-23 09:22:02,626] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1183984: loss 0.0082
[2019-03-23 09:22:02,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1183985: learning rate 0.0010
[2019-03-23 09:22:02,737] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184035: loss 0.0011
[2019-03-23 09:22:02,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184036: learning rate 0.0010
[2019-03-23 09:22:02,847] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1184099: loss 0.0097
[2019-03-23 09:22:02,848] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1184099: learning rate 0.0010
[2019-03-23 09:22:03,480] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184430: loss 0.0032
[2019-03-23 09:22:03,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184430: learning rate 0.0010
[2019-03-23 09:22:03,664] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184530: loss 0.0073
[2019-03-23 09:22:03,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184530: learning rate 0.0010
[2019-03-23 09:22:03,774] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184587: loss 0.0070
[2019-03-23 09:22:03,777] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184588: learning rate 0.0010
[2019-03-23 09:22:03,940] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184674: loss 0.0025
[2019-03-23 09:22:03,942] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184674: learning rate 0.0010
[2019-03-23 09:22:04,625] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1185047: loss 0.0032
[2019-03-23 09:22:04,630] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1185047: learning rate 0.0010
[2019-03-23 09:22:04,670] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185066: loss 0.0071
[2019-03-23 09:22:04,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185066: learning rate 0.0010
[2019-03-23 09:22:04,838] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1185151: loss 0.0025
[2019-03-23 09:22:04,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1185152: learning rate 0.0010
[2019-03-23 09:22:05,693] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1185600: loss 0.0383
[2019-03-23 09:22:05,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1185601: learning rate 0.0010
[2019-03-23 09:22:06,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1186008: loss 0.0120
[2019-03-23 09:22:06,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1186009: learning rate 0.0010
[2019-03-23 09:22:07,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1458732e-15 1.0000000e+00 1.4573970e-22 6.2096434e-22 3.2509978e-24], sum to 1.0000
[2019-03-23 09:22:07,627] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4528
[2019-03-23 09:22:07,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1084155.74380475 W.
[2019-03-23 09:22:07,643] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 53.5, 1.0, 2.0, 0.953192840070028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1084155.74380475, 1084155.74380475, 201299.9116200556], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4715400.0000, 
sim time next is 4716000.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.456474660735344, 1.0, 1.0, 0.456474660735344, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1041844.941124577, 1041844.941124577, 213769.185919285], 
processed observation next is [1.0, 0.6086956521739131, 0.8181818181818182, 0.54, 1.0, 1.0, 0.32059332591917994, 1.0, 0.5, 0.32059332591917994, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38586849671280626, 0.38586849671280626, 0.5213882583397195], 
reward next is 0.4786, 
noisyNet noise sample is [array([0.9301384], dtype=float32), -0.96584004]. 
=============================================
[2019-03-23 09:22:07,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.78955]
 [67.78955]
 [67.78955]
 [67.78955]
 [67.78955]], R is [[67.59027863]
 [67.42340088]
 [67.2641983 ]
 [67.11775208]
 [67.02603912]].
[2019-03-23 09:22:07,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2788023e-15 1.0000000e+00 4.6556183e-22 2.1889391e-22 1.9834336e-23], sum to 1.0000
[2019-03-23 09:22:07,942] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9955
[2019-03-23 09:22:07,945] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4954007559871142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561752.2466626638, 561752.2466626638, 136056.625884002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4781400.0000, 
sim time next is 4782000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6563391966367967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744660.4840142245, 744660.4840142247, 155151.8566806336], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.5704239957959959, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2758001792645276, 0.27580017926452766, 0.3784191626356917], 
reward next is 0.6216, 
noisyNet noise sample is [array([0.84705377], dtype=float32), 0.38291305]. 
=============================================
[2019-03-23 09:22:07,957] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.12437]
 [68.12437]
 [68.12437]
 [68.12437]
 [68.12437]], R is [[68.06469727]
 [68.05220032]
 [68.05505371]
 [68.06083679]
 [68.06394958]].
[2019-03-23 09:22:17,029] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1191441: loss 0.0044
[2019-03-23 09:22:17,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1191441: learning rate 0.0010
[2019-03-23 09:22:17,191] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1191523: loss 0.0015
[2019-03-23 09:22:17,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1191523: learning rate 0.0010
[2019-03-23 09:22:17,672] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1191771: loss 0.0067
[2019-03-23 09:22:17,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1191773: learning rate 0.0010
[2019-03-23 09:22:17,813] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1191842: loss 0.0018
[2019-03-23 09:22:17,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1191842: learning rate 0.0010
[2019-03-23 09:22:17,910] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1191895: loss 0.0003
[2019-03-23 09:22:17,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1191895: learning rate 0.0010
[2019-03-23 09:22:18,190] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1192036: loss 0.0097
[2019-03-23 09:22:18,192] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1192037: learning rate 0.0010
[2019-03-23 09:22:18,267] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192074: loss 0.0165
[2019-03-23 09:22:18,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192074: learning rate 0.0010
[2019-03-23 09:22:19,150] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192524: loss 0.0003
[2019-03-23 09:22:19,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192525: learning rate 0.0010
[2019-03-23 09:22:19,159] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192528: loss 0.0004
[2019-03-23 09:22:19,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192528: learning rate 0.0010
[2019-03-23 09:22:19,321] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192609: loss 0.0018
[2019-03-23 09:22:19,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192611: learning rate 0.0010
[2019-03-23 09:22:19,500] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192697: loss 0.0026
[2019-03-23 09:22:19,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192699: learning rate 0.0010
[2019-03-23 09:22:20,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6050967e-15 1.0000000e+00 6.9306088e-22 4.7361189e-22 1.0871340e-24], sum to 1.0000
[2019-03-23 09:22:20,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1127
[2019-03-23 09:22:20,174] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 64.0, 1.0, 2.0, 0.2855333238258375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 310042.00522192, 310042.00522192, 98184.07417188774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4991400.0000, 
sim time next is 4992000.0000, 
raw observation next is [19.33333333333334, 65.33333333333333, 1.0, 2.0, 0.284430470788518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308844.1088187675, 308844.1088187672, 98454.42325449373], 
processed observation next is [1.0, 0.782608695652174, 0.5151515151515155, 0.6533333333333333, 1.0, 1.0, 0.10553808848564751, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11438670696991388, 0.11438670696991378, 0.24013273964510665], 
reward next is 0.7599, 
noisyNet noise sample is [array([-0.95591086], dtype=float32), 0.5946252]. 
=============================================
[2019-03-23 09:22:20,184] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1193045: loss 0.0015
[2019-03-23 09:22:20,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1193045: learning rate 0.0010
[2019-03-23 09:22:20,196] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.13716]
 [72.13716]
 [72.13716]
 [72.13716]
 [72.13716]], R is [[72.17565155]
 [72.21442413]
 [72.25376129]
 [72.29405975]
 [72.33531189]].
[2019-03-23 09:22:20,412] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1193152: loss 0.0026
[2019-03-23 09:22:20,413] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1193152: learning rate 0.0010
[2019-03-23 09:22:20,474] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193189: loss 0.0016
[2019-03-23 09:22:20,476] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193189: learning rate 0.0010
[2019-03-23 09:22:21,307] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1193604: loss 0.0147
[2019-03-23 09:22:21,310] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1193606: learning rate 0.0010
[2019-03-23 09:22:21,934] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1193923: loss 0.1009
[2019-03-23 09:22:21,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1193924: learning rate 0.0010
[2019-03-23 09:22:23,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2115528e-17 1.0000000e+00 3.9535500e-24 6.1349315e-23 3.4002743e-26], sum to 1.0000
[2019-03-23 09:22:23,965] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9733
[2019-03-23 09:22:23,971] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 67.66666666666667, 1.0, 2.0, 0.36175519155054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406227.5727647666, 406227.5727647663, 120756.9627746182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5047800.0000, 
sim time next is 5048400.0000, 
raw observation next is [22.33333333333334, 66.33333333333334, 1.0, 2.0, 0.3623915195214751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406791.9066111686, 406791.9066111686, 120735.8066152776], 
processed observation next is [0.0, 0.43478260869565216, 0.6515151515151518, 0.6633333333333334, 1.0, 1.0, 0.20298939940184382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15066366911524762, 0.15066366911524762, 0.29447757711043315], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.15180498], dtype=float32), -1.5862393]. 
=============================================
[2019-03-23 09:22:29,971] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1564253e-16 1.0000000e+00 1.3729315e-22 5.0351554e-21 2.8956916e-24], sum to 1.0000
[2019-03-23 09:22:29,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4702
[2019-03-23 09:22:29,989] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4308359050608702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490849.1951359095, 490849.1951359095, 131532.1677195505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5202000.0000, 
sim time next is 5202600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4663719618646605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531373.0217937328, 531373.0217937328, 135247.897639678], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3329649523308256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1968048228865677, 0.1968048228865677, 0.32987292107238536], 
reward next is 0.6701, 
noisyNet noise sample is [array([-1.040849], dtype=float32), -0.22740148]. 
=============================================
[2019-03-23 09:22:32,556] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8018337e-15 1.0000000e+00 2.5523727e-22 3.5697771e-22 6.9972270e-24], sum to 1.0000
[2019-03-23 09:22:32,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2340
[2019-03-23 09:22:32,575] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.425823553951088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 485133.3766844978, 485133.3766844981, 131022.1868437692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5204400.0000, 
sim time next is 5205000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.424997579745768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484190.6087238663, 484190.6087238663, 130937.3756082425], 
processed observation next is [1.0, 0.21739130434782608, 0.6363636363636364, 0.83, 1.0, 1.0, 0.28124697468221, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17932985508291344, 0.17932985508291344, 0.31935945270303046], 
reward next is 0.6806, 
noisyNet noise sample is [array([1.0689838], dtype=float32), 2.1973653]. 
=============================================
[2019-03-23 09:22:32,593] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.692215]
 [64.692215]
 [64.692215]
 [64.692215]
 [64.692215]], R is [[64.72594452]
 [64.75911713]
 [64.79158783]
 [64.82123566]
 [64.84315491]].
[2019-03-23 09:22:32,819] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1199428: loss 0.0002
[2019-03-23 09:22:32,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1199428: learning rate 0.0010
[2019-03-23 09:22:32,969] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1199503: loss 0.0011
[2019-03-23 09:22:32,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1199503: learning rate 0.0010
[2019-03-23 09:22:33,303] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4185317e-13 1.0000000e+00 1.4051432e-19 1.2628139e-20 1.5286396e-21], sum to 1.0000
[2019-03-23 09:22:33,307] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8629
[2019-03-23 09:22:33,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1134650.420797828 W.
[2019-03-23 09:22:33,323] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.3340133110437516, 1.0, 1.0, 0.3340133110437516, 1.0, 2.0, 0.6762787886798763, 6.911199999999999, 6.9112, 77.3421103, 1134650.420797828, 1134650.420797828, 274776.3317706803], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5245200.0000, 
sim time next is 5245800.0000, 
raw observation next is [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.3369682630215659, 1.0, 2.0, 0.3369682630215659, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846330059331, 764172.4877734858, 764172.4877734861, 197182.2664542971], 
processed observation next is [1.0, 0.7391304347826086, 0.6742424242424245, 0.8983333333333334, 1.0, 1.0, 0.17121032877695735, 1.0, 1.0, 0.17121032877695735, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288119807836, 0.2830268473235133, 0.28302684732351335, 0.4809323572056027], 
reward next is 0.5191, 
noisyNet noise sample is [array([-1.3583038], dtype=float32), 0.9455843]. 
=============================================
[2019-03-23 09:22:33,537] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1199782: loss 0.0023
[2019-03-23 09:22:33,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1199784: learning rate 0.0010
[2019-03-23 09:22:33,669] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1199850: loss 0.0005
[2019-03-23 09:22:33,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1199850: learning rate 0.0010
[2019-03-23 09:22:33,883] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1199956: loss 0.0000
[2019-03-23 09:22:33,885] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1199956: learning rate 0.0010
[2019-03-23 09:22:33,967] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 09:22:33,969] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:22:33,970] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:33,970] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:22:33,971] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:33,971] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:22:33,972] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:22:33,972] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:33,973] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:22:33,975] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200000: loss 0.0034
[2019-03-23 09:22:33,977] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:33,973] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:22:33,979] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200000: learning rate 0.0010
[2019-03-23 09:22:33,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 09:22:34,015] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 09:22:34,034] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 09:22:34,074] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 09:22:34,095] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 09:22:40,824] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:22:40,825] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.325980867, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 178623.4204479287, 178623.420447928, 69558.64929296687]
[2019-03-23 09:22:40,826] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:22:40,829] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.18525970505474942
[2019-03-23 09:22:45,616] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:22:45,617] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.32637557, 93.62435873999999, 1.0, 2.0, 0.3664439244178596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 409352.0196202776, 409352.0196202769, 124469.0540282727]
[2019-03-23 09:22:45,619] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:22:45,625] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.9933814075464544
[2019-03-23 09:23:14,211] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:23:14,213] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [28.28333333333333, 46.83333333333334, 1.0, 2.0, 0.5394952440617621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 614772.7811921664, 614772.781192166, 147862.3937653269]
[2019-03-23 09:23:14,215] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:23:14,221] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.13582746170663584
[2019-03-23 09:23:32,389] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:23:32,390] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [30.08333333333334, 47.83333333333333, 1.0, 2.0, 0.6104013102843915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 695544.2890085311, 695544.2890085308, 160933.0993653514]
[2019-03-23 09:23:32,392] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:23:32,394] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.23678984865462427
[2019-03-23 09:23:41,579] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:23:41,581] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.4006557242413041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438673.1984432286, 438673.1984432283, 119675.6506247765]
[2019-03-23 09:23:41,582] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:23:41,586] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.9231631356641872
[2019-03-23 09:23:55,340] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:23:55,342] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.33333333333334, 58.33333333333334, 1.0, 2.0, 0.3815385482911263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 426847.8089124289, 426847.8089124285, 126010.6176897282]
[2019-03-23 09:23:55,343] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:23:55,345] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.9856080671381771
[2019-03-23 09:24:05,885] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30886132]
[2019-03-23 09:24:05,886] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.06708644666667, 87.39732934, 1.0, 2.0, 0.4322659680750375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 491449.9280929166, 491449.9280929162, 134968.1794667571]
[2019-03-23 09:24:05,886] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:24:05,888] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.8694015e-15 1.0000000e+00 8.5299992e-22 4.1824671e-21 8.6726516e-24], sampled 0.3557017989072473
[2019-03-23 09:24:15,465] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:24:15,596] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:24:15,645] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:24:15,758] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:24:15,764] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:24:16,778] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1200000, evaluation results [1200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:24:16,856] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200039: loss 0.0000
[2019-03-23 09:24:16,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200039: learning rate 0.0010
[2019-03-23 09:24:17,732] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200505: loss 0.0001
[2019-03-23 09:24:17,734] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200505: learning rate 0.0010
[2019-03-23 09:24:17,781] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200532: loss 0.0007
[2019-03-23 09:24:17,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200532: learning rate 0.0010
[2019-03-23 09:24:17,952] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200621: loss 0.0010
[2019-03-23 09:24:17,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200621: learning rate 0.0010
[2019-03-23 09:24:18,021] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200656: loss 0.0007
[2019-03-23 09:24:18,024] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200657: learning rate 0.0010
[2019-03-23 09:24:18,775] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1201057: loss 0.0006
[2019-03-23 09:24:18,779] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1201058: learning rate 0.0010
[2019-03-23 09:24:18,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1201097: loss 0.0038
[2019-03-23 09:24:18,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1201098: learning rate 0.0010
[2019-03-23 09:24:19,108] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201236: loss 0.0000
[2019-03-23 09:24:19,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201236: learning rate 0.0010
[2019-03-23 09:24:19,831] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1201622: loss 0.0006
[2019-03-23 09:24:19,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1201622: learning rate 0.0010
[2019-03-23 09:24:20,585] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1202020: loss 0.0136
[2019-03-23 09:24:20,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1202021: learning rate 0.0010
[2019-03-23 09:24:24,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1155659e-11 1.0000000e+00 1.9502307e-19 4.4607689e-19 4.2771276e-22], sum to 1.0000
[2019-03-23 09:24:24,878] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3837
[2019-03-23 09:24:24,881] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 90.0, 1.0, 2.0, 0.9410946810984743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354101, 1067990.152804371, 1067990.152804371, 197315.3778811355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5415600.0000, 
sim time next is 5416200.0000, 
raw observation next is [20.0, 90.0, 1.0, 2.0, 0.9464176162157554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1074126.916844031, 1074126.916844032, 198276.2786612254], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.9, 1.0, 1.0, 0.9330220202696943, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.39782478401630783, 0.39782478401630816, 0.48360067966152537], 
reward next is 0.5164, 
noisyNet noise sample is [array([-0.66304827], dtype=float32), 1.5316509]. 
=============================================
[2019-03-23 09:24:27,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3038011e-15 1.0000000e+00 9.0331465e-23 6.3166049e-22 1.1133308e-24], sum to 1.0000
[2019-03-23 09:24:27,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3299
[2019-03-23 09:24:27,319] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 94.0, 1.0, 2.0, 0.3281863309524263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 360210.3849008055, 360210.3849008052, 114473.0703574719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5467200.0000, 
sim time next is 5467800.0000, 
raw observation next is [17.2, 95.0, 1.0, 2.0, 0.3269762733194131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 359575.7567413406, 359575.7567413409, 114643.2848225369], 
processed observation next is [1.0, 0.2608695652173913, 0.41818181818181815, 0.95, 1.0, 1.0, 0.15872034164926635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13317620620049653, 0.13317620620049664, 0.2796177678598461], 
reward next is 0.7204, 
noisyNet noise sample is [array([0.06604033], dtype=float32), -1.8795807]. 
=============================================
[2019-03-23 09:24:30,606] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1207360: loss 0.0062
[2019-03-23 09:24:30,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1207362: learning rate 0.0010
[2019-03-23 09:24:30,871] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1207501: loss 0.0005
[2019-03-23 09:24:30,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1207501: learning rate 0.0010
[2019-03-23 09:24:30,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6588844e-15 1.0000000e+00 5.7692208e-22 1.0262459e-19 5.3038956e-23], sum to 1.0000
[2019-03-23 09:24:30,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7126
[2019-03-23 09:24:30,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1536663.914937605 W.
[2019-03-23 09:24:30,951] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 69.0, 1.0, 2.0, 0.4554545753790623, 1.0, 2.0, 0.4554545753790623, 1.0, 1.0, 0.9215574207402565, 6.911199999999999, 6.9112, 77.3421103, 1536663.914937605, 1536663.914937605, 335626.2759023585], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5496000.0000, 
sim time next is 5496600.0000, 
raw observation next is [27.1, 69.0, 1.0, 2.0, 0.4585767216295117, 1.0, 2.0, 0.4585767216295117, 1.0, 2.0, 0.9278747072519649, 6.911199999999999, 6.9112, 77.3421103, 1547212.155776028, 1547212.155776028, 337316.3450637101], 
processed observation next is [1.0, 0.6086956521739131, 0.8681818181818183, 0.69, 1.0, 1.0, 0.3232209020368896, 1.0, 1.0, 0.3232209020368896, 1.0, 1.0, 0.896963867502807, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5730415391763067, 0.5730415391763067, 0.8227227928383174], 
reward next is 0.1773, 
noisyNet noise sample is [array([1.2724135], dtype=float32), 0.21043602]. 
=============================================
[2019-03-23 09:24:31,262] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1207705: loss 0.0012
[2019-03-23 09:24:31,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1207706: learning rate 0.0010
[2019-03-23 09:24:31,655] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1207911: loss 0.0001
[2019-03-23 09:24:31,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1207911: learning rate 0.0010
[2019-03-23 09:24:31,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1207963: loss 0.0079
[2019-03-23 09:24:31,748] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1207965: learning rate 0.0010
[2019-03-23 09:24:31,767] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1207973: loss 0.0006
[2019-03-23 09:24:31,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1207973: learning rate 0.0010
[2019-03-23 09:24:31,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208050: loss 0.0010
[2019-03-23 09:24:31,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208050: learning rate 0.0010
[2019-03-23 09:24:32,706] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208475: loss 0.0316
[2019-03-23 09:24:32,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208476: learning rate 0.0010
[2019-03-23 09:24:32,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0578174e-14 1.0000000e+00 8.6723960e-22 6.6629439e-21 8.6838408e-24], sum to 1.0000
[2019-03-23 09:24:32,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7404
[2019-03-23 09:24:32,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1144088.578037101 W.
[2019-03-23 09:24:32,767] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.88333333333333, 60.0, 1.0, 2.0, 0.3383490955332255, 1.0, 2.0, 0.3383490955332255, 1.0, 2.0, 0.6840478926645719, 6.911199999999999, 6.9112, 77.3421103, 1144088.578037101, 1144088.578037101, 278394.1172615816], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5577000.0000, 
sim time next is 5577600.0000, 
raw observation next is [28.06666666666667, 59.0, 1.0, 2.0, 0.6850081633423951, 0.0, 1.0, 0.0, 1.0, 2.0, 0.978648184391626, 6.9112, 6.9112, 77.32846344354104, 1325500.10510516, 1325500.10510516, 291135.0973442623], 
processed observation next is [1.0, 0.5652173913043478, 0.9121212121212122, 0.59, 1.0, 1.0, 0.6062602041779939, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9694974062737517, 0.0, 0.0, 0.5084288129206541, 0.490925964853763, 0.490925964853763, 0.7100856032786885], 
reward next is 0.2899, 
noisyNet noise sample is [array([3.4251287], dtype=float32), 0.35536095]. 
=============================================
[2019-03-23 09:24:32,844] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208550: loss 0.0205
[2019-03-23 09:24:32,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208551: learning rate 0.0010
[2019-03-23 09:24:32,887] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208569: loss 0.0128
[2019-03-23 09:24:32,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208569: learning rate 0.0010
[2019-03-23 09:24:32,987] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208623: loss 0.0091
[2019-03-23 09:24:32,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208623: learning rate 0.0010
[2019-03-23 09:24:33,740] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1209023: loss 0.0115
[2019-03-23 09:24:33,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1209023: learning rate 0.0010
[2019-03-23 09:24:33,915] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1209115: loss 0.0057
[2019-03-23 09:24:33,920] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1209116: learning rate 0.0010
[2019-03-23 09:24:34,038] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209180: loss 0.0003
[2019-03-23 09:24:34,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209183: learning rate 0.0010
[2019-03-23 09:24:34,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1199036e-15 1.0000000e+00 1.7999070e-21 7.1452931e-22 2.3787463e-22], sum to 1.0000
[2019-03-23 09:24:34,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2600
[2019-03-23 09:24:34,255] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 92.0, 1.0, 2.0, 0.4192411589675644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 475773.4984225266, 475773.4984225263, 128644.4853843624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4212428746749354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478161.3394232859, 478161.3394232859, 128923.7347220462], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.93, 1.0, 1.0, 0.2765535933436692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17709679237899478, 0.17709679237899478, 0.31444813346840533], 
reward next is 0.6856, 
noisyNet noise sample is [array([-1.0622493], dtype=float32), 0.64159274]. 
=============================================
[2019-03-23 09:24:34,713] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1209533: loss 0.0013
[2019-03-23 09:24:34,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1209534: learning rate 0.0010
[2019-03-23 09:24:35,280] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1209838: loss 0.0134
[2019-03-23 09:24:35,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1209838: learning rate 0.0010
[2019-03-23 09:24:36,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.01754683e-19 1.00000000e+00 3.66706607e-24 1.27112005e-23
 2.81655082e-26], sum to 1.0000
[2019-03-23 09:24:36,089] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4686
[2019-03-23 09:24:36,093] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4288550167658048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487824.7276806809, 487824.7276806812, 130509.2510336262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5622600.0000, 
sim time next is 5623200.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4285491876280844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487476.4004411264, 487476.4004411267, 130478.5189374761], 
processed observation next is [0.0, 0.08695652173913043, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2856864845351055, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18054681497819494, 0.18054681497819508, 0.3182402900914051], 
reward next is 0.6818, 
noisyNet noise sample is [array([-0.53385335], dtype=float32), -2.0891864]. 
=============================================
[2019-03-23 09:24:37,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1345879e-16 1.0000000e+00 1.1413039e-23 7.3581940e-24 4.6343259e-27], sum to 1.0000
[2019-03-23 09:24:37,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2148
[2019-03-23 09:24:37,133] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.7, 86.66666666666667, 1.0, 2.0, 0.2497257116065806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271150.01674923, 271150.0167492303, 85482.47477309477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5665200.0000, 
sim time next is 5665800.0000, 
raw observation next is [15.6, 86.83333333333333, 1.0, 2.0, 0.2470333098154122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 268225.8240589416, 268225.8240589419, 84621.62668347491], 
processed observation next is [0.0, 0.5652173913043478, 0.34545454545454546, 0.8683333333333333, 1.0, 1.0, 0.05879163726926522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.099342897799608, 0.09934289779960812, 0.20639421142310954], 
reward next is 0.7936, 
noisyNet noise sample is [array([-0.76336944], dtype=float32), 1.7944345]. 
=============================================
[2019-03-23 09:24:37,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3590599e-15 1.0000000e+00 8.6517673e-24 6.2900796e-23 1.1770786e-24], sum to 1.0000
[2019-03-23 09:24:37,554] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7055
[2019-03-23 09:24:37,558] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 96.33333333333333, 1.0, 2.0, 0.4035502777978255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 456784.9907222936, 456784.9907222939, 126342.5885597562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5628000.0000, 
sim time next is 5628600.0000, 
raw observation next is [19.1, 96.5, 1.0, 2.0, 0.4004478761343627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452963.2394714696, 452963.2394714699, 125862.0675320908], 
processed observation next is [0.0, 0.13043478260869565, 0.5045454545454546, 0.965, 1.0, 1.0, 0.2505598451679534, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16776416276721096, 0.16776416276721107, 0.30698065251729467], 
reward next is 0.6930, 
noisyNet noise sample is [array([0.715789], dtype=float32), 1.1833647]. 
=============================================
[2019-03-23 09:24:39,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3989983e-17 1.0000000e+00 3.9357507e-23 4.6212209e-22 2.5911093e-25], sum to 1.0000
[2019-03-23 09:24:39,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3102
[2019-03-23 09:24:39,696] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.13333333333333, 64.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 203655.6813480069, 203655.6813480066, 67667.65666117522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5734200.0000, 
sim time next is 5734800.0000, 
raw observation next is [15.5, 62.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 212319.0148919458, 212319.0148919461, 69250.25654579702], 
processed observation next is [0.0, 0.391304347826087, 0.3409090909090909, 0.62, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07863667218220215, 0.07863667218220226, 0.16890306474584638], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.151634], dtype=float32), 0.6362036]. 
=============================================
[2019-03-23 09:24:42,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2719905e-14 1.0000000e+00 3.5713298e-22 3.1751984e-20 1.5063796e-24], sum to 1.0000
[2019-03-23 09:24:42,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8470
[2019-03-23 09:24:42,573] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 48.16666666666667, 1.0, 2.0, 0.2613452722473595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 283770.1157949906, 283770.1157949909, 84459.03156170135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5770200.0000, 
sim time next is 5770800.0000, 
raw observation next is [20.5, 49.0, 1.0, 2.0, 0.2596190249128819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 281895.2038535417, 281895.2038535417, 84106.78456096363], 
processed observation next is [0.0, 0.8260869565217391, 0.5681818181818182, 0.49, 1.0, 1.0, 0.07452378114110238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10440563105686729, 0.10440563105686729, 0.20513849892917957], 
reward next is 0.7949, 
noisyNet noise sample is [array([0.5616914], dtype=float32), -0.04908027]. 
=============================================
[2019-03-23 09:24:46,190] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1215427: loss 0.0311
[2019-03-23 09:24:46,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1215428: learning rate 0.0010
[2019-03-23 09:24:46,284] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1215475: loss 0.0155
[2019-03-23 09:24:46,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1215476: learning rate 0.0010
[2019-03-23 09:24:46,665] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1215668: loss 0.0001
[2019-03-23 09:24:46,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1215668: learning rate 0.0010
[2019-03-23 09:24:47,123] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1215902: loss 0.0012
[2019-03-23 09:24:47,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1215903: learning rate 0.0010
[2019-03-23 09:24:47,137] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1215907: loss 0.0002
[2019-03-23 09:24:47,140] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1215907: learning rate 0.0010
[2019-03-23 09:24:47,177] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1215925: loss 0.0002
[2019-03-23 09:24:47,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1215926: learning rate 0.0010
[2019-03-23 09:24:47,358] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216017: loss 0.0006
[2019-03-23 09:24:47,359] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216017: learning rate 0.0010
[2019-03-23 09:24:48,264] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216474: loss 0.0003
[2019-03-23 09:24:48,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216475: learning rate 0.0010
[2019-03-23 09:24:48,388] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216539: loss 0.0037
[2019-03-23 09:24:48,393] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216541: learning rate 0.0010
[2019-03-23 09:24:48,508] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216601: loss 0.0009
[2019-03-23 09:24:48,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216602: learning rate 0.0010
[2019-03-23 09:24:48,749] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216722: loss 0.0004
[2019-03-23 09:24:48,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216723: learning rate 0.0010
[2019-03-23 09:24:49,467] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1217092: loss 0.0003
[2019-03-23 09:24:49,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1217092: learning rate 0.0010
[2019-03-23 09:24:49,691] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1217204: loss 0.0002
[2019-03-23 09:24:49,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1217204: learning rate 0.0010
[2019-03-23 09:24:49,782] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217250: loss 0.0000
[2019-03-23 09:24:49,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217250: learning rate 0.0010
[2019-03-23 09:24:49,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9524595e-19 1.0000000e+00 6.3846380e-27 7.8786243e-27 7.9754408e-29], sum to 1.0000
[2019-03-23 09:24:49,806] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1191
[2019-03-23 09:24:49,811] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 52.66666666666666, 1.0, 2.0, 0.7891931938302611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 897760.8993709072, 897760.8993709072, 175212.6893074002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5922600.0000, 
sim time next is 5923200.0000, 
raw observation next is [26.63333333333333, 51.33333333333334, 1.0, 2.0, 0.8416515846493249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 957670.7667713922, 957670.7667713922, 183413.5136719242], 
processed observation next is [1.0, 0.5652173913043478, 0.8469696969696968, 0.5133333333333334, 1.0, 1.0, 0.8020644808116562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3546928765819971, 0.3546928765819971, 0.44735003334615653], 
reward next is 0.5526, 
noisyNet noise sample is [array([0.9131251], dtype=float32), 1.3759887]. 
=============================================
[2019-03-23 09:24:50,370] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1217548: loss 0.0033
[2019-03-23 09:24:50,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1217548: learning rate 0.0010
[2019-03-23 09:24:51,341] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1218042: loss 0.0409
[2019-03-23 09:24:51,344] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1218043: learning rate 0.0010
[2019-03-23 09:24:57,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.39133602e-16 1.00000000e+00 1.00032075e-22 4.70697209e-24
 5.52062179e-26], sum to 1.0000
[2019-03-23 09:24:57,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6372
[2019-03-23 09:24:57,594] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.65, 82.5, 1.0, 2.0, 0.2089646292780097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 226881.6637041137, 226881.663704114, 74261.40928895352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6060600.0000, 
sim time next is 6061200.0000, 
raw observation next is [14.36666666666667, 84.0, 1.0, 2.0, 0.2053985001978001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 223008.8801624471, 223008.8801624473, 73545.0694702467], 
processed observation next is [1.0, 0.13043478260869565, 0.2893939393939396, 0.84, 1.0, 1.0, 0.006748125247250103, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08259588154164708, 0.08259588154164715, 0.1793782182201139], 
reward next is 0.8206, 
noisyNet noise sample is [array([-1.5161046], dtype=float32), 0.8762195]. 
=============================================
[2019-03-23 09:25:02,080] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1223441: loss 0.0047
[2019-03-23 09:25:02,088] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1223442: learning rate 0.0010
[2019-03-23 09:25:02,178] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1223486: loss 0.0096
[2019-03-23 09:25:02,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1223486: learning rate 0.0010
[2019-03-23 09:25:02,634] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1223716: loss 0.0047
[2019-03-23 09:25:02,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1223716: learning rate 0.0010
[2019-03-23 09:25:02,947] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1223876: loss 0.0014
[2019-03-23 09:25:02,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1223876: learning rate 0.0010
[2019-03-23 09:25:02,956] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1223879: loss 0.0008
[2019-03-23 09:25:02,958] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1223879: learning rate 0.0010
[2019-03-23 09:25:03,017] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1223907: loss 0.0053
[2019-03-23 09:25:03,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1223908: learning rate 0.0010
[2019-03-23 09:25:03,225] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224013: loss 0.0009
[2019-03-23 09:25:03,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224013: learning rate 0.0010
[2019-03-23 09:25:04,178] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224488: loss 0.0323
[2019-03-23 09:25:04,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224489: learning rate 0.0010
[2019-03-23 09:25:04,239] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224524: loss 0.0470
[2019-03-23 09:25:04,250] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224528: learning rate 0.0010
[2019-03-23 09:25:04,413] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224613: loss 0.0330
[2019-03-23 09:25:04,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224613: learning rate 0.0010
[2019-03-23 09:25:04,713] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224766: loss 0.0113
[2019-03-23 09:25:04,715] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224766: learning rate 0.0010
[2019-03-23 09:25:05,184] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 09:25:05,186] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:25:05,187] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:25:05,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:25:05,188] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:25:05,189] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:25:05,190] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:25:05,191] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:25:05,192] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:25:05,193] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:25:05,193] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:25:05,210] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 09:25:05,211] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 09:25:05,261] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 09:25:05,296] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 09:25:05,322] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 09:25:11,202] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:25:11,203] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.49527781333333, 75.25953849, 1.0, 2.0, 0.427966315151942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464732.2467033069, 464732.2467033066, 94744.14707507829]
[2019-03-23 09:25:11,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:25:11,207] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.24877071461971523
[2019-03-23 09:25:12,421] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:25:12,423] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.218150555, 87.31258175833332, 1.0, 2.0, 0.2858804537324801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 310400.1576458364, 310400.157645836, 99576.47095129234]
[2019-03-23 09:25:12,424] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:25:12,427] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.4312819205124193
[2019-03-23 09:25:14,858] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:25:14,860] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.41586369, 61.34053009000001, 1.0, 2.0, 0.3577034707002901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 398207.9271256591, 398207.9271256587, 123151.4156354621]
[2019-03-23 09:25:14,860] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:25:14,863] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.8816597120594165
[2019-03-23 09:25:39,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:25:39,539] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.97339778666667, 98.18552894000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 201486.6081519717, 201486.6081519714, 72584.7242434634]
[2019-03-23 09:25:39,540] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:25:39,543] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.5767885378196032
[2019-03-23 09:26:25,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:26:25,300] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.72714816, 62.01943417, 1.0, 2.0, 0.6737996435801598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 768661.2080417487, 768661.2080417484, 168619.0622847748]
[2019-03-23 09:26:25,304] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:26:25,306] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.12886752182675942
[2019-03-23 09:26:35,705] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:26:35,706] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.04636240666667, 60.07185398666667, 1.0, 2.0, 0.4950845159917936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 564658.048880883, 564658.0488808826, 145618.4026003494]
[2019-03-23 09:26:35,707] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:26:35,711] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.7821590221372948
[2019-03-23 09:26:37,158] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:26:37,158] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.76666666666667, 74.66666666666667, 1.0, 2.0, 0.5495062906028826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 623790.7584499695, 623790.7584499695, 154506.308887162]
[2019-03-23 09:26:37,159] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:26:37,161] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.47407319487489763
[2019-03-23 09:26:40,440] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.28531408]
[2019-03-23 09:26:40,440] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.3, 86.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 207530.458320369, 207530.4583203683, 73890.15228920164]
[2019-03-23 09:26:40,441] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:26:40,444] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.5004506e-16 1.0000000e+00 7.2479619e-23 3.7040879e-22 5.6578845e-25], sampled 0.3424576768326244
[2019-03-23 09:26:46,189] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:26:46,442] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:26:46,444] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:26:46,541] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:26:46,566] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:26:47,583] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1225000, evaluation results [1225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:26:47,860] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1225148: loss 0.0272
[2019-03-23 09:26:47,864] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1225148: learning rate 0.0010
[2019-03-23 09:26:47,903] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1225160: loss 0.0185
[2019-03-23 09:26:47,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1225160: learning rate 0.0010
[2019-03-23 09:26:48,210] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225328: loss 0.0434
[2019-03-23 09:26:48,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225329: learning rate 0.0010
[2019-03-23 09:26:48,613] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1225544: loss 0.0188
[2019-03-23 09:26:48,616] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1225545: learning rate 0.0010
[2019-03-23 09:26:49,325] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1225927: loss 0.0170
[2019-03-23 09:26:49,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1225927: learning rate 0.0010
[2019-03-23 09:26:51,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.493261e-15 1.000000e+00 3.239338e-23 4.851171e-22 7.675395e-25], sum to 1.0000
[2019-03-23 09:26:51,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8164
[2019-03-23 09:26:51,429] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 57.0, 1.0, 2.0, 0.5620506528551339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 636247.0652749294, 636247.0652749294, 152539.6248383235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6276600.0000, 
sim time next is 6277200.0000, 
raw observation next is [29.4, 56.33333333333333, 1.0, 2.0, 0.5554456921795898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629369.5838013747, 629369.5838013747, 151466.8284699252], 
processed observation next is [0.0, 0.6521739130434783, 0.9727272727272727, 0.5633333333333332, 1.0, 1.0, 0.44430711522448724, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.233099845852361, 0.233099845852361, 0.3694312889510371], 
reward next is 0.6306, 
noisyNet noise sample is [array([0.24432027], dtype=float32), -1.0887787]. 
=============================================
[2019-03-23 09:26:51,614] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1257290e-15 1.0000000e+00 2.2559966e-21 1.1523551e-22 6.2838619e-25], sum to 1.0000
[2019-03-23 09:26:51,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3099
[2019-03-23 09:26:51,626] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 82.0, 1.0, 2.0, 0.4114474469756476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467580.095766594, 467580.0957665937, 128410.7758656911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6253200.0000, 
sim time next is 6253800.0000, 
raw observation next is [21.6, 82.83333333333334, 1.0, 2.0, 0.4144637000002989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471265.4742332404, 471265.4742332404, 128923.810075695], 
processed observation next is [0.0, 0.391304347826087, 0.6181818181818183, 0.8283333333333335, 1.0, 1.0, 0.26807962500037363, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1745427682345335, 0.1745427682345335, 0.3144483172577927], 
reward next is 0.6856, 
noisyNet noise sample is [array([-1.5760351], dtype=float32), 1.1800051]. 
=============================================
[2019-03-23 09:26:54,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0627677e-15 1.0000000e+00 8.0965230e-22 1.8108029e-20 5.9914385e-25], sum to 1.0000
[2019-03-23 09:26:54,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9729
[2019-03-23 09:26:54,042] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 86.66666666666666, 1.0, 2.0, 0.4707285194892691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537127.3138136041, 537127.3138136038, 137419.2910024867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324600.0000, 
sim time next is 6325200.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4687788106655684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534891.4354269903, 534891.4354269903, 137121.2989457202], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.3359735133319605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19810793904703344, 0.19810793904703344, 0.33444219255053703], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.08175573], dtype=float32), -0.6447287]. 
=============================================
[2019-03-23 09:26:54,219] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3916465e-16 1.0000000e+00 8.0544081e-23 1.8203032e-22 1.2336436e-23], sum to 1.0000
[2019-03-23 09:26:54,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8663
[2019-03-23 09:26:54,238] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 55.0, 1.0, 2.0, 0.5591110860392411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632405.4163453304, 632405.4163453308, 152318.4763665209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282000.0000, 
sim time next is 6282600.0000, 
raw observation next is [29.9, 54.66666666666667, 1.0, 2.0, 0.5575721078277899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631144.1481702137, 631144.148170214, 151963.1424713912], 
processed observation next is [0.0, 0.7391304347826086, 0.9954545454545454, 0.5466666666666667, 1.0, 1.0, 0.4469651347847373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23375709191489397, 0.23375709191489408, 0.3706418109058322], 
reward next is 0.6294, 
noisyNet noise sample is [array([1.4522679], dtype=float32), 0.25924593]. 
=============================================
[2019-03-23 09:26:54,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9867317e-14 1.0000000e+00 1.3252717e-20 3.2601432e-21 8.0566819e-23], sum to 1.0000
[2019-03-23 09:26:54,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8374
[2019-03-23 09:26:54,969] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 85.0, 1.0, 2.0, 0.4775333698276072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 544899.6209082358, 544899.6209082354, 138557.293317113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6320400.0000, 
sim time next is 6321000.0000, 
raw observation next is [22.7, 85.0, 1.0, 2.0, 0.4777361100270023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545131.0965589774, 545131.0965589777, 138579.9366812806], 
processed observation next is [0.0, 0.13043478260869565, 0.6681818181818181, 0.85, 1.0, 1.0, 0.3471701375337528, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2019004061329546, 0.2019004061329547, 0.33799984556409907], 
reward next is 0.6620, 
noisyNet noise sample is [array([-1.5235043], dtype=float32), 0.04498696]. 
=============================================
[2019-03-23 09:26:54,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[62.022335]
 [62.022335]
 [62.022335]
 [62.022335]
 [62.022335]], R is [[62.0641098 ]
 [62.10552597]
 [62.14641571]
 [62.18672943]
 [62.22638702]].
[2019-03-23 09:26:56,226] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0141074e-14 1.0000000e+00 6.0322259e-21 1.6916700e-20 5.3688933e-23], sum to 1.0000
[2019-03-23 09:26:56,235] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1453
[2019-03-23 09:26:56,239] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 85.33333333333334, 1.0, 2.0, 0.4782021685921423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545667.3540578359, 545667.3540578362, 138573.4002581129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6322200.0000, 
sim time next is 6322800.0000, 
raw observation next is [22.53333333333333, 85.66666666666667, 1.0, 2.0, 0.4776892524667284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545084.637868731, 545084.6378687313, 138437.7834245601], 
processed observation next is [0.0, 0.17391304347826086, 0.6606060606060605, 0.8566666666666667, 1.0, 1.0, 0.34711156558341044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20188319921064113, 0.2018831992106412, 0.3376531303038051], 
reward next is 0.6623, 
noisyNet noise sample is [array([0.10006037], dtype=float32), -0.21764852]. 
=============================================
[2019-03-23 09:26:59,747] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1231494: loss 0.0069
[2019-03-23 09:26:59,749] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1231494: learning rate 0.0010
[2019-03-23 09:26:59,835] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1231547: loss 0.0086
[2019-03-23 09:26:59,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1231547: learning rate 0.0010
[2019-03-23 09:27:00,207] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1231738: loss 0.0066
[2019-03-23 09:27:00,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1231739: learning rate 0.0010
[2019-03-23 09:27:00,285] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1231782: loss 0.0060
[2019-03-23 09:27:00,287] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1231782: learning rate 0.0010
[2019-03-23 09:27:00,313] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1231796: loss 0.0053
[2019-03-23 09:27:00,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1231796: learning rate 0.0010
[2019-03-23 09:27:00,503] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1231898: loss 0.0032
[2019-03-23 09:27:00,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1231898: learning rate 0.0010
[2019-03-23 09:27:00,684] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1231994: loss 0.0035
[2019-03-23 09:27:00,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1231996: learning rate 0.0010
[2019-03-23 09:27:00,989] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9477277e-15 1.0000000e+00 2.8264157e-22 2.0087457e-21 4.3765818e-24], sum to 1.0000
[2019-03-23 09:27:01,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8188
[2019-03-23 09:27:01,003] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 71.0, 1.0, 2.0, 0.4942651481286594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563918.4872175365, 563918.4872175365, 140884.1062055776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6418800.0000, 
sim time next is 6419400.0000, 
raw observation next is [24.9, 71.5, 1.0, 2.0, 0.5346801302674933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610044.5104875583, 610044.5104875583, 145701.4343904134], 
processed observation next is [1.0, 0.30434782608695654, 0.7681818181818181, 0.715, 1.0, 1.0, 0.41835016283436655, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22594241129168827, 0.22594241129168827, 0.35536935217174], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.6556582], dtype=float32), -1.7058823]. 
=============================================
[2019-03-23 09:27:01,641] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232501: loss 0.0034
[2019-03-23 09:27:01,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232501: learning rate 0.0010
[2019-03-23 09:27:01,703] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232535: loss 0.0031
[2019-03-23 09:27:01,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232535: learning rate 0.0010
[2019-03-23 09:27:01,869] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232621: loss 0.0061
[2019-03-23 09:27:01,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232622: learning rate 0.0010
[2019-03-23 09:27:02,211] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8472733e-16 1.0000000e+00 1.5086765e-21 7.4666137e-21 8.0665761e-25], sum to 1.0000
[2019-03-23 09:27:02,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2909
[2019-03-23 09:27:02,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 70.0, 1.0, 2.0, 0.2414760763191526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 262190.2197379285, 262190.2197379285, 79115.12173672295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6465600.0000, 
sim time next is 6466200.0000, 
raw observation next is [16.51666666666667, 70.33333333333334, 1.0, 2.0, 0.2410854140319524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 261765.9317659394, 261765.9317659391, 78927.74822402318], 
processed observation next is [1.0, 0.8695652173913043, 0.38712121212121225, 0.7033333333333335, 1.0, 1.0, 0.0513567675399405, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09695034509849608, 0.09695034509849597, 0.19250670298542238], 
reward next is 0.8075, 
noisyNet noise sample is [array([0.83027136], dtype=float32), -1.7404574]. 
=============================================
[2019-03-23 09:27:02,307] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232854: loss 0.0089
[2019-03-23 09:27:02,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232855: learning rate 0.0010
[2019-03-23 09:27:02,846] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1233138: loss 0.0055
[2019-03-23 09:27:02,847] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1233138: learning rate 0.0010
[2019-03-23 09:27:02,867] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1233146: loss 0.0087
[2019-03-23 09:27:02,868] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1233146: learning rate 0.0010
[2019-03-23 09:27:03,311] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233388: loss 0.0274
[2019-03-23 09:27:03,314] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233388: learning rate 0.0010
[2019-03-23 09:27:03,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1233556: loss 0.1383
[2019-03-23 09:27:03,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1233556: learning rate 0.0010
[2019-03-23 09:27:04,050] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1233781: loss 0.0144
[2019-03-23 09:27:04,054] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1233784: learning rate 0.0010
[2019-03-23 09:27:04,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4478827e-18 1.0000000e+00 3.4487390e-26 2.3931725e-22 1.1999452e-26], sum to 1.0000
[2019-03-23 09:27:04,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6175
[2019-03-23 09:27:04,831] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.7, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 199428.5955407397, 199428.59554074, 67713.70698080146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6494400.0000, 
sim time next is 6495000.0000, 
raw observation next is [12.7, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 212489.4237423856, 212489.4237423853, 69701.36153890163], 
processed observation next is [1.0, 0.17391304347826086, 0.2136363636363636, 0.8933333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07869978657125393, 0.07869978657125382, 0.17000332082658934], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3785354], dtype=float32), -0.061555933]. 
=============================================
[2019-03-23 09:27:04,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.096115]
 [77.096115]
 [77.096115]
 [77.096115]
 [77.096115]], R is [[76.32515717]
 [75.56190491]
 [74.80628967]
 [74.05822754]
 [73.31764221]].
[2019-03-23 09:27:04,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5866786e-18 1.0000000e+00 9.3242186e-25 3.4397702e-23 1.2200325e-26], sum to 1.0000
[2019-03-23 09:27:04,999] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4733
[2019-03-23 09:27:05,004] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.71666666666667, 57.5, 1.0, 2.0, 0.4510384059444616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489843.6985975142, 489843.6985975142, 102847.9012556882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6516600.0000, 
sim time next is 6517200.0000, 
raw observation next is [18.63333333333333, 58.00000000000001, 1.0, 2.0, 0.4411837612790967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479135.9310127657, 479135.9310127657, 101879.0493887391], 
processed observation next is [1.0, 0.43478260869565216, 0.48333333333333317, 0.5800000000000001, 1.0, 1.0, 0.30147970159887083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17745775222695026, 0.17745775222695026, 0.2484854863139978], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.84864545], dtype=float32), -0.8883578]. 
=============================================
[2019-03-23 09:27:14,810] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1239384: loss 0.0033
[2019-03-23 09:27:14,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1239385: learning rate 0.0010
[2019-03-23 09:27:15,178] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1239572: loss 0.0125
[2019-03-23 09:27:15,181] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1239573: learning rate 0.0010
[2019-03-23 09:27:15,467] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1239720: loss 0.0005
[2019-03-23 09:27:15,474] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1239720: learning rate 0.0010
[2019-03-23 09:27:15,789] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1239878: loss 0.0056
[2019-03-23 09:27:15,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1239879: learning rate 0.0010
[2019-03-23 09:27:15,819] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1239892: loss 0.0016
[2019-03-23 09:27:15,821] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1239893: learning rate 0.0010
[2019-03-23 09:27:15,842] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1239903: loss 0.0012
[2019-03-23 09:27:15,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1239903: learning rate 0.0010
[2019-03-23 09:27:15,899] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1239933: loss 0.0028
[2019-03-23 09:27:15,900] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1239933: learning rate 0.0010
[2019-03-23 09:27:17,130] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240549: loss 0.0279
[2019-03-23 09:27:17,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240549: learning rate 0.0010
[2019-03-23 09:27:17,182] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240577: loss 0.0192
[2019-03-23 09:27:17,184] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240578: learning rate 0.0010
[2019-03-23 09:27:17,206] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240589: loss 0.0137
[2019-03-23 09:27:17,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240589: learning rate 0.0010
[2019-03-23 09:27:17,533] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240749: loss 0.0136
[2019-03-23 09:27:17,540] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240751: learning rate 0.0010
[2019-03-23 09:27:17,728] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1559896e-16 1.0000000e+00 1.1476437e-22 4.5893534e-22 2.2432664e-24], sum to 1.0000
[2019-03-23 09:27:17,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4551
[2019-03-23 09:27:17,740] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 61.0, 1.0, 2.0, 0.8135596801070722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 927323.0067549037, 927323.0067549037, 180800.5788802607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6791400.0000, 
sim time next is 6792000.0000, 
raw observation next is [25.33333333333334, 60.66666666666667, 1.0, 2.0, 0.8855260536479075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1009529.749503954, 1009529.749503954, 192509.3662680959], 
processed observation next is [1.0, 0.6086956521739131, 0.7878787878787882, 0.6066666666666667, 1.0, 1.0, 0.8569075670598844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.37389990722368666, 0.37389990722368666, 0.4695350396782827], 
reward next is 0.5305, 
noisyNet noise sample is [array([-1.7328432], dtype=float32), -1.1848971]. 
=============================================
[2019-03-23 09:27:17,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.97427]
 [68.97427]
 [68.97427]
 [68.97427]
 [68.97427]], R is [[68.81500244]
 [68.68587494]
 [67.99901581]
 [67.6913147 ]
 [67.44441223]].
[2019-03-23 09:27:18,270] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1241122: loss 0.0191
[2019-03-23 09:27:18,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1241123: learning rate 0.0010
[2019-03-23 09:27:18,316] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1241139: loss 0.0176
[2019-03-23 09:27:18,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1241139: learning rate 0.0010
[2019-03-23 09:27:18,751] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241362: loss 0.0094
[2019-03-23 09:27:18,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241363: learning rate 0.0010
[2019-03-23 09:27:19,087] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1241532: loss 0.0049
[2019-03-23 09:27:19,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1241533: learning rate 0.0010
[2019-03-23 09:27:19,644] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1241821: loss -42.0779
[2019-03-23 09:27:19,648] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1241822: learning rate 0.0010
[2019-03-23 09:27:30,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3428217e-16 1.0000000e+00 9.7884264e-22 2.9524257e-21 3.1904901e-24], sum to 1.0000
[2019-03-23 09:27:30,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3806
[2019-03-23 09:27:30,074] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 56.66666666666667, 1.0, 2.0, 0.5097602823928854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 580993.9911681822, 580993.9911681825, 143712.1417489722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6967200.0000, 
sim time next is 6967800.0000, 
raw observation next is [28.0, 57.0, 1.0, 2.0, 0.5077266587197536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578725.3312198841, 578725.3312198845, 143413.3084323728], 
processed observation next is [0.0, 0.6521739130434783, 0.9090909090909091, 0.57, 1.0, 1.0, 0.384658323399692, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21434271526662374, 0.21434271526662388, 0.3497885571521288], 
reward next is 0.6502, 
noisyNet noise sample is [array([0.28720427], dtype=float32), -1.2107452]. 
=============================================
[2019-03-23 09:27:30,704] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1247391: loss -35.6716
[2019-03-23 09:27:30,706] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1247391: learning rate 0.0010
[2019-03-23 09:27:31,003] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1247539: loss -37.7213
[2019-03-23 09:27:31,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1247541: learning rate 0.0010
[2019-03-23 09:27:31,336] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1247709: loss -62.3704
[2019-03-23 09:27:31,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1247712: learning rate 0.0010
[2019-03-23 09:27:31,625] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1247854: loss -66.5387
[2019-03-23 09:27:31,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1247854: learning rate 0.0010
[2019-03-23 09:27:31,648] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1247864: loss -31.4956
[2019-03-23 09:27:31,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1247864: learning rate 0.0010
[2019-03-23 09:27:31,760] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1247921: loss -31.5829
[2019-03-23 09:27:31,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1247923: learning rate 0.0010
[2019-03-23 09:27:31,890] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1247984: loss -31.7522
[2019-03-23 09:27:31,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1247985: learning rate 0.0010
[2019-03-23 09:27:33,078] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248582: loss -63.6560
[2019-03-23 09:27:33,079] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248582: learning rate 0.0010
[2019-03-23 09:27:33,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248604: loss -42.9633
[2019-03-23 09:27:33,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248604: learning rate 0.0010
[2019-03-23 09:27:33,216] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248653: loss -64.9638
[2019-03-23 09:27:33,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248653: learning rate 0.0010
[2019-03-23 09:27:33,368] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248733: loss -40.5434
[2019-03-23 09:27:33,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248734: learning rate 0.0010
[2019-03-23 09:27:34,113] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1249117: loss -68.9029
[2019-03-23 09:27:34,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1249117: learning rate 0.0010
[2019-03-23 09:27:34,211] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1249160: loss -57.6135
[2019-03-23 09:27:34,215] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1249163: learning rate 0.0010
[2019-03-23 09:27:34,795] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249454: loss -67.1722
[2019-03-23 09:27:34,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249454: learning rate 0.0010
[2019-03-23 09:27:34,891] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1249509: loss -44.5537
[2019-03-23 09:27:34,892] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1249509: learning rate 0.0010
[2019-03-23 09:27:35,600] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1249819: loss 0.0372
[2019-03-23 09:27:35,602] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1249819: learning rate 0.0010
[2019-03-23 09:27:35,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3800479e-15 1.0000000e+00 2.1293915e-23 3.2000894e-20 9.9478299e-25], sum to 1.0000
[2019-03-23 09:27:35,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1397
[2019-03-23 09:27:35,711] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 92.0, 1.0, 2.0, 0.3426203828282322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379445.9403904856, 379445.9403904856, 116821.5294552188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7083600.0000, 
sim time next is 7084200.0000, 
raw observation next is [17.8, 92.5, 1.0, 2.0, 0.3412758673570651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377692.8606089979, 377692.8606089979, 116613.2580510826], 
processed observation next is [1.0, 1.0, 0.4454545454545455, 0.925, 1.0, 1.0, 0.17659483419633137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13988624466999922, 0.13988624466999922, 0.28442258061239656], 
reward next is 0.7156, 
noisyNet noise sample is [array([-1.1700727], dtype=float32), -2.5582364]. 
=============================================
[2019-03-23 09:27:35,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8081273e-17 1.0000000e+00 7.9951084e-24 3.4811403e-23 3.4788007e-25], sum to 1.0000
[2019-03-23 09:27:35,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6577
[2019-03-23 09:27:35,915] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 48.66666666666667, 1.0, 2.0, 0.7035056478702418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 782502.9648002512, 782502.9648002515, 153725.9371203979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7141200.0000, 
sim time next is 7141800.0000, 
raw observation next is [24.4, 48.33333333333333, 1.0, 2.0, 0.680898423323138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 756534.7163270697, 756534.7163270699, 150668.5653721352], 
processed observation next is [1.0, 0.6521739130434783, 0.7454545454545454, 0.4833333333333333, 1.0, 1.0, 0.6011230291539225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2801980430840999, 0.28019804308409996, 0.36748430578569563], 
reward next is 0.6325, 
noisyNet noise sample is [array([-0.06353205], dtype=float32), -0.1510285]. 
=============================================
[2019-03-23 09:27:35,958] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 09:27:35,961] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:27:35,963] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:35,964] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:27:35,965] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:35,966] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:27:35,968] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:35,969] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:27:35,969] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:27:35,969] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:35,970] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:27:35,993] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 09:27:35,993] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 09:27:35,993] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 09:27:36,017] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 09:27:36,099] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 09:27:41,682] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:27:41,683] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.33333333333333, 61.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 209360.9779887297, 209360.97798873, 68593.64154290328]
[2019-03-23 09:27:41,684] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:27:41,687] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.8579766940143276
[2019-03-23 09:27:52,294] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:27:52,296] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.73333333333333, 58.66666666666666, 1.0, 2.0, 0.8021939797153226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 914127.2894858056, 914127.2894858052, 189660.173651721]
[2019-03-23 09:27:52,297] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:27:52,302] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.5220303572012668
[2019-03-23 09:27:53,651] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:27:53,654] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.46666666666667, 73.66666666666667, 1.0, 2.0, 0.5097053084936122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 581529.0301320425, 581529.0301320421, 146791.4743203316]
[2019-03-23 09:27:53,655] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:27:53,657] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.42120947015067745
[2019-03-23 09:27:58,217] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:27:58,218] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.0, 45.5, 1.0, 2.0, 0.3992518073845893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 442213.8151652039, 442213.8151652036, 125703.040260444]
[2019-03-23 09:27:58,219] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:27:58,222] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.3066234893789903
[2019-03-23 09:28:20,121] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:28:20,122] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.07304790166667, 97.31060814666668, 1.0, 2.0, 0.3928125770989823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 443948.1687697748, 443948.1687697745, 129265.5808400196]
[2019-03-23 09:28:20,125] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:28:20,129] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.5425364605911859
[2019-03-23 09:28:48,065] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:28:48,067] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.01666666666667, 51.0, 1.0, 2.0, 0.5049776411015853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 571917.919522181, 571917.9195221807, 140976.2135001298]
[2019-03-23 09:28:48,068] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:28:48,071] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.5764262953907436
[2019-03-23 09:28:52,748] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:28:52,749] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.33333333333334, 80.0, 1.0, 2.0, 0.281917996206175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 306096.7481808909, 306096.7481808909, 101826.3958208059]
[2019-03-23 09:28:52,751] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:28:52,753] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.22100120279598934
[2019-03-23 09:29:08,064] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:29:08,065] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 97.0, 1.0, 2.0, 0.3510442996264675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390813.5035992468, 390813.5035992465, 118309.0886940011]
[2019-03-23 09:29:08,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:29:08,070] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.3585214378566528
[2019-03-23 09:29:14,657] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.30737412]
[2019-03-23 09:29:14,657] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.06666666666667, 64.0, 1.0, 2.0, 0.2453451828049012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 266378.4606109794, 266378.4606109787, 86852.05271878367]
[2019-03-23 09:29:14,658] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:29:14,660] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.238510e-16 1.000000e+00 6.127704e-23 3.176164e-22 4.739907e-25], sampled 0.9508843356356801
[2019-03-23 09:29:17,184] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:29:17,303] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:29:17,396] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:29:17,434] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:29:17,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:29:18,531] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1250000, evaluation results [1250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:29:20,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0537792e-16 1.0000000e+00 4.0044781e-22 5.1027304e-23 4.0092717e-25], sum to 1.0000
[2019-03-23 09:29:20,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2101
[2019-03-23 09:29:20,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 89.0, 1.0, 2.0, 0.428336138977747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 476073.5037440493, 476073.5037440496, 124500.1225705229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7114800.0000, 
sim time next is 7115400.0000, 
raw observation next is [18.55, 88.5, 1.0, 2.0, 0.5168020250582002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 575046.2974975049, 575046.2974975045, 133052.9198991281], 
processed observation next is [1.0, 0.34782608695652173, 0.47954545454545455, 0.885, 1.0, 1.0, 0.39600253132275015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21298011018426105, 0.21298011018426094, 0.3245193168271417], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.27586696], dtype=float32), 1.8062371]. 
=============================================
[2019-03-23 09:29:22,275] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1382619e-15 1.0000000e+00 3.6491679e-21 1.7263508e-21 8.3640762e-25], sum to 1.0000
[2019-03-23 09:29:22,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9886
[2019-03-23 09:29:22,287] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.55, 79.5, 1.0, 2.0, 0.2078311692619951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225650.733158007, 225650.7331580067, 73006.7461545412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7176600.0000, 
sim time next is 7177200.0000, 
raw observation next is [14.4, 80.33333333333333, 1.0, 2.0, 0.2055603351356421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223184.630755809, 223184.6307558087, 72645.03969856685], 
processed observation next is [1.0, 0.043478260869565216, 0.29090909090909095, 0.8033333333333332, 1.0, 1.0, 0.006950418919552601, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08266097435400332, 0.08266097435400323, 0.1771830236550411], 
reward next is 0.8228, 
noisyNet noise sample is [array([1.172599], dtype=float32), -0.69518334]. 
=============================================
[2019-03-23 09:29:24,332] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9819871e-18 1.0000000e+00 2.5449119e-25 2.0373658e-24 1.6144855e-28], sum to 1.0000
[2019-03-23 09:29:24,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7610
[2019-03-23 09:29:24,347] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.18333333333333, 61.33333333333333, 1.0, 2.0, 0.493176023529643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535631.8573891624, 535631.8573891624, 113078.9298624251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [19.56666666666667, 59.66666666666667, 1.0, 2.0, 0.5111637878817245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 555179.2834337, 555179.2834337003, 116417.7965653], 
processed observation next is [1.0, 0.391304347826087, 0.5257575757575759, 0.5966666666666667, 1.0, 1.0, 0.38895473485215554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20562195682729628, 0.20562195682729642, 0.2839458452812195], 
reward next is 0.7161, 
noisyNet noise sample is [array([1.673472], dtype=float32), -1.04243]. 
=============================================
[2019-03-23 09:29:24,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9930394e-16 1.0000000e+00 6.7340240e-23 3.3038331e-23 1.5731228e-25], sum to 1.0000
[2019-03-23 09:29:24,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2013
[2019-03-23 09:29:24,730] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.3, 78.66666666666667, 1.0, 2.0, 0.2059936152582873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 223655.1675277322, 223655.1675277322, 72060.08733987859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7271400.0000, 
sim time next is 7272000.0000, 
raw observation next is [14.4, 77.0, 1.0, 2.0, 0.2072360918765407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225004.4840559388, 225004.4840559385, 72003.16708462582], 
processed observation next is [1.0, 0.17391304347826086, 0.29090909090909095, 0.77, 1.0, 1.0, 0.009045114845675876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08333499409479216, 0.08333499409479203, 0.17561748069420932], 
reward next is 0.8244, 
noisyNet noise sample is [array([-0.35566378], dtype=float32), -0.39892566]. 
=============================================
[2019-03-23 09:29:24,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.98436]
 [71.98436]
 [71.98436]
 [71.98436]
 [71.98436]], R is [[72.08890533]
 [72.19226074]
 [72.29424286]
 [72.39495087]
 [72.49416351]].
[2019-03-23 09:29:25,010] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9792223e-16 1.0000000e+00 2.9952582e-23 4.5844166e-23 3.0843751e-25], sum to 1.0000
[2019-03-23 09:29:25,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0384
[2019-03-23 09:29:25,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 71.0, 1.0, 2.0, 0.3158414111672111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 342963.1843867769, 342963.1843867772, 88676.34535079358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7201200.0000, 
sim time next is 7201800.0000, 
raw observation next is [17.45, 69.0, 1.0, 2.0, 0.3803805419451977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413074.1540174656, 413074.1540174656, 96643.89049155098], 
processed observation next is [1.0, 0.34782608695652173, 0.4295454545454545, 0.69, 1.0, 1.0, 0.22547567743149713, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15299042741387614, 0.15299042741387614, 0.2357168060769536], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.80543476], dtype=float32), -0.4012858]. 
=============================================
[2019-03-23 09:29:25,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.10867317e-16 1.00000000e+00 3.54548091e-24 1.23652235e-23
 5.52596775e-28], sum to 1.0000
[2019-03-23 09:29:25,152] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0130
[2019-03-23 09:29:25,155] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 49.0, 1.0, 2.0, 0.3195554447608329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346997.5864928535, 346997.5864928532, 112521.3836337097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7237200.0000, 
sim time next is 7237800.0000, 
raw observation next is [22.45, 50.5, 1.0, 2.0, 0.3130475958264115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339928.3996213253, 339928.3996213256, 112073.6701586724], 
processed observation next is [1.0, 0.782608695652174, 0.6568181818181817, 0.505, 1.0, 1.0, 0.14130949478301436, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1258994072671575, 0.12589940726715762, 0.2733504150211522], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.6139452], dtype=float32), 1.3479297]. 
=============================================
[2019-03-23 09:29:28,429] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1255280: loss 0.0045
[2019-03-23 09:29:28,434] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1255281: learning rate 0.0010
[2019-03-23 09:29:29,010] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1255579: loss 0.0079
[2019-03-23 09:29:29,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1255580: learning rate 0.0010
[2019-03-23 09:29:29,079] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1255624: loss 0.0125
[2019-03-23 09:29:29,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1255626: learning rate 0.0010
[2019-03-23 09:29:29,487] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1255840: loss 0.0009
[2019-03-23 09:29:29,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1255841: learning rate 0.0010
[2019-03-23 09:29:29,553] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1255878: loss 0.0015
[2019-03-23 09:29:29,555] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1255878: learning rate 0.0010
[2019-03-23 09:29:29,659] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1255932: loss 0.0015
[2019-03-23 09:29:29,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1255933: learning rate 0.0010
[2019-03-23 09:29:29,725] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1255968: loss 0.0060
[2019-03-23 09:29:29,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1255972: learning rate 0.0010
[2019-03-23 09:29:30,750] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256508: loss 0.0176
[2019-03-23 09:29:30,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256509: learning rate 0.0010
[2019-03-23 09:29:30,995] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256637: loss 0.0270
[2019-03-23 09:29:30,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256638: learning rate 0.0010
[2019-03-23 09:29:31,139] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256715: loss 0.0456
[2019-03-23 09:29:31,142] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256715: learning rate 0.0010
[2019-03-23 09:29:31,156] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256724: loss 0.0431
[2019-03-23 09:29:31,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256724: learning rate 0.0010
[2019-03-23 09:29:31,609] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256963: loss 0.0013
[2019-03-23 09:29:31,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256963: learning rate 0.0010
[2019-03-23 09:29:31,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.3760558e-16 1.0000000e+00 8.7403678e-25 2.3192668e-23 3.1430982e-25], sum to 1.0000
[2019-03-23 09:29:31,789] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5066
[2019-03-23 09:29:31,793] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 72.66666666666667, 1.0, 2.0, 0.3481321985366734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 385685.2244684424, 385685.2244684421, 117300.201846574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7339200.0000, 
sim time next is 7339800.0000, 
raw observation next is [20.18333333333333, 73.83333333333333, 1.0, 2.0, 0.3473258567033705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384680.44884157, 384680.44884157, 117193.2917607934], 
processed observation next is [1.0, 0.9565217391304348, 0.5537878787878786, 0.7383333333333333, 1.0, 1.0, 0.18415732087921313, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1424742403116926, 0.1424742403116926, 0.2858372969775449], 
reward next is 0.7142, 
noisyNet noise sample is [array([-0.46480143], dtype=float32), 0.08371331]. 
=============================================
[2019-03-23 09:29:31,916] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1257128: loss 0.0094
[2019-03-23 09:29:31,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1257128: learning rate 0.0010
[2019-03-23 09:29:32,588] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1257485: loss 0.0233
[2019-03-23 09:29:32,589] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1257485: learning rate 0.0010
[2019-03-23 09:29:32,658] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257523: loss 0.0237
[2019-03-23 09:29:32,661] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257524: learning rate 0.0010
[2019-03-23 09:29:33,312] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1257876: loss -114.4799
[2019-03-23 09:29:33,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1257876: learning rate 0.0010
[2019-03-23 09:29:34,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8335078e-16 1.0000000e+00 3.8606278e-23 4.8372534e-23 3.5711610e-25], sum to 1.0000
[2019-03-23 09:29:34,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5637
[2019-03-23 09:29:34,834] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 72.0, 1.0, 2.0, 0.4705079388728119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 536883.1805125239, 536883.1805125242, 137709.2547125217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7468800.0000, 
sim time next is 7469400.0000, 
raw observation next is [24.8, 71.5, 1.0, 2.0, 0.4742823595787837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 541166.2394597087, 541166.2394597087, 138363.2479384086], 
processed observation next is [0.0, 0.43478260869565216, 0.7636363636363637, 0.715, 1.0, 1.0, 0.34285294947347955, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20043194054063285, 0.20043194054063285, 0.33747133643514293], 
reward next is 0.6625, 
noisyNet noise sample is [array([1.0508798], dtype=float32), -1.6039807]. 
=============================================
[2019-03-23 09:29:43,601] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1263296: loss -92.9046
[2019-03-23 09:29:43,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1263296: learning rate 0.0010
[2019-03-23 09:29:44,266] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1263628: loss -172.5366
[2019-03-23 09:29:44,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1263628: learning rate 0.0010
[2019-03-23 09:29:44,540] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1263772: loss -175.3466
[2019-03-23 09:29:44,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1263772: learning rate 0.0010
[2019-03-23 09:29:44,573] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1263786: loss -106.8119
[2019-03-23 09:29:44,576] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1263787: learning rate 0.0010
[2019-03-23 09:29:44,754] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1263869: loss -96.1004
[2019-03-23 09:29:44,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1263870: learning rate 0.0010
[2019-03-23 09:29:44,928] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1263952: loss -105.3368
[2019-03-23 09:29:44,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1263953: learning rate 0.0010
[2019-03-23 09:29:45,064] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264021: loss -126.6789
[2019-03-23 09:29:45,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264021: learning rate 0.0010
[2019-03-23 09:29:45,960] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264472: loss -80.7510
[2019-03-23 09:29:45,961] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264472: learning rate 0.0010
[2019-03-23 09:29:46,381] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264680: loss -97.3857
[2019-03-23 09:29:46,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264682: learning rate 0.0010
[2019-03-23 09:29:46,458] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264720: loss -140.9002
[2019-03-23 09:29:46,461] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264720: learning rate 0.0010
[2019-03-23 09:29:46,648] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264816: loss -101.5878
[2019-03-23 09:29:46,652] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264817: learning rate 0.0010
[2019-03-23 09:29:47,001] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264992: loss -121.7041
[2019-03-23 09:29:47,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264993: learning rate 0.0010
[2019-03-23 09:29:47,141] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1265063: loss -95.1229
[2019-03-23 09:29:47,142] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1265064: learning rate 0.0010
[2019-03-23 09:29:48,046] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1265514: loss -136.2718
[2019-03-23 09:29:48,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1265514: learning rate 0.0010
[2019-03-23 09:29:48,283] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265633: loss -107.6017
[2019-03-23 09:29:48,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265634: learning rate 0.0010
[2019-03-23 09:29:49,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:29:49,094] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:49,155] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 09:29:51,189] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1722246e-15 1.0000000e+00 5.4051669e-22 2.7643998e-21 9.0287671e-24], sum to 1.0000
[2019-03-23 09:29:51,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6954
[2019-03-23 09:29:51,206] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 49.66666666666667, 1.0, 2.0, 0.6459063915979537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 701629.9953396142, 701629.995339614, 137806.0887352481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7738800.0000, 
sim time next is 7739400.0000, 
raw observation next is [21.78333333333333, 49.33333333333334, 1.0, 2.0, 0.6294124900742599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 683700.5284268726, 683700.5284268726, 133856.156561104], 
processed observation next is [1.0, 0.5652173913043478, 0.6265151515151515, 0.4933333333333334, 1.0, 1.0, 0.5367656125928248, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25322241793587874, 0.25322241793587874, 0.326478430636839], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.16340609], dtype=float32), -0.10744575]. 
=============================================
[2019-03-23 09:29:56,523] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9008337e-16 1.0000000e+00 6.8101510e-24 6.3049979e-23 2.4050099e-26], sum to 1.0000
[2019-03-23 09:29:56,531] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6290
[2019-03-23 09:29:56,535] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 90.0, 1.0, 2.0, 0.6435248652996128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 732792.8285197171, 732792.8285197171, 155705.0232758826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7907400.0000, 
sim time next is 7908000.0000, 
raw observation next is [20.7, 91.0, 1.0, 2.0, 0.6385304693683153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 727139.2097784377, 727139.2097784374, 155093.4812424021], 
processed observation next is [1.0, 0.5217391304347826, 0.5772727272727273, 0.91, 1.0, 1.0, 0.548163086710394, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.26931081843645843, 0.26931081843645827, 0.37827678351805394], 
reward next is 0.6217, 
noisyNet noise sample is [array([-1.0073955], dtype=float32), 1.0933297]. 
=============================================
[2019-03-23 09:29:56,552] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.54916]
 [72.54916]
 [72.54916]
 [72.54916]
 [72.54916]], R is [[72.44539642]
 [72.34117126]
 [72.2228241 ]
 [72.06752014]
 [71.92626953]].
[2019-03-23 09:29:59,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:29:59,870] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:29:59,922] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0868202e-15 1.0000000e+00 1.7448690e-21 9.2459557e-22 2.2444145e-23], sum to 1.0000
[2019-03-23 09:29:59,925] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0243
[2019-03-23 09:29:59,928] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 93.0, 1.0, 2.0, 0.85570259865617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 975969.569644999, 975969.5696449992, 188306.8384008958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [20.9, 93.0, 1.0, 2.0, 0.8741729395362463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 997348.673033981, 997348.673033981, 191859.0089857454], 
processed observation next is [1.0, 0.5652173913043478, 0.5863636363636363, 0.93, 1.0, 1.0, 0.8427161744203079, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.36938839741999296, 0.36938839741999296, 0.46794880240425707], 
reward next is 0.5321, 
noisyNet noise sample is [array([-0.0268725], dtype=float32), -6.949156e-05]. 
=============================================
[2019-03-23 09:29:59,931] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 09:30:00,662] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:00,663] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:00,669] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 09:30:00,694] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:00,696] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:00,723] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 09:30:00,832] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:00,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:00,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:00,857] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:00,868] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 09:30:00,907] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 09:30:01,021] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:01,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:01,026] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 09:30:01,163] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:01,165] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:01,184] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 09:30:01,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:01,833] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:01,845] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 09:30:01,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:01,874] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:01,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:01,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:01,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 09:30:01,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 09:30:02,128] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:02,129] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:02,139] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 09:30:02,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:02,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:02,345] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:02,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:02,353] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 09:30:02,396] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 09:30:02,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:02,557] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:02,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 09:30:02,658] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4205999e-16 1.0000000e+00 2.2539640e-23 4.4023053e-22 3.2627352e-26], sum to 1.0000
[2019-03-23 09:30:02,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9242
[2019-03-23 09:30:02,669] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3971698716229071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 445936.2672629722, 445936.267262972, 123771.8577439786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 26400.0000, 
sim time next is 27000.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4074029975585636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457456.7647621991, 457456.7647621991, 124695.7407616639], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2592537469482044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16942843139340708, 0.16942843139340708, 0.304135953077229], 
reward next is 0.6959, 
noisyNet noise sample is [array([0.10413834], dtype=float32), -1.8147106]. 
=============================================
[2019-03-23 09:30:02,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:30:02,675] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:02,680] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 09:30:02,737] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.35296]
 [72.35296]
 [72.35296]
 [72.35296]
 [72.35296]], R is [[72.32529449]
 [72.30016327]
 [72.27611542]
 [72.2567215 ]
 [72.23838043]].
[2019-03-23 09:30:03,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2905103e-16 1.0000000e+00 1.4400615e-21 5.4713462e-21 4.2306003e-24], sum to 1.0000
[2019-03-23 09:30:03,945] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4296
[2019-03-23 09:30:03,948] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.4726452381824026, 1.0, 2.0, 0.4726452381824026, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1078628.689468478, 1078628.689468478, 216935.2189289193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 59400.0000, 
sim time next is 60000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.9292610834799843, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1056876.340715085, 1056876.340715084, 197189.4899940885], 
processed observation next is [1.0, 0.6956521739130435, 0.5909090909090909, 0.83, 1.0, 1.0, 0.9115763543499802, 0.0, 0.5, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.39143568174632776, 0.3914356817463274, 0.4809499755953378], 
reward next is 0.5191, 
noisyNet noise sample is [array([-1.5774689], dtype=float32), 0.3162227]. 
=============================================
[2019-03-23 09:30:03,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.28631]
 [68.28631]
 [68.28631]
 [68.28631]
 [68.28631]], R is [[68.12249756]
 [67.44127655]
 [67.14336395]
 [66.97709656]
 [66.83065796]].
[2019-03-23 09:30:04,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0691435e-15 1.0000000e+00 4.8657591e-21 9.9099355e-21 2.9802234e-24], sum to 1.0000
[2019-03-23 09:30:04,538] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1756
[2019-03-23 09:30:04,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 76.33333333333334, 1.0, 2.0, 0.3554691271288914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393189.1731936367, 393189.1731936367, 117626.5513519154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 73200.0000, 
sim time next is 73800.0000, 
raw observation next is [19.5, 75.5, 1.0, 2.0, 0.3477881779620072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382991.2166179075, 382991.2166179075, 116381.6874494977], 
processed observation next is [1.0, 0.8695652173913043, 0.5227272727272727, 0.755, 1.0, 1.0, 0.18473522245250895, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14184859874737316, 0.14184859874737316, 0.28385777426706754], 
reward next is 0.7161, 
noisyNet noise sample is [array([-1.2783158], dtype=float32), -0.10893153]. 
=============================================
[2019-03-23 09:30:07,077] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6982343e-17 1.0000000e+00 1.4140288e-23 1.2584798e-22 9.4451432e-26], sum to 1.0000
[2019-03-23 09:30:07,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5677
[2019-03-23 09:30:07,092] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 73.66666666666667, 1.0, 2.0, 0.3144831358267037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 341487.7540462222, 341487.7540462222, 106673.2232230525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 76200.0000, 
sim time next is 76800.0000, 
raw observation next is [18.0, 74.33333333333334, 1.0, 2.0, 0.3037962725112994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329879.2754178653, 329879.2754178656, 99311.67459121472], 
processed observation next is [1.0, 0.9130434782608695, 0.45454545454545453, 0.7433333333333334, 1.0, 1.0, 0.12974534063912427, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1221775094140242, 0.12217750941402429, 0.24222359656393833], 
reward next is 0.7578, 
noisyNet noise sample is [array([1.3198771], dtype=float32), 0.29876342]. 
=============================================
[2019-03-23 09:30:07,412] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 09:30:07,415] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:30:07,416] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:30:07,417] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:30:07,418] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:30:07,418] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:07,417] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:07,419] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:07,420] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:30:07,421] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:07,425] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:30:07,446] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 09:30:07,472] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 09:30:07,498] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 09:30:07,523] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 09:30:07,524] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 09:30:37,081] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38478392]
[2019-03-23 09:30:37,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.43333333333333, 43.0, 1.0, 2.0, 0.2531098189067185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 274810.6810065745, 274810.6810065745, 79905.69104772963]
[2019-03-23 09:30:37,085] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:30:37,088] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.4173242e-16 1.0000000e+00 3.6278590e-23 1.9128059e-22 2.6610692e-25], sampled 0.44742778101056446
[2019-03-23 09:30:50,019] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38478392]
[2019-03-23 09:30:50,020] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.46234047, 83.33083612, 1.0, 2.0, 0.4119965971133664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 461819.6289978079, 461819.6289978076, 129058.167609092]
[2019-03-23 09:30:50,022] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:30:50,026] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4173242e-16 1.0000000e+00 3.6278590e-23 1.9128059e-22 2.6610692e-25], sampled 0.8612546961259063
[2019-03-23 09:30:52,786] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38478392]
[2019-03-23 09:30:52,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.65305376833333, 66.99208683, 1.0, 2.0, 0.2141037396657849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 232452.1505880418, 232452.1505880414, 77273.29019418274]
[2019-03-23 09:30:52,788] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:30:52,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.4173242e-16 1.0000000e+00 3.6278590e-23 1.9128059e-22 2.6610692e-25], sampled 0.7515496167038654
[2019-03-23 09:31:06,959] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38478392]
[2019-03-23 09:31:06,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.0, 52.33333333333334, 1.0, 2.0, 0.4652508438119435, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530883.8952135417, 530883.8952135417, 137016.1164201869]
[2019-03-23 09:31:06,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:31:06,963] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.4173242e-16 1.0000000e+00 3.6278590e-23 1.9128059e-22 2.6610692e-25], sampled 0.1809755938809824
[2019-03-23 09:31:21,108] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38478392]
[2019-03-23 09:31:21,109] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.10664443333334, 92.48501270666668, 1.0, 2.0, 0.3749322092918826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417066.9567435118, 417066.9567435118, 124418.9539720254]
[2019-03-23 09:31:21,110] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:31:21,112] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.4173242e-16 1.0000000e+00 3.6278590e-23 1.9128059e-22 2.6610692e-25], sampled 0.007411079932160725
[2019-03-23 09:31:36,862] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38478392]
[2019-03-23 09:31:36,863] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.5, 89.0, 1.0, 2.0, 0.3297414148947842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 360335.3979272765, 360335.3979272761, 118331.7676722426]
[2019-03-23 09:31:36,864] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:31:36,867] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.4173242e-16 1.0000000e+00 3.6278590e-23 1.9128059e-22 2.6610692e-25], sampled 0.13914696230631562
[2019-03-23 09:31:47,936] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:31:48,136] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:31:48,189] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:31:48,191] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:31:48,363] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:31:49,380] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1275000, evaluation results [1275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:31:53,332] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5187580e-14 1.0000000e+00 1.0965325e-20 7.9392211e-23 6.0955278e-24], sum to 1.0000
[2019-03-23 09:31:53,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9962
[2019-03-23 09:31:53,349] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333334, 80.66666666666667, 1.0, 2.0, 0.2149988087887368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 233434.797656656, 233434.7976566563, 73527.41374435525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 170400.0000, 
sim time next is 171000.0000, 
raw observation next is [14.0, 82.5, 1.0, 2.0, 0.2129836173142588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 231246.2848854575, 231246.2848854578, 73023.00076805848], 
processed observation next is [1.0, 1.0, 0.2727272727272727, 0.825, 1.0, 1.0, 0.016229521642823486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08564677217979907, 0.08564677217979919, 0.17810487992209387], 
reward next is 0.8219, 
noisyNet noise sample is [array([0.57445544], dtype=float32), -0.54703605]. 
=============================================
[2019-03-23 09:31:53,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.52095]
 [72.52095]
 [72.52095]
 [72.52095]
 [72.52095]], R is [[72.61762238]
 [72.71211243]
 [72.80428314]
 [72.89419556]
 [72.98228455]].
[2019-03-23 09:31:56,007] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0691612e-17 1.0000000e+00 8.7964943e-25 1.4559064e-24 7.1508916e-27], sum to 1.0000
[2019-03-23 09:31:56,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9586
[2019-03-23 09:31:56,021] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 94.0, 1.0, 2.0, 0.2610276704456658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 283425.1615492334, 283425.1615492331, 91985.9162907057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 246600.0000, 
sim time next is 247200.0000, 
raw observation next is [15.33333333333333, 96.0, 1.0, 2.0, 0.2620800889469381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284568.2171813729, 284568.2171813732, 92556.29710241083], 
processed observation next is [0.0, 0.8695652173913043, 0.3333333333333332, 0.96, 1.0, 1.0, 0.07760011118367258, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10539563599310109, 0.10539563599310119, 0.22574706610344103], 
reward next is 0.7743, 
noisyNet noise sample is [array([0.5746251], dtype=float32), -0.13332556]. 
=============================================
[2019-03-23 09:31:58,052] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3770289e-17 1.0000000e+00 5.2400811e-24 3.1264912e-23 2.2128370e-26], sum to 1.0000
[2019-03-23 09:31:58,058] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0684
[2019-03-23 09:31:58,061] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 96.0, 1.0, 2.0, 0.2250548944428258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244355.9278572436, 244355.9278572439, 82324.26422016414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 286800.0000, 
sim time next is 287400.0000, 
raw observation next is [14.83333333333333, 95.0, 1.0, 2.0, 0.2269581269975035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 246422.907870062, 246422.9078700623, 83007.64098141323], 
processed observation next is [0.0, 0.30434782608695654, 0.3106060606060605, 0.95, 1.0, 1.0, 0.03369765874687937, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09126774365557852, 0.09126774365557863, 0.20245766093027617], 
reward next is 0.7975, 
noisyNet noise sample is [array([0.8684367], dtype=float32), 0.65127546]. 
=============================================
[2019-03-23 09:31:59,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3422826e-17 1.0000000e+00 8.0617773e-25 8.8613992e-24 5.8684468e-27], sum to 1.0000
[2019-03-23 09:31:59,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6697
[2019-03-23 09:31:59,297] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 83.0, 1.0, 2.0, 0.3046101367155888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331520.6916012447, 331520.6916012444, 111767.4649504162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [18.0, 83.0, 1.0, 2.0, 0.3046434892528854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 331555.6471144638, 331555.6471144636, 111769.2550915364], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.83, 1.0, 1.0, 0.13080436156610675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12279838782017177, 0.1227983878201717, 0.27260793924764976], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.3039167], dtype=float32), 0.99981934]. 
=============================================
[2019-03-23 09:31:59,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.25669]
 [78.25669]
 [78.25669]
 [78.25669]
 [78.25669]], R is [[78.20152283]
 [78.14690399]
 [78.09272766]
 [78.03894043]
 [77.98550415]].
[2019-03-23 09:31:59,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7094808e-16 1.0000000e+00 8.3555930e-25 2.2137172e-24 3.1631217e-27], sum to 1.0000
[2019-03-23 09:31:59,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1516
[2019-03-23 09:31:59,425] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2196157404409852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 238448.8565315725, 238448.8565315728, 80414.21268434114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 285000.0000, 
sim time next is 285600.0000, 
raw observation next is [14.33333333333333, 98.0, 1.0, 2.0, 0.2209028363951395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239846.6717723987, 239846.6717723984, 80977.88715310967], 
processed observation next is [0.0, 0.30434782608695654, 0.28787878787878773, 0.98, 1.0, 1.0, 0.026128545493924356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08883210065644397, 0.08883210065644385, 0.19750704183685286], 
reward next is 0.8025, 
noisyNet noise sample is [array([0.85331625], dtype=float32), -0.654984]. 
=============================================
[2019-03-23 09:32:00,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2672700e-18 1.0000000e+00 3.0294424e-24 5.2150914e-25 2.7849770e-28], sum to 1.0000
[2019-03-23 09:32:00,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2326
[2019-03-23 09:32:00,868] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.5, 71.5, 1.0, 2.0, 0.4041894618642209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438941.1156739252, 438941.1156739252, 87395.81485484118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 354600.0000, 
sim time next is 355200.0000, 
raw observation next is [12.33333333333333, 73.0, 1.0, 2.0, 0.4013425615439996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 435848.0570052839, 435848.0570052839, 87132.82908379873], 
processed observation next is [1.0, 0.08695652173913043, 0.19696969696969682, 0.73, 1.0, 1.0, 0.25167820192999946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1614252062982533, 0.1614252062982533, 0.21251909532633836], 
reward next is 0.7875, 
noisyNet noise sample is [array([-0.4081038], dtype=float32), -0.8094542]. 
=============================================
[2019-03-23 09:32:01,891] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1423445e-17 1.0000000e+00 5.9037946e-25 5.9984392e-24 4.0904961e-27], sum to 1.0000
[2019-03-23 09:32:01,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-23 09:32:01,900] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 73.66666666666667, 1.0, 2.0, 0.2913328846953019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 316341.4181282644, 316341.4181282641, 79751.8742258601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 375600.0000, 
sim time next is 376200.0000, 
raw observation next is [14.5, 74.5, 1.0, 2.0, 0.22582559641307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245192.9372653615, 245192.9372653618, 74010.20968543316], 
processed observation next is [1.0, 0.34782608695652173, 0.29545454545454547, 0.745, 1.0, 1.0, 0.0322819955163375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09081219898717093, 0.09081219898717104, 0.18051270654983698], 
reward next is 0.8195, 
noisyNet noise sample is [array([-0.21750371], dtype=float32), -0.13877936]. 
=============================================
[2019-03-23 09:32:07,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4330179e-17 1.0000000e+00 6.9732717e-24 1.7993226e-22 1.7391630e-26], sum to 1.0000
[2019-03-23 09:32:07,196] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1789
[2019-03-23 09:32:07,201] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 98.0, 1.0, 2.0, 0.2015537423920375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218833.5429180626, 218833.5429180629, 74283.7529883824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 427200.0000, 
sim time next is 427800.0000, 
raw observation next is [13.16666666666667, 99.0, 1.0, 2.0, 0.2005925255326135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 217789.6844427578, 217789.6844427575, 73944.16979363059], 
processed observation next is [1.0, 0.9565217391304348, 0.23484848484848497, 0.99, 1.0, 1.0, 0.0007406569157668644, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0806628460899103, 0.08066284608991019, 0.18035163364300144], 
reward next is 0.8196, 
noisyNet noise sample is [array([0.6903803], dtype=float32), 0.059771087]. 
=============================================
[2019-03-23 09:32:07,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7643794e-13 1.0000000e+00 9.9376849e-21 1.2820785e-21 6.7776809e-23], sum to 1.0000
[2019-03-23 09:32:07,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3753
[2019-03-23 09:32:07,444] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5483631237520248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 595606.5491451613, 595606.5491451609, 111158.6225218045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 445200.0000, 
sim time next is 445800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5500791682260833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597471.5825566523, 597471.5825566523, 111370.2717341069], 
processed observation next is [1.0, 0.13043478260869565, 0.22727272727272727, 1.0, 1.0, 1.0, 0.43759896028260403, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2212857713172786, 0.2212857713172786, 0.2716348091075778], 
reward next is 0.7284, 
noisyNet noise sample is [array([1.1902606], dtype=float32), 0.4767397]. 
=============================================
[2019-03-23 09:32:11,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0498831e-16 1.0000000e+00 3.8720986e-25 9.0115281e-24 4.0811932e-26], sum to 1.0000
[2019-03-23 09:32:11,198] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7205
[2019-03-23 09:32:11,206] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.00000000000001, 1.0, 2.0, 0.259273875976106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 281520.3315200994, 281520.3315200991, 87173.56030560962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 501000.0000, 
sim time next is 501600.0000, 
raw observation next is [15.0, 94.0, 1.0, 2.0, 0.2582840989128672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 280445.3188380913, 280445.318838091, 87059.78691388416], 
processed observation next is [1.0, 0.8260869565217391, 0.3181818181818182, 0.94, 1.0, 1.0, 0.07285512364108397, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10386863660670047, 0.10386863660670037, 0.2123409436924004], 
reward next is 0.7877, 
noisyNet noise sample is [array([-0.3085928], dtype=float32), 1.3437247]. 
=============================================
[2019-03-23 09:32:14,698] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1856595e-15 1.0000000e+00 8.6423051e-23 2.4349337e-22 9.9708192e-24], sum to 1.0000
[2019-03-23 09:32:14,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6904
[2019-03-23 09:32:14,708] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 92.0, 1.0, 2.0, 0.2515824231235125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273166.5842026772, 273166.5842026775, 87293.9670408106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 618000.0000, 
sim time next is 618600.0000, 
raw observation next is [15.16666666666667, 93.0, 1.0, 2.0, 0.24966938933657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271088.845472504, 271088.8454725043, 86570.98022209581], 
processed observation next is [1.0, 0.13043478260869565, 0.3257575757575759, 0.93, 1.0, 1.0, 0.0620867366707125, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1004032761009274, 0.10040327610092753, 0.21114873224901418], 
reward next is 0.7889, 
noisyNet noise sample is [array([-1.2892141], dtype=float32), 0.7960741]. 
=============================================
[2019-03-23 09:32:24,241] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.6334961e-13 1.0000000e+00 7.9945152e-20 4.4285353e-20 5.3616894e-23], sum to 1.0000
[2019-03-23 09:32:24,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2589
[2019-03-23 09:32:24,249] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 62.33333333333334, 1.0, 2.0, 0.4591187044696765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523708.1563121511, 523708.1563121511, 135490.7885071468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 764400.0000, 
sim time next is 765000.0000, 
raw observation next is [25.5, 63.0, 1.0, 2.0, 0.4567523482304043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520968.7934440237, 520968.7934440237, 135143.715724461], 
processed observation next is [1.0, 0.8695652173913043, 0.7954545454545454, 0.63, 1.0, 1.0, 0.3209404352880053, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19295140497926805, 0.19295140497926805, 0.3296188188401488], 
reward next is 0.6704, 
noisyNet noise sample is [array([-1.5023249], dtype=float32), 0.36528924]. 
=============================================
[2019-03-23 09:32:24,264] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.778275]
 [68.778275]
 [68.778275]
 [68.778275]
 [68.778275]], R is [[68.76086426]
 [68.74279022]
 [68.72409821]
 [68.7049408 ]
 [68.68533325]].
[2019-03-23 09:32:30,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.55919928e-14 1.00000000e+00 1.02536546e-19 3.10619180e-20
 2.99717824e-23], sum to 1.0000
[2019-03-23 09:32:30,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3845
[2019-03-23 09:32:30,649] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666666, 90.0, 1.0, 2.0, 0.398400083759033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449757.1277672657, 449757.1277672654, 125149.6602856817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 870000.0000, 
sim time next is 870600.0000, 
raw observation next is [19.83333333333334, 89.0, 1.0, 2.0, 0.3992217219054573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450875.9167420417, 450875.9167420414, 125333.3896089848], 
processed observation next is [0.0, 0.043478260869565216, 0.5378787878787882, 0.89, 1.0, 1.0, 0.2490271523818216, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16699108027483026, 0.16699108027483014, 0.30569119416825563], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.95174634], dtype=float32), -0.16233996]. 
=============================================
[2019-03-23 09:32:37,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5979345e-15 1.0000000e+00 5.5441432e-22 9.8787224e-21 2.0844170e-23], sum to 1.0000
[2019-03-23 09:32:37,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8321
[2019-03-23 09:32:37,078] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 100.0, 1.0, 2.0, 0.5076530163107033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551364.042313206, 551364.042313206, 111223.5332745275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1008600.0000, 
sim time next is 1009200.0000, 
raw observation next is [14.0, 100.0, 1.0, 2.0, 0.4893622590020345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 531487.5144979542, 531487.5144979545, 109488.8432863826], 
processed observation next is [1.0, 0.6956521739130435, 0.2727272727272727, 1.0, 1.0, 1.0, 0.3617028237525431, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19684722759183487, 0.196847227591835, 0.2670459592350795], 
reward next is 0.7330, 
noisyNet noise sample is [array([-0.49732324], dtype=float32), 0.63968104]. 
=============================================
[2019-03-23 09:32:37,808] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 09:32:37,809] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:32:37,811] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:32:37,812] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:32:37,815] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:37,815] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:37,815] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:37,817] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:32:37,817] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:32:37,819] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:37,820] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:32:37,839] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 09:32:37,865] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 09:32:37,891] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 09:32:37,915] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 09:32:37,916] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 09:32:48,832] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41662362]
[2019-03-23 09:32:48,834] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.66666666666667, 50.66666666666666, 1.0, 2.0, 0.2810088497188848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 305109.3780067945, 305109.3780067949, 93301.54724834942]
[2019-03-23 09:32:48,835] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:32:48,838] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6426506e-16 1.0000000e+00 3.5718047e-23 1.8986011e-22 2.6215527e-25], sampled 0.6600766178800926
[2019-03-23 09:32:56,859] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41662362]
[2019-03-23 09:32:56,863] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 72.0, 1.0, 2.0, 0.6400525489730124, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9848163788334728, 6.911199999999999, 6.9112, 77.32846344354104, 1267874.077384967, 1267874.077384967, 289781.9254408968]
[2019-03-23 09:32:56,863] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:32:56,865] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6426506e-16 1.0000000e+00 3.5718047e-23 1.8986011e-22 2.6215527e-25], sampled 0.45039240305178285
[2019-03-23 09:32:56,866] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1267874.077384967 W.
[2019-03-23 09:33:33,035] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41662362]
[2019-03-23 09:33:33,039] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.99748709, 96.91578274666668, 1.0, 2.0, 0.2946201152917543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 319891.9373489424, 319891.9373489424, 112986.7380593474]
[2019-03-23 09:33:33,040] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:33:33,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6426506e-16 1.0000000e+00 3.5718047e-23 1.8986011e-22 2.6215527e-25], sampled 0.7256764511473403
[2019-03-23 09:33:55,773] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41662362]
[2019-03-23 09:33:55,774] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.46858932, 56.52695472, 1.0, 2.0, 0.2713275664614999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294595.2100432771, 294595.2100432767, 91034.96763081908]
[2019-03-23 09:33:55,775] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:33:55,777] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6426506e-16 1.0000000e+00 3.5718047e-23 1.8986011e-22 2.6215527e-25], sampled 0.4578544597380396
[2019-03-23 09:34:18,413] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41662362]
[2019-03-23 09:34:18,413] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.201155465, 93.21205607499999, 1.0, 2.0, 0.5241484455203228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 597303.1882638992, 597303.1882638992, 149780.8445957302]
[2019-03-23 09:34:18,414] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:34:18,417] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6426506e-16 1.0000000e+00 3.5718047e-23 1.8986011e-22 2.6215527e-25], sampled 0.16923752543502435
[2019-03-23 09:34:18,736] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:34:18,828] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:34:18,844] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:34:18,947] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:34:19,026] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:34:20,041] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1300000, evaluation results [1300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:34:24,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.33217674e-14 1.00000000e+00 8.95926995e-21 1.19308926e-19
 9.72696672e-23], sum to 1.0000
[2019-03-23 09:34:24,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6103
[2019-03-23 09:34:24,478] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 86.33333333333333, 1.0, 2.0, 0.5203304083931412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592463.3440699412, 592463.3440699412, 145514.7879695651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210200.0000, 
sim time next is 1210800.0000, 
raw observation next is [23.6, 85.66666666666667, 1.0, 2.0, 0.5210115254744966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593216.1461624702, 593216.1461624702, 145615.6945076272], 
processed observation next is [1.0, 0.0, 0.7090909090909091, 0.8566666666666667, 1.0, 1.0, 0.4012644068431207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21970968376387787, 0.21970968376387787, 0.35516023050640777], 
reward next is 0.6448, 
noisyNet noise sample is [array([1.4815018], dtype=float32), -1.0478169]. 
=============================================
[2019-03-23 09:34:25,865] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4575717e-15 1.0000000e+00 2.6823202e-24 1.2139533e-22 4.2375108e-25], sum to 1.0000
[2019-03-23 09:34:25,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2258
[2019-03-23 09:34:25,876] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 69.33333333333334, 1.0, 2.0, 0.7245016076671473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 824669.5586981112, 824669.5586981116, 173884.9173854415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1170600.0000, 
sim time next is 1171200.0000, 
raw observation next is [26.33333333333334, 68.66666666666667, 1.0, 2.0, 0.9878084037453624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1124143.453808521, 1124143.453808521, 219908.2975498558], 
processed observation next is [1.0, 0.5652173913043478, 0.8333333333333336, 0.6866666666666668, 1.0, 1.0, 0.9847605046817028, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4163494273364892, 0.4163494273364892, 0.5363617013411117], 
reward next is 0.4636, 
noisyNet noise sample is [array([-2.307137], dtype=float32), -0.93186134]. 
=============================================
[2019-03-23 09:34:26,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.37916784e-14 1.00000000e+00 6.97327544e-23 1.53263998e-20
 3.33781919e-24], sum to 1.0000
[2019-03-23 09:34:26,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4992
[2019-03-23 09:34:26,356] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1396651.961630429 W.
[2019-03-23 09:34:26,364] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 65.33333333333333, 1.0, 2.0, 0.6190456928899057, 1.0, 1.0, 0.6190456928899057, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 77.32846344354104, 1396651.961630429, 1396651.961630429, 266423.5102893278], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1174200.0000, 
sim time next is 1174800.0000, 
raw observation next is [27.0, 64.66666666666667, 1.0, 2.0, 0.6142233108870543, 1.0, 2.0, 0.6142233108870543, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1385244.736713717, 1385244.736713717, 265168.1451237234], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.6466666666666667, 1.0, 1.0, 0.5177791386088179, 1.0, 1.0, 0.5177791386088179, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5130536061902655, 0.5130536061902655, 0.6467515734724961], 
reward next is 0.3532, 
noisyNet noise sample is [array([-0.80448943], dtype=float32), -0.9744968]. 
=============================================
[2019-03-23 09:34:33,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4795006e-15 1.0000000e+00 1.2796549e-21 1.2281612e-20 6.3670143e-24], sum to 1.0000
[2019-03-23 09:34:33,728] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2540
[2019-03-23 09:34:33,732] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.8950367762259857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1019755.038980954, 1019755.038980954, 201633.7315811075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1328400.0000, 
sim time next is 1329000.0000, 
raw observation next is [23.16666666666667, 89.0, 1.0, 2.0, 0.9977833120494295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.002941514123458, 6.9112, 81.64417062235076, 1510807.082062596, 1136442.89415328, 222935.1775193469], 
processed observation next is [1.0, 0.391304347826087, 0.6893939393939396, 0.89, 1.0, 1.0, 0.9972291400617869, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.10917415141234584, 0.0, 0.5368042620130496, 0.5595581785417022, 0.4209047756123259, 0.5437443354130412], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18662876], dtype=float32), 0.741551]. 
=============================================
[2019-03-23 09:34:33,750] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.71979]
 [66.71979]
 [66.71979]
 [66.71979]
 [66.71979]], R is [[66.05258942]
 [65.90027618]
 [65.78351593]
 [65.66088867]
 [65.52029419]].
[2019-03-23 09:34:42,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8952430e-15 1.0000000e+00 1.9154429e-21 4.2173477e-20 2.6687471e-23], sum to 1.0000
[2019-03-23 09:34:42,750] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6099
[2019-03-23 09:34:42,756] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4793960919468967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 546961.9143857162, 546961.914385716, 139127.3680182685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1479600.0000, 
sim time next is 1480200.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4764892117876702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543696.9113737689, 543696.9113737689, 138536.3458521967], 
processed observation next is [0.0, 0.13043478260869565, 0.5833333333333331, 1.0, 1.0, 1.0, 0.3456115147345877, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20136922643472924, 0.20136922643472924, 0.33789352646877246], 
reward next is 0.6621, 
noisyNet noise sample is [array([1.2822025], dtype=float32), 0.29490086]. 
=============================================
[2019-03-23 09:34:44,533] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5340601e-15 1.0000000e+00 1.0118358e-19 8.2026028e-20 3.4712480e-23], sum to 1.0000
[2019-03-23 09:34:44,539] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6854
[2019-03-23 09:34:44,543] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4299925501624713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 489298.0302683457, 489298.0302683457, 130793.2300743123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1551600.0000, 
sim time next is 1552200.0000, 
raw observation next is [20.83333333333333, 89.00000000000001, 1.0, 2.0, 0.4263842959443394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485042.3021190444, 485042.3021190444, 130290.827284428], 
processed observation next is [0.0, 1.0, 0.5833333333333331, 0.8900000000000001, 1.0, 1.0, 0.28298036993042425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17964529708112756, 0.17964529708112756, 0.3177825055717756], 
reward next is 0.6822, 
noisyNet noise sample is [array([0.01414882], dtype=float32), -0.16785222]. 
=============================================
[2019-03-23 09:34:47,167] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5768778e-15 1.0000000e+00 5.5719549e-24 3.0778466e-21 3.4999400e-24], sum to 1.0000
[2019-03-23 09:34:47,174] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2833
[2019-03-23 09:34:47,179] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.4620386972925497, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9326798383551451, 6.916821550469524, 6.9112, 77.3284478645446, 1050738.572012589, 1048912.807768507, 251573.0754482273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1591200.0000, 
sim time next is 1591800.0000, 
raw observation next is [23.16666666666667, 86.5, 1.0, 2.0, 0.8689538304335344, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846006550454, 990138.6905154863, 990138.6905154863, 196919.2601823378], 
processed observation next is [1.0, 0.43478260869565216, 0.6893939393939396, 0.865, 1.0, 1.0, 0.8361922880419178, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.508428790710319, 0.3667180335242542, 0.3667180335242542, 0.4802908784935068], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15417191], dtype=float32), 0.13613826]. 
=============================================
[2019-03-23 09:34:49,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4063566e-13 1.0000000e+00 7.2807552e-20 2.8446664e-20 2.5261419e-22], sum to 1.0000
[2019-03-23 09:34:49,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6315
[2019-03-23 09:34:49,405] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1388069.257224397 W.
[2019-03-23 09:34:49,409] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.738551521216807, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9767421763699047, 6.9112, 6.9112, 77.32846337268887, 1388069.257224397, 1388069.257224397, 297509.5337572973], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1606800.0000, 
sim time next is 1607400.0000, 
raw observation next is [27.0, 62.0, 1.0, 2.0, 0.7434898275602632, 0.0, 2.0, 0.0, 1.0, 2.0, 0.975721098288942, 6.911199999999999, 6.9112, 77.32846344310246, 1394496.815565687, 1394496.815565687, 297260.8611302139], 
processed observation next is [1.0, 0.6086956521739131, 0.8636363636363636, 0.62, 1.0, 1.0, 0.6793622844503289, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9653158546984888, -8.881784197001253e-17, 0.0, 0.5084288129177705, 0.5164803020613655, 0.5164803020613655, 0.7250264905614973], 
reward next is 0.2750, 
noisyNet noise sample is [array([-1.2350938], dtype=float32), 1.6475638]. 
=============================================
[2019-03-23 09:35:04,830] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6936782e-16 1.0000000e+00 9.5176439e-22 6.6299835e-21 3.0353058e-25], sum to 1.0000
[2019-03-23 09:35:04,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0471
[2019-03-23 09:35:04,841] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 46.66666666666667, 1.0, 2.0, 0.3113925527874732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338130.6163639897, 338130.61636399, 103806.8689667771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1880400.0000, 
sim time next is 1881000.0000, 
raw observation next is [22.5, 46.5, 1.0, 2.0, 0.3079430527254544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 334383.6333812024, 334383.6333812024, 101001.4073355877], 
processed observation next is [1.0, 0.782608695652174, 0.6590909090909091, 0.465, 1.0, 1.0, 0.134928815906818, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12384579014118607, 0.12384579014118607, 0.2463448959404578], 
reward next is 0.7537, 
noisyNet noise sample is [array([0.34316593], dtype=float32), 0.09967378]. 
=============================================
[2019-03-23 09:35:04,861] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.80269]
 [68.80269]
 [68.80269]
 [68.80269]
 [68.80269]], R is [[68.86831665]
 [68.92644501]
 [68.977005  ]
 [69.01893616]
 [69.06447601]].
[2019-03-23 09:35:08,377] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 09:35:08,382] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:35:08,383] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:35:08,385] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:35:08,386] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:35:08,386] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:35:08,387] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:35:08,387] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:35:08,388] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:35:08,387] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:35:08,390] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:35:08,410] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 09:35:08,411] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 09:35:08,465] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 09:35:08,466] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 09:35:08,518] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 09:35:31,282] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42084697]
[2019-03-23 09:35:31,284] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.5, 70.0, 1.0, 2.0, 0.3154624103670235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 342528.4845394892, 342528.4845394896, 116547.3606795231]
[2019-03-23 09:35:31,286] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:35:31,288] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2764312e-15 1.0000000e+00 9.0512946e-22 4.6730401e-21 9.6072238e-24], sampled 0.9619784862174693
[2019-03-23 09:35:35,074] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42084697]
[2019-03-23 09:35:35,075] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 85.66666666666667, 1.0, 2.0, 0.535490483407932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 610311.6774563895, 610311.6774563892, 151086.1190700368]
[2019-03-23 09:35:35,076] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:35:35,078] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2764312e-15 1.0000000e+00 9.0512946e-22 4.6730401e-21 9.6072238e-24], sampled 0.649211770473156
[2019-03-23 09:35:43,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42084697]
[2019-03-23 09:35:43,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.46666666666667, 58.66666666666666, 1.0, 2.0, 0.6676191570342931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 761258.7923226261, 761258.7923226258, 168332.0818491085]
[2019-03-23 09:35:43,108] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:35:43,111] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2764312e-15 1.0000000e+00 9.0512946e-22 4.6730401e-21 9.6072238e-24], sampled 0.3344189265939148
[2019-03-23 09:36:48,906] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:36:49,206] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:36:49,302] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:36:49,385] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:36:49,477] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:36:50,491] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1325000, evaluation results [1325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:36:51,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.49516482e-16 1.00000000e+00 1.02162744e-22 6.98517929e-22
 3.09354269e-25], sum to 1.0000
[2019-03-23 09:36:51,403] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6442
[2019-03-23 09:36:51,407] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.16666666666667, 76.16666666666667, 1.0, 2.0, 0.2280434439535432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 247601.6056257341, 247601.6056257338, 79002.58336174095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2008200.0000, 
sim time next is 2008800.0000, 
raw observation next is [16.0, 77.0, 1.0, 2.0, 0.2261991316963089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245598.6102204237, 245598.610220424, 78524.87787056869], 
processed observation next is [0.0, 0.2608695652173913, 0.36363636363636365, 0.77, 1.0, 1.0, 0.03274891462038611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09096244822978655, 0.09096244822978666, 0.1915240923672407], 
reward next is 0.8085, 
noisyNet noise sample is [array([-0.99786806], dtype=float32), 0.38796014]. 
=============================================
[2019-03-23 09:36:56,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3514924e-13 1.0000000e+00 1.7443434e-21 5.0692875e-21 3.8414860e-23], sum to 1.0000
[2019-03-23 09:36:56,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1273
[2019-03-23 09:36:56,460] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 61.33333333333333, 1.0, 2.0, 0.2904082093815906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315337.0415129002, 315337.0415128999, 110554.6060292125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2105400.0000, 
sim time next is 2106000.0000, 
raw observation next is [21.0, 60.0, 1.0, 2.0, 0.2941465232280215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 319397.587685739, 319397.5876857393, 110802.5359359315], 
processed observation next is [0.0, 0.391304347826087, 0.5909090909090909, 0.6, 1.0, 1.0, 0.11768315403502684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11829540284656999, 0.1182954028465701, 0.2702500876486134], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.32924795], dtype=float32), -0.62500924]. 
=============================================
[2019-03-23 09:36:56,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[75.12328]
 [75.12328]
 [75.12328]
 [75.12328]
 [75.12328]], R is [[75.10180664]
 [75.08114624]
 [75.06518555]
 [75.05683136]
 [75.0556488 ]].
[2019-03-23 09:36:59,522] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5379142e-16 1.0000000e+00 2.5948510e-23 8.8728076e-22 1.1886116e-24], sum to 1.0000
[2019-03-23 09:36:59,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1657
[2019-03-23 09:36:59,531] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 51.0, 1.0, 2.0, 0.3847935522139505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435244.1211361834, 435244.1211361831, 124433.0115951691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2124000.0000, 
sim time next is 2124600.0000, 
raw observation next is [26.16666666666667, 50.0, 1.0, 2.0, 0.3861022948915781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436728.8344243781, 436728.8344243781, 124553.0598184395], 
processed observation next is [0.0, 0.6086956521739131, 0.825757575757576, 0.5, 1.0, 1.0, 0.2326278686144726, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16175142015717708, 0.16175142015717708, 0.30378795077668175], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.4655293], dtype=float32), -1.1679542]. 
=============================================
[2019-03-23 09:37:00,743] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7129134e-13 1.0000000e+00 6.5311305e-21 1.1061201e-19 1.3695941e-22], sum to 1.0000
[2019-03-23 09:37:00,748] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9317
[2019-03-23 09:37:00,751] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 58.83333333333334, 1.0, 2.0, 0.3005056016681337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 326304.879011088, 326304.8790110883, 111227.3601403342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2157000.0000, 
sim time next is 2157600.0000, 
raw observation next is [20.66666666666667, 64.66666666666667, 1.0, 2.0, 0.306643637342823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 334347.2617299545, 334347.2617299542, 112123.2747235553], 
processed observation next is [0.0, 1.0, 0.575757575757576, 0.6466666666666667, 1.0, 1.0, 0.13330454667852876, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12383231915924241, 0.1238323191592423, 0.27347140176476903], 
reward next is 0.7265, 
noisyNet noise sample is [array([0.76951903], dtype=float32), -0.07324443]. 
=============================================
[2019-03-23 09:37:01,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8667659e-15 1.0000000e+00 2.0415535e-22 2.1169763e-22 1.7671718e-25], sum to 1.0000
[2019-03-23 09:37:01,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8166
[2019-03-23 09:37:01,286] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.36666666666667, 94.83333333333334, 1.0, 2.0, 0.2680790317747169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291083.8565108483, 291083.856510848, 84326.74172512924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2178600.0000, 
sim time next is 2179200.0000, 
raw observation next is [14.33333333333333, 94.66666666666667, 1.0, 2.0, 0.2474882752024005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 268719.9565244907, 268719.9565244907, 82236.35379335395], 
processed observation next is [1.0, 0.21739130434782608, 0.28787878787878773, 0.9466666666666668, 1.0, 1.0, 0.0593603440030006, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09952590982388546, 0.09952590982388546, 0.20057647266671694], 
reward next is 0.7994, 
noisyNet noise sample is [array([-1.5652263], dtype=float32), -1.0461245]. 
=============================================
[2019-03-23 09:37:01,584] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4138450e-16 1.0000000e+00 5.7999756e-24 4.9015439e-22 7.1330504e-26], sum to 1.0000
[2019-03-23 09:37:01,593] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2153
[2019-03-23 09:37:01,596] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.3032969092368858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 329336.8547555919, 329336.8547555922, 110322.604075456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2165400.0000, 
sim time next is 2166000.0000, 
raw observation next is [17.0, 88.0, 1.0, 2.0, 0.3017394041185956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327645.0583012966, 327645.0583012966, 110185.898786017], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.88, 1.0, 1.0, 0.1271742551482445, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12135002159307282, 0.12135002159307282, 0.26874609460004145], 
reward next is 0.7313, 
noisyNet noise sample is [array([0.29706454], dtype=float32), -0.27154267]. 
=============================================
[2019-03-23 09:37:01,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.59509]
 [71.59509]
 [71.59509]
 [71.59509]
 [71.59509]], R is [[71.61038971]
 [71.62520599]
 [71.63965607]
 [71.65379333]
 [71.66667938]].
[2019-03-23 09:37:05,506] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3825828e-15 1.0000000e+00 4.2748441e-22 2.6041439e-22 7.0355245e-25], sum to 1.0000
[2019-03-23 09:37:05,525] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9851
[2019-03-23 09:37:05,531] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 54.66666666666667, 1.0, 2.0, 0.4034189425017942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438103.9711116278, 438103.9711116278, 93618.34218203645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2287200.0000, 
sim time next is 2287800.0000, 
raw observation next is [18.0, 54.0, 1.0, 2.0, 0.4147830297837002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450450.8334303189, 450450.8334303186, 94496.99485362924], 
processed observation next is [1.0, 0.4782608695652174, 0.45454545454545453, 0.54, 1.0, 1.0, 0.2684787872296252, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16683364201122922, 0.16683364201122913, 0.23048047525275422], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.00183428], dtype=float32), -1.4633245]. 
=============================================
[2019-03-23 09:37:08,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9096467e-17 1.0000000e+00 7.5020049e-24 7.3459374e-24 8.5248701e-27], sum to 1.0000
[2019-03-23 09:37:08,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7762
[2019-03-23 09:37:08,041] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 202594.7467028977, 202594.746702898, 68417.81049881934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2354400.0000, 
sim time next is 2355000.0000, 
raw observation next is [13.5, 85.33333333333334, 1.0, 2.0, 0.2093025909421774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227248.6885777822, 227248.6885777819, 72027.8340181798], 
processed observation next is [1.0, 0.2608695652173913, 0.25, 0.8533333333333334, 1.0, 1.0, 0.011628238677721739, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08416618095473415, 0.08416618095473404, 0.17567764394677998], 
reward next is 0.8243, 
noisyNet noise sample is [array([1.6405268], dtype=float32), 1.5746757]. 
=============================================
[2019-03-23 09:37:08,067] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.70694]
 [76.70694]
 [76.70694]
 [76.70694]
 [76.70694]], R is [[76.7641983 ]
 [75.99655914]
 [75.23659515]
 [74.48423004]
 [73.73938751]].
[2019-03-23 09:37:16,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0522343e-13 1.0000000e+00 7.7793434e-22 3.6496832e-21 4.7996621e-24], sum to 1.0000
[2019-03-23 09:37:16,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5400
[2019-03-23 09:37:16,598] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 75.0, 1.0, 2.0, 0.613426190913632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 666323.4749055696, 666323.4749055699, 133077.4177067456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2467800.0000, 
sim time next is 2468400.0000, 
raw observation next is [18.0, 74.33333333333333, 1.0, 2.0, 0.6097527048779942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 662330.4957136337, 662330.4957136337, 132050.1784418766], 
processed observation next is [1.0, 0.5652173913043478, 0.45454545454545453, 0.7433333333333333, 1.0, 1.0, 0.5121908810974927, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24530759100504954, 0.24530759100504954, 0.3220736059557966], 
reward next is 0.6779, 
noisyNet noise sample is [array([1.2570032], dtype=float32), -0.49056676]. 
=============================================
[2019-03-23 09:37:18,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.72035399e-15 1.00000000e+00 1.26262345e-24 1.20522321e-22
 3.18377729e-25], sum to 1.0000
[2019-03-23 09:37:18,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6961
[2019-03-23 09:37:18,995] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 51.0, 1.0, 2.0, 0.6737789235225539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 735080.6392715886, 735080.6392715883, 145184.4521255889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2559000.0000, 
sim time next is 2559600.0000, 
raw observation next is [23.0, 50.0, 1.0, 2.0, 0.6921186861012161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 757051.3392571855, 757051.3392571855, 147863.7098788805], 
processed observation next is [1.0, 0.6521739130434783, 0.6818181818181818, 0.5, 1.0, 1.0, 0.6151483576265201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2803893849100687, 0.2803893849100687, 0.3606431948265378], 
reward next is 0.6394, 
noisyNet noise sample is [array([0.07464685], dtype=float32), 0.22250964]. 
=============================================
[2019-03-23 09:37:22,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6250270e-16 1.0000000e+00 3.2990223e-23 3.6948462e-21 9.1683955e-24], sum to 1.0000
[2019-03-23 09:37:22,497] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4182
[2019-03-23 09:37:22,505] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 69.0, 1.0, 2.0, 0.3851146315969883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 435291.9959306064, 435291.9959306067, 124269.1705529561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2625600.0000, 
sim time next is 2626200.0000, 
raw observation next is [23.0, 67.0, 1.0, 2.0, 0.385538403342085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435849.6489598649, 435849.6489598646, 124354.5201161529], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.67, 1.0, 1.0, 0.23192300417760622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16142579591106107, 0.16142579591106096, 0.3033037076003729], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.7270481], dtype=float32), 0.13327225]. 
=============================================
[2019-03-23 09:37:26,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3574304e-17 1.0000000e+00 5.9887452e-24 2.9348955e-22 8.0305578e-26], sum to 1.0000
[2019-03-23 09:37:26,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4820
[2019-03-23 09:37:26,164] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.4, 85.5, 1.0, 2.0, 0.3361023113739292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 370739.8638278311, 370739.8638278308, 115739.5490411606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2687400.0000, 
sim time next is 2688000.0000, 
raw observation next is [18.26666666666667, 86.0, 1.0, 2.0, 0.3352849152501854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369384.0799089549, 369384.0799089549, 115505.0963629855], 
processed observation next is [0.0, 0.08695652173913043, 0.4666666666666668, 0.86, 1.0, 1.0, 0.16910614406273172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13680891848479812, 0.13680891848479812, 0.2817197472267939], 
reward next is 0.7183, 
noisyNet noise sample is [array([-0.35236835], dtype=float32), -0.17112651]. 
=============================================
[2019-03-23 09:37:26,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.7896]
 [72.7896]
 [72.7896]
 [72.7896]
 [72.7896]], R is [[72.77998352]
 [72.76988983]
 [72.75921631]
 [72.74778748]
 [72.73547363]].
[2019-03-23 09:37:32,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5578183e-13 1.0000000e+00 1.5263729e-21 4.2650937e-19 1.3975395e-22], sum to 1.0000
[2019-03-23 09:37:32,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7314
[2019-03-23 09:37:32,031] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3216783218051674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 354002.7727720173, 354002.7727720173, 114354.3016940536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2785200.0000, 
sim time next is 2785800.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3214903569271784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353794.7631565205, 353794.7631565208, 114340.2377222111], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.88, 1.0, 1.0, 0.151862946158973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13103509746537795, 0.13103509746537806, 0.2788786285907588], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.13462938], dtype=float32), -0.536215]. 
=============================================
[2019-03-23 09:37:34,895] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5307048e-15 1.0000000e+00 7.9717847e-23 1.3411589e-21 1.5707738e-23], sum to 1.0000
[2019-03-23 09:37:34,906] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1901
[2019-03-23 09:37:34,909] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 86.33333333333334, 1.0, 2.0, 0.5835598916951967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 665819.0080318232, 665819.0080318232, 150148.3241252878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3118800.0000, 
sim time next is 3119400.0000, 
raw observation next is [22.0, 85.5, 1.0, 2.0, 0.5337574884032581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 608834.4245660999, 608834.4245660995, 143753.6381420469], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.855, 1.0, 1.0, 0.41719686050407256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22549423132077773, 0.22549423132077762, 0.35061862961474854], 
reward next is 0.6494, 
noisyNet noise sample is [array([1.0722861], dtype=float32), -2.2183754]. 
=============================================
[2019-03-23 09:37:38,801] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 09:37:38,803] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:37:38,803] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:37:38,804] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:38,805] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:37:38,806] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:37:38,807] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:37:38,805] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:38,809] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:38,808] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:38,809] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:37:38,826] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 09:37:38,854] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 09:37:38,856] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 09:37:38,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 09:37:38,900] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 09:38:16,891] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:16,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.65011912333333, 93.492926295, 1.0, 2.0, 0.5023870024561561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 572167.4023297152, 572167.4023297149, 143246.2819853227]
[2019-03-23 09:38:16,892] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:38:16,897] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.31021249785853366
[2019-03-23 09:38:26,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:26,483] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.777218445, 63.12092944, 1.0, 2.0, 0.485045833335023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 553371.5952407788, 553371.5952407788, 143057.6993449688]
[2019-03-23 09:38:26,484] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:38:26,488] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.6554242985743632
[2019-03-23 09:38:38,174] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:38,175] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.71666666666667, 62.83333333333334, 1.0, 2.0, 0.5927411360764937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 668485.6987339192, 668485.6987339188, 161643.6332827796]
[2019-03-23 09:38:38,178] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:38:38,181] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.8653126495444389
[2019-03-23 09:38:39,052] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:39,053] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.13333333333333, 85.33333333333334, 1.0, 2.0, 0.5130158451345015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 585027.2103038641, 585027.2103038637, 147890.6030303384]
[2019-03-23 09:38:39,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:38:39,059] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.8077202569573511
[2019-03-23 09:38:41,497] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:41,499] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.6, 58.66666666666667, 1.0, 2.0, 0.4980978961794634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 567134.5651423028, 567134.5651423028, 142607.3008514707]
[2019-03-23 09:38:41,500] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:38:41,507] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.836199651216246
[2019-03-23 09:38:45,151] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:45,152] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.5, 87.0, 1.0, 2.0, 0.3664283685375503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 411216.1252234902, 411216.1252234902, 125344.6953095351]
[2019-03-23 09:38:45,153] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:38:45,158] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.9187448004044134
[2019-03-23 09:38:45,303] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:45,305] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.33333333333334, 67.16666666666666, 1.0, 2.0, 0.7171935531351327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 817422.4034252553, 817422.4034252553, 170959.4012234436]
[2019-03-23 09:38:45,306] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:38:45,309] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.8697420710640688
[2019-03-23 09:38:54,423] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:38:54,424] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.9, 93.0, 1.0, 2.0, 0.4202660818823343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476848.4641822498, 476848.4641822498, 128678.4248059482]
[2019-03-23 09:38:54,426] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:38:54,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.4691493907692741
[2019-03-23 09:39:02,695] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:39:02,696] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.51053248, 66.694897075, 1.0, 2.0, 0.4927631179001005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 562206.8456803601, 562206.8456803598, 144739.0217361806]
[2019-03-23 09:39:02,698] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:39:02,701] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.34950045845053834
[2019-03-23 09:39:08,344] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:39:08,345] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.75581645, 96.74679179, 1.0, 2.0, 0.4614943543424458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 526394.1347658124, 526394.1347658121, 140129.2410602797]
[2019-03-23 09:39:08,346] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:39:08,349] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.08789773596790618
[2019-03-23 09:39:17,335] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:39:17,335] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 96.33333333333334, 1.0, 2.0, 0.4077726934457163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 460847.8849258842, 460847.8849258845, 126298.2782253169]
[2019-03-23 09:39:17,335] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:39:17,339] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.07028099650440889
[2019-03-23 09:39:17,363] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36368686]
[2019-03-23 09:39:17,364] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.2, 67.0, 1.0, 2.0, 0.2322379609544682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 252144.5804864949, 252144.5804864949, 83453.84215034277]
[2019-03-23 09:39:17,366] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:39:17,368] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [9.4126313e-14 1.0000000e+00 4.8067078e-20 2.3350378e-19 7.6547639e-22], sampled 0.06543980940588412
[2019-03-23 09:39:19,108] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:39:19,345] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:39:19,425] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:39:19,598] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:39:19,611] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:39:20,627] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1350000, evaluation results [1350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:39:22,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5717078e-12 1.0000000e+00 9.1562116e-21 1.4876534e-18 4.0637885e-21], sum to 1.0000
[2019-03-23 09:39:22,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0670
[2019-03-23 09:39:22,306] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 88.0, 1.0, 2.0, 0.3538154541998506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390929.9733424254, 390929.9733424254, 117331.7248713573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3027000.0000, 
sim time next is 3027600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3498075616041232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385426.3384592746, 385426.3384592746, 116614.0113400956], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 0.88, 1.0, 1.0, 0.18725945200515395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14275049572565726, 0.14275049572565726, 0.2844244179026722], 
reward next is 0.7156, 
noisyNet noise sample is [array([0.4323683], dtype=float32), 0.39892226]. 
=============================================
[2019-03-23 09:39:23,032] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2379091e-13 1.0000000e+00 6.9027007e-20 1.2642804e-18 5.3197235e-22], sum to 1.0000
[2019-03-23 09:39:23,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2551
[2019-03-23 09:39:23,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1380932.996476295 W.
[2019-03-23 09:39:23,047] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 64.66666666666666, 1.0, 2.0, 0.6108447920453802, 1.0, 2.0, 0.6108447920453802, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1380932.996476295, 1380932.996476295, 263350.3572074456], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2976000.0000, 
sim time next is 2976600.0000, 
raw observation next is [26.83333333333333, 63.33333333333334, 1.0, 2.0, 0.588087202040988, 1.0, 2.0, 0.588087202040988, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1330827.181986569, 1330827.181986569, 256596.2502426492], 
processed observation next is [1.0, 0.43478260869565216, 0.8560606060606059, 0.6333333333333334, 1.0, 1.0, 0.4851090025512349, 1.0, 1.0, 0.4851090025512349, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.49289895629132185, 0.49289895629132185, 0.6258445127869493], 
reward next is 0.3742, 
noisyNet noise sample is [array([0.06992186], dtype=float32), -0.6477842]. 
=============================================
[2019-03-23 09:39:26,994] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6267977e-14 1.0000000e+00 4.1081008e-21 2.7497624e-19 1.2457506e-22], sum to 1.0000
[2019-03-23 09:39:27,002] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0000
[2019-03-23 09:39:27,011] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.5, 1.0, 2.0, 0.5971463425209921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 659216.9347269076, 659216.9347269076, 139555.353085059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3054600.0000, 
sim time next is 3055200.0000, 
raw observation next is [18.33333333333333, 86.66666666666666, 1.0, 2.0, 0.6475941971459486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 716770.9419855453, 716770.941985545, 145741.9160387191], 
processed observation next is [1.0, 0.34782608695652173, 0.4696969696969695, 0.8666666666666666, 1.0, 1.0, 0.5594927464324356, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2654707192539057, 0.26547071925390553, 0.3554680878993149], 
reward next is 0.6445, 
noisyNet noise sample is [array([-1.0901765], dtype=float32), -0.5497821]. 
=============================================
[2019-03-23 09:39:30,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9448835e-13 1.0000000e+00 6.8860036e-19 2.2634908e-18 2.8326992e-21], sum to 1.0000
[2019-03-23 09:39:30,211] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4505
[2019-03-23 09:39:30,218] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4504427790091548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511610.3718078391, 511610.3718078391, 132033.9996275283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3135000.0000, 
sim time next is 3135600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4457297248511113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506241.4661714248, 506241.4661714248, 131547.0300909847], 
processed observation next is [1.0, 0.30434782608695654, 0.6363636363636364, 0.78, 1.0, 1.0, 0.3071621560638891, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1874968393227499, 0.1874968393227499, 0.3208464148560603], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.22887011], dtype=float32), 1.2965375]. 
=============================================
[2019-03-23 09:39:31,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3235345e-16 1.0000000e+00 2.6407588e-21 1.7529484e-21 1.5054375e-24], sum to 1.0000
[2019-03-23 09:39:31,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7636
[2019-03-23 09:39:31,905] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 89.0, 1.0, 2.0, 0.5374355615314994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 611760.231701785, 611760.2317017852, 147762.6728230692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3102600.0000, 
sim time next is 3103200.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5308054072433199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604624.8415171591, 604624.8415171591, 146613.2193180486], 
processed observation next is [1.0, 0.9565217391304348, 0.6818181818181818, 0.89, 1.0, 1.0, 0.41350675905414985, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22393512648783673, 0.22393512648783673, 0.357593217848899], 
reward next is 0.6424, 
noisyNet noise sample is [array([-1.0611275], dtype=float32), 0.12097891]. 
=============================================
[2019-03-23 09:39:32,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4056569e-13 1.0000000e+00 1.5840564e-20 4.6609032e-19 4.7850783e-22], sum to 1.0000
[2019-03-23 09:39:32,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4674
[2019-03-23 09:39:32,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1253031.427779739 W.
[2019-03-23 09:39:32,133] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.5497959040399679, 1.0, 1.0, 0.5497959040399679, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1253031.427779739, 1253031.427779739, 242078.944026664], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3170400.0000, 
sim time next is 3171000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3679291866979855, 1.0, 2.0, 0.3679291866979855, 1.0, 1.0, 0.745240758263298, 6.911199999999999, 6.9112, 77.3421103, 1256133.714853348, 1256133.714853348, 285627.6930108458], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.74, 1.0, 1.0, 0.2099114833724819, 1.0, 1.0, 0.2099114833724819, 1.0, 0.5, 0.6360582260904258, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4652347092049437, 0.4652347092049437, 0.6966529097825508], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.84856415], dtype=float32), -1.8854146]. 
=============================================
[2019-03-23 09:39:32,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.41615]
 [62.41615]
 [62.41615]
 [62.41615]
 [62.41615]], R is [[61.79198456]
 [61.58362961]
 [61.30158615]
 [60.68857193]
 [60.37663651]].
[2019-03-23 09:39:34,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0503849e-14 1.0000000e+00 2.9122114e-22 3.6834611e-21 2.3813508e-23], sum to 1.0000
[2019-03-23 09:39:34,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9413
[2019-03-23 09:39:34,407] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 94.0, 1.0, 2.0, 0.3888644780554948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438172.9190402292, 438172.9190402295, 123838.5604077375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3207600.0000, 
sim time next is 3208200.0000, 
raw observation next is [18.83333333333334, 94.00000000000001, 1.0, 2.0, 0.3855302887050325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433855.7167689805, 433855.7167689805, 123248.8248825479], 
processed observation next is [0.0, 0.13043478260869565, 0.4924242424242427, 0.9400000000000002, 1.0, 1.0, 0.23191286088129057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1606873025070298, 0.1606873025070298, 0.3006068899574339], 
reward next is 0.6994, 
noisyNet noise sample is [array([0.11727283], dtype=float32), -1.6932217]. 
=============================================
[2019-03-23 09:39:39,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0994909e-16 1.0000000e+00 2.5961493e-22 2.1041428e-22 2.8806185e-25], sum to 1.0000
[2019-03-23 09:39:39,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4606
[2019-03-23 09:39:39,873] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 81.16666666666667, 1.0, 2.0, 0.2886934594811117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 313474.4962506196, 313474.4962506199, 97858.32542964337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3282600.0000, 
sim time next is 3283200.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2867675250771526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 311382.5728662632, 311382.5728662635, 96817.25668430219], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.10845940634644072, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11532687883935674, 0.11532687883935686, 0.23613965044951754], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.5837305], dtype=float32), -1.2505935]. 
=============================================
[2019-03-23 09:39:42,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7532738e-15 1.0000000e+00 1.2588261e-21 9.9323684e-23 4.9538123e-25], sum to 1.0000
[2019-03-23 09:39:42,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3133
[2019-03-23 09:39:42,634] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 54.0, 1.0, 2.0, 0.3461989087637435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386430.6556348579, 386430.6556348579, 118368.5902411232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3326400.0000, 
sim time next is 3327000.0000, 
raw observation next is [24.0, 54.0, 1.0, 2.0, 0.3481597106984216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388804.1578161587, 388804.1578161587, 118607.3451975545], 
processed observation next is [0.0, 0.5217391304347826, 0.7272727272727273, 0.54, 1.0, 1.0, 0.185199638373027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14400153993191064, 0.14400153993191064, 0.2892862077989134], 
reward next is 0.7107, 
noisyNet noise sample is [array([1.7363987], dtype=float32), -0.43471155]. 
=============================================
[2019-03-23 09:39:42,655] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.87156]
 [71.87156]
 [71.87156]
 [71.87156]
 [71.87156]], R is [[71.86357117]
 [71.85623169]
 [71.85040283]
 [71.8460083 ]
 [71.84295654]].
[2019-03-23 09:39:45,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2923682e-14 1.0000000e+00 3.4060745e-20 7.8944728e-21 8.6270876e-23], sum to 1.0000
[2019-03-23 09:39:45,885] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8670
[2019-03-23 09:39:45,890] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 84.0, 1.0, 2.0, 0.5576422747355227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631899.2616776883, 631899.2616776883, 151738.7030769052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3440400.0000, 
sim time next is 3441000.0000, 
raw observation next is [24.33333333333333, 86.5, 1.0, 2.0, 0.5601452009886931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 634643.2759094269, 634643.2759094265, 152099.0642521191], 
processed observation next is [1.0, 0.8260869565217391, 0.7424242424242422, 0.865, 1.0, 1.0, 0.45018150123586637, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23505306515163957, 0.23505306515163946, 0.3709733274441929], 
reward next is 0.6290, 
noisyNet noise sample is [array([-0.9749225], dtype=float32), -0.6089491]. 
=============================================
[2019-03-23 09:39:45,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.53951]
 [66.53951]
 [66.53951]
 [66.53951]
 [66.53951]], R is [[66.50315094]
 [66.46802521]
 [66.43399048]
 [66.4010849 ]
 [66.36933136]].
[2019-03-23 09:39:46,499] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8284886e-13 1.0000000e+00 1.5907901e-20 1.9500437e-20 9.5261803e-22], sum to 1.0000
[2019-03-23 09:39:46,505] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5767
[2019-03-23 09:39:46,510] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 78.0, 1.0, 2.0, 0.6904522156575673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 783142.2545198718, 783142.254519872, 159453.178810487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3400800.0000, 
sim time next is 3401400.0000, 
raw observation next is [21.83333333333334, 78.0, 1.0, 2.0, 0.7032312671129247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 798555.7042171211, 798555.7042171208, 161803.8308857737], 
processed observation next is [1.0, 0.34782608695652173, 0.628787878787879, 0.78, 1.0, 1.0, 0.6290390838911558, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2957613719322671, 0.2957613719322669, 0.3946434899653017], 
reward next is 0.6054, 
noisyNet noise sample is [array([0.5149252], dtype=float32), 0.6486475]. 
=============================================
[2019-03-23 09:39:46,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0076192e-14 1.0000000e+00 7.3762757e-21 2.7739626e-19 5.1205135e-23], sum to 1.0000
[2019-03-23 09:39:46,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4398
[2019-03-23 09:39:46,585] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3506162167975383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388297.8200219888, 388297.8200219888, 117437.9834741831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3391800.0000, 
sim time next is 3392400.0000, 
raw observation next is [17.33333333333334, 98.0, 1.0, 2.0, 0.3418434499230469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 378974.9681550421, 378974.9681550418, 116918.9692738403], 
processed observation next is [1.0, 0.2608695652173913, 0.42424242424242453, 0.98, 1.0, 1.0, 0.1773043124038086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14036109931668225, 0.14036109931668214, 0.28516821774107387], 
reward next is 0.7148, 
noisyNet noise sample is [array([-1.0710329], dtype=float32), -0.40047938]. 
=============================================
[2019-03-23 09:39:54,275] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8405991e-13 1.0000000e+00 6.2272069e-19 1.0277430e-18 3.5111515e-21], sum to 1.0000
[2019-03-23 09:39:54,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3443
[2019-03-23 09:39:54,293] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1697173.729468949 W.
[2019-03-23 09:39:54,298] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 82.33333333333333, 1.0, 2.0, 0.518483913276359, 1.0, 1.0, 0.5030303935797867, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 85.67542473108588, 1697173.729468949, 1697173.729468949, 363525.7322048694], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3589800.0000, 
sim time next is 3590400.0000, 
raw observation next is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.5296609644337641, 1.0, 2.0, 0.5086189191584893, 1.0, 2.0, 0.9865530188920543, 6.911199999999999, 6.9112, 77.3421103, 1716307.662783944, 1716307.662783944, 361077.6370120635], 
processed observation next is [1.0, 0.5652173913043478, 0.8333333333333336, 0.8066666666666668, 1.0, 1.0, 0.4120762055422051, 1.0, 1.0, 0.3857736489481116, 1.0, 1.0, 0.9807900269886491, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.6356695047347941, 0.6356695047347941, 0.8806771634440573], 
reward next is 0.1193, 
noisyNet noise sample is [array([0.5676389], dtype=float32), 0.71749353]. 
=============================================
[2019-03-23 09:39:58,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0576045e-13 1.0000000e+00 2.1197767e-18 7.7713768e-19 1.0532821e-21], sum to 1.0000
[2019-03-23 09:39:58,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1447
[2019-03-23 09:39:58,079] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 82.16666666666667, 1.0, 2.0, 0.518140843904466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 590086.3562937574, 590086.3562937574, 145154.2168815394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3607800.0000, 
sim time next is 3608400.0000, 
raw observation next is [24.0, 81.33333333333334, 1.0, 2.0, 0.5136132866351661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585183.8992926861, 585183.8992926861, 144380.2401802913], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.8133333333333335, 1.0, 1.0, 0.3920166082939576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2167347775158097, 0.2167347775158097, 0.35214692726900315], 
reward next is 0.6479, 
noisyNet noise sample is [array([-0.49319315], dtype=float32), -0.27602515]. 
=============================================
[2019-03-23 09:40:00,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8166870e-13 1.0000000e+00 8.6005174e-20 8.7853496e-20 4.5075628e-22], sum to 1.0000
[2019-03-23 09:40:00,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1099
[2019-03-23 09:40:00,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1258966.196345432 W.
[2019-03-23 09:40:00,483] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 76.0, 1.0, 2.0, 0.5547305894281561, 1.0, 2.0, 0.5547305894281561, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846326664067, 1258966.196345432, 1258966.196345432, 246320.9842565373], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3672600.0000, 
sim time next is 3673200.0000, 
raw observation next is [25.0, 74.0, 1.0, 2.0, 0.3075336770182674, 1.0, 2.0, 0.3075336770182674, 1.0, 1.0, 0.6226970950280181, 6.911199999999999, 6.9112, 77.3421103, 1044843.444984102, 1044843.444984102, 264417.3137947786], 
processed observation next is [1.0, 0.5217391304347826, 0.7727272727272727, 0.74, 1.0, 1.0, 0.1344170962728342, 1.0, 1.0, 0.1344170962728342, 1.0, 0.5, 0.46099585004002586, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.38697905369781554, 0.38697905369781554, 0.6449202775482404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52330154], dtype=float32), 0.15942177]. 
=============================================
[2019-03-23 09:40:01,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3687469e-13 1.0000000e+00 5.7537789e-19 2.0593757e-18 2.7111501e-20], sum to 1.0000
[2019-03-23 09:40:01,106] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5584
[2019-03-23 09:40:01,112] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5257067463730998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599549.0974007729, 599549.0974007729, 145150.9164448066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3729600.0000, 
sim time next is 3730200.0000, 
raw observation next is [21.83333333333334, 94.00000000000001, 1.0, 2.0, 0.5560504814332045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 634325.4267569595, 634325.4267569595, 148616.7954710978], 
processed observation next is [1.0, 0.17391304347826086, 0.628787878787879, 0.9400000000000002, 1.0, 1.0, 0.44506310179150554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23493534324331836, 0.23493534324331836, 0.3624799889538971], 
reward next is 0.6375, 
noisyNet noise sample is [array([2.1313684], dtype=float32), -0.46353534]. 
=============================================
[2019-03-23 09:40:03,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5766159e-15 1.0000000e+00 3.7390438e-20 5.7571570e-20 1.5417209e-23], sum to 1.0000
[2019-03-23 09:40:03,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4663
[2019-03-23 09:40:03,778] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5089935710144614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 580482.6410448605, 580482.6410448605, 143142.8333144495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3722400.0000, 
sim time next is 3723000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.8863941770010234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 85.22654624974355, 1011078.557698673, 1011078.557698673, 201220.1634675362], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.8579927212512791, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5603581114827346, 0.3744735398883974, 0.3744735398883974, 0.49078088650618584], 
reward next is 0.5092, 
noisyNet noise sample is [array([0.74505347], dtype=float32), -1.682925]. 
=============================================
[2019-03-23 09:40:03,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.7195]
 [63.7195]
 [63.7195]
 [63.7195]
 [63.7195]], R is [[63.59152222]
 [63.60647964]
 [63.62092972]
 [63.63525009]
 [63.64985275]].
[2019-03-23 09:40:03,922] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4108213e-14 1.0000000e+00 9.3762780e-21 1.7213154e-19 5.8551124e-22], sum to 1.0000
[2019-03-23 09:40:03,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5007
[2019-03-23 09:40:03,935] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 94.0, 1.0, 2.0, 0.3502312029572296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387083.2220995162, 387083.2220995162, 117098.7535242938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4037400.0000, 
sim time next is 4038000.0000, 
raw observation next is [17.33333333333333, 94.0, 1.0, 2.0, 0.3453853844239688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380617.737869088, 380617.7378690882, 116302.3145568291], 
processed observation next is [1.0, 0.7391304347826086, 0.42424242424242403, 0.94, 1.0, 1.0, 0.181731730529961, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14096953254410668, 0.14096953254410674, 0.2836641818459246], 
reward next is 0.7163, 
noisyNet noise sample is [array([0.0236211], dtype=float32), -0.10651375]. 
=============================================
[2019-03-23 09:40:03,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.31301]
 [63.31301]
 [63.31301]
 [63.31301]
 [63.31301]], R is [[63.39621735]
 [63.47665024]
 [63.5527916 ]
 [63.61463547]
 [63.64365005]].
[2019-03-23 09:40:03,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7733061e-14 1.0000000e+00 2.0491014e-19 1.0555126e-17 6.9048533e-22], sum to 1.0000
[2019-03-23 09:40:04,008] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2865
[2019-03-23 09:40:04,016] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 94.0, 1.0, 2.0, 0.339685892228969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373221.2908191834, 373221.2908191837, 115457.1286439191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4038600.0000, 
sim time next is 4039200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3345622444334198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366451.8598301183, 366451.8598301183, 114663.8665722539], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.94, 1.0, 1.0, 0.16820280554177475, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13572291104819198, 0.13572291104819198, 0.27966796724939974], 
reward next is 0.7203, 
noisyNet noise sample is [array([-0.44179344], dtype=float32), 0.79784715]. 
=============================================
[2019-03-23 09:40:04,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2345105e-13 1.0000000e+00 8.1629514e-22 3.5539767e-21 1.3758143e-23], sum to 1.0000
[2019-03-23 09:40:04,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4036
[2019-03-23 09:40:04,305] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 56.66666666666667, 1.0, 2.0, 0.3820268641120507, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7683678497977314, 6.9112, 6.9112, 77.3284634434936, 871863.3278025294, 871863.3278025294, 213280.0296625896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3759600.0000, 
sim time next is 3760200.0000, 
raw observation next is [26.0, 56.0, 1.0, 2.0, 0.6414701296296923, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354076, 730679.7626264321, 730679.7626264318, 155679.0685163394], 
processed observation next is [1.0, 0.5217391304347826, 0.8181818181818182, 0.56, 1.0, 1.0, 0.5518376620371154, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206522, 0.27062213430608595, 0.27062213430608584, 0.3797050451618034], 
reward next is 0.6203, 
noisyNet noise sample is [array([-0.43461668], dtype=float32), 0.6068953]. 
=============================================
[2019-03-23 09:40:06,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4978967e-14 1.0000000e+00 4.3644678e-21 4.2644711e-21 1.3867742e-23], sum to 1.0000
[2019-03-23 09:40:06,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8451
[2019-03-23 09:40:06,466] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3305697046222101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 361684.9367589866, 361684.9367589863, 114233.375117231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3806400.0000, 
sim time next is 3807000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3289831895895513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 359947.9792539942, 359947.9792539942, 114118.7584787035], 
processed observation next is [0.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.1612289869869391, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13331406639036822, 0.13331406639036822, 0.278338435313911], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.41227773], dtype=float32), 0.07058024]. 
=============================================
[2019-03-23 09:40:06,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.489525]
 [72.489525]
 [72.489525]
 [72.489525]
 [72.489525]], R is [[72.48629761]
 [72.4828186 ]
 [72.47964478]
 [72.47683716]
 [72.47421265]].
[2019-03-23 09:40:07,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4881317e-16 1.0000000e+00 4.1369875e-22 5.3826003e-20 5.0892730e-25], sum to 1.0000
[2019-03-23 09:40:07,261] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1198
[2019-03-23 09:40:07,269] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 84.83333333333334, 1.0, 2.0, 0.3434242280828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378956.8321703812, 378956.8321703812, 116344.249383605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3786600.0000, 
sim time next is 3787200.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3416763748208801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376289.4215244665, 376289.4215244662, 115931.8251060038], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17709546852610009, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13936645241646906, 0.13936645241646897, 0.28276054903903364], 
reward next is 0.7172, 
noisyNet noise sample is [array([1.9248285], dtype=float32), 0.3567719]. 
=============================================
[2019-03-23 09:40:08,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8605594e-16 1.0000000e+00 3.0022819e-23 2.8436559e-21 4.9083660e-25], sum to 1.0000
[2019-03-23 09:40:08,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5328
[2019-03-23 09:40:08,194] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 88.66666666666667, 1.0, 2.0, 0.3163924317204428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346487.4467434597, 346487.44674346, 113337.6296285474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3831600.0000, 
sim time next is 3832200.0000, 
raw observation next is [18.0, 86.0, 1.0, 2.0, 0.3178351782353355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 348226.0696776807, 348226.069677681, 113497.6492677612], 
processed observation next is [0.0, 0.34782608695652173, 0.45454545454545453, 0.86, 1.0, 1.0, 0.1472939727941694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12897261839914098, 0.12897261839914112, 0.27682353479941757], 
reward next is 0.7232, 
noisyNet noise sample is [array([1.2665175], dtype=float32), -0.3103833]. 
=============================================
[2019-03-23 09:40:09,317] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 09:40:09,320] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:40:09,321] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:40:09,322] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:40:09,323] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:40:09,323] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:40:09,324] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:40:09,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:40:09,325] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:40:09,325] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:40:09,327] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:40:09,347] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 09:40:09,376] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 09:40:09,376] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 09:40:09,376] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 09:40:09,452] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 09:40:26,468] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42382306]
[2019-03-23 09:40:26,469] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.94383093, 87.12303588500001, 1.0, 2.0, 0.6576213835474167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 738930.0661510249, 738930.0661510245, 171495.7677606792]
[2019-03-23 09:40:26,470] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:40:26,473] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.8111854e-16 1.0000000e+00 6.0155825e-23 3.2607011e-22 4.7484856e-25], sampled 0.8646708602735784
[2019-03-23 09:40:55,534] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42382306]
[2019-03-23 09:40:55,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.63612383666667, 54.19092514, 1.0, 2.0, 0.3308483663477863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 363123.5110643363, 363123.5110643363, 118978.7836464249]
[2019-03-23 09:40:55,538] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:40:55,540] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.8111854e-16 1.0000000e+00 6.0155825e-23 3.2607011e-22 4.7484856e-25], sampled 0.08184711462003214
[2019-03-23 09:41:16,092] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42382306]
[2019-03-23 09:41:16,093] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.54974631166667, 100.0, 1.0, 2.0, 0.395218922116974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 446128.0787361016, 446128.0787361016, 129169.1162260549]
[2019-03-23 09:41:16,095] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:41:16,098] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [7.8111854e-16 1.0000000e+00 6.0155825e-23 3.2607011e-22 4.7484856e-25], sampled 0.8179130784957303
[2019-03-23 09:41:45,733] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42382306]
[2019-03-23 09:41:45,734] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.35, 61.5, 1.0, 2.0, 0.2859781488117803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 310506.259343695, 310506.259343695, 97093.05481063813]
[2019-03-23 09:41:45,734] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:41:45,737] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.8111854e-16 1.0000000e+00 6.0155825e-23 3.2607011e-22 4.7484856e-25], sampled 0.9882883321887116
[2019-03-23 09:41:48,785] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42382306]
[2019-03-23 09:41:48,787] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.072824445, 72.415489295, 1.0, 2.0, 0.3152255886350347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 346978.0922278185, 346978.0922278182, 118234.2395431699]
[2019-03-23 09:41:48,788] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:41:48,791] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.8111854e-16 1.0000000e+00 6.0155825e-23 3.2607011e-22 4.7484856e-25], sampled 0.48482400766910794
[2019-03-23 09:41:49,136] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:41:49,502] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:41:49,549] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:41:49,669] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:41:49,695] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:41:50,707] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1375000, evaluation results [1375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:41:52,411] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2567416e-16 1.0000000e+00 1.0398646e-20 1.5732512e-22 2.7358085e-24], sum to 1.0000
[2019-03-23 09:41:52,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0780
[2019-03-23 09:41:52,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 77.0, 1.0, 2.0, 0.2812653472231958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305406.2327507673, 305406.2327507673, 101637.6843283391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894000.0000, 
sim time next is 3894600.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.281362457399602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305511.7109732488, 305511.710973249, 101643.3464513569], 
processed observation next is [0.0, 0.043478260869565216, 0.45454545454545453, 0.77, 1.0, 1.0, 0.10170307174950245, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1131524855456477, 0.11315248554564777, 0.2479106011008705], 
reward next is 0.7521, 
noisyNet noise sample is [array([0.7171984], dtype=float32), 0.4061169]. 
=============================================
[2019-03-23 09:41:53,124] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9858860e-16 1.0000000e+00 3.2785444e-25 7.3631955e-23 9.0236961e-26], sum to 1.0000
[2019-03-23 09:41:53,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5327
[2019-03-23 09:41:53,140] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 57.66666666666666, 1.0, 2.0, 0.3405862679409606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378506.4108385473, 378506.4108385473, 117204.0403004181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3856200.0000, 
sim time next is 3856800.0000, 
raw observation next is [23.0, 58.33333333333334, 1.0, 2.0, 0.3440894373123491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 382961.9978796279, 382961.9978796279, 117713.9577019531], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.5833333333333335, 1.0, 1.0, 0.18011179664043633, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14183777699245478, 0.14183777699245478, 0.2871072139072027], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.11019684], dtype=float32), -0.25211307]. 
=============================================
[2019-03-23 09:41:55,329] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8447363e-17 1.0000000e+00 2.5211827e-23 1.0333901e-22 1.0590656e-25], sum to 1.0000
[2019-03-23 09:41:55,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8252
[2019-03-23 09:41:55,343] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 46.66666666666667, 1.0, 2.0, 0.3347484620520323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 372274.9818601834, 372274.9818601834, 116862.3934518291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [25.33333333333334, 46.33333333333334, 1.0, 2.0, 0.3376301024170078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375921.2889882079, 375921.2889882082, 117274.1372078825], 
processed observation next is [0.0, 0.5217391304347826, 0.7878787878787882, 0.46333333333333343, 1.0, 1.0, 0.17203762802125974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13923010703266958, 0.13923010703266972, 0.28603448099483536], 
reward next is 0.7140, 
noisyNet noise sample is [array([1.1370503], dtype=float32), 0.26262274]. 
=============================================
[2019-03-23 09:41:57,581] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4794878e-17 1.0000000e+00 7.5208090e-22 7.1947714e-22 2.5194989e-24], sum to 1.0000
[2019-03-23 09:41:57,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6575
[2019-03-23 09:41:57,594] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 53.66666666666667, 1.0, 2.0, 0.3220360675148651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353658.7723394582, 353658.7723394582, 114102.4062646259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3960600.0000, 
sim time next is 3961200.0000, 
raw observation next is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.5433333333333334, 1.0, 1.0, 0.15232919094777073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13082397889296254, 0.13082397889296268, 0.2780468098392517], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.44085547], dtype=float32), -0.15105797]. 
=============================================
[2019-03-23 09:41:58,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0677650e-14 1.0000000e+00 1.7520992e-21 1.8472847e-21 1.4035547e-23], sum to 1.0000
[2019-03-23 09:41:58,493] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-23 09:41:58,498] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.91666666666667, 77.5, 1.0, 2.0, 0.2841579316104174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308548.0827947466, 308548.0827947463, 101660.7507304346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3978600.0000, 
sim time next is 3979200.0000, 
raw observation next is [17.83333333333334, 78.0, 1.0, 2.0, 0.2843422445095502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 308748.2793672562, 308748.2793672562, 101343.3713712544], 
processed observation next is [1.0, 0.043478260869565216, 0.44696969696969724, 0.78, 1.0, 1.0, 0.10542780563693774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11435121458046527, 0.11435121458046527, 0.2471789545640351], 
reward next is 0.7528, 
noisyNet noise sample is [array([-1.6035821], dtype=float32), -0.52412903]. 
=============================================
[2019-03-23 09:42:07,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.13469033e-14 1.00000000e+00 3.00646969e-20 1.23438458e-20
 1.17014436e-23], sum to 1.0000
[2019-03-23 09:42:07,367] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-23 09:42:07,371] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.331483987102119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366821.4108692124, 366821.4108692126, 115857.4452158532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4167000.0000, 
sim time next is 4167600.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3314010326702816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366728.5716894891, 366728.5716894894, 115850.7949666023], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 1.0, 1.0, 1.0, 0.16425129083785198, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13582539692203302, 0.1358253969220331, 0.28256291455268856], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.62670916], dtype=float32), -0.56921333]. 
=============================================
[2019-03-23 09:42:09,961] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2913390e-14 1.0000000e+00 5.0130361e-22 9.9963129e-21 7.9905354e-24], sum to 1.0000
[2019-03-23 09:42:09,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6126
[2019-03-23 09:42:09,983] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 63.66666666666667, 1.0, 2.0, 0.5960029246070693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 673525.8676731569, 673525.8676731571, 146020.7522216648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4191600.0000, 
sim time next is 4192200.0000, 
raw observation next is [23.5, 63.0, 1.0, 2.0, 0.5346918171936101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 604210.5984482459, 604210.5984482459, 139057.5450543764], 
processed observation next is [1.0, 0.5217391304347826, 0.7045454545454546, 0.63, 1.0, 1.0, 0.4183647714920126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22378170312897996, 0.22378170312897996, 0.33916474403506436], 
reward next is 0.6608, 
noisyNet noise sample is [array([-0.4979868], dtype=float32), -0.3569297]. 
=============================================
[2019-03-23 09:42:10,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1966920e-16 1.0000000e+00 2.2476127e-21 1.1158411e-21 1.0685743e-24], sum to 1.0000
[2019-03-23 09:42:10,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2469
[2019-03-23 09:42:10,390] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 70.33333333333334, 1.0, 2.0, 0.4119434333621848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 466446.6021575693, 466446.6021575696, 127227.6422723491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4213200.0000, 
sim time next is 4213800.0000, 
raw observation next is [22.5, 71.0, 1.0, 2.0, 0.4077157371280898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461437.485132498, 461437.485132498, 126690.4105814183], 
processed observation next is [1.0, 0.782608695652174, 0.6590909090909091, 0.71, 1.0, 1.0, 0.2596446714101122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17090277227129558, 0.17090277227129558, 0.3090010014180934], 
reward next is 0.6910, 
noisyNet noise sample is [array([-0.7128596], dtype=float32), -0.38679737]. 
=============================================
[2019-03-23 09:42:15,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9353367e-14 1.0000000e+00 2.9489138e-21 7.7600269e-20 8.1858979e-23], sum to 1.0000
[2019-03-23 09:42:15,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2244
[2019-03-23 09:42:15,027] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2548986015751719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 276768.2940535975, 276768.2940535972, 89781.14139355613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4604400.0000, 
sim time next is 4605000.0000, 
raw observation next is [16.16666666666667, 87.00000000000001, 1.0, 2.0, 0.2659667779004223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288789.6615930272, 288789.6615930269, 91535.86452729454], 
processed observation next is [1.0, 0.30434782608695654, 0.37121212121212144, 0.8700000000000001, 1.0, 1.0, 0.08245847237552784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1069591339233434, 0.10695913392334329, 0.22325820616413303], 
reward next is 0.7767, 
noisyNet noise sample is [array([-0.4232886], dtype=float32), -0.22772548]. 
=============================================
[2019-03-23 09:42:15,044] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.13463]
 [69.13463]
 [69.13463]
 [69.13463]
 [69.13463]], R is [[69.22002411]
 [69.30884552]
 [69.40286255]
 [69.50153351]
 [69.604599  ]].
[2019-03-23 09:42:16,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3647123e-15 1.0000000e+00 1.1902560e-21 1.5700445e-21 2.0849816e-23], sum to 1.0000
[2019-03-23 09:42:16,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9710
[2019-03-23 09:42:16,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1389426.336774277 W.
[2019-03-23 09:42:16,057] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 58.0, 1.0, 2.0, 0.4075460009749505, 1.0, 1.0, 0.4075460009749505, 1.0, 2.0, 0.8255647582563606, 6.911199999999999, 6.9112, 77.3421103, 1389426.336774277, 1389426.336774277, 304822.759485781], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4362600.0000, 
sim time next is 4363200.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.5906629210565951, 1.0, 2.0, 0.5906629210565951, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1342865.627573099, 1342865.627573099, 254904.2278585694], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.58, 1.0, 1.0, 0.4883286513207439, 1.0, 1.0, 0.4883286513207439, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4973576398418885, 0.4973576398418885, 0.6217176289233399], 
reward next is 0.3783, 
noisyNet noise sample is [array([0.06333818], dtype=float32), 0.25467318]. 
=============================================
[2019-03-23 09:42:25,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0965317e-14 1.0000000e+00 1.8751865e-22 3.7766748e-19 1.5719255e-22], sum to 1.0000
[2019-03-23 09:42:25,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0493
[2019-03-23 09:42:25,440] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 67.66666666666667, 1.0, 2.0, 0.399700475937742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452810.7581111881, 452810.7581111881, 126236.259527762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4547400.0000, 
sim time next is 4548000.0000, 
raw observation next is [23.33333333333334, 66.33333333333334, 1.0, 2.0, 0.3998630627461124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 452868.272995636, 452868.2729956358, 126167.6661929554], 
processed observation next is [0.0, 0.6521739130434783, 0.6969696969696972, 0.6633333333333334, 1.0, 1.0, 0.24982882843264045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1677289899983837, 0.16772898999838362, 0.30772601510476927], 
reward next is 0.6923, 
noisyNet noise sample is [array([0.02347983], dtype=float32), -1.078159]. 
=============================================
[2019-03-23 09:42:25,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.57434]
 [67.57434]
 [67.57434]
 [67.57434]
 [67.57434]], R is [[67.59087372]
 [67.60707092]
 [67.62405396]
 [67.6439209 ]
 [67.66638184]].
[2019-03-23 09:42:26,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6548783e-14 1.0000000e+00 5.3331798e-20 2.2511159e-19 4.7792567e-23], sum to 1.0000
[2019-03-23 09:42:26,074] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-23 09:42:26,077] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 94.0, 1.0, 2.0, 0.4553378588981704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518974.290113049, 518974.290113049, 134322.613904694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4497600.0000, 
sim time next is 4498200.0000, 
raw observation next is [20.5, 94.0, 1.0, 2.0, 0.4499717501016298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512566.4781352606, 512566.4781352606, 133382.0111200084], 
processed observation next is [0.0, 0.043478260869565216, 0.5681818181818182, 0.94, 1.0, 1.0, 0.3124646876270372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1898394363463928, 0.1898394363463928, 0.3253219783414839], 
reward next is 0.6747, 
noisyNet noise sample is [array([-0.244773], dtype=float32), -1.3895895]. 
=============================================
[2019-03-23 09:42:26,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2755712e-15 1.0000000e+00 7.9613080e-21 1.6746806e-20 2.7760107e-23], sum to 1.0000
[2019-03-23 09:42:26,382] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2757
[2019-03-23 09:42:26,386] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.3928323945068219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 444171.1683943663, 444171.1683943666, 125057.320835738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4550400.0000, 
sim time next is 4551000.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.3918336075314381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442985.09104493, 442985.0910449303, 124932.5846566247], 
processed observation next is [0.0, 0.6956521739130435, 0.7272727272727273, 0.61, 1.0, 1.0, 0.2397920094142976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16406855223886296, 0.16406855223886307, 0.3047136211137188], 
reward next is 0.6953, 
noisyNet noise sample is [array([0.17505458], dtype=float32), -0.43749228]. 
=============================================
[2019-03-23 09:42:26,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.91956]
 [69.91956]
 [69.91956]
 [69.91956]
 [69.91956]], R is [[69.91565704]
 [69.91148376]
 [69.90662384]
 [69.9010849 ]
 [69.89489746]].
[2019-03-23 09:42:27,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.79387641e-14 1.00000000e+00 1.18012024e-20 9.82277430e-20
 2.12794818e-21], sum to 1.0000
[2019-03-23 09:42:27,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9604
[2019-03-23 09:42:27,536] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2625354588303387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 285062.8055848001, 285062.8055848004, 90675.23837278981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4585800.0000, 
sim time next is 4586400.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2617761519879255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 284238.104072609, 284238.1040726087, 90592.74181878754], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07722018998490683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10527337187874407, 0.10527337187874396, 0.22095790687509156], 
reward next is 0.7790, 
noisyNet noise sample is [array([0.2123071], dtype=float32), 0.3127453]. 
=============================================
[2019-03-23 09:42:30,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5204141e-15 1.0000000e+00 4.0966237e-24 3.5684700e-22 4.0962955e-24], sum to 1.0000
[2019-03-23 09:42:30,052] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4577
[2019-03-23 09:42:30,057] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 83.0, 1.0, 2.0, 0.7422070561248427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 843691.9704476943, 843691.9704476943, 167855.2717486244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4886400.0000, 
sim time next is 4887000.0000, 
raw observation next is [21.5, 83.0, 1.0, 2.0, 0.7797854964890104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 887321.6685258156, 887321.6685258156, 174056.2043489424], 
processed observation next is [1.0, 0.5652173913043478, 0.6136363636363636, 0.83, 1.0, 1.0, 0.7247318706112629, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3286376550095613, 0.3286376550095613, 0.42452732768034734], 
reward next is 0.5755, 
noisyNet noise sample is [array([0.6078522], dtype=float32), 0.87099147]. 
=============================================
[2019-03-23 09:42:30,081] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.786964]
 [72.786964]
 [72.786964]
 [72.786964]
 [72.786964]], R is [[72.63456726]
 [72.49882507]
 [72.391922  ]
 [72.33097839]
 [72.28418732]].
[2019-03-23 09:42:38,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2581266e-15 1.0000000e+00 2.6351322e-22 1.5095400e-21 1.3667438e-23], sum to 1.0000
[2019-03-23 09:42:38,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6808
[2019-03-23 09:42:38,898] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.7397966229188008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 839833.6673420384, 839833.6673420384, 166662.8141682965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4784400.0000, 
sim time next is 4785000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.6573863613017588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 746110.7504468913, 746110.7504468913, 155467.9147090999], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.5717329516271984, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2763373149803301, 0.2763373149803301, 0.37919003587585337], 
reward next is 0.6208, 
noisyNet noise sample is [array([-0.0037926], dtype=float32), 1.3202809]. 
=============================================
[2019-03-23 09:42:38,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.85928]
 [67.85928]
 [67.85928]
 [67.85928]
 [67.85928]], R is [[67.80150604]
 [67.71699524]
 [67.63411713]
 [67.5520401 ]
 [67.4739151 ]].
[2019-03-23 09:42:39,801] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5553012e-16 1.0000000e+00 1.7453009e-22 3.3089557e-22 3.2316700e-25], sum to 1.0000
[2019-03-23 09:42:39,810] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-23 09:42:39,819] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4661425616334453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528543.5336695788, 528543.5336695788, 132989.8579308875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4865400.0000, 
sim time next is 4866000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4417414720324274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500846.0270205991, 500846.0270205993, 130519.1796274957], 
processed observation next is [1.0, 0.30434782608695654, 0.5, 1.0, 1.0, 1.0, 0.30217684004053424, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18549852852614782, 0.18549852852614787, 0.3183394625060871], 
reward next is 0.6817, 
noisyNet noise sample is [array([1.125277], dtype=float32), 1.458145]. 
=============================================
[2019-03-23 09:42:39,837] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.00766]
 [68.00766]
 [68.00766]
 [68.00766]
 [68.00766]], R is [[68.00924683]
 [68.00479126]
 [68.00270844]
 [68.00284576]
 [68.00735474]].
[2019-03-23 09:42:39,978] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 09:42:39,984] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:42:39,985] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:39,986] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:42:39,986] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:42:39,986] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:39,987] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:42:39,987] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:42:39,988] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:39,987] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:39,989] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:42:40,009] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 09:42:40,034] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 09:42:40,073] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 09:42:40,095] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 09:42:40,118] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 09:43:16,783] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4055507]
[2019-03-23 09:43:16,785] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.65, 99.5, 1.0, 2.0, 0.328318973363902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 360678.3728340906, 360678.3728340906, 114601.7398036387]
[2019-03-23 09:43:16,786] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:43:16,795] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.4298114e-14 1.0000000e+00 3.1172174e-21 1.6014454e-20 3.7371269e-23], sampled 0.89451456506399
[2019-03-23 09:43:23,165] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4055507]
[2019-03-23 09:43:23,166] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.7067643, 86.03176496333333, 1.0, 2.0, 0.580377294941415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 659699.0681937952, 659699.0681937952, 158112.4442633994]
[2019-03-23 09:43:23,168] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:43:23,170] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.4298114e-14 1.0000000e+00 3.1172174e-21 1.6014454e-20 3.7371269e-23], sampled 0.35260149894509973
[2019-03-23 09:43:23,948] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4055507]
[2019-03-23 09:43:23,949] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.89423302666667, 92.41951036333333, 1.0, 2.0, 0.4290072281898691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 486952.0310232224, 486952.031023222, 134000.9804451882]
[2019-03-23 09:43:23,950] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:43:23,955] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4298114e-14 1.0000000e+00 3.1172174e-21 1.6014454e-20 3.7371269e-23], sampled 0.5264022238675942
[2019-03-23 09:44:04,056] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4055507]
[2019-03-23 09:44:04,056] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.64308609, 82.34599623, 1.0, 2.0, 0.6751394241334793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 758626.4794920575, 758626.4794920575, 174132.2918087716]
[2019-03-23 09:44:04,060] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:44:04,064] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.4298114e-14 1.0000000e+00 3.1172174e-21 1.6014454e-20 3.7371269e-23], sampled 0.21272801454736745
[2019-03-23 09:44:06,920] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4055507]
[2019-03-23 09:44:06,920] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.83333333333333, 54.33333333333334, 1.0, 2.0, 0.3606602031137609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 402296.5632218859, 402296.5632218859, 123731.498652965]
[2019-03-23 09:44:06,922] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:44:06,925] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.4298114e-14 1.0000000e+00 3.1172174e-21 1.6014454e-20 3.7371269e-23], sampled 0.05659717210723336
[2019-03-23 09:44:20,723] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:44:20,786] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:44:21,006] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:44:21,056] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:44:21,093] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:44:22,109] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1400000, evaluation results [1400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:44:24,675] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.7439458e-14 1.0000000e+00 4.7105202e-20 1.3511893e-19 6.6091978e-22], sum to 1.0000
[2019-03-23 09:44:24,683] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6831
[2019-03-23 09:44:24,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1178394.873863141 W.
[2019-03-23 09:44:24,693] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5218440628505403, 1.0, 2.0, 0.5218440628505403, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846343927433, 1178394.873863141, 1178394.873863141, 239830.5586897307], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4809600.0000, 
sim time next is 4810200.0000, 
raw observation next is [22.0, 99.00000000000001, 1.0, 2.0, 0.4700753787969643, 1.0, 2.0, 0.4700753787969643, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344351464, 1062532.607356071, 1062532.60735607, 226809.1588113707], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.9900000000000001, 1.0, 1.0, 0.3375942234962054, 1.0, 1.0, 0.3375942234962054, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129204805, 0.39353059531706336, 0.39353059531706297, 0.5531930702716359], 
reward next is 0.4468, 
noisyNet noise sample is [array([-1.6146953], dtype=float32), -1.4221201]. 
=============================================
[2019-03-23 09:44:26,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5322815e-15 1.0000000e+00 5.9120750e-22 2.0659743e-21 9.8410193e-24], sum to 1.0000
[2019-03-23 09:44:26,697] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8359
[2019-03-23 09:44:26,704] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4199084648685328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477039.4878292025, 477039.4878292025, 129100.3908253982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4850400.0000, 
sim time next is 4851000.0000, 
raw observation next is [20.0, 94.0, 1.0, 2.0, 0.4150020672130239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471447.0900417712, 471447.0900417712, 128611.135307073], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.94, 1.0, 1.0, 0.2687525840162798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17461003334880415, 0.17461003334880415, 0.3136856958709097], 
reward next is 0.6863, 
noisyNet noise sample is [array([-1.526537], dtype=float32), -1.6997133]. 
=============================================
[2019-03-23 09:44:26,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.64928]
 [65.64928]
 [65.64928]
 [65.64928]
 [65.64928]], R is [[65.67910004]
 [65.70742798]
 [65.73008728]
 [65.74817657]
 [65.76553345]].
[2019-03-23 09:44:31,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1534185e-16 1.0000000e+00 8.7086924e-23 2.0716722e-21 2.0518662e-23], sum to 1.0000
[2019-03-23 09:44:31,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1817
[2019-03-23 09:44:31,310] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.4949870657817326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542622.3476937641, 542622.3476937641, 128005.5555938832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4956000.0000, 
sim time next is 4956600.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.5188150923229332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 569011.1481951758, 569011.1481951762, 130316.4644521534], 
processed observation next is [1.0, 0.34782608695652173, 0.4090909090909091, 0.94, 1.0, 1.0, 0.3985188654036665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21074486970191697, 0.21074486970191708, 0.31784503524915464], 
reward next is 0.6822, 
noisyNet noise sample is [array([0.40377283], dtype=float32), -0.43476686]. 
=============================================
[2019-03-23 09:44:33,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0874294e-15 1.0000000e+00 4.2761815e-22 8.4777434e-21 3.4063778e-25], sum to 1.0000
[2019-03-23 09:44:33,318] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-23 09:44:33,325] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2756332786145833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299288.8843221362, 299288.8843221365, 95623.10474029719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5011200.0000, 
sim time next is 5011800.0000, 
raw observation next is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2740152009870689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297531.4013827565, 297531.4013827562, 94851.73891866134], 
processed observation next is [0.0, 0.0, 0.40151515151515177, 0.8300000000000002, 1.0, 1.0, 0.09251900123383609, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11019681532694685, 0.11019681532694674, 0.2313457046796618], 
reward next is 0.7687, 
noisyNet noise sample is [array([-0.9055233], dtype=float32), -0.7215088]. 
=============================================
[2019-03-23 09:44:39,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2400478e-13 1.0000000e+00 1.2940379e-21 1.2587643e-20 5.0320203e-23], sum to 1.0000
[2019-03-23 09:44:39,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0520
[2019-03-23 09:44:39,623] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.4036410748284259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 456088.0511426257, 456088.0511426257, 125864.6619422887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5422800.0000, 
sim time next is 5423400.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.4020107353877769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454242.0378813867, 454242.0378813867, 125712.9460820156], 
processed observation next is [1.0, 0.782608695652174, 0.5181818181818181, 0.93, 1.0, 1.0, 0.25251341923472104, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.168237791807921, 0.168237791807921, 0.30661694166345266], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.03169172], dtype=float32), -2.2387006]. 
=============================================
[2019-03-23 09:44:40,487] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0347083e-14 1.0000000e+00 2.5123719e-21 3.9753357e-20 1.2599544e-22], sum to 1.0000
[2019-03-23 09:44:40,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8656
[2019-03-23 09:44:40,499] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.400301652117823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453622.6443276401, 453622.6443276398, 126379.7445047885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5112000.0000, 
sim time next is 5112600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4001169321438467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453413.2536427455, 453413.2536427452, 126362.5553931215], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2501461651798083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16793083468249834, 0.16793083468249823, 0.3082013546173695], 
reward next is 0.6918, 
noisyNet noise sample is [array([-1.124634], dtype=float32), -1.2339964]. 
=============================================
[2019-03-23 09:44:41,353] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7236653e-16 1.0000000e+00 3.6035441e-22 2.8243046e-21 7.0413779e-25], sum to 1.0000
[2019-03-23 09:44:41,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7430
[2019-03-23 09:44:41,366] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 80.83333333333334, 1.0, 2.0, 0.5184935019522673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 589895.922885592, 589895.922885592, 145625.873598064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5141400.0000, 
sim time next is 5142000.0000, 
raw observation next is [25.0, 78.66666666666667, 1.0, 2.0, 0.5256338423851808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 597475.9917698953, 597475.9917698953, 146825.0516508891], 
processed observation next is [0.0, 0.5217391304347826, 0.7727272727272727, 0.7866666666666667, 1.0, 1.0, 0.40704230298147603, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22128740435922048, 0.22128740435922048, 0.3581098820753393], 
reward next is 0.6419, 
noisyNet noise sample is [array([0.7570649], dtype=float32), 0.2842949]. 
=============================================
[2019-03-23 09:44:41,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.614845]
 [66.614845]
 [66.614845]
 [66.614845]
 [66.614845]], R is [[66.59059906]
 [66.56950378]
 [66.55106354]
 [66.53395081]
 [66.51811981]].
[2019-03-23 09:44:42,242] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3187298e-14 1.0000000e+00 1.3428336e-20 7.6959669e-20 1.6871883e-23], sum to 1.0000
[2019-03-23 09:44:42,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3415
[2019-03-23 09:44:42,255] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 74.66666666666667, 1.0, 2.0, 0.5399894132409541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 613283.2233973027, 613283.223397303, 148881.3628326687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5163000.0000, 
sim time next is 5163600.0000, 
raw observation next is [25.33333333333334, 75.33333333333334, 1.0, 2.0, 0.5372619580692399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 610920.4091981691, 610920.4091981694, 148151.3734331164], 
processed observation next is [0.0, 0.782608695652174, 0.7878787878787882, 0.7533333333333334, 1.0, 1.0, 0.42157744758654986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22626681822154412, 0.2262668182215442, 0.36134481325150336], 
reward next is 0.6387, 
noisyNet noise sample is [array([0.23980278], dtype=float32), -1.3002656]. 
=============================================
[2019-03-23 09:44:42,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5140651e-15 1.0000000e+00 3.2285469e-21 6.1078039e-21 2.5921712e-22], sum to 1.0000
[2019-03-23 09:44:42,483] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0731
[2019-03-23 09:44:42,489] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4386581447584045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499775.048020429, 499775.048020429, 132342.3261533377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199600.0000, 
sim time next is 5200200.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4329355927031092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493245.955639325, 493245.9556393247, 131749.8619988137], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2911694908788865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18268368727382409, 0.18268368727382395, 0.32134112682637483], 
reward next is 0.6787, 
noisyNet noise sample is [array([1.7555486], dtype=float32), -1.5348552]. 
=============================================
[2019-03-23 09:44:53,194] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5779393e-13 1.0000000e+00 7.3086060e-21 6.6601268e-20 7.1275161e-22], sum to 1.0000
[2019-03-23 09:44:53,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5490
[2019-03-23 09:44:53,209] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1279997.864050799 W.
[2019-03-23 09:44:53,218] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.86666666666667, 67.66666666666666, 1.0, 2.0, 0.6431819551925597, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9760305290521434, 6.9112, 6.9112, 77.32846344354104, 1279997.864050799, 1279997.864050799, 282602.0356458146], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5409600.0000, 
sim time next is 5410200.0000, 
raw observation next is [25.13333333333333, 69.33333333333334, 1.0, 2.0, 0.5370421077568241, 1.0, 1.0, 0.5370421077568241, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1221159.01896669, 1221159.018966689, 240653.5722360163], 
processed observation next is [1.0, 0.6086956521739131, 0.7787878787878786, 0.6933333333333335, 1.0, 1.0, 0.42130263469603013, 1.0, 0.5, 0.42130263469603013, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.45228111813581107, 0.45228111813581073, 0.5869599322829666], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31940874], dtype=float32), 0.111302644]. 
=============================================
[2019-03-23 09:44:54,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5499216e-14 1.0000000e+00 1.8187277e-22 4.6465368e-21 4.2084842e-24], sum to 1.0000
[2019-03-23 09:44:54,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-23 09:44:54,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1279997.864064341 W.
[2019-03-23 09:44:54,455] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.86666666666667, 67.66666666666666, 1.0, 2.0, 0.5650319814507678, 1.0, 2.0, 0.5650319814507678, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1279997.864064341, 1279997.864064341, 249906.6683520736], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5409600.0000, 
sim time next is 5410200.0000, 
raw observation next is [25.13333333333333, 69.33333333333334, 1.0, 2.0, 0.5373924482987633, 1.0, 2.0, 0.5373924482987633, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1221159.018966773, 1221159.018966773, 241139.4952280631], 
processed observation next is [1.0, 0.6086956521739131, 0.7787878787878786, 0.6933333333333335, 1.0, 1.0, 0.4217405603734541, 1.0, 1.0, 0.4217405603734541, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.4522811181358419, 0.4522811181358419, 0.5881451103123491], 
reward next is 0.4119, 
noisyNet noise sample is [array([0.8279875], dtype=float32), -0.3053258]. 
=============================================
[2019-03-23 09:44:56,285] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7777361e-14 1.0000000e+00 1.6433476e-21 9.3383335e-21 2.2384879e-24], sum to 1.0000
[2019-03-23 09:44:56,295] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6190
[2019-03-23 09:44:56,301] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.38333333333333, 95.0, 1.0, 2.0, 0.3324295737164704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366804.1771581601, 366804.1771581604, 115510.4856929733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469000.0000, 
sim time next is 5469600.0000, 
raw observation next is [17.56666666666667, 94.0, 1.0, 2.0, 0.3408441789054418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376582.669593591, 376582.669593591, 116332.0987962633], 
processed observation next is [1.0, 0.30434782608695654, 0.434848484848485, 0.94, 1.0, 1.0, 0.1760552236318022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13947506281244113, 0.13947506281244113, 0.2837368263323495], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.00986776], dtype=float32), -0.81574446]. 
=============================================
[2019-03-23 09:44:56,774] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8212556e-13 1.0000000e+00 1.3309314e-19 4.0932598e-19 3.7361046e-21], sum to 1.0000
[2019-03-23 09:44:56,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9894
[2019-03-23 09:44:56,789] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 85.33333333333334, 1.0, 2.0, 0.753009645266359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 855222.3163131514, 855222.3163131516, 168810.1112818748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5476800.0000, 
sim time next is 5477400.0000, 
raw observation next is [21.35, 84.5, 1.0, 2.0, 0.7954124395747453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 905147.4749658565, 905147.4749658565, 176422.4478382318], 
processed observation next is [1.0, 0.391304347826087, 0.6068181818181819, 0.845, 1.0, 1.0, 0.7442655494684316, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33523980554290983, 0.33523980554290983, 0.43029865326398004], 
reward next is 0.5697, 
noisyNet noise sample is [array([-0.71570265], dtype=float32), 0.5915526]. 
=============================================
[2019-03-23 09:44:57,009] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5092584e-14 1.0000000e+00 1.6110162e-20 4.3742371e-20 2.5217707e-22], sum to 1.0000
[2019-03-23 09:44:57,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2757
[2019-03-23 09:44:57,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1165742.265883505 W.
[2019-03-23 09:44:57,027] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.23333333333333, 76.66666666666666, 1.0, 2.0, 0.9956294139663969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.002231540776014, 6.9112, 77.32828281800357, 1165742.265883505, 1136177.152415463, 218304.2961322994], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5481600.0000, 
sim time next is 5482200.0000, 
raw observation next is [24.61666666666667, 75.33333333333334, 1.0, 2.0, 0.6108732821148265, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9738142995479249, 6.911199999999999, 6.9112, 77.3284087418987, 1244415.099856319, 1244415.099856319, 276026.3812166415], 
processed observation next is [1.0, 0.43478260869565216, 0.7553030303030305, 0.7533333333333334, 1.0, 1.0, 0.5135916026435331, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9625918564970355, -8.881784197001253e-17, 0.0, 0.5084284532614828, 0.4608944814282663, 0.4608944814282663, 0.67323507613815], 
reward next is 0.3268, 
noisyNet noise sample is [array([-1.1977568], dtype=float32), 0.20764607]. 
=============================================
[2019-03-23 09:44:58,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7220004e-13 1.0000000e+00 1.6010613e-19 2.7362107e-20 1.1219746e-21], sum to 1.0000
[2019-03-23 09:44:58,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5360
[2019-03-23 09:44:58,117] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 74.66666666666667, 1.0, 2.0, 0.4801652257392837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547911.2132126631, 547911.2132126631, 138626.1510218682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5520000.0000, 
sim time next is 5520600.0000, 
raw observation next is [23.85, 75.0, 1.0, 2.0, 0.4757158783181442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542807.6085882082, 542807.6085882082, 137861.1512232865], 
processed observation next is [1.0, 0.9130434782608695, 0.7204545454545456, 0.75, 1.0, 1.0, 0.34464484789768024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20103985503266972, 0.20103985503266972, 0.33624671030069875], 
reward next is 0.6638, 
noisyNet noise sample is [array([-0.29531202], dtype=float32), -0.51826733]. 
=============================================
[2019-03-23 09:44:58,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0739730e-16 1.0000000e+00 1.9718910e-23 8.6869969e-22 2.6493704e-25], sum to 1.0000
[2019-03-23 09:44:58,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4837
[2019-03-23 09:44:58,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1192373.053139318 W.
[2019-03-23 09:44:58,619] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 61.5, 1.0, 2.0, 0.527413271968648, 1.0, 2.0, 0.527413271968648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353986, 1192373.053139318, 1192373.053139318, 240861.3743097439], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5574600.0000, 
sim time next is 5575200.0000, 
raw observation next is [27.53333333333333, 61.33333333333333, 1.0, 2.0, 0.5926695494198622, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9778307471023902, 6.911199999999999, 6.9112, 77.32846344354104, 1221244.086371891, 1221244.086371891, 277088.8577707512], 
processed observation next is [1.0, 0.5217391304347826, 0.8878787878787878, 0.6133333333333333, 1.0, 1.0, 0.49083693677482765, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9683296387177002, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.45231262458218185, 0.45231262458218185, 0.6758264823676858], 
reward next is 0.3242, 
noisyNet noise sample is [array([-0.5012691], dtype=float32), 0.17140393]. 
=============================================
[2019-03-23 09:45:01,776] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2035036e-13 1.0000000e+00 5.0009698e-20 4.9875954e-20 4.1899386e-22], sum to 1.0000
[2019-03-23 09:45:01,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2690
[2019-03-23 09:45:01,795] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 40.0, 1.0, 2.0, 0.6554852989136425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 726748.7480239382, 726748.7480239384, 147095.1362284555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5850000.0000, 
sim time next is 5850600.0000, 
raw observation next is [26.0, 40.33333333333334, 1.0, 2.0, 0.4405308018469349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487683.035880072, 487683.0358800723, 124846.641053865], 
processed observation next is [1.0, 0.7391304347826086, 0.8181818181818182, 0.40333333333333343, 1.0, 1.0, 0.30066350230866856, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18062334662224888, 0.180623346622249, 0.30450400257040244], 
reward next is 0.6955, 
noisyNet noise sample is [array([-1.8592271], dtype=float32), -1.0828124]. 
=============================================
[2019-03-23 09:45:02,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9542619e-15 1.0000000e+00 1.4067293e-21 7.2780302e-21 2.5362211e-23], sum to 1.0000
[2019-03-23 09:45:02,168] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1889
[2019-03-23 09:45:02,169] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1336786.42925301 W.
[2019-03-23 09:45:02,172] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 55.0, 1.0, 2.0, 0.589506422514839, 1.0, 1.0, 0.589506422514839, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1336786.42925301, 1336786.429253009, 256066.2011836142], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5590800.0000, 
sim time next is 5591400.0000, 
raw observation next is [28.2, 55.33333333333334, 1.0, 2.0, 0.2281082713159931, 1.0, 2.0, 0.2281082713159931, 1.0, 1.0, 0.462003235179093, 6.911199999999999, 6.9112, 77.3421103, 775890.2675525314, 775890.2675525317, 237530.2608501769], 
processed observation next is [1.0, 0.7391304347826086, 0.9181818181818181, 0.5533333333333335, 1.0, 1.0, 0.035135339144991354, 1.0, 1.0, 0.035135339144991354, 1.0, 0.5, 0.23143319311299, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.2873667657601968, 0.28736676576019693, 0.5793420996345778], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49146768], dtype=float32), 0.010246914]. 
=============================================
[2019-03-23 09:45:04,237] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5291518e-15 1.0000000e+00 5.6897990e-21 3.0655299e-22 1.4340190e-23], sum to 1.0000
[2019-03-23 09:45:04,245] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8573
[2019-03-23 09:45:04,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1221290.929932059 W.
[2019-03-23 09:45:04,254] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 61.33333333333333, 1.0, 2.0, 0.3603799570340542, 1.0, 1.0, 0.3603799570340542, 1.0, 2.0, 0.7291475733139213, 6.9112, 6.9112, 77.3421103, 1221290.929932059, 1221290.929932059, 286857.1585286465], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5575200.0000, 
sim time next is 5575800.0000, 
raw observation next is [27.61666666666666, 61.16666666666666, 1.0, 2.0, 0.5510362515237079, 1.0, 2.0, 0.5510362515237079, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1244593.507979839, 1244593.50797984, 247320.2149032575], 
processed observation next is [1.0, 0.5217391304347826, 0.8916666666666664, 0.6116666666666666, 1.0, 1.0, 0.4387953144046349, 1.0, 1.0, 0.4387953144046349, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4609605585110515, 0.4609605585110519, 0.6032200363494086], 
reward next is 0.3968, 
noisyNet noise sample is [array([0.2471315], dtype=float32), 0.030079188]. 
=============================================
[2019-03-23 09:45:09,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2453849e-15 1.0000000e+00 6.1928036e-21 8.2856582e-20 8.9761895e-24], sum to 1.0000
[2019-03-23 09:45:09,598] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-23 09:45:09,602] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 88.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 132961.066995444, 132961.0669954443, 55632.38761097036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5719200.0000, 
sim time next is 5719800.0000, 
raw observation next is [8.9, 89.33333333333333, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 131456.6506483555, 131456.6506483555, 55446.34579719703], 
processed observation next is [0.0, 0.17391304347826086, 0.04090909090909092, 0.8933333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.04868764838827982, 0.04868764838827982, 0.13523498974926104], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5236293], dtype=float32), -0.0055610836]. 
=============================================
[2019-03-23 09:45:10,529] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 09:45:10,531] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:45:10,531] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:45:10,532] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:45:10,533] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:45:10,535] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:45:10,535] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:45:10,536] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:45:10,538] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:45:10,537] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:45:10,538] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:45:10,561] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 09:45:10,561] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 09:45:10,608] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 09:45:10,632] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 09:45:10,661] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 09:45:17,485] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:45:17,487] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.13066102166667, 100.0, 1.0, 2.0, 0.5635148834404724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 91.93398642720153, 612012.8307901903, 612012.8307901906, 120720.9004108125]
[2019-03-23 09:45:17,488] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:45:17,490] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.23188904944235555
[2019-03-23 09:45:39,582] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:45:39,583] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.76666666666667, 72.83333333333333, 1.0, 2.0, 0.2397785749773796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 260333.3223531605, 260333.3223531601, 85662.36726596853]
[2019-03-23 09:45:39,584] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:45:39,587] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.40597931275491617
[2019-03-23 09:45:46,454] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:45:46,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.4, 72.33333333333333, 1.0, 2.0, 0.4846217851654243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 552939.377044019, 552939.377044019, 143430.0122404932]
[2019-03-23 09:45:46,458] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:45:46,461] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.43443376266047584
[2019-03-23 09:45:49,433] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:45:49,438] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4929341483793033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562348.9711435647, 562348.9711435647, 140875.0440997068]
[2019-03-23 09:45:49,440] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:45:49,443] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.3227326771270609
[2019-03-23 09:46:31,257] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:46:31,258] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.48333333333333, 83.83333333333334, 1.0, 2.0, 0.3752607639689853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 419317.7586849569, 419317.7586849566, 125252.4551682766]
[2019-03-23 09:46:31,259] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:46:31,262] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.11792292192182918
[2019-03-23 09:46:31,834] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:46:31,836] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.96250432, 47.82415348, 1.0, 2.0, 0.2831928673660388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 307481.3130013939, 307481.3130013939, 85308.56196381258]
[2019-03-23 09:46:31,839] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:46:31,842] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.09880289439710244
[2019-03-23 09:46:33,242] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:46:33,244] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.95615608, 71.55434826666666, 1.0, 2.0, 0.5056329509426392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 575485.536957817, 575485.536957817, 148174.7082071239]
[2019-03-23 09:46:33,246] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:46:33,251] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.5975150106666732
[2019-03-23 09:46:33,937] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:46:33,938] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 53.0, 1.0, 2.0, 0.3040838397446474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 330170.2604333164, 330170.260433316, 115773.203509234]
[2019-03-23 09:46:33,939] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:46:33,941] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.9418433564966752
[2019-03-23 09:46:34,751] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.38103133]
[2019-03-23 09:46:34,753] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.36666666666667, 69.0, 1.0, 2.0, 0.6735618187162844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 768280.3544612372, 768280.3544612372, 165880.4047981125]
[2019-03-23 09:46:34,753] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:46:34,755] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.3428186e-14 1.0000000e+00 9.3760276e-21 4.8254104e-20 1.2967996e-22], sampled 0.7278340821287527
[2019-03-23 09:46:51,088] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:46:51,309] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:46:51,320] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:46:51,399] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:46:51,536] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:46:52,550] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1425000, evaluation results [1425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:46:56,891] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4129005e-16 1.0000000e+00 6.4181300e-23 2.3453181e-22 1.7815347e-25], sum to 1.0000
[2019-03-23 09:46:56,909] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9282
[2019-03-23 09:46:56,916] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 45.0, 1.0, 2.0, 0.6382271289113015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 708166.8375686449, 708166.8375686452, 145326.9676180422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5839800.0000, 
sim time next is 5840400.0000, 
raw observation next is [25.16666666666667, 45.0, 1.0, 2.0, 0.6028669220098636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 669537.6362426328, 669537.6362426328, 141613.5401338472], 
processed observation next is [1.0, 0.6086956521739131, 0.7803030303030305, 0.45, 1.0, 1.0, 0.5035836525123294, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24797690231208622, 0.24797690231208622, 0.34539887837523703], 
reward next is 0.6546, 
noisyNet noise sample is [array([1.5613425], dtype=float32), -0.18438035]. 
=============================================
[2019-03-23 09:46:58,440] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6104418e-16 1.0000000e+00 1.2164699e-23 2.9487002e-21 1.5166653e-25], sum to 1.0000
[2019-03-23 09:46:58,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8892
[2019-03-23 09:46:58,449] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.61666666666667, 80.5, 1.0, 2.0, 0.3765507552068461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408913.4492047354, 408913.4492047354, 86077.06893625174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5800200.0000, 
sim time next is 5800800.0000, 
raw observation next is [12.53333333333333, 81.0, 1.0, 2.0, 0.3834742737396136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 416435.2300283517, 416435.2300283517, 86788.5573630417], 
processed observation next is [1.0, 0.13043478260869565, 0.2060606060606059, 0.81, 1.0, 1.0, 0.229342842174517, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.154235270380871, 0.154235270380871, 0.21167940820254075], 
reward next is 0.7883, 
noisyNet noise sample is [array([1.2704474], dtype=float32), 0.28360817]. 
=============================================
[2019-03-23 09:47:08,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5080709e-15 1.0000000e+00 3.2484722e-22 2.0928647e-21 3.1164534e-23], sum to 1.0000
[2019-03-23 09:47:08,678] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4337
[2019-03-23 09:47:08,682] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 78.0, 1.0, 2.0, 0.3417950681413913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377405.580634076, 377405.580634076, 116315.6854965085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6037200.0000, 
sim time next is 6037800.0000, 
raw observation next is [19.21666666666667, 77.16666666666667, 1.0, 2.0, 0.3355286349022858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369023.6462009157, 369023.6462009157, 115286.492722969], 
processed observation next is [1.0, 0.9130434782608695, 0.5098484848484849, 0.7716666666666667, 1.0, 1.0, 0.16941079362785721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13667542451885767, 0.13667542451885767, 0.28118656761699756], 
reward next is 0.7188, 
noisyNet noise sample is [array([1.0683397], dtype=float32), 0.41747963]. 
=============================================
[2019-03-23 09:47:18,145] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5947185e-16 1.0000000e+00 1.9799043e-22 1.5154020e-21 4.6286264e-24], sum to 1.0000
[2019-03-23 09:47:18,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-23 09:47:18,163] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 76.33333333333333, 1.0, 2.0, 0.486715783787588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555264.5444125591, 555264.5444125589, 140125.0009931829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306000.0000, 
sim time next is 6306600.0000, 
raw observation next is [24.0, 77.66666666666667, 1.0, 2.0, 0.4868411451647196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555407.5148399968, 555407.5148399968, 140139.6675985963], 
processed observation next is [0.0, 1.0, 0.7272727272727273, 0.7766666666666667, 1.0, 1.0, 0.35855143145589946, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2057064869777766, 0.2057064869777766, 0.34180406731364954], 
reward next is 0.6582, 
noisyNet noise sample is [array([0.06341588], dtype=float32), -0.46309084]. 
=============================================
[2019-03-23 09:47:18,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8626685e-16 1.0000000e+00 1.7145376e-21 1.7393732e-21 2.0386564e-24], sum to 1.0000
[2019-03-23 09:47:18,372] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1129
[2019-03-23 09:47:18,377] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 57.0, 1.0, 2.0, 0.3380410778301128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 373769.0330265781, 373769.0330265784, 116230.8297848218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6199200.0000, 
sim time next is 6199800.0000, 
raw observation next is [22.51666666666667, 58.83333333333333, 1.0, 2.0, 0.3411837938594273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 377770.2109817147, 377770.2109817149, 116677.9127445914], 
processed observation next is [1.0, 0.782608695652174, 0.659848484848485, 0.5883333333333333, 1.0, 1.0, 0.17647974232428412, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13991489295619064, 0.1399148929561907, 0.2845802749868083], 
reward next is 0.7154, 
noisyNet noise sample is [array([1.6040273], dtype=float32), -1.9870509]. 
=============================================
[2019-03-23 09:47:19,163] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5332669e-15 1.0000000e+00 3.0405849e-21 1.2612583e-21 7.2466585e-24], sum to 1.0000
[2019-03-23 09:47:19,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9551
[2019-03-23 09:47:19,174] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 82.0, 1.0, 2.0, 0.3695786149159364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413779.5438855948, 413779.543885595, 120826.1913175251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6214200.0000, 
sim time next is 6214800.0000, 
raw observation next is [19.8, 83.0, 1.0, 2.0, 0.3694428937832023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413769.6284489585, 413769.6284489582, 120880.8145226314], 
processed observation next is [1.0, 0.9565217391304348, 0.5363636363636364, 0.83, 1.0, 1.0, 0.21180361722900282, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1532480105366513, 0.15324801053665119, 0.2948312549332473], 
reward next is 0.7052, 
noisyNet noise sample is [array([1.1113999], dtype=float32), 1.1226212]. 
=============================================
[2019-03-23 09:47:21,047] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8696658e-13 1.0000000e+00 2.4650215e-19 5.9899970e-18 3.4201848e-22], sum to 1.0000
[2019-03-23 09:47:21,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2973
[2019-03-23 09:47:21,064] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 83.0, 1.0, 2.0, 0.4837581807954817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 551963.2354294084, 551963.2354294084, 139534.8458287561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6315600.0000, 
sim time next is 6316200.0000, 
raw observation next is [23.0, 83.5, 1.0, 2.0, 0.482884282187117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550978.8271423334, 550978.8271423331, 139373.0563816174], 
processed observation next is [0.0, 0.08695652173913043, 0.6818181818181818, 0.835, 1.0, 1.0, 0.3536053527338962, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20406623227493828, 0.2040662322749382, 0.33993428385760344], 
reward next is 0.6601, 
noisyNet noise sample is [array([0.59228426], dtype=float32), -1.103022]. 
=============================================
[2019-03-23 09:47:26,163] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4389562e-12 1.0000000e+00 1.6602107e-19 1.1661985e-19 3.3537383e-22], sum to 1.0000
[2019-03-23 09:47:26,168] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9350
[2019-03-23 09:47:26,174] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.556558022395505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630813.1571080239, 630813.1571080239, 151544.7132050181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [27.61666666666667, 65.66666666666667, 1.0, 2.0, 0.5581300983310046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 632447.2977915723, 632447.2977915725, 151804.1144464445], 
processed observation next is [0.0, 0.782608695652174, 0.8916666666666668, 0.6566666666666667, 1.0, 1.0, 0.4476626229137557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23423973992280456, 0.23423973992280464, 0.37025393767425485], 
reward next is 0.6297, 
noisyNet noise sample is [array([-0.63636863], dtype=float32), 1.0535917]. 
=============================================
[2019-03-23 09:47:27,259] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5175310e-14 1.0000000e+00 1.3657459e-19 5.7982395e-20 1.7157143e-22], sum to 1.0000
[2019-03-23 09:47:27,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5817
[2019-03-23 09:47:27,271] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 71.5, 1.0, 2.0, 0.5346801302674933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 610044.5104875583, 610044.5104875583, 145701.4343904134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6419400.0000, 
sim time next is 6420000.0000, 
raw observation next is [24.8, 72.0, 1.0, 2.0, 0.5390687764177086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 615062.7122673099, 615062.7122673099, 146210.8846233359], 
processed observation next is [1.0, 0.30434782608695654, 0.7636363636363637, 0.72, 1.0, 1.0, 0.4238359705221357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22780100454344812, 0.22780100454344812, 0.3566119137154534], 
reward next is 0.6434, 
noisyNet noise sample is [array([-1.1503142], dtype=float32), 1.1962132]. 
=============================================
[2019-03-23 09:47:27,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.012863]
 [62.012863]
 [62.012863]
 [62.012863]
 [62.012863]], R is [[62.03612137]
 [62.06039047]
 [62.09616852]
 [62.1350174 ]
 [62.17272568]].
[2019-03-23 09:47:34,037] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3429300e-15 1.0000000e+00 5.2308767e-23 3.4820055e-22 1.0326645e-23], sum to 1.0000
[2019-03-23 09:47:34,045] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3004
[2019-03-23 09:47:34,049] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 51.00000000000001, 1.0, 2.0, 0.4515697544751163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490421.0530130503, 490421.0530130503, 106648.6816045663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6535200.0000, 
sim time next is 6535800.0000, 
raw observation next is [20.5, 51.0, 1.0, 2.0, 0.4587270101955814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 498198.074049669, 498198.0740496687, 107392.1914023696], 
processed observation next is [1.0, 0.6521739130434783, 0.5681818181818182, 0.51, 1.0, 1.0, 0.32340876274447666, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18451780520358113, 0.184517805203581, 0.261932174152121], 
reward next is 0.7381, 
noisyNet noise sample is [array([-0.06050117], dtype=float32), -1.370056]. 
=============================================
[2019-03-23 09:47:41,037] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 09:47:41,037] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:47:41,038] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:41,040] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:47:41,042] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:47:41,044] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:47:41,045] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:47:41,046] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:41,046] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:41,047] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:41,045] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:47:41,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 09:47:41,091] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 09:47:41,091] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 09:47:41,148] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 09:47:41,174] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 09:47:46,555] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3744153]
[2019-03-23 09:47:46,557] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.1, 85.66666666666667, 1.0, 2.0, 0.3552076563093863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 395873.0427166967, 395873.0427166964, 123141.8931478085]
[2019-03-23 09:47:46,559] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:47:46,562] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7874808e-14 1.0000000e+00 3.7380433e-21 1.9483335e-20 4.6528818e-23], sampled 0.19989534460679703
[2019-03-23 09:48:08,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3744153]
[2019-03-23 09:48:08,229] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.5, 85.0, 1.0, 2.0, 0.7889410826614125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 900420.2932573862, 900420.2932573862, 184576.6244016683]
[2019-03-23 09:48:08,231] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:48:08,234] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7874808e-14 1.0000000e+00 3.7380433e-21 1.9483335e-20 4.6528818e-23], sampled 0.22877377475391858
[2019-03-23 09:48:13,261] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3744153]
[2019-03-23 09:48:13,263] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.46666666666667, 55.33333333333334, 1.0, 2.0, 0.2263013623161803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 245697.8001819404, 245697.80018194, 75996.42437513861]
[2019-03-23 09:48:13,264] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:48:13,267] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7874808e-14 1.0000000e+00 3.7380433e-21 1.9483335e-20 4.6528818e-23], sampled 0.9292799792933931
[2019-03-23 09:48:26,667] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3744153]
[2019-03-23 09:48:26,668] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.06666666666667, 42.16666666666666, 1.0, 2.0, 0.3162833136551761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 343420.074439037, 343420.074439037, 116025.324315494]
[2019-03-23 09:48:26,669] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:48:26,671] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7874808e-14 1.0000000e+00 3.7380433e-21 1.9483335e-20 4.6528818e-23], sampled 0.2721780300467679
[2019-03-23 09:49:00,072] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3744153]
[2019-03-23 09:49:00,073] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.8562803, 67.22133554, 1.0, 2.0, 0.4619329879382152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 526823.1912078696, 526823.1912078691, 139998.6734390759]
[2019-03-23 09:49:00,074] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:49:00,075] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7874808e-14 1.0000000e+00 3.7380433e-21 1.9483335e-20 4.6528818e-23], sampled 0.2462783494330525
[2019-03-23 09:49:13,862] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3744153]
[2019-03-23 09:49:13,865] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.73333333333333, 49.0, 1.0, 2.0, 0.3195554447608329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346997.5864928535, 346997.5864928532, 112521.3836337097]
[2019-03-23 09:49:13,866] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:49:13,868] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7874808e-14 1.0000000e+00 3.7380433e-21 1.9483335e-20 4.6528818e-23], sampled 0.18099803988997754
[2019-03-23 09:49:21,608] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:49:21,942] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:49:21,942] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:49:21,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:49:22,028] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:49:23,043] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1450000, evaluation results [1450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:49:29,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.18687407e-14 1.00000000e+00 6.40316705e-22 4.17247551e-21
 1.29213255e-23], sum to 1.0000
[2019-03-23 09:49:29,645] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-23 09:49:29,649] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 75.0, 1.0, 2.0, 0.3795657441663178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 426414.9639273803, 426414.9639273803, 122359.586495698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6825600.0000, 
sim time next is 6826200.0000, 
raw observation next is [20.91666666666667, 76.0, 1.0, 2.0, 0.3767972894353036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 423025.568578032, 423025.5685780317, 121984.1893526061], 
processed observation next is [0.0, 0.0, 0.5871212121212124, 0.76, 1.0, 1.0, 0.2209966117941295, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15667613651038223, 0.15667613651038212, 0.2975224130551368], 
reward next is 0.7025, 
noisyNet noise sample is [array([-0.21652412], dtype=float32), 0.7220836]. 
=============================================
[2019-03-23 09:49:32,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5190651e-14 1.0000000e+00 6.0043580e-20 2.9556162e-20 5.3568669e-22], sum to 1.0000
[2019-03-23 09:49:32,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8260
[2019-03-23 09:49:32,547] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 88.0, 1.0, 2.0, 0.3760997590167083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 423641.3393125735, 423641.3393125738, 122639.3460091111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6855600.0000, 
sim time next is 6856200.0000, 
raw observation next is [20.2, 85.5, 1.0, 2.0, 0.3811412589505759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 429995.1776241367, 429995.177624137, 123447.025583334], 
processed observation next is [0.0, 0.34782608695652173, 0.5545454545454546, 0.855, 1.0, 1.0, 0.22642657368821983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1592574731941247, 0.1592574731941248, 0.3010903063008146], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.53642666], dtype=float32), 0.024557104]. 
=============================================
[2019-03-23 09:49:36,428] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5108760e-14 1.0000000e+00 2.4786835e-20 1.6157929e-19 7.2140333e-23], sum to 1.0000
[2019-03-23 09:49:36,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6218
[2019-03-23 09:49:36,442] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.81666666666667, 64.83333333333333, 1.0, 2.0, 0.469734087371272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 535997.4278812034, 535997.427881203, 137660.1394850064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6951000.0000, 
sim time next is 6951600.0000, 
raw observation next is [26.1, 64.0, 1.0, 2.0, 0.4743321270897157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 541211.7624018831, 541211.7624018835, 138428.9786130454], 
processed observation next is [0.0, 0.4782608695652174, 0.8227272727272728, 0.64, 1.0, 1.0, 0.34291515886214463, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20044880088958636, 0.20044880088958647, 0.33763165515376925], 
reward next is 0.6624, 
noisyNet noise sample is [array([0.7349538], dtype=float32), -0.4248674]. 
=============================================
[2019-03-23 09:49:37,586] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9731550e-15 1.0000000e+00 7.1684717e-22 1.3444687e-20 5.2402635e-23], sum to 1.0000
[2019-03-23 09:49:37,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5889
[2019-03-23 09:49:37,597] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 92.0, 1.0, 2.0, 0.3798985508057527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426949.0120024701, 426949.0120024699, 122468.327602911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6916800.0000, 
sim time next is 6917400.0000, 
raw observation next is [19.1, 91.5, 1.0, 2.0, 0.3809816574064594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 428361.126895634, 428361.1268956343, 122659.8750938598], 
processed observation next is [0.0, 0.043478260869565216, 0.5045454545454546, 0.915, 1.0, 1.0, 0.22622707175807422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15865226922060519, 0.1586522692206053, 0.29917042705819463], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.00992536], dtype=float32), -0.0561525]. 
=============================================
[2019-03-23 09:49:37,721] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7036590e-15 1.0000000e+00 9.1094929e-21 1.8802885e-20 2.2646955e-22], sum to 1.0000
[2019-03-23 09:49:37,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3827
[2019-03-23 09:49:37,736] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 60.33333333333334, 1.0, 2.0, 0.5101054739094485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581370.5151265902, 581370.5151265905, 143771.7486015012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6975600.0000, 
sim time next is 6976200.0000, 
raw observation next is [27.28333333333333, 60.16666666666666, 1.0, 2.0, 0.5058371336576881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 576678.1402709187, 576678.1402709191, 143059.1254912481], 
processed observation next is [0.0, 0.7391304347826086, 0.8765151515151515, 0.6016666666666666, 1.0, 1.0, 0.3822964170721101, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21358449639663657, 0.21358449639663668, 0.3489246963201173], 
reward next is 0.6511, 
noisyNet noise sample is [array([-1.3302145], dtype=float32), -0.0810351]. 
=============================================
[2019-03-23 09:49:39,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8132305e-14 1.0000000e+00 7.1818600e-21 6.0370371e-21 3.5190189e-23], sum to 1.0000
[2019-03-23 09:49:39,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-23 09:49:39,570] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 62.33333333333334, 1.0, 2.0, 0.4590376567941428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498535.623159236, 498535.623159236, 114012.7726571581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7291200.0000, 
sim time next is 7291800.0000, 
raw observation next is [19.95, 62.0, 1.0, 2.0, 0.4970158308508375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539804.5361689796, 539804.5361689796, 121503.5995117287], 
processed observation next is [1.0, 0.391304347826087, 0.5431818181818181, 0.62, 1.0, 1.0, 0.37126978856354687, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19992760598851098, 0.19992760598851098, 0.29635024271153343], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.56234366], dtype=float32), 0.49483767]. 
=============================================
[2019-03-23 09:49:47,789] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3515495e-14 1.0000000e+00 8.4505527e-22 2.2373731e-21 4.4241193e-24], sum to 1.0000
[2019-03-23 09:49:47,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9644
[2019-03-23 09:49:47,801] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.86666666666667, 98.5, 1.0, 2.0, 0.3337298015087308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367534.4966217313, 367534.4966217316, 115338.0015511576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7447800.0000, 
sim time next is 7448400.0000, 
raw observation next is [16.8, 99.0, 1.0, 2.0, 0.3330412526856016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 366682.7148065521, 366682.7148065524, 115251.6484719345], 
processed observation next is [0.0, 0.21739130434782608, 0.4, 0.99, 1.0, 1.0, 0.16630156585700195, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1358084128913156, 0.1358084128913157, 0.2811015816388646], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.2454863], dtype=float32), 0.8942335]. 
=============================================
[2019-03-23 09:49:48,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2097271e-16 1.0000000e+00 2.2817897e-20 1.5008067e-21 5.5347314e-25], sum to 1.0000
[2019-03-23 09:49:48,351] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9562
[2019-03-23 09:49:48,357] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 55.0, 1.0, 2.0, 0.4171048929156319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 463069.6991346429, 463069.6991346429, 123310.5148880431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7131600.0000, 
sim time next is 7132200.0000, 
raw observation next is [23.38333333333333, 54.16666666666667, 1.0, 2.0, 0.5300495975566677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588506.6028793635, 588506.6028793635, 133896.876083063], 
processed observation next is [1.0, 0.5652173913043478, 0.6992424242424241, 0.5416666666666667, 1.0, 1.0, 0.41256199694583456, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21796540847383833, 0.21796540847383833, 0.3265777465440561], 
reward next is 0.6734, 
noisyNet noise sample is [array([-1.004965], dtype=float32), -1.0023937]. 
=============================================
[2019-03-23 09:49:53,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1537367e-15 1.0000000e+00 2.0494813e-22 4.7583982e-20 1.3274757e-23], sum to 1.0000
[2019-03-23 09:49:53,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1396
[2019-03-23 09:49:53,917] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.7, 89.0, 1.0, 2.0, 0.2356820211717796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 255897.4877348988, 255897.4877348985, 79740.76085735696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263000.0000, 
sim time next is 7263600.0000, 
raw observation next is [14.6, 88.66666666666667, 1.0, 2.0, 0.2329711596066834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252953.3384459658, 252953.3384459655, 78865.88260087534], 
processed observation next is [1.0, 0.043478260869565216, 0.3, 0.8866666666666667, 1.0, 1.0, 0.04121394950835425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.093686421646654, 0.09368642164665389, 0.19235581122164716], 
reward next is 0.8076, 
noisyNet noise sample is [array([-0.16689081], dtype=float32), -0.61274594]. 
=============================================
[2019-03-23 09:49:56,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9805638e-16 1.0000000e+00 3.3425482e-23 5.9306876e-22 1.6214324e-24], sum to 1.0000
[2019-03-23 09:49:56,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8137
[2019-03-23 09:49:56,230] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 81.66666666666667, 1.0, 2.0, 0.2036498208738833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221109.8416890171, 221109.8416890168, 71891.3873732303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7274400.0000, 
sim time next is 7275000.0000, 
raw observation next is [13.9, 82.83333333333333, 1.0, 2.0, 0.2032330390763043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220657.224251111, 220657.2242511113, 71905.61605999315], 
processed observation next is [1.0, 0.17391304347826086, 0.2681818181818182, 0.8283333333333333, 1.0, 1.0, 0.004041298845380362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08172489787078185, 0.08172489787078197, 0.17537955136583694], 
reward next is 0.8246, 
noisyNet noise sample is [array([1.3011166], dtype=float32), 0.15922405]. 
=============================================
[2019-03-23 09:49:56,246] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.473404]
 [68.473404]
 [68.473404]
 [68.473404]
 [68.473404]], R is [[68.61329651]
 [68.7518158 ]
 [68.88906097]
 [69.02462769]
 [69.15771484]].
[2019-03-23 09:50:04,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5917665e-14 1.0000000e+00 7.7760799e-22 7.5112407e-20 4.6117619e-23], sum to 1.0000
[2019-03-23 09:50:04,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7099
[2019-03-23 09:50:04,303] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 56.33333333333334, 1.0, 2.0, 0.2689083065497772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291984.5646343926, 291984.5646343929, 84816.7339934744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7759200.0000, 
sim time next is 7759800.0000, 
raw observation next is [19.1, 56.5, 1.0, 2.0, 0.266931339747504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289837.3055710798, 289837.3055710798, 84253.12940731813], 
processed observation next is [1.0, 0.8260869565217391, 0.5045454545454546, 0.565, 1.0, 1.0, 0.08366417468437998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10734715021151103, 0.10734715021151103, 0.2054954375788247], 
reward next is 0.7945, 
noisyNet noise sample is [array([-0.64848614], dtype=float32), 0.33717448]. 
=============================================
[2019-03-23 09:50:06,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5379340e-13 1.0000000e+00 1.1694456e-20 6.9753380e-19 4.7903907e-23], sum to 1.0000
[2019-03-23 09:50:06,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6720
[2019-03-23 09:50:06,375] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.3, 95.5, 1.0, 2.0, 0.2004016930155302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 217582.4451687236, 217582.4451687236, 73279.31107844827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7797000.0000, 
sim time next is 7797600.0000, 
raw observation next is [13.3, 96.0, 1.0, 2.0, 0.203878668695625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 221358.3664326669, 221358.3664326672, 73764.81849193096], 
processed observation next is [1.0, 0.2608695652173913, 0.24090909090909093, 0.96, 1.0, 1.0, 0.00484833586953122, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.081984580160247, 0.08198458016024711, 0.17991419144373405], 
reward next is 0.8201, 
noisyNet noise sample is [array([0.29533145], dtype=float32), -0.39377624]. 
=============================================
[2019-03-23 09:50:11,391] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 09:50:11,392] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:50:11,393] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:50:11,394] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:50:11,394] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:50:11,395] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:50:11,395] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:50:11,396] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:50:11,397] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:50:11,397] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:50:11,397] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:50:11,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 09:50:11,446] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 09:50:11,470] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 09:50:11,472] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 09:50:11,472] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 09:50:17,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:50:17,018] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.06666666666667, 86.0, 1.0, 2.0, 0.3559331189598902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396814.4096471306, 396814.4096471306, 123257.5622576576]
[2019-03-23 09:50:17,020] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:50:17,022] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.8580442690820694
[2019-03-23 09:50:21,527] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:50:21,528] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.73067601666667, 60.17613038333334, 1.0, 2.0, 0.3063452162486819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 332626.3129833803, 332626.3129833799, 115084.4208587347]
[2019-03-23 09:50:21,530] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:50:21,534] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.11568569735006928
[2019-03-23 09:50:40,422] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:50:40,424] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 54.00000000000001, 1.0, 2.0, 0.4122403418842813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468178.8932741473, 468178.8932741476, 128241.2434605529]
[2019-03-23 09:50:40,424] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:50:40,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.34959248644498764
[2019-03-23 09:51:03,201] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:51:03,203] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.16666666666667, 77.16666666666667, 1.0, 2.0, 0.3221726873548971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 353336.3661532597, 353336.3661532594, 113937.5486790358]
[2019-03-23 09:51:03,205] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:51:03,208] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.016722609421647716
[2019-03-23 09:51:18,039] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:51:18,040] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.5, 97.0, 1.0, 2.0, 0.3110726353921776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 338986.244332385, 338986.2443323847, 112360.0572080208]
[2019-03-23 09:51:18,041] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:51:18,046] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.73961165335849
[2019-03-23 09:51:19,262] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:51:19,263] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.81158532, 69.8991566, 1.0, 2.0, 0.3181043716564544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345397.9454258549, 345397.9454258546, 107872.8099434472]
[2019-03-23 09:51:19,264] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:51:19,267] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.6039131933396952
[2019-03-23 09:51:31,921] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:51:31,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.03794214333333, 70.68396578, 1.0, 2.0, 0.2365800296019518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 256859.8432589862, 256859.8432589862, 81647.93300733063]
[2019-03-23 09:51:31,925] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:51:31,929] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.6133507256029475
[2019-03-23 09:51:43,318] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36829674]
[2019-03-23 09:51:43,318] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.3, 82.0, 1.0, 2.0, 0.4999526029005737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 570336.2868742798, 570336.2868742795, 145882.4804762762]
[2019-03-23 09:51:43,319] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:51:43,323] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [8.7278885e-14 1.0000000e+00 3.0675450e-20 1.5670603e-19 4.7737015e-22], sampled 0.44848031175537206
[2019-03-23 09:51:52,048] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:51:52,057] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:51:52,492] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:51:52,550] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:51:52,599] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:51:53,613] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1475000, evaluation results [1475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:51:57,243] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:51:57,245] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:51:57,297] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 09:51:58,155] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.13401876e-13 1.00000000e+00 5.65211737e-20 7.13214705e-20
 1.09950524e-22], sum to 1.0000
[2019-03-23 09:51:58,157] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7958
[2019-03-23 09:51:58,163] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 65.33333333333334, 1.0, 2.0, 0.5594240135116971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 608214.76476617, 608214.7647661702, 132588.9090986034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7724400.0000, 
sim time next is 7725000.0000, 
raw observation next is [20.31666666666667, 64.16666666666666, 1.0, 2.0, 0.5693184755325924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 619152.7825665998, 619152.7825665998, 133606.6788435992], 
processed observation next is [1.0, 0.391304347826087, 0.559848484848485, 0.6416666666666666, 1.0, 1.0, 0.46164809441574045, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22931584539503697, 0.22931584539503697, 0.3258699483990224], 
reward next is 0.6741, 
noisyNet noise sample is [array([-0.7118534], dtype=float32), 0.4453414]. 
=============================================
[2019-03-23 09:51:58,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.38431]
 [67.38431]
 [67.38431]
 [67.38431]
 [67.38431]], R is [[67.38459778]
 [67.38736725]
 [67.39302063]
 [67.39929199]
 [67.39750671]].
[2019-03-23 09:51:58,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8848998e-15 1.0000000e+00 1.3769452e-20 3.5782589e-21 7.5282971e-23], sum to 1.0000
[2019-03-23 09:51:58,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4147
[2019-03-23 09:51:58,388] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1299802.708090432 W.
[2019-03-23 09:51:58,395] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.06666666666667, 56.33333333333333, 1.0, 2.0, 0.3831915392710907, 1.0, 2.0, 0.3831915392710907, 1.0, 2.0, 0.775511092343968, 6.911199999999999, 6.9112, 77.3421103, 1299802.708090432, 1299802.708090432, 296574.9430921373], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7663200.0000, 
sim time next is 7663800.0000, 
raw observation next is [27.88333333333333, 57.16666666666667, 1.0, 2.0, 0.5664803084748967, 1.0, 2.0, 0.5664803084748967, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1283286.489500561, 1283286.48950056, 250291.4635624915], 
processed observation next is [1.0, 0.6956521739130435, 0.9037878787878786, 0.5716666666666668, 1.0, 1.0, 0.4581003855936209, 1.0, 1.0, 0.4581003855936209, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4752912924076152, 0.47529129240761486, 0.6104669842987598], 
reward next is 0.3895, 
noisyNet noise sample is [array([-0.30118853], dtype=float32), 0.3406546]. 
=============================================
[2019-03-23 09:52:03,862] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2904384e-15 1.0000000e+00 4.3100627e-23 7.4337241e-23 3.6586666e-25], sum to 1.0000
[2019-03-23 09:52:03,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8955
[2019-03-23 09:52:03,874] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 71.33333333333334, 1.0, 2.0, 0.5826681180546882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 639732.2160846526, 639732.2160846523, 136840.8706747672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7809600.0000, 
sim time next is 7810200.0000, 
raw observation next is [20.25, 73.0, 1.0, 2.0, 0.610413784958852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 675833.0888972767, 675833.0888972764, 141677.9960632497], 
processed observation next is [1.0, 0.391304347826087, 0.5568181818181818, 0.73, 1.0, 1.0, 0.513017231198565, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2503085514434358, 0.2503085514434357, 0.3455560879591456], 
reward next is 0.6544, 
noisyNet noise sample is [array([1.0075601], dtype=float32), 0.5614178]. 
=============================================
[2019-03-23 09:52:08,351] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:08,352] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:08,394] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 09:52:09,448] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0674797e-14 1.0000000e+00 4.4743324e-20 6.0626342e-20 4.7641327e-22], sum to 1.0000
[2019-03-23 09:52:09,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9629
[2019-03-23 09:52:09,462] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 70.0, 1.0, 2.0, 0.3124791202106658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 339998.2237532994, 339998.2237532992, 112274.695382522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7878600.0000, 
sim time next is 7879200.0000, 
raw observation next is [19.6, 71.0, 1.0, 2.0, 0.3116577853951367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339356.2747003317, 339356.274700332, 112306.2570923225], 
processed observation next is [1.0, 0.17391304347826086, 0.5272727272727273, 0.71, 1.0, 1.0, 0.1395722317439209, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12568750914827098, 0.12568750914827112, 0.2739177002251768], 
reward next is 0.7261, 
noisyNet noise sample is [array([-0.16676633], dtype=float32), 0.8371346]. 
=============================================
[2019-03-23 09:52:09,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:09,889] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:09,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 09:52:10,021] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:10,021] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:10,043] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 09:52:10,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:10,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:10,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 09:52:10,305] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0950257e-16 1.0000000e+00 6.6182047e-22 3.7029578e-22 2.3334111e-24], sum to 1.0000
[2019-03-23 09:52:10,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0838
[2019-03-23 09:52:10,312] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 94.0, 1.0, 2.0, 0.4331662932333079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 492917.1106442205, 492917.1106442205, 131117.6843526312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7939200.0000, 
sim time next is 7939800.0000, 
raw observation next is [20.2, 94.5, 1.0, 2.0, 0.4315654349683655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490998.2215414611, 490998.2215414614, 130863.5122796603], 
processed observation next is [1.0, 0.9130434782608695, 0.5545454545454546, 0.945, 1.0, 1.0, 0.28945679371045685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18185119316350412, 0.18185119316350423, 0.3191792982430739], 
reward next is 0.6808, 
noisyNet noise sample is [array([0.16316806], dtype=float32), 0.3147955]. 
=============================================
[2019-03-23 09:52:10,746] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:10,746] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:10,779] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 09:52:11,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:11,002] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,013] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 09:52:11,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:11,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,265] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 09:52:11,425] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:11,425] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,436] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 09:52:11,598] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:11,598] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,607] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 09:52:11,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:11,665] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:11,669] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 09:52:12,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:12,185] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:12,190] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 09:52:12,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:12,261] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:12,264] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 09:52:12,361] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:12,361] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:12,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 09:52:12,797] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:12,797] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:12,800] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 09:52:12,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 09:52:12,853] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:12,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 09:52:13,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6739142e-15 1.0000000e+00 1.4806139e-21 1.4176658e-20 6.0361759e-24], sum to 1.0000
[2019-03-23 09:52:13,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2041
[2019-03-23 09:52:13,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3541551135089671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391703.9777158659, 391703.9777158661, 117512.8877796386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 14400.0000, 
sim time next is 15000.0000, 
raw observation next is [17.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3982470326265929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441226.6053496612, 441226.6053496615, 121346.4317065424], 
processed observation next is [1.0, 0.17391304347826086, 0.4166666666666669, 0.9900000000000001, 1.0, 1.0, 0.24780879078324108, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16341726124061526, 0.16341726124061537, 0.2959669066013229], 
reward next is 0.7040, 
noisyNet noise sample is [array([-0.968417], dtype=float32), -1.1252769]. 
=============================================
[2019-03-23 09:52:13,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.25318]
 [71.25318]
 [71.25318]
 [71.25318]
 [71.25318]], R is [[71.24468231]
 [71.24562073]
 [71.24802399]
 [71.25179291]
 [71.25807953]].
[2019-03-23 09:52:13,879] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1092589e-13 1.0000000e+00 1.4276562e-21 3.0896117e-20 8.1232439e-24], sum to 1.0000
[2019-03-23 09:52:13,884] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7766
[2019-03-23 09:52:13,893] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.4074029975585636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 457456.7647621991, 457456.7647621991, 124695.7407616639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27000.0000, 
sim time next is 27600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3953188425724404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 443876.0084675962, 443876.0084675965, 123617.5636893258], 
processed observation next is [1.0, 0.30434782608695654, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24414855321555046, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16439852165466526, 0.16439852165466537, 0.30150625290079464], 
reward next is 0.6985, 
noisyNet noise sample is [array([0.631882], dtype=float32), -1.0800946]. 
=============================================
[2019-03-23 09:52:16,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1723393e-14 1.0000000e+00 3.0506910e-22 9.7491111e-22 1.6361900e-23], sum to 1.0000
[2019-03-23 09:52:16,942] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0987
[2019-03-23 09:52:16,945] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 86.0, 1.0, 2.0, 0.8073730999412144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 915610.0519820467, 915610.0519820467, 175772.9026414024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 52200.0000, 
sim time next is 52800.0000, 
raw observation next is [20.33333333333333, 88.66666666666667, 1.0, 2.0, 0.9203833233113101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1045225.975574811, 1045225.975574811, 194438.5960930548], 
processed observation next is [1.0, 0.6086956521739131, 0.5606060606060604, 0.8866666666666667, 1.0, 1.0, 0.9004791541391377, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.38712073169437444, 0.38712073169437444, 0.4742404782757434], 
reward next is 0.5258, 
noisyNet noise sample is [array([0.05333481], dtype=float32), 1.5852764]. 
=============================================
[2019-03-23 09:52:18,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2219158e-12 1.0000000e+00 6.2665943e-20 6.4516217e-20 7.6209908e-23], sum to 1.0000
[2019-03-23 09:52:18,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-23 09:52:18,095] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 46.0, 1.0, 2.0, 0.5650249047042086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 613715.2275185897, 613715.2275185897, 117693.7134728364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 129600.0000, 
sim time next is 130200.0000, 
raw observation next is [21.16666666666667, 46.0, 1.0, 2.0, 0.5361207434845346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582301.479107803, 582301.479107803, 115138.4907082736], 
processed observation next is [1.0, 0.5217391304347826, 0.5984848484848487, 0.46, 1.0, 1.0, 0.4201509293556683, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21566721448437146, 0.21566721448437146, 0.28082558709335026], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.6027495], dtype=float32), 1.4298929]. 
=============================================
[2019-03-23 09:52:19,055] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4637030e-16 1.0000000e+00 3.3305076e-23 2.6867058e-22 3.0908534e-25], sum to 1.0000
[2019-03-23 09:52:19,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8673
[2019-03-23 09:52:19,064] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.66666666666667, 80.33333333333333, 1.0, 2.0, 0.2163740384530835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 234928.3128455211, 234928.3128455208, 74393.54969384018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [14.33333333333333, 81.16666666666667, 1.0, 2.0, 0.2124794135135589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 230698.7173875274, 230698.7173875277, 73415.6620964039], 
processed observation next is [1.0, 0.043478260869565216, 0.28787878787878773, 0.8116666666666668, 1.0, 1.0, 0.015599266891948606, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08544396940278792, 0.08544396940278803, 0.17906259047903392], 
reward next is 0.8209, 
noisyNet noise sample is [array([-0.11365423], dtype=float32), -0.092485994]. 
=============================================
[2019-03-23 09:52:19,084] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[79.50209]
 [79.50209]
 [79.50209]
 [79.50209]
 [79.50209]], R is [[79.52800751]
 [79.55127716]
 [79.57203674]
 [79.58999634]
 [79.60486603]].
[2019-03-23 09:52:21,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2164725e-16 1.0000000e+00 8.0892290e-24 7.6411102e-22 9.8463036e-26], sum to 1.0000
[2019-03-23 09:52:21,485] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1758
[2019-03-23 09:52:21,491] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 215040.7329289477, 215040.7329289474, 70576.13772371896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 172800.0000, 
sim time next is 173400.0000, 
raw observation next is [13.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213208.9295714411, 213208.9295714414, 70538.75774276041], 
processed observation next is [0.0, 0.0, 0.23484848484848497, 0.8800000000000001, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07896627021164486, 0.07896627021164497, 0.17204575059209856], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54364234], dtype=float32), -0.7159534]. 
=============================================
[2019-03-23 09:52:21,887] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1064473e-15 1.0000000e+00 9.4269800e-23 1.1956173e-20 1.1424141e-24], sum to 1.0000
[2019-03-23 09:52:21,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4376
[2019-03-23 09:52:21,908] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2788771745090226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302812.276863957, 302812.2768639567, 92543.50716436273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 496800.0000, 
sim time next is 497400.0000, 
raw observation next is [15.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2771369400343586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 300922.0992305593, 300922.099230559, 91809.17160593925], 
processed observation next is [1.0, 0.782608695652174, 0.3560606060606059, 0.8900000000000001, 1.0, 1.0, 0.09642117504294827, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1114526293446516, 0.11145262934465149, 0.22392480879497378], 
reward next is 0.7761, 
noisyNet noise sample is [array([-0.42793763], dtype=float32), -0.29791173]. 
=============================================
[2019-03-23 09:52:23,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4268746e-15 1.0000000e+00 7.6865742e-21 2.8714401e-22 2.5472526e-25], sum to 1.0000
[2019-03-23 09:52:23,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0454
[2019-03-23 09:52:23,667] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 71.5, 1.0, 2.0, 0.2914788344247075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316499.9480125677, 316499.948012568, 110626.6643276347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 209400.0000, 
sim time next is 210000.0000, 
raw observation next is [19.66666666666667, 70.0, 1.0, 2.0, 0.2953234779576699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 320939.44159584, 320939.4415958397, 110974.5052869962], 
processed observation next is [0.0, 0.43478260869565216, 0.5303030303030305, 0.7, 1.0, 1.0, 0.11915434744708735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11886645985031111, 0.118866459850311, 0.2706695250902346], 
reward next is 0.7293, 
noisyNet noise sample is [array([0.57545793], dtype=float32), -0.065878235]. 
=============================================
[2019-03-23 09:52:23,690] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.15013]
 [77.15013]
 [77.15013]
 [77.15013]
 [77.15013]], R is [[77.10796356]
 [77.06706238]
 [77.0274353 ]
 [76.99864197]
 [76.98336792]].
[2019-03-23 09:52:33,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2394430e-16 1.0000000e+00 2.4451900e-23 5.6649765e-22 1.3524848e-25], sum to 1.0000
[2019-03-23 09:52:33,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9472
[2019-03-23 09:52:33,936] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 72.83333333333333, 1.0, 2.0, 0.2500504928185813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 271502.7598088585, 271502.7598088588, 74845.52083918761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 373800.0000, 
sim time next is 374400.0000, 
raw observation next is [14.0, 72.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 211999.4727957428, 211999.4727957431, 69328.1728474252], 
processed observation next is [1.0, 0.34782608695652173, 0.2727272727272727, 0.72, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07851832325768252, 0.07851832325768263, 0.16909310450591514], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28412852], dtype=float32), -0.19173756]. 
=============================================
[2019-03-23 09:52:40,508] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3918415e-15 1.0000000e+00 1.3080037e-21 3.2772864e-22 3.0890044e-24], sum to 1.0000
[2019-03-23 09:52:40,515] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8170
[2019-03-23 09:52:40,523] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2169499814197313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235553.79487563, 235553.7948756303, 76927.45783176579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 513000.0000, 
sim time next is 513600.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2165381204461804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 235106.5080782091, 235106.5080782094, 76878.8384773578], 
processed observation next is [1.0, 0.9565217391304348, 0.2727272727272727, 0.94, 1.0, 1.0, 0.020672650557725485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08707648447341078, 0.08707648447341089, 0.18750936213989708], 
reward next is 0.8125, 
noisyNet noise sample is [array([-1.8117968], dtype=float32), -1.0075004]. 
=============================================
[2019-03-23 09:52:42,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9293023e-15 1.0000000e+00 1.0264558e-22 1.9571214e-22 1.8047385e-23], sum to 1.0000
[2019-03-23 09:52:42,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7382
[2019-03-23 09:52:42,481] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 55.00000000000001, 1.0, 2.0, 0.7165177345512715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 803697.6914060283, 803697.6914060283, 158130.5849196806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 652800.0000, 
sim time next is 653400.0000, 
raw observation next is [24.0, 55.5, 1.0, 2.0, 0.7479029879894886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 839963.9377832324, 839963.9377832328, 162719.8448307936], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.555, 1.0, 1.0, 0.6848787349868607, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31109775473453055, 0.31109775473453066, 0.3968776703190088], 
reward next is 0.6031, 
noisyNet noise sample is [array([-0.8882386], dtype=float32), 0.47486293]. 
=============================================
[2019-03-23 09:52:43,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1979302e-14 1.0000000e+00 1.8801667e-20 3.7742515e-21 6.3228937e-23], sum to 1.0000
[2019-03-23 09:52:43,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0770
[2019-03-23 09:52:43,149] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 66.5, 1.0, 2.0, 0.3520946606349395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391445.5950382671, 391445.5950382668, 118166.0545838847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 581400.0000, 
sim time next is 582000.0000, 
raw observation next is [21.33333333333334, 67.33333333333334, 1.0, 2.0, 0.3515660000517705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 390621.9738593232, 390621.973859323, 118026.3232397959], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.6733333333333335, 1.0, 1.0, 0.18945750006471312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14467480513308267, 0.1446748051330826, 0.2878690810726729], 
reward next is 0.7121, 
noisyNet noise sample is [array([-1.3917879], dtype=float32), 0.8695677]. 
=============================================
[2019-03-23 09:52:43,158] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.59397]
 [68.59397]
 [68.59397]
 [68.59397]
 [68.59397]], R is [[68.62016296]
 [68.64575195]
 [68.66955566]
 [68.67800903]
 [68.64260101]].
[2019-03-23 09:52:43,380] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 09:52:43,381] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:52:43,382] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:52:43,382] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:43,383] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:52:43,384] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:43,384] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:43,385] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:52:43,385] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:52:43,386] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:43,388] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:52:43,406] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 09:52:43,433] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 09:52:43,435] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 09:52:43,456] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 09:52:43,505] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 09:53:10,245] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43425885]
[2019-03-23 09:53:10,249] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.55037984, 43.66116114666667, 1.0, 2.0, 0.356664517385011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 387280.069214785, 387280.069214785, 106254.1603520695]
[2019-03-23 09:53:10,250] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:53:10,253] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5843997e-14 1.0000000e+00 2.7886545e-21 1.4740155e-20 3.3680959e-23], sampled 0.15138965147961214
[2019-03-23 09:53:52,227] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43425885]
[2019-03-23 09:53:52,229] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 73.0, 1.0, 2.0, 0.5303877962688123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576264.4856148174, 576264.4856148174, 129711.6787644095]
[2019-03-23 09:53:52,231] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:53:52,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5843997e-14 1.0000000e+00 2.7886545e-21 1.4740155e-20 3.3680959e-23], sampled 0.9232329999755013
[2019-03-23 09:54:24,591] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:54:24,769] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:54:24,890] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:54:24,944] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:54:25,052] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:54:26,065] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1500000, evaluation results [1500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:54:26,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3732932e-14 1.0000000e+00 1.0385122e-21 1.0928941e-22 1.7564406e-23], sum to 1.0000
[2019-03-23 09:54:26,147] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2665
[2019-03-23 09:54:26,151] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 82.5, 1.0, 2.0, 0.2921716766551349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 317252.5105693174, 317252.5105693171, 106335.309973859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 606600.0000, 
sim time next is 607200.0000, 
raw observation next is [17.33333333333333, 82.33333333333334, 1.0, 2.0, 0.2860197181972941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 310570.3177734928, 310570.3177734931, 102181.2769859523], 
processed observation next is [1.0, 0.0, 0.42424242424242403, 0.8233333333333335, 1.0, 1.0, 0.10752464774661762, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11502604361981214, 0.11502604361981227, 0.2492226267950056], 
reward next is 0.7508, 
noisyNet noise sample is [array([-1.7995781], dtype=float32), -0.04973002]. 
=============================================
[2019-03-23 09:54:27,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4966271e-14 1.0000000e+00 4.8493761e-22 4.1097800e-20 1.7616075e-23], sum to 1.0000
[2019-03-23 09:54:27,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1517
[2019-03-23 09:54:27,587] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4378720403501203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498184.193366529, 498184.193366529, 131505.2734807484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4375236906570158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497789.0445275598, 497789.0445275598, 131471.3767264673], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2969046133212697, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1843663127879851, 0.1843663127879851, 0.3206618944547983], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.35478914], dtype=float32), -1.4489132]. 
=============================================
[2019-03-23 09:54:32,837] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0335975e-16 1.0000000e+00 2.8074724e-21 5.4507608e-22 3.0324718e-24], sum to 1.0000
[2019-03-23 09:54:32,845] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3447
[2019-03-23 09:54:32,852] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.5, 1.0, 2.0, 0.4368289449936144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497352.1881958548, 497352.1881958548, 131759.8722825133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 804600.0000, 
sim time next is 805200.0000, 
raw observation next is [21.66666666666667, 84.66666666666666, 1.0, 2.0, 0.4381029973050802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498919.5977803159, 498919.5977803162, 132017.9641098129], 
processed observation next is [0.0, 0.30434782608695654, 0.6212121212121214, 0.8466666666666666, 1.0, 1.0, 0.2976287466313502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1847850362149318, 0.18478503621493192, 0.32199503441417776], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.8099171], dtype=float32), 0.35861063]. 
=============================================
[2019-03-23 09:54:42,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7222378e-14 1.0000000e+00 7.3788970e-20 1.1832086e-19 3.8206187e-22], sum to 1.0000
[2019-03-23 09:54:42,882] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4421
[2019-03-23 09:54:42,886] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 94.0, 1.0, 2.0, 0.4951394823610286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564880.0538195468, 564880.0538195468, 141093.6761205566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1237800.0000, 
sim time next is 1238400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5122453889389036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 584240.5456047223, 584240.5456047223, 143448.974963424], 
processed observation next is [1.0, 0.34782608695652173, 0.6363636363636364, 0.94, 1.0, 1.0, 0.39030673617362943, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21638538726100828, 0.21638538726100828, 0.34987554869127807], 
reward next is 0.6501, 
noisyNet noise sample is [array([-1.428434], dtype=float32), 0.4897973]. 
=============================================
[2019-03-23 09:54:42,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2465480e-13 1.0000000e+00 9.8277539e-21 1.0508677e-18 3.7084728e-21], sum to 1.0000
[2019-03-23 09:54:42,909] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-23 09:54:42,913] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4223413290876724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479661.8223697242, 479661.8223697242, 129224.3043946974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 921000.0000, 
sim time next is 921600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4216811435640896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 478910.887309756, 478910.8873097557, 129159.2943992917], 
processed observation next is [0.0, 0.6956521739130435, 0.6363636363636364, 0.78, 1.0, 1.0, 0.27710142945511196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17737440270731705, 0.17737440270731694, 0.31502266926656514], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.6113345], dtype=float32), -0.22478293]. 
=============================================
[2019-03-23 09:54:45,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3550563e-13 1.0000000e+00 1.3729007e-21 3.8281796e-20 8.4842375e-23], sum to 1.0000
[2019-03-23 09:54:45,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4236
[2019-03-23 09:54:45,856] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 95.0, 1.0, 2.0, 0.2321986358655192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 252114.3371457989, 252114.3371457986, 78309.15633264196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1019400.0000, 
sim time next is 1020000.0000, 
raw observation next is [13.66666666666667, 96.0, 1.0, 2.0, 0.2295216126069724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249206.9606799857, 249206.960679986, 77753.46476487744], 
processed observation next is [1.0, 0.8260869565217391, 0.25757575757575774, 0.96, 1.0, 1.0, 0.03690201575871549, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09229887432592063, 0.09229887432592074, 0.18964259698750596], 
reward next is 0.8104, 
noisyNet noise sample is [array([-0.7174513], dtype=float32), -1.3506272]. 
=============================================
[2019-03-23 09:54:45,872] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.82978]
 [68.82978]
 [68.82978]
 [68.82978]
 [68.82978]], R is [[68.95184326]
 [69.07133484]
 [69.18816376]
 [69.30187988]
 [69.41249084]].
[2019-03-23 09:54:48,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7267817e-14 1.0000000e+00 9.6026167e-22 5.5240486e-21 3.9831906e-24], sum to 1.0000
[2019-03-23 09:54:48,578] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0167
[2019-03-23 09:54:48,586] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1223647.595406559 W.
[2019-03-23 09:54:48,588] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 71.33333333333333, 1.0, 2.0, 0.3627792200586886, 1.0, 2.0, 0.3627792200586886, 1.0, 2.0, 0.734040012787664, 6.911199999999999, 6.9112, 77.3421103, 1223647.595406559, 1223647.595406559, 290209.0709374133], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1341600.0000, 
sim time next is 1342200.0000, 
raw observation next is [27.0, 70.66666666666667, 1.0, 2.0, 0.3614721745497615, 1.0, 2.0, 0.3614721745497615, 1.0, 2.0, 0.7313953637861813, 6.9112, 6.9112, 77.3421103, 1219234.21112882, 1219234.21112882, 289634.3465380332], 
processed observation next is [1.0, 0.5217391304347826, 0.8636363636363636, 0.7066666666666667, 1.0, 1.0, 0.20184021818720185, 1.0, 1.0, 0.20184021818720185, 1.0, 1.0, 0.6162790911231162, 0.0, 0.0, 0.5085185399722538, 0.4515682263440074, 0.4515682263440074, 0.7064252354586176], 
reward next is 0.2936, 
noisyNet noise sample is [array([0.3975628], dtype=float32), 0.44786015]. 
=============================================
[2019-03-23 09:54:54,480] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1243038e-15 1.0000000e+00 2.1155728e-21 6.8108697e-19 8.0894841e-22], sum to 1.0000
[2019-03-23 09:54:54,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-23 09:54:54,493] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3426527449931661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 381271.7499714233, 381271.749971423, 117562.258273542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1144200.0000, 
sim time next is 1144800.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.34194622670091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380483.5543699621, 380483.5543699618, 117506.2086341453], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.94, 1.0, 1.0, 0.1774327833761375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1409198349518378, 0.14091983495183769, 0.28660050886376903], 
reward next is 0.7134, 
noisyNet noise sample is [array([-0.53933436], dtype=float32), 0.050334357]. 
=============================================
[2019-03-23 09:55:03,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3542043e-14 1.0000000e+00 4.5541794e-21 5.2927468e-20 1.1972774e-22], sum to 1.0000
[2019-03-23 09:55:03,500] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6274
[2019-03-23 09:55:03,505] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4013605221464269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 454803.9598201325, 454803.9598201328, 126465.9568966894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1317600.0000, 
sim time next is 1318200.0000, 
raw observation next is [19.16666666666667, 99.00000000000001, 1.0, 2.0, 0.4234301503172303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480146.9147506352, 480146.9147506352, 128777.24060053], 
processed observation next is [1.0, 0.2608695652173913, 0.5075757575757578, 0.9900000000000001, 1.0, 1.0, 0.27928768789653785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1778321906483834, 0.1778321906483834, 0.314090830733], 
reward next is 0.6859, 
noisyNet noise sample is [array([0.42578712], dtype=float32), 0.25211626]. 
=============================================
[2019-03-23 09:55:06,347] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6235321e-11 1.0000000e+00 3.6082834e-18 4.0047327e-17 3.5062012e-20], sum to 1.0000
[2019-03-23 09:55:06,352] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4252
[2019-03-23 09:55:06,355] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 88.66666666666667, 1.0, 2.0, 0.4942795518400816, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563731.6664448412, 563731.6664448412, 141347.3151794811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1358400.0000, 
sim time next is 1359000.0000, 
raw observation next is [22.5, 86.0, 1.0, 2.0, 0.4651382624309786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530748.619664775, 530748.619664775, 137175.2455659978], 
processed observation next is [1.0, 0.7391304347826086, 0.6590909090909091, 0.86, 1.0, 1.0, 0.33142282803872325, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19657356283880556, 0.19657356283880556, 0.3345737696731653], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.49983597], dtype=float32), -0.16086017]. 
=============================================
[2019-03-23 09:55:06,368] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.391235]
 [61.391235]
 [61.391235]
 [61.391235]
 [61.391235]], R is [[61.44275665]
 [60.82833099]
 [60.63599014]
 [60.40971375]
 [60.19176102]].
[2019-03-23 09:55:13,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0563874e-12 1.0000000e+00 3.5025934e-19 4.0283243e-19 2.6898849e-22], sum to 1.0000
[2019-03-23 09:55:13,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2032
[2019-03-23 09:55:13,529] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 100.0, 1.0, 2.0, 0.4630429209930692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 528211.103992179, 528211.1039921793, 135976.3333151418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1467600.0000, 
sim time next is 1468200.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4565495442557985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520634.1256041912, 520634.1256041912, 134905.6492087091], 
processed observation next is [0.0, 1.0, 0.5530303030303032, 1.0, 1.0, 1.0, 0.3206869303197481, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19282745392747822, 0.19282745392747822, 0.32903816880172954], 
reward next is 0.6710, 
noisyNet noise sample is [array([-0.87630147], dtype=float32), 0.7101629]. 
=============================================
[2019-03-23 09:55:14,452] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 09:55:14,453] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:55:14,456] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:55:14,457] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:55:14,458] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:55:14,458] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:55:14,459] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:55:14,460] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:55:14,460] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:55:14,457] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:55:14,462] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:55:14,488] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 09:55:14,514] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 09:55:14,538] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 09:55:14,540] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 09:55:14,591] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 09:55:30,467] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:55:30,468] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.67941718, 85.12765555, 1.0, 2.0, 0.3309025729875346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 360950.5369134671, 360950.5369134668, 118184.898625082]
[2019-03-23 09:55:30,470] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:55:30,474] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.38629998425541434
[2019-03-23 09:55:34,665] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:55:34,666] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.76063796166667, 96.42516691666665, 1.0, 2.0, 0.4347583983749218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 494184.3491263521, 494184.3491263521, 135128.7924919263]
[2019-03-23 09:55:34,667] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:55:34,670] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.9923431588348851
[2019-03-23 09:55:40,053] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:55:40,054] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.10287180666667, 64.90615368833333, 1.0, 2.0, 0.2175380683058551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 40.27546989427147, 236245.2491362882, 236245.2491362884, 59619.81360918983]
[2019-03-23 09:55:40,056] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:55:40,060] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.6280583031497726
[2019-03-23 09:55:42,436] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:55:42,438] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.30563711, 52.251679, 1.0, 2.0, 0.2925975781555963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 317695.3312994612, 317695.3312994608, 102509.5233623489]
[2019-03-23 09:55:42,439] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:55:42,442] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.2357184702569829
[2019-03-23 09:55:49,922] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:55:49,923] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.85149133, 68.41012015, 1.0, 2.0, 0.3744041553772398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 419272.6221945951, 419272.6221945954, 125595.2617178884]
[2019-03-23 09:55:49,924] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:55:49,927] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.49029926048230554
[2019-03-23 09:55:55,812] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:55:55,814] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.66092094, 85.38334294, 1.0, 2.0, 0.3631440481628747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 406766.9450773158, 406766.9450773158, 124703.3653598543]
[2019-03-23 09:55:55,815] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:55:55,817] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.7104403522751811
[2019-03-23 09:56:34,805] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43701133]
[2019-03-23 09:56:34,807] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.06666666666667, 61.33333333333333, 1.0, 2.0, 0.4012776748992894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 450291.3282585912, 450291.3282585908, 128337.229535163]
[2019-03-23 09:56:34,809] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:56:34,813] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.2748511e-13 1.0000000e+00 4.4852350e-20 2.2898479e-19 7.3564054e-22], sampled 0.6502201576722335
[2019-03-23 09:56:54,927] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:56:54,996] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:56:55,190] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:56:55,195] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:56:55,221] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:56:56,235] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1525000, evaluation results [1525000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:57:03,368] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0581824e-15 1.0000000e+00 7.8231752e-23 1.4584164e-20 1.1404373e-24], sum to 1.0000
[2019-03-23 09:57:03,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3568
[2019-03-23 09:57:03,376] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 90.0, 1.0, 2.0, 0.3651545496331129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 403473.9780956352, 403473.9780956352, 118224.0372055824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650000.0000, 
sim time next is 1650600.0000, 
raw observation next is [18.0, 91.0, 1.0, 2.0, 0.3445507262609159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 381313.802067222, 381313.802067222, 116863.0281022471], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.91, 1.0, 1.0, 0.18068840782614481, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14122733409897112, 0.14122733409897112, 0.2850317758591393], 
reward next is 0.7150, 
noisyNet noise sample is [array([-2.4294267], dtype=float32), 0.6944958]. 
=============================================
[2019-03-23 09:57:08,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7359762e-16 1.0000000e+00 2.0365198e-23 2.1480347e-22 6.5588805e-25], sum to 1.0000
[2019-03-23 09:57:08,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6994
[2019-03-23 09:57:08,117] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 73.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 195505.1874730904, 195505.1874730907, 64418.07230973669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1722600.0000, 
sim time next is 1723200.0000, 
raw observation next is [12.0, 72.66666666666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196800.5818194564, 196800.5818194567, 64559.94385419001], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.7266666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07288910437757644, 0.07288910437757656, 0.15746327769314636], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9796813], dtype=float32), 0.6219894]. 
=============================================
[2019-03-23 09:57:15,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9562568e-14 1.0000000e+00 6.0313975e-21 1.1220528e-19 2.9491246e-23], sum to 1.0000
[2019-03-23 09:57:15,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0855
[2019-03-23 09:57:15,920] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 68.0, 1.0, 2.0, 0.2518953453129263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273506.4486488107, 273506.448648811, 85792.83904903907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1998000.0000, 
sim time next is 1998600.0000, 
raw observation next is [17.83333333333333, 68.66666666666667, 1.0, 2.0, 0.2503907408248878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 271872.3015417642, 271872.3015417639, 85150.55167860996], 
processed observation next is [0.0, 0.13043478260869565, 0.44696969696969674, 0.6866666666666668, 1.0, 1.0, 0.06298842603110977, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10069344501546822, 0.1006934450154681, 0.20768427238685355], 
reward next is 0.7923, 
noisyNet noise sample is [array([-0.74004453], dtype=float32), -0.20847943]. 
=============================================
[2019-03-23 09:57:23,874] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3339438e-14 1.0000000e+00 2.5393023e-21 8.9683271e-22 6.5993405e-24], sum to 1.0000
[2019-03-23 09:57:23,882] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8440
[2019-03-23 09:57:23,888] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 57.33333333333334, 1.0, 2.0, 0.2761282378883663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299826.4880298654, 299826.4880298651, 90360.40265287337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2063400.0000, 
sim time next is 2064000.0000, 
raw observation next is [19.66666666666667, 58.66666666666667, 1.0, 2.0, 0.2743676264603362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297914.1894954786, 297914.1894954789, 90498.20899330558], 
processed observation next is [0.0, 0.9130434782608695, 0.5303030303030305, 0.5866666666666667, 1.0, 1.0, 0.09295953307542022, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1103385887020291, 0.11033858870202921, 0.2207273390080624], 
reward next is 0.7793, 
noisyNet noise sample is [array([-0.96528566], dtype=float32), 0.7476252]. 
=============================================
[2019-03-23 09:57:23,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.80729]
 [75.80729]
 [75.80729]
 [75.80729]
 [75.80729]], R is [[75.82849121]
 [75.84981537]
 [75.8712616 ]
 [75.89037323]
 [75.90707397]].
[2019-03-23 09:57:31,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.9533515e-14 1.0000000e+00 1.0852753e-21 5.6158817e-20 1.0522289e-23], sum to 1.0000
[2019-03-23 09:57:31,923] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2780
[2019-03-23 09:57:31,931] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2230821802266438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 242213.497495178, 242213.497495178, 77644.44824291923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2255400.0000, 
sim time next is 2256000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.222001240487798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241039.5665720187, 241039.566572019, 77458.17771425941], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.027501550609747502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08927391354519211, 0.08927391354519222, 0.18892238466892539], 
reward next is 0.8111, 
noisyNet noise sample is [array([0.21414694], dtype=float32), -0.8902399]. 
=============================================
[2019-03-23 09:57:31,946] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.30225]
 [71.30225]
 [71.30225]
 [71.30225]
 [71.30225]], R is [[71.4003067 ]
 [71.49692535]
 [71.5901947 ]
 [71.67884827]
 [71.77244568]].
[2019-03-23 09:57:36,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7944014e-15 1.0000000e+00 1.0899885e-21 4.1192423e-21 2.8825576e-22], sum to 1.0000
[2019-03-23 09:57:36,496] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8387
[2019-03-23 09:57:36,503] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 49.66666666666667, 1.0, 2.0, 0.5254997757518762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 570758.8620356087, 570758.862035609, 111387.0180956928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2303400.0000, 
sim time next is 2304000.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.5247197322487847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569911.1399708436, 569911.1399708436, 110829.1145861259], 
processed observation next is [1.0, 0.6956521739130435, 0.5454545454545454, 0.49, 1.0, 1.0, 0.40589966531098076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21107819998920133, 0.21107819998920133, 0.27031491362469734], 
reward next is 0.7297, 
noisyNet noise sample is [array([-2.108349], dtype=float32), 0.81078804]. 
=============================================
[2019-03-23 09:57:36,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.01363]
 [73.01363]
 [73.01363]
 [73.01363]
 [73.01363]], R is [[73.01318359]
 [73.01137543]
 [73.00919342]
 [73.00844574]
 [73.00722504]].
[2019-03-23 09:57:42,975] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7083351e-15 1.0000000e+00 3.9022803e-22 2.2359140e-21 1.5818122e-25], sum to 1.0000
[2019-03-23 09:57:42,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2699
[2019-03-23 09:57:42,985] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 65.66666666666667, 1.0, 2.0, 0.4578397183139886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522406.1303428798, 522406.1303428798, 135954.1926720357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2747400.0000, 
sim time next is 2748000.0000, 
raw observation next is [25.0, 70.33333333333334, 1.0, 2.0, 0.46791027504343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533899.0677954779, 533899.0677954779, 137607.3269093437], 
processed observation next is [0.0, 0.8260869565217391, 0.7727272727272727, 0.7033333333333335, 1.0, 1.0, 0.3348878438042875, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19774039547980665, 0.19774039547980665, 0.33562762660815537], 
reward next is 0.6644, 
noisyNet noise sample is [array([1.4227661], dtype=float32), 0.48216507]. 
=============================================
[2019-03-23 09:57:42,998] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.58757]
 [77.58757]
 [77.58757]
 [77.58757]
 [77.58757]], R is [[77.47607422]
 [77.36972046]
 [77.26818848]
 [77.17037964]
 [77.0761795 ]].
[2019-03-23 09:57:44,695] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 09:57:44,696] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 09:57:44,696] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 09:57:44,697] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:44,697] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:44,699] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 09:57:44,700] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 09:57:44,702] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 09:57:44,704] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:44,705] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:44,703] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 09:57:44,729] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 09:57:44,756] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 09:57:44,757] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 09:57:44,818] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 09:57:44,846] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 09:57:50,259] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:57:50,260] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.83163547166667, 70.54429362833334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 202506.8781507612, 202506.8781507608, 72746.654927691]
[2019-03-23 09:57:50,262] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:57:50,265] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.26048866339119847
[2019-03-23 09:57:52,252] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:57:52,253] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.95077164333333, 96.64405804, 1.0, 2.0, 0.2232117082526703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 242342.6536123203, 242342.6536123199, 79544.11596898457]
[2019-03-23 09:57:52,254] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:57:52,256] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.3666396119244931
[2019-03-23 09:58:16,020] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:58:16,021] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.13333333333334, 55.33333333333334, 1.0, 2.0, 0.2447069024933756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 265685.3077917517, 265685.3077917513, 80194.48611256115]
[2019-03-23 09:58:16,022] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:58:16,025] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.6405328905352468
[2019-03-23 09:58:17,252] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:58:17,252] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.66666666666667, 62.0, 1.0, 2.0, 0.3625764361215842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393731.9615209153, 393731.9615209153, 96518.7113140707]
[2019-03-23 09:58:17,254] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:58:17,255] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.8078161092090728
[2019-03-23 09:58:17,424] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:58:17,424] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [10.5, 84.0, 1.0, 2.0, 0.2748727613684872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 298445.3781538921, 298445.3781538914, 78797.60336722908]
[2019-03-23 09:58:17,427] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:58:17,430] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.9828056019189302
[2019-03-23 09:58:27,905] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:58:27,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 90.0, 1.0, 2.0, 0.4541337132804222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 513874.2702455628, 513874.2702455625, 135436.829119245]
[2019-03-23 09:58:27,907] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 09:58:27,910] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.12035554120991265
[2019-03-23 09:58:36,766] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:58:36,768] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.26369031, 84.48524497, 1.0, 2.0, 0.2825243522162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 306755.2764459568, 306755.2764459564, 96063.368591134]
[2019-03-23 09:58:36,769] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:58:36,772] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.3747910153657995
[2019-03-23 09:58:42,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:58:42,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.329421555, 46.32342111, 1.0, 2.0, 0.3199964559923992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 350204.614330242, 350204.6143302416, 117826.5752895277]
[2019-03-23 09:58:42,882] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 09:58:42,886] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.9219262481432354
[2019-03-23 09:59:04,029] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:59:04,031] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.93333333333333, 89.0, 1.0, 2.0, 0.3401110406310388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374560.5870098806, 374560.5870098806, 115813.031266354]
[2019-03-23 09:59:04,032] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 09:59:04,037] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.34169078783287243
[2019-03-23 09:59:07,619] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:59:07,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.36666666666667, 79.33333333333334, 1.0, 2.0, 0.2448988342667287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 265893.7397200938, 265893.7397200942, 88368.89583238591]
[2019-03-23 09:59:07,620] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 09:59:07,623] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.7241814566044834
[2019-03-23 09:59:18,111] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.3997471]
[2019-03-23 09:59:18,112] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.44283614, 85.81413831, 1.0, 2.0, 0.3717466077092668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 419978.467962814, 419978.467962814, 127290.5967910909]
[2019-03-23 09:59:18,112] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 09:59:18,114] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.8593747e-15 1.0000000e+00 4.5594095e-22 2.5158436e-21 4.6117771e-24], sampled 0.3186833996942604
[2019-03-23 09:59:25,424] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 09:59:25,468] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 09:59:25,477] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 09:59:25,518] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 09:59:25,561] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 09:59:26,575] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1550000, evaluation results [1550000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 09:59:27,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0485063e-13 1.0000000e+00 9.6037983e-20 5.3452221e-18 4.3169266e-22], sum to 1.0000
[2019-03-23 09:59:27,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3773
[2019-03-23 09:59:27,980] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 69.66666666666666, 1.0, 2.0, 0.6552546769128673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723682.8514049833, 723682.8514049833, 146059.2786445302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2472600.0000, 
sim time next is 2473200.0000, 
raw observation next is [21.0, 69.0, 1.0, 2.0, 0.674043044466019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 748905.4529270153, 748905.4529270153, 149849.1816969808], 
processed observation next is [1.0, 0.6521739130434783, 0.5909090909090909, 0.69, 1.0, 1.0, 0.5925538055825238, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2773723899729686, 0.2773723899729686, 0.3654858090170264], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.741125], dtype=float32), -1.1379502]. 
=============================================
[2019-03-23 09:59:29,821] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2492946e-14 1.0000000e+00 1.2805534e-21 1.2416622e-20 3.1760761e-24], sum to 1.0000
[2019-03-23 09:59:29,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7146
[2019-03-23 09:59:29,836] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 47.0, 1.0, 2.0, 0.6584792276400967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 715297.566753349, 715297.566753349, 142547.2912288712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2563200.0000, 
sim time next is 2563800.0000, 
raw observation next is [23.0, 47.5, 1.0, 2.0, 0.6905967483949167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 750213.3528785488, 750213.3528785488, 146076.3721755087], 
processed observation next is [1.0, 0.6956521739130435, 0.6818181818181818, 0.475, 1.0, 1.0, 0.6132459354936458, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.27785679736242547, 0.27785679736242547, 0.3562838345744115], 
reward next is 0.6437, 
noisyNet noise sample is [array([0.81640553], dtype=float32), 0.25030977]. 
=============================================
[2019-03-23 09:59:30,807] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1707176e-18 1.0000000e+00 4.4976623e-25 1.6513771e-23 9.5911749e-26], sum to 1.0000
[2019-03-23 09:59:30,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9982
[2019-03-23 09:59:30,826] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2104273361857854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 228470.1589360929, 228470.1589360929, 74715.40343289085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2507400.0000, 
sim time next is 2508000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2117675755686463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 229925.6593646847, 229925.6593646847, 74844.63825667983], 
processed observation next is [1.0, 0.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.014709469460807874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08515765161654988, 0.08515765161654988, 0.18254789818702397], 
reward next is 0.8175, 
noisyNet noise sample is [array([0.04624402], dtype=float32), 1.252433]. 
=============================================
[2019-03-23 09:59:30,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.93018]
 [76.93018]
 [76.93018]
 [76.93018]
 [76.93018]], R is [[76.97834015]
 [77.02632141]
 [77.07386017]
 [77.12055206]
 [77.16645813]].
[2019-03-23 09:59:32,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7844323e-15 1.0000000e+00 7.9673765e-23 2.0343788e-21 1.0557465e-24], sum to 1.0000
[2019-03-23 09:59:32,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8970
[2019-03-23 09:59:32,936] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.18333333333334, 71.5, 1.0, 2.0, 0.2667925821145861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 289686.5959685546, 289686.5959685549, 92964.9031065481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587800.0000, 
sim time next is 2588400.0000, 
raw observation next is [18.1, 73.0, 1.0, 2.0, 0.2701086806818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 293288.3413981639, 293288.3413981636, 94624.43038887338], 
processed observation next is [1.0, 1.0, 0.45909090909090916, 0.73, 1.0, 1.0, 0.08763585085234213, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10862531162894959, 0.10862531162894948, 0.2307912936313985], 
reward next is 0.7692, 
noisyNet noise sample is [array([-0.2096899], dtype=float32), -0.37330458]. 
=============================================
[2019-03-23 09:59:43,631] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4050116e-12 1.0000000e+00 8.0675241e-19 1.5364466e-18 5.9687980e-21], sum to 1.0000
[2019-03-23 09:59:43,637] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3694
[2019-03-23 09:59:43,640] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.0, 1.0, 2.0, 0.4908188279543259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 559927.2144676483, 559927.2144676481, 140650.3126386991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2844000.0000, 
sim time next is 2844600.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4929341483793033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562348.9711435647, 562348.9711435647, 140875.0440997068], 
processed observation next is [1.0, 0.9565217391304348, 0.7196969696969695, 0.7883333333333333, 1.0, 1.0, 0.36616768547412915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20827739671983878, 0.20827739671983878, 0.34359766853587026], 
reward next is 0.6564, 
noisyNet noise sample is [array([0.66946447], dtype=float32), -0.82084614]. 
=============================================
[2019-03-23 09:59:45,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9754021e-16 1.0000000e+00 1.6692020e-20 5.4600273e-20 1.2767141e-22], sum to 1.0000
[2019-03-23 09:59:45,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7748
[2019-03-23 09:59:45,531] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 52.00000000000001, 1.0, 2.0, 0.4551042004756409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 519113.1222756415, 519113.1222756415, 135027.6643044855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2830800.0000, 
sim time next is 2831400.0000, 
raw observation next is [27.5, 52.5, 1.0, 2.0, 0.455005824926269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518952.3331494952, 518952.3331494952, 134904.7583989039], 
processed observation next is [1.0, 0.782608695652174, 0.8863636363636364, 0.525, 1.0, 1.0, 0.31875728115783625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19220456783314638, 0.19220456783314638, 0.3290359960948876], 
reward next is 0.6710, 
noisyNet noise sample is [array([-0.12371222], dtype=float32), 0.33640844]. 
=============================================
[2019-03-23 09:59:47,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4317354e-14 1.0000000e+00 1.2543168e-19 3.0067220e-20 1.0583651e-21], sum to 1.0000
[2019-03-23 09:59:48,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2256
[2019-03-23 09:59:48,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1162901.556840966 W.
[2019-03-23 09:59:48,019] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 75.5, 1.0, 2.0, 0.3436677330437028, 1.0, 1.0, 0.3436677330437028, 1.0, 1.0, 0.6949822098896523, 6.911199999999999, 6.9112, 77.3421103, 1162901.556840966, 1162901.556840966, 280344.8398757579], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2883000.0000, 
sim time next is 2883600.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.3649105746744917, 1.0, 2.0, 0.3649105746744917, 1.0, 2.0, 0.7377684024433967, 6.911199999999999, 6.9112, 77.3421103, 1230844.424648667, 1230844.424648667, 290880.3681876997], 
processed observation next is [1.0, 0.391304347826087, 0.8181818181818182, 0.74, 1.0, 1.0, 0.20613821834311458, 1.0, 1.0, 0.20613821834311458, 1.0, 1.0, 0.6253834320619953, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.4558683054254322, 0.4558683054254322, 0.7094643126529261], 
reward next is 0.2905, 
noisyNet noise sample is [array([-0.20908616], dtype=float32), -2.451726]. 
=============================================
[2019-03-23 09:59:57,789] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2846720e-14 1.0000000e+00 8.6178205e-21 1.7973633e-19 1.9000501e-22], sum to 1.0000
[2019-03-23 09:59:57,796] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8947
[2019-03-23 09:59:57,812] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1213987.638511189 W.
[2019-03-23 09:59:57,822] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 69.83333333333333, 1.0, 2.0, 0.5316808409398425, 1.0, 1.0, 0.5316808409398425, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1213987.638511189, 1213987.638511189, 234372.5966004555], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3067800.0000, 
sim time next is 3068400.0000, 
raw observation next is [24.0, 70.66666666666667, 1.0, 2.0, 0.4003930604713041, 1.0, 2.0, 0.4003930604713041, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 913753.8345118026, 913753.8345118026, 205624.1143313581], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.7066666666666667, 1.0, 1.0, 0.25049132558913006, 1.0, 1.0, 0.25049132558913006, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3384273461154825, 0.3384273461154825, 0.5015222300764832], 
reward next is 0.4985, 
noisyNet noise sample is [array([0.2592936], dtype=float32), -0.089770906]. 
=============================================
[2019-03-23 10:00:00,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5804337e-12 1.0000000e+00 1.0615164e-18 4.1854582e-18 7.3740011e-20], sum to 1.0000
[2019-03-23 10:00:00,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1195
[2019-03-23 10:00:00,954] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.6505658423492433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 741529.566919295, 741529.566919295, 157453.4229696238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3121800.0000, 
sim time next is 3122400.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.530366192185336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 604430.0772611053, 604430.0772611051, 142483.9509134935], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.4129577402316699, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22386299157818715, 0.22386299157818706, 0.3475218314963256], 
reward next is 0.6525, 
noisyNet noise sample is [array([-0.31853852], dtype=float32), 0.8902068]. 
=============================================
[2019-03-23 10:00:01,916] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4587277e-13 1.0000000e+00 1.0958049e-20 3.7289607e-19 1.1353733e-21], sum to 1.0000
[2019-03-23 10:00:01,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5413
[2019-03-23 10:00:01,933] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4537841598840607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517347.8455972456, 517347.8455972459, 134381.1988996188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [22.5, 80.5, 1.0, 2.0, 0.4532732913972191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516699.1811813164, 516699.1811813164, 134223.0309054879], 
processed observation next is [1.0, 0.8260869565217391, 0.6590909090909091, 0.805, 1.0, 1.0, 0.3165916142465239, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19137006710419124, 0.19137006710419124, 0.3273732461109461], 
reward next is 0.6726, 
noisyNet noise sample is [array([0.4164767], dtype=float32), 0.41709924]. 
=============================================
[2019-03-23 10:00:03,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.0116813e-13 1.0000000e+00 7.0419902e-19 1.0559993e-18 4.1923209e-22], sum to 1.0000
[2019-03-23 10:00:03,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8038
[2019-03-23 10:00:03,022] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.01666666666667, 49.66666666666667, 1.0, 2.0, 0.3340997199961303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369119.042321479, 369119.042321479, 115818.4900504444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3250200.0000, 
sim time next is 3250800.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3351726012929923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370557.0261069332, 370557.0261069332, 115998.2899956653], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.5, 1.0, 1.0, 0.16896575161624036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13724334300256785, 0.13724334300256785, 0.28292265852601295], 
reward next is 0.7171, 
noisyNet noise sample is [array([-0.49739242], dtype=float32), 0.4255586]. 
=============================================
[2019-03-23 10:00:03,713] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7325312e-12 1.0000000e+00 3.0839377e-19 1.3890218e-19 1.0325243e-20], sum to 1.0000
[2019-03-23 10:00:03,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4674
[2019-03-23 10:00:03,734] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1287253.510579429 W.
[2019-03-23 10:00:03,738] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.3771275972599707, 1.0, 2.0, 0.3771275972599707, 1.0, 1.0, 0.7639002680135487, 6.911199999999999, 6.9112, 77.3421103, 1287253.510579429, 1287253.51057943, 289846.2473698934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3168600.0000, 
sim time next is 3169200.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3699821357526564, 1.0, 2.0, 0.3699821357526564, 1.0, 2.0, 0.749441742999774, 6.9112, 6.9112, 77.3421103, 1262617.178431817, 1262617.178431817, 286891.8553901247], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.74, 1.0, 1.0, 0.21247766969082052, 1.0, 1.0, 0.21247766969082052, 1.0, 1.0, 0.64205963285682, 0.0, 0.0, 0.5085185399722538, 0.46763599201178413, 0.46763599201178413, 0.6997362326588408], 
reward next is 0.3003, 
noisyNet noise sample is [array([1.0817515], dtype=float32), -0.9163082]. 
=============================================
[2019-03-23 10:00:04,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5468547e-12 1.0000000e+00 1.4826840e-19 9.9589138e-18 1.0287259e-21], sum to 1.0000
[2019-03-23 10:00:04,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5591
[2019-03-23 10:00:04,282] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4534711713626576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517052.7621204607, 517052.762120461, 134453.2505927123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3178800.0000, 
sim time next is 3179400.0000, 
raw observation next is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4544442403046661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518157.6352084509, 518157.6352084509, 134546.6625945471], 
processed observation next is [1.0, 0.8260869565217391, 0.6742424242424245, 0.7883333333333333, 1.0, 1.0, 0.31805530038083263, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19191023526238923, 0.19191023526238923, 0.3281625916940173], 
reward next is 0.6718, 
noisyNet noise sample is [array([-0.70085436], dtype=float32), 0.85206205]. 
=============================================
[2019-03-23 10:00:05,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5016230e-13 1.0000000e+00 9.3553100e-20 6.3380719e-19 1.8552286e-22], sum to 1.0000
[2019-03-23 10:00:05,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7348
[2019-03-23 10:00:05,069] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1303941.873329489 W.
[2019-03-23 10:00:05,073] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.6618139348660284, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9690671835311613, 6.9112, 6.9112, 77.32846344354104, 1303941.873329489, 1303941.873329489, 278203.9139491183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3164400.0000, 
sim time next is 3165000.0000, 
raw observation next is [23.16666666666667, 77.33333333333333, 1.0, 2.0, 0.5526653587330811, 1.0, 1.0, 0.5526653587330811, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1260763.867057426, 1260763.867057426, 241655.7164656907], 
processed observation next is [1.0, 0.6521739130434783, 0.6893939393939396, 0.7733333333333333, 1.0, 1.0, 0.44083169841635134, 1.0, 0.5, 0.44083169841635134, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4669495803916392, 0.4669495803916392, 0.5894041865016846], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22813265], dtype=float32), -0.5135866]. 
=============================================
[2019-03-23 10:00:05,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.10824]
 [69.10824]
 [69.10824]
 [69.10824]
 [69.10824]], R is [[68.41716003]
 [67.73298645]
 [67.05565643]
 [66.38510132]
 [66.11186981]].
[2019-03-23 10:00:09,035] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8592474e-14 1.0000000e+00 5.5568927e-21 6.7554891e-21 2.2700828e-23], sum to 1.0000
[2019-03-23 10:00:09,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6027
[2019-03-23 10:00:09,048] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 61.33333333333334, 1.0, 2.0, 0.3339141195990529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 367675.0367586098, 367675.0367586098, 115327.9830060847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3273600.0000, 
sim time next is 3274200.0000, 
raw observation next is [21.5, 62.0, 1.0, 2.0, 0.331610945727925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 364803.6458380651, 364803.6458380654, 115031.3032075596], 
processed observation next is [0.0, 0.9130434782608695, 0.6136363636363636, 0.62, 1.0, 1.0, 0.16451368215990622, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13511246142150557, 0.1351124614215057, 0.28056415416477953], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.16136259], dtype=float32), 2.2047238]. 
=============================================
[2019-03-23 10:00:10,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7676520e-13 1.0000000e+00 8.2610728e-20 4.4270003e-19 2.9088583e-22], sum to 1.0000
[2019-03-23 10:00:10,393] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-23 10:00:10,399] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.66666666666667, 84.0, 1.0, 2.0, 0.2365968238527174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 256891.0193116805, 256891.0193116808, 81912.94395562419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3304200.0000, 
sim time next is 3304800.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2401003522416112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 260696.0838665585, 260696.0838665582, 82909.9704529661], 
processed observation next is [0.0, 0.2608695652173913, 0.36363636363636365, 0.82, 1.0, 1.0, 0.05012544030201398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0965541051357624, 0.0965541051357623, 0.2022194401291856], 
reward next is 0.7978, 
noisyNet noise sample is [array([-1.0087204], dtype=float32), 0.44358647]. 
=============================================
[2019-03-23 10:00:15,215] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 10:00:15,216] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:00:15,217] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:00:15,217] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:00:15,219] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:00:15,218] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:00:15,220] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:00:15,221] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:00:15,223] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:00:15,220] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:00:15,224] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:00:15,249] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 10:00:15,249] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 10:00:15,273] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 10:00:15,329] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 10:00:15,329] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 10:00:16,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:00:16,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.5, 68.0, 1.0, 2.0, 0.2145531491985372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 232940.1684743262, 232940.1684743266, 77284.24106049481]
[2019-03-23 10:00:16,362] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:00:16,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.6691257928042209
[2019-03-23 10:00:25,238] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:00:25,239] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.94396463333333, 68.46697954166666, 1.0, 2.0, 0.4104033225769393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464427.8903112771, 464427.8903112768, 131242.4209127482]
[2019-03-23 10:00:25,239] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:00:25,242] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.8218034682114068
[2019-03-23 10:00:29,295] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:00:29,297] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.586507045, 89.17539071499999, 1.0, 2.0, 0.3474958583819435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 387016.4671898493, 387016.4671898489, 122412.869652054]
[2019-03-23 10:00:29,299] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:00:29,301] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.29154053058873064
[2019-03-23 10:00:47,739] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:00:47,741] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.77026680333334, 85.30646385666667, 1.0, 2.0, 0.5056524693549497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 549130.8515177659, 549130.8515177655, 111699.0321169249]
[2019-03-23 10:00:47,742] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:00:47,746] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.9695617195282482
[2019-03-23 10:00:48,884] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:00:48,886] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.92039607333333, 85.61555644, 1.0, 2.0, 0.2927783466523544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 317891.6572435678, 317891.6572435674, 89680.61929090206]
[2019-03-23 10:00:48,887] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:00:48,892] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.9810437897615117
[2019-03-23 10:00:54,955] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:00:54,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.0, 1.0, 2.0, 0.4290373977863206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488108.1295351337, 488108.1295351337, 130598.8121108446]
[2019-03-23 10:00:54,957] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:00:54,960] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.04137077836097025
[2019-03-23 10:01:10,869] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:01:10,871] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [16.0, 100.0, 1.0, 2.0, 0.3066434216676769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333101.3832790264, 333101.3832790267, 111684.9778994275]
[2019-03-23 10:01:10,872] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:01:10,875] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.44514460866647587
[2019-03-23 10:01:13,646] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:01:13,648] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.47473137, 93.2441863, 1.0, 2.0, 0.3806026052931615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 426812.3703387874, 426812.370338787, 126399.065627404]
[2019-03-23 10:01:13,650] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:01:13,652] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.9869721282468563
[2019-03-23 10:01:28,630] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:01:28,631] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.2, 90.0, 1.0, 2.0, 0.321987313242994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 350629.1845485394, 350629.1845485397, 113031.245017317]
[2019-03-23 10:01:28,632] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:01:28,635] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.04938083744020105
[2019-03-23 10:01:31,536] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:01:31,537] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.91666666666667, 73.33333333333333, 1.0, 2.0, 0.3170359733919125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 348967.7990186387, 348967.7990186384, 118363.1882707129]
[2019-03-23 10:01:31,538] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:01:31,540] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.8657478020542965
[2019-03-23 10:01:50,182] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:01:50,183] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.98540641833333, 61.67166840833334, 1.0, 2.0, 0.460651513426656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 524185.4789957663, 524185.4789957663, 138270.8337979843]
[2019-03-23 10:01:50,184] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:01:50,186] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.10750858897050786
[2019-03-23 10:01:53,398] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.40610757]
[2019-03-23 10:01:53,399] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.18289764, 57.24557988, 1.0, 2.0, 0.5038474004265576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574145.1020927326, 574145.1020927326, 143793.8437256527]
[2019-03-23 10:01:53,400] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:01:53,403] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4718136e-14 1.0000000e+00 5.4291612e-21 3.3157948e-20 7.4964871e-23], sampled 0.3097565676677032
[2019-03-23 10:01:55,504] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:01:55,619] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:01:55,642] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:01:55,770] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:01:55,931] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:01:56,948] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1575000, evaluation results [1575000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:01:58,791] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2135947e-12 1.0000000e+00 1.0446127e-18 6.9015757e-18 2.9682611e-19], sum to 1.0000
[2019-03-23 10:01:58,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5093
[2019-03-23 10:01:58,803] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 83.33333333333334, 1.0, 2.0, 0.3788246869586175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 425325.5592705904, 425325.5592705904, 122169.9728503436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3397200.0000, 
sim time next is 3397800.0000, 
raw observation next is [20.5, 80.66666666666666, 1.0, 2.0, 0.3830849956473654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430856.1185005694, 430856.1185005694, 122908.6077389108], 
processed observation next is [1.0, 0.30434782608695654, 0.5681818181818182, 0.8066666666666665, 1.0, 1.0, 0.22885624455920675, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15957634018539607, 0.15957634018539607, 0.2997770920461239], 
reward next is 0.7002, 
noisyNet noise sample is [array([0.1496627], dtype=float32), -1.2086921]. 
=============================================
[2019-03-23 10:02:00,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1385048e-13 1.0000000e+00 2.2070365e-19 1.3417641e-19 3.5653133e-22], sum to 1.0000
[2019-03-23 10:02:00,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9255
[2019-03-23 10:02:00,472] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5011197388417051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571492.8492846964, 571492.8492846964, 142223.5268144624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3459000.0000, 
sim time next is 3459600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5011247021865457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 571498.5747714925, 571498.5747714925, 142224.0083828243], 
processed observation next is [1.0, 0.043478260869565216, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37640587773318207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2116661388042565, 0.2116661388042565, 0.34688782532396173], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.12995481], dtype=float32), -0.12812673]. 
=============================================
[2019-03-23 10:02:03,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3514584e-10 1.0000000e+00 1.7940711e-16 2.0930936e-16 1.4208507e-18], sum to 1.0000
[2019-03-23 10:02:03,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4528
[2019-03-23 10:02:03,141] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1724595.683948126 W.
[2019-03-23 10:02:03,147] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.766606737401587, 1.0, 2.0, 0.766606737401587, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1724595.683948126, 1724595.683948126, 313502.3294605843], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3601800.0000, 
sim time next is 3602400.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.7229427765854914, 1.0, 2.0, 0.7229427765854914, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1626225.999162229, 1626225.999162229, 299101.0223158913], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.6536784707318644, 1.0, 1.0, 0.6536784707318644, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6023059256156403, 0.6023059256156403, 0.7295146885753446], 
reward next is 0.2705, 
noisyNet noise sample is [array([0.3980673], dtype=float32), 0.8055732]. 
=============================================
[2019-03-23 10:02:05,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5523246e-13 1.0000000e+00 9.2618105e-21 8.2096144e-20 5.5490733e-22], sum to 1.0000
[2019-03-23 10:02:05,926] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7115
[2019-03-23 10:02:05,928] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 81.33333333333334, 1.0, 2.0, 0.5136132866299777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 585183.8992926861, 585183.8992926861, 144380.2401738851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [24.0, 80.5, 1.0, 2.0, 0.5110566245995302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582492.4566197668, 582492.4566197668, 143844.4607358651], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.805, 1.0, 1.0, 0.3888207807494127, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21573794689620993, 0.21573794689620993, 0.35084014813625636], 
reward next is 0.6492, 
noisyNet noise sample is [array([0.5663305], dtype=float32), 0.88931215]. 
=============================================
[2019-03-23 10:02:05,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.20341]
 [63.20341]
 [63.20341]
 [63.20341]
 [63.20341]], R is [[63.22053146]
 [63.23617935]
 [63.24978256]
 [63.26110458]
 [63.27183914]].
[2019-03-23 10:02:10,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8805114e-12 1.0000000e+00 3.0606037e-19 9.9397796e-19 6.9972113e-21], sum to 1.0000
[2019-03-23 10:02:10,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5855
[2019-03-23 10:02:10,116] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5484365158029727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625768.3057671419, 625768.3057671419, 147325.4596056487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3654600.0000, 
sim time next is 3655200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5153120956894959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587955.0947288447, 587955.0947288447, 143310.4795033351], 
processed observation next is [1.0, 0.30434782608695654, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3941401196118698, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21776114619586842, 0.21776114619586842, 0.3495377548861832], 
reward next is 0.6505, 
noisyNet noise sample is [array([1.6926056], dtype=float32), -1.0933021]. 
=============================================
[2019-03-23 10:02:10,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0794175e-11 1.0000000e+00 3.3948057e-18 4.8062362e-18 6.0414403e-20], sum to 1.0000
[2019-03-23 10:02:10,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9048
[2019-03-23 10:02:10,271] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 64.33333333333334, 1.0, 2.0, 0.3010255766570777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326869.6851158258, 326869.6851158258, 111261.1656663993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3968400.0000, 
sim time next is 3969000.0000, 
raw observation next is [20.0, 66.5, 1.0, 2.0, 0.3015648326998657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 327455.4353379763, 327455.4353379763, 111297.2591958274], 
processed observation next is [0.0, 0.9565217391304348, 0.5454545454545454, 0.665, 1.0, 1.0, 0.12695604087483214, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12127979086591716, 0.12127979086591716, 0.2714567297459205], 
reward next is 0.7285, 
noisyNet noise sample is [array([0.5430359], dtype=float32), 0.26780227]. 
=============================================
[2019-03-23 10:02:10,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.38938]
 [62.38938]
 [62.38938]
 [62.38938]
 [62.38938]], R is [[62.49403381]
 [62.59772491]
 [62.70034409]
 [62.80175018]
 [62.901577  ]].
[2019-03-23 10:02:15,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6547257e-11 1.0000000e+00 1.8464360e-17 6.7414505e-16 8.9645738e-20], sum to 1.0000
[2019-03-23 10:02:15,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2906
[2019-03-23 10:02:15,057] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.2982750101389878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323881.9781609855, 323881.9781609857, 111076.2838134219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3842400.0000, 
sim time next is 3843000.0000, 
raw observation next is [19.0, 73.0, 1.0, 2.0, 0.2975113223775083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 323052.4522192201, 323052.4522192198, 111025.3536026662], 
processed observation next is [0.0, 0.4782608695652174, 0.5, 0.73, 1.0, 1.0, 0.12188915297188539, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11964905637748893, 0.11964905637748882, 0.2707935453723566], 
reward next is 0.7292, 
noisyNet noise sample is [array([0.40280867], dtype=float32), 0.78039366]. 
=============================================
[2019-03-23 10:02:15,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.569992]
 [63.569992]
 [63.569992]
 [63.569992]
 [63.569992]], R is [[63.66349411]
 [63.7559433 ]
 [63.84718704]
 [63.93701553]
 [64.02487946]].
[2019-03-23 10:02:18,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5252483e-15 1.0000000e+00 8.0548116e-22 1.9380427e-22 6.1123164e-24], sum to 1.0000
[2019-03-23 10:02:18,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1730
[2019-03-23 10:02:18,919] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 88.0, 1.0, 2.0, 0.2998518770690036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 325594.7926256446, 325594.7926256449, 109875.3452187322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3826800.0000, 
sim time next is 3827400.0000, 
raw observation next is [17.0, 89.00000000000001, 1.0, 2.0, 0.3007764058903748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326599.031304178, 326599.031304178, 111243.3092786074], 
processed observation next is [0.0, 0.30434782608695654, 0.4090909090909091, 0.8900000000000001, 1.0, 1.0, 0.12597050736296847, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12096260418673259, 0.12096260418673259, 0.27132514458196927], 
reward next is 0.7287, 
noisyNet noise sample is [array([-0.15711607], dtype=float32), 0.31081554]. 
=============================================
[2019-03-23 10:02:30,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0249712e-14 1.0000000e+00 5.7945850e-22 4.1976860e-20 8.5807067e-24], sum to 1.0000
[2019-03-23 10:02:30,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-23 10:02:30,038] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.4199678482831342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465310.3075974668, 465310.3075974665, 123199.001691594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4021200.0000, 
sim time next is 4021800.0000, 
raw observation next is [17.16666666666667, 100.0, 1.0, 2.0, 0.4860156546704225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 539603.1009148221, 539603.1009148221, 129583.7304927396], 
processed observation next is [1.0, 0.5652173913043478, 0.4166666666666669, 1.0, 1.0, 1.0, 0.3575195683380281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.199853000338823, 0.199853000338823, 0.3160578792505844], 
reward next is 0.6839, 
noisyNet noise sample is [array([-1.0502535], dtype=float32), 1.5372223]. 
=============================================
[2019-03-23 10:02:38,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5101020e-13 1.0000000e+00 2.8544277e-20 2.3562622e-19 4.8313361e-22], sum to 1.0000
[2019-03-23 10:02:38,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3688
[2019-03-23 10:02:38,546] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 61.0, 1.0, 2.0, 0.8508326094963271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 963914.2676698657, 963914.2676698657, 181687.8982493195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4195800.0000, 
sim time next is 4196400.0000, 
raw observation next is [24.0, 61.0, 1.0, 2.0, 0.8383459623049918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 949852.2137695564, 949852.2137695566, 179840.7500361243], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.61, 1.0, 1.0, 0.7979324528812398, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3517971162109468, 0.3517971162109469, 0.4386359756978641], 
reward next is 0.5614, 
noisyNet noise sample is [array([1.0998211], dtype=float32), 0.09892266]. 
=============================================
[2019-03-23 10:02:39,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0193089e-14 1.0000000e+00 7.2499356e-20 3.2162333e-19 1.1439602e-20], sum to 1.0000
[2019-03-23 10:02:39,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1754
[2019-03-23 10:02:39,030] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 97.0, 1.0, 2.0, 0.324746436234119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352636.4033487799, 352636.4033487802, 111874.4892495506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4249800.0000, 
sim time next is 4250400.0000, 
raw observation next is [16.0, 96.0, 1.0, 2.0, 0.3189581721160394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 346348.7914985236, 346348.7914985239, 108940.1252991367], 
processed observation next is [1.0, 0.17391304347826086, 0.36363636363636365, 0.96, 1.0, 1.0, 0.1486977151450492, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12827733018463838, 0.1282773301846385, 0.2657076226808212], 
reward next is 0.7343, 
noisyNet noise sample is [array([0.86927253], dtype=float32), -0.32324767]. 
=============================================
[2019-03-23 10:02:39,407] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3020247e-14 1.0000000e+00 3.3220746e-20 3.2063824e-20 1.4862324e-22], sum to 1.0000
[2019-03-23 10:02:39,411] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7747
[2019-03-23 10:02:39,415] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4013863925321234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453793.195483635, 453793.1954836347, 125807.8056325475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4215000.0000, 
sim time next is 4215600.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.3985222856437403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 450299.7160064297, 450299.71600643, 125393.8058125209], 
processed observation next is [1.0, 0.8260869565217391, 0.6363636363636364, 0.73, 1.0, 1.0, 0.24815285705467538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16677767259497395, 0.16677767259497406, 0.3058385507622461], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.5256653], dtype=float32), -1.0971415]. 
=============================================
[2019-03-23 10:02:43,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7876887e-14 1.0000000e+00 5.4265756e-20 2.2621691e-19 1.5007782e-21], sum to 1.0000
[2019-03-23 10:02:43,113] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6752
[2019-03-23 10:02:43,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1204194.950970673 W.
[2019-03-23 10:02:43,124] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 49.0, 1.0, 2.0, 0.5273513938550705, 1.0, 1.0, 0.5273513938550705, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846033050488, 1204194.950970673, 1204194.950970673, 231045.3400954066], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4287600.0000, 
sim time next is 4288200.0000, 
raw observation next is [27.08333333333334, 49.33333333333334, 1.0, 2.0, 0.586734848089683, 1.0, 2.0, 0.586734848089683, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 78.26345941398532, 1340035.08548148, 1340035.08548148, 247640.3072203556], 
processed observation next is [1.0, 0.6521739130434783, 0.8674242424242427, 0.4933333333333334, 1.0, 1.0, 0.4834185601121037, 1.0, 1.0, 0.4834185601121037, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5145763408834418, 0.49630929091906667, 0.49630929091906667, 0.6040007493179405], 
reward next is 0.3960, 
noisyNet noise sample is [array([-1.0142081], dtype=float32), 0.28642958]. 
=============================================
[2019-03-23 10:02:44,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6832599e-14 1.0000000e+00 1.8674575e-20 1.3845252e-19 7.9093295e-22], sum to 1.0000
[2019-03-23 10:02:44,606] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8648
[2019-03-23 10:02:44,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1204196.640583519 W.
[2019-03-23 10:02:44,620] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.1, 49.0, 1.0, 2.0, 0.5753598915561378, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9634375061785778, 6.911199999999999, 6.9112, 77.32846031898772, 1204196.640583519, 1204196.640583519, 260401.8801739283], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4287600.0000, 
sim time next is 4288200.0000, 
raw observation next is [27.08333333333334, 49.33333333333334, 1.0, 2.0, 0.6941831230651341, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9639053263883278, 6.911199999999999, 6.9112, 78.26345941391399, 1340035.331249731, 1340035.331249732, 277217.2255091175], 
processed observation next is [1.0, 0.6521739130434783, 0.8674242424242427, 0.4933333333333334, 1.0, 1.0, 0.6177289038314175, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9484361805547542, -8.881784197001253e-17, 0.0, 0.5145763408829729, 0.49630938194434476, 0.4963093819443452, 0.6761395744124816], 
reward next is 0.3239, 
noisyNet noise sample is [array([-1.23139], dtype=float32), 0.51817685]. 
=============================================
[2019-03-23 10:02:45,449] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 10:02:45,450] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:02:45,453] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:02:45,454] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:45,454] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:02:45,455] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:02:45,456] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:02:45,456] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:45,455] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:45,458] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:45,458] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:02:45,481] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 10:02:45,507] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 10:02:45,508] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 10:02:45,545] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 10:02:45,546] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 10:02:48,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:02:48,494] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.28333333333333, 31.83333333333334, 1.0, 2.0, 0.3439657807646761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 373487.0070007292, 373487.0070007292, 95238.28663304423]
[2019-03-23 10:02:48,495] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:02:48,498] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.7802997144391325
[2019-03-23 10:03:12,224] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:03:12,225] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.677396615, 100.0, 1.0, 2.0, 0.3379278306011173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 376481.223571185, 376481.2235711847, 121716.7750403595]
[2019-03-23 10:03:12,226] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:03:12,229] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.5061488826810603
[2019-03-23 10:03:31,462] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:03:31,462] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 66.5, 1.0, 2.0, 0.351179048866915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 390404.7067048412, 390404.7067048412, 118084.1919036844]
[2019-03-23 10:03:31,463] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:03:31,468] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.9096526800619129
[2019-03-23 10:03:43,282] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:03:43,283] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 88.0, 1.0, 2.0, 0.3629124990955317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405567.7423269204, 405567.7423269204, 119929.7324109269]
[2019-03-23 10:03:43,284] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:03:43,289] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.05421274047318647
[2019-03-23 10:03:43,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:03:43,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.15947961166667, 58.87137909166667, 1.0, 2.0, 0.3552589111397864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390784.1993814119, 390784.1993814119, 121110.6164847853]
[2019-03-23 10:03:43,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:03:43,382] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.5607217752717544
[2019-03-23 10:03:53,955] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:03:53,956] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.16666666666667, 51.33333333333334, 1.0, 2.0, 0.2891151087893739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 313913.1633031838, 313913.1633031838, 111836.0545141745]
[2019-03-23 10:03:53,957] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:03:53,962] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.32493052992836513
[2019-03-23 10:03:58,441] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:03:58,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.8, 62.33333333333334, 1.0, 2.0, 0.9075291289971552, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9853182785919935, 6.911200000000001, 6.9112, 77.32846278670078, 1569033.730360941, 1569033.730360941, 334634.424483838]
[2019-03-23 10:03:58,442] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:03:58,447] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.3925056509820142
[2019-03-23 10:03:58,448] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1569033.730360941 W.
[2019-03-23 10:04:12,805] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:04:12,806] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.70924790833334, 77.05512854166668, 1.0, 2.0, 0.3477125988794871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 390206.542463881, 390206.542463881, 123789.409636527]
[2019-03-23 10:04:12,807] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:04:12,810] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.39763449573443643
[2019-03-23 10:04:13,775] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:04:13,775] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.91891998, 93.91887638, 1.0, 2.0, 0.4488723127791058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 511822.2309806951, 511822.2309806951, 138397.505332377]
[2019-03-23 10:04:13,777] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:04:13,779] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.8077455166415125
[2019-03-23 10:04:20,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41345266]
[2019-03-23 10:04:20,026] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.496074235, 50.76086618, 1.0, 2.0, 0.508671004627996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 576484.3084928272, 576484.3084928269, 141618.565485351]
[2019-03-23 10:04:20,027] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:04:20,030] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.73511308e-14 1.00000000e+00 7.14616841e-21 3.64471805e-20
 1.00897045e-22], sampled 0.08333300989690284
[2019-03-23 10:04:25,884] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:04:25,989] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:04:26,167] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:04:26,328] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:04:26,466] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:04:27,482] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1600000, evaluation results [1600000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:04:32,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4854969e-14 1.0000000e+00 5.4738541e-20 8.3661354e-21 3.4053436e-22], sum to 1.0000
[2019-03-23 10:04:32,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6159
[2019-03-23 10:04:32,662] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 78.0, 1.0, 2.0, 0.4586197070307861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522974.4779762502, 522974.4779762502, 135085.9844980179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4402200.0000, 
sim time next is 4402800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4584473616228734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522777.526993349, 522777.526993349, 135067.0184311457], 
processed observation next is [1.0, 1.0, 0.6818181818181818, 0.78, 1.0, 1.0, 0.32305920202859173, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19362130629383298, 0.19362130629383298, 0.32943175227108706], 
reward next is 0.6706, 
noisyNet noise sample is [array([-1.1855187], dtype=float32), -0.43306273]. 
=============================================
[2019-03-23 10:04:36,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8967974e-12 1.0000000e+00 7.7293857e-21 2.0775060e-20 3.4673343e-21], sum to 1.0000
[2019-03-23 10:04:36,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1099
[2019-03-23 10:04:36,014] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 78.0, 1.0, 2.0, 0.4338136214725926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493933.5129912495, 493933.5129912495, 131471.3250251538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4537800.0000, 
sim time next is 4538400.0000, 
raw observation next is [22.66666666666666, 76.33333333333334, 1.0, 2.0, 0.4318295694995072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491529.3542412783, 491529.3542412783, 131118.2183896216], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666664, 0.7633333333333334, 1.0, 1.0, 0.28978696187438396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18204790897825124, 0.18204790897825124, 0.3198005326576136], 
reward next is 0.6802, 
noisyNet noise sample is [array([-1.756968], dtype=float32), 0.08141364]. 
=============================================
[2019-03-23 10:04:41,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8810894e-14 1.0000000e+00 1.0745030e-21 1.0220923e-20 1.9125871e-22], sum to 1.0000
[2019-03-23 10:04:41,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8500
[2019-03-23 10:04:41,978] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 46.5, 1.0, 2.0, 0.6317883361924831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 692024.1951508492, 692024.1951508494, 141495.6057775584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4629000.0000, 
sim time next is 4629600.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.6520553433708458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 717218.7433849239, 717218.7433849239, 144689.0339296748], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.47, 1.0, 1.0, 0.5650691792135573, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2656365716240459, 0.2656365716240459, 0.3529000827553044], 
reward next is 0.6471, 
noisyNet noise sample is [array([1.5248414], dtype=float32), 0.8490793]. 
=============================================
[2019-03-23 10:04:44,670] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9295103e-15 1.0000000e+00 5.0237348e-23 1.6045378e-22 1.2836522e-24], sum to 1.0000
[2019-03-23 10:04:44,679] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6690
[2019-03-23 10:04:44,683] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2627115123002044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 285254.0217129315, 285254.0217129315, 90485.42495677786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4656600.0000, 
sim time next is 4657200.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2623343844149451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 284844.4136666176, 284844.4136666179, 90437.5266976074], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.07791798051868137, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10549793098763614, 0.10549793098763625, 0.22057933340879854], 
reward next is 0.7794, 
noisyNet noise sample is [array([-0.69076234], dtype=float32), 0.35052365]. 
=============================================
[2019-03-23 10:04:46,904] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9277391e-15 1.0000000e+00 6.3962826e-22 2.5478700e-21 3.5008363e-23], sum to 1.0000
[2019-03-23 10:04:46,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6432
[2019-03-23 10:04:46,913] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 87.00000000000001, 1.0, 2.0, 0.2194727158757639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 238293.528875358, 238293.528875358, 74672.27844658685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4684200.0000, 
sim time next is 4684800.0000, 
raw observation next is [14.0, 86.0, 1.0, 2.0, 0.2105302754364159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 228581.9508431006, 228581.9508431003, 73724.72356642838], 
processed observation next is [1.0, 0.21739130434782608, 0.2727272727272727, 0.86, 1.0, 1.0, 0.013162844295519852, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08465998179374097, 0.08465998179374085, 0.17981639894250825], 
reward next is 0.8202, 
noisyNet noise sample is [array([-0.65930915], dtype=float32), -2.547437]. 
=============================================
[2019-03-23 10:04:52,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0617913e-14 1.0000000e+00 3.8450671e-21 1.2332274e-19 1.6022992e-22], sum to 1.0000
[2019-03-23 10:04:52,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8405
[2019-03-23 10:04:52,617] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.6563391966367967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 744660.4840142245, 744660.4840142247, 155151.8566806336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4782000.0000, 
sim time next is 4782600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.7290549459463277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 827500.0364919282, 827500.0364919282, 165067.671810204], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 1.0, 1.0, 1.0, 0.6613186824329095, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30648149499701044, 0.30648149499701044, 0.40260407758586336], 
reward next is 0.5974, 
noisyNet noise sample is [array([-0.3503214], dtype=float32), 1.161165]. 
=============================================
[2019-03-23 10:04:55,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6067511e-15 1.0000000e+00 1.4606266e-20 2.6875901e-20 2.3650194e-23], sum to 1.0000
[2019-03-23 10:04:55,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7341
[2019-03-23 10:04:55,380] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 84.66666666666666, 1.0, 2.0, 0.8021715367309322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911913.6085457095, 911913.6085457095, 176633.9611631692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4880400.0000, 
sim time next is 4881000.0000, 
raw observation next is [21.0, 83.83333333333334, 1.0, 2.0, 0.8126087957393369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 923263.989136106, 923263.989136106, 177793.0622330927], 
processed observation next is [1.0, 0.4782608695652174, 0.5909090909090909, 0.8383333333333334, 1.0, 1.0, 0.7657609946741711, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3419496256059652, 0.3419496256059652, 0.43364161520266514], 
reward next is 0.5664, 
noisyNet noise sample is [array([-0.13505258], dtype=float32), -0.9636466]. 
=============================================
[2019-03-23 10:04:55,399] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[65.45987]
 [65.45987]
 [65.45987]
 [65.45987]
 [65.45987]], R is [[65.37163544]
 [65.28710175]
 [65.21367645]
 [65.13606262]
 [65.03656006]].
[2019-03-23 10:04:55,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2687985e-13 1.0000000e+00 3.8860813e-18 1.8804338e-18 2.5614352e-21], sum to 1.0000
[2019-03-23 10:04:56,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5505
[2019-03-23 10:04:56,006] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 76.33333333333334, 1.0, 2.0, 0.8346573625723921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 949749.3659881642, 949749.3659881642, 182358.611699206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4893600.0000, 
sim time next is 4894200.0000, 
raw observation next is [22.5, 75.5, 1.0, 2.0, 0.8329676146656159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 948003.3184229999, 948003.3184229999, 182261.2097861601], 
processed observation next is [1.0, 0.6521739130434783, 0.6590909090909091, 0.755, 1.0, 1.0, 0.7912095183320197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.35111234015666665, 0.35111234015666665, 0.4445395360638051], 
reward next is 0.5555, 
noisyNet noise sample is [array([0.20800208], dtype=float32), 0.51616573]. 
=============================================
[2019-03-23 10:04:57,899] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4801624e-13 1.0000000e+00 4.3148213e-21 7.0548425e-19 2.0074894e-21], sum to 1.0000
[2019-03-23 10:04:57,908] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1678
[2019-03-23 10:04:57,914] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3875140015423765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430838.0097964984, 430838.0097964987, 121049.4728432002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4936800.0000, 
sim time next is 4937400.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.3777030424279411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 419500.1296384802, 419500.1296384802, 120062.5292917263], 
processed observation next is [1.0, 0.13043478260869565, 0.4318181818181818, 0.97, 1.0, 1.0, 0.22212880303492638, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1553704183846223, 0.1553704183846223, 0.29283543729689343], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.93915224], dtype=float32), -1.2844825]. 
=============================================
[2019-03-23 10:04:58,394] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4808964e-14 1.0000000e+00 3.1148758e-21 6.0711044e-20 1.2798104e-22], sum to 1.0000
[2019-03-23 10:04:58,403] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1642
[2019-03-23 10:04:58,408] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333333, 98.0, 1.0, 2.0, 0.3846937479730377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 432624.0662360684, 432624.0662360684, 123027.1426898832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4920600.0000, 
sim time next is 4921200.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3804132868627348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 427246.5410246626, 427246.5410246623, 122373.0752704277], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 1.0, 0.22551660857841846, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15823945963876393, 0.15823945963876382, 0.2984709152937261], 
reward next is 0.7015, 
noisyNet noise sample is [array([-0.8862537], dtype=float32), -0.19570595]. 
=============================================
[2019-03-23 10:05:01,945] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1933508e-16 1.0000000e+00 4.7869017e-23 8.1142359e-23 6.0708807e-25], sum to 1.0000
[2019-03-23 10:05:01,953] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7727
[2019-03-23 10:05:01,957] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 79.0, 1.0, 2.0, 0.2814307607021613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 305585.9000288247, 305585.9000288244, 95915.65884235923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4999200.0000, 
sim time next is 4999800.0000, 
raw observation next is [17.16666666666667, 80.5, 1.0, 2.0, 0.2809960490557844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 305113.7291075381, 305113.7291075384, 96064.85837890288], 
processed observation next is [1.0, 0.8695652173913043, 0.4166666666666669, 0.805, 1.0, 1.0, 0.10124506131973049, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11300508485464375, 0.11300508485464386, 0.23430453263147044], 
reward next is 0.7657, 
noisyNet noise sample is [array([-2.1901278], dtype=float32), 1.3358381]. 
=============================================
[2019-03-23 10:05:07,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6572149e-15 1.0000000e+00 1.7615621e-21 2.2009891e-21 3.8123892e-24], sum to 1.0000
[2019-03-23 10:05:07,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0801
[2019-03-23 10:05:07,251] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4070488694550926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460999.6430120211, 460999.6430120211, 126830.8343296951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5103600.0000, 
sim time next is 5104200.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4022999060115081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455188.4364264177, 455188.4364264177, 126112.8960155551], 
processed observation next is [0.0, 0.043478260869565216, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.2528748825143851, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16858830978756212, 0.16858830978756212, 0.307592429306232], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.85437363], dtype=float32), -1.5886723]. 
=============================================
[2019-03-23 10:05:07,762] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0503048e-14 1.0000000e+00 5.8205751e-21 5.0861389e-21 8.8262460e-24], sum to 1.0000
[2019-03-23 10:05:07,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5195
[2019-03-23 10:05:07,774] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 83.0, 1.0, 2.0, 0.400301652117823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453622.6443276401, 453622.6443276398, 126379.7445047885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5112000.0000, 
sim time next is 5112600.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.4001169321438467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453413.2536427455, 453413.2536427452, 126362.5553931215], 
processed observation next is [0.0, 0.17391304347826086, 0.5909090909090909, 0.83, 1.0, 1.0, 0.2501461651798083, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16793083468249834, 0.16793083468249823, 0.3082013546173695], 
reward next is 0.6918, 
noisyNet noise sample is [array([1.1489501], dtype=float32), 1.9416537]. 
=============================================
[2019-03-23 10:05:08,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9424444e-13 1.0000000e+00 4.9141513e-19 1.9936175e-19 2.6569042e-22], sum to 1.0000
[2019-03-23 10:05:08,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-23 10:05:08,202] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4253480409250084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 484589.8871335417, 484589.8871335417, 130972.4117039246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5205600.0000, 
sim time next is 5206200.0000, 
raw observation next is [22.0, 82.16666666666667, 1.0, 2.0, 0.4375265406204841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498329.4466243614, 498329.4466243617, 132035.6624747939], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.8216666666666668, 1.0, 1.0, 0.2969081757756051, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18456646171272645, 0.18456646171272656, 0.32203820115803394], 
reward next is 0.6780, 
noisyNet noise sample is [array([-2.564265], dtype=float32), -1.7790506]. 
=============================================
[2019-03-23 10:05:08,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7827242e-14 1.0000000e+00 2.7798057e-22 1.0980478e-20 1.3231581e-23], sum to 1.0000
[2019-03-23 10:05:08,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5403
[2019-03-23 10:05:08,815] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4167726396807079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 473308.8029296006, 473308.8029296006, 128663.0101438421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5101200.0000, 
sim time next is 5101800.0000, 
raw observation next is [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4145699536681598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 470591.2716519482, 470591.2716519482, 128284.8368584827], 
processed observation next is [0.0, 0.043478260869565216, 0.6212121212121214, 0.7966666666666667, 1.0, 1.0, 0.26821244208519973, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17429306357479563, 0.17429306357479563, 0.31288984599629927], 
reward next is 0.6871, 
noisyNet noise sample is [array([0.6434227], dtype=float32), -1.307441]. 
=============================================
[2019-03-23 10:05:15,957] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 10:05:15,958] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:05:15,960] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:05:15,961] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:05:15,962] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:05:15,963] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:05:15,962] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:05:15,960] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:05:15,966] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:05:15,969] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:05:15,969] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:05:15,988] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 10:05:16,014] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 10:05:16,038] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 10:05:16,038] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 10:05:16,038] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 10:05:45,570] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:05:45,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.4, 40.83333333333334, 1.0, 2.0, 0.2777270972087204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 301545.2743962349, 301545.2743962349, 85139.30621856218]
[2019-03-23 10:05:45,571] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:05:45,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.8005981777996853
[2019-03-23 10:06:02,469] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:06:02,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.0, 65.0, 1.0, 2.0, 0.4890536050361192, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9416132987766108, 6.95667259389456, 6.9112, 77.3283429362866, 1106497.186967151, 1091728.64156065, 249756.7571120713]
[2019-03-23 10:06:02,470] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:06:02,473] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.12398983636668115
[2019-03-23 10:06:02,474] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1106497.186967151 W.
[2019-03-23 10:06:23,330] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:06:23,330] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.37608630333333, 89.55489023000001, 1.0, 2.0, 0.2849918114461424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 309435.0489421187, 309435.0489421187, 104260.3221474545]
[2019-03-23 10:06:23,331] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:06:23,333] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.051651550207070906
[2019-03-23 10:06:27,086] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:06:27,088] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.83643375, 75.07915536, 1.0, 2.0, 0.4741615347981525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 540990.629041575, 540990.6290415747, 142117.4986275826]
[2019-03-23 10:06:27,091] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:06:27,093] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.5805958897661527
[2019-03-23 10:06:32,405] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:06:32,407] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.7, 53.0, 1.0, 2.0, 0.2843155884504955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 308700.6389483112, 308700.6389483109, 96798.36995655927]
[2019-03-23 10:06:32,407] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:06:32,409] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.2751349614965174
[2019-03-23 10:06:35,857] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:06:35,857] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.25464835666667, 63.30923954666667, 1.0, 2.0, 0.3513809055070109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 381541.0986461687, 381541.0986461683, 118967.1620984091]
[2019-03-23 10:06:35,858] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:06:35,862] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.07988342494074141
[2019-03-23 10:06:40,230] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47990757]
[2019-03-23 10:06:40,231] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.58333333333334, 65.33333333333334, 1.0, 2.0, 0.2761099061628302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299806.5768788178, 299806.576878818, 90091.18151834181]
[2019-03-23 10:06:40,233] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:06:40,236] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.2982207e-13 1.0000000e+00 8.2717312e-20 4.1226263e-19 1.5278235e-21], sampled 0.9056621352709194
[2019-03-23 10:06:56,280] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:06:56,619] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:06:56,763] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:06:56,882] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:06:57,039] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:06:58,053] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1625000, evaluation results [1625000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:07:01,279] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8768844e-14 1.0000000e+00 2.4271012e-19 3.1110909e-19 5.1558954e-22], sum to 1.0000
[2019-03-23 10:07:01,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6614
[2019-03-23 10:07:01,295] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1085436.555926969 W.
[2019-03-23 10:07:01,299] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.2, 80.5, 1.0, 2.0, 0.4755324439962649, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9332248726112671, 6.951409475257147, 6.9112, 77.32833442188904, 1085436.555926969, 1072377.362578593, 245344.1629857824], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5412600.0000, 
sim time next is 5413200.0000, 
raw observation next is [21.46666666666667, 83.66666666666667, 1.0, 2.0, 0.3042888729524705, 1.0, 1.0, 0.3042888729524705, 1.0, 2.0, 0.6137267385495351, 6.911199999999999, 6.9112, 77.3421103, 1042185.503487687, 1042185.503487688, 254566.2095655199], 
processed observation next is [1.0, 0.6521739130434783, 0.6121212121212122, 0.8366666666666667, 1.0, 1.0, 0.13036109119058809, 1.0, 0.5, 0.13036109119058809, 1.0, 1.0, 0.44818105507076444, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.38599463092136554, 0.38599463092136593, 0.6208931940622436], 
reward next is 0.3791, 
noisyNet noise sample is [array([0.3312042], dtype=float32), 1.8583374]. 
=============================================
[2019-03-23 10:07:02,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2367219e-12 1.0000000e+00 6.3815475e-19 5.8336768e-18 1.4443858e-21], sum to 1.0000
[2019-03-23 10:07:02,748] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4619
[2019-03-23 10:07:02,751] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 81.0, 1.0, 2.0, 0.445322281903741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507307.999810956, 507307.999810956, 132949.3969643841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5364000.0000, 
sim time next is 5364600.0000, 
raw observation next is [22.1, 82.0, 1.0, 2.0, 0.692227033181693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 82.07701056898799, 788910.4419772085, 788910.4419772085, 164647.3166240455], 
processed observation next is [1.0, 0.08695652173913043, 0.640909090909091, 0.82, 1.0, 1.0, 0.6152837914771162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5396501520056017, 0.2921890525841513, 0.2921890525841513, 0.4015788210342573], 
reward next is 0.5984, 
noisyNet noise sample is [array([-0.71387154], dtype=float32), -0.03968614]. 
=============================================
[2019-03-23 10:07:11,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2397956e-12 1.0000000e+00 8.3547310e-18 6.4124406e-19 2.1510216e-20], sum to 1.0000
[2019-03-23 10:07:11,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8250
[2019-03-23 10:07:11,689] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 75.66666666666667, 1.0, 2.0, 0.4672160934704077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532955.2300469268, 532955.2300469268, 136378.6349358762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5521800.0000, 
sim time next is 5522400.0000, 
raw observation next is [23.3, 76.0, 1.0, 2.0, 0.4628867125822501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 527889.0401786108, 527889.0401786106, 135630.5000952322], 
processed observation next is [1.0, 0.9565217391304348, 0.6954545454545454, 0.76, 1.0, 1.0, 0.3286083907278126, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19551445932541142, 0.19551445932541134, 0.3308060977932492], 
reward next is 0.6692, 
noisyNet noise sample is [array([2.3959336], dtype=float32), -0.9768101]. 
=============================================
[2019-03-23 10:07:13,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8436527e-13 1.0000000e+00 4.1462183e-20 1.2470655e-18 3.6830257e-21], sum to 1.0000
[2019-03-23 10:07:13,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9744
[2019-03-23 10:07:13,288] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1164232.005356591 W.
[2019-03-23 10:07:13,292] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.01666666666667, 62.83333333333334, 1.0, 2.0, 0.5140336985486963, 1.0, 2.0, 0.5140336985486963, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1164232.005356591, 1164232.00535659, 236808.3007378532], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5572200.0000, 
sim time next is 5572800.0000, 
raw observation next is [27.2, 62.0, 1.0, 2.0, 0.6446699112257354, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9768269620750311, 6.911199999999999, 6.9112, 77.32846344354104, 1281135.753319065, 1281135.753319066, 283559.9839832917], 
processed observation next is [1.0, 0.5217391304347826, 0.8727272727272727, 0.62, 1.0, 1.0, 0.5558373890321692, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9668956601071874, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.47449472345150556, 0.47449472345150595, 0.6916097170324188], 
reward next is 0.3084, 
noisyNet noise sample is [array([-0.00464691], dtype=float32), -0.17339998]. 
=============================================
[2019-03-23 10:07:16,268] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3306011e-12 1.0000000e+00 1.0399597e-20 1.4413827e-18 1.0075983e-20], sum to 1.0000
[2019-03-23 10:07:16,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4852
[2019-03-23 10:07:16,275] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 96.83333333333334, 1.0, 2.0, 0.3953492762551838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 446547.142900709, 446547.1429007093, 125007.6727910698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5629800.0000, 
sim time next is 5630400.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.3937994763752523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 444456.6751735881, 444456.6751735878, 124673.2117895052], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.97, 1.0, 1.0, 0.24224934546906537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16461358339762522, 0.1646135833976251, 0.30408100436464686], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.6334397], dtype=float32), -0.4628436]. 
=============================================
[2019-03-23 10:07:26,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9485404e-15 1.0000000e+00 5.1811548e-21 3.0024208e-22 2.2501399e-24], sum to 1.0000
[2019-03-23 10:07:26,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3663
[2019-03-23 10:07:26,616] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 45.0, 1.0, 2.0, 0.6486634199476116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 721887.6126921391, 721887.6126921389, 147331.1261635341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5841600.0000, 
sim time next is 5842200.0000, 
raw observation next is [25.41666666666666, 45.0, 1.0, 2.0, 0.682811130539594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 760887.1853665427, 760887.1853665427, 151762.0927216847], 
processed observation next is [1.0, 0.6086956521739131, 0.7916666666666664, 0.45, 1.0, 1.0, 0.6035139131744924, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28181006865427505, 0.28181006865427505, 0.3701514456626456], 
reward next is 0.6298, 
noisyNet noise sample is [array([0.37314463], dtype=float32), -0.5358533]. 
=============================================
[2019-03-23 10:07:29,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9375717e-15 1.0000000e+00 1.7260414e-21 2.2643684e-21 2.8932752e-23], sum to 1.0000
[2019-03-23 10:07:29,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4146
[2019-03-23 10:07:29,152] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.01666666666667, 85.0, 1.0, 2.0, 0.309504271561614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 336079.4872641606, 336079.4872641606, 104164.9046069346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5886600.0000, 
sim time next is 5887200.0000, 
raw observation next is [16.83333333333334, 86.0, 1.0, 2.0, 0.2884191983643805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313176.5970591477, 313176.5970591474, 101289.8764932788], 
processed observation next is [1.0, 0.13043478260869565, 0.40151515151515177, 0.86, 1.0, 1.0, 0.11052399795547563, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11599133224412879, 0.11599133224412865, 0.24704847925189952], 
reward next is 0.7530, 
noisyNet noise sample is [array([1.7184783], dtype=float32), -1.455497]. 
=============================================
[2019-03-23 10:07:40,416] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1157485e-15 1.0000000e+00 1.0599690e-21 8.9776284e-24 2.1756246e-25], sum to 1.0000
[2019-03-23 10:07:40,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8464
[2019-03-23 10:07:40,427] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 59.66666666666667, 1.0, 2.0, 0.2828057705748392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307079.3980656464, 307079.3980656466, 99051.42963345133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6119400.0000, 
sim time next is 6120000.0000, 
raw observation next is [20.0, 61.0, 1.0, 2.0, 0.2836669297831858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308014.7679305127, 308014.7679305124, 98374.88421792857], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.61, 1.0, 1.0, 0.10458366222898224, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11407954367796767, 0.11407954367796755, 0.23993874199494775], 
reward next is 0.7601, 
noisyNet noise sample is [array([-1.172402], dtype=float32), -0.40498567]. 
=============================================
[2019-03-23 10:07:40,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.94219]
 [73.94219]
 [73.94219]
 [73.94219]
 [73.94219]], R is [[73.96284485]
 [73.98162842]
 [73.99806976]
 [74.01222229]
 [74.02412415]].
[2019-03-23 10:07:46,662] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 10:07:46,664] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:07:46,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:46,664] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:07:46,666] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:07:46,666] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:46,666] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:46,668] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:07:46,669] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:46,669] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:07:46,669] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:07:46,689] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 10:07:46,713] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 10:07:46,739] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 10:07:46,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 10:07:46,793] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 10:08:15,908] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:08:15,911] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.33333333333334, 53.0, 1.0, 2.0, 0.4146812352394942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 471311.8928651516, 471311.8928651516, 128769.803819108]
[2019-03-23 10:08:15,912] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:08:15,914] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.5245096604711911
[2019-03-23 10:08:22,188] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:08:22,192] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.2, 59.0, 1.0, 2.0, 0.55453649519965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 630674.1426088482, 630674.1426088482, 154542.6603669338]
[2019-03-23 10:08:22,192] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:08:22,195] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.023355226326905787
[2019-03-23 10:08:47,326] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:08:47,328] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.43333333333334, 76.66666666666667, 1.0, 2.0, 0.5167713426499136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 589219.0040760223, 589219.004076022, 148484.3089270605]
[2019-03-23 10:08:47,329] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:08:47,333] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.6554863601642628
[2019-03-23 10:08:50,057] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:08:50,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.439195305, 41.74888254833333, 1.0, 2.0, 0.3352975040598855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 364245.3645828099, 364245.3645828103, 117990.8205971816]
[2019-03-23 10:08:50,062] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:08:50,063] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.5533360471841973
[2019-03-23 10:09:06,989] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:09:06,990] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.4357593, 91.57794709666668, 1.0, 2.0, 0.2326935089645494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 252639.2804108562, 252639.2804108558, 83902.78634478839]
[2019-03-23 10:09:06,990] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:09:06,995] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.0417437069645239
[2019-03-23 10:09:11,763] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:09:11,765] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [11.51051994666667, 95.12243282, 1.0, 2.0, 0.4314050027778285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 468467.8024170756, 468467.8024170753, 96211.70216327382]
[2019-03-23 10:09:11,766] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:09:11,770] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.5317050738703111
[2019-03-23 10:09:17,100] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.59811133]
[2019-03-23 10:09:17,101] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [31.02896688333333, 64.89440158333333, 1.0, 2.0, 0.6899539551608922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 775283.7053294263, 775283.705329426, 176393.482885042]
[2019-03-23 10:09:17,102] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:09:17,104] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1205494e-14 1.0000000e+00 3.3353934e-21 1.7232067e-20 4.3405875e-23], sampled 0.6024098719834384
[2019-03-23 10:09:27,285] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:09:27,294] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:09:27,411] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:09:27,471] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:09:27,498] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:09:28,512] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1650000, evaluation results [1650000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:09:30,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.224806e-14 1.000000e+00 1.630527e-22 7.998141e-21 9.219883e-24], sum to 1.0000
[2019-03-23 10:09:30,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9065
[2019-03-23 10:09:30,281] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 70.5, 1.0, 2.0, 0.6037318026957819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 678433.6541686939, 678433.6541686939, 159413.323836291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6273000.0000, 
sim time next is 6273600.0000, 
raw observation next is [28.3, 66.66666666666666, 1.0, 2.0, 0.5993612205055978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 673979.7288907168, 673979.7288907168, 158711.2281893927], 
processed observation next is [0.0, 0.6086956521739131, 0.9227272727272727, 0.6666666666666665, 1.0, 1.0, 0.4992015256319972, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24962212181137658, 0.24962212181137658, 0.38710055655949444], 
reward next is 0.6129, 
noisyNet noise sample is [array([0.19544931], dtype=float32), -0.9197827]. 
=============================================
[2019-03-23 10:09:30,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1921473e-15 1.0000000e+00 4.0201838e-21 5.7802602e-21 3.2177713e-24], sum to 1.0000
[2019-03-23 10:09:30,364] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9132
[2019-03-23 10:09:30,368] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333334, 74.66666666666667, 1.0, 2.0, 0.360077355531465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402158.8674286057, 402158.8674286057, 119589.8247718623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6205800.0000, 
sim time next is 6206400.0000, 
raw observation next is [20.5, 76.0, 1.0, 2.0, 0.3593397431368855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 401346.7406805633, 401346.740680563, 119534.9328234247], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.76, 1.0, 1.0, 0.19917467892110685, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14864694099280124, 0.1486469409928011, 0.29154861664249926], 
reward next is 0.7085, 
noisyNet noise sample is [array([-0.48906055], dtype=float32), 1.986852]. 
=============================================
[2019-03-23 10:09:34,482] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0449627e-12 1.0000000e+00 4.2881658e-17 5.2258866e-17 1.0433702e-18], sum to 1.0000
[2019-03-23 10:09:34,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-23 10:09:34,496] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.28333333333333, 86.66666666666666, 1.0, 2.0, 0.4707285194892691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 537127.3138136041, 537127.3138136038, 137419.2910024867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6324600.0000, 
sim time next is 6325200.0000, 
raw observation next is [22.2, 87.0, 1.0, 2.0, 0.4687788106655684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 534891.4354269903, 534891.4354269903, 137121.2989457202], 
processed observation next is [0.0, 0.21739130434782608, 0.6454545454545454, 0.87, 1.0, 1.0, 0.3359735133319605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19810793904703344, 0.19810793904703344, 0.33444219255053703], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.8676679], dtype=float32), -0.96361494]. 
=============================================
[2019-03-23 10:09:34,752] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4345421e-11 1.0000000e+00 2.4023881e-18 4.6047594e-18 2.8574783e-20], sum to 1.0000
[2019-03-23 10:09:34,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-23 10:09:34,766] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 65.0, 1.0, 2.0, 0.5568757027888104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 631148.3911133218, 631148.3911133218, 151595.2739476465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6359400.0000, 
sim time next is 6360000.0000, 
raw observation next is [27.7, 65.0, 1.0, 2.0, 0.5576137208325436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 631984.5756895146, 631984.575689515, 151691.5546650293], 
processed observation next is [0.0, 0.6086956521739131, 0.8954545454545454, 0.65, 1.0, 1.0, 0.4470171510406794, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2340683613664869, 0.23406836136648704, 0.3699794016220227], 
reward next is 0.6300, 
noisyNet noise sample is [array([0.01427991], dtype=float32), -0.93880993]. 
=============================================
[2019-03-23 10:09:34,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.98005]
 [66.98005]
 [66.98005]
 [66.98005]
 [66.98005]], R is [[66.9402771 ]
 [66.90113068]
 [66.86253357]
 [66.8243866 ]
 [66.78674316]].
[2019-03-23 10:09:36,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1280208e-12 1.0000000e+00 1.8177802e-19 4.4550085e-17 1.4905604e-20], sum to 1.0000
[2019-03-23 10:09:36,582] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3485
[2019-03-23 10:09:36,592] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 61.66666666666666, 1.0, 2.0, 0.5535354244819652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627841.0493793384, 627841.0493793384, 150975.4763646408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6364200.0000, 
sim time next is 6364800.0000, 
raw observation next is [28.3, 61.0, 1.0, 2.0, 0.5522878624225768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626536.1941695438, 626536.1941695438, 150769.1194935606], 
processed observation next is [0.0, 0.6956521739130435, 0.9227272727272727, 0.61, 1.0, 1.0, 0.44035982802822093, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23205044228501623, 0.23205044228501623, 0.36772955974039173], 
reward next is 0.6323, 
noisyNet noise sample is [array([0.5301341], dtype=float32), 2.348759]. 
=============================================
[2019-03-23 10:09:40,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5656276e-12 1.0000000e+00 2.1059689e-19 1.5225379e-17 8.1540549e-21], sum to 1.0000
[2019-03-23 10:09:40,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0541
[2019-03-23 10:09:40,138] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 88.5, 1.0, 2.0, 0.6513345234242524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723612.7389809107, 723612.7389809107, 147164.0318502174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6449400.0000, 
sim time next is 6450000.0000, 
raw observation next is [18.3, 88.0, 1.0, 2.0, 0.633671058454794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 703317.2261290294, 703317.2261290294, 144886.9719380347], 
processed observation next is [1.0, 0.6521739130434783, 0.4681818181818182, 0.88, 1.0, 1.0, 0.5420888230684925, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26048786152927017, 0.26048786152927017, 0.35338285838545047], 
reward next is 0.6466, 
noisyNet noise sample is [array([-1.4827758], dtype=float32), -1.4621512]. 
=============================================
[2019-03-23 10:09:40,153] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.95449]
 [62.95449]
 [62.95449]
 [62.95449]
 [62.95449]], R is [[62.97156525]
 [62.98291397]
 [62.99504089]
 [62.99753952]
 [63.00165176]].
[2019-03-23 10:09:43,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.07121485e-13 1.00000000e+00 1.22947368e-20 1.97546369e-19
 1.93895233e-22], sum to 1.0000
[2019-03-23 10:09:43,249] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6884
[2019-03-23 10:09:43,253] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 51.0, 1.0, 2.0, 0.5031980574195593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546522.7729052689, 546522.7729052689, 108779.9041867607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6529200.0000, 
sim time next is 6529800.0000, 
raw observation next is [19.58333333333334, 51.5, 1.0, 2.0, 0.4998045797563767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 542835.0631269406, 542835.063126941, 108025.9541482745], 
processed observation next is [1.0, 0.5652173913043478, 0.5265151515151518, 0.515, 1.0, 1.0, 0.37475572469547086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20105002338034839, 0.2010500233803485, 0.263477936947011], 
reward next is 0.7365, 
noisyNet noise sample is [array([1.9936455], dtype=float32), 0.24950016]. 
=============================================
[2019-03-23 10:09:43,618] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4818008e-13 1.0000000e+00 7.4070140e-20 1.9907969e-20 4.0679585e-22], sum to 1.0000
[2019-03-23 10:09:43,626] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5479
[2019-03-23 10:09:43,630] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 60.33333333333334, 1.0, 2.0, 0.4411856588475871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 479137.9928322767, 479137.9928322767, 102431.9347355129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6514800.0000, 
sim time next is 6515400.0000, 
raw observation next is [18.61666666666667, 58.66666666666666, 1.0, 2.0, 0.4480957039537811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486646.2203065782, 486646.2203065782, 102926.6476983468], 
processed observation next is [1.0, 0.391304347826087, 0.48257575757575777, 0.5866666666666666, 1.0, 1.0, 0.31011962994222636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18023934085428822, 0.18023934085428822, 0.2510406041423093], 
reward next is 0.7490, 
noisyNet noise sample is [array([0.9607262], dtype=float32), 0.27319217]. 
=============================================
[2019-03-23 10:09:56,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3580419e-12 1.0000000e+00 7.8977943e-19 2.7080417e-18 2.7199033e-20], sum to 1.0000
[2019-03-23 10:09:56,102] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6560
[2019-03-23 10:09:56,107] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3769464593178719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420845.771529017, 420845.771529017, 120915.4849089316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6715200.0000, 
sim time next is 6715800.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3674616894323653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 410079.6129196725, 410079.6129196727, 120051.6280395749], 
processed observation next is [1.0, 0.7391304347826086, 0.4681818181818182, 0.93, 1.0, 1.0, 0.2093271117904566, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1518813381183972, 0.1518813381183973, 0.292808848877012], 
reward next is 0.7072, 
noisyNet noise sample is [array([-0.44194478], dtype=float32), -0.07321901]. 
=============================================
[2019-03-23 10:09:56,663] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.67883139e-15 1.00000000e+00 4.44920822e-21 7.85176478e-21
 1.02117546e-22], sum to 1.0000
[2019-03-23 10:09:56,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9283
[2019-03-23 10:09:56,676] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.9, 89.0, 1.0, 2.0, 0.3649569783977639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407929.1291870957, 407929.1291870957, 120132.2619205124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7069800.0000, 
sim time next is 7070400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3655309196119287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408668.0784307547, 408668.0784307547, 120223.4895621449], 
processed observation next is [1.0, 0.8695652173913043, 0.49090909090909096, 0.9, 1.0, 1.0, 0.20691364951491084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1513585475669462, 0.1513585475669462, 0.29322802332230463], 
reward next is 0.7068, 
noisyNet noise sample is [array([1.5203283], dtype=float32), -0.023479423]. 
=============================================
[2019-03-23 10:09:58,611] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8084095e-14 1.0000000e+00 1.8949698e-21 2.6109504e-20 1.1518585e-22], sum to 1.0000
[2019-03-23 10:09:58,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1000
[2019-03-23 10:09:58,629] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 52.5, 1.0, 2.0, 0.4479853880415834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 510862.5271409272, 510862.5271409272, 133999.6407050921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6874200.0000, 
sim time next is 6874800.0000, 
raw observation next is [27.73333333333333, 51.33333333333333, 1.0, 2.0, 0.4483185407266065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 511277.345659726, 511277.3456597257, 134103.2364093869], 
processed observation next is [0.0, 0.5652173913043478, 0.8969696969696969, 0.5133333333333333, 1.0, 1.0, 0.3103981759082581, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1893619798739726, 0.1893619798739725, 0.32708106441313883], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.02708934], dtype=float32), -1.4949037]. 
=============================================
[2019-03-23 10:10:02,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2734255e-14 1.0000000e+00 2.1310767e-20 9.3405467e-20 1.0304766e-23], sum to 1.0000
[2019-03-23 10:10:02,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-23 10:10:02,716] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 66.0, 1.0, 2.0, 0.4452226365088366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 507766.5232200219, 507766.5232200222, 133822.9674963538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6865200.0000, 
sim time next is 6865800.0000, 
raw observation next is [25.36666666666667, 64.66666666666667, 1.0, 2.0, 0.45073430593452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514169.9100243775, 514169.9100243775, 134677.9181268527], 
processed observation next is [0.0, 0.4782608695652174, 0.7893939393939395, 0.6466666666666667, 1.0, 1.0, 0.31341788241815, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19043330000902872, 0.19043330000902872, 0.3284827271386651], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.95911276], dtype=float32), -1.2414103]. 
=============================================
[2019-03-23 10:10:07,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5828555e-11 1.0000000e+00 7.9071733e-18 9.6706802e-18 2.4035499e-20], sum to 1.0000
[2019-03-23 10:10:07,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8766
[2019-03-23 10:10:07,930] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 74.33333333333334, 1.0, 2.0, 0.4861163824782919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 554678.9025927024, 554678.9025927024, 139683.5503472533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6988200.0000, 
sim time next is 6988800.0000, 
raw observation next is [24.2, 74.66666666666667, 1.0, 2.0, 0.4856855113032804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 554200.5919897574, 554200.5919897571, 139538.7173588671], 
processed observation next is [0.0, 0.9130434782608695, 0.7363636363636363, 0.7466666666666667, 1.0, 1.0, 0.3571068891291005, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20525947851472495, 0.20525947851472487, 0.3403383350216271], 
reward next is 0.6597, 
noisyNet noise sample is [array([1.030623], dtype=float32), 0.09143828]. 
=============================================
[2019-03-23 10:10:09,672] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4594698e-13 1.0000000e+00 1.8395023e-19 2.8222517e-18 2.2035851e-21], sum to 1.0000
[2019-03-23 10:10:09,679] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8500
[2019-03-23 10:10:09,687] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1130042.687019625 W.
[2019-03-23 10:10:09,692] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 42.0, 1.0, 2.0, 0.4991287156122696, 1.0, 2.0, 0.4991287156122696, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353445, 1130042.687019625, 1130042.687019625, 214735.9260666384], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7315200.0000, 
sim time next is 7315800.0000, 
raw observation next is [26.0, 42.83333333333334, 1.0, 2.0, 0.4308596543423356, 0.0, 1.0, 0.0, 1.0, 1.0, 0.843092606869152, 6.9112, 6.9112, 77.328463443541, 969183.2812170929, 969183.2812170929, 217647.7458093526], 
processed observation next is [1.0, 0.6956521739130435, 0.8181818181818182, 0.42833333333333345, 1.0, 1.0, 0.28857456792791947, 0.0, 0.5, -0.25, 1.0, 0.5, 0.7758465812416457, 0.0, 0.0, 0.5084288129206538, 0.3589567708211455, 0.3589567708211455, 0.5308481605106161], 
reward next is 0.4692, 
noisyNet noise sample is [array([0.18321863], dtype=float32), 0.5707761]. 
=============================================
[2019-03-23 10:10:10,891] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9734859e-16 1.0000000e+00 2.5288801e-22 5.1753495e-20 5.8389604e-23], sum to 1.0000
[2019-03-23 10:10:10,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9198
[2019-03-23 10:10:10,903] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.3886134154227718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 438590.3068977339, 438590.3068977341, 124201.0835659917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7023600.0000, 
sim time next is 7024200.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.4406045168993365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497264.66568565, 497264.66568565, 129018.0362238066], 
processed observation next is [1.0, 0.30434782608695654, 0.49090909090909096, 0.97, 1.0, 1.0, 0.3007556461241706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1841720984020926, 0.1841720984020926, 0.3146781371312356], 
reward next is 0.6853, 
noisyNet noise sample is [array([-0.10062832], dtype=float32), 1.5450131]. 
=============================================
[2019-03-23 10:10:14,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2185515e-14 1.0000000e+00 1.7715839e-20 1.2281812e-18 1.3115155e-22], sum to 1.0000
[2019-03-23 10:10:14,832] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8658
[2019-03-23 10:10:14,838] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 86.5, 1.0, 2.0, 0.7597904660104551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862598.1601160733, 862598.1601160733, 169536.8861697364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7042200.0000, 
sim time next is 7042800.0000, 
raw observation next is [20.7, 86.0, 1.0, 2.0, 0.6121130283769876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 694799.1237861754, 694799.1237861757, 149834.3640402386], 
processed observation next is [1.0, 0.5217391304347826, 0.5772727272727273, 0.86, 1.0, 1.0, 0.5151412854712344, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.25733300880969456, 0.25733300880969473, 0.3654496683908259], 
reward next is 0.6346, 
noisyNet noise sample is [array([0.01133038], dtype=float32), -0.6315745]. 
=============================================
[2019-03-23 10:10:16,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2352068e-12 1.0000000e+00 7.3460406e-19 7.1146782e-19 5.9187994e-22], sum to 1.0000
[2019-03-23 10:10:16,785] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3504
[2019-03-23 10:10:16,788] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 50.0, 1.0, 2.0, 0.8007075046273474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 890670.7197746023, 890670.7197746023, 166257.2510855097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7144200.0000, 
sim time next is 7144800.0000, 
raw observation next is [24.0, 50.66666666666666, 1.0, 2.0, 0.7704474589577663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 857126.847450871, 857126.8474508714, 162282.0627748889], 
processed observation next is [1.0, 0.6956521739130435, 0.7272727272727273, 0.5066666666666666, 1.0, 1.0, 0.7130593236972079, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31745438794476705, 0.31745438794476716, 0.3958099092070461], 
reward next is 0.6042, 
noisyNet noise sample is [array([0.9292808], dtype=float32), -0.8790715]. 
=============================================
[2019-03-23 10:10:17,050] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 10:10:17,052] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:10:17,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:10:17,053] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:10:17,053] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:10:17,053] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:10:17,054] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:10:17,054] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:10:17,055] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:10:17,056] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:10:17,057] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:10:17,081] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 10:10:17,105] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 10:10:17,107] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 10:10:17,107] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 10:10:17,129] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 10:10:25,431] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:10:25,432] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [12.24027149583333, 95.07783477833334, 1.0, 2.0, 0.2799578819128859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 52.76698777717183, 304030.3400743477, 304030.3400743474, 67002.36626042367]
[2019-03-23 10:10:25,436] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:10:25,440] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.6048438789857866
[2019-03-23 10:10:58,979] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:10:58,981] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.4, 84.5, 1.0, 2.0, 0.4615931229244048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 521139.1712939691, 521139.1712939691, 135502.5573188882]
[2019-03-23 10:10:58,984] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:10:58,988] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.8868218006798695
[2019-03-23 10:11:11,577] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:11,579] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.83333333333334, 74.16666666666667, 1.0, 2.0, 0.3668745406439474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 410278.4409776109, 410278.4409776105, 124704.5828955915]
[2019-03-23 10:11:11,580] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:11:11,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.8105578727163208
[2019-03-23 10:11:39,724] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:39,725] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 61.0, 1.0, 2.0, 0.277674401590965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 301488.0451947336, 301488.0451947332, 100985.6979061278]
[2019-03-23 10:11:39,726] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:11:39,729] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.825271941026281
[2019-03-23 10:11:42,062] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:42,065] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.76666666666667, 52.33333333333334, 1.0, 2.0, 0.3930829261151755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 426874.3603314558, 426874.3603314561, 98230.19277359218]
[2019-03-23 10:11:42,067] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:11:42,070] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.19445212232653908
[2019-03-23 10:11:45,011] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:45,012] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.41666666666666, 60.33333333333333, 1.0, 2.0, 0.9322993138970398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344353972, 1063035.14905557, 1063035.149055569, 200626.8596058025]
[2019-03-23 10:11:45,013] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:11:45,016] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.31577853286729773
[2019-03-23 10:11:46,001] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:46,002] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.21666666666667, 44.0, 1.0, 2.0, 0.3825601774975327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 431813.6556331135, 431813.6556331135, 128022.1953794841]
[2019-03-23 10:11:46,003] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:11:46,005] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.9124408486992652
[2019-03-23 10:11:48,226] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:48,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.95, 62.0, 1.0, 2.0, 0.6166667066087634, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9228343863231324, 6.9908239242051, 6.9112, 95.55308731151182, 1246447.887052639, 1214492.977569688, 277398.5609973817]
[2019-03-23 10:11:48,228] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:11:48,232] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.2292265366974804
[2019-03-23 10:11:48,233] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1246447.887052639 W.
[2019-03-23 10:11:50,710] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.58538485]
[2019-03-23 10:11:50,711] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.7, 43.66666666666667, 1.0, 2.0, 0.8720405901232605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 973791.0988438042, 973791.0988438039, 177746.1655563815]
[2019-03-23 10:11:50,712] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:11:50,714] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.3890096e-14 1.0000000e+00 7.5389952e-21 3.9704857e-20 1.0969790e-22], sampled 0.1564417646746774
[2019-03-23 10:11:56,722] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:11:57,138] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:11:57,355] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:11:57,504] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:11:57,575] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:11:58,592] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1675000, evaluation results [1675000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:12:01,884] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7451712e-15 1.0000000e+00 5.0069470e-19 5.9334092e-20 3.3343977e-23], sum to 1.0000
[2019-03-23 10:12:01,888] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6876
[2019-03-23 10:12:01,892] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.7, 78.66666666666667, 1.0, 2.0, 0.2104656825032567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 228511.8029894684, 228511.8029894686, 73403.43609399935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7176000.0000, 
sim time next is 7176600.0000, 
raw observation next is [14.55, 79.5, 1.0, 2.0, 0.2078311692619951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 225650.733158007, 225650.7331580067, 73006.7461545412], 
processed observation next is [1.0, 0.043478260869565216, 0.2977272727272728, 0.795, 1.0, 1.0, 0.009788961577493864, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08357434561407667, 0.08357434561407656, 0.1780652345232712], 
reward next is 0.8219, 
noisyNet noise sample is [array([-0.33914047], dtype=float32), -0.7497318]. 
=============================================
[2019-03-23 10:12:05,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8557069e-14 1.0000000e+00 1.0579048e-21 1.4567697e-21 2.1583089e-23], sum to 1.0000
[2019-03-23 10:12:05,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6122
[2019-03-23 10:12:05,851] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.25, 63.0, 1.0, 2.0, 0.369010245791535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400721.4955984231, 400721.4955984228, 95264.66234054175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7288200.0000, 
sim time next is 7288800.0000, 
raw observation next is [18.43333333333333, 63.0, 1.0, 2.0, 0.3972490620024415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 431400.6459147704, 431400.6459147704, 99565.21922969661], 
processed observation next is [1.0, 0.34782608695652173, 0.4742424242424241, 0.63, 1.0, 1.0, 0.24656132750305182, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1597780170054705, 0.1597780170054705, 0.24284199812121124], 
reward next is 0.7572, 
noisyNet noise sample is [array([-0.66606075], dtype=float32), 0.6948319]. 
=============================================
[2019-03-23 10:12:11,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4403483e-12 1.0000000e+00 1.1499769e-19 1.5627561e-19 1.1909923e-20], sum to 1.0000
[2019-03-23 10:12:11,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3865
[2019-03-23 10:12:11,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1682862.414663251 W.
[2019-03-23 10:12:11,066] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.38333333333333, 54.66666666666667, 1.0, 2.0, 0.5086264442319298, 1.0, 2.0, 0.4975081482361999, 1.0, 1.0, 0.9832994313660962, 6.911199999999999, 6.9112, 77.3421103, 1682862.414663251, 1682862.414663251, 354686.5571914053], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7401000.0000, 
sim time next is 7401600.0000, 
raw observation next is [28.3, 55.0, 1.0, 2.0, 0.4608333807528618, 1.0, 2.0, 0.4608333807528618, 1.0, 2.0, 0.9317169109967461, 6.911199999999999, 6.9112, 77.3421103, 1558999.680592333, 1558999.680592333, 336513.7163346371], 
processed observation next is [1.0, 0.6956521739130435, 0.9227272727272727, 0.55, 1.0, 1.0, 0.3260417259410772, 1.0, 1.0, 0.3260417259410772, 1.0, 1.0, 0.9024527299953518, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5774072891082714, 0.5774072891082714, 0.8207651617917977], 
reward next is 0.1792, 
noisyNet noise sample is [array([-1.7163333], dtype=float32), 1.1968029]. 
=============================================
[2019-03-23 10:12:12,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2197708e-13 1.0000000e+00 8.2704103e-19 8.6524456e-20 1.8817863e-22], sum to 1.0000
[2019-03-23 10:12:12,185] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1554
[2019-03-23 10:12:12,194] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 76.0, 1.0, 2.0, 0.4407784907406964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502551.108638789, 502551.108638789, 133082.8849482238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7407600.0000, 
sim time next is 7408200.0000, 
raw observation next is [22.11666666666667, 80.0, 1.0, 2.0, 0.4332995677875981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493339.2177936045, 493339.2177936042, 131409.0137503952], 
processed observation next is [1.0, 0.7391304347826086, 0.6416666666666668, 0.8, 1.0, 1.0, 0.2916244597344976, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1827182288124461, 0.18271822881244598, 0.3205097896351103], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.24462198], dtype=float32), -0.2414311]. 
=============================================
[2019-03-23 10:12:14,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5316073e-14 1.0000000e+00 5.1656601e-22 2.3801647e-20 6.6531588e-23], sum to 1.0000
[2019-03-23 10:12:14,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9419
[2019-03-23 10:12:14,179] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 69.0, 1.0, 2.0, 0.4484560534151398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511369.2545364974, 511369.2545364974, 133992.3862593248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7506000.0000, 
sim time next is 7506600.0000, 
raw observation next is [24.3, 69.83333333333333, 1.0, 2.0, 0.4507461102250096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514033.7668665426, 514033.7668665426, 134332.3530508752], 
processed observation next is [0.0, 0.9130434782608695, 0.740909090909091, 0.6983333333333333, 1.0, 1.0, 0.31343263778126196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.190382876617238, 0.190382876617238, 0.3276398854899395], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.46976736], dtype=float32), 0.2504291]. 
=============================================
[2019-03-23 10:12:16,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6829984e-14 1.0000000e+00 6.7762660e-21 6.1041002e-21 8.9445088e-23], sum to 1.0000
[2019-03-23 10:12:16,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7249
[2019-03-23 10:12:16,089] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 97.66666666666666, 1.0, 2.0, 0.4515701834948514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514821.1712968913, 514821.1712968913, 134145.6738456565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [20.18333333333333, 98.83333333333334, 1.0, 2.0, 0.4498093771873603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 512743.2269326216, 512743.2269326216, 133850.8807998749], 
processed observation next is [0.0, 0.17391304347826086, 0.5537878787878786, 0.9883333333333334, 1.0, 1.0, 0.31226172148420034, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18990489886393394, 0.18990489886393394, 0.3264655629265241], 
reward next is 0.6735, 
noisyNet noise sample is [array([-0.0497109], dtype=float32), -0.416198]. 
=============================================
[2019-03-23 10:12:16,122] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7463765e-15 1.0000000e+00 6.9948019e-23 2.6775295e-21 7.8542999e-24], sum to 1.0000
[2019-03-23 10:12:16,132] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1049
[2019-03-23 10:12:16,135] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 59.0, 1.0, 2.0, 0.4230292373238199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480864.2224840181, 480864.2224840181, 129636.0155751212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7500600.0000, 
sim time next is 7501200.0000, 
raw observation next is [25.16666666666666, 60.0, 1.0, 2.0, 0.4240651687595823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482268.4989105516, 482268.4989105516, 129937.0001621484], 
processed observation next is [0.0, 0.8260869565217391, 0.78030303030303, 0.6, 1.0, 1.0, 0.28008146094947783, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17861796255946355, 0.17861796255946355, 0.31691951259060586], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.16215274], dtype=float32), 0.11957909]. 
=============================================
[2019-03-23 10:12:19,613] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2831383e-14 1.0000000e+00 5.2000838e-21 8.6109616e-19 8.1881780e-23], sum to 1.0000
[2019-03-23 10:12:19,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5757
[2019-03-23 10:12:19,623] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.43333333333333, 53.0, 1.0, 2.0, 0.4944716995893358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 564060.1758542956, 564060.1758542956, 141158.0246377012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7573200.0000, 
sim time next is 7573800.0000, 
raw observation next is [28.61666666666667, 52.0, 1.0, 2.0, 0.4932018306345178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562634.4279028171, 562634.4279028171, 140956.1569757647], 
processed observation next is [0.0, 0.6521739130434783, 0.9371212121212124, 0.52, 1.0, 1.0, 0.3665022882931472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20838312144548782, 0.20838312144548782, 0.3437955048189383], 
reward next is 0.6562, 
noisyNet noise sample is [array([-0.47751144], dtype=float32), -0.098035745]. 
=============================================
[2019-03-23 10:12:21,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7073138e-12 1.0000000e+00 1.1289653e-19 1.3663562e-18 1.0631404e-20], sum to 1.0000
[2019-03-23 10:12:21,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-23 10:12:21,062] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 95.5, 1.0, 2.0, 0.4347207577195493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 494317.936026263, 494317.9360262627, 130931.2372638307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7595400.0000, 
sim time next is 7596000.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4365173406285046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 496513.2129724653, 496513.2129724656, 131247.8562464824], 
processed observation next is [0.0, 0.9565217391304348, 0.5454545454545454, 0.96, 1.0, 1.0, 0.29564667578563075, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18389378258239455, 0.18389378258239467, 0.3201167225523961], 
reward next is 0.6799, 
noisyNet noise sample is [array([1.4558923], dtype=float32), 0.33776942]. 
=============================================
[2019-03-23 10:12:21,087] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.68022]
 [68.68022]
 [68.68022]
 [68.68022]
 [68.68022]], R is [[68.67330933]
 [68.66723633]
 [68.66201782]
 [68.65795898]
 [68.65514374]].
[2019-03-23 10:12:24,728] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:24,730] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:24,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 10:12:28,875] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.06070954e-13 1.00000000e+00 7.88517674e-20 4.15402742e-18
 8.81155844e-21], sum to 1.0000
[2019-03-23 10:12:28,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6156
[2019-03-23 10:12:28,887] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 92.33333333333334, 1.0, 2.0, 0.4810618399168459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548932.3673823808, 548932.3673823808, 138663.2117749951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7680000.0000, 
sim time next is 7680600.0000, 
raw observation next is [21.6, 92.0, 1.0, 2.0, 0.4790239470140739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 546598.877480183, 546598.8774801828, 138346.1224338837], 
processed observation next is [1.0, 0.9130434782608695, 0.6181818181818183, 0.92, 1.0, 1.0, 0.34877993376759236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20244402869636408, 0.202444028696364, 0.33742956691191145], 
reward next is 0.6626, 
noisyNet noise sample is [array([-0.8849181], dtype=float32), -1.0309478]. 
=============================================
[2019-03-23 10:12:29,627] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4882530e-15 1.0000000e+00 4.0395188e-23 9.3079969e-21 2.7869623e-22], sum to 1.0000
[2019-03-23 10:12:29,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0465
[2019-03-23 10:12:29,640] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.03333333333333, 85.0, 1.0, 2.0, 0.2120414031151464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 230223.0367097669, 230223.0367097666, 73722.67349463065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7791600.0000, 
sim time next is 7792200.0000, 
raw observation next is [13.85, 87.0, 1.0, 2.0, 0.2044377948394141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 221965.5682086248, 221965.5682086245, 72969.25750119155], 
processed observation next is [1.0, 0.17391304347826086, 0.2659090909090909, 0.87, 1.0, 1.0, 0.005547243549267611, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08220946970689808, 0.08220946970689796, 0.177973798783394], 
reward next is 0.8220, 
noisyNet noise sample is [array([1.3224258], dtype=float32), 0.48544803]. 
=============================================
[2019-03-23 10:12:30,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8586207e-14 1.0000000e+00 5.1287465e-22 3.5235377e-20 1.4257934e-23], sum to 1.0000
[2019-03-23 10:12:30,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8450
[2019-03-23 10:12:30,148] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 63.0, 1.0, 2.0, 0.2487411268572745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270080.6663177864, 270080.6663177864, 80483.633033743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7768800.0000, 
sim time next is 7769400.0000, 
raw observation next is [17.51666666666667, 64.16666666666667, 1.0, 2.0, 0.247986710201251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 269261.3013918719, 269261.3013918716, 80312.72204348199], 
processed observation next is [1.0, 0.9565217391304348, 0.43257575757575767, 0.6416666666666667, 1.0, 1.0, 0.05998338775156372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09972640792291551, 0.0997264079229154, 0.1958846879109317], 
reward next is 0.8041, 
noisyNet noise sample is [array([-0.21560305], dtype=float32), 0.17440167]. 
=============================================
[2019-03-23 10:12:32,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.0243661e-15 1.0000000e+00 1.3985589e-21 1.9114221e-20 2.1708174e-24], sum to 1.0000
[2019-03-23 10:12:32,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4802
[2019-03-23 10:12:32,950] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 45.33333333333334, 1.0, 2.0, 0.6271621381716037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686461.1098702074, 686461.1098702074, 140838.9315818353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7827600.0000, 
sim time next is 7828200.0000, 
raw observation next is [24.1, 45.5, 1.0, 2.0, 0.6192376165336796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 678887.269035562, 678887.2690355617, 140350.7291952471], 
processed observation next is [1.0, 0.6086956521739131, 0.7318181818181819, 0.455, 1.0, 1.0, 0.5240470206670994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2514397292724304, 0.25143972927243025, 0.3423188516957247], 
reward next is 0.6577, 
noisyNet noise sample is [array([0.75379574], dtype=float32), 0.56176]. 
=============================================
[2019-03-23 10:12:35,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4768017e-15 1.0000000e+00 8.6799375e-23 2.1662449e-22 8.5661814e-25], sum to 1.0000
[2019-03-23 10:12:35,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0993
[2019-03-23 10:12:35,630] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 68.66666666666666, 1.0, 2.0, 0.295921252913477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 321325.3060360212, 321325.3060360212, 104638.0441136177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7861200.0000, 
sim time next is 7861800.0000, 
raw observation next is [19.3, 66.83333333333334, 1.0, 2.0, 0.2915713888902913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 316600.480248487, 316600.480248487, 101594.203996909], 
processed observation next is [1.0, 1.0, 0.5136363636363637, 0.6683333333333334, 1.0, 1.0, 0.11446423611286415, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11725943712906925, 0.11725943712906925, 0.2477907414558756], 
reward next is 0.7522, 
noisyNet noise sample is [array([-0.02492583], dtype=float32), -0.5394611]. 
=============================================
[2019-03-23 10:12:36,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:36,739] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:36,808] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 10:12:38,355] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:38,357] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:38,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 10:12:38,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:38,857] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:38,893] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 10:12:39,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:39,064] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:39,111] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 10:12:39,552] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:39,553] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:39,564] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 10:12:39,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:39,847] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:39,856] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 10:12:39,884] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:39,886] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:39,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 10:12:40,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7943464e-17 1.0000000e+00 1.2821847e-23 2.4334746e-23 2.0810711e-24], sum to 1.0000
[2019-03-23 10:12:40,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3525
[2019-03-23 10:12:40,089] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.06666666666667, 94.66666666666666, 1.0, 2.0, 0.6888825522454957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 778331.5001018338, 778331.5001018338, 157406.8539695405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 31200.0000, 
sim time next is 31800.0000, 
raw observation next is [19.33333333333334, 93.33333333333334, 1.0, 2.0, 0.7199120453715333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 814381.1807792928, 814381.1807792928, 162054.3706551171], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515155, 0.9333333333333335, 1.0, 1.0, 0.6498900567144167, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.30162265954788625, 0.30162265954788625, 0.3952545625734563], 
reward next is 0.6047, 
noisyNet noise sample is [array([1.5516115], dtype=float32), 0.30469924]. 
=============================================
[2019-03-23 10:12:40,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,100] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,113] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 10:12:40,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,253] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,267] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 10:12:40,379] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,391] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 10:12:40,418] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,419] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,421] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,422] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,441] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 10:12:40,473] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 10:12:40,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,649] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,653] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 10:12:40,820] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:40,821] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:40,824] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 10:12:40,999] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0444182e-13 1.0000000e+00 2.4518360e-19 3.8096495e-20 9.2715971e-22], sum to 1.0000
[2019-03-23 10:12:40,999] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6168
[2019-03-23 10:12:41,009] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 100.0, 1.0, 2.0, 0.3462935757240004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 384036.6511989605, 384036.6511989605, 117314.6115286756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 22200.0000, 
sim time next is 22800.0000, 
raw observation next is [17.33333333333334, 100.0, 1.0, 2.0, 0.3476839489630847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 386534.0548766736, 386534.0548766739, 117815.8059404389], 
processed observation next is [1.0, 0.2608695652173913, 0.42424242424242453, 1.0, 1.0, 1.0, 0.18460493620385585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14316076106543468, 0.1431607610654348, 0.28735562424497296], 
reward next is 0.7126, 
noisyNet noise sample is [array([1.3901093], dtype=float32), -1.412282]. 
=============================================
[2019-03-23 10:12:41,187] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:12:41,187] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:41,195] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 10:12:45,314] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.839802e-15 1.000000e+00 8.516733e-22 5.645542e-21 7.967072e-23], sum to 1.0000
[2019-03-23 10:12:45,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-23 10:12:45,329] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 82.0, 1.0, 2.0, 0.2242059170299454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243433.9102365124, 243433.9102365127, 74078.16788183725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 96000.0000, 
sim time next is 96600.0000, 
raw observation next is [14.0, 82.0, 1.0, 2.0, 0.220970551010619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239920.2114835629, 239920.2114835626, 73716.16968616439], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.82, 1.0, 1.0, 0.026213188763273727, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08885933758650477, 0.08885933758650466, 0.17979553581991314], 
reward next is 0.8202, 
noisyNet noise sample is [array([-1.278617], dtype=float32), 1.0048058]. 
=============================================
[2019-03-23 10:12:47,599] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 10:12:47,601] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:12:47,602] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:47,602] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:12:47,603] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:12:47,605] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:47,604] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:12:47,603] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:47,608] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:12:47,610] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:47,612] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:12:47,632] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 10:12:47,657] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 10:12:47,658] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 10:12:47,701] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 10:12:47,701] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 10:13:05,229] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52014434]
[2019-03-23 10:13:05,231] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.89861877666667, 99.936321735, 1.0, 2.0, 0.4117359083387225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 468758.5844134707, 468758.5844134707, 133597.939113037]
[2019-03-23 10:13:05,234] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:13:05,238] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.3218475e-15 1.0000000e+00 8.2182545e-22 3.9435997e-21 8.7404715e-24], sampled 0.17480586548668098
[2019-03-23 10:13:13,722] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52014434]
[2019-03-23 10:13:13,723] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [22.394985645, 39.25914141333333, 1.0, 2.0, 0.3343062145716101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 362995.2305844637, 362995.2305844637, 96791.6273252664]
[2019-03-23 10:13:13,724] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:13:13,727] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.3218475e-15 1.0000000e+00 8.2182545e-22 3.9435997e-21 8.7404715e-24], sampled 0.351316871365818
[2019-03-23 10:13:20,533] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52014434]
[2019-03-23 10:13:20,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.00688949666667, 44.74418932, 1.0, 2.0, 0.294643816438148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 319917.6783733589, 319917.6783733585, 85311.98230926078]
[2019-03-23 10:13:20,536] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:13:20,541] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [9.3218475e-15 1.0000000e+00 8.2182545e-22 3.9435997e-21 8.7404715e-24], sampled 0.4289788291139617
[2019-03-23 10:13:34,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52014434]
[2019-03-23 10:13:34,512] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.80064010333334, 56.56186174333334, 1.0, 2.0, 0.653085132071961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 744692.4904631528, 744692.4904631528, 166254.7687994411]
[2019-03-23 10:13:34,514] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:13:34,516] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [9.3218475e-15 1.0000000e+00 8.2182545e-22 3.9435997e-21 8.7404715e-24], sampled 0.25569891178417714
[2019-03-23 10:14:27,609] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:14:27,820] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:14:27,838] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:14:27,893] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:14:27,922] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:14:28,938] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1700000, evaluation results [1700000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:14:31,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2072971e-15 1.0000000e+00 1.6262346e-22 1.0255566e-20 5.8141055e-25], sum to 1.0000
[2019-03-23 10:14:31,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7807
[2019-03-23 10:14:31,776] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 88.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 213208.9295714411, 213208.9295714414, 70538.75774276041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 173400.0000, 
sim time next is 174000.0000, 
raw observation next is [13.33333333333333, 88.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 213865.8742959758, 213865.8742959755, 70959.16391505473], 
processed observation next is [0.0, 0.0, 0.2424242424242423, 0.88, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07920958307258363, 0.07920958307258351, 0.17307113150013348], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5300598], dtype=float32), 0.8982761]. 
=============================================
[2019-03-23 10:14:31,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[79.70312]
 [79.70312]
 [79.70312]
 [79.70312]
 [79.70312]], R is [[78.90608978]
 [78.11702728]
 [77.33586121]
 [77.38784027]
 [77.43727875]].
[2019-03-23 10:14:32,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7163882e-15 1.0000000e+00 1.2366181e-21 5.8051801e-23 9.1406980e-25], sum to 1.0000
[2019-03-23 10:14:32,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3624
[2019-03-23 10:14:32,547] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214108.1917454251, 214108.1917454248, 72418.21090997373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [13.66666666666667, 90.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 212259.4433789966, 212259.4433789966, 71937.62038282063], 
processed observation next is [0.0, 0.17391304347826086, 0.25757575757575774, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07861460865888763, 0.07861460865888763, 0.17545761068980642], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1489444], dtype=float32), 0.00635221]. 
=============================================
[2019-03-23 10:14:34,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3599422e-14 1.0000000e+00 5.9302352e-22 2.0464590e-21 2.7909716e-23], sum to 1.0000
[2019-03-23 10:14:34,554] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1518
[2019-03-23 10:14:34,562] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3085720591493592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 337215.3084927169, 337215.3084927172, 112530.1562954868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 241200.0000, 
sim time next is 241800.0000, 
raw observation next is [16.83333333333334, 93.00000000000001, 1.0, 2.0, 0.3060782876077001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 333486.8564944037, 333486.856494404, 111996.661856974], 
processed observation next is [0.0, 0.8260869565217391, 0.40151515151515177, 0.9300000000000002, 1.0, 1.0, 0.13259785950962513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12351365055348285, 0.12351365055348297, 0.27316258989505854], 
reward next is 0.7268, 
noisyNet noise sample is [array([1.4352168], dtype=float32), 0.09063889]. 
=============================================
[2019-03-23 10:14:34,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0192919e-15 1.0000000e+00 1.8730561e-22 5.5037928e-21 7.7883286e-25], sum to 1.0000
[2019-03-23 10:14:34,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8319
[2019-03-23 10:14:34,697] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 66.0, 1.0, 2.0, 0.2609238993550433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 283312.4535568238, 283312.4535568238, 93042.45193283867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 221400.0000, 
sim time next is 222000.0000, 
raw observation next is [18.0, 71.33333333333333, 1.0, 2.0, 0.2565219037470286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278531.3763952542, 278531.3763952539, 89904.25207089241], 
processed observation next is [0.0, 0.5652173913043478, 0.45454545454545453, 0.7133333333333333, 1.0, 1.0, 0.07065237968378574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10315976903527935, 0.10315976903527921, 0.21927866358754247], 
reward next is 0.7807, 
noisyNet noise sample is [array([0.1172238], dtype=float32), -0.06477695]. 
=============================================
[2019-03-23 10:14:34,723] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[74.066635]
 [74.066635]
 [74.066635]
 [74.066635]
 [74.066635]], R is [[74.10668945]
 [74.13868713]
 [74.16316223]
 [74.18083191]
 [74.19539642]].
[2019-03-23 10:14:39,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8431656e-15 1.0000000e+00 7.2495413e-22 4.4147842e-22 4.1512720e-25], sum to 1.0000
[2019-03-23 10:14:39,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9749
[2019-03-23 10:14:39,735] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 209539.9304423279, 209539.9304423276, 72517.68386178861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 460200.0000, 
sim time next is 460800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 216756.6259694437, 216756.625969444, 73506.483633915], 
processed observation next is [1.0, 0.34782608695652173, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0802802318405347, 0.08028023184053482, 0.17928410642418294], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0585146], dtype=float32), -1.167416]. 
=============================================
[2019-03-23 10:14:40,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0428335e-15 1.0000000e+00 2.3668965e-23 2.5729520e-21 2.7495982e-24], sum to 1.0000
[2019-03-23 10:14:40,526] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-23 10:14:40,532] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 53.0, 1.0, 2.0, 0.3801855009992373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412862.2594255919, 412862.2594255916, 98137.64777054798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 396000.0000, 
sim time next is 396600.0000, 
raw observation next is [19.83333333333334, 53.5, 1.0, 2.0, 0.3884880302139595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 421882.298608367, 421882.2986083668, 98512.90785658394], 
processed observation next is [1.0, 0.6086956521739131, 0.5378787878787882, 0.535, 1.0, 1.0, 0.23561003776744935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15625270318828408, 0.156252703188284, 0.2402753850160584], 
reward next is 0.7597, 
noisyNet noise sample is [array([0.32253677], dtype=float32), -0.7619852]. 
=============================================
[2019-03-23 10:14:41,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.7678577e-16 1.0000000e+00 6.9545201e-23 3.2568863e-21 3.6185395e-25], sum to 1.0000
[2019-03-23 10:14:41,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1657
[2019-03-23 10:14:41,037] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 59.33333333333333, 1.0, 2.0, 0.3889939832391234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422431.9818321469, 422431.9818321469, 99112.50197603447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 402600.0000, 
sim time next is 403200.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.390628557460716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 424207.8387432214, 424207.8387432217, 99878.35408663638], 
processed observation next is [1.0, 0.6956521739130435, 0.5, 0.6, 1.0, 1.0, 0.23828569682589498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15711401434934127, 0.15711401434934139, 0.24360574167472288], 
reward next is 0.7564, 
noisyNet noise sample is [array([0.9753077], dtype=float32), -0.076991476]. 
=============================================
[2019-03-23 10:14:48,477] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6947593e-14 1.0000000e+00 9.3283906e-23 2.1615574e-21 2.3510821e-26], sum to 1.0000
[2019-03-23 10:14:48,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1871
[2019-03-23 10:14:48,488] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 94.0, 1.0, 2.0, 0.2560496582979461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 278018.4659237721, 278018.4659237718, 86799.68272656604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 504000.0000, 
sim time next is 504600.0000, 
raw observation next is [15.0, 93.00000000000001, 1.0, 2.0, 0.2533916292199213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 275131.5642392403, 275131.5642392406, 85762.61161092528], 
processed observation next is [1.0, 0.8695652173913043, 0.3181818181818182, 0.9300000000000002, 1.0, 1.0, 0.06673953652490162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10190057934786678, 0.1019005793478669, 0.20917710149006166], 
reward next is 0.7908, 
noisyNet noise sample is [array([0.9773963], dtype=float32), 0.20112607]. 
=============================================
[2019-03-23 10:14:50,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4013640e-15 1.0000000e+00 9.7903682e-22 2.4145015e-22 1.0082856e-22], sum to 1.0000
[2019-03-23 10:14:50,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0088
[2019-03-23 10:14:50,643] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 78.0, 1.0, 2.0, 0.324865953285973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356441.1669112549, 356441.1669112549, 114186.0305905474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 590400.0000, 
sim time next is 591000.0000, 
raw observation next is [18.83333333333334, 78.83333333333333, 1.0, 2.0, 0.3211556759724298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351807.8256316044, 351807.8256316041, 113713.0860498277], 
processed observation next is [1.0, 0.8695652173913043, 0.4924242424242427, 0.7883333333333333, 1.0, 1.0, 0.1514445949655372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.130299194678372, 0.1302991946783719, 0.2773489903654334], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.6310826], dtype=float32), 0.2870881]. 
=============================================
[2019-03-23 10:14:50,661] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[76.803474]
 [76.803474]
 [76.803474]
 [76.803474]
 [76.803474]], R is [[76.75809479]
 [76.71201324]
 [76.66465759]
 [76.6160202 ]
 [76.56607819]].
[2019-03-23 10:14:54,645] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2438439e-11 1.0000000e+00 5.0255300e-18 2.1741483e-17 1.8189723e-20], sum to 1.0000
[2019-03-23 10:14:54,651] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8807
[2019-03-23 10:14:54,656] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 80.5, 1.0, 2.0, 0.4803250756514038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529524.962711226, 529524.962711226, 127678.856378466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 635400.0000, 
sim time next is 636000.0000, 
raw observation next is [19.33333333333333, 79.66666666666667, 1.0, 2.0, 0.5152018024396411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 570368.7293321774, 570368.7293321774, 131807.3810147967], 
processed observation next is [1.0, 0.34782608695652173, 0.5151515151515149, 0.7966666666666667, 1.0, 1.0, 0.39400225304955133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21124767753043608, 0.21124767753043608, 0.32148141710926026], 
reward next is 0.6785, 
noisyNet noise sample is [array([-0.37006727], dtype=float32), 0.64245224]. 
=============================================
[2019-03-23 10:14:54,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.51426]
 [73.51426]
 [73.51426]
 [73.51426]
 [73.51426]], R is [[73.45763397]
 [73.41165161]
 [73.38677216]
 [73.3772583 ]
 [73.37076569]].
[2019-03-23 10:14:58,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7083848e-15 1.0000000e+00 9.8064776e-22 2.3361313e-21 2.8973066e-23], sum to 1.0000
[2019-03-23 10:14:58,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3353
[2019-03-23 10:14:58,492] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6192068542674781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 695835.938683066, 695835.938683066, 161602.1368190172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 820800.0000, 
sim time next is 821400.0000, 
raw observation next is [29.0, 64.66666666666667, 1.0, 2.0, 0.615723996910011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 691919.2786708378, 691919.2786708378, 161104.503073487], 
processed observation next is [0.0, 0.5217391304347826, 0.9545454545454546, 0.6466666666666667, 1.0, 1.0, 0.5196549961375138, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2562663995077177, 0.2562663995077177, 0.39293781237435854], 
reward next is 0.6071, 
noisyNet noise sample is [array([0.45057076], dtype=float32), -0.6656751]. 
=============================================
[2019-03-23 10:14:59,472] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.34571385e-15 1.00000000e+00 8.62952362e-23 1.03928555e-20
 2.15492771e-23], sum to 1.0000
[2019-03-23 10:14:59,479] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3733
[2019-03-23 10:14:59,483] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 93.0, 1.0, 2.0, 0.2889824077344305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 313788.3486340965, 313788.3486340962, 100282.4032121619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 712200.0000, 
sim time next is 712800.0000, 
raw observation next is [16.0, 94.0, 1.0, 2.0, 0.3029825946657501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 328995.4388532988, 328995.4388532991, 103327.2544886813], 
processed observation next is [1.0, 0.2608695652173913, 0.36363636363636365, 0.94, 1.0, 1.0, 0.12872824333218763, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12185016253825881, 0.12185016253825894, 0.2520176938748324], 
reward next is 0.7480, 
noisyNet noise sample is [array([-0.1871994], dtype=float32), 0.22298563]. 
=============================================
[2019-03-23 10:15:03,882] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5721399e-15 1.0000000e+00 3.1500890e-22 2.2872276e-20 6.9964792e-24], sum to 1.0000
[2019-03-23 10:15:03,890] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9992
[2019-03-23 10:15:03,893] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4093612263780536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 463632.0289567424, 463632.0289567421, 127056.0249923679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783600.0000, 
sim time next is 784200.0000, 
raw observation next is [20.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4050755239930654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 458341.4387878088, 458341.4387878088, 126377.3123157696], 
processed observation next is [0.0, 0.043478260869565216, 0.5606060606060609, 0.8633333333333334, 1.0, 1.0, 0.2563444049913317, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1697560884399292, 0.1697560884399292, 0.30823734711163314], 
reward next is 0.6918, 
noisyNet noise sample is [array([-0.4926191], dtype=float32), -0.6877872]. 
=============================================
[2019-03-23 10:15:06,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3635522e-14 1.0000000e+00 1.3007751e-19 7.0835043e-20 2.4520018e-21], sum to 1.0000
[2019-03-23 10:15:06,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1649
[2019-03-23 10:15:06,855] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4375236906570158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 497789.0445275598, 497789.0445275598, 131471.3767264673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930600.0000, 
sim time next is 931200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4357469089393176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495765.5165771325, 495765.5165771325, 131291.0864896584], 
processed observation next is [0.0, 0.782608695652174, 0.5909090909090909, 0.88, 1.0, 1.0, 0.294683636174147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18361685799153055, 0.18361685799153055, 0.3202221621698985], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.48894718], dtype=float32), -0.4662069]. 
=============================================
[2019-03-23 10:15:09,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5980671e-13 1.0000000e+00 3.0308257e-19 9.4419710e-19 7.8712883e-21], sum to 1.0000
[2019-03-23 10:15:09,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5788
[2019-03-23 10:15:09,287] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 92.0, 1.0, 2.0, 0.4244887120570196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 482436.8865281576, 482436.8865281576, 129705.825573106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 888000.0000, 
sim time next is 888600.0000, 
raw observation next is [20.66666666666666, 90.0, 1.0, 2.0, 0.4282960533882011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 487012.5627388791, 487012.5627388794, 130293.7757116967], 
processed observation next is [0.0, 0.2608695652173913, 0.5757575757575755, 0.9, 1.0, 1.0, 0.28537006673525134, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18037502323662188, 0.180375023236622, 0.31778969685779684], 
reward next is 0.6822, 
noisyNet noise sample is [array([-0.95626414], dtype=float32), -0.12286332]. 
=============================================
[2019-03-23 10:15:09,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0041091e-12 1.0000000e+00 2.1175530e-19 6.4965764e-18 1.4603975e-21], sum to 1.0000
[2019-03-23 10:15:09,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5670
[2019-03-23 10:15:09,961] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 76.66666666666667, 1.0, 2.0, 0.4603590447493962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525091.4115156214, 525091.4115156214, 135545.7714502264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 912000.0000, 
sim time next is 912600.0000, 
raw observation next is [23.5, 76.0, 1.0, 2.0, 0.4613726802786369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526304.1811756205, 526304.1811756205, 135795.2033838622], 
processed observation next is [0.0, 0.5652173913043478, 0.7045454545454546, 0.76, 1.0, 1.0, 0.32671585034829614, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19492747450948908, 0.19492747450948908, 0.3312078131313712], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.2726552], dtype=float32), 0.08648465]. 
=============================================
[2019-03-23 10:15:11,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2575162e-12 1.0000000e+00 1.1285993e-19 6.3147351e-19 8.7111602e-21], sum to 1.0000
[2019-03-23 10:15:11,109] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0354
[2019-03-23 10:15:11,113] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4102488036455231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465060.4075355385, 465060.4075355382, 127422.3036534508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 945000.0000, 
sim time next is 945600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4108488816724606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 465741.6073026133, 465741.607302613, 127479.6097442258], 
processed observation next is [0.0, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.2635611020905757, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1724968915935605, 0.17249689159356035, 0.310925877424941], 
reward next is 0.6891, 
noisyNet noise sample is [array([-0.13409404], dtype=float32), 0.95077616]. 
=============================================
[2019-03-23 10:15:17,512] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 10:15:17,514] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:15:17,514] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:15:17,517] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:15:17,520] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:15:17,520] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:15:17,522] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:15:17,522] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:15:17,522] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:15:17,523] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:15:17,527] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:15:17,546] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 10:15:17,572] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 10:15:17,599] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 10:15:17,600] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 10:15:17,645] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 10:15:37,611] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:15:37,612] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.5, 53.5, 1.0, 2.0, 0.5107462740985714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 582393.1057813041, 582393.1057813037, 147693.6126637504]
[2019-03-23 10:15:37,613] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:15:37,617] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.7795170084515356
[2019-03-23 10:15:41,259] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:15:41,260] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.75378481, 60.83137586, 1.0, 2.0, 0.33205718035878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 360552.459376564, 360552.459376564, 104887.4135730574]
[2019-03-23 10:15:41,262] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:15:41,266] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.11054288137944313
[2019-03-23 10:15:45,560] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:15:45,561] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.75, 43.5, 1.0, 2.0, 0.3564335593516286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 396293.0176500846, 396293.0176500846, 122839.049173797]
[2019-03-23 10:15:45,562] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:15:45,565] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.9037331781592741
[2019-03-23 10:15:47,039] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:15:47,044] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.9, 40.0, 1.0, 2.0, 0.2744124438971253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 297945.460762844, 297945.4607628444, 83423.01858378848]
[2019-03-23 10:15:47,046] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:15:47,050] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.678046568621246
[2019-03-23 10:15:47,904] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:15:47,908] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.14343431, 81.54004236, 1.0, 2.0, 0.4434069411511773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 481506.0717116615, 481506.0717116612, 109731.0173353679]
[2019-03-23 10:15:47,909] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:15:47,912] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.45782693417326714
[2019-03-23 10:16:09,638] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:16:09,641] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.73333333333333, 79.83333333333334, 1.0, 2.0, 0.3586593134213891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 399350.4576651623, 399350.4576651619, 123261.4919433624]
[2019-03-23 10:16:09,642] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:16:09,645] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.9762035335752355
[2019-03-23 10:16:20,233] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:16:20,235] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.363401945, 90.12227066333334, 1.0, 2.0, 0.2609231714080231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 283295.9257336624, 283295.9257336621, 91212.00313283168]
[2019-03-23 10:16:20,237] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:16:20,239] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.4988999768621677
[2019-03-23 10:16:26,319] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:16:26,321] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.01532972, 67.34306637666666, 1.0, 2.0, 0.4054025437573296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460763.588032587, 460763.5880325867, 132221.2900892023]
[2019-03-23 10:16:26,322] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:16:26,328] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.2292625801313476
[2019-03-23 10:16:31,504] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43859255]
[2019-03-23 10:16:31,506] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 93.0, 1.0, 2.0, 0.4237886258365116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481092.7925237375, 481092.7925237375, 129201.5181731795]
[2019-03-23 10:16:31,507] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:16:31,509] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.7893646e-13 1.0000000e+00 4.9465546e-20 2.4976393e-19 8.5915571e-22], sampled 0.6265532737870734
[2019-03-23 10:16:57,636] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:16:57,813] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:16:57,844] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:16:57,877] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:16:58,007] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:16:59,027] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1725000, evaluation results [1725000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:17:03,375] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4496190e-13 1.0000000e+00 2.6236788e-21 2.3128913e-20 1.1262187e-23], sum to 1.0000
[2019-03-23 10:17:03,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5371
[2019-03-23 10:17:03,394] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 92.16666666666667, 1.0, 2.0, 0.3906693443356448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440600.5132053933, 440600.5132053933, 124212.5023157498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1152600.0000, 
sim time next is 1153200.0000, 
raw observation next is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4876187984136287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550733.1127340088, 550733.1127340088, 133905.0140992742], 
processed observation next is [1.0, 0.34782608695652173, 0.5303030303030305, 0.9033333333333334, 1.0, 1.0, 0.35952349801703587, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20397522693852177, 0.20397522693852177, 0.32659759536408345], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.03878622], dtype=float32), -0.43628255]. 
=============================================
[2019-03-23 10:17:06,835] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7804087e-12 1.0000000e+00 5.1821480e-19 8.7314632e-19 1.0033064e-20], sum to 1.0000
[2019-03-23 10:17:06,840] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9307
[2019-03-23 10:17:06,848] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3708825434219346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 412817.6116157622, 412817.6116157625, 119873.5700843613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1284000.0000, 
sim time next is 1284600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3684379764663139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 410087.0120585484, 410087.0120585481, 119670.0674471776], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.94, 1.0, 1.0, 0.21054747058289233, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1518840785402031, 0.151884078540203, 0.29187821328579905], 
reward next is 0.7081, 
noisyNet noise sample is [array([-0.3179753], dtype=float32), -0.39579374]. 
=============================================
[2019-03-23 10:17:07,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9821550e-14 1.0000000e+00 6.7736851e-20 2.5974001e-20 6.8135363e-22], sum to 1.0000
[2019-03-23 10:17:07,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4764
[2019-03-23 10:17:07,155] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4091689747754452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463831.2561950829, 463831.2561950831, 127317.0055032597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1226400.0000, 
sim time next is 1227000.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4083008504096193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 462845.2027136751, 462845.2027136751, 127233.9200589653], 
processed observation next is [1.0, 0.17391304347826086, 0.5, 1.0, 1.0, 1.0, 0.26037606301202404, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.171424149153213, 0.171424149153213, 0.3103266342901593], 
reward next is 0.6897, 
noisyNet noise sample is [array([-1.5128154], dtype=float32), -0.325777]. 
=============================================
[2019-03-23 10:17:07,172] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.25589]
 [65.25589]
 [65.25589]
 [65.25589]
 [65.25589]], R is [[65.2930069 ]
 [65.32954407]
 [65.36552429]
 [65.4008255 ]
 [65.43434143]].
[2019-03-23 10:17:07,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5317599e-12 1.0000000e+00 1.7792465e-17 3.7995226e-18 9.5609889e-21], sum to 1.0000
[2019-03-23 10:17:07,844] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9402
[2019-03-23 10:17:07,848] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.16666666666667, 100.0, 1.0, 2.0, 0.4214969588876555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467658.5499376846, 467658.5499376846, 123581.4854005548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1303800.0000, 
sim time next is 1304400.0000, 
raw observation next is [17.33333333333334, 100.0, 1.0, 2.0, 0.3890538276816274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 432748.5192705041, 432748.5192705044, 121259.2544780878], 
processed observation next is [1.0, 0.08695652173913043, 0.42424242424242453, 1.0, 1.0, 1.0, 0.23631728460203422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16027722935944597, 0.16027722935944608, 0.29575427921484826], 
reward next is 0.7042, 
noisyNet noise sample is [array([-1.3692981], dtype=float32), -0.5887242]. 
=============================================
[2019-03-23 10:17:09,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2598812e-14 1.0000000e+00 1.1568715e-19 1.6149619e-18 1.2542765e-22], sum to 1.0000
[2019-03-23 10:17:09,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2589
[2019-03-23 10:17:09,384] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3915076442830501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 439585.4580977918, 439585.4580977915, 123277.8501154104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1312200.0000, 
sim time next is 1312800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3944510228895281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442886.4674956352, 442886.4674956352, 123533.9798800577], 
processed observation next is [1.0, 0.17391304347826086, 0.45454545454545453, 1.0, 1.0, 1.0, 0.24306377861191011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1640320249983834, 0.1640320249983834, 0.3013023899513602], 
reward next is 0.6987, 
noisyNet noise sample is [array([0.7555103], dtype=float32), -1.2649903]. 
=============================================
[2019-03-23 10:17:15,704] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0309687e-12 1.0000000e+00 1.6270633e-18 6.2190197e-18 9.0479511e-21], sum to 1.0000
[2019-03-23 10:17:15,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7541
[2019-03-23 10:17:15,714] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5744051518555072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 649211.9850114712, 649211.9850114716, 154490.0023823034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1517400.0000, 
sim time next is 1518000.0000, 
raw observation next is [23.66666666666667, 88.66666666666666, 1.0, 2.0, 0.553343519624027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627923.8385153346, 627923.8385153346, 150824.2495378758], 
processed observation next is [0.0, 0.5652173913043478, 0.7121212121212124, 0.8866666666666666, 1.0, 1.0, 0.44167939953003366, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23256438463530912, 0.23256438463530912, 0.3678640232631117], 
reward next is 0.6321, 
noisyNet noise sample is [array([0.71829623], dtype=float32), -1.1514877]. 
=============================================
[2019-03-23 10:17:15,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.332245]
 [67.332245]
 [67.332245]
 [67.332245]
 [67.332245]], R is [[67.29105377]
 [67.24133301]
 [67.18428802]
 [67.12283325]
 [67.05995941]].
[2019-03-23 10:17:16,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7738944e-15 1.0000000e+00 5.0499811e-23 4.6818342e-22 3.5409935e-24], sum to 1.0000
[2019-03-23 10:17:16,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6729
[2019-03-23 10:17:16,375] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4898469705351425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558891.4259081689, 558891.4259081689, 140319.3156099917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1390200.0000, 
sim time next is 1390800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4897925180367891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558829.2895103826, 558829.2895103829, 140312.9875769284], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36224064754598634, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20697381092977132, 0.20697381092977146, 0.34222679896811803], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.15891042], dtype=float32), -0.29911312]. 
=============================================
[2019-03-23 10:17:23,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4418025e-13 1.0000000e+00 3.1073427e-19 1.5946681e-18 3.4728673e-21], sum to 1.0000
[2019-03-23 10:17:23,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5950
[2019-03-23 10:17:23,888] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 88.5, 1.0, 2.0, 0.3728611842031813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 419556.629332902, 419556.6293329018, 122128.0120775433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1668600.0000, 
sim time next is 1669200.0000, 
raw observation next is [19.66666666666666, 86.66666666666666, 1.0, 2.0, 0.3712435534112012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 417490.6834969555, 417490.6834969558, 121862.3049458675], 
processed observation next is [1.0, 0.30434782608695654, 0.53030303030303, 0.8666666666666666, 1.0, 1.0, 0.21405444176400146, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15462617907294648, 0.1546261790729466, 0.29722513401431094], 
reward next is 0.7028, 
noisyNet noise sample is [array([1.5201148], dtype=float32), -0.19881701]. 
=============================================
[2019-03-23 10:17:25,487] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1896517e-12 1.0000000e+00 5.1647247e-18 1.6301572e-18 2.2903445e-20], sum to 1.0000
[2019-03-23 10:17:25,496] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5168
[2019-03-23 10:17:25,498] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 90.0, 1.0, 2.0, 0.4191381778622623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476680.6651168343, 476680.6651168343, 129467.9470314269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1560000.0000, 
sim time next is 1560600.0000, 
raw observation next is [20.5, 91.0, 1.0, 2.0, 0.4179626575096686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475234.463349767, 475234.463349767, 129254.8174648503], 
processed observation next is [1.0, 0.043478260869565216, 0.5681818181818182, 0.91, 1.0, 1.0, 0.2724533218870857, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1760127642036174, 0.1760127642036174, 0.31525565235329345], 
reward next is 0.6847, 
noisyNet noise sample is [array([-2.0034697], dtype=float32), -0.26127845]. 
=============================================
[2019-03-23 10:17:29,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8035010e-14 1.0000000e+00 3.4604384e-20 2.2535893e-20 2.4183085e-22], sum to 1.0000
[2019-03-23 10:17:29,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7186
[2019-03-23 10:17:29,042] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 66.0, 1.0, 2.0, 0.4489745472747571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 488190.2820966896, 488190.2820966899, 122617.3074822302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1688400.0000, 
sim time next is 1689000.0000, 
raw observation next is [20.25, 65.0, 1.0, 2.0, 0.4566659311500944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 496632.5884228879, 496632.5884228876, 123292.5509885148], 
processed observation next is [1.0, 0.5652173913043478, 0.5568181818181818, 0.65, 1.0, 1.0, 0.32083241393761797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1839379957121807, 0.18393799571218059, 0.3007135389963776], 
reward next is 0.6993, 
noisyNet noise sample is [array([-0.40522876], dtype=float32), -0.08612648]. 
=============================================
[2019-03-23 10:17:29,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.14205]
 [70.14205]
 [70.14205]
 [70.14205]
 [70.14205]], R is [[70.13991547]
 [70.13945007]
 [70.13972473]
 [70.14073944]
 [70.14109802]].
[2019-03-23 10:17:43,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3229609e-13 1.0000000e+00 7.5205549e-21 2.2678025e-19 9.6591946e-22], sum to 1.0000
[2019-03-23 10:17:43,423] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2017
[2019-03-23 10:17:43,433] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1279090.578901655 W.
[2019-03-23 10:17:43,437] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666666, 61.0, 1.0, 2.0, 0.5606314765240719, 1.0, 2.0, 0.5606314765240719, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1279090.578901655, 1279090.578901655, 243524.7123754289], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1957200.0000, 
sim time next is 1957800.0000, 
raw observation next is [25.83333333333334, 61.0, 1.0, 2.0, 0.6550434486381094, 0.0, 1.0, 0.0, 1.0, 1.0, 0.969368571050112, 6.911200000000001, 6.9112, 77.32846344354104, 1296173.26042471, 1296173.26042471, 277585.5450248134], 
processed observation next is [1.0, 0.6521739130434783, 0.8106060606060609, 0.61, 1.0, 1.0, 0.5688043107976367, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9562408157858744, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4800641705276704, 0.4800641705276704, 0.6770379146946668], 
reward next is 0.3230, 
noisyNet noise sample is [array([0.7998789], dtype=float32), -1.5962296]. 
=============================================
[2019-03-23 10:17:47,730] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 10:17:47,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:17:47,731] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:17:47,731] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:47,732] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:47,733] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:17:47,734] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:17:47,732] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:17:47,735] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:47,736] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:47,738] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:17:47,761] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 10:17:47,787] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 10:17:47,809] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 10:17:47,833] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 10:17:47,866] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 10:17:57,635] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:17:57,636] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [25.83333333333334, 50.83333333333333, 1.0, 2.0, 0.7127937220040496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 806359.1520734229, 806359.1520734229, 161118.3509551703]
[2019-03-23 10:17:57,637] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:17:57,640] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.8290967461490873
[2019-03-23 10:18:00,575] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:18:00,576] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.86991968, 72.076964285, 1.0, 2.0, 0.5160056392563124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 587200.2917494198, 587200.2917494198, 149493.8032295344]
[2019-03-23 10:18:00,578] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:18:00,583] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.6415796658539992
[2019-03-23 10:18:00,709] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:18:00,710] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 88.00000000000001, 1.0, 2.0, 0.4309797877758846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 490332.6498775432, 490332.6498775432, 130805.9662751655]
[2019-03-23 10:18:00,712] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:18:00,718] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.9915846967476136
[2019-03-23 10:18:06,425] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:18:06,429] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.1, 92.33333333333334, 1.0, 2.0, 0.4003565714127585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 450704.5576609479, 450704.5576609476, 128973.3346926644]
[2019-03-23 10:18:06,431] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:18:06,434] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.15045701716171778
[2019-03-23 10:18:17,316] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:18:17,318] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.2, 40.66666666666667, 1.0, 2.0, 0.297317872891533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 322821.8889587948, 322821.8889587944, 93109.4750801761]
[2019-03-23 10:18:17,319] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:18:17,321] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.3154175624965787
[2019-03-23 10:18:37,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:18:37,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.5384792081667601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 614407.5794771836, 614407.579477184, 146080.0115454008]
[2019-03-23 10:18:37,494] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:18:37,498] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.22826398376141532
[2019-03-23 10:19:24,052] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4656546]
[2019-03-23 10:19:24,054] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.98333333333333, 56.83333333333333, 1.0, 2.0, 0.371199399105191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417015.211197045, 417015.211197045, 125966.4482468061]
[2019-03-23 10:19:24,056] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:19:24,060] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3309247e-14 1.0000000e+00 1.2027392e-21 6.5461462e-21 1.4499601e-23], sampled 0.5347976562136559
[2019-03-23 10:19:28,064] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:19:28,071] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:19:28,073] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:19:28,087] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:19:28,186] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:19:29,202] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1750000, evaluation results [1750000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:19:39,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8847718e-14 1.0000000e+00 1.0953613e-21 2.8972098e-21 7.6079450e-24], sum to 1.0000
[2019-03-23 10:19:39,194] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1312
[2019-03-23 10:19:39,198] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 77.0, 1.0, 2.0, 0.4929274520552578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535361.7385811824, 535361.7385811824, 117421.793416489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2194200.0000, 
sim time next is 2194800.0000, 
raw observation next is [17.66666666666667, 77.0, 1.0, 2.0, 0.5116698336630561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 555729.2181998958, 555729.2181998955, 121069.6865658928], 
processed observation next is [1.0, 0.391304347826087, 0.4393939393939396, 0.77, 1.0, 1.0, 0.38958729207882004, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20582563637033177, 0.20582563637033166, 0.2952919184533971], 
reward next is 0.7047, 
noisyNet noise sample is [array([2.1169891], dtype=float32), 1.7918091]. 
=============================================
[2019-03-23 10:19:44,156] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1773136e-14 1.0000000e+00 9.2422530e-22 9.8262120e-22 1.5667814e-24], sum to 1.0000
[2019-03-23 10:19:44,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5868
[2019-03-23 10:19:44,174] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 67.0, 1.0, 2.0, 0.2084532483936795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 226326.306850348, 226326.3068503477, 71137.63165879183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2336400.0000, 
sim time next is 2337000.0000, 
raw observation next is [14.83333333333333, 68.66666666666667, 1.0, 2.0, 0.2063728551935875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 224067.0177084226, 224067.0177084229, 70999.29731352761], 
processed observation next is [1.0, 0.043478260869565216, 0.3106060606060605, 0.6866666666666668, 1.0, 1.0, 0.007966068991984362, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0829877843364528, 0.08298778433645293, 0.17316901783787222], 
reward next is 0.8268, 
noisyNet noise sample is [array([-0.08732765], dtype=float32), 0.42607802]. 
=============================================
[2019-03-23 10:19:44,197] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.82022]
 [77.82022]
 [77.82022]
 [77.82022]
 [77.82022]], R is [[77.86884308]
 [77.91664886]
 [77.9628067 ]
 [78.00726318]
 [78.04993439]].
[2019-03-23 10:19:44,275] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9781692e-14 1.0000000e+00 2.0205272e-21 1.8926941e-21 1.3421555e-23], sum to 1.0000
[2019-03-23 10:19:44,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9513
[2019-03-23 10:19:44,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 67.0, 1.0, 2.0, 0.37777172276608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 425274.655629214, 425274.6556292143, 122651.7326164767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2673000.0000, 
sim time next is 2673600.0000, 
raw observation next is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.3765941757038916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423692.5067797057, 423692.5067797057, 122416.1347689297], 
processed observation next is [0.0, 0.9565217391304348, 0.6515151515151518, 0.6766666666666667, 1.0, 1.0, 0.22074271962986447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15692315065915025, 0.15692315065915025, 0.29857593846080416], 
reward next is 0.7014, 
noisyNet noise sample is [array([1.0221591], dtype=float32), 0.87280494]. 
=============================================
[2019-03-23 10:19:44,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4762927e-15 1.0000000e+00 3.5006342e-24 1.7516648e-21 1.5903553e-25], sum to 1.0000
[2019-03-23 10:19:44,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8283
[2019-03-23 10:19:44,781] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 49.5, 1.0, 2.0, 0.3546837535787502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385157.6807249016, 385157.6807249016, 91135.4021954006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2292600.0000, 
sim time next is 2293200.0000, 
raw observation next is [20.0, 49.0, 1.0, 2.0, 0.412819292850086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448317.2486012555, 448317.2486012555, 97910.36060857684], 
processed observation next is [1.0, 0.5652173913043478, 0.5454545454545454, 0.49, 1.0, 1.0, 0.26602411606260745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1660434254078724, 0.1660434254078724, 0.23880575758189473], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.5066984], dtype=float32), 1.0657041]. 
=============================================
[2019-03-23 10:19:47,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9594690e-14 1.0000000e+00 8.7693363e-22 2.7252002e-20 3.3214505e-22], sum to 1.0000
[2019-03-23 10:19:47,505] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5178
[2019-03-23 10:19:47,512] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 62.0, 1.0, 2.0, 0.3625764361215842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393731.9615209153, 393731.9615209153, 96518.7113140707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2364600.0000, 
sim time next is 2365200.0000, 
raw observation next is [19.0, 60.0, 1.0, 2.0, 0.3923335092997586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 426060.163197749, 426060.1631977487, 99710.12918032902], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.6, 1.0, 1.0, 0.2404168866246982, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15780006044361075, 0.15780006044361064, 0.24319543702519275], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.983284], dtype=float32), 1.0851316]. 
=============================================
[2019-03-23 10:19:52,988] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0413867e-15 1.0000000e+00 2.9501710e-23 3.7740786e-21 5.4214515e-25], sum to 1.0000
[2019-03-23 10:19:52,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2081
[2019-03-23 10:19:53,003] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 72.33333333333334, 1.0, 2.0, 0.556355414276072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 604292.8003970796, 604292.8003970798, 128539.0602135992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2470200.0000, 
sim time next is 2470800.0000, 
raw observation next is [19.0, 71.66666666666667, 1.0, 2.0, 0.6012748913082814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 653115.4686723606, 653115.4686723606, 136555.6803652932], 
processed observation next is [1.0, 0.6086956521739131, 0.5, 0.7166666666666667, 1.0, 1.0, 0.5015936141353516, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24189461802680023, 0.24189461802680023, 0.3330626350373005], 
reward next is 0.6669, 
noisyNet noise sample is [array([-1.2217795], dtype=float32), -0.2629365]. 
=============================================
[2019-03-23 10:19:54,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8059946e-17 1.0000000e+00 3.7803608e-21 7.2619965e-22 2.8180569e-25], sum to 1.0000
[2019-03-23 10:19:54,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7691
[2019-03-23 10:19:54,197] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.5055914020099112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576129.0566119277, 576129.0566119277, 139592.1268365822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2861400.0000, 
sim time next is 2862000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4830300214273789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550394.0224676426, 550394.0224676428, 137081.4149143145], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.83, 1.0, 1.0, 0.3537875267842236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2038496379509787, 0.20384963795097882, 0.3343449144251573], 
reward next is 0.6657, 
noisyNet noise sample is [array([-0.7091467], dtype=float32), -0.5372542]. 
=============================================
[2019-03-23 10:19:54,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.27937]
 [73.27937]
 [73.27937]
 [73.27937]
 [73.27937]], R is [[73.2122345 ]
 [73.13964081]
 [73.06742096]
 [72.99002838]
 [72.88417816]].
[2019-03-23 10:19:58,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1562586e-15 1.0000000e+00 1.1224064e-22 2.8448803e-22 2.1554857e-24], sum to 1.0000
[2019-03-23 10:19:58,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5764
[2019-03-23 10:19:58,759] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 72.5, 1.0, 2.0, 0.267123288435319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290045.7879480149, 290045.7879480146, 91535.45090957469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2590200.0000, 
sim time next is 2590800.0000, 
raw observation next is [17.83333333333333, 72.33333333333334, 1.0, 2.0, 0.2650432155680816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287786.5507206807, 287786.5507206804, 90486.5588616702], 
processed observation next is [1.0, 1.0, 0.44696969696969674, 0.7233333333333334, 1.0, 1.0, 0.08130401946010196, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10658761137802988, 0.10658761137802977, 0.22069892405285416], 
reward next is 0.7793, 
noisyNet noise sample is [array([-0.6861546], dtype=float32), 1.2833306]. 
=============================================
[2019-03-23 10:20:01,261] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4118877e-14 1.0000000e+00 7.8802710e-21 1.4194192e-20 6.6624577e-22], sum to 1.0000
[2019-03-23 10:20:01,268] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1024
[2019-03-23 10:20:01,272] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 70.33333333333334, 1.0, 2.0, 0.46791027504343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 533899.0677954779, 533899.0677954779, 137607.3269093437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2748000.0000, 
sim time next is 2748600.0000, 
raw observation next is [24.5, 75.0, 1.0, 2.0, 0.478392561199207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 545736.0895911386, 545736.0895911386, 139251.7484325507], 
processed observation next is [0.0, 0.8260869565217391, 0.75, 0.75, 1.0, 1.0, 0.3479907014990087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20212447762634764, 0.20212447762634764, 0.33963841081109925], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.1690662], dtype=float32), -0.5912009]. 
=============================================
[2019-03-23 10:20:01,764] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2686924e-15 1.0000000e+00 2.2753043e-21 2.7409417e-21 2.7160629e-23], sum to 1.0000
[2019-03-23 10:20:01,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1564
[2019-03-23 10:20:01,778] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 42.0, 1.0, 2.0, 0.3582116570048572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402059.1208740401, 402059.1208740398, 120367.3982619846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2641800.0000, 
sim time next is 2642400.0000, 
raw observation next is [27.0, 42.0, 1.0, 2.0, 0.3581755609135088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402016.1867118045, 402016.1867118048, 120363.2066829189], 
processed observation next is [0.0, 0.6086956521739131, 0.8636363636363636, 0.42, 1.0, 1.0, 0.19771945114188594, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.148894883967335, 0.1488948839673351, 0.29356879678760706], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.22966458], dtype=float32), 0.6167963]. 
=============================================
[2019-03-23 10:20:02,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0391500e-16 1.0000000e+00 2.3663833e-22 6.9288115e-22 4.3890876e-24], sum to 1.0000
[2019-03-23 10:20:02,128] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6508
[2019-03-23 10:20:02,134] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 67.0, 1.0, 2.0, 0.385538403342085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 435849.6489598649, 435849.6489598646, 124354.5201161529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2626200.0000, 
sim time next is 2626800.0000, 
raw observation next is [23.33333333333334, 65.0, 1.0, 2.0, 0.385714962007895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436095.4351498336, 436095.4351498336, 124398.348831439], 
processed observation next is [0.0, 0.391304347826087, 0.6969696969696972, 0.65, 1.0, 1.0, 0.23214370250986874, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1615168278332717, 0.1615168278332717, 0.3034106069059488], 
reward next is 0.6966, 
noisyNet noise sample is [array([-0.4983125], dtype=float32), -1.1092018]. 
=============================================
[2019-03-23 10:20:03,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0441062e-14 1.0000000e+00 6.8652467e-22 3.9006005e-21 1.0314908e-24], sum to 1.0000
[2019-03-23 10:20:03,346] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4884
[2019-03-23 10:20:03,352] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.93333333333333, 98.33333333333334, 1.0, 2.0, 0.3523390316610959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393720.9328433673, 393720.9328433673, 119055.9691923903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2704800.0000, 
sim time next is 2705400.0000, 
raw observation next is [18.4, 97.5, 1.0, 2.0, 0.3638761514178303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408552.1595267473, 408552.1595267473, 120907.3240172225], 
processed observation next is [0.0, 0.30434782608695654, 0.47272727272727266, 0.975, 1.0, 1.0, 0.20484518927228787, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15131561463953605, 0.15131561463953605, 0.2948959122371281], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.13274406], dtype=float32), 1.2654666]. 
=============================================
[2019-03-23 10:20:03,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9937005e-15 1.0000000e+00 2.7401875e-22 4.8205298e-22 1.2194521e-24], sum to 1.0000
[2019-03-23 10:20:03,365] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9984
[2019-03-23 10:20:03,371] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 56.0, 1.0, 2.0, 0.368705396493871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 413360.4819946928, 413360.4819946925, 121015.7456791246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2666400.0000, 
sim time next is 2667000.0000, 
raw observation next is [24.0, 56.5, 1.0, 2.0, 0.3703278239976789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 415576.4658791418, 415576.4658791421, 121343.0747570348], 
processed observation next is [0.0, 0.8695652173913043, 0.7272727272727273, 0.565, 1.0, 1.0, 0.2129097799970986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15391720958486735, 0.15391720958486746, 0.2959587189195971], 
reward next is 0.7040, 
noisyNet noise sample is [array([-2.3470874], dtype=float32), -0.6843796]. 
=============================================
[2019-03-23 10:20:03,388] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.96059]
 [73.96059]
 [73.96059]
 [73.96059]
 [73.96059]], R is [[73.92501831]
 [73.89060974]
 [73.85797882]
 [73.82698059]
 [73.79707336]].
[2019-03-23 10:20:14,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9883813e-14 1.0000000e+00 1.7232725e-20 2.0683342e-19 2.3347670e-22], sum to 1.0000
[2019-03-23 10:20:14,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8889
[2019-03-23 10:20:14,279] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4219262756220962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 480006.6243122802, 480006.6243122802, 129885.383497385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871600.0000, 
sim time next is 2872200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4207447283945023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478660.0982324827, 478660.0982324827, 129767.1128608627], 
processed observation next is [1.0, 0.21739130434782608, 0.5909090909090909, 0.88, 1.0, 1.0, 0.2759309104931278, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17728151786388247, 0.17728151786388247, 0.31650515331917733], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.8766943], dtype=float32), 0.5735756]. 
=============================================
[2019-03-23 10:20:16,220] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8858802e-13 1.0000000e+00 2.3014609e-18 3.2454936e-18 3.2065291e-20], sum to 1.0000
[2019-03-23 10:20:16,226] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8550
[2019-03-23 10:20:16,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1195427.345244685 W.
[2019-03-23 10:20:16,237] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 68.0, 1.0, 2.0, 0.5316321185166809, 1.0, 2.0, 0.5316321185166809, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1195427.345244685, 1195427.345244685, 243532.2323404233], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2896200.0000, 
sim time next is 2896800.0000, 
raw observation next is [28.66666666666666, 67.33333333333334, 1.0, 2.0, 0.3338282338405399, 1.0, 2.0, 0.3338282338405399, 1.0, 1.0, 0.6754611826927446, 6.911199999999999, 6.9112, 77.3421103, 1125899.42807503, 1125899.428075031, 277908.5865451516], 
processed observation next is [1.0, 0.5217391304347826, 0.9393939393939391, 0.6733333333333335, 1.0, 1.0, 0.16728529230067485, 1.0, 1.0, 0.16728529230067485, 1.0, 0.5, 0.5363731181324923, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.416999788175937, 0.41699978817593736, 0.6778258208418332], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.72226745], dtype=float32), -1.8158619]. 
=============================================
[2019-03-23 10:20:16,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8696864e-11 1.0000000e+00 5.9642974e-19 1.4776362e-19 3.5954465e-20], sum to 1.0000
[2019-03-23 10:20:16,848] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2836
[2019-03-23 10:20:16,858] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1081550.561845782 W.
[2019-03-23 10:20:16,863] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4772021360762254, 1.0, 1.0, 0.4772021360762254, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32844620722796, 1081550.561845782, 1081550.561845782, 227552.6671945361], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2983200.0000, 
sim time next is 2983800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.4705519386860675, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9388431774827077, 6.935986024629885, 6.9112, 77.32840044857662, 1069963.922117987, 1061913.934837933, 253629.276890269], 
processed observation next is [1.0, 0.5217391304347826, 0.9090909090909091, 0.58, 1.0, 1.0, 0.3381899233575843, 0.0, 0.5, -0.25, 1.0, 0.5, 0.9126331106895825, 0.002478602462988455, 0.0, 0.5084283987335159, 0.39628293411777293, 0.3933014573473826, 0.6186079924152902], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5720929], dtype=float32), 0.71214956]. 
=============================================
[2019-03-23 10:20:17,903] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 10:20:17,905] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:20:17,906] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:20:17,906] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:20:17,908] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:20:17,908] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:20:17,911] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:20:17,911] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:20:17,912] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:20:17,914] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:20:17,916] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:20:17,937] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 10:20:17,964] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 10:20:17,998] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 10:20:18,022] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 10:20:18,024] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 10:20:43,392] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:20:43,393] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.03454557666667, 57.18563304, 1.0, 2.0, 0.2235089441587302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 242665.4300444095, 242665.4300444091, 78391.66036626951]
[2019-03-23 10:20:43,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:20:43,397] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.40073561148393066
[2019-03-23 10:20:48,588] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:20:48,590] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.2, 58.33333333333334, 1.0, 2.0, 0.2057557385126558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 223387.0524834158, 223387.0524834158, 74180.67713447074]
[2019-03-23 10:20:48,593] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:20:48,596] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.8787223338250995
[2019-03-23 10:20:48,842] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:20:48,843] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.85, 41.0, 1.0, 2.0, 0.3777304676035064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 410162.0957874904, 410162.0957874907, 96577.72902733389]
[2019-03-23 10:20:48,844] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:20:48,847] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.7292001414434918
[2019-03-23 10:21:22,533] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:21:22,534] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.0, 73.5, 1.0, 2.0, 0.320114699747422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 347581.3922839407, 347581.3922839403, 116868.2469852678]
[2019-03-23 10:21:22,535] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:21:22,538] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.6295314726578435
[2019-03-23 10:21:36,502] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:21:36,504] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.30480625666667, 82.66210695333334, 1.0, 2.0, 0.3952296350972268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432059.2248899944, 432059.2248899944, 123333.3829382438]
[2019-03-23 10:21:36,506] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:21:36,508] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.7854155062803173
[2019-03-23 10:21:44,949] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:21:44,950] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.3, 93.0, 1.0, 2.0, 0.3598988649910714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401577.0390481144, 401577.0390481144, 119406.2548785785]
[2019-03-23 10:21:44,951] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:21:44,954] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.07491602425920862
[2019-03-23 10:21:50,863] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.41333777]
[2019-03-23 10:21:50,863] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.7, 75.0, 1.0, 2.0, 0.2692188751367614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 292321.8858862549, 292321.8858862549, 92939.55853061099]
[2019-03-23 10:21:50,865] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:21:50,867] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6394176e-13 1.0000000e+00 1.5682145e-19 8.0372368e-19 3.1562009e-21], sampled 0.7404840992358279
[2019-03-23 10:21:58,151] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:21:58,215] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:21:58,261] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:21:58,341] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:21:58,455] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:21:59,472] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1775000, evaluation results [1775000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:22:01,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.8991778e-12 1.0000000e+00 2.7211099e-18 1.5887246e-17 5.9943569e-20], sum to 1.0000
[2019-03-23 10:22:01,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5864
[2019-03-23 10:22:01,249] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5493116277500281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626303.7593775381, 626303.7593775381, 148308.400253889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2960400.0000, 
sim time next is 2961000.0000, 
raw observation next is [22.5, 91.5, 1.0, 2.0, 0.5514712014379658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 628659.4517007879, 628659.4517007879, 148711.536472957], 
processed observation next is [1.0, 0.2608695652173913, 0.6590909090909091, 0.915, 1.0, 1.0, 0.4393390017974572, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23283683396325477, 0.23283683396325477, 0.3627110645681878], 
reward next is 0.6373, 
noisyNet noise sample is [array([2.2913344], dtype=float32), 0.4218746]. 
=============================================
[2019-03-23 10:22:01,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.667755]
 [62.667755]
 [62.667755]
 [62.667755]
 [62.667755]], R is [[62.67836761]
 [62.68985748]
 [62.70034027]
 [62.7282486 ]
 [62.75517273]].
[2019-03-23 10:22:06,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6342448e-13 1.0000000e+00 4.9589509e-19 4.5367057e-19 1.3223824e-21], sum to 1.0000
[2019-03-23 10:22:06,179] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0492
[2019-03-23 10:22:06,186] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5556546431517955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 630376.7551433728, 630376.7551433728, 151196.2889095287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3435600.0000, 
sim time next is 3436200.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5554558908646212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 630147.921337049, 630147.9213370492, 151171.8959310657], 
processed observation next is [1.0, 0.782608695652174, 0.8181818181818182, 0.74, 1.0, 1.0, 0.44431986358077646, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23338811901372183, 0.23338811901372195, 0.3687119412952822], 
reward next is 0.6313, 
noisyNet noise sample is [array([-0.33553743], dtype=float32), -0.66621083]. 
=============================================
[2019-03-23 10:22:10,200] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3774737e-13 1.0000000e+00 9.0379860e-20 2.4595737e-19 1.3623310e-21], sum to 1.0000
[2019-03-23 10:22:10,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9076
[2019-03-23 10:22:10,214] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.00000000000001, 1.0, 2.0, 0.4417445927138505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502584.6499824583, 502584.6499824583, 131890.4887037398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3186600.0000, 
sim time next is 3187200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.4404602780686391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 501119.2734017011, 501119.2734017011, 131756.8154564659], 
processed observation next is [1.0, 0.9130434782608695, 0.5909090909090909, 0.88, 1.0, 1.0, 0.3005753475857988, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18559973088951892, 0.18559973088951892, 0.3213580864791851], 
reward next is 0.6786, 
noisyNet noise sample is [array([0.50670695], dtype=float32), -0.10268725]. 
=============================================
[2019-03-23 10:22:20,960] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0618726e-13 1.0000000e+00 7.1865260e-19 1.1246711e-19 1.1018025e-21], sum to 1.0000
[2019-03-23 10:22:20,968] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8740
[2019-03-23 10:22:20,974] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 62.5, 1.0, 2.0, 0.3606981569721083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 402934.3573421519, 402934.3573421519, 119676.903754655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3353400.0000, 
sim time next is 3354000.0000, 
raw observation next is [22.33333333333334, 63.0, 1.0, 2.0, 0.3581261961812577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399648.7793603945, 399648.7793603945, 119284.2066804925], 
processed observation next is [0.0, 0.8260869565217391, 0.6515151515151518, 0.63, 1.0, 1.0, 0.1976577452265721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14801806642977575, 0.14801806642977575, 0.29093708946461583], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.92964995], dtype=float32), 0.57652265]. 
=============================================
[2019-03-23 10:22:20,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.77515]
 [71.77515]
 [71.77515]
 [71.77515]
 [71.77515]], R is [[71.76644897]
 [71.75688934]
 [71.746521  ]
 [71.73532867]
 [71.72351074]].
[2019-03-23 10:22:23,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0110096e-12 1.0000000e+00 9.4152117e-19 2.4228842e-18 5.9629751e-20], sum to 1.0000
[2019-03-23 10:22:23,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4243
[2019-03-23 10:22:23,911] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 75.83333333333333, 1.0, 2.0, 0.7575852805313941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862043.49452963, 862043.49452963, 170795.049551322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3406200.0000, 
sim time next is 3406800.0000, 
raw observation next is [23.0, 73.66666666666667, 1.0, 2.0, 0.8238436555047217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 938336.5601339161, 938336.5601339161, 181570.1326848564], 
processed observation next is [1.0, 0.43478260869565216, 0.6818181818181818, 0.7366666666666667, 1.0, 1.0, 0.7798045693809021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.34753205930885783, 0.34753205930885783, 0.44285398215818633], 
reward next is 0.5571, 
noisyNet noise sample is [array([-0.79006344], dtype=float32), 0.6065723]. 
=============================================
[2019-03-23 10:22:27,314] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.7995976e-14 1.0000000e+00 6.1773731e-21 4.9441021e-20 1.0816382e-21], sum to 1.0000
[2019-03-23 10:22:27,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7509
[2019-03-23 10:22:27,331] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5023114058673374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 572852.019945291, 572852.0199452908, 142364.3073209051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3457200.0000, 
sim time next is 3457800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5019756331196162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 572469.1336670852, 572469.1336670852, 142324.483396341], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.94, 1.0, 1.0, 0.37746954139952027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21202560506188342, 0.21202560506188342, 0.347132886332539], 
reward next is 0.6529, 
noisyNet noise sample is [array([-1.4520198], dtype=float32), -0.1493564]. 
=============================================
[2019-03-23 10:22:35,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3021698e-14 1.0000000e+00 9.2682165e-19 2.9023123e-19 5.2309020e-21], sum to 1.0000
[2019-03-23 10:22:35,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2127
[2019-03-23 10:22:35,512] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.5366410753167988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612303.2646920797, 612303.2646920797, 145875.8877886218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3639600.0000, 
sim time next is 3640200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.5331440168575148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 608312.5537737053, 608312.5537737053, 145445.7859757817], 
processed observation next is [1.0, 0.13043478260869565, 0.5909090909090909, 1.0, 1.0, 1.0, 0.4164300210718934, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22530094584211305, 0.22530094584211305, 0.3547458194531261], 
reward next is 0.6453, 
noisyNet noise sample is [array([-0.64432764], dtype=float32), -0.03990927]. 
=============================================
[2019-03-23 10:22:44,619] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6476948e-14 1.0000000e+00 7.6195781e-20 1.0304467e-20 5.2952427e-23], sum to 1.0000
[2019-03-23 10:22:44,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5194
[2019-03-23 10:22:44,636] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 69.66666666666666, 1.0, 2.0, 0.3461825052606276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387472.9961180944, 387472.9961180947, 118853.3494295193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3919800.0000, 
sim time next is 3920400.0000, 
raw observation next is [22.0, 69.0, 1.0, 2.0, 0.3528543946813593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 395988.5984968066, 395988.5984968063, 119896.4866173647], 
processed observation next is [0.0, 0.391304347826087, 0.6363636363636364, 0.69, 1.0, 1.0, 0.19106799335169913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14666244388770613, 0.14666244388770602, 0.29243045516430416], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.69963413], dtype=float32), -0.016870111]. 
=============================================
[2019-03-23 10:22:47,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6043569e-14 1.0000000e+00 1.8699462e-19 1.6081802e-19 9.5415647e-22], sum to 1.0000
[2019-03-23 10:22:47,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2868
[2019-03-23 10:22:47,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 73.0, 1.0, 2.0, 0.3030047344507545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 329019.4876022324, 329019.4876022324, 111393.2657516467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3970800.0000, 
sim time next is 3971400.0000, 
raw observation next is [18.83333333333334, 73.66666666666667, 1.0, 2.0, 0.3012224609009528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 327083.5444634098, 327083.5444634095, 111272.8515485997], 
processed observation next is [0.0, 1.0, 0.4924242424242427, 0.7366666666666667, 1.0, 1.0, 0.12652807612619096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1211420535049666, 0.12114205350496648, 0.2713971988990237], 
reward next is 0.7286, 
noisyNet noise sample is [array([-0.04319024], dtype=float32), -0.37425035]. 
=============================================
[2019-03-23 10:22:48,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.4446822e-15 1.0000000e+00 2.4791442e-22 2.3921514e-21 2.4018230e-23], sum to 1.0000
[2019-03-23 10:22:48,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2722
[2019-03-23 10:22:48,321] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 98.0, 1.0, 2.0, 0.3380313717914618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 367067.7243935345, 367067.7243935348, 113819.4839001192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4249200.0000, 
sim time next is 4249800.0000, 
raw observation next is [16.0, 97.0, 1.0, 2.0, 0.324746436234119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352636.4033487799, 352636.4033487802, 111874.4892495506], 
processed observation next is [1.0, 0.17391304347826086, 0.36363636363636365, 0.97, 1.0, 1.0, 0.1559330452926487, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1306060753143629, 0.13060607531436302, 0.2728646079257332], 
reward next is 0.7271, 
noisyNet noise sample is [array([-1.4718204], dtype=float32), 0.64920264]. 
=============================================
[2019-03-23 10:22:48,373] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 10:22:48,379] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:22:48,379] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:48,380] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:22:48,381] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:48,381] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:22:48,383] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:22:48,385] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:48,384] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:22:48,385] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:48,386] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:22:48,407] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 10:22:48,432] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 10:22:48,454] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 10:22:48,476] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 10:22:48,477] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 10:23:00,609] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.45409334]
[2019-03-23 10:23:00,611] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.5, 43.33333333333334, 1.0, 2.0, 0.3912643541160437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 442153.0592157028, 442153.0592157028, 129097.3349961948]
[2019-03-23 10:23:00,612] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:23:00,615] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.5671864e-14 1.0000000e+00 2.6130712e-21 1.4001664e-20 3.4209531e-23], sampled 0.7661760584358621
[2019-03-23 10:23:40,827] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.45409334]
[2019-03-23 10:23:40,828] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 90.0, 1.0, 2.0, 0.311503041341496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 338250.633865177, 338250.6338651773, 111970.0208367677]
[2019-03-23 10:23:40,833] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:23:40,836] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5671864e-14 1.0000000e+00 2.6130712e-21 1.4001664e-20 3.4209531e-23], sampled 0.856207003036007
[2019-03-23 10:23:48,669] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.45409334]
[2019-03-23 10:23:48,670] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.20632723666667, 70.8626839, 1.0, 2.0, 0.5120273158993025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 583905.4237144133, 583905.4237144133, 147762.116624483]
[2019-03-23 10:23:48,671] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:23:48,673] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5671864e-14 1.0000000e+00 2.6130712e-21 1.4001664e-20 3.4209531e-23], sampled 0.36127011758531935
[2019-03-23 10:23:56,116] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.45409334]
[2019-03-23 10:23:56,118] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 73.0, 1.0, 2.0, 0.4175922576878713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 453503.0538684455, 453503.0538684452, 119854.6015666464]
[2019-03-23 10:23:56,118] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:23:56,120] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5671864e-14 1.0000000e+00 2.6130712e-21 1.4001664e-20 3.4209531e-23], sampled 0.5154524321043298
[2019-03-23 10:24:07,430] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.45409334]
[2019-03-23 10:24:07,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.2550339, 65.95841671, 1.0, 2.0, 0.363139573160403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 409867.5411587994, 409867.5411587991, 126313.6806089869]
[2019-03-23 10:24:07,431] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:24:07,432] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5671864e-14 1.0000000e+00 2.6130712e-21 1.4001664e-20 3.4209531e-23], sampled 0.7436561702839933
[2019-03-23 10:24:28,373] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:24:28,449] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:24:28,617] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:24:28,745] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:24:28,810] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:24:29,826] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1800000, evaluation results [1800000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:24:30,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2579858e-15 1.0000000e+00 3.4993677e-23 2.2306492e-21 3.4663618e-25], sum to 1.0000
[2019-03-23 10:24:30,678] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6574
[2019-03-23 10:24:30,683] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 51.5, 1.0, 2.0, 0.3309122441848896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364898.7988099745, 364898.7988099745, 115308.0534541003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3954600.0000, 
sim time next is 3955200.0000, 
raw observation next is [23.33333333333333, 52.0, 1.0, 2.0, 0.3296402082665599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363115.3113986875, 363115.3113986875, 115067.9772517413], 
processed observation next is [0.0, 0.782608695652174, 0.6969696969696968, 0.52, 1.0, 1.0, 0.16205026033319983, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13448715236988426, 0.13448715236988426, 0.28065360305302756], 
reward next is 0.7193, 
noisyNet noise sample is [array([-1.9848472], dtype=float32), -1.642955]. 
=============================================
[2019-03-23 10:24:34,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4493607e-13 1.0000000e+00 4.1581729e-22 3.2491322e-20 1.4485020e-21], sum to 1.0000
[2019-03-23 10:24:34,429] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5489
[2019-03-23 10:24:34,432] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.0, 1.0, 2.0, 0.3368253189391334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372522.4393481191, 372522.4393481194, 116177.276462922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3952800.0000, 
sim time next is 3953400.0000, 
raw observation next is [23.83333333333333, 50.5, 1.0, 2.0, 0.33446939875783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 369562.7981458544, 369562.7981458544, 115859.8363953181], 
processed observation next is [0.0, 0.782608695652174, 0.7196969696969695, 0.505, 1.0, 1.0, 0.16808674844728747, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13687511042439052, 0.13687511042439052, 0.282584966817849], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.6512805], dtype=float32), 2.2709548]. 
=============================================
[2019-03-23 10:24:35,353] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4856517e-14 1.0000000e+00 1.0801078e-22 4.1442124e-19 1.7864773e-23], sum to 1.0000
[2019-03-23 10:24:35,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0612
[2019-03-23 10:24:35,368] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 79.0, 1.0, 2.0, 0.281773515300733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 305958.1902502673, 305958.1902502673, 100419.2868493307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3980400.0000, 
sim time next is 3981000.0000, 
raw observation next is [17.58333333333333, 79.5, 1.0, 2.0, 0.2807729314283414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 304871.385523712, 304871.3855237123, 99969.01930769808], 
processed observation next is [1.0, 0.043478260869565216, 0.4356060606060604, 0.795, 1.0, 1.0, 0.10096616428542676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11291532797174518, 0.1129153279717453, 0.24382687636023923], 
reward next is 0.7562, 
noisyNet noise sample is [array([-0.18489742], dtype=float32), -1.6895533]. 
=============================================
[2019-03-23 10:24:35,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.10819]
 [73.10819]
 [73.10819]
 [73.10819]
 [73.10819]], R is [[73.13328552]
 [73.1570282 ]
 [73.1792984 ]
 [73.20033264]
 [73.22037506]].
[2019-03-23 10:24:37,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0153817e-13 1.0000000e+00 2.9811279e-20 2.9205250e-20 4.6761024e-23], sum to 1.0000
[2019-03-23 10:24:37,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2057
[2019-03-23 10:24:37,445] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 94.0, 1.0, 2.0, 0.3502312029572296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 387083.2220995162, 387083.2220995162, 117098.7535242938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4037400.0000, 
sim time next is 4038000.0000, 
raw observation next is [17.33333333333333, 94.0, 1.0, 2.0, 0.3453853844239688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 380617.737869088, 380617.7378690882, 116302.3145568291], 
processed observation next is [1.0, 0.7391304347826086, 0.42424242424242403, 0.94, 1.0, 1.0, 0.181731730529961, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14096953254410668, 0.14096953254410674, 0.2836641818459246], 
reward next is 0.7163, 
noisyNet noise sample is [array([1.9179472], dtype=float32), 0.80832636]. 
=============================================
[2019-03-23 10:24:37,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.08697]
 [69.08697]
 [69.08697]
 [69.08697]
 [69.08697]], R is [[69.11243439]
 [69.13570404]
 [69.15525818]
 [69.16107941]
 [69.1346283 ]].
[2019-03-23 10:24:37,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4862919e-13 1.0000000e+00 7.2163288e-20 6.4707698e-21 3.1687336e-22], sum to 1.0000
[2019-03-23 10:24:37,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7287
[2019-03-23 10:24:37,476] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.5030531329522024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 560103.0243904042, 560103.0243904042, 131831.5448036797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4018800.0000, 
sim time next is 4019400.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.4265043659152431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 474081.8960963286, 474081.8960963289, 124355.4584164675], 
processed observation next is [1.0, 0.5217391304347826, 0.4318181818181818, 0.97, 1.0, 1.0, 0.28313045739405385, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17558588744308468, 0.1755858874430848, 0.30330599613772563], 
reward next is 0.6967, 
noisyNet noise sample is [array([-1.5578717], dtype=float32), -0.40636584]. 
=============================================
[2019-03-23 10:24:38,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5420180e-14 1.0000000e+00 5.3846484e-22 5.3185519e-20 8.2080674e-23], sum to 1.0000
[2019-03-23 10:24:38,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0937
[2019-03-23 10:24:38,442] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3183658651175765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348304.471991756, 348304.471991756, 113352.2780809082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056600.0000, 
sim time next is 4057200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3175327869473207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347386.1100369328, 347386.1100369328, 113290.9632149848], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.94, 1.0, 1.0, 0.14691598368415082, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12866152223590105, 0.12866152223590105, 0.2763194224755727], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.5826029], dtype=float32), -1.8663443]. 
=============================================
[2019-03-23 10:24:51,882] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0806317e-15 1.0000000e+00 3.4358526e-21 4.1210183e-21 9.1402497e-24], sum to 1.0000
[2019-03-23 10:24:51,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3849
[2019-03-23 10:24:51,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1161605.234571939 W.
[2019-03-23 10:24:51,901] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.03333333333334, 48.33333333333333, 1.0, 2.0, 0.5088475239391457, 1.0, 1.0, 0.5088475239391457, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32844454067495, 1161605.234571939, 1161605.234571938, 225682.220405681], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4285200.0000, 
sim time next is 4285800.0000, 
raw observation next is [27.05, 48.5, 1.0, 2.0, 0.3441187999547672, 1.0, 2.0, 0.3441187999547672, 1.0, 1.0, 0.6936658474904087, 6.9112, 6.9112, 77.3421103, 1178733.316418589, 1178733.316418589, 268646.8442523842], 
processed observation next is [1.0, 0.6086956521739131, 0.865909090909091, 0.485, 1.0, 1.0, 0.18014849994345897, 1.0, 1.0, 0.18014849994345897, 1.0, 0.5, 0.5623797821291554, 0.0, 0.0, 0.5085185399722538, 0.4365678949698478, 0.4365678949698478, 0.65523620549362], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0007054], dtype=float32), 0.89266944]. 
=============================================
[2019-03-23 10:24:53,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7353664e-14 1.0000000e+00 1.8746520e-20 5.6456524e-20 3.7863195e-22], sum to 1.0000
[2019-03-23 10:24:53,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9538
[2019-03-23 10:24:53,279] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 66.66666666666667, 1.0, 2.0, 0.3981213271792034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449943.2872487389, 449943.2872487389, 125414.3472820842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4310400.0000, 
sim time next is 4311000.0000, 
raw observation next is [22.5, 69.5, 1.0, 2.0, 0.3976534456587701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 449226.8225314104, 449226.8225314104, 125261.4061396105], 
processed observation next is [1.0, 0.9130434782608695, 0.6590909090909091, 0.695, 1.0, 1.0, 0.2470668070734626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1663803046412631, 0.1663803046412631, 0.30551562473075733], 
reward next is 0.6945, 
noisyNet noise sample is [array([-0.62478364], dtype=float32), -0.25282153]. 
=============================================
[2019-03-23 10:24:53,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.1497]
 [68.1497]
 [68.1497]
 [68.1497]
 [68.1497]], R is [[68.16268158]
 [68.1751709 ]
 [68.1869812 ]
 [68.19847107]
 [68.21000671]].
[2019-03-23 10:24:54,007] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1406947e-13 1.0000000e+00 1.0465900e-20 1.6046138e-19 5.9219160e-22], sum to 1.0000
[2019-03-23 10:24:54,013] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-23 10:24:54,018] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 75.0, 1.0, 2.0, 0.4688857178598277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 534901.131314285, 534901.1313142852, 136670.0989104424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4397400.0000, 
sim time next is 4398000.0000, 
raw observation next is [23.43333333333333, 76.0, 1.0, 2.0, 0.465369664925363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530835.6717306746, 530835.6717306746, 136147.8601069842], 
processed observation next is [1.0, 0.9130434782608695, 0.7015151515151513, 0.76, 1.0, 1.0, 0.33171208115670375, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1966058043446943, 0.1966058043446943, 0.3320679514804493], 
reward next is 0.6679, 
noisyNet noise sample is [array([-1.0911618], dtype=float32), -0.7683366]. 
=============================================
[2019-03-23 10:24:54,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.43858]
 [66.43858]
 [66.43858]
 [66.43858]
 [66.43858]], R is [[66.44213104]
 [66.44436646]
 [66.44522858]
 [66.44486237]
 [66.44361877]].
[2019-03-23 10:24:54,450] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8950106e-14 1.0000000e+00 1.2894897e-21 4.9516899e-20 4.8987404e-22], sum to 1.0000
[2019-03-23 10:24:54,457] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1907
[2019-03-23 10:24:54,462] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 89.00000000000001, 1.0, 2.0, 0.3686171668274763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412449.9544874814, 412449.9544874812, 120629.5398528194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320600.0000, 
sim time next is 4321200.0000, 
raw observation next is [19.0, 90.0, 1.0, 2.0, 0.370079152329483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414663.7140027492, 414663.7140027492, 121019.2136782735], 
processed observation next is [1.0, 0.0, 0.5, 0.9, 1.0, 1.0, 0.21259894041185376, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15357915333435154, 0.15357915333435154, 0.29516881384944754], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.39246196], dtype=float32), 0.0037148108]. 
=============================================
[2019-03-23 10:24:56,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.5956204e-15 1.0000000e+00 9.9342301e-22 4.6289911e-19 2.8429386e-22], sum to 1.0000
[2019-03-23 10:24:56,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5022
[2019-03-23 10:24:56,948] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 82.0, 1.0, 2.0, 0.4530928639284997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516435.3146668026, 516435.3146668029, 134117.2385285512], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4408200.0000, 
sim time next is 4408800.0000, 
raw observation next is [22.16666666666667, 82.33333333333333, 1.0, 2.0, 0.4519359174699271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 515058.2956889392, 515058.2956889389, 133913.3874377168], 
processed observation next is [0.0, 0.0, 0.6439393939393941, 0.8233333333333333, 1.0, 1.0, 0.31491989683740884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19076233173664417, 0.19076233173664403, 0.3266180181407727], 
reward next is 0.6734, 
noisyNet noise sample is [array([0.45952898], dtype=float32), -0.969969]. 
=============================================
[2019-03-23 10:25:00,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.2907810e-13 1.0000000e+00 7.3189050e-20 1.5710954e-18 5.3499239e-22], sum to 1.0000
[2019-03-23 10:25:00,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7524
[2019-03-23 10:25:00,759] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 84.0, 1.0, 2.0, 0.2738230916740566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297322.7413333947, 297322.7413333944, 94244.38286062122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4580400.0000, 
sim time next is 4581000.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.2725474711953219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295937.2249748379, 295937.2249748379, 93524.04819832453], 
processed observation next is [1.0, 0.0, 0.38636363636363635, 0.85, 1.0, 1.0, 0.09068433899415237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10960637962031033, 0.10960637962031033, 0.2281074346300598], 
reward next is 0.7719, 
noisyNet noise sample is [array([0.335191], dtype=float32), 0.74638337]. 
=============================================
[2019-03-23 10:25:00,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.16471]
 [68.16471]
 [68.16471]
 [68.16471]
 [68.16471]], R is [[68.25495911]
 [68.34254456]
 [68.42766571]
 [68.51051331]
 [68.59265137]].
[2019-03-23 10:25:10,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3740275e-13 1.0000000e+00 2.7481567e-20 4.0791821e-20 2.7742139e-21], sum to 1.0000
[2019-03-23 10:25:10,655] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5854
[2019-03-23 10:25:10,658] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 47.5, 1.0, 2.0, 0.7477705406904742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 823767.4823943279, 823767.4823943279, 156355.1618308878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4637400.0000, 
sim time next is 4638000.0000, 
raw observation next is [23.66666666666666, 48.0, 1.0, 2.0, 0.6959591994142409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 765805.3973189397, 765805.3973189397, 149804.7821161551], 
processed observation next is [1.0, 0.6956521739130435, 0.7121212121212118, 0.48, 1.0, 1.0, 0.6199489992678011, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2836316286366443, 0.2836316286366443, 0.3653775173564759], 
reward next is 0.6346, 
noisyNet noise sample is [array([0.21853192], dtype=float32), -0.402784]. 
=============================================
[2019-03-23 10:25:10,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.802246]
 [73.802246]
 [73.802246]
 [73.802246]
 [73.802246]], R is [[73.69884491]
 [73.58050537]
 [73.46666718]
 [73.36032104]
 [73.26473236]].
[2019-03-23 10:25:11,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3658963e-13 1.0000000e+00 1.2224133e-18 1.1977406e-19 1.6593100e-21], sum to 1.0000
[2019-03-23 10:25:11,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9437
[2019-03-23 10:25:11,286] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 85.0, 1.0, 2.0, 0.2098933842298644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227890.288142433, 227890.288142433, 74730.09385594192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4678200.0000, 
sim time next is 4678800.0000, 
raw observation next is [14.33333333333333, 86.0, 1.0, 2.0, 0.2092439617810899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 227185.0175480972, 227185.0175480972, 74442.4012568119], 
processed observation next is [1.0, 0.13043478260869565, 0.28787878787878773, 0.86, 1.0, 1.0, 0.011554952226362353, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08414259909188786, 0.08414259909188786, 0.1815668323336876], 
reward next is 0.8184, 
noisyNet noise sample is [array([0.4447048], dtype=float32), -0.11395018]. 
=============================================
[2019-03-23 10:25:18,971] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 10:25:18,974] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:25:18,975] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:25:18,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:25:18,978] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:25:18,980] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:25:18,982] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:25:18,980] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:25:18,983] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:25:18,984] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:25:18,986] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:25:19,008] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 10:25:19,033] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 10:25:19,059] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 10:25:19,084] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 10:25:19,084] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 10:25:23,265] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:25:23,267] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [15.0, 98.0, 1.0, 2.0, 0.2597595617670253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282047.8434864808, 282047.8434864808, 90879.1670368199]
[2019-03-23 10:25:23,268] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:25:23,272] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.30830089075143285
[2019-03-23 10:25:49,847] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:25:49,849] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.16666666666667, 87.16666666666667, 1.0, 2.0, 0.3703481130396409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 414353.4398925584, 414353.4398925584, 120758.2120106526]
[2019-03-23 10:25:49,850] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:25:49,852] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.2718895024643785
[2019-03-23 10:25:54,296] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:25:54,297] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.22615256, 45.165197455, 1.0, 2.0, 0.3306937819611066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 359071.6195300621, 359071.6195300617, 96200.21231719996]
[2019-03-23 10:25:54,298] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:25:54,302] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.7287639307455313
[2019-03-23 10:26:03,629] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:26:03,630] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 63.0, 1.0, 2.0, 0.3812955937867599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 427756.8215444971, 427756.8215444967, 126539.5966426737]
[2019-03-23 10:26:03,632] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:26:03,636] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.44840641895509303
[2019-03-23 10:26:11,206] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:26:11,206] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 88.0, 1.0, 2.0, 0.2977192903620567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 323278.3491628054, 323278.3491628054, 109690.6323119708]
[2019-03-23 10:26:11,207] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:26:11,211] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.7801378532075476
[2019-03-23 10:26:31,297] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:26:31,298] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.43333333333333, 63.0, 1.0, 2.0, 0.867134902303354, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846332190856, 979789.5168216741, 979789.5168216737, 200489.7831428282]
[2019-03-23 10:26:31,300] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:26:31,304] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.2276076870347462
[2019-03-23 10:26:33,861] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:26:33,862] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 97.0, 1.0, 2.0, 0.3880746111557765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 437884.7526318709, 437884.7526318711, 124098.3397172595]
[2019-03-23 10:26:33,864] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:26:33,867] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.30667084790542865
[2019-03-23 10:26:48,510] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:26:48,511] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.39762342166667, 64.76569178999999, 1.0, 2.0, 0.5014686725176948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 571743.5759455621, 571743.5759455618, 146698.1630445755]
[2019-03-23 10:26:48,512] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:26:48,513] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.3238809420211004
[2019-03-23 10:26:50,737] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43385273]
[2019-03-23 10:26:50,739] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.8, 84.0, 1.0, 2.0, 0.3488896760001163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 386261.0461278114, 386261.046127811, 121572.0283437409]
[2019-03-23 10:26:50,741] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:26:50,743] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [3.4980509e-13 1.0000000e+00 9.0494742e-20 4.6328954e-19 1.7700766e-21], sampled 0.20558113747684714
[2019-03-23 10:26:59,244] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:26:59,259] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:26:59,339] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:26:59,343] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:26:59,389] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:27:00,404] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1825000, evaluation results [1825000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:27:00,475] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0443922e-15 1.0000000e+00 1.7341780e-22 1.0362255e-20 3.9276347e-24], sum to 1.0000
[2019-03-23 10:27:00,481] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6006
[2019-03-23 10:27:00,489] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.5, 1.0, 2.0, 0.4549093991982819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518049.1965510637, 518049.196551064, 133730.0767880293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193000.0000, 
sim time next is 5193600.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4320411805894002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 491844.110288247, 491844.1102882473, 131216.5677402594], 
processed observation next is [1.0, 0.08695652173913043, 0.6060606060606063, 0.8633333333333334, 1.0, 1.0, 0.2900514757367502, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18216448529194335, 0.18216448529194343, 0.3200404091225839], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.06813133], dtype=float32), -0.92806715]. 
=============================================
[2019-03-23 10:27:01,523] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8077733e-15 1.0000000e+00 1.0196307e-21 1.2539949e-21 5.6474505e-24], sum to 1.0000
[2019-03-23 10:27:01,534] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7109
[2019-03-23 10:27:01,537] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 95.0, 1.0, 2.0, 0.8392447974977797, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344283942, 956349.1505961729, 956349.1505961729, 191722.2080350319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4806600.0000, 
sim time next is 4807200.0000, 
raw observation next is [22.0, 96.0, 1.0, 2.0, 0.9456107939578062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284634435367, 1077907.118519895, 1077907.118519895, 210400.2566621406], 
processed observation next is [1.0, 0.6521739130434783, 0.6363636363636364, 0.96, 1.0, 1.0, 0.9320134924472578, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206256, 0.3992248587110722, 0.3992248587110722, 0.5131713577125381], 
reward next is 0.4868, 
noisyNet noise sample is [array([-0.18011168], dtype=float32), 1.45777]. 
=============================================
[2019-03-23 10:27:05,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7213413e-13 1.0000000e+00 4.8341065e-20 2.2406882e-20 7.4718239e-22], sum to 1.0000
[2019-03-23 10:27:05,635] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1371
[2019-03-23 10:27:05,639] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3735943791233374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 419403.2034270405, 419403.2034270408, 121698.0831682279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4930200.0000, 
sim time next is 4930800.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3728970256442006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 418617.5189899665, 418617.5189899662, 121637.4031548709], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.2161212820552507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15504352555183945, 0.15504352555183934, 0.29667659306066074], 
reward next is 0.7033, 
noisyNet noise sample is [array([0.53512335], dtype=float32), 0.7024231]. 
=============================================
[2019-03-23 10:27:06,329] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7816067e-13 1.0000000e+00 7.9949423e-20 6.0187853e-19 3.1583191e-22], sum to 1.0000
[2019-03-23 10:27:06,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7510
[2019-03-23 10:27:06,348] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 92.0, 1.0, 2.0, 0.395935110612157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 446730.3512306605, 446730.3512306605, 124789.0753981127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4918800.0000, 
sim time next is 4919400.0000, 
raw observation next is [19.0, 94.0, 1.0, 2.0, 0.3915224532148444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 441312.3786047756, 441312.3786047759, 124151.7704161575], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.94, 1.0, 1.0, 0.2394030665185555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16344902911287984, 0.16344902911287995, 0.3028091961369695], 
reward next is 0.6972, 
noisyNet noise sample is [array([-2.3273048], dtype=float32), -1.2858725]. 
=============================================
[2019-03-23 10:27:10,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4009579e-16 1.0000000e+00 5.1505877e-22 2.6164913e-22 2.2673371e-25], sum to 1.0000
[2019-03-23 10:27:10,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5742
[2019-03-23 10:27:10,953] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2788553666872602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302788.5899777184, 302788.5899777181, 95977.29532100848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5009400.0000, 
sim time next is 5010000.0000, 
raw observation next is [17.0, 82.0, 1.0, 2.0, 0.2779352247381852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 301789.1653225396, 301789.1653225393, 95880.02017892257], 
processed observation next is [1.0, 1.0, 0.4090909090909091, 0.82, 1.0, 1.0, 0.0974190309227315, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11177376493427392, 0.11177376493427381, 0.23385370775346967], 
reward next is 0.7661, 
noisyNet noise sample is [array([0.7987559], dtype=float32), -1.6309719]. 
=============================================
[2019-03-23 10:27:10,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.470245]
 [75.470245]
 [75.470245]
 [75.470245]
 [75.470245]], R is [[75.48168945]
 [75.49278259]
 [75.50370026]
 [75.51451874]
 [75.52470398]].
[2019-03-23 10:27:12,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2500049e-13 1.0000000e+00 2.2434154e-21 7.0074450e-20 1.9346217e-23], sum to 1.0000
[2019-03-23 10:27:12,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2855
[2019-03-23 10:27:12,292] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666667, 84.0, 1.0, 2.0, 0.2721268677951454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295480.3870694334, 295480.3870694334, 94052.1013895089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5012400.0000, 
sim time next is 5013000.0000, 
raw observation next is [16.5, 85.0, 1.0, 2.0, 0.270232939941762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 293423.3047991807, 293423.304799181, 93254.88732884127], 
processed observation next is [0.0, 0.0, 0.38636363636363635, 0.85, 1.0, 1.0, 0.0877911749272025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10867529807377063, 0.10867529807377074, 0.2274509447044909], 
reward next is 0.7725, 
noisyNet noise sample is [array([-0.6784078], dtype=float32), 0.09225164]. 
=============================================
[2019-03-23 10:27:12,311] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.49431]
 [70.49431]
 [70.49431]
 [70.49431]
 [70.49431]], R is [[70.56192017]
 [70.62690735]
 [70.68929291]
 [70.7491684 ]
 [70.80815125]].
[2019-03-23 10:27:20,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0984438e-14 1.0000000e+00 1.6493272e-20 1.9537229e-19 2.2763709e-22], sum to 1.0000
[2019-03-23 10:27:20,713] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3037
[2019-03-23 10:27:20,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1562916.663563525 W.
[2019-03-23 10:27:20,724] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.8, 51.0, 1.0, 2.0, 0.6931714925421826, 1.0, 1.0, 0.6931714925421826, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1562916.663563525, 1562916.663563525, 288839.0923049091], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5326800.0000, 
sim time next is 5327400.0000, 
raw observation next is [29.9, 51.0, 1.0, 2.0, 0.466743923953428, 1.0, 2.0, 0.466743923953428, 1.0, 1.0, 0.9437249356094843, 6.911199999999999, 6.9112, 77.3421103, 1574806.160666475, 1574806.160666475, 341426.2027518879], 
processed observation next is [1.0, 0.6521739130434783, 0.9954545454545454, 0.51, 1.0, 1.0, 0.333429904941785, 1.0, 1.0, 0.333429904941785, 1.0, 0.5, 0.9196070508706919, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5832615409875833, 0.5832615409875833, 0.8327468359802144], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3447077], dtype=float32), -0.4868248]. 
=============================================
[2019-03-23 10:27:20,748] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1548030e-13 1.0000000e+00 4.4470579e-19 2.8895528e-19 1.0541067e-20], sum to 1.0000
[2019-03-23 10:27:20,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7072
[2019-03-23 10:27:20,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.6899946006261096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344315566, 786958.2313845264, 786958.2313845267, 167182.0625068035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5229600.0000, 
sim time next is 5230200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.7278931114242033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344353865, 830202.4288318651, 830202.4288318651, 172833.3298808995], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.6598663892802542, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206385, 0.3074823810488389, 0.3074823810488389, 0.42154470702658414], 
reward next is 0.5785, 
noisyNet noise sample is [array([-0.33019498], dtype=float32), 0.47305405]. 
=============================================
[2019-03-23 10:27:23,247] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2946581e-13 1.0000000e+00 7.3266709e-20 2.9005982e-18 2.8376511e-22], sum to 1.0000
[2019-03-23 10:27:23,253] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9562
[2019-03-23 10:27:23,257] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.9029233074446253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1029771.000268853, 1029771.000268853, 201986.9108508775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5242200.0000, 
sim time next is 5242800.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8863976288778728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1010717.434196761, 1010717.434196761, 199294.0706151924], 
processed observation next is [1.0, 0.6956521739130435, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.857997036097341, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.37433979044324484, 0.37433979044324484, 0.4860830990614449], 
reward next is 0.5139, 
noisyNet noise sample is [array([-0.6369901], dtype=float32), -0.4446559]. 
=============================================
[2019-03-23 10:27:27,771] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4490171e-12 1.0000000e+00 2.9207269e-19 1.6468787e-16 3.3056661e-20], sum to 1.0000
[2019-03-23 10:27:27,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7865
[2019-03-23 10:27:27,783] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.4926066601110737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561504.4036327157, 561504.4036327157, 141605.5730914455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5335200.0000, 
sim time next is 5335800.0000, 
raw observation next is [28.71666666666667, 51.83333333333334, 1.0, 2.0, 0.4853596150054807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 553570.4216004944, 553570.4216004944, 140289.4316906762], 
processed observation next is [1.0, 0.782608695652174, 0.9416666666666668, 0.5183333333333334, 1.0, 1.0, 0.35669951875685085, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20502608207425718, 0.20502608207425718, 0.3421693455870151], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.16086242], dtype=float32), 0.5877611]. 
=============================================
[2019-03-23 10:27:28,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7735921e-12 1.0000000e+00 4.8678431e-19 5.8646915e-18 5.6873062e-20], sum to 1.0000
[2019-03-23 10:27:28,113] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9115
[2019-03-23 10:27:28,121] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 90.0, 1.0, 2.0, 0.3229236141814408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 351644.2493624321, 351644.2493624324, 113095.2400403471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5463600.0000, 
sim time next is 5464200.0000, 
raw observation next is [17.2, 90.0, 1.0, 2.0, 0.3232221185051365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 351970.6876271881, 351970.6876271878, 113116.6384186741], 
processed observation next is [1.0, 0.21739130434782608, 0.41818181818181815, 0.9, 1.0, 1.0, 0.15402764813142059, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1303595139359956, 0.13035951393599549, 0.2758942400455466], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.20619741], dtype=float32), 0.5125661]. 
=============================================
[2019-03-23 10:27:28,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5941877e-11 1.0000000e+00 1.3592711e-17 3.6257514e-18 1.0243094e-20], sum to 1.0000
[2019-03-23 10:27:28,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3431
[2019-03-23 10:27:28,282] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 52.66666666666666, 1.0, 2.0, 0.4204568566596529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478035.7663767057, 478035.7663767057, 129467.3762360129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5341800.0000, 
sim time next is 5342400.0000, 
raw observation next is [26.1, 54.0, 1.0, 2.0, 0.4181025308419765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475140.0053196145, 475140.0053196145, 129050.2507599915], 
processed observation next is [1.0, 0.8695652173913043, 0.8227272727272728, 0.54, 1.0, 1.0, 0.2726281635524706, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17597777974800535, 0.17597777974800535, 0.31475670917071097], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.6495791], dtype=float32), -1.1235105]. 
=============================================
[2019-03-23 10:27:31,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9921971e-16 1.0000000e+00 5.2813918e-20 3.8465217e-20 6.1305568e-23], sum to 1.0000
[2019-03-23 10:27:31,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6385
[2019-03-23 10:27:31,342] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3558380742791467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396354.9853073673, 396354.9853073676, 118777.7552956398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5450400.0000, 
sim time next is 5451000.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3937383839429948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 438475.8232771831, 438475.8232771831, 121864.4152406062], 
processed observation next is [1.0, 0.08695652173913043, 0.44090909090909086, 0.97, 1.0, 1.0, 0.2421729799287435, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16239845306562337, 0.16239845306562337, 0.29723028107464927], 
reward next is 0.7028, 
noisyNet noise sample is [array([-1.8249437], dtype=float32), -0.018783642]. 
=============================================
[2019-03-23 10:27:31,358] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.87651]
 [67.87651]
 [67.87651]
 [67.87651]
 [67.87651]], R is [[67.9005127 ]
 [67.93180847]
 [67.9614563 ]
 [67.98946381]
 [68.01586914]].
[2019-03-23 10:27:31,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1280451e-14 1.0000000e+00 8.6985039e-22 1.8950068e-20 1.8361484e-22], sum to 1.0000
[2019-03-23 10:27:31,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8586
[2019-03-23 10:27:31,688] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.2, 82.5, 1.0, 2.0, 0.3032737142136486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 72.46276211267944, 329319.1471886617, 329319.147188662, 76369.17988295808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5796600.0000, 
sim time next is 5797200.0000, 
raw observation next is [13.1, 82.0, 1.0, 2.0, 0.36538597538087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396784.1641650766, 396784.1641650769, 85847.45489937464], 
processed observation next is [1.0, 0.08695652173913043, 0.2318181818181818, 0.82, 1.0, 1.0, 0.20673246922608746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14695709783891728, 0.1469570978389174, 0.20938403633993816], 
reward next is 0.7906, 
noisyNet noise sample is [array([1.1533862], dtype=float32), -0.8329179]. 
=============================================
[2019-03-23 10:27:33,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5947512e-13 1.0000000e+00 1.9448583e-20 8.2453038e-19 1.9407653e-22], sum to 1.0000
[2019-03-23 10:27:33,684] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9960
[2019-03-23 10:27:33,689] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 78.0, 1.0, 2.0, 0.8873131743379532, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012669.931356388, 1012669.931356388, 198021.0783453604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5481000.0000, 
sim time next is 5481600.0000, 
raw observation next is [24.23333333333333, 76.66666666666666, 1.0, 2.0, 0.9956294139663969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.002231540776014, 6.9112, 77.32828281800357, 1165742.265883505, 1136177.152415463, 218304.2961322994], 
processed observation next is [1.0, 0.43478260869565216, 0.7378787878787878, 0.7666666666666666, 1.0, 1.0, 0.994536767457996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.009103154077601427, 0.0, 0.508427625321373, 0.43175639477166855, 0.42080635274646777, 0.5324495027617059], 
reward next is 0.0124, 
noisyNet noise sample is [array([0.8375054], dtype=float32), 1.490218]. 
=============================================
[2019-03-23 10:27:33,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1721343e-13 1.0000000e+00 3.2823570e-20 6.4245297e-21 2.9955352e-21], sum to 1.0000
[2019-03-23 10:27:33,895] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7184
[2019-03-23 10:27:33,902] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 82.0, 1.0, 2.0, 0.909755964030951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1038499.669351031, 1038499.669351031, 199244.3565117414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5479200.0000, 
sim time next is 5479800.0000, 
raw observation next is [23.08333333333334, 80.66666666666667, 1.0, 2.0, 0.9750117840370619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1113205.07124757, 1113205.07124757, 212011.1240558046], 
processed observation next is [1.0, 0.43478260869565216, 0.6856060606060609, 0.8066666666666668, 1.0, 1.0, 0.9687647300463272, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.41229817453613704, 0.41229817453613704, 0.5171003025751332], 
reward next is 0.4829, 
noisyNet noise sample is [array([0.7755393], dtype=float32), 0.48723328]. 
=============================================
[2019-03-23 10:27:37,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7376053e-12 1.0000000e+00 2.3653669e-19 5.3207261e-19 1.0491758e-21], sum to 1.0000
[2019-03-23 10:27:37,887] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4067
[2019-03-23 10:27:37,892] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 90.0, 1.0, 2.0, 0.4282060805361732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486507.013255471, 486507.013255471, 129943.186070107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5551800.0000, 
sim time next is 5552400.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4247483549473416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 482582.5407914596, 482582.5407914593, 129607.684722063], 
processed observation next is [1.0, 0.2608695652173913, 0.5681818181818182, 0.9, 1.0, 1.0, 0.28093544368417694, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17873427436720726, 0.17873427436720715, 0.3161163042001537], 
reward next is 0.6839, 
noisyNet noise sample is [array([1.3846306], dtype=float32), -0.05560998]. 
=============================================
[2019-03-23 10:27:44,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4438723e-14 1.0000000e+00 1.4686049e-20 1.2853502e-20 1.7093832e-23], sum to 1.0000
[2019-03-23 10:27:44,173] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6950
[2019-03-23 10:27:44,182] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 97.0, 1.0, 2.0, 0.3229415006497224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353121.7489254708, 353121.7489254708, 113608.7048024116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5644800.0000, 
sim time next is 5645400.0000, 
raw observation next is [16.51666666666667, 96.83333333333334, 1.0, 2.0, 0.3192319337842606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 348263.8910562976, 348263.8910562976, 113060.8529179188], 
processed observation next is [0.0, 0.34782608695652173, 0.38712121212121225, 0.9683333333333334, 1.0, 1.0, 0.14903991723032575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12898662631714725, 0.12898662631714725, 0.2757581778485825], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.68680596], dtype=float32), -0.96724707]. 
=============================================
[2019-03-23 10:27:49,217] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 10:27:49,220] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:27:49,222] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:27:49,222] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:49,223] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:49,224] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:27:49,226] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:27:49,227] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:49,229] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:27:49,230] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:49,230] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:27:49,251] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 10:27:49,278] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 10:27:49,279] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 10:27:49,279] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 10:27:49,301] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 10:28:13,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47686338]
[2019-03-23 10:28:13,906] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.6, 76.0, 1.0, 2.0, 0.2924396367437925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 317523.7970562039, 317523.7970562039, 100112.2109379859]
[2019-03-23 10:28:13,908] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:28:13,911] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.0097398e-14 1.0000000e+00 6.0016069e-21 3.1624333e-20 8.5531619e-23], sampled 0.08280418086266073
[2019-03-23 10:28:41,577] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47686338]
[2019-03-23 10:28:41,577] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 91.0, 1.0, 2.0, 0.315364517071785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342988.0075399734, 342988.0075399734, 112421.1669580742]
[2019-03-23 10:28:41,579] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:28:41,582] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0097398e-14 1.0000000e+00 6.0016069e-21 3.1624333e-20 8.5531619e-23], sampled 0.46534645023418464
[2019-03-23 10:29:01,146] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47686338]
[2019-03-23 10:29:01,146] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.6, 64.33333333333334, 1.0, 2.0, 0.4348525134818228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495016.983809417, 495016.983809417, 131470.0609977097]
[2019-03-23 10:29:01,147] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:29:01,154] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.0097398e-14 1.0000000e+00 6.0016069e-21 3.1624333e-20 8.5531619e-23], sampled 0.6494362957787655
[2019-03-23 10:29:28,690] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:29:29,282] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:29:29,456] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:29:29,473] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:29:29,569] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:29:30,584] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1850000, evaluation results [1850000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:29:31,195] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4751844e-14 1.0000000e+00 4.5246376e-21 3.2581678e-20 1.0942696e-24], sum to 1.0000
[2019-03-23 10:29:31,200] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0386
[2019-03-23 10:29:31,204] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.8, 95.83333333333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 127572.5521543788, 127572.5521543785, 54935.64790873558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5723400.0000, 
sim time next is 5724000.0000, 
raw observation next is [8.8, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 127187.4389903195, 127187.4389903198, 54894.15875724972], 
processed observation next is [0.0, 0.2608695652173913, 0.0363636363636364, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.047106458885303515, 0.04710645888530363, 0.13388819209085298], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16727383], dtype=float32), -0.13441725]. 
=============================================
[2019-03-23 10:29:31,219] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.02182]
 [74.02182]
 [74.02182]
 [74.02182]
 [74.02182]], R is [[73.28160095]
 [72.54878235]
 [71.82329559]
 [71.10506439]
 [70.39401245]].
[2019-03-23 10:29:36,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1378362e-13 1.0000000e+00 4.6095706e-20 5.0708395e-19 5.1970868e-22], sum to 1.0000
[2019-03-23 10:29:36,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0613
[2019-03-23 10:29:36,704] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.65, 84.0, 1.0, 2.0, 0.2680755004307636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 291080.0209821147, 291080.0209821144, 93363.86196085908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5891400.0000, 
sim time next is 5892000.0000, 
raw observation next is [16.83333333333333, 82.0, 1.0, 2.0, 0.2655713016563089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288360.1218204914, 288360.1218204914, 92505.68223752017], 
processed observation next is [1.0, 0.17391304347826086, 0.4015151515151513, 0.82, 1.0, 1.0, 0.08196412707038608, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10680004511870052, 0.10680004511870052, 0.22562361521346383], 
reward next is 0.7744, 
noisyNet noise sample is [array([-0.45351976], dtype=float32), -0.114700995]. 
=============================================
[2019-03-23 10:29:36,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.52962]
 [70.52962]
 [70.52962]
 [70.52962]
 [70.52962]], R is [[70.59869385]
 [70.66499329]
 [70.72802734]
 [70.7866745 ]
 [70.84682465]].
[2019-03-23 10:29:44,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7546381e-13 1.0000000e+00 1.2257688e-21 8.5741431e-21 4.7009069e-24], sum to 1.0000
[2019-03-23 10:29:44,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0234
[2019-03-23 10:29:44,451] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.26666666666667, 80.33333333333333, 1.0, 2.0, 0.2494364252474355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 270835.824666384, 270835.8246663837, 84416.99619143596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6054000.0000, 
sim time next is 6054600.0000, 
raw observation next is [16.18333333333333, 80.16666666666667, 1.0, 2.0, 0.2468982299387384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 268079.1155170578, 268079.1155170575, 83520.65034382598], 
processed observation next is [1.0, 0.043478260869565216, 0.37196969696969684, 0.8016666666666667, 1.0, 1.0, 0.05862278742342297, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09928856130261401, 0.09928856130261388, 0.20370890327762434], 
reward next is 0.7963, 
noisyNet noise sample is [array([-0.42340037], dtype=float32), -0.73822397]. 
=============================================
[2019-03-23 10:29:48,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3421411e-15 1.0000000e+00 1.5646737e-23 1.0502810e-21 1.7013861e-25], sum to 1.0000
[2019-03-23 10:29:48,870] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4025
[2019-03-23 10:29:48,876] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 46.0, 1.0, 2.0, 0.8269499646176546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911855.9393490432, 911855.9393490432, 166827.6815792164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6100800.0000, 
sim time next is 6101400.0000, 
raw observation next is [24.3, 45.5, 1.0, 2.0, 0.8261247477434641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 910918.9990284728, 910918.9990284732, 166707.86492014], 
processed observation next is [1.0, 0.6086956521739131, 0.740909090909091, 0.455, 1.0, 1.0, 0.7826559346793301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3373774070475825, 0.3373774070475827, 0.4066045485857073], 
reward next is 0.5934, 
noisyNet noise sample is [array([-0.6467163], dtype=float32), -0.008231149]. 
=============================================
[2019-03-23 10:29:54,355] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2301818e-13 1.0000000e+00 1.8168859e-19 8.6306888e-20 4.8162288e-22], sum to 1.0000
[2019-03-23 10:29:54,362] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0729
[2019-03-23 10:29:54,371] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 71.0, 1.0, 2.0, 0.4727470371524771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 532420.2227208886, 532420.2227208882, 131590.9011857076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6179400.0000, 
sim time next is 6180000.0000, 
raw observation next is [22.0, 71.0, 1.0, 2.0, 0.5157822072426558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 581420.6369544042, 581420.6369544044, 136255.254994485], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.71, 1.0, 1.0, 0.3947277590533197, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21534097664977933, 0.21534097664977941, 0.33232989023045123], 
reward next is 0.6677, 
noisyNet noise sample is [array([1.4296914], dtype=float32), -0.9660741]. 
=============================================
[2019-03-23 10:29:54,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.61281]
 [68.61281]
 [68.61281]
 [68.61281]
 [68.61281]], R is [[68.59435272]
 [68.58745575]
 [68.56441498]
 [68.49332428]
 [68.40660858]].
[2019-03-23 10:29:57,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.99724696e-12 1.00000000e+00 5.66915781e-19 1.33409956e-17
 8.80702623e-20], sum to 1.0000
[2019-03-23 10:29:57,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6221
[2019-03-23 10:29:57,403] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 83.5, 1.0, 2.0, 0.482884282187117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 550978.8271423334, 550978.8271423331, 139373.0563816174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6316200.0000, 
sim time next is 6316800.0000, 
raw observation next is [22.9, 84.0, 1.0, 2.0, 0.4828177391463732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 550914.1766338851, 550914.1766338855, 139302.1047923789], 
processed observation next is [0.0, 0.08695652173913043, 0.6772727272727272, 0.84, 1.0, 1.0, 0.3535221739329665, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2040422876421797, 0.2040422876421798, 0.33976123120092416], 
reward next is 0.6602, 
noisyNet noise sample is [array([2.0677578], dtype=float32), 1.3503922]. 
=============================================
[2019-03-23 10:29:59,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.4521216e-11 1.0000000e+00 1.1332775e-16 1.5980433e-16 1.8576686e-18], sum to 1.0000
[2019-03-23 10:29:59,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4209
[2019-03-23 10:29:59,070] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 59.0, 1.0, 2.0, 0.5271187211059866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599308.8364742039, 599308.8364742039, 146928.7751619645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6289200.0000, 
sim time next is 6289800.0000, 
raw observation next is [28.11666666666667, 59.5, 1.0, 2.0, 0.5262799226725623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 598523.477499717, 598523.4774997167, 146726.761548842], 
processed observation next is [0.0, 0.8260869565217391, 0.9143939393939395, 0.595, 1.0, 1.0, 0.4078499033407028, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22167536203693222, 0.2216753620369321, 0.3578701501191269], 
reward next is 0.6421, 
noisyNet noise sample is [array([-0.61650515], dtype=float32), 1.0371635]. 
=============================================
[2019-03-23 10:30:01,778] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4451881e-13 1.0000000e+00 2.7590930e-19 5.2324442e-19 1.1546527e-21], sum to 1.0000
[2019-03-23 10:30:01,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8108
[2019-03-23 10:30:01,794] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 63.0, 1.0, 2.0, 0.5527106775631407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 626749.3851181747, 626749.3851181747, 150931.166326169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6370200.0000, 
sim time next is 6370800.0000, 
raw observation next is [27.9, 63.66666666666666, 1.0, 2.0, 0.5537471184868261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 627822.228094971, 627822.228094971, 151105.2846165162], 
processed observation next is [0.0, 0.7391304347826086, 0.9045454545454544, 0.6366666666666666, 1.0, 1.0, 0.4421838981085326, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23252675114628557, 0.23252675114628557, 0.3685494746744298], 
reward next is 0.6315, 
noisyNet noise sample is [array([-1.0326853], dtype=float32), -0.4375043]. 
=============================================
[2019-03-23 10:30:02,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7898505e-13 1.0000000e+00 3.9319344e-18 4.2472685e-18 4.7809028e-21], sum to 1.0000
[2019-03-23 10:30:02,289] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4300
[2019-03-23 10:30:02,293] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 79.0, 1.0, 2.0, 0.5680139854327776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 643140.6616727517, 643140.6616727517, 153279.1389862543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6379200.0000, 
sim time next is 6379800.0000, 
raw observation next is [25.41666666666666, 79.33333333333334, 1.0, 2.0, 0.5663931096331004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 641458.7142524117, 641458.7142524117, 153012.4975225381], 
processed observation next is [0.0, 0.8695652173913043, 0.7916666666666664, 0.7933333333333334, 1.0, 1.0, 0.4579913870413755, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23757730157496731, 0.23757730157496731, 0.3732012134696051], 
reward next is 0.6268, 
noisyNet noise sample is [array([-0.53916943], dtype=float32), 0.68979156]. 
=============================================
[2019-03-23 10:30:19,254] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 10:30:19,257] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:30:19,258] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:30:19,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:30:19,261] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:30:19,261] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:30:19,262] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:30:19,263] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:30:19,260] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:30:19,266] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:30:19,266] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:30:19,288] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 10:30:19,313] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 10:30:19,337] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 10:30:19,340] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 10:30:19,361] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 10:30:25,615] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:30:25,616] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.6, 66.0, 1.0, 2.0, 0.5616842239295922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 632486.4442445417, 632486.4442445413, 145236.2493952943]
[2019-03-23 10:30:25,616] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:30:25,621] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.8617436235035708
[2019-03-23 10:30:29,815] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:30:29,816] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.96378055, 91.18015154, 1.0, 2.0, 0.4887992448980705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 557682.4174635332, 557682.4174635332, 144286.0446864816]
[2019-03-23 10:30:29,817] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:30:29,821] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.02753517891961521
[2019-03-23 10:30:31,904] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:30:31,905] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.76666666666667, 57.0, 1.0, 2.0, 0.3154273673810712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 343826.1660662665, 343826.1660662662, 117008.3789267197]
[2019-03-23 10:30:31,906] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:30:31,910] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.10553579429505
[2019-03-23 10:31:11,492] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:31:11,493] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.3271084055835137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 357886.7852649736, 357886.7852649739, 113980.6100207005]
[2019-03-23 10:31:11,495] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:31:11,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.2531076298686191
[2019-03-23 10:31:17,116] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:31:17,118] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.031180345, 73.06394985333333, 1.0, 2.0, 0.3611169245214805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 403877.1502791893, 403877.1502791896, 124246.7443170172]
[2019-03-23 10:31:17,119] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:31:17,122] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.1923931105609048
[2019-03-23 10:31:47,321] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:31:47,322] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.52990127, 82.07645295, 1.0, 2.0, 0.2936883591712605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318879.9889839359, 318879.9889839359, 110140.7764831679]
[2019-03-23 10:31:47,322] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:31:47,324] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.1181658884339507
[2019-03-23 10:31:54,086] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.46648544]
[2019-03-23 10:31:54,087] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.55246281, 84.730605365, 1.0, 2.0, 0.4089243645766303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 465023.8641731691, 465023.8641731691, 132787.0623306492]
[2019-03-23 10:31:54,090] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:31:54,092] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.30260386e-13 1.00000000e+00 1.94141891e-20 1.03274934e-19
 3.24382835e-22], sampled 0.6557507157362671
[2019-03-23 10:31:59,093] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:31:59,121] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:31:59,255] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:31:59,302] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:31:59,438] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:32:00,452] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1875000, evaluation results [1875000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:32:00,765] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6979325e-15 1.0000000e+00 5.0296433e-22 4.3247087e-21 4.4448437e-23], sum to 1.0000
[2019-03-23 10:32:00,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-23 10:32:00,780] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.6825821147033578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 763752.1966554319, 763752.1966554315, 153015.7209612036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6711600.0000, 
sim time next is 6712200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.7076730286618307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 791875.1749016488, 791875.174901649, 156163.4179252149], 
processed observation next is [1.0, 0.6956521739130435, 0.4681818181818182, 0.93, 1.0, 1.0, 0.6345912858272884, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2932871018154255, 0.29328710181542555, 0.38088638518345097], 
reward next is 0.6191, 
noisyNet noise sample is [array([0.04989741], dtype=float32), -0.3722003]. 
=============================================
[2019-03-23 10:32:02,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2614343e-13 1.0000000e+00 2.2523430e-20 2.0620554e-19 1.2739994e-22], sum to 1.0000
[2019-03-23 10:32:02,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3072
[2019-03-23 10:32:02,550] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 100.0, 1.0, 2.0, 0.3411667141418419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 378650.0009582135, 378650.0009582135, 117040.6899468316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6742800.0000, 
sim time next is 6743400.0000, 
raw observation next is [17.2, 98.83333333333334, 1.0, 2.0, 0.3402290725018242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377187.617767767, 377187.617767767, 116795.4804489139], 
processed observation next is [1.0, 0.043478260869565216, 0.41818181818181815, 0.9883333333333334, 1.0, 1.0, 0.17528634062728024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13969911769176555, 0.13969911769176555, 0.28486702548515586], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.6221506], dtype=float32), -1.6754342]. 
=============================================
[2019-03-23 10:32:03,324] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2802959e-14 1.0000000e+00 1.3942654e-21 3.3306780e-20 4.0668702e-23], sum to 1.0000
[2019-03-23 10:32:03,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4909
[2019-03-23 10:32:03,332] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 99.5, 1.0, 2.0, 0.3616353099777824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 404061.8108968242, 404061.8108968239, 119789.837097744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6731400.0000, 
sim time next is 6732000.0000, 
raw observation next is [17.7, 100.0, 1.0, 2.0, 0.3648719829031241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407974.971760404, 407974.971760404, 120188.9277730229], 
processed observation next is [1.0, 0.9565217391304348, 0.44090909090909086, 1.0, 1.0, 1.0, 0.20608997862890513, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15110184139274221, 0.15110184139274221, 0.2931437262756656], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.82691026], dtype=float32), 0.6627011]. 
=============================================
[2019-03-23 10:32:03,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.49549]
 [69.49549]
 [69.49549]
 [69.49549]
 [69.49549]], R is [[69.50740051]
 [69.52015686]
 [69.53340912]
 [69.54675293]
 [69.56038666]].
[2019-03-23 10:32:05,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2925705e-13 1.0000000e+00 6.0149265e-20 1.0446208e-18 9.9542978e-22], sum to 1.0000
[2019-03-23 10:32:05,754] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8414
[2019-03-23 10:32:05,757] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 75.16666666666667, 1.0, 2.0, 0.4003068646311877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 452674.6514718512, 452674.6514718515, 125770.3538795809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6821400.0000, 
sim time next is 6822000.0000, 
raw observation next is [21.6, 76.0, 1.0, 2.0, 0.3993626293498188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451368.4349880773, 451368.4349880773, 125540.7308191262], 
processed observation next is [1.0, 1.0, 0.6181818181818183, 0.76, 1.0, 1.0, 0.24920328668727348, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16717349444002863, 0.16717349444002863, 0.3061969044368932], 
reward next is 0.6938, 
noisyNet noise sample is [array([0.6022838], dtype=float32), 0.042285338]. 
=============================================
[2019-03-23 10:32:05,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.90608]
 [68.90608]
 [68.90608]
 [68.90608]
 [68.90608]], R is [[68.91082764]
 [68.91496277]
 [68.91819763]
 [68.92024994]
 [68.92152405]].
[2019-03-23 10:32:06,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7269626e-13 1.0000000e+00 2.6384153e-19 2.3037874e-19 1.6172096e-21], sum to 1.0000
[2019-03-23 10:32:06,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4039
[2019-03-23 10:32:06,149] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 71.0, 1.0, 2.0, 0.4063226113451103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 460385.9135840933, 460385.9135840933, 126901.2198640911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6818400.0000, 
sim time next is 6819000.0000, 
raw observation next is [22.51666666666667, 71.83333333333334, 1.0, 2.0, 0.4075708034054413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461729.7404420506, 461729.7404420506, 126971.0044281856], 
processed observation next is [1.0, 0.9565217391304348, 0.659848484848485, 0.7183333333333334, 1.0, 1.0, 0.25946350425680154, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17101101497853727, 0.17101101497853727, 0.3096853766541112], 
reward next is 0.6903, 
noisyNet noise sample is [array([1.2591537], dtype=float32), 0.04336921]. 
=============================================
[2019-03-23 10:32:06,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.334274]
 [69.334274]
 [69.334274]
 [69.334274]
 [69.334274]], R is [[69.33124542]
 [69.32841492]
 [69.32649231]
 [69.32543182]
 [69.32522583]].
[2019-03-23 10:32:14,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.5890301e-12 1.0000000e+00 3.9004707e-19 7.8716906e-18 1.9655115e-19], sum to 1.0000
[2019-03-23 10:32:14,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6791
[2019-03-23 10:32:14,825] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 77.5, 1.0, 2.0, 0.4724695954014746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 539111.6443574842, 539111.6443574845, 137579.5744897374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6993000.0000, 
sim time next is 6993600.0000, 
raw observation next is [23.46666666666667, 78.0, 1.0, 2.0, 0.4719152480968442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538476.2759714761, 538476.2759714763, 137497.6232402388], 
processed observation next is [0.0, 0.9565217391304348, 0.7030303030303031, 0.78, 1.0, 1.0, 0.3398940601210552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19943565776721336, 0.19943565776721345, 0.3353600566835093], 
reward next is 0.6646, 
noisyNet noise sample is [array([-0.703444], dtype=float32), -1.5532464]. 
=============================================
[2019-03-23 10:32:17,162] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2633352e-13 1.0000000e+00 2.5877094e-19 4.6940936e-18 4.0331174e-21], sum to 1.0000
[2019-03-23 10:32:17,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3051
[2019-03-23 10:32:17,176] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 97.0, 1.0, 2.0, 0.6220963543247509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 702916.8408460031, 702916.8408460031, 149074.8719921183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7032600.0000, 
sim time next is 7033200.0000, 
raw observation next is [18.8, 97.0, 1.0, 2.0, 0.5906481320371125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 667287.9099860733, 667287.9099860733, 145290.9673681012], 
processed observation next is [1.0, 0.391304347826087, 0.49090909090909096, 0.97, 1.0, 1.0, 0.48831016504639063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.24714367036521231, 0.24714367036521231, 0.35436821309292976], 
reward next is 0.6456, 
noisyNet noise sample is [array([0.4865138], dtype=float32), -0.24569616]. 
=============================================
[2019-03-23 10:32:17,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.8426854e-13 1.0000000e+00 9.0949532e-19 1.1442543e-17 7.0980026e-20], sum to 1.0000
[2019-03-23 10:32:17,578] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7730
[2019-03-23 10:32:17,584] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.4570858388304922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 521259.9939512297, 521259.99395123, 134990.3161223205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6999000.0000, 
sim time next is 6999600.0000, 
raw observation next is [22.2, 84.0, 1.0, 2.0, 0.4567019411022332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 520820.4802582015, 520820.4802582018, 134946.52727272], 
processed observation next is [1.0, 0.0, 0.6454545454545454, 0.84, 1.0, 1.0, 0.3208774263777915, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19289647416970426, 0.19289647416970437, 0.32913787139687806], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.38883376], dtype=float32), -1.6924795]. 
=============================================
[2019-03-23 10:32:17,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5413846e-13 1.0000000e+00 1.3271689e-20 3.6169910e-19 6.6138891e-22], sum to 1.0000
[2019-03-23 10:32:17,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5264
[2019-03-23 10:32:17,861] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 55.0, 1.0, 2.0, 0.3176576905154065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 345519.6629993082, 345519.6629993079, 112592.334260119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7150800.0000, 
sim time next is 7151400.0000, 
raw observation next is [21.6, 56.0, 1.0, 2.0, 0.3123885386229151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 339212.5008221976, 339212.5008221979, 112029.8592437278], 
processed observation next is [1.0, 0.782608695652174, 0.6181818181818183, 0.56, 1.0, 1.0, 0.14048567327864386, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12563425956377688, 0.125634259563777, 0.2732435591310434], 
reward next is 0.7268, 
noisyNet noise sample is [array([1.6094285], dtype=float32), 0.7193788]. 
=============================================
[2019-03-23 10:32:23,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0379773e-14 1.0000000e+00 1.5793606e-22 5.2564056e-21 6.5859649e-23], sum to 1.0000
[2019-03-23 10:32:23,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0277
[2019-03-23 10:32:23,242] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 80.33333333333333, 1.0, 2.0, 0.2055603351356421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 223184.630755809, 223184.6307558087, 72645.03969856685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7177200.0000, 
sim time next is 7177800.0000, 
raw observation next is [14.25, 81.16666666666667, 1.0, 2.0, 0.2034577860410507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 220901.2953073437, 220901.2953073434, 72303.91293998313], 
processed observation next is [1.0, 0.043478260869565216, 0.2840909090909091, 0.8116666666666668, 1.0, 1.0, 0.004322232551313351, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08181529455827545, 0.08181529455827533, 0.17635100717069055], 
reward next is 0.8236, 
noisyNet noise sample is [array([-2.1454206], dtype=float32), 1.8761256]. 
=============================================
[2019-03-23 10:32:30,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5698165e-14 1.0000000e+00 1.0031113e-20 9.2551397e-20 8.2708311e-24], sum to 1.0000
[2019-03-23 10:32:30,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2570
[2019-03-23 10:32:30,464] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 67.5, 1.0, 2.0, 0.2659305906457725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288750.357408266, 288750.3574082658, 89651.94568457293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7253400.0000, 
sim time next is 7254000.0000, 
raw observation next is [18.3, 68.0, 1.0, 2.0, 0.2658023927495355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 288611.1174210529, 288611.1174210526, 89523.93346668355], 
processed observation next is [1.0, 1.0, 0.4681818181818182, 0.68, 1.0, 1.0, 0.08225299093691935, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10689300645224181, 0.1068930064522417, 0.21835105723581352], 
reward next is 0.7816, 
noisyNet noise sample is [array([0.20403086], dtype=float32), 1.1077836]. 
=============================================
[2019-03-23 10:32:30,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.97315]
 [70.97315]
 [70.97315]
 [70.97315]
 [70.97315]], R is [[71.04506683]
 [71.11595154]
 [71.18580627]
 [71.25457764]
 [71.32223511]].
[2019-03-23 10:32:36,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6824160e-12 1.0000000e+00 7.5161133e-20 4.6158039e-18 1.4497521e-20], sum to 1.0000
[2019-03-23 10:32:36,244] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9713
[2019-03-23 10:32:36,248] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3199884337881482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 349480.3518388549, 349480.3518388549, 113252.5082287371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7364400.0000, 
sim time next is 7365000.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3226155095210239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352360.7723392691, 352360.7723392688, 113441.8773758516], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.87, 1.0, 1.0, 0.15326938690127986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13050398975528485, 0.13050398975528474, 0.27668750579476004], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.01386671], dtype=float32), 1.0231053]. 
=============================================
[2019-03-23 10:32:36,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.93181]
 [68.93181]
 [68.93181]
 [68.93181]
 [68.93181]], R is [[68.96579742]
 [68.99991608]
 [69.03416443]
 [69.06771088]
 [69.09880829]].
[2019-03-23 10:32:41,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0717135e-12 1.0000000e+00 4.1471380e-19 1.3711397e-17 3.6604209e-20], sum to 1.0000
[2019-03-23 10:32:41,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7306
[2019-03-23 10:32:41,988] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 70.66666666666667, 1.0, 2.0, 0.4525117243922129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516082.6810059867, 516082.6810059867, 134589.2335200417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7507200.0000, 
sim time next is 7507800.0000, 
raw observation next is [24.1, 71.5, 1.0, 2.0, 0.4540598878160192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517879.6437557714, 517879.6437557714, 134819.2941018456], 
processed observation next is [0.0, 0.9130434782608695, 0.7318181818181819, 0.715, 1.0, 1.0, 0.317574859770024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1918072754651005, 0.1918072754651005, 0.3288275465898673], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.7314026], dtype=float32), 0.2979635]. 
=============================================
[2019-03-23 10:32:47,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:32:47,152] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:47,199] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 10:32:49,149] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 10:32:49,150] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:32:49,150] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:49,152] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:32:49,152] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:32:49,152] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:49,153] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:32:49,154] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:49,155] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:49,153] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:32:49,159] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:32:49,180] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 10:32:49,180] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 10:32:49,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 10:32:49,256] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 10:32:49,283] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 10:32:58,948] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:32:58,949] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.51378117666667, 63.95370328333333, 1.0, 2.0, 0.4065430488232278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 459450.0125004718, 459450.0125004715, 130511.3931032513]
[2019-03-23 10:32:58,950] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:32:58,952] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.9379511443706803
[2019-03-23 10:33:14,853] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:33:14,856] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 80.0, 1.0, 2.0, 0.422191397607427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 480459.1331546876, 480459.1331546872, 134411.2178975368]
[2019-03-23 10:33:14,858] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:33:14,862] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.7915730160445678
[2019-03-23 10:33:17,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:33:17,363] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.1, 48.0, 1.0, 2.0, 0.3539070287967809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 394499.4640407321, 394499.4640407321, 123070.8168724185]
[2019-03-23 10:33:17,365] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:33:17,367] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.8928792001209921
[2019-03-23 10:33:41,248] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:33:41,250] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.746254615, 98.74862502, 1.0, 2.0, 0.3223971426125242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 353823.122114723, 353823.1221147226, 118358.3651109786]
[2019-03-23 10:33:41,252] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:33:41,254] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.04076152326564042
[2019-03-23 10:33:44,271] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:33:44,272] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [28.73333333333333, 52.66666666666667, 1.0, 2.0, 0.7824446364425558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 892158.7840377371, 892158.7840377367, 185841.7741539647]
[2019-03-23 10:33:44,274] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:33:44,277] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.5120222077341005
[2019-03-23 10:33:47,815] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:33:47,817] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [30.6, 48.0, 1.0, 2.0, 0.7522876344139058, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9610434164459538, 6.935857314224141, 6.9112, 95.55328722387866, 1401538.819529753, 1391643.252331192, 302980.7839559923]
[2019-03-23 10:33:47,819] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:33:47,822] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.20956185405103012
[2019-03-23 10:33:47,823] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1401538.819529753 W.
[2019-03-23 10:33:58,390] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:33:58,391] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.5, 83.0, 1.0, 2.0, 0.4105895271946146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 466634.1235858407, 466634.1235858407, 128353.0501900908]
[2019-03-23 10:33:58,392] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:33:58,395] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.7472167973436452
[2019-03-23 10:34:10,515] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:34:10,515] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.5, 76.0, 1.0, 2.0, 0.358389248163288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400282.8401446967, 400282.8401446967, 119456.5590217559]
[2019-03-23 10:34:10,518] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:34:10,519] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.7505049167777236
[2019-03-23 10:34:14,834] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:34:14,837] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.67057743333334, 91.15275971666665, 1.0, 2.0, 0.4243027121100838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 482683.1342506542, 482683.1342506542, 134443.9739145719]
[2019-03-23 10:34:14,838] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:34:14,840] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.3164188215911883
[2019-03-23 10:34:15,633] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:34:15,634] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.17858408, 88.95707564, 1.0, 2.0, 0.4018522808488563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 436364.4986900182, 436364.4986900182, 113150.5516476009]
[2019-03-23 10:34:15,635] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:34:15,638] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.8629343889561685
[2019-03-23 10:34:25,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.49157372]
[2019-03-23 10:34:25,597] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.35376591, 98.96445527166668, 1.0, 2.0, 0.4056090481883662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 460304.7768075112, 460304.7768075108, 131684.1969646765]
[2019-03-23 10:34:25,598] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:34:25,603] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.1355842e-12 1.0000000e+00 3.4549664e-19 1.8127053e-18 8.0251577e-21], sampled 0.2413457974791946
[2019-03-23 10:34:29,020] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:34:29,124] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:34:29,211] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:34:29,389] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:34:29,436] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:34:30,452] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1900000, evaluation results [1900000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:34:32,283] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2597223e-13 1.0000000e+00 2.1140099e-19 2.5596603e-19 3.5343053e-21], sum to 1.0000
[2019-03-23 10:34:32,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6514
[2019-03-23 10:34:32,293] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4353304895673298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495205.8245173619, 495205.8245173619, 131168.336606083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7621200.0000, 
sim time next is 7621800.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4341111433436372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 493813.4979632529, 493813.4979632532, 131041.515874987], 
processed observation next is [1.0, 0.21739130434782608, 0.5454545454545454, 0.96, 1.0, 1.0, 0.2926389291795465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1828938881345381, 0.18289388813453822, 0.31961345335362684], 
reward next is 0.6804, 
noisyNet noise sample is [array([-1.5261314], dtype=float32), 1.532595]. 
=============================================
[2019-03-23 10:34:34,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6716221e-13 1.0000000e+00 8.3922540e-20 5.7560180e-19 1.5463933e-21], sum to 1.0000
[2019-03-23 10:34:34,102] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8594
[2019-03-23 10:34:34,107] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 93.0, 1.0, 2.0, 0.4503933636229362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 513159.7977592946, 513159.7977592949, 133565.4960077753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7688400.0000, 
sim time next is 7689000.0000, 
raw observation next is [20.6, 93.0, 1.0, 2.0, 0.4455256967469054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507423.430137087, 507423.430137087, 132831.8516482842], 
processed observation next is [1.0, 1.0, 0.5727272727272728, 0.93, 1.0, 1.0, 0.3069071209336317, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18793460375447668, 0.18793460375447668, 0.3239801259714249], 
reward next is 0.6760, 
noisyNet noise sample is [array([-2.0514824], dtype=float32), 0.236534]. 
=============================================
[2019-03-23 10:34:34,128] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.55257]
 [66.55257]
 [66.55257]
 [66.55257]
 [66.55257]], R is [[66.56306458]
 [66.57167053]
 [66.57849884]
 [66.58379364]
 [66.58790588]].
[2019-03-23 10:34:34,323] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2179652e-14 1.0000000e+00 1.0242625e-20 3.1903400e-19 3.6589234e-22], sum to 1.0000
[2019-03-23 10:34:34,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7433
[2019-03-23 10:34:34,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1350733.908625287 W.
[2019-03-23 10:34:34,340] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.38333333333334, 54.66666666666667, 1.0, 2.0, 0.3980550526849941, 1.0, 2.0, 0.3980550526849941, 1.0, 2.0, 0.805671876442049, 6.911199999999999, 6.9112, 77.3421103, 1350733.908625287, 1350733.908625287, 303285.2038699382], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7657800.0000, 
sim time next is 7658400.0000, 
raw observation next is [28.46666666666667, 54.33333333333334, 1.0, 2.0, 0.5367338766358463, 1.0, 2.0, 0.5367338766358463, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1216026.198390797, 1216026.198390797, 242441.6768930729], 
processed observation next is [1.0, 0.6521739130434783, 0.9303030303030304, 0.5433333333333334, 1.0, 1.0, 0.4209173457948078, 1.0, 1.0, 0.4209173457948078, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.45038007347807296, 0.45038007347807296, 0.5913211631538363], 
reward next is 0.4087, 
noisyNet noise sample is [array([-0.5917755], dtype=float32), -0.4191855]. 
=============================================
[2019-03-23 10:34:41,524] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:41,524] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:41,584] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 10:34:44,642] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:44,642] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:44,698] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 10:34:45,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.5116081e-13 1.0000000e+00 5.5464121e-20 5.0909777e-19 6.2921020e-21], sum to 1.0000
[2019-03-23 10:34:45,005] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0103
[2019-03-23 10:34:45,008] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 87.0, 1.0, 2.0, 0.764727531762551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 870797.2360820172, 870797.2360820172, 172436.023628183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7905600.0000, 
sim time next is 7906200.0000, 
raw observation next is [21.0, 88.0, 1.0, 2.0, 0.7980281095254543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 908880.588905085, 908880.588905085, 177560.578849469], 
processed observation next is [1.0, 0.5217391304347826, 0.5909090909090909, 0.88, 1.0, 1.0, 0.7475351369068178, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.33662244033521665, 0.33662244033521665, 0.43307458255968045], 
reward next is 0.5669, 
noisyNet noise sample is [array([-0.1821038], dtype=float32), 1.2797543]. 
=============================================
[2019-03-23 10:34:45,083] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:45,084] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:45,127] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 10:34:45,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:45,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:45,531] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 10:34:45,763] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:45,764] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:45,786] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 10:34:45,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:45,980] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:46,001] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 10:34:46,225] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:46,226] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:46,236] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 10:34:46,274] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:46,275] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:46,285] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 10:34:46,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:46,493] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:46,512] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 10:34:46,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:46,961] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:46,968] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 10:34:47,223] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:47,223] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:47,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 10:34:47,276] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:47,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:47,277] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:47,284] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:47,305] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 10:34:47,364] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 10:34:47,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9013023e-13 1.0000000e+00 5.3594304e-19 2.8464464e-20 7.9805516e-22], sum to 1.0000
[2019-03-23 10:34:47,494] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-23 10:34:47,504] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 98.66666666666667, 1.0, 2.0, 0.4201868164316516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472321.3299809741, 472321.3299809741, 126097.3376229644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 29400.0000, 
sim time next is 30000.0000, 
raw observation next is [18.53333333333333, 97.33333333333334, 1.0, 2.0, 0.5414121387533938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 609717.4238127038, 609717.4238127038, 138700.5742237109], 
processed observation next is [1.0, 0.34782608695652173, 0.4787878787878787, 0.9733333333333334, 1.0, 1.0, 0.4267651734417422, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2258212680787792, 0.2258212680787792, 0.3382940834724656], 
reward next is 0.6617, 
noisyNet noise sample is [array([1.249683], dtype=float32), -1.5881473]. 
=============================================
[2019-03-23 10:34:47,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.967766]
 [68.967766]
 [68.967766]
 [68.967766]
 [68.967766]], R is [[68.93980408]
 [68.94284821]
 [68.95227051]
 [68.96282959]
 [68.97169495]].
[2019-03-23 10:34:47,560] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:47,563] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:47,583] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 10:34:47,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:34:47,880] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:34:47,899] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 10:34:54,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.1394227e-13 1.0000000e+00 5.9998274e-19 3.3495735e-20 7.6715140e-22], sum to 1.0000
[2019-03-23 10:34:54,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8196
[2019-03-23 10:34:54,291] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 93.00000000000001, 1.0, 2.0, 0.2394556081054064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 259995.8466719688, 259995.8466719685, 80025.66205556986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 544200.0000, 
sim time next is 544800.0000, 
raw observation next is [14.66666666666667, 92.0, 1.0, 2.0, 0.2345460270961787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254663.7316207033, 254663.7316207036, 81002.76671684775], 
processed observation next is [1.0, 0.30434782608695654, 0.30303030303030315, 0.92, 1.0, 1.0, 0.043182533870223354, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09431990060026048, 0.09431990060026059, 0.19756772369962866], 
reward next is 0.8024, 
noisyNet noise sample is [array([-1.489766], dtype=float32), 0.12877825]. 
=============================================
[2019-03-23 10:34:59,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6589922e-15 1.0000000e+00 1.6975923e-19 1.3380271e-20 7.7007718e-23], sum to 1.0000
[2019-03-23 10:34:59,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6307
[2019-03-23 10:34:59,209] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 52.33333333333334, 1.0, 2.0, 0.2762553168353845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 299964.5158720849, 299964.5158720847, 100938.4405289969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 219000.0000, 
sim time next is 219600.0000, 
raw observation next is [22.0, 50.0, 1.0, 2.0, 0.2786691465589966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302586.3242944745, 302586.3242944742, 99888.65233229715], 
processed observation next is [0.0, 0.5652173913043478, 0.6363636363636364, 0.5, 1.0, 1.0, 0.09833643319874574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11206900899795352, 0.11206900899795341, 0.24363085934706621], 
reward next is 0.7564, 
noisyNet noise sample is [array([-1.0169953], dtype=float32), -0.3617109]. 
=============================================
[2019-03-23 10:35:06,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8932331e-14 1.0000000e+00 1.5806692e-21 9.4769638e-21 4.0898803e-23], sum to 1.0000
[2019-03-23 10:35:06,730] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3532
[2019-03-23 10:35:06,735] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 75.5, 1.0, 2.0, 0.26746688772817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 290418.9837272667, 290418.9837272664, 79701.17802560655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 378600.0000, 
sim time next is 379200.0000, 
raw observation next is [15.66666666666667, 74.0, 1.0, 2.0, 0.2709164052613105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294165.6469577102, 294165.6469577099, 80826.5021977394], 
processed observation next is [1.0, 0.391304347826087, 0.3484848484848486, 0.74, 1.0, 1.0, 0.08864550657663811, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10895023961396674, 0.10895023961396663, 0.1971378102383888], 
reward next is 0.8029, 
noisyNet noise sample is [array([-0.97711176], dtype=float32), 1.0436946]. 
=============================================
[2019-03-23 10:35:10,470] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1219658e-14 1.0000000e+00 1.2674995e-21 5.0506412e-21 3.8556975e-23], sum to 1.0000
[2019-03-23 10:35:10,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6298
[2019-03-23 10:35:10,480] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.83333333333333, 89.00000000000001, 1.0, 2.0, 0.2345604325951616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254679.376816901, 254679.3768169013, 80254.30294790174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 508200.0000, 
sim time next is 508800.0000, 
raw observation next is [14.66666666666667, 90.0, 1.0, 2.0, 0.2310342188828885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 250849.7219662056, 250849.7219662053, 79585.74261782176], 
processed observation next is [1.0, 0.9130434782608695, 0.30303030303030315, 0.9, 1.0, 1.0, 0.03879277360361061, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.092907304431928, 0.09290730443192789, 0.19411156736054086], 
reward next is 0.8059, 
noisyNet noise sample is [array([0.21806626], dtype=float32), -0.13590516]. 
=============================================
[2019-03-23 10:35:11,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.48014278e-13 1.00000000e+00 4.17105905e-21 1.07013946e-19
 2.93491629e-23], sum to 1.0000
[2019-03-23 10:35:11,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5480
[2019-03-23 10:35:11,156] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 210508.3995519143, 210508.3995519143, 72474.9815706925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 430800.0000, 
sim time next is 431400.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210483.8625780522, 210483.8625780524, 72466.72237976131], 
processed observation next is [1.0, 1.0, 0.22727272727272727, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07795698614001934, 0.0779569861400194, 0.1767481033652715], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.875656], dtype=float32), 1.0019724]. 
=============================================
[2019-03-23 10:35:15,025] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3182680e-13 1.0000000e+00 2.0866705e-21 1.0326430e-19 1.3759987e-22], sum to 1.0000
[2019-03-23 10:35:15,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7885
[2019-03-23 10:35:15,037] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2790439611622603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 302993.4346777189, 302993.4346777192, 92569.2179060084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 496200.0000, 
sim time next is 496800.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2788771745090226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302812.276863957, 302812.2768639567, 92543.50716436273], 
processed observation next is [1.0, 0.782608695652174, 0.36363636363636365, 0.88, 1.0, 1.0, 0.09859646813627825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11215269513479889, 0.11215269513479878, 0.22571587113259203], 
reward next is 0.7743, 
noisyNet noise sample is [array([-0.9444263], dtype=float32), 1.8902466]. 
=============================================
[2019-03-23 10:35:19,319] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 10:35:19,320] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:35:19,321] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:35:19,321] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:35:19,322] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:35:19,324] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:35:19,324] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:35:19,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:35:19,325] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:35:19,327] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:35:19,328] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:35:19,346] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 10:35:19,371] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 10:35:19,372] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 10:35:19,416] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 10:35:19,443] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 10:35:52,428] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42536828]
[2019-03-23 10:35:52,432] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.7, 62.0, 1.0, 2.0, 0.2581049484597687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 280235.3420312459, 280235.3420312463, 85515.15939499915]
[2019-03-23 10:35:52,432] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:35:52,434] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3474189e-13 1.0000000e+00 3.6699564e-20 1.9804285e-19 6.5306288e-22], sampled 0.054542732466072885
[2019-03-23 10:36:09,078] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42536828]
[2019-03-23 10:36:09,080] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.33333333333334, 79.66666666666667, 1.0, 2.0, 0.7385590036506297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 842872.3297597253, 842872.3297597249, 177028.8227666915]
[2019-03-23 10:36:09,081] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:36:09,084] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3474189e-13 1.0000000e+00 3.6699564e-20 1.9804285e-19 6.5306288e-22], sampled 0.7939940400390575
[2019-03-23 10:36:23,006] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42536828]
[2019-03-23 10:36:23,007] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.81698521333334, 58.86216824333334, 1.0, 2.0, 0.2738234755335187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 297305.8255829275, 297305.8255829268, 96440.12406403368]
[2019-03-23 10:36:23,011] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:36:23,014] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.3474189e-13 1.0000000e+00 3.6699564e-20 1.9804285e-19 6.5306288e-22], sampled 0.5925560445426284
[2019-03-23 10:36:23,370] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42536828]
[2019-03-23 10:36:23,370] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 54.0, 1.0, 2.0, 0.5171336116519295, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9462943650361862, 6.939927151468511, 6.9112, 77.32839203400695, 1137441.012704287, 1128111.030095022, 249618.539316577]
[2019-03-23 10:36:23,371] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:36:23,374] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3474189e-13 1.0000000e+00 3.6699564e-20 1.9804285e-19 6.5306288e-22], sampled 0.8572987547412754
[2019-03-23 10:36:23,375] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1137441.012704287 W.
[2019-03-23 10:36:36,343] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42536828]
[2019-03-23 10:36:36,344] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [16.1, 90.0, 1.0, 2.0, 0.6991246389437349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 759371.4816889362, 759371.4816889362, 146791.371436181]
[2019-03-23 10:36:36,345] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:36:36,348] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.3474189e-13 1.0000000e+00 3.6699564e-20 1.9804285e-19 6.5306288e-22], sampled 0.4220699669192165
[2019-03-23 10:36:50,164] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.42536828]
[2019-03-23 10:36:50,167] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.88333333333333, 52.83333333333334, 1.0, 2.0, 0.3239989015903857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355448.2589921253, 355448.2589921253, 114108.3075494486]
[2019-03-23 10:36:50,168] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:36:50,172] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.3474189e-13 1.0000000e+00 3.6699564e-20 1.9804285e-19 6.5306288e-22], sampled 0.9424299992037058
[2019-03-23 10:36:58,933] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:36:58,990] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:36:59,058] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:36:59,075] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:36:59,101] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:37:00,117] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1925000, evaluation results [1925000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:37:11,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9777604e-12 1.0000000e+00 1.0120568e-17 8.9240442e-19 9.6973795e-20], sum to 1.0000
[2019-03-23 10:37:11,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8827
[2019-03-23 10:37:11,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 80.5, 1.0, 2.0, 0.4613503425525965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526364.2418566496, 526364.2418566496, 136069.8241871129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 901800.0000, 
sim time next is 902400.0000, 
raw observation next is [23.0, 81.33333333333333, 1.0, 2.0, 0.4649890654104986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530564.7398986603, 530564.7398986603, 136705.7478255277], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.8133333333333332, 1.0, 1.0, 0.3312363317631232, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19650545922172605, 0.19650545922172605, 0.3334286532329944], 
reward next is 0.6666, 
noisyNet noise sample is [array([1.086081], dtype=float32), 2.4119189]. 
=============================================
[2019-03-23 10:37:20,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7782369e-15 1.0000000e+00 5.2876988e-21 1.2838654e-20 6.2073695e-22], sum to 1.0000
[2019-03-23 10:37:20,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1395
[2019-03-23 10:37:20,271] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 100.0, 1.0, 2.0, 0.5655873791138193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614326.5585863458, 614326.5585863458, 127857.839993497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1000200.0000, 
sim time next is 1000800.0000, 
raw observation next is [15.0, 100.0, 1.0, 2.0, 0.521130918203559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566010.9703244931, 566010.9703244931, 121251.2974866804], 
processed observation next is [1.0, 0.6086956521739131, 0.3181818181818182, 1.0, 1.0, 1.0, 0.40141364775444865, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20963369271277524, 0.20963369271277524, 0.29573487191873266], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.01847605], dtype=float32), -0.19623996]. 
=============================================
[2019-03-23 10:37:20,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4104965e-13 1.0000000e+00 2.6797700e-19 4.7518522e-19 1.9307595e-22], sum to 1.0000
[2019-03-23 10:37:20,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-23 10:37:20,445] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3924630471788959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 440658.8130639003, 440658.8130639, 123361.7720155168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 979800.0000, 
sim time next is 980400.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.4352035554142433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 488738.3581778428, 488738.3581778428, 127265.3371222012], 
processed observation next is [1.0, 0.34782608695652173, 0.45454545454545453, 1.0, 1.0, 1.0, 0.29400444426780414, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18101420673253438, 0.18101420673253438, 0.31040326127366147], 
reward next is 0.6896, 
noisyNet noise sample is [array([-0.32589754], dtype=float32), 2.1153502]. 
=============================================
[2019-03-23 10:37:29,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3895625e-12 1.0000000e+00 2.5619167e-19 2.6999535e-19 3.9655188e-21], sum to 1.0000
[2019-03-23 10:37:29,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-23 10:37:29,467] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 90.33333333333334, 1.0, 2.0, 0.4876187984136287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550733.1127340088, 550733.1127340088, 133905.0140992742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1153200.0000, 
sim time next is 1153800.0000, 
raw observation next is [20.0, 88.5, 1.0, 2.0, 0.5720119456089479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 646977.0163746881, 646977.0163746881, 143562.589081862], 
processed observation next is [1.0, 0.34782608695652173, 0.5454545454545454, 0.885, 1.0, 1.0, 0.46501493201118477, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23962111717581042, 0.23962111717581042, 0.3501526562972244], 
reward next is 0.6498, 
noisyNet noise sample is [array([0.62178445], dtype=float32), 1.592891]. 
=============================================
[2019-03-23 10:37:33,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1246604e-13 1.0000000e+00 2.9679085e-20 7.0886442e-19 2.1358438e-22], sum to 1.0000
[2019-03-23 10:37:33,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9927
[2019-03-23 10:37:33,622] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 93.0, 1.0, 2.0, 0.3512995376539663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391337.1687496797, 391337.16874968, 118431.7305430492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1659000.0000, 
sim time next is 1659600.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3460124353435253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 385144.0633298625, 385144.0633298625, 117882.4048403556], 
processed observation next is [1.0, 0.21739130434782608, 0.45454545454545453, 0.94, 1.0, 1.0, 0.18251554417940663, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14264594938143055, 0.14264594938143055, 0.28751806058623314], 
reward next is 0.7125, 
noisyNet noise sample is [array([1.0691518], dtype=float32), 0.3533192]. 
=============================================
[2019-03-23 10:37:34,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4803346e-13 1.0000000e+00 9.9063553e-19 8.5943933e-18 1.7510512e-20], sum to 1.0000
[2019-03-23 10:37:34,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1028
[2019-03-23 10:37:34,343] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.582519420993091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 649919.6377623884, 649919.6377623882, 140565.2928551696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1674000.0000, 
sim time next is 1674600.0000, 
raw observation next is [18.0, 93.00000000000001, 1.0, 2.0, 0.6047621244530843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 673822.1376541215, 673822.1376541212, 142658.6787708206], 
processed observation next is [1.0, 0.391304347826087, 0.45454545454545453, 0.9300000000000002, 1.0, 1.0, 0.5059526555663554, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24956375468671166, 0.24956375468671155, 0.34794799700200146], 
reward next is 0.6521, 
noisyNet noise sample is [array([0.01171737], dtype=float32), -1.7906743]. 
=============================================
[2019-03-23 10:37:37,289] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4685438e-13 1.0000000e+00 2.9360630e-20 4.5216401e-19 2.4468067e-21], sum to 1.0000
[2019-03-23 10:37:37,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1481
[2019-03-23 10:37:37,298] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 150825.4768491953, 150825.476849195, 57956.42952494114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1732200.0000, 
sim time next is 1732800.0000, 
raw observation next is [9.0, 71.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 149933.366700707, 149933.3667007067, 57841.4508399247], 
processed observation next is [1.0, 0.043478260869565216, 0.045454545454545456, 0.71, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.055530876555817406, 0.0555308765558173, 0.14107670936567], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.557092], dtype=float32), -0.09909117]. 
=============================================
[2019-03-23 10:37:37,765] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7493462e-13 1.0000000e+00 6.1999688e-20 8.7066795e-20 7.4511389e-20], sum to 1.0000
[2019-03-23 10:37:37,774] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3137
[2019-03-23 10:37:37,779] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4754158841547946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542419.101671539, 542419.101671539, 138675.9824336459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1491600.0000, 
sim time next is 1492200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4763857967924539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 543525.8634540077, 543525.863454008, 138786.6617301772], 
processed observation next is [0.0, 0.2608695652173913, 0.5909090909090909, 1.0, 1.0, 1.0, 0.34548224599056737, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20130587535333616, 0.2013058753533363, 0.33850405300043224], 
reward next is 0.6615, 
noisyNet noise sample is [array([0.82128143], dtype=float32), -0.993275]. 
=============================================
[2019-03-23 10:37:38,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3991503e-11 1.0000000e+00 9.9032619e-18 3.1195555e-17 1.3719134e-18], sum to 1.0000
[2019-03-23 10:37:39,000] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7566
[2019-03-23 10:37:39,006] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 66.0, 1.0, 2.0, 0.6119603859703205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 687686.9316760901, 687686.9316760901, 160575.2946647007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515600.0000, 
sim time next is 1516200.0000, 
raw observation next is [27.66666666666667, 71.66666666666666, 1.0, 2.0, 0.6060597401118228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 681051.468577749, 681051.468577749, 159741.1430270525], 
processed observation next is [0.0, 0.5652173913043478, 0.8939393939393941, 0.7166666666666666, 1.0, 1.0, 0.5075746751397785, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.25224128465842555, 0.25224128465842555, 0.3896125439684207], 
reward next is 0.6104, 
noisyNet noise sample is [array([-1.1441481], dtype=float32), 0.08498111]. 
=============================================
[2019-03-23 10:37:39,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7436585e-13 1.0000000e+00 2.9512224e-20 5.5518341e-19 1.0655434e-21], sum to 1.0000
[2019-03-23 10:37:39,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6270
[2019-03-23 10:37:39,364] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4900668913768946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559142.439666166, 559142.439666166, 140344.6633350509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1389600.0000, 
sim time next is 1390200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4898469705351425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 558891.4259081689, 558891.4259081689, 140319.3156099917], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.36230871316892804, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20699682441043293, 0.20699682441043293, 0.3422422331951017], 
reward next is 0.6578, 
noisyNet noise sample is [array([-0.7275812], dtype=float32), 0.90620637]. 
=============================================
[2019-03-23 10:37:43,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.70737892e-12 1.00000000e+00 1.00191095e-19 8.02933054e-19
 5.22348149e-22], sum to 1.0000
[2019-03-23 10:37:43,815] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6997
[2019-03-23 10:37:43,822] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 70.66666666666666, 1.0, 2.0, 0.5396908300497921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 612925.105788076, 612925.105788076, 148852.7752533819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1435200.0000, 
sim time next is 1435800.0000, 
raw observation next is [26.16666666666667, 70.83333333333334, 1.0, 2.0, 0.534872312052363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 607918.1474693981, 607918.1474693984, 148009.5001500405], 
processed observation next is [0.0, 0.6086956521739131, 0.825757575757576, 0.7083333333333335, 1.0, 1.0, 0.4185903900654537, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.22515486943311042, 0.22515486943311053, 0.3609987808537573], 
reward next is 0.6390, 
noisyNet noise sample is [array([0.4387269], dtype=float32), -0.2964425]. 
=============================================
[2019-03-23 10:37:46,431] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0653519e-11 1.0000000e+00 9.5496265e-19 6.8307781e-18 3.7930457e-20], sum to 1.0000
[2019-03-23 10:37:46,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9863
[2019-03-23 10:37:46,443] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4626643987472182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527737.4690593651, 527737.4690593653, 135829.1351206088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1450800.0000, 
sim time next is 1451400.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.4607588966697403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 525533.8270011899, 525533.8270011899, 135556.4977247802], 
processed observation next is [0.0, 0.8260869565217391, 0.5909090909090909, 0.9400000000000002, 1.0, 1.0, 0.32594862083717535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19464215814858887, 0.19464215814858887, 0.330625604206781], 
reward next is 0.6694, 
noisyNet noise sample is [array([0.51979065], dtype=float32), 0.4753952]. 
=============================================
[2019-03-23 10:37:49,062] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 10:37:49,063] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:37:49,063] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:49,064] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:37:49,065] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:37:49,065] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:49,066] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:37:49,066] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:49,067] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:49,067] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:37:49,071] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:37:49,091] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 10:37:49,118] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 10:37:49,143] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 10:37:49,172] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 10:37:49,196] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 10:37:55,378] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:37:55,380] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.9, 64.66666666666667, 1.0, 2.0, 0.5032411416788023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 566692.4252744606, 566692.4252744601, 138982.4226002951]
[2019-03-23 10:37:55,381] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:37:55,384] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.9027790412860733
[2019-03-23 10:38:33,060] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:38:33,061] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.40221130833334, 91.53269046166668, 1.0, 2.0, 0.4176990559402788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 471963.8172126094, 471963.8172126091, 131493.3388756294]
[2019-03-23 10:38:33,063] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:38:33,067] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.9689631633842121
[2019-03-23 10:38:36,090] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:38:36,091] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.15, 90.0, 1.0, 2.0, 0.3847244934553911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 432124.7216308904, 432124.7216308904, 127087.7979752812]
[2019-03-23 10:38:36,094] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:38:36,095] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.033050860167814555
[2019-03-23 10:38:36,147] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:38:36,148] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.555455890876764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 630147.921337049, 630147.9213370492, 151171.8959383156]
[2019-03-23 10:38:36,149] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:38:36,151] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.7664200140829185
[2019-03-23 10:38:40,375] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:38:40,376] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.35, 69.16666666666667, 1.0, 2.0, 0.6160350911823207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 700418.6803909813, 700418.6803909813, 162830.5283647865]
[2019-03-23 10:38:40,378] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:38:40,383] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.2223295563461407
[2019-03-23 10:38:48,531] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:38:48,532] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [29.4, 57.66666666666666, 1.0, 2.0, 0.9124600414653163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1031272.828739001, 1031272.828739001, 212969.9611627727]
[2019-03-23 10:38:48,532] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:38:48,535] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.5837841307766963
[2019-03-23 10:39:05,317] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:39:05,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.05, 88.83333333333334, 1.0, 2.0, 0.2605206650502784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 282858.8037919872, 282858.8037919872, 96375.70057546592]
[2019-03-23 10:39:05,319] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:39:05,324] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.8879113470338016
[2019-03-23 10:39:06,206] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:39:06,208] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.2, 76.0, 1.0, 2.0, 0.2481930609325699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269485.4168681987, 269485.4168681987, 87155.96487345401]
[2019-03-23 10:39:06,209] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:39:06,212] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.9646807159367133
[2019-03-23 10:39:09,112] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:39:09,113] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.32285748, 62.46531687, 1.0, 2.0, 0.4479334365700292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 507822.7561627189, 507822.7561627186, 135445.5562433464]
[2019-03-23 10:39:09,115] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:39:09,117] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.35071562933987566
[2019-03-23 10:39:15,678] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.39363667]
[2019-03-23 10:39:15,679] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.2, 90.0, 1.0, 2.0, 0.3265575088015993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355750.8621235488, 355750.8621235485, 113402.0108787447]
[2019-03-23 10:39:15,681] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:39:15,684] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5395520e-12 1.0000000e+00 4.7719429e-19 2.4614052e-18 1.1389179e-20], sampled 0.8617093652733536
[2019-03-23 10:39:28,511] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:39:28,512] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:39:28,681] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:39:28,761] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:39:29,044] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:39:30,062] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1950000, evaluation results [1950000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:39:39,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6171956e-14 1.0000000e+00 1.0971590e-22 9.1557229e-21 1.5406692e-22], sum to 1.0000
[2019-03-23 10:39:39,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7039
[2019-03-23 10:39:39,840] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 53.0, 1.0, 2.0, 0.2997755373016985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 325511.8711854767, 325511.8711854764, 111175.7599243176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2154600.0000, 
sim time next is 2155200.0000, 
raw observation next is [22.0, 53.0, 1.0, 2.0, 0.2979533178851273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 323532.5523681073, 323532.5523681076, 111054.0322200535], 
processed observation next is [0.0, 0.9565217391304348, 0.6363636363636364, 0.53, 1.0, 1.0, 0.12244164735640911, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11982687124744715, 0.11982687124744726, 0.2708634932196427], 
reward next is 0.7291, 
noisyNet noise sample is [array([1.8282492], dtype=float32), 1.173929]. 
=============================================
[2019-03-23 10:39:41,637] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.64661372e-14 1.00000000e+00 8.47175826e-22 2.17992404e-21
 1.21227285e-23], sum to 1.0000
[2019-03-23 10:39:41,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1116
[2019-03-23 10:39:41,647] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.66666666666666, 78.66666666666666, 1.0, 2.0, 0.4403747202013596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 478256.8612051755, 478256.8612051755, 106191.9165962366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [16.83333333333334, 77.83333333333334, 1.0, 2.0, 0.4526695047754566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 491616.0254514437, 491616.0254514434, 108182.9073935421], 
processed observation next is [1.0, 0.34782608695652173, 0.40151515151515177, 0.7783333333333334, 1.0, 1.0, 0.3158368809693207, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18208000942646063, 0.18208000942646052, 0.26386074974034657], 
reward next is 0.7361, 
noisyNet noise sample is [array([-0.1414818], dtype=float32), 1.7978336]. 
=============================================
[2019-03-23 10:40:00,025] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4141512e-14 1.0000000e+00 6.6502918e-23 1.0901714e-21 2.2458951e-24], sum to 1.0000
[2019-03-23 10:40:00,041] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1747
[2019-03-23 10:40:00,048] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 54.00000000000001, 1.0, 2.0, 0.4122403418842813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 468178.8932741473, 468178.8932741476, 128241.2434605529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2136000.0000, 
sim time next is 2136600.0000, 
raw observation next is [26.0, 54.0, 1.0, 2.0, 0.4121625356111729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468088.7411587946, 468088.7411587946, 128232.3861064064], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.54, 1.0, 1.0, 0.26520316951396605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1733662004291832, 0.1733662004291832, 0.31276191733269854], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.61907107], dtype=float32), -0.39317837]. 
=============================================
[2019-03-23 10:40:02,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6102181e-14 1.0000000e+00 1.2436004e-21 1.6028955e-18 7.3684819e-22], sum to 1.0000
[2019-03-23 10:40:02,082] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6687
[2019-03-23 10:40:02,087] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 75.66666666666667, 1.0, 2.0, 0.5519538747629273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 599509.0614319097, 599509.0614319097, 131326.0277692722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2197200.0000, 
sim time next is 2197800.0000, 
raw observation next is [18.5, 75.0, 1.0, 2.0, 0.5807550691625855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 630812.0076827705, 630812.0076827707, 134497.5197557497], 
processed observation next is [1.0, 0.43478260869565216, 0.4772727272727273, 0.75, 1.0, 1.0, 0.4759438364532318, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23363407691954463, 0.23363407691954471, 0.32804273111158466], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.18845892], dtype=float32), -1.3136319]. 
=============================================
[2019-03-23 10:40:08,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3780788e-13 1.0000000e+00 3.6414699e-18 1.3974617e-19 4.6052970e-21], sum to 1.0000
[2019-03-23 10:40:08,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3416
[2019-03-23 10:40:08,178] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 80.66666666666667, 1.0, 2.0, 0.2052252459041196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 222820.7283706747, 222820.7283706744, 70831.09492922926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2341200.0000, 
sim time next is 2341800.0000, 
raw observation next is [13.0, 82.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 210865.4177908082, 210865.4177908085, 69010.88751104308], 
processed observation next is [1.0, 0.08695652173913043, 0.22727272727272727, 0.825, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07809830288548451, 0.07809830288548464, 0.1683192378318124], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.695833], dtype=float32), -0.25709605]. 
=============================================
[2019-03-23 10:40:15,032] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.28661860e-14 1.00000000e+00 7.49848894e-23 1.95484008e-20
 1.10186024e-23], sum to 1.0000
[2019-03-23 10:40:15,041] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9842
[2019-03-23 10:40:15,046] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 47.5, 1.0, 2.0, 0.5219380038532252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566888.0737699055, 566888.0737699055, 116448.4491693947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2381400.0000, 
sim time next is 2382000.0000, 
raw observation next is [21.66666666666667, 47.0, 1.0, 2.0, 0.5213140018123974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566209.93700437, 566209.93700437, 117111.772590873], 
processed observation next is [1.0, 0.5652173913043478, 0.6212121212121214, 0.47, 1.0, 1.0, 0.4016425022654967, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20970738407569262, 0.20970738407569262, 0.2856384697338366], 
reward next is 0.7144, 
noisyNet noise sample is [array([1.3483713], dtype=float32), 1.0592818]. 
=============================================
[2019-03-23 10:40:15,055] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.235725]
 [73.235725]
 [73.235725]
 [73.235725]
 [73.235725]], R is [[73.21773529]
 [73.20153809]
 [73.20182037]
 [73.22309113]
 [73.24967957]].
[2019-03-23 10:40:15,460] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4509951e-15 1.0000000e+00 1.6630670e-22 1.3230888e-21 1.0878310e-24], sum to 1.0000
[2019-03-23 10:40:15,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0846
[2019-03-23 10:40:15,479] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2256888858049184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245044.4646382963, 245044.4646382965, 77859.71286907907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [14.0, 93.00000000000001, 1.0, 2.0, 0.222592565278794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 241681.7615560542, 241681.7615560539, 77139.50474541729], 
processed observation next is [1.0, 0.043478260869565216, 0.2727272727272727, 0.9300000000000002, 1.0, 1.0, 0.028240706598492496, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08951176353927934, 0.08951176353927923, 0.18814513352540801], 
reward next is 0.8119, 
noisyNet noise sample is [array([0.27021077], dtype=float32), -1.6356776]. 
=============================================
[2019-03-23 10:40:17,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2901838e-13 1.0000000e+00 1.5436526e-21 4.4882796e-21 1.1658987e-22], sum to 1.0000
[2019-03-23 10:40:17,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8725
[2019-03-23 10:40:17,358] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.83333333333333, 100.0, 1.0, 2.0, 0.2946804621724605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 319977.553459277, 319977.553459277, 110837.0343761914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2613000.0000, 
sim time next is 2613600.0000, 
raw observation next is [16.0, 100.0, 1.0, 2.0, 0.3002906268287293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 326071.369698946, 326071.369698946, 111212.5464421749], 
processed observation next is [0.0, 0.2608695652173913, 0.36363636363636365, 1.0, 1.0, 1.0, 0.1253632835359116, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1207671739625726, 0.1207671739625726, 0.2712501132735973], 
reward next is 0.7287, 
noisyNet noise sample is [array([0.91808116], dtype=float32), -0.57600665]. 
=============================================
[2019-03-23 10:40:17,828] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3287318e-16 1.0000000e+00 9.1325117e-24 1.0559898e-21 1.7716942e-25], sum to 1.0000
[2019-03-23 10:40:17,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0704
[2019-03-23 10:40:17,849] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.2251516786362953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 244461.0388115011, 244461.0388115014, 77750.05530918232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434200.0000, 
sim time next is 2434800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2217817749476316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240801.2211759981, 240801.2211759978, 77442.02389081357], 
processed observation next is [1.0, 0.17391304347826086, 0.2727272727272727, 0.94, 1.0, 1.0, 0.027227218684539485, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0891856374725919, 0.08918563747259178, 0.1888829850995453], 
reward next is 0.8111, 
noisyNet noise sample is [array([0.16650322], dtype=float32), -0.09939113]. 
=============================================
[2019-03-23 10:40:19,095] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 10:40:19,096] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:40:19,097] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:40:19,098] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:40:19,099] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:40:19,097] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:40:19,100] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:40:19,100] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:40:19,100] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:40:19,101] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:40:19,104] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:40:19,124] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 10:40:19,154] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 10:40:19,155] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 10:40:19,155] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 10:40:19,241] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 10:40:58,841] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.35217687]
[2019-03-23 10:40:58,842] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6559504525501388, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865530188920543, 6.911200000000001, 6.9112, 77.32846344354104, 1285769.512713228, 1285769.512713228, 293078.8363993253]
[2019-03-23 10:40:58,843] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:40:58,845] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.3672697e-14 1.0000000e+00 4.4602540e-21 2.4387661e-20 6.3774703e-23], sampled 0.3974288657077776
[2019-03-23 10:40:58,849] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1285769.512713228 W.
[2019-03-23 10:41:27,040] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.35217687]
[2019-03-23 10:41:27,042] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.8, 44.0, 1.0, 2.0, 0.3173596559617428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 344589.1007885188, 344589.1007885188, 116676.7099235228]
[2019-03-23 10:41:27,044] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:41:27,046] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.3672697e-14 1.0000000e+00 4.4602540e-21 2.4387661e-20 6.3774703e-23], sampled 0.7769880083522719
[2019-03-23 10:41:27,388] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.35217687]
[2019-03-23 10:41:27,390] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.63333333333333, 63.83333333333334, 1.0, 2.0, 0.2344744311848985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 254573.2672753718, 254573.2672753718, 83683.39169557269]
[2019-03-23 10:41:27,391] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:41:27,393] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.3672697e-14 1.0000000e+00 4.4602540e-21 2.4387661e-20 6.3774703e-23], sampled 0.780996569178108
[2019-03-23 10:41:32,085] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.35217687]
[2019-03-23 10:41:32,087] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.70478936, 80.38184773, 1.0, 2.0, 0.3991369853788967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 450098.2718215067, 450098.2718215067, 129271.3281109979]
[2019-03-23 10:41:32,088] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:41:32,091] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.3672697e-14 1.0000000e+00 4.4602540e-21 2.4387661e-20 6.3774703e-23], sampled 0.6248271572668276
[2019-03-23 10:41:52,992] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.35217687]
[2019-03-23 10:41:52,993] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.39557189, 88.65061583, 1.0, 2.0, 0.3301700199522413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 365001.5219753903, 365001.5219753903, 119931.1955828687]
[2019-03-23 10:41:52,993] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:41:52,997] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.3672697e-14 1.0000000e+00 4.4602540e-21 2.4387661e-20 6.3774703e-23], sampled 0.28169592525213216
[2019-03-23 10:41:57,849] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:41:58,214] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:41:58,347] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:41:58,433] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:41:58,448] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:41:59,462] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1975000, evaluation results [1975000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:42:04,699] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.7391404e-13 1.0000000e+00 1.5856542e-18 5.4189012e-20 5.1593016e-21], sum to 1.0000
[2019-03-23 10:42:04,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5926
[2019-03-23 10:42:04,708] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.33333333333333, 94.0, 1.0, 2.0, 0.4059968620398621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 440904.803623806, 440904.803623806, 98615.99538622443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2539200.0000, 
sim time next is 2539800.0000, 
raw observation next is [14.5, 94.0, 1.0, 2.0, 0.4094734265162873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 444682.0125493848, 444682.0125493845, 99938.4956043003], 
processed observation next is [1.0, 0.391304347826087, 0.29545454545454547, 0.94, 1.0, 1.0, 0.2618417831453591, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16469704168495733, 0.16469704168495722, 0.24375242830317148], 
reward next is 0.7562, 
noisyNet noise sample is [array([-0.01009061], dtype=float32), -1.0590417]. 
=============================================
[2019-03-23 10:42:06,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.8630042e-13 1.0000000e+00 2.4266093e-20 1.3590785e-18 2.5710779e-21], sum to 1.0000
[2019-03-23 10:42:06,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3899
[2019-03-23 10:42:06,014] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.81666666666667, 93.00000000000001, 1.0, 2.0, 0.3129092295128519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 340723.7022249435, 340723.7022249432, 112393.5521589766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2599800.0000, 
sim time next is 2600400.0000, 
raw observation next is [16.73333333333333, 92.0, 1.0, 2.0, 0.3088586403924025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 335378.1779925019, 335378.1779925022, 111789.6299509721], 
processed observation next is [0.0, 0.08695652173913043, 0.39696969696969686, 0.92, 1.0, 1.0, 0.13607330049050312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12421413999722292, 0.12421413999722304, 0.27265763402676124], 
reward next is 0.7273, 
noisyNet noise sample is [array([-0.05582739], dtype=float32), 0.21912904]. 
=============================================
[2019-03-23 10:42:07,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7270712e-13 1.0000000e+00 5.1291037e-20 3.1002861e-19 2.5464513e-21], sum to 1.0000
[2019-03-23 10:42:07,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0775
[2019-03-23 10:42:07,622] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 45.0, 1.0, 2.0, 0.3838779900669521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 433435.0368165645, 433435.0368165645, 123888.278423883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2655600.0000, 
sim time next is 2656200.0000, 
raw observation next is [27.0, 45.0, 1.0, 2.0, 0.3845446065843475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 434188.8858216365, 434188.8858216368, 123948.192319895], 
processed observation next is [0.0, 0.7391304347826086, 0.8636363636363636, 0.45, 1.0, 1.0, 0.23068075823043438, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16081069845245796, 0.16081069845245807, 0.30231266419486585], 
reward next is 0.6977, 
noisyNet noise sample is [array([0.6779422], dtype=float32), 0.5480799]. 
=============================================
[2019-03-23 10:42:09,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7856708e-14 1.0000000e+00 4.7028201e-19 1.1808014e-18 5.5845395e-21], sum to 1.0000
[2019-03-23 10:42:09,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0183
[2019-03-23 10:42:09,113] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 59.33333333333334, 1.0, 2.0, 0.4545317030103911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 518448.5057915826, 518448.5057915829, 134939.1857611062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2736600.0000, 
sim time next is 2737200.0000, 
raw observation next is [26.33333333333334, 57.66666666666667, 1.0, 2.0, 0.4511995276312597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 514515.0188324074, 514515.0188324074, 134310.0878085838], 
processed observation next is [0.0, 0.6956521739130435, 0.8333333333333336, 0.5766666666666667, 1.0, 1.0, 0.31399940953907457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19056111808607681, 0.19056111808607681, 0.32758558002093613], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.8667454], dtype=float32), 0.008695643]. 
=============================================
[2019-03-23 10:42:11,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4936702e-13 1.0000000e+00 9.3228192e-20 2.7513364e-19 2.7679455e-21], sum to 1.0000
[2019-03-23 10:42:11,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8329
[2019-03-23 10:42:11,972] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 55.16666666666666, 1.0, 2.0, 0.4192880608728306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 476623.8620089654, 476623.8620089654, 129281.7243596192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2743800.0000, 
sim time next is 2744400.0000, 
raw observation next is [26.0, 56.33333333333334, 1.0, 2.0, 0.4241803234486796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 482662.2346314666, 482662.2346314669, 130195.8743190396], 
processed observation next is [0.0, 0.782608695652174, 0.8181818181818182, 0.5633333333333335, 1.0, 1.0, 0.28022540431084947, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1787637906042469, 0.178763790604247, 0.3175509129732673], 
reward next is 0.6824, 
noisyNet noise sample is [array([-0.36911458], dtype=float32), -0.18196875]. 
=============================================
[2019-03-23 10:42:12,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7802682e-12 1.0000000e+00 7.2460724e-18 2.1039635e-17 6.3136001e-20], sum to 1.0000
[2019-03-23 10:42:12,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1779
[2019-03-23 10:42:12,180] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.449721319463076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 513027.8258410466, 513027.8258410466, 134610.8486672673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2719800.0000, 
sim time next is 2720400.0000, 
raw observation next is [25.33333333333333, 66.33333333333333, 1.0, 2.0, 0.4565218056276835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520895.4171675468, 520895.4171675468, 135766.545684238], 
processed observation next is [0.0, 0.4782608695652174, 0.7878787878787876, 0.6633333333333333, 1.0, 1.0, 0.32065225703460437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1929242285805729, 0.1929242285805729, 0.3311379163030195], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.12696372], dtype=float32), -0.41812125]. 
=============================================
[2019-03-23 10:42:13,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.013351e-13 1.000000e+00 4.537240e-20 1.207867e-19 3.821510e-21], sum to 1.0000
[2019-03-23 10:42:13,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4171
[2019-03-23 10:42:13,532] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 53.5, 1.0, 2.0, 0.4539434753573563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 517622.3969420854, 517622.3969420857, 134557.6567448672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [27.0, 54.0, 1.0, 2.0, 0.4534432325738671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516981.9379101463, 516981.9379101463, 134383.1450428399], 
processed observation next is [1.0, 0.8260869565217391, 0.8636363636363636, 0.54, 1.0, 1.0, 0.3168040407173338, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19147479181857271, 0.19147479181857271, 0.3277637683971705], 
reward next is 0.6722, 
noisyNet noise sample is [array([0.6827002], dtype=float32), 0.03662005]. 
=============================================
[2019-03-23 10:42:21,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9993737e-10 1.0000000e+00 9.4257551e-16 4.5148237e-15 3.7246690e-18], sum to 1.0000
[2019-03-23 10:42:21,523] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4826
[2019-03-23 10:42:21,531] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1441087.439634467 W.
[2019-03-23 10:42:21,536] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.7853783482948193, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9770714148363755, 6.9112, 6.9112, 77.32846344354104, 1441087.439634467, 1441087.439634467, 305348.0558315499], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2979600.0000, 
sim time next is 2980200.0000, 
raw observation next is [27.83333333333334, 58.66666666666666, 1.0, 2.0, 0.4479118664663584, 1.0, 1.0, 0.4479118664663584, 1.0, 2.0, 0.9059435511598174, 6.9112, 6.9112, 77.3421103, 1516827.74200463, 1516827.74200463, 329149.6321475079], 
processed observation next is [1.0, 0.4782608695652174, 0.9015151515151518, 0.5866666666666666, 1.0, 1.0, 0.30988983308294793, 1.0, 0.5, 0.30988983308294793, 1.0, 1.0, 0.865633644514025, 0.0, 0.0, 0.5085185399722538, 0.5617880525943074, 0.5617880525943074, 0.8028039808475803], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6543238], dtype=float32), 0.4326889]. 
=============================================
[2019-03-23 10:42:24,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6156939e-12 1.0000000e+00 2.5480086e-19 1.2791248e-18 4.8099886e-21], sum to 1.0000
[2019-03-23 10:42:24,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0986
[2019-03-23 10:42:24,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1431989.359562265 W.
[2019-03-23 10:42:24,163] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 67.33333333333334, 1.0, 2.0, 0.63413657279752, 1.0, 2.0, 0.63413657279752, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1431989.359562265, 1431989.359562265, 270466.2761376529], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2974800.0000, 
sim time next is 2975400.0000, 
raw observation next is [26.5, 66.0, 1.0, 2.0, 0.6516540731393662, 1.0, 2.0, 0.6516540731393662, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1472078.121942287, 1472078.121942287, 275486.0022376846], 
processed observation next is [1.0, 0.43478260869565216, 0.8409090909090909, 0.66, 1.0, 1.0, 0.5645675914242076, 1.0, 1.0, 0.5645675914242076, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.5452141192378841, 0.5452141192378841, 0.671917078628499], 
reward next is 0.3281, 
noisyNet noise sample is [array([-0.5249039], dtype=float32), 0.9604793]. 
=============================================
[2019-03-23 10:42:30,578] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1476872e-11 1.0000000e+00 2.2745713e-17 1.8776967e-17 5.3848185e-20], sum to 1.0000
[2019-03-23 10:42:30,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6753
[2019-03-23 10:42:30,594] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3286730747995727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 359507.2312721538, 359507.2312721536, 114060.4149534753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3049200.0000, 
sim time next is 3049800.0000, 
raw observation next is [17.0, 94.00000000000001, 1.0, 2.0, 0.4017706832767349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439851.7335309854, 439851.7335309854, 119751.2330771909], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.9400000000000002, 1.0, 1.0, 0.25221335409591855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16290804945592052, 0.16290804945592052, 0.292076178237051], 
reward next is 0.7079, 
noisyNet noise sample is [array([0.21106729], dtype=float32), -0.08802952]. 
=============================================
[2019-03-23 10:42:34,295] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4519227e-11 1.0000000e+00 2.1339516e-17 6.8344272e-18 3.3033861e-19], sum to 1.0000
[2019-03-23 10:42:34,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1138
[2019-03-23 10:42:34,308] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.4899803472467422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 556593.6702485511, 556593.6702485511, 136194.3552544649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3133800.0000, 
sim time next is 3134400.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.4635888842758006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526575.5778957175, 526575.5778957175, 133400.264324098], 
processed observation next is [1.0, 0.2608695652173913, 0.6363636363636364, 0.78, 1.0, 1.0, 0.3294861053447507, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1950279918132287, 0.1950279918132287, 0.3253664983514586], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.93889767], dtype=float32), -0.051808555]. 
=============================================
[2019-03-23 10:42:36,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5483395e-14 1.0000000e+00 5.2344180e-20 1.3422863e-19 6.6089459e-22], sum to 1.0000
[2019-03-23 10:42:36,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2208
[2019-03-23 10:42:36,809] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3405068620123731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 375019.4487673512, 375019.4487673509, 115850.8797398717], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3214800.0000, 
sim time next is 3215400.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3381300585982622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 372191.5950644125, 372191.5950644122, 115594.3987138019], 
processed observation next is [0.0, 0.21739130434782608, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.1726625732478277, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13784873891274538, 0.13784873891274527, 0.28193755783854124], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.17072742], dtype=float32), 0.26799133]. 
=============================================
[2019-03-23 10:42:37,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3910398e-11 1.0000000e+00 1.7973847e-18 1.0648259e-18 2.9440020e-21], sum to 1.0000
[2019-03-23 10:42:37,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2442
[2019-03-23 10:42:37,030] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 93.00000000000001, 1.0, 2.0, 0.3601109401147968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 400312.99613095, 400312.9961309497, 118785.0320296126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3211800.0000, 
sim time next is 3212400.0000, 
raw observation next is [18.0, 92.0, 1.0, 2.0, 0.35503182702358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 393978.255831579, 393978.2558315793, 118097.8651329956], 
processed observation next is [0.0, 0.17391304347826086, 0.45454545454545453, 0.92, 1.0, 1.0, 0.19378978377947498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14591787253021443, 0.14591787253021457, 0.2880435734951112], 
reward next is 0.7120, 
noisyNet noise sample is [array([-1.1890743], dtype=float32), -1.194808]. 
=============================================
[2019-03-23 10:42:39,227] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7588936e-13 1.0000000e+00 9.5507508e-20 5.9322550e-20 1.2561014e-21], sum to 1.0000
[2019-03-23 10:42:39,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5170
[2019-03-23 10:42:39,240] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 47.0, 1.0, 2.0, 0.3248884545620374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356139.3910098441, 356139.3910098441, 114068.3587553682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3260400.0000, 
sim time next is 3261000.0000, 
raw observation next is [24.0, 47.0, 1.0, 2.0, 0.3244971128404946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355707.4243855517, 355707.4243855514, 114039.1491095525], 
processed observation next is [0.0, 0.7391304347826086, 0.7272727272727273, 0.47, 1.0, 1.0, 0.15562139105061823, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1317434905131673, 0.1317434905131672, 0.27814426612085974], 
reward next is 0.7219, 
noisyNet noise sample is [array([1.7137412], dtype=float32), -1.7866261]. 
=============================================
[2019-03-23 10:42:39,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.22654]
 [69.22654]
 [69.22654]
 [69.22654]
 [69.22654]], R is [[69.2561264 ]
 [69.28535461]
 [69.31414032]
 [69.34238434]
 [69.36994171]].
[2019-03-23 10:42:48,659] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 10:42:48,663] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:42:48,664] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:48,665] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:42:48,665] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:48,666] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:42:48,666] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:42:48,667] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:48,667] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:48,669] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:42:48,670] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:42:48,690] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 10:42:48,713] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 10:42:48,737] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 10:42:48,762] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 10:42:48,787] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 10:43:13,230] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36437932]
[2019-03-23 10:43:13,232] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.17771075333334, 57.63291108000001, 1.0, 2.0, 0.2996690500045164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 325375.4418039299, 325375.4418039295, 89179.14610003243]
[2019-03-23 10:43:13,233] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:43:13,236] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0777878e-12 1.0000000e+00 6.7328304e-19 3.3528625e-18 1.6550627e-20], sampled 0.8471170468918755
[2019-03-23 10:43:15,269] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36437932]
[2019-03-23 10:43:15,272] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [25.9, 69.0, 1.0, 2.0, 0.725237358456729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 826403.868929414, 826403.868929414, 177475.1472092812]
[2019-03-23 10:43:15,272] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:43:15,274] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.0777878e-12 1.0000000e+00 6.7328304e-19 3.3528625e-18 1.6550627e-20], sampled 0.06046570938715912
[2019-03-23 10:43:34,518] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36437932]
[2019-03-23 10:43:34,520] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.44436262166667, 58.08322734333333, 1.0, 2.0, 0.337231835748196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 372966.8686889539, 372966.8686889542, 120522.6399075242]
[2019-03-23 10:43:34,522] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:43:34,524] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.0777878e-12 1.0000000e+00 6.7328304e-19 3.3528625e-18 1.6550627e-20], sampled 0.1580649371462789
[2019-03-23 10:43:38,496] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36437932]
[2019-03-23 10:43:38,497] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.5, 91.5, 1.0, 2.0, 0.5304361699416911, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9629426777044983, 6.931965385278475, 6.9112, 77.32841067490811, 1152153.485137811, 1145409.317327137, 263914.1722847527]
[2019-03-23 10:43:38,500] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:43:38,503] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.0777878e-12 1.0000000e+00 6.7328304e-19 3.3528625e-18 1.6550627e-20], sampled 0.6292946074968313
[2019-03-23 10:43:38,503] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1152153.485137811 W.
[2019-03-23 10:43:51,277] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36437932]
[2019-03-23 10:43:51,278] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.84165974, 100.0, 1.0, 2.0, 0.4514109327663248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 514365.5177963291, 514365.5177963291, 138105.2170222218]
[2019-03-23 10:43:51,279] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:43:51,282] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.0777878e-12 1.0000000e+00 6.7328304e-19 3.3528625e-18 1.6550627e-20], sampled 0.3258820288792328
[2019-03-23 10:44:08,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.36437932]
[2019-03-23 10:44:08,815] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.1, 65.5, 1.0, 2.0, 0.3666549792717392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 409881.5462610745, 409881.5462610745, 124617.988143504]
[2019-03-23 10:44:08,817] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:44:08,822] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.0777878e-12 1.0000000e+00 6.7328304e-19 3.3528625e-18 1.6550627e-20], sampled 0.6589439008951785
[2019-03-23 10:44:28,844] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:44:28,885] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:44:29,004] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:44:29,019] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:44:29,114] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:44:30,132] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2000000, evaluation results [2000000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:44:34,469] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.61340913e-11 1.00000000e+00 3.23614893e-17 1.07159065e-17
 1.47677408e-19], sum to 1.0000
[2019-03-23 10:44:34,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5430
[2019-03-23 10:44:34,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1474409.71738557 W.
[2019-03-23 10:44:34,488] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 62.0, 1.0, 2.0, 0.8192307867021681, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9815380305492186, 6.911199999999999, 6.9112, 77.32846344354104, 1474409.71738557, 1474409.71738557, 315429.4911796053], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3510600.0000, 
sim time next is 3511200.0000, 
raw observation next is [28.33333333333334, 62.0, 1.0, 2.0, 0.4646351184437242, 1.0, 1.0, 0.4646351184437242, 1.0, 2.0, 0.9401331427661541, 6.911200000000001, 6.9112, 77.3421103, 1567681.145377468, 1567681.145377467, 340625.5613844717], 
processed observation next is [1.0, 0.6521739130434783, 0.9242424242424245, 0.62, 1.0, 1.0, 0.3307938980546552, 1.0, 0.5, 0.3307938980546552, 1.0, 1.0, 0.9144759182373631, 8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5806226464360993, 0.5806226464360988, 0.8307940521572481], 
reward next is 0.1692, 
noisyNet noise sample is [array([0.65891284], dtype=float32), 1.0040164]. 
=============================================
[2019-03-23 10:44:38,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2485878e-12 1.0000000e+00 1.2997044e-18 1.5865512e-16 8.1466589e-20], sum to 1.0000
[2019-03-23 10:44:38,030] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8214
[2019-03-23 10:44:38,036] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1687154.157604731 W.
[2019-03-23 10:44:38,040] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 70.0, 1.0, 2.0, 0.7499882299275189, 1.0, 2.0, 0.7499882299275189, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1687154.157604731, 1687154.157604731, 307945.4563709099], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3601200.0000, 
sim time next is 3601800.0000, 
raw observation next is [27.0, 70.0, 1.0, 2.0, 0.7666320177403007, 1.0, 2.0, 0.7666320177403007, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1724652.642482364, 1724652.642482364, 313510.7620589925], 
processed observation next is [1.0, 0.6956521739130435, 0.8636363636363636, 0.7, 1.0, 1.0, 0.7082900221753757, 1.0, 1.0, 0.7082900221753757, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.6387602379564311, 0.6387602379564311, 0.7646603952658354], 
reward next is 0.2353, 
noisyNet noise sample is [array([1.3552852], dtype=float32), -1.1364329]. 
=============================================
[2019-03-23 10:44:39,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4375700e-11 1.0000000e+00 4.5439702e-16 9.5439236e-16 1.9181961e-17], sum to 1.0000
[2019-03-23 10:44:39,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7779
[2019-03-23 10:44:39,499] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1123495.614129394 W.
[2019-03-23 10:44:39,501] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333334, 78.0, 1.0, 2.0, 0.3308034872622753, 1.0, 2.0, 0.3308034872622753, 1.0, 1.0, 0.6697449867326631, 6.911200000000001, 6.9112, 77.3421103, 1123495.614129394, 1123495.614129393, 273586.372202976], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3670800.0000, 
sim time next is 3671400.0000, 
raw observation next is [24.16666666666666, 78.0, 1.0, 2.0, 0.4814230953031135, 1.0, 2.0, 0.4814230953031135, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846343529889, 1092653.024667601, 1092653.024667601, 227949.6149004067], 
processed observation next is [1.0, 0.4782608695652174, 0.7348484848484845, 0.78, 1.0, 1.0, 0.35177886912889184, 1.0, 1.0, 0.35177886912889184, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288128664626, 0.4046863054324448, 0.4046863054324448, 0.5559746704887969], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17457443], dtype=float32), -1.4859377]. 
=============================================
[2019-03-23 10:44:41,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3515130e-13 1.0000000e+00 6.8037479e-21 1.7949788e-19 9.6709924e-22], sum to 1.0000
[2019-03-23 10:44:41,360] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4284
[2019-03-23 10:44:41,366] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5339720275695984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 607908.6198355359, 607908.6198355359, 147264.3341759643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3709800.0000, 
sim time next is 3710400.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5318793514300938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 605526.0726375626, 605526.0726375626, 147004.1147654279], 
processed observation next is [1.0, 0.9565217391304348, 0.7272727272727273, 0.83, 1.0, 1.0, 0.4148491892876172, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22426891579168987, 0.22426891579168987, 0.35854662137909243], 
reward next is 0.6415, 
noisyNet noise sample is [array([-0.7159624], dtype=float32), -0.051367976]. 
=============================================
[2019-03-23 10:44:49,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2329295e-14 1.0000000e+00 2.6742516e-22 3.7928990e-21 3.7594882e-24], sum to 1.0000
[2019-03-23 10:44:49,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0669
[2019-03-23 10:44:49,664] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 53.66666666666667, 1.0, 2.0, 0.3220360675148651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353658.7723394582, 353658.7723394582, 114102.4062646259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3960600.0000, 
sim time next is 3961200.0000, 
raw observation next is [22.66666666666667, 54.33333333333334, 1.0, 2.0, 0.3218633527582166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353224.7430109989, 353224.7430109992, 113999.1920340932], 
processed observation next is [0.0, 0.8695652173913043, 0.6666666666666669, 0.5433333333333334, 1.0, 1.0, 0.15232919094777073, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13082397889296254, 0.13082397889296268, 0.2780468098392517], 
reward next is 0.7220, 
noisyNet noise sample is [array([1.2093873], dtype=float32), -0.50709814]. 
=============================================
[2019-03-23 10:44:54,188] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9739769e-13 1.0000000e+00 1.3499367e-20 3.7432107e-20 3.1795585e-22], sum to 1.0000
[2019-03-23 10:44:54,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3705
[2019-03-23 10:44:54,203] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 49.5, 1.0, 2.0, 0.3390163397341452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375290.150425946, 375290.1504259463, 116479.9730307644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3952200.0000, 
sim time next is 3952800.0000, 
raw observation next is [24.0, 50.0, 1.0, 2.0, 0.3368253189391334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372522.4393481191, 372522.4393481194, 116177.276462922], 
processed observation next is [0.0, 0.782608695652174, 0.7272727272727273, 0.5, 1.0, 1.0, 0.17103164867391676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1379712738326367, 0.13797127383263683, 0.2833592108851756], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.9159532], dtype=float32), 0.1428567]. 
=============================================
[2019-03-23 10:44:55,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8991432e-12 1.0000000e+00 3.6876931e-21 5.3787238e-19 3.6275582e-21], sum to 1.0000
[2019-03-23 10:44:55,165] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6397
[2019-03-23 10:44:55,168] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 56.33333333333333, 1.0, 2.0, 0.3342393918813696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 370658.2936535372, 370658.2936535372, 116383.4507887633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3924600.0000, 
sim time next is 3925200.0000, 
raw observation next is [23.0, 55.66666666666667, 1.0, 2.0, 0.3299350592661541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 365273.1902601794, 365273.1902601791, 115807.6382635086], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.5566666666666668, 1.0, 1.0, 0.16241882408269256, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1352863667630294, 0.1352863667630293, 0.2824576543012405], 
reward next is 0.7175, 
noisyNet noise sample is [array([-0.29278785], dtype=float32), -1.0397894]. 
=============================================
[2019-03-23 10:44:55,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9636880e-14 1.0000000e+00 2.9079391e-21 4.7631564e-20 5.1934970e-23], sum to 1.0000
[2019-03-23 10:44:55,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4920
[2019-03-23 10:44:55,270] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.16666666666666, 76.33333333333334, 1.0, 2.0, 0.2929213914807777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 318066.8492314044, 318066.8492314044, 104308.1695263644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.2895903108613428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 314448.6469200488, 314448.6469200488, 102576.4528121615], 
processed observation next is [1.0, 0.0, 0.45454545454545453, 0.77, 1.0, 1.0, 0.11198788857667848, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11646246182224029, 0.11646246182224029, 0.2501864702735646], 
reward next is 0.7498, 
noisyNet noise sample is [array([-0.92953646], dtype=float32), -1.247975]. 
=============================================
[2019-03-23 10:44:55,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5844103e-12 1.0000000e+00 1.6846458e-18 6.8490361e-20 7.6096653e-22], sum to 1.0000
[2019-03-23 10:44:55,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1751
[2019-03-23 10:44:55,752] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 45.0, 1.0, 2.0, 0.3513591581583679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392998.9852245351, 392998.9852245351, 119146.650736108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3940200.0000, 
sim time next is 3940800.0000, 
raw observation next is [26.0, 45.0, 1.0, 2.0, 0.3539806358805589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395938.737523505, 395938.737523505, 119362.7023000614], 
processed observation next is [0.0, 0.6086956521739131, 0.8181818181818182, 0.45, 1.0, 1.0, 0.1924757948506986, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1466439768605574, 0.1466439768605574, 0.2911285421952717], 
reward next is 0.7089, 
noisyNet noise sample is [array([1.8877068], dtype=float32), -0.59521157]. 
=============================================
[2019-03-23 10:44:57,524] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0887649e-13 1.0000000e+00 6.3985036e-22 6.6823977e-19 2.7770289e-22], sum to 1.0000
[2019-03-23 10:44:57,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3022
[2019-03-23 10:44:57,536] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.33333333333333, 96.0, 1.0, 2.0, 0.275107658520295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 298717.9787861248, 298717.9787861245, 94184.7373459646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3990000.0000, 
sim time next is 3990600.0000, 
raw observation next is [15.0, 97.0, 1.0, 2.0, 0.26407413942859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286734.0080571207, 286734.0080571204, 90414.11577068052], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 0.97, 1.0, 1.0, 0.08009267428573746, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10619778076189657, 0.10619778076189644, 0.22052223358702566], 
reward next is 0.7795, 
noisyNet noise sample is [array([-0.88535035], dtype=float32), -0.8459646]. 
=============================================
[2019-03-23 10:44:57,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2478997e-12 1.0000000e+00 1.0815969e-21 2.7954617e-20 1.8884606e-21], sum to 1.0000
[2019-03-23 10:44:57,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1021
[2019-03-23 10:44:57,898] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 48.5, 1.0, 2.0, 0.3392759141451539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 376220.0638959208, 376220.063895921, 116758.8034752272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3951000.0000, 
sim time next is 3951600.0000, 
raw observation next is [24.33333333333334, 49.0, 1.0, 2.0, 0.3398903091271803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 376586.4482494449, 376586.4482494446, 116678.366630983], 
processed observation next is [0.0, 0.7391304347826086, 0.7424242424242427, 0.49, 1.0, 1.0, 0.17486288640897538, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13947646231460922, 0.1394764623146091, 0.2845813820267878], 
reward next is 0.7154, 
noisyNet noise sample is [array([-0.667409], dtype=float32), 0.76488173]. 
=============================================
[2019-03-23 10:45:01,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7404962e-12 1.0000000e+00 8.3467621e-19 2.1937082e-18 3.9614387e-20], sum to 1.0000
[2019-03-23 10:45:01,549] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9359
[2019-03-23 10:45:01,552] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 91.0, 1.0, 2.0, 0.476811265311344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 524431.0357723563, 524431.0357723567, 126935.1201900491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4008600.0000, 
sim time next is 4009200.0000, 
raw observation next is [17.33333333333333, 92.0, 1.0, 2.0, 0.495852651193795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 544945.3850678536, 544945.385067854, 128541.2374050813], 
processed observation next is [1.0, 0.391304347826087, 0.42424242424242403, 0.92, 1.0, 1.0, 0.3698158139922437, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20183162409920505, 0.20183162409920516, 0.3135152131831251], 
reward next is 0.6865, 
noisyNet noise sample is [array([-0.79001516], dtype=float32), -0.3337508]. 
=============================================
[2019-03-23 10:45:02,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3714255e-13 1.0000000e+00 1.4377309e-18 8.5405662e-18 2.7356159e-20], sum to 1.0000
[2019-03-23 10:45:02,690] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2926
[2019-03-23 10:45:02,694] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 95.0, 1.0, 2.0, 0.5272353111005128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 579112.0722266735, 579112.0722266738, 131405.3022712235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4011000.0000, 
sim time next is 4011600.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.5108839362330245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 562216.6156760076, 562216.6156760076, 130203.6899639429], 
processed observation next is [1.0, 0.43478260869565216, 0.4090909090909091, 0.96, 1.0, 1.0, 0.38860492029128063, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2082283761762991, 0.2082283761762991, 0.31756997552181193], 
reward next is 0.6824, 
noisyNet noise sample is [array([-0.8315058], dtype=float32), -2.6972983]. 
=============================================
[2019-03-23 10:45:09,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9638011e-13 1.0000000e+00 4.1386314e-21 1.2037410e-19 2.6786417e-22], sum to 1.0000
[2019-03-23 10:45:09,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2509
[2019-03-23 10:45:09,693] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.5, 97.0, 1.0, 2.0, 0.3429540246491666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 374231.586976953, 374231.5869769533, 114785.9247352115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4242600.0000, 
sim time next is 4243200.0000, 
raw observation next is [16.33333333333333, 98.0, 1.0, 2.0, 0.3316846728518382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 361406.2766921752, 361406.2766921755, 113789.3798949598], 
processed observation next is [1.0, 0.08695652173913043, 0.37878787878787856, 0.98, 1.0, 1.0, 0.16460584106479775, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13385417655265747, 0.13385417655265758, 0.2775350729145361], 
reward next is 0.7225, 
noisyNet noise sample is [array([-1.5959449], dtype=float32), 1.2985322]. 
=============================================
[2019-03-23 10:45:12,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1904015e-13 1.0000000e+00 2.8153351e-20 9.3194107e-19 1.1866609e-21], sum to 1.0000
[2019-03-23 10:45:12,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3132
[2019-03-23 10:45:12,901] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 56.0, 1.0, 2.0, 0.3997762769145623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 452794.6585435743, 452794.6585435743, 126175.9710657734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4301400.0000, 
sim time next is 4302000.0000, 
raw observation next is [25.0, 57.0, 1.0, 2.0, 0.4023841748231529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 455819.5223651348, 455819.5223651348, 126464.430155752], 
processed observation next is [1.0, 0.8260869565217391, 0.7727272727272727, 0.57, 1.0, 1.0, 0.2529802185289411, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1688220453204203, 0.1688220453204203, 0.3084498296481756], 
reward next is 0.6916, 
noisyNet noise sample is [array([1.9996569], dtype=float32), 0.341269]. 
=============================================
[2019-03-23 10:45:12,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.222145]
 [68.222145]
 [68.222145]
 [68.222145]
 [68.222145]], R is [[68.23147583]
 [68.24141693]
 [68.25174713]
 [68.26216125]
 [68.27280426]].
[2019-03-23 10:45:19,334] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 10:45:19,337] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:45:19,337] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:45:19,338] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:45:19,339] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:45:19,339] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:45:19,340] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:45:19,339] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:45:19,338] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:45:19,343] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:45:19,340] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:45:19,367] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 10:45:19,367] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 10:45:19,367] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 10:45:19,449] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 10:45:19,451] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 10:45:28,353] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4279897]
[2019-03-23 10:45:28,354] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.0, 83.0, 1.0, 2.0, 0.3098153118444125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 337213.4364795523, 337213.436479552, 112131.7947670279]
[2019-03-23 10:45:28,356] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:45:28,360] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6042006e-13 1.0000000e+00 6.5480974e-20 3.1223974e-19 1.4318995e-21], sampled 0.8292668354117189
[2019-03-23 10:46:17,264] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4279897]
[2019-03-23 10:46:17,265] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.13793219333333, 99.6910614, 1.0, 2.0, 0.2979517160877491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 323510.2886444582, 323510.2886444579, 103296.3518058735]
[2019-03-23 10:46:17,266] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:46:17,270] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6042006e-13 1.0000000e+00 6.5480974e-20 3.1223974e-19 1.4318995e-21], sampled 0.25578769938641444
[2019-03-23 10:46:19,073] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4279897]
[2019-03-23 10:46:19,074] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [30.25451361666667, 46.87982473666667, 1.0, 2.0, 0.6300764729969505, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9236554269316539, 6.984284149227445, 6.9112, 95.55312292727723, 1264900.234651064, 1235569.876131369, 276532.9542092388]
[2019-03-23 10:46:19,074] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:46:19,076] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6042006e-13 1.0000000e+00 6.5480974e-20 3.1223974e-19 1.4318995e-21], sampled 0.1837177723525133
[2019-03-23 10:46:19,078] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1264900.234651064 W.
[2019-03-23 10:46:44,535] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4279897]
[2019-03-23 10:46:44,536] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.150534825, 82.76309948333335, 1.0, 2.0, 0.3550628606428415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 394257.5117645269, 394257.5117645269, 122518.740475814]
[2019-03-23 10:46:44,537] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:46:44,539] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6042006e-13 1.0000000e+00 6.5480974e-20 3.1223974e-19 1.4318995e-21], sampled 0.22526655364057668
[2019-03-23 10:46:48,548] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4279897]
[2019-03-23 10:46:48,550] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [17.61948715666667, 92.22732378666666, 1.0, 2.0, 0.5133917881151703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 568349.8728997777, 568349.8728997777, 135953.162123198]
[2019-03-23 10:46:48,551] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:46:48,552] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6042006e-13 1.0000000e+00 6.5480974e-20 3.1223974e-19 1.4318995e-21], sampled 0.8220123225299789
[2019-03-23 10:46:55,394] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4279897]
[2019-03-23 10:46:55,395] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.21284811, 96.38854222166667, 1.0, 2.0, 0.4695340834124238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 535715.5297586394, 535715.5297586394, 141897.1751059647]
[2019-03-23 10:46:55,396] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:46:55,399] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6042006e-13 1.0000000e+00 6.5480974e-20 3.1223974e-19 1.4318995e-21], sampled 0.7507178016526985
[2019-03-23 10:46:58,586] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:46:58,690] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:46:58,732] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:46:58,779] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:46:58,799] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:46:59,814] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2025000, evaluation results [2025000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:47:02,397] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.7444951e-12 1.0000000e+00 3.1287184e-18 6.0791290e-18 4.1467721e-20], sum to 1.0000
[2019-03-23 10:47:02,408] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-23 10:47:02,413] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 88.0, 1.0, 2.0, 0.4340993529323934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493901.3240725614, 493901.3240725614, 131135.8426489297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4417200.0000, 
sim time next is 4417800.0000, 
raw observation next is [21.0, 87.16666666666667, 1.0, 2.0, 0.4317958856564903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491063.2627936656, 491063.2627936656, 130703.5078307502], 
processed observation next is [0.0, 0.13043478260869565, 0.5909090909090909, 0.8716666666666667, 1.0, 1.0, 0.2897448570706128, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18187528251617244, 0.18187528251617244, 0.3187890434896346], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.448593], dtype=float32), -0.3982859]. 
=============================================
[2019-03-23 10:47:05,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9511798e-11 1.0000000e+00 3.6463627e-18 2.0316532e-17 3.9901507e-19], sum to 1.0000
[2019-03-23 10:47:05,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6165
[2019-03-23 10:47:05,526] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4598558859679799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 524609.5765154335, 524609.5765154335, 135737.5966759002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4441200.0000, 
sim time next is 4441800.0000, 
raw observation next is [23.83333333333333, 74.66666666666667, 1.0, 2.0, 0.4626067143954578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527789.3961995936, 527789.3961995936, 136170.5452206318], 
processed observation next is [0.0, 0.391304347826087, 0.7196969696969695, 0.7466666666666667, 1.0, 1.0, 0.32825839299432225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1954775541479976, 0.1954775541479976, 0.3321232810259312], 
reward next is 0.6679, 
noisyNet noise sample is [array([-1.0660042], dtype=float32), -0.75325614]. 
=============================================
[2019-03-23 10:47:06,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1365440e-15 1.0000000e+00 4.3994013e-22 9.4891914e-21 1.1840421e-22], sum to 1.0000
[2019-03-23 10:47:06,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8804
[2019-03-23 10:47:07,003] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.4618811080632377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 526808.9039500986, 526808.9039500986, 135664.5435188529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4494000.0000, 
sim time next is 4494600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.4616544531435548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 526550.0462893476, 526550.0462893473, 135639.720165106], 
processed observation next is [0.0, 0.0, 0.5909090909090909, 0.94, 1.0, 1.0, 0.32706806642944347, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19501853566272132, 0.19501853566272123, 0.33082858576855123], 
reward next is 0.6692, 
noisyNet noise sample is [array([1.0835955], dtype=float32), 0.13835542]. 
=============================================
[2019-03-23 10:47:13,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.9139152e-15 1.0000000e+00 1.1434878e-22 1.3969867e-20 4.8808098e-24], sum to 1.0000
[2019-03-23 10:47:13,893] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2524
[2019-03-23 10:47:13,898] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 67.66666666666667, 1.0, 2.0, 0.36175519155054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406227.5727647666, 406227.5727647663, 120756.9627746182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5047800.0000, 
sim time next is 5048400.0000, 
raw observation next is [22.33333333333334, 66.33333333333334, 1.0, 2.0, 0.3623915195214751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406791.9066111686, 406791.9066111686, 120735.8066152776], 
processed observation next is [0.0, 0.43478260869565216, 0.6515151515151518, 0.6633333333333334, 1.0, 1.0, 0.20298939940184382, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15066366911524762, 0.15066366911524762, 0.29447757711043315], 
reward next is 0.7055, 
noisyNet noise sample is [array([0.12976849], dtype=float32), -1.9522662]. 
=============================================
[2019-03-23 10:47:23,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7415701e-14 1.0000000e+00 1.8459674e-21 9.7492328e-20 3.0860881e-21], sum to 1.0000
[2019-03-23 10:47:23,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9978
[2019-03-23 10:47:23,919] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 79.66666666666667, 1.0, 2.0, 0.8824587658953529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1005057.493259306, 1005057.493259306, 190842.8523374269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4891200.0000, 
sim time next is 4891800.0000, 
raw observation next is [22.0, 78.83333333333333, 1.0, 2.0, 0.8770471158846873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 998384.7193791039, 998384.7193791039, 189442.9993684967], 
processed observation next is [1.0, 0.6086956521739131, 0.6363636363636364, 0.7883333333333333, 1.0, 1.0, 0.8463088948558591, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.369772118288557, 0.369772118288557, 0.4620560960207237], 
reward next is 0.5379, 
noisyNet noise sample is [array([-0.18580218], dtype=float32), -0.7189154]. 
=============================================
[2019-03-23 10:47:25,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5974455e-13 1.0000000e+00 2.2240399e-20 2.8616138e-19 5.6575908e-22], sum to 1.0000
[2019-03-23 10:47:25,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9935
[2019-03-23 10:47:25,449] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4455654627042325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507804.2246033997, 507804.2246033997, 133262.3689480448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4840800.0000, 
sim time next is 4841400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4447708574377938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506897.6585365623, 506897.6585365623, 133179.0958903647], 
processed observation next is [1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.30596357179724226, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18773987353206012, 0.18773987353206012, 0.324827063147231], 
reward next is 0.6752, 
noisyNet noise sample is [array([0.29777074], dtype=float32), -1.6311278]. 
=============================================
[2019-03-23 10:47:26,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4720252e-14 1.0000000e+00 2.9209369e-20 4.9114127e-20 5.6375550e-22], sum to 1.0000
[2019-03-23 10:47:26,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3177
[2019-03-23 10:47:26,754] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4011323307925338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454699.6339689923, 454699.6339689923, 126549.4514948649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4860000.0000, 
sim time next is 4860600.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4191090764561712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 475104.632146619, 475104.632146619, 128263.9011287549], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 1.0, 1.0, 1.0, 0.27388634557021396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.17596467857282186, 0.17596467857282186, 0.3128387832408656], 
reward next is 0.6872, 
noisyNet noise sample is [array([1.4745879], dtype=float32), 2.1684456]. 
=============================================
[2019-03-23 10:47:27,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6196541e-12 1.0000000e+00 5.5914973e-18 3.1952396e-17 5.8383652e-21], sum to 1.0000
[2019-03-23 10:47:27,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1285
[2019-03-23 10:47:27,080] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 87.0, 1.0, 2.0, 0.3654375169752801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 409786.4869952445, 409786.4869952445, 120784.8563878006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5294400.0000, 
sim time next is 5295000.0000, 
raw observation next is [19.4, 87.0, 1.0, 2.0, 0.3653427537620773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 409682.1742347017, 409682.1742347014, 120777.8684153927], 
processed observation next is [1.0, 0.2608695652173913, 0.5181818181818181, 0.87, 1.0, 1.0, 0.20667844220259662, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.15173413860544507, 0.15173413860544496, 0.2945801668668115], 
reward next is 0.7054, 
noisyNet noise sample is [array([0.1993728], dtype=float32), 1.0519172]. 
=============================================
[2019-03-23 10:47:27,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.12022]
 [69.12022]
 [69.12022]
 [69.12022]
 [69.12022]], R is [[69.13443756]
 [69.14849854]
 [69.16273499]
 [69.1776123 ]
 [69.19126129]].
[2019-03-23 10:47:27,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4540224e-16 1.0000000e+00 3.6340245e-22 1.5645918e-21 1.5588590e-23], sum to 1.0000
[2019-03-23 10:47:27,421] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4797
[2019-03-23 10:47:27,427] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.7783446208208739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 883752.6973242161, 883752.6973242161, 172274.1214511367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4872600.0000, 
sim time next is 4873200.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.7834177862233779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 889500.3091360445, 889500.3091360445, 173004.0083197685], 
processed observation next is [1.0, 0.391304347826087, 0.5, 1.0, 1.0, 1.0, 0.7292722327792223, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3294445589392757, 0.3294445589392757, 0.4219609959018744], 
reward next is 0.5780, 
noisyNet noise sample is [array([0.05565586], dtype=float32), 0.7102803]. 
=============================================
[2019-03-23 10:47:28,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7559287e-12 1.0000000e+00 2.0132278e-19 6.6645810e-18 7.4560542e-21], sum to 1.0000
[2019-03-23 10:47:28,319] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1830
[2019-03-23 10:47:28,324] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.00000000000001, 1.0, 2.0, 0.3351753034907791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 366747.3355253571, 366747.3355253568, 114574.8960953046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4950600.0000, 
sim time next is 4951200.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3633166450082376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397659.4924174282, 397659.4924174282, 116706.9118397684], 
processed observation next is [1.0, 0.30434782608695654, 0.4090909090909091, 0.94, 1.0, 1.0, 0.20414580626029702, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14728129348793637, 0.14728129348793637, 0.28465100448724], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.8271117], dtype=float32), -1.1162093]. 
=============================================
[2019-03-23 10:47:30,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3655927e-13 1.0000000e+00 3.0314978e-18 1.9773872e-18 5.7481318e-22], sum to 1.0000
[2019-03-23 10:47:30,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2142
[2019-03-23 10:47:30,769] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 95.0, 1.0, 2.0, 0.3250812436343497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356625.3358282366, 356625.3358282366, 114182.5343241763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4942200.0000, 
sim time next is 4942800.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3223177634561957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 352872.4165057332, 352872.4165057334, 113720.2672367843], 
processed observation next is [1.0, 0.21739130434782608, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15289720432024465, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.130693487594716, 0.13069348759471608, 0.27736650545557145], 
reward next is 0.7226, 
noisyNet noise sample is [array([-0.5856093], dtype=float32), 0.93271446]. 
=============================================
[2019-03-23 10:47:33,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0736060e-13 1.0000000e+00 8.1994657e-22 4.9726799e-21 3.2505545e-22], sum to 1.0000
[2019-03-23 10:47:33,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2403
[2019-03-23 10:47:33,969] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 77.83333333333334, 1.0, 2.0, 0.2892031892454048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 314028.1591956608, 314028.1591956611, 101629.6110270828], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5003400.0000, 
sim time next is 5004000.0000, 
raw observation next is [18.0, 77.0, 1.0, 2.0, 0.290844790643175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 315811.2531246115, 315811.2531246112, 102804.7953797564], 
processed observation next is [1.0, 0.9565217391304348, 0.45454545454545453, 0.77, 1.0, 1.0, 0.11355598830396871, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11696713078689315, 0.11696713078689304, 0.2507434033652595], 
reward next is 0.7493, 
noisyNet noise sample is [array([-1.0785236], dtype=float32), 1.6203642]. 
=============================================
[2019-03-23 10:47:33,982] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.56024]
 [70.56024]
 [70.56024]
 [70.56024]
 [70.56024]], R is [[70.60390472]
 [70.64998627]
 [70.6984024 ]
 [70.74910736]
 [70.80213165]].
[2019-03-23 10:47:34,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1648379e-14 1.0000000e+00 2.2340565e-20 7.9103030e-20 3.0934412e-22], sum to 1.0000
[2019-03-23 10:47:34,106] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9071
[2019-03-23 10:47:34,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 66.66666666666667, 1.0, 2.0, 0.2838678946342951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308233.0512476545, 308233.0512476548, 98736.62333364406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4992600.0000, 
sim time next is 4993200.0000, 
raw observation next is [19.0, 68.0, 1.0, 2.0, 0.2841244075427778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 308511.6697068024, 308511.6697068021, 99066.23218713807], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.68, 1.0, 1.0, 0.10515550942847222, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11426358137288978, 0.11426358137288967, 0.2416249565539953], 
reward next is 0.7584, 
noisyNet noise sample is [array([-1.0465153], dtype=float32), 1.4113367]. 
=============================================
[2019-03-23 10:47:34,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6100033e-15 1.0000000e+00 1.8409035e-22 2.0475767e-20 6.3861370e-23], sum to 1.0000
[2019-03-23 10:47:34,418] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6080
[2019-03-23 10:47:34,425] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2756332786145833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 299288.8843221362, 299288.8843221365, 95623.10474029719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5011200.0000, 
sim time next is 5011800.0000, 
raw observation next is [16.83333333333334, 83.00000000000001, 1.0, 2.0, 0.2740152009870689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297531.4013827565, 297531.4013827562, 94851.73891866134], 
processed observation next is [0.0, 0.0, 0.40151515151515177, 0.8300000000000002, 1.0, 1.0, 0.09251900123383609, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11019681532694685, 0.11019681532694674, 0.2313457046796618], 
reward next is 0.7687, 
noisyNet noise sample is [array([0.5652414], dtype=float32), 0.25832322]. 
=============================================
[2019-03-23 10:47:35,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7334506e-15 1.0000000e+00 1.1677204e-20 1.1567777e-21 4.2336236e-22], sum to 1.0000
[2019-03-23 10:47:35,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8283
[2019-03-23 10:47:35,907] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 53.00000000000001, 1.0, 2.0, 0.4112358447509502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 467335.4641109086, 467335.4641109086, 128386.9231319708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5070000.0000, 
sim time next is 5070600.0000, 
raw observation next is [26.5, 52.5, 1.0, 2.0, 0.4127024564124548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 469149.0581890019, 469149.0581890022, 128653.1548879705], 
processed observation next is [0.0, 0.6956521739130435, 0.8409090909090909, 0.525, 1.0, 1.0, 0.26587807051556844, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1737589104403711, 0.1737589104403712, 0.31378818265358654], 
reward next is 0.6862, 
noisyNet noise sample is [array([0.8899019], dtype=float32), -0.3196338]. 
=============================================
[2019-03-23 10:47:36,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9589190e-13 1.0000000e+00 1.0069884e-18 5.9832569e-19 1.4375039e-21], sum to 1.0000
[2019-03-23 10:47:36,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1416
[2019-03-23 10:47:36,626] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 52.16666666666666, 1.0, 2.0, 0.4200000289657189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 477984.9289601113, 477984.9289601113, 129862.9201099052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5076600.0000, 
sim time next is 5077200.0000, 
raw observation next is [26.66666666666667, 53.33333333333334, 1.0, 2.0, 0.4219285406173166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 480313.3897752074, 480313.3897752077, 130190.8576020961], 
processed observation next is [0.0, 0.782608695652174, 0.8484848484848487, 0.5333333333333334, 1.0, 1.0, 0.27741067577164574, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1778938480648916, 0.17789384806489172, 0.3175386770782832], 
reward next is 0.6825, 
noisyNet noise sample is [array([2.194103], dtype=float32), 0.15622629]. 
=============================================
[2019-03-23 10:47:40,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2465698e-12 1.0000000e+00 1.6166252e-19 4.0124815e-19 5.3688964e-22], sum to 1.0000
[2019-03-23 10:47:40,361] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2122
[2019-03-23 10:47:40,366] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 78.83333333333333, 1.0, 2.0, 0.4432790299317216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505397.1223963806, 505397.1223963806, 133333.4328197665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5129400.0000, 
sim time next is 5130000.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.4447441189722908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 507124.8563272175, 507124.8563272175, 133585.4404401843], 
processed observation next is [0.0, 0.391304347826087, 0.6818181818181818, 0.78, 1.0, 1.0, 0.3059301487153635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1878240208619324, 0.1878240208619324, 0.32581814741508364], 
reward next is 0.6742, 
noisyNet noise sample is [array([-0.93072706], dtype=float32), 0.6295874]. 
=============================================
[2019-03-23 10:47:40,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.10167]
 [67.10167]
 [67.10167]
 [67.10167]
 [67.10167]], R is [[67.10483551]
 [67.10858154]
 [67.11277008]
 [67.11730194]
 [67.12239838]].
[2019-03-23 10:47:43,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6057706e-12 1.0000000e+00 2.0072071e-20 1.5857267e-18 1.3957235e-21], sum to 1.0000
[2019-03-23 10:47:43,029] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6984
[2019-03-23 10:47:43,034] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.8545503359681601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 974716.1770468483, 974716.1770468483, 193331.2076669901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5231400.0000, 
sim time next is 5232000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.8461526389645394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 965115.2398041103, 965115.2398041103, 191922.6197614978], 
processed observation next is [1.0, 0.5652173913043478, 0.6363636363636364, 0.94, 1.0, 1.0, 0.8076907987056742, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3574500888163371, 0.3574500888163371, 0.4681039506377995], 
reward next is 0.5319, 
noisyNet noise sample is [array([-1.5230501], dtype=float32), -1.308639]. 
=============================================
[2019-03-23 10:47:43,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.05604]
 [65.05604]
 [65.05604]
 [65.05604]
 [65.05604]], R is [[64.9373703 ]
 [64.81645203]
 [64.71601105]
 [64.64730835]
 [64.59308624]].
[2019-03-23 10:47:43,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1687896e-11 1.0000000e+00 3.1386163e-18 1.0298824e-17 1.5374945e-20], sum to 1.0000
[2019-03-23 10:47:43,438] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8318
[2019-03-23 10:47:43,442] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 58.0, 1.0, 2.0, 0.4266002193183771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 485204.5014636535, 485204.5014636535, 130234.9462516586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347800.0000, 
sim time next is 5348400.0000, 
raw observation next is [25.36666666666667, 59.33333333333333, 1.0, 2.0, 0.4313867724052046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 490794.466430725, 490794.4664307253, 130845.4727944333], 
processed observation next is [1.0, 0.9130434782608695, 0.7893939393939395, 0.5933333333333333, 1.0, 1.0, 0.28923346550650575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18177572830767594, 0.18177572830767605, 0.3191352994986178], 
reward next is 0.6809, 
noisyNet noise sample is [array([-1.4943233], dtype=float32), 0.26827458]. 
=============================================
[2019-03-23 10:47:44,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6230727e-12 1.0000000e+00 1.4819166e-17 1.5330810e-17 1.9074160e-20], sum to 1.0000
[2019-03-23 10:47:44,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7787
[2019-03-23 10:47:44,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 96.0, 1.0, 2.0, 0.4998769642112281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 569987.0119567572, 569987.0119567572, 142211.7342958284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5260800.0000, 
sim time next is 5261400.0000, 
raw observation next is [21.75, 97.0, 1.0, 2.0, 0.5019969705168223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 572350.5364314921, 572350.5364314923, 142537.1257287049], 
processed observation next is [1.0, 0.9130434782608695, 0.625, 0.97, 1.0, 1.0, 0.3774962131460279, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2119816801598119, 0.21198168015981197, 0.34765152616757294], 
reward next is 0.6523, 
noisyNet noise sample is [array([0.16865726], dtype=float32), 0.28825548]. 
=============================================
[2019-03-23 10:47:44,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0137259e-13 1.0000000e+00 1.1875089e-19 2.6872019e-19 3.1099604e-21], sum to 1.0000
[2019-03-23 10:47:44,817] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8595
[2019-03-23 10:47:44,824] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.5, 1.0, 2.0, 0.4516454265388739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 514238.615549457, 514238.6155494567, 133289.929700493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5196600.0000, 
sim time next is 5197200.0000, 
raw observation next is [21.66666666666667, 84.66666666666666, 1.0, 2.0, 0.452422480689804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 515238.0184294698, 515238.0184294698, 133496.5088933237], 
processed observation next is [1.0, 0.13043478260869565, 0.6212121212121214, 0.8466666666666666, 1.0, 1.0, 0.31552810086225497, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19082889571461845, 0.19082889571461845, 0.3256012412032286], 
reward next is 0.6744, 
noisyNet noise sample is [array([0.49762177], dtype=float32), 1.1120822]. 
=============================================
[2019-03-23 10:47:48,895] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 10:47:48,897] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:47:48,898] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:48,898] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:47:48,899] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:47:48,900] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:48,901] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:47:48,902] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:48,903] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:47:48,902] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:48,903] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:47:48,931] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 10:47:48,956] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 10:47:48,981] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 10:47:48,982] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 10:47:48,983] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 10:47:55,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:47:55,056] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [12.88420945, 82.82716597, 1.0, 2.0, 0.4976825821924245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 540471.7826729409, 540471.7826729409, 104377.370369208]
[2019-03-23 10:47:55,059] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:47:55,061] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.618103814720393
[2019-03-23 10:48:08,133] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:48:08,135] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.45, 80.16666666666667, 1.0, 2.0, 0.4608760637069551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 525161.3713939185, 525161.3713939182, 139111.9895605005]
[2019-03-23 10:48:08,136] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:48:08,138] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.05705935307735033
[2019-03-23 10:48:08,237] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:48:08,239] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.6813006680474288, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9740665666454755, 6.911199999999999, 6.9112, 77.32846344259124, 1324641.454157649, 1324641.454157649, 286179.7145166187]
[2019-03-23 10:48:08,240] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:48:08,242] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.909455104748306
[2019-03-23 10:48:08,245] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1324641.454157649 W.
[2019-03-23 10:48:10,732] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:48:10,734] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4456443911992561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 507229.7269481258, 507229.7269481258, 136847.4475847385]
[2019-03-23 10:48:10,735] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:48:10,736] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.572633689426927
[2019-03-23 10:48:24,057] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:48:24,058] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.02430448, 99.02325762833334, 1.0, 2.0, 0.2038410315939257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 221307.8906766133, 221307.8906766129, 78290.43585505283]
[2019-03-23 10:48:24,060] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:48:24,062] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.9987633964448014
[2019-03-23 10:48:52,373] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:48:52,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.26007731, 78.47933166, 1.0, 2.0, 0.3385991066948964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 373657.7680422298, 373657.7680422291, 120306.1910939935]
[2019-03-23 10:48:52,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:48:52,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.8837575217675381
[2019-03-23 10:48:57,982] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:48:57,983] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.4373628052243182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 498294.179672632, 498294.1796726323, 132204.0570837193]
[2019-03-23 10:48:57,985] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:48:57,989] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.39336467921766516
[2019-03-23 10:49:05,058] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:49:05,059] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [15.9, 88.33333333333334, 1.0, 2.0, 0.256063275302798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 278018.0993683961, 278018.0993683957, 93829.92379358804]
[2019-03-23 10:49:05,061] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:49:05,063] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.14019682209103523
[2019-03-23 10:49:11,552] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:49:11,553] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.49351659833333, 66.73466970666666, 1.0, 2.0, 0.4790049436744353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 538224.610158037, 538224.610158037, 135943.393657672]
[2019-03-23 10:49:11,553] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:49:11,556] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.18743758748302586
[2019-03-23 10:49:16,633] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:49:16,637] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.96148024666667, 89.28907274, 1.0, 2.0, 0.2871379704897423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 311765.8845975601, 311765.8845975601, 99094.65873183461]
[2019-03-23 10:49:16,638] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:49:16,640] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.4586220821800733
[2019-03-23 10:49:18,375] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.43267226]
[2019-03-23 10:49:18,375] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.83333333333333, 79.83333333333334, 1.0, 2.0, 0.5619058838331664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 639130.1451530505, 639130.1451530508, 144885.3407628185]
[2019-03-23 10:49:18,376] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:49:18,379] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7773017e-13 1.0000000e+00 1.2574548e-19 6.0589842e-19 2.7772316e-21], sampled 0.8858249344521502
[2019-03-23 10:49:28,157] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:49:28,293] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:49:28,454] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:49:28,471] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:49:28,558] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:49:29,571] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2050000, evaluation results [2050000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:49:30,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1746636e-12 1.0000000e+00 5.6544520e-18 3.9547257e-17 2.2390477e-20], sum to 1.0000
[2019-03-23 10:49:30,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7058
[2019-03-23 10:49:30,544] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 163219.1922972146, 163219.1922972146, 59579.78386459305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5708400.0000, 
sim time next is 5709000.0000, 
raw observation next is [11.1, 77.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 162228.5255568689, 162228.5255568689, 59449.46271651904], 
processed observation next is [0.0, 0.043478260869565216, 0.1409090909090909, 0.77, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.06008463909513663, 0.06008463909513663, 0.14499868955248546], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43376973], dtype=float32), 0.7098721]. 
=============================================
[2019-03-23 10:49:30,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.8858]
 [67.8858]
 [67.8858]
 [67.8858]
 [67.8858]], R is [[67.20695496]
 [66.53488922]
 [65.86953735]
 [65.21084595]
 [64.55873871]].
[2019-03-23 10:49:33,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3782226e-12 1.0000000e+00 1.3706683e-18 8.7258693e-19 1.4896054e-20], sum to 1.0000
[2019-03-23 10:49:33,347] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-23 10:49:33,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1566302.050424408 W.
[2019-03-23 10:49:33,357] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.7, 67.0, 1.0, 2.0, 0.9051036120003075, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9853018871588604, 6.911200000000001, 6.9112, 77.32846344354104, 1566302.050424408, 1566302.050424408, 334168.8646671293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5396400.0000, 
sim time next is 5397000.0000, 
raw observation next is [27.7, 66.33333333333334, 1.0, 2.0, 0.6863825385310109, 1.0, 1.0, 0.6863825385310109, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1543873.300831062, 1543873.300831062, 287536.4583658034], 
processed observation next is [1.0, 0.4782608695652174, 0.8954545454545454, 0.6633333333333334, 1.0, 1.0, 0.6079781731637637, 1.0, 0.5, 0.6079781731637637, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5718049262337267, 0.5718049262337267, 0.7013084350385449], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50978047], dtype=float32), -1.4328336]. 
=============================================
[2019-03-23 10:49:33,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.08382]
 [69.08382]
 [69.08382]
 [69.08382]
 [69.08382]], R is [[68.39298248]
 [67.89400482]
 [67.215065  ]
 [66.85951233]
 [66.42635345]].
[2019-03-23 10:49:35,438] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4519091e-12 1.0000000e+00 4.2299518e-18 2.2807824e-18 1.6228589e-20], sum to 1.0000
[2019-03-23 10:49:35,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6149
[2019-03-23 10:49:35,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1080642.715275245 W.
[2019-03-23 10:49:35,462] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.08333333333334, 78.66666666666667, 1.0, 2.0, 0.9473013741597893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1080642.715275245, 1080642.715275245, 209747.5858339002], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5389800.0000, 
sim time next is 5390400.0000, 
raw observation next is [24.36666666666667, 78.33333333333334, 1.0, 2.0, 0.3196983741695247, 1.0, 1.0, 0.3196983741695247, 1.0, 1.0, 0.6475262180922473, 6.9112, 6.9112, 77.3421103, 1087979.903770686, 1087979.903770686, 268217.0569988661], 
processed observation next is [1.0, 0.391304347826087, 0.7439393939393941, 0.7833333333333334, 1.0, 1.0, 0.14962296771190584, 1.0, 0.5, 0.14962296771190584, 1.0, 0.5, 0.49646602584606764, 0.0, 0.0, 0.5085185399722538, 0.40295551991506884, 0.40295551991506884, 0.6541879438996734], 
reward next is 0.3458, 
noisyNet noise sample is [array([-0.38258305], dtype=float32), -2.0491462]. 
=============================================
[2019-03-23 10:49:35,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.16916675e-12 1.00000000e+00 5.76518459e-18 1.26545366e-17
 6.61725232e-20], sum to 1.0000
[2019-03-23 10:49:35,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7424
[2019-03-23 10:49:35,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 95.0, 1.0, 2.0, 0.3979735967784411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 449418.4144784815, 449418.4144784812, 125192.2559948009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427000.0000, 
sim time next is 5427600.0000, 
raw observation next is [19.0, 95.66666666666666, 1.0, 2.0, 0.3970694942735168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 448296.2640756891, 448296.2640756891, 125052.4173724242], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.9566666666666666, 1.0, 1.0, 0.24633686784189596, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16603565336136633, 0.16603565336136633, 0.3050058960303029], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.871218], dtype=float32), -0.37919256]. 
=============================================
[2019-03-23 10:49:42,345] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8222795e-11 1.0000000e+00 1.0985517e-18 2.6585332e-17 8.9651593e-19], sum to 1.0000
[2019-03-23 10:49:42,350] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2425
[2019-03-23 10:49:42,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.0, 1.0, 2.0, 0.4284749419684503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486429.8484705383, 486429.8484705383, 129670.7283763466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5545800.0000, 
sim time next is 5546400.0000, 
raw observation next is [20.0, 93.0, 1.0, 2.0, 0.4237886258365116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 481092.7925237375, 481092.7925237375, 129201.5181731795], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.93, 1.0, 1.0, 0.2797357822956395, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1781825157495324, 0.1781825157495324, 0.31512565408092563], 
reward next is 0.6849, 
noisyNet noise sample is [array([0.90684843], dtype=float32), 0.3926082]. 
=============================================
[2019-03-23 10:49:43,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1423158e-13 1.0000000e+00 5.8092429e-20 8.1561120e-20 3.1425771e-21], sum to 1.0000
[2019-03-23 10:49:43,721] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0691
[2019-03-23 10:49:43,726] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 89.5, 1.0, 2.0, 0.3462922666434518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 384637.4116694953, 384637.4116694956, 117560.6710494995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5975400.0000, 
sim time next is 5976000.0000, 
raw observation next is [18.3, 90.0, 1.0, 2.0, 0.3452596873042789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 383344.676788314, 383344.6767883142, 117419.8922196493], 
processed observation next is [1.0, 0.17391304347826086, 0.4681818181818182, 0.9, 1.0, 1.0, 0.18157460913034862, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14197950992159777, 0.14197950992159786, 0.28638998102353486], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.67054445], dtype=float32), -0.31376436]. 
=============================================
[2019-03-23 10:49:43,742] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.347855]
 [67.347855]
 [67.347855]
 [67.347855]
 [67.347855]], R is [[67.38798523]
 [67.42736816]
 [67.46606445]
 [67.50387573]
 [67.53933716]].
[2019-03-23 10:49:56,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1006546e-13 1.0000000e+00 1.4881684e-20 2.5420863e-19 2.5443334e-22], sum to 1.0000
[2019-03-23 10:49:56,088] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9226
[2019-03-23 10:49:56,093] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 42.0, 1.0, 2.0, 0.2688878619743221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 291962.3589525361, 291962.3589525364, 84171.8929612721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5758800.0000, 
sim time next is 5759400.0000, 
raw observation next is [21.6, 42.0, 1.0, 2.0, 0.2679238792115763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 290915.3393623795, 290915.3393623798, 84062.11944394822], 
processed observation next is [0.0, 0.6521739130434783, 0.6181818181818183, 0.42, 1.0, 1.0, 0.08490484901447035, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10774642198606649, 0.1077464219860666, 0.2050295596193859], 
reward next is 0.7950, 
noisyNet noise sample is [array([0.14534473], dtype=float32), 0.05625567]. 
=============================================
[2019-03-23 10:49:57,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6374131e-12 1.0000000e+00 4.0514541e-20 2.8968261e-19 2.9615724e-22], sum to 1.0000
[2019-03-23 10:49:57,869] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8723
[2019-03-23 10:49:57,872] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 73.5, 1.0, 2.0, 0.4808930524224904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 536177.9273824187, 536177.9273824187, 129983.7590249659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5907000.0000, 
sim time next is 5907600.0000, 
raw observation next is [21.1, 73.0, 1.0, 2.0, 0.4891890644450901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 547556.6741299711, 547556.6741299714, 131673.433709341], 
processed observation next is [1.0, 0.391304347826087, 0.5954545454545456, 0.73, 1.0, 1.0, 0.3614863305563626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2027987681962856, 0.2027987681962857, 0.32115471636424636], 
reward next is 0.6788, 
noisyNet noise sample is [array([0.5341858], dtype=float32), -0.35048532]. 
=============================================
[2019-03-23 10:49:58,273] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5483921e-14 1.0000000e+00 6.1939139e-21 6.4868622e-20 8.9784886e-23], sum to 1.0000
[2019-03-23 10:49:58,278] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5298
[2019-03-23 10:49:58,284] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333334, 54.33333333333334, 1.0, 2.0, 0.3808226893769292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413554.5081083887, 413554.508108389, 116974.5412300251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5825400.0000, 
sim time next is 5826000.0000, 
raw observation next is [21.96666666666667, 53.66666666666667, 1.0, 2.0, 0.3893537482714606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422822.8422168452, 422822.8422168452, 117629.3104530311], 
processed observation next is [1.0, 0.43478260869565216, 0.6348484848484849, 0.5366666666666667, 1.0, 1.0, 0.2366921853393257, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15660105267290564, 0.15660105267290564, 0.28690075720251484], 
reward next is 0.7131, 
noisyNet noise sample is [array([0.20337144], dtype=float32), -0.49490082]. 
=============================================
[2019-03-23 10:49:58,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.8493]
 [70.8493]
 [70.8493]
 [70.8493]
 [70.8493]], R is [[70.85390472]
 [70.86006165]
 [70.87221527]
 [70.89587402]
 [70.92826843]].
[2019-03-23 10:50:00,461] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8397695e-13 1.0000000e+00 6.2553931e-20 1.0032156e-18 1.0941878e-21], sum to 1.0000
[2019-03-23 10:50:00,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2727
[2019-03-23 10:50:00,478] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 71.83333333333334, 1.0, 2.0, 0.6369750653213468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 715295.0729709056, 715295.0729709059, 148669.5090841691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5908200.0000, 
sim time next is 5908800.0000, 
raw observation next is [21.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6781210972128503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 763409.3043953661, 763409.3043953661, 154585.0807421559], 
processed observation next is [1.0, 0.391304347826087, 0.628787878787879, 0.7066666666666667, 1.0, 1.0, 0.5976513715160628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.28274418681309854, 0.28274418681309854, 0.37703678229794124], 
reward next is 0.6230, 
noisyNet noise sample is [array([1.9365808], dtype=float32), 0.754255]. 
=============================================
[2019-03-23 10:50:01,809] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1019062e-13 1.0000000e+00 6.0095628e-19 1.9015975e-19 7.2023506e-22], sum to 1.0000
[2019-03-23 10:50:01,812] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3181
[2019-03-23 10:50:01,816] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 53.0, 1.0, 2.0, 0.3081918993146751, 1.0, 2.0, 0.3081918993146751, 1.0, 1.0, 0.6221535365191068, 6.911199999999999, 6.9112, 77.3421103, 1055493.114670937, 1055493.114670938, 256748.068483381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5918400.0000, 
sim time next is 5919000.0000, 
raw observation next is [26.51666666666667, 53.16666666666667, 1.0, 2.0, 0.7831087789198861, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 892837.8991351757, 892837.899135176, 176458.1108742773], 
processed observation next is [1.0, 0.5217391304347826, 0.8416666666666668, 0.5316666666666667, 1.0, 1.0, 0.7288859736498576, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.33068070338339844, 0.3306807033833985, 0.4303856362787251], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0709522], dtype=float32), -0.18294388]. 
=============================================
[2019-03-23 10:50:01,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.69422]
 [71.69422]
 [71.69422]
 [71.69422]
 [71.69422]], R is [[70.97727966]
 [70.64129639]
 [70.39556885]
 [70.19361877]
 [70.00048828]].
[2019-03-23 10:50:06,990] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4712599e-13 1.0000000e+00 3.9634188e-20 2.0120225e-19 2.6529760e-21], sum to 1.0000
[2019-03-23 10:50:07,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6875
[2019-03-23 10:50:07,006] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 78.0, 1.0, 2.0, 0.2210385729075685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 239994.0849210345, 239994.0849210348, 76539.08626361765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6058800.0000, 
sim time next is 6059400.0000, 
raw observation next is [15.21666666666667, 79.5, 1.0, 2.0, 0.222952192437141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 242072.3269541627, 242072.3269541624, 76342.89285292955], 
processed observation next is [1.0, 0.13043478260869565, 0.32803030303030317, 0.795, 1.0, 1.0, 0.02869024054642625, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08965641739043063, 0.08965641739043051, 0.18620217769007208], 
reward next is 0.8138, 
noisyNet noise sample is [array([0.15697894], dtype=float32), 0.23584366]. 
=============================================
[2019-03-23 10:50:18,675] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 10:50:18,676] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:50:18,677] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:50:18,678] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:50:18,678] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:50:18,679] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:50:18,679] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:50:18,681] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:50:18,679] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:50:18,684] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:50:18,685] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:50:18,708] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 10:50:18,734] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 10:50:18,735] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 10:50:18,782] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 10:50:18,811] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 10:50:23,199] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:50:23,200] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.54334409666667, 91.570291, 1.0, 2.0, 0.2959811081706423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 321370.0680973683, 321370.0680973687, 113569.4485542618]
[2019-03-23 10:50:23,204] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:50:23,208] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.8436253986103746
[2019-03-23 10:50:24,098] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:50:24,099] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.3, 82.66666666666667, 1.0, 2.0, 0.3530467888760037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 392591.8747322764, 392591.874732276, 122597.0724972141]
[2019-03-23 10:50:24,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:50:24,103] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.7292711289427843
[2019-03-23 10:50:41,930] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:50:41,931] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [22.271237225, 99.74896208, 1.0, 2.0, 0.5427174244068415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 615967.9295113703, 615967.9295113703, 153689.6019402816]
[2019-03-23 10:50:41,933] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:50:41,936] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.8351526308606387
[2019-03-23 10:50:44,082] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:50:44,083] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.4, 90.0, 1.0, 2.0, 0.3474002826450625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 386142.3902403206, 386142.3902403206, 122079.9311255788]
[2019-03-23 10:50:44,084] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:50:44,089] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.5715974068571451
[2019-03-23 10:50:54,502] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:50:54,503] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.36666666666667, 85.33333333333334, 1.0, 2.0, 0.2911847750485214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316180.5422050726, 316180.5422050729, 110605.3320469066]
[2019-03-23 10:50:54,504] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:50:54,508] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.3568886549292506
[2019-03-23 10:51:22,246] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:51:22,247] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [14.23942793, 83.80814785666666, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 31.85675028, 194472.2022007096, 194472.2022007096, 54897.65483785533]
[2019-03-23 10:51:22,248] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:51:22,250] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.4757356080067071
[2019-03-23 10:51:40,138] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:51:40,140] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.9, 49.0, 1.0, 2.0, 0.3694776899306048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 412604.2962022888, 412604.2962022888, 124658.6260616013]
[2019-03-23 10:51:40,141] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:51:40,146] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.5107282600433825
[2019-03-23 10:51:45,426] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.4121905]
[2019-03-23 10:51:45,428] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [27.31426058, 62.6667947, 1.0, 2.0, 0.5848658443253073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 665818.1439135305, 665818.1439135305, 158067.5175216177]
[2019-03-23 10:51:45,429] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:51:45,431] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6559506e-13 1.0000000e+00 7.8996278e-20 3.6904973e-19 1.7035651e-21], sampled 0.4322396899674268
[2019-03-23 10:51:57,853] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:51:57,937] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:51:58,005] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:51:58,043] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:51:58,211] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:51:59,228] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2075000, evaluation results [2075000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:52:03,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6568860e-12 1.0000000e+00 2.0848914e-18 7.2002226e-18 7.0246278e-20], sum to 1.0000
[2019-03-23 10:52:03,701] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5692
[2019-03-23 10:52:03,706] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 73.66666666666667, 1.0, 2.0, 0.5730497937783862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 645584.5932702341, 645584.5932702341, 154848.4161341115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [26.55, 77.83333333333334, 1.0, 2.0, 0.5860617326979844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 658714.7679813298, 658714.7679813298, 156937.3444874697], 
processed observation next is [0.0, 0.5652173913043478, 0.8431818181818183, 0.7783333333333334, 1.0, 1.0, 0.4825771658724805, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2439684325856777, 0.2439684325856777, 0.38277401094504804], 
reward next is 0.6172, 
noisyNet noise sample is [array([-0.4003617], dtype=float32), 1.6879363]. 
=============================================
[2019-03-23 10:52:04,077] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1760137e-12 1.0000000e+00 4.2671299e-18 2.2326116e-17 6.0856427e-20], sum to 1.0000
[2019-03-23 10:52:04,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4625
[2019-03-23 10:52:04,093] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 56.33333333333333, 1.0, 2.0, 0.5554456921795898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 629369.5838013747, 629369.5838013747, 151466.8284699252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6277200.0000, 
sim time next is 6277800.0000, 
raw observation next is [29.4, 55.66666666666666, 1.0, 2.0, 0.5498651583091381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 623604.5095730027, 623604.5095730027, 150530.6574724369], 
processed observation next is [0.0, 0.6521739130434783, 0.9727272727272727, 0.5566666666666665, 1.0, 1.0, 0.43733144788642253, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23096463317518617, 0.23096463317518617, 0.36714794505472415], 
reward next is 0.6329, 
noisyNet noise sample is [array([-0.46030182], dtype=float32), 0.6562247]. 
=============================================
[2019-03-23 10:52:05,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7559935e-15 1.0000000e+00 1.4803082e-22 1.1685983e-20 3.5473362e-23], sum to 1.0000
[2019-03-23 10:52:05,871] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9153
[2019-03-23 10:52:05,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 76.0, 1.0, 2.0, 0.521651774787865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593958.2517192913, 593958.2517192913, 145684.0242553583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6390000.0000, 
sim time next is 6390600.0000, 
raw observation next is [24.9, 76.5, 1.0, 2.0, 0.5208556920953176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593092.8776276096, 593092.8776276096, 145554.4468794944], 
processed observation next is [0.0, 1.0, 0.7681818181818181, 0.765, 1.0, 1.0, 0.4010696151191469, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21966402875096652, 0.21966402875096652, 0.35501084604754735], 
reward next is 0.6450, 
noisyNet noise sample is [array([-2.3825028], dtype=float32), -0.46746543]. 
=============================================
[2019-03-23 10:52:11,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0838125e-12 1.0000000e+00 4.6698171e-20 4.0069579e-20 1.4111204e-21], sum to 1.0000
[2019-03-23 10:52:11,510] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5193
[2019-03-23 10:52:11,516] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2192101063668565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 238008.3296091833, 238008.329609183, 75249.50223918281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6473400.0000, 
sim time next is 6474000.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2186431782385491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 237392.6347049871, 237392.6347049874, 75188.25774682713], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.02330397279818635, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08792319803888411, 0.08792319803888422, 0.18338599450445642], 
reward next is 0.8166, 
noisyNet noise sample is [array([-0.43452775], dtype=float32), 0.48992303]. 
=============================================
[2019-03-23 10:52:11,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.97874]
 [68.97874]
 [68.97874]
 [68.97874]
 [68.97874]], R is [[69.1055603 ]
 [69.23097229]
 [69.35490417]
 [69.47695923]
 [69.59715271]].
[2019-03-23 10:52:13,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2331206e-14 1.0000000e+00 5.4424736e-21 2.0817967e-21 9.0379676e-24], sum to 1.0000
[2019-03-23 10:52:13,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5619
[2019-03-23 10:52:13,830] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.9, 89.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 201645.4057058938, 201645.4057058941, 68267.6405190482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6493200.0000, 
sim time next is 6493800.0000, 
raw observation next is [12.8, 89.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 200153.4940718499, 200153.4940718496, 67927.98393568805], 
processed observation next is [1.0, 0.13043478260869565, 0.21818181818181823, 0.895, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07413092373031478, 0.07413092373031466, 0.16567800959923915], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.01388], dtype=float32), 0.9019673]. 
=============================================
[2019-03-23 10:52:16,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4544348e-14 1.0000000e+00 9.8947886e-21 4.3469383e-21 2.8800845e-22], sum to 1.0000
[2019-03-23 10:52:16,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8818
[2019-03-23 10:52:16,992] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 81.0, 1.0, 2.0, 0.2224167895274722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 241490.8641678469, 241490.8641678472, 77881.63002415113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6595200.0000, 
sim time next is 6595800.0000, 
raw observation next is [15.86666666666667, 79.16666666666667, 1.0, 2.0, 0.2453923346017063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266443.5846757729, 266443.5846757732, 80886.2019733844], 
processed observation next is [1.0, 0.34782608695652173, 0.35757575757575777, 0.7916666666666667, 1.0, 1.0, 0.05674041825213288, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09868280913917514, 0.09868280913917526, 0.19728341944727903], 
reward next is 0.8027, 
noisyNet noise sample is [array([0.31233585], dtype=float32), 1.335094]. 
=============================================
[2019-03-23 10:52:19,955] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8526977e-12 1.0000000e+00 2.5521442e-18 3.8006517e-19 1.0565347e-19], sum to 1.0000
[2019-03-23 10:52:19,966] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3264
[2019-03-23 10:52:19,973] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3690773463738448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411839.8879447641, 411839.8879447641, 120165.9961733421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6665400.0000, 
sim time next is 6666000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3637565167132937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 405897.243199237, 405897.2431992373, 119727.26358986], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.20469564589161707, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1503323122960137, 0.1503323122960138, 0.2920177160728293], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.07291771], dtype=float32), -0.15779036]. 
=============================================
[2019-03-23 10:52:19,997] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.61092]
 [65.61092]
 [65.61092]
 [65.61092]
 [65.61092]], R is [[65.66280365]
 [65.71308899]
 [65.7642746 ]
 [65.81143951]
 [65.86365509]].
[2019-03-23 10:52:25,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7164525e-15 1.0000000e+00 1.8188960e-20 3.0687270e-20 1.5998561e-22], sum to 1.0000
[2019-03-23 10:52:25,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6448
[2019-03-23 10:52:25,125] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.2, 96.0, 1.0, 2.0, 0.3325088919787453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 366578.3001272756, 366578.3001272756, 115395.5796044529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6739200.0000, 
sim time next is 6739800.0000, 
raw observation next is [17.2, 96.66666666666666, 1.0, 2.0, 0.335179656124852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 369860.019598657, 369860.0195986573, 115723.9815725141], 
processed observation next is [1.0, 0.0, 0.41818181818181815, 0.9666666666666666, 1.0, 1.0, 0.16897457015606498, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13698519244394702, 0.13698519244394716, 0.2822536135914978], 
reward next is 0.7177, 
noisyNet noise sample is [array([0.11779497], dtype=float32), -0.916429]. 
=============================================
[2019-03-23 10:52:25,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0839476e-12 1.0000000e+00 3.1630503e-19 2.1186620e-17 9.0405679e-21], sum to 1.0000
[2019-03-23 10:52:25,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4403
[2019-03-23 10:52:25,219] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.362862227404659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 404894.5177067375, 404894.5177067378, 119652.1568348116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6719400.0000, 
sim time next is 6720000.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.3598988649910714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 401577.0390481144, 401577.0390481144, 119406.2548785785], 
processed observation next is [1.0, 0.782608695652174, 0.4681818181818182, 0.93, 1.0, 1.0, 0.1998735812388392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14873223668448682, 0.14873223668448682, 0.2912347679965329], 
reward next is 0.7088, 
noisyNet noise sample is [array([0.14089516], dtype=float32), -0.56413126]. 
=============================================
[2019-03-23 10:52:25,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.34293]
 [68.34293]
 [68.34293]
 [68.34293]
 [68.34293]], R is [[68.36827087]
 [68.3927536 ]
 [68.41633606]
 [68.43925476]
 [68.46190643]].
[2019-03-23 10:52:27,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1844685e-14 1.0000000e+00 2.3811182e-20 1.1958779e-19 8.9342483e-22], sum to 1.0000
[2019-03-23 10:52:27,545] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0876
[2019-03-23 10:52:27,550] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 69.33333333333334, 1.0, 2.0, 0.7007863367087634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 798464.7068739649, 798464.7068739651, 163872.2671439816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6784800.0000, 
sim time next is 6785400.0000, 
raw observation next is [24.11666666666666, 67.66666666666666, 1.0, 2.0, 0.7524020062905419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 857443.1355986105, 857443.1355986103, 171398.3691577474], 
processed observation next is [1.0, 0.5217391304347826, 0.7325757575757573, 0.6766666666666665, 1.0, 1.0, 0.6905025078631774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3175715317031891, 0.31757153170318897, 0.41804480282377415], 
reward next is 0.5820, 
noisyNet noise sample is [array([-0.28599545], dtype=float32), -1.378574]. 
=============================================
[2019-03-23 10:52:28,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0639131e-13 1.0000000e+00 5.8958655e-20 2.6889553e-19 3.0179342e-22], sum to 1.0000
[2019-03-23 10:52:28,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9317
[2019-03-23 10:52:28,632] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666666, 67.66666666666666, 1.0, 2.0, 0.7524020062905419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 857443.1355986105, 857443.1355986103, 171398.3691577474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6785400.0000, 
sim time next is 6786000.0000, 
raw observation next is [24.4, 66.0, 1.0, 2.0, 0.6667026342530882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 759701.7684583683, 759701.7684583685, 159321.6966319043], 
processed observation next is [1.0, 0.5652173913043478, 0.7454545454545454, 0.66, 1.0, 1.0, 0.5833782928163602, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28137102535495123, 0.2813710253549513, 0.38858950398025444], 
reward next is 0.6114, 
noisyNet noise sample is [array([-0.31717333], dtype=float32), 0.42929402]. 
=============================================
[2019-03-23 10:52:28,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.906204]
 [67.906204]
 [67.906204]
 [67.906204]
 [67.906204]], R is [[67.83855438]
 [67.74212646]
 [67.66501617]
 [67.61895752]
 [67.53347015]].
[2019-03-23 10:52:32,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1773377e-12 1.0000000e+00 1.1308618e-19 4.2097150e-19 7.6234411e-21], sum to 1.0000
[2019-03-23 10:52:32,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1010
[2019-03-23 10:52:32,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.46666666666667, 95.5, 1.0, 2.0, 0.3340835884599344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 369275.9006172193, 369275.900617219, 115886.2611264943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6851400.0000, 
sim time next is 6852000.0000, 
raw observation next is [17.73333333333333, 95.0, 1.0, 2.0, 0.338642414237675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 375566.0118740706, 375566.0118740706, 116730.6358912148], 
processed observation next is [0.0, 0.30434782608695654, 0.44242424242424233, 0.95, 1.0, 1.0, 0.17330301779709373, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13909852291632246, 0.13909852291632246, 0.2847088680273532], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.7352164], dtype=float32), -0.31314996]. 
=============================================
[2019-03-23 10:52:32,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.97543]
 [68.97543]
 [68.97543]
 [68.97543]
 [68.97543]], R is [[69.00097656]
 [69.02832031]
 [69.05678558]
 [69.08493805]
 [69.11277008]].
[2019-03-23 10:52:48,071] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 10:52:48,072] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:52:48,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:48,074] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:52:48,075] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:48,077] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:52:48,078] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:52:48,079] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:48,081] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:48,079] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:52:48,085] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:52:48,101] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 10:52:48,129] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 10:52:48,149] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 10:52:48,150] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 10:52:48,201] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 10:53:00,456] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.414782]
[2019-03-23 10:53:00,458] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.2, 43.83333333333334, 1.0, 2.0, 0.3867109368971882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 436414.4259712085, 436414.4259712078, 128342.833831385]
[2019-03-23 10:53:00,459] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:53:00,461] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0364234e-12 1.0000000e+00 2.3267686e-19 1.0684390e-18 5.3865618e-21], sampled 0.6226450837177815
[2019-03-23 10:53:40,719] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.414782]
[2019-03-23 10:53:40,720] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.0, 54.0, 1.0, 2.0, 0.3634365703372783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 406003.1537616315, 406003.1537616315, 124226.1420216426]
[2019-03-23 10:53:40,720] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:53:40,723] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0364234e-12 1.0000000e+00 2.3267686e-19 1.0684390e-18 5.3865618e-21], sampled 0.2501789469090909
[2019-03-23 10:53:49,719] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.414782]
[2019-03-23 10:53:49,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.94243303666666, 97.90772663833333, 1.0, 2.0, 0.6774956904496958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 761275.7974051188, 761275.7974051185, 174496.6403940648]
[2019-03-23 10:53:49,720] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:53:49,721] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.0364234e-12 1.0000000e+00 2.3267686e-19 1.0684390e-18 5.3865618e-21], sampled 0.5955723623386779
[2019-03-23 10:53:57,809] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.414782]
[2019-03-23 10:53:57,813] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.8, 38.0, 1.0, 2.0, 0.7502105055285352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 842808.6904147394, 842808.6904147394, 167518.2896957498]
[2019-03-23 10:53:57,814] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:53:57,816] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.0364234e-12 1.0000000e+00 2.3267686e-19 1.0684390e-18 5.3865618e-21], sampled 0.22302327060965366
[2019-03-23 10:54:27,228] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:54:27,321] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:54:27,362] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:54:27,504] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:54:27,513] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:54:28,530] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2100000, evaluation results [2100000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:54:31,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4349124e-13 1.0000000e+00 4.1441966e-19 6.5478759e-19 4.2969177e-21], sum to 1.0000
[2019-03-23 10:54:31,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3178
[2019-03-23 10:54:31,144] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 96.0, 1.0, 2.0, 0.4492539438612752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511081.6595593743, 511081.6595593743, 132609.6928125504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7618800.0000, 
sim time next is 7619400.0000, 
raw observation next is [20.0, 96.0, 1.0, 2.0, 0.4553469057983269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518005.2262090584, 518005.2262090584, 133226.6963216101], 
processed observation next is [1.0, 0.17391304347826086, 0.5454545454545454, 0.96, 1.0, 1.0, 0.3191836322479086, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19185378748483645, 0.19185378748483645, 0.32494316176002463], 
reward next is 0.6751, 
noisyNet noise sample is [array([-0.6348014], dtype=float32), 1.0623112]. 
=============================================
[2019-03-23 10:54:32,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8048845e-13 1.0000000e+00 3.9026414e-20 5.5241202e-18 2.7029805e-21], sum to 1.0000
[2019-03-23 10:54:32,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1444
[2019-03-23 10:54:32,900] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2342758123674686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 254370.2630565255, 254370.2630565255, 76647.16115181417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7284000.0000, 
sim time next is 7284600.0000, 
raw observation next is [16.05, 72.0, 1.0, 2.0, 0.2558452122845646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 277796.4152463397, 277796.41524634, 79459.0281654079], 
processed observation next is [1.0, 0.30434782608695654, 0.36590909090909096, 0.72, 1.0, 1.0, 0.06980651535570571, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10288756120234803, 0.10288756120234814, 0.19380250772050708], 
reward next is 0.8062, 
noisyNet noise sample is [array([-1.6293912], dtype=float32), 0.41094464]. 
=============================================
[2019-03-23 10:54:38,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9910482e-12 1.0000000e+00 2.2675158e-20 6.7941552e-20 1.8598284e-21], sum to 1.0000
[2019-03-23 10:54:38,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2415
[2019-03-23 10:54:38,295] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 53.0, 1.0, 2.0, 0.8827464099308916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1007572.482180547, 1007572.482180547, 196905.6127145759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7390200.0000, 
sim time next is 7390800.0000, 
raw observation next is [28.3, 53.0, 1.0, 2.0, 0.9790882565560073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1117484.022518148, 1117484.022518148, 214687.5818433373], 
processed observation next is [1.0, 0.5652173913043478, 0.9227272727272727, 0.53, 1.0, 1.0, 0.9738603206950092, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.41388297130301777, 0.41388297130301777, 0.5236282483983836], 
reward next is 0.4764, 
noisyNet noise sample is [array([-1.5970275], dtype=float32), -1.3645817]. 
=============================================
[2019-03-23 10:54:44,041] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4883549e-10 1.0000000e+00 4.5129942e-17 3.2025125e-17 7.8635492e-20], sum to 1.0000
[2019-03-23 10:54:44,051] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5960
[2019-03-23 10:54:44,055] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.9, 98.0, 1.0, 2.0, 0.3303368309730801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 363572.8956297837, 363572.8956297837, 115002.1656544499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7453800.0000, 
sim time next is 7454400.0000, 
raw observation next is [17.0, 97.33333333333334, 1.0, 2.0, 0.3311451201359346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 364653.6879245663, 364653.6879245663, 115133.9148289881], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.9733333333333334, 1.0, 1.0, 0.16393140016991825, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13505692145354306, 0.13505692145354306, 0.2808144264121661], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.7277741], dtype=float32), -1.4221424]. 
=============================================
[2019-03-23 10:54:45,335] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5506836e-11 1.0000000e+00 2.1754092e-17 1.2690412e-16 1.0979352e-19], sum to 1.0000
[2019-03-23 10:54:45,343] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8292
[2019-03-23 10:54:45,349] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 88.0, 1.0, 2.0, 0.4623922297613607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527478.592785785, 527478.5927857853, 135934.6314431853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7525800.0000, 
sim time next is 7526400.0000, 
raw observation next is [21.76666666666667, 88.66666666666667, 1.0, 2.0, 0.4627581469059572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527898.2850271725, 527898.2850271729, 135979.9116971487], 
processed observation next is [0.0, 0.08695652173913043, 0.6257575757575758, 0.8866666666666667, 1.0, 1.0, 0.3284476836324464, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19551788334339723, 0.19551788334339737, 0.3316583212125578], 
reward next is 0.6683, 
noisyNet noise sample is [array([-0.35951176], dtype=float32), 0.18054466]. 
=============================================
[2019-03-23 10:54:48,978] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:54:48,979] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:54:48,994] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.22096595e-11 1.00000000e+00 6.34843518e-17 5.28258847e-17
 1.62700662e-19], sum to 1.0000
[2019-03-23 10:54:49,002] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9310
[2019-03-23 10:54:49,007] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 56.0, 1.0, 2.0, 0.5071986909159997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 578004.9305567789, 578004.9305567786, 143479.6288561249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7567200.0000, 
sim time next is 7567800.0000, 
raw observation next is [28.2, 56.16666666666667, 1.0, 2.0, 0.5061700043625438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 576893.0009884045, 576893.0009884045, 143291.9260216209], 
processed observation next is [0.0, 0.6086956521739131, 0.9181818181818181, 0.5616666666666668, 1.0, 1.0, 0.3827125054531797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21366407444014981, 0.21366407444014981, 0.3494925024917583], 
reward next is 0.6505, 
noisyNet noise sample is [array([1.0787537], dtype=float32), -0.16437164]. 
=============================================
[2019-03-23 10:54:49,041] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 10:54:49,986] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.17860504e-11 1.00000000e+00 3.78717943e-18 9.46231689e-17
 3.28354850e-19], sum to 1.0000
[2019-03-23 10:54:49,992] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2603
[2019-03-23 10:54:49,997] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 91.5, 1.0, 2.0, 0.4066445215002133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459798.988582283, 459798.988582283, 126329.3237766708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7590600.0000, 
sim time next is 7591200.0000, 
raw observation next is [19.8, 92.0, 1.0, 2.0, 0.4095160062279861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 463655.6163621103, 463655.6163621106, 126973.2547644939], 
processed observation next is [0.0, 0.8695652173913043, 0.5363636363636364, 0.92, 1.0, 1.0, 0.2618950077849826, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17172430235633715, 0.17172430235633726, 0.30969086527925344], 
reward next is 0.6903, 
noisyNet noise sample is [array([0.61728275], dtype=float32), -0.002094944]. 
=============================================
[2019-03-23 10:54:50,795] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2111665: loss 0.0321
[2019-03-23 10:54:50,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2111665: learning rate 0.0010
[2019-03-23 10:54:51,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1582371e-12 1.0000000e+00 7.7634359e-19 5.6942560e-19 7.4298195e-21], sum to 1.0000
[2019-03-23 10:54:51,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2454
[2019-03-23 10:54:51,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1254029.114891367 W.
[2019-03-23 10:54:51,177] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.68333333333333, 70.83333333333333, 1.0, 2.0, 0.6205141796577943, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9762609055255775, 6.9112, 6.9112, 77.32846340900659, 1254029.114891367, 1254029.114891367, 279647.4938105834], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7643400.0000, 
sim time next is 7644000.0000, 
raw observation next is [25.86666666666667, 69.66666666666667, 1.0, 2.0, 0.3705166938967238, 1.0, 1.0, 0.3705166938967238, 1.0, 2.0, 0.7499053152173423, 6.911199999999999, 6.9112, 77.3421103, 1257020.174984375, 1257020.174984375, 290810.0901457567], 
processed observation next is [1.0, 0.4782608695652174, 0.8121212121212124, 0.6966666666666668, 1.0, 1.0, 0.21314586737090474, 1.0, 0.5, 0.21314586737090474, 1.0, 1.0, 0.6427218788819176, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.46556302777199077, 0.46556302777199077, 0.7092929027945286], 
reward next is 0.2907, 
noisyNet noise sample is [array([-0.5887765], dtype=float32), -0.3952066]. 
=============================================
[2019-03-23 10:54:51,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.8248]
 [66.8248]
 [66.8248]
 [66.8248]
 [66.8248]], R is [[66.44726562]
 [66.10072327]
 [65.7742157 ]
 [65.41543579]
 [64.76128387]].
[2019-03-23 10:54:52,587] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5324846e-08 1.0000000e+00 1.1376665e-14 3.5775961e-14 1.3033002e-16], sum to 1.0000
[2019-03-23 10:54:52,593] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4288
[2019-03-23 10:54:52,599] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.53333333333333, 96.66666666666667, 1.0, 2.0, 0.3558018869267291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395138.3647459169, 395138.3647459169, 118283.0189331946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7712400.0000, 
sim time next is 7713000.0000, 
raw observation next is [17.45, 96.5, 1.0, 2.0, 0.3641988730504885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 403838.5856111746, 403838.5856111743, 118701.0025937241], 
processed observation next is [1.0, 0.2608695652173913, 0.4295454545454545, 0.965, 1.0, 1.0, 0.20524859131311057, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14956984652265726, 0.14956984652265715, 0.2895146404724978], 
reward next is 0.7105, 
noisyNet noise sample is [array([-0.9220754], dtype=float32), -2.1414132]. 
=============================================
[2019-03-23 10:54:52,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.07922]
 [65.07922]
 [65.07922]
 [65.07922]
 [65.07922]], R is [[65.13890839]
 [65.19902039]
 [65.2544632 ]
 [65.31332397]
 [65.37154388]].
[2019-03-23 10:54:56,925] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3482841e-12 1.0000000e+00 3.8276121e-19 6.1305224e-19 4.3118433e-21], sum to 1.0000
[2019-03-23 10:54:56,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9773
[2019-03-23 10:54:56,936] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.0, 1.0, 2.0, 0.2132352010440429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231519.5061294874, 231519.5061294872, 73541.75401802636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7790400.0000, 
sim time next is 7791000.0000, 
raw observation next is [14.21666666666667, 83.0, 1.0, 2.0, 0.2260521735392129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 245439.0082561235, 245439.0082561238, 74843.61648032827], 
processed observation next is [1.0, 0.17391304347826086, 0.28257575757575776, 0.83, 1.0, 1.0, 0.0325652169240161, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09090333639115684, 0.09090333639115697, 0.18254540604958117], 
reward next is 0.8175, 
noisyNet noise sample is [array([0.68295604], dtype=float32), 0.654245]. 
=============================================
[2019-03-23 10:54:56,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.922264]
 [70.922264]
 [70.922264]
 [70.922264]
 [70.922264]], R is [[71.03049469]
 [71.14082336]
 [71.25070953]
 [71.3589859 ]
 [71.46546173]].
[2019-03-23 10:54:58,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7500023e-13 1.0000000e+00 7.1221963e-20 9.5424791e-21 1.9451615e-21], sum to 1.0000
[2019-03-23 10:54:58,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9133
[2019-03-23 10:54:58,995] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 51.33333333333334, 1.0, 2.0, 0.297066822356408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 322569.6321195728, 322569.6321195731, 92807.81593529816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7755600.0000, 
sim time next is 7756200.0000, 
raw observation next is [20.5, 52.5, 1.0, 2.0, 0.2902851015139143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 315203.3226637584, 315203.3226637587, 90973.88944669161], 
processed observation next is [1.0, 0.782608695652174, 0.5681818181818182, 0.525, 1.0, 1.0, 0.11285637689239285, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11674197135694755, 0.11674197135694767, 0.22188753523583318], 
reward next is 0.7781, 
noisyNet noise sample is [array([1.1176045], dtype=float32), 0.3460959]. 
=============================================
[2019-03-23 10:55:01,400] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:01,401] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:01,448] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 10:55:03,179] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2117913: loss 0.0138
[2019-03-23 10:55:03,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2117915: learning rate 0.0010
[2019-03-23 10:55:05,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:05,910] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:05,949] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 10:55:06,022] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:06,025] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:06,052] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 10:55:06,137] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2119354: loss 0.1017
[2019-03-23 10:55:06,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2119354: learning rate 0.0010
[2019-03-23 10:55:06,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:06,324] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:06,359] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 10:55:06,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0553745e-13 1.0000000e+00 5.2167363e-20 5.3345227e-20 1.5603362e-21], sum to 1.0000
[2019-03-23 10:55:06,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5476
[2019-03-23 10:55:06,794] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 88.5, 1.0, 2.0, 0.4000273761171341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 451265.1186871433, 451265.1186871433, 125112.5244212037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7943400.0000, 
sim time next is 7944000.0000, 
raw observation next is [19.56666666666667, 86.0, 1.0, 2.0, 0.3865194793573861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 434271.9207657637, 434271.9207657634, 122983.1437163961], 
processed observation next is [1.0, 0.9565217391304348, 0.5257575757575759, 0.86, 1.0, 1.0, 0.23314934919673264, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16084145213546802, 0.1608414521354679, 0.2999588871131612], 
reward next is 0.7000, 
noisyNet noise sample is [array([-0.16162695], dtype=float32), -0.81340986]. 
=============================================
[2019-03-23 10:55:06,805] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.58937]
 [66.58937]
 [66.58937]
 [66.58937]
 [66.58937]], R is [[66.6235199 ]
 [66.65213013]
 [66.67559052]
 [66.69456482]
 [66.71020508]].
[2019-03-23 10:55:07,557] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2120139: loss 0.0357
[2019-03-23 10:55:07,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2120139: learning rate 0.0010
[2019-03-23 10:55:07,656] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2120193: loss 0.0400
[2019-03-23 10:55:07,657] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2120194: learning rate 0.0010
[2019-03-23 10:55:07,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:07,900] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:07,948] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 10:55:08,008] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:08,009] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:08,055] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2120377: loss 0.0018
[2019-03-23 10:55:08,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2120377: learning rate 0.0010
[2019-03-23 10:55:08,062] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 10:55:08,429] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:08,430] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:08,466] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 10:55:08,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:08,846] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:08,864] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 10:55:09,146] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:09,147] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:09,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:09,160] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:09,186] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 10:55:09,188] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 10:55:09,244] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:09,248] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:09,260] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 10:55:09,458] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:09,458] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:09,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 10:55:09,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:09,530] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:09,543] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 10:55:09,619] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2121078: loss 0.0029
[2019-03-23 10:55:09,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2121078: learning rate 0.0010
[2019-03-23 10:55:09,654] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121096: loss 0.0005
[2019-03-23 10:55:09,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121096: learning rate 0.0010
[2019-03-23 10:55:09,912] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:09,913] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:09,918] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 10:55:10,018] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2121250: loss 0.0001
[2019-03-23 10:55:10,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2121250: learning rate 0.0010
[2019-03-23 10:55:10,403] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2121448: loss 0.0001
[2019-03-23 10:55:10,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2121449: learning rate 0.0010
[2019-03-23 10:55:10,475] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 10:55:10,475] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:10,480] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 10:55:10,934] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2121730: loss 0.0000
[2019-03-23 10:55:10,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2121730: learning rate 0.0010
[2019-03-23 10:55:10,950] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2121739: loss 0.0002
[2019-03-23 10:55:10,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2121739: learning rate 0.0010
[2019-03-23 10:55:10,959] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2121744: loss 0.0053
[2019-03-23 10:55:10,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2121744: learning rate 0.0010
[2019-03-23 10:55:11,213] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121900: loss 0.0003
[2019-03-23 10:55:11,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121901: learning rate 0.0010
[2019-03-23 10:55:11,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.58437315e-13 1.00000000e+00 1.07687174e-19 1.27633128e-19
 7.51854670e-21], sum to 1.0000
[2019-03-23 10:55:11,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-23 10:55:11,245] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.83333333333333, 95.0, 1.0, 2.0, 0.3657822884346946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 406866.275000817, 406866.2750008167, 119343.6929902378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18600.0000, 
sim time next is 19200.0000, 
raw observation next is [17.66666666666667, 96.0, 1.0, 2.0, 0.3554738781628841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395055.3200971914, 395055.3200971914, 118372.8525196534], 
processed observation next is [1.0, 0.21739130434782608, 0.4393939393939396, 0.96, 1.0, 1.0, 0.19434234770360512, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.146316785221182, 0.146316785221182, 0.28871427443817904], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.34924302], dtype=float32), 0.6077051]. 
=============================================
[2019-03-23 10:55:11,298] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2121953: loss 0.0018
[2019-03-23 10:55:11,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2121956: learning rate 0.0010
[2019-03-23 10:55:11,734] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2122215: loss 0.0029
[2019-03-23 10:55:11,736] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2122215: learning rate 0.0010
[2019-03-23 10:55:12,223] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2122462: loss 0.0088
[2019-03-23 10:55:12,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2122462: learning rate 0.0010
[2019-03-23 10:55:15,658] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2124203: loss 0.0059
[2019-03-23 10:55:15,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2124203: learning rate 0.0010
[2019-03-23 10:55:17,423] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 10:55:17,425] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:55:17,426] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:17,427] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:55:17,427] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:55:17,428] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:55:17,428] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:17,429] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:17,428] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:17,429] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:55:17,431] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:55:17,456] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 10:55:17,483] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 10:55:17,508] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 10:55:17,508] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 10:55:17,530] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 10:56:06,783] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:06,784] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [24.97277637333333, 75.52178378666667, 1.0, 2.0, 0.5156313812658507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 587343.8783019526, 587343.8783019523, 148998.053906633]
[2019-03-23 10:56:06,786] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:56:06,789] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.462178100081694
[2019-03-23 10:56:18,980] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:18,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 87.0, 1.0, 2.0, 0.5032784797236916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574007.0663948188, 574007.0663948188, 146575.0752323496]
[2019-03-23 10:56:18,983] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:56:18,987] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.7643609104658939
[2019-03-23 10:56:22,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:22,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.14553064, 100.0, 1.0, 2.0, 0.4323325610396167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 490911.7852958814, 490911.7852958814, 134468.4678554894]
[2019-03-23 10:56:22,131] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:56:22,134] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.8340996937041742
[2019-03-23 10:56:22,954] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:22,955] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.3633166450082376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397659.4924174282, 397659.4924174282, 116706.9118397684]
[2019-03-23 10:56:22,956] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:56:22,959] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.09715256783284687
[2019-03-23 10:56:27,121] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:27,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.39504431, 93.65189976666667, 1.0, 2.0, 0.3719819345849062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 416284.2469101365, 416284.2469101361, 125263.2560768929]
[2019-03-23 10:56:27,123] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 10:56:27,125] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.3226824890822032
[2019-03-23 10:56:29,693] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:29,694] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.70478936, 80.38184773, 1.0, 2.0, 0.3991369853788967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 450098.2718215067, 450098.2718215067, 129271.3281109979]
[2019-03-23 10:56:29,695] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:56:29,697] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.547560672532013
[2019-03-23 10:56:37,076] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:37,077] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.31082471, 63.45151701, 1.0, 2.0, 0.5508901904098603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 628118.5390060602, 628118.5390060602, 149732.969961011]
[2019-03-23 10:56:37,078] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:56:37,083] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.601839538450012
[2019-03-23 10:56:43,699] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:43,701] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.468885145, 49.6081595, 1.0, 2.0, 0.7090891774363219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 808316.4827361442, 808316.4827361439, 169996.4283662916]
[2019-03-23 10:56:43,701] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 10:56:43,704] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.8000989276526378
[2019-03-23 10:56:44,187] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.52240723]
[2019-03-23 10:56:44,188] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.36666666666667, 90.33333333333334, 1.0, 2.0, 0.5147581526732548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 587133.5909538164, 587133.5909538161, 147873.2705333924]
[2019-03-23 10:56:44,188] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:56:44,190] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.5346140e-13 1.0000000e+00 3.1262577e-20 1.4424876e-19 5.7914033e-22], sampled 0.8567482821455861
[2019-03-23 10:56:55,918] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:56:56,225] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:56:56,241] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:56:56,300] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:56:56,558] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:56:57,572] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2125000, evaluation results [2125000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:56:57,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2338106e-12 1.0000000e+00 7.4052302e-21 1.7553064e-18 1.8470733e-21], sum to 1.0000
[2019-03-23 10:56:57,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4768
[2019-03-23 10:56:57,604] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 88.0, 1.0, 2.0, 0.2050774003399813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 222660.1701689931, 222660.1701689934, 73627.10471066818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 177600.0000, 
sim time next is 178200.0000, 
raw observation next is [14.0, 88.0, 1.0, 2.0, 0.2048213987956934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 222382.1562205359, 222382.1562205359, 73610.68519844176], 
processed observation next is [0.0, 0.043478260869565216, 0.2727272727272727, 0.88, 1.0, 1.0, 0.006026748494616721, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.08236376156316144, 0.08236376156316144, 0.17953825658156528], 
reward next is 0.8205, 
noisyNet noise sample is [array([-1.2686622], dtype=float32), 1.055405]. 
=============================================
[2019-03-23 10:56:58,621] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2125558: loss 0.0221
[2019-03-23 10:56:58,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2125558: learning rate 0.0010
[2019-03-23 10:57:00,650] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2255927e-15 1.0000000e+00 5.4789250e-22 6.4244319e-21 1.3544945e-23], sum to 1.0000
[2019-03-23 10:57:00,659] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0159
[2019-03-23 10:57:00,664] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 55.5, 1.0, 2.0, 0.7479029879894886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 839963.9377832324, 839963.9377832328, 162719.8448307936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 653400.0000, 
sim time next is 654000.0000, 
raw observation next is [24.0, 56.0, 1.0, 2.0, 0.7671979048430845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 862546.9380088518, 862546.9380088518, 165750.8290552387], 
processed observation next is [1.0, 0.5652173913043478, 0.7272727272727273, 0.56, 1.0, 1.0, 0.7089973810538555, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.31946182889216734, 0.31946182889216734, 0.40427031476887487], 
reward next is 0.5957, 
noisyNet noise sample is [array([0.6409444], dtype=float32), -0.3018875]. 
=============================================
[2019-03-23 10:57:00,679] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.11557]
 [75.11557]
 [75.11557]
 [75.11557]
 [75.11557]], R is [[74.96014404]
 [74.81365967]
 [74.67984009]
 [74.56732178]
 [74.50577545]].
[2019-03-23 10:57:00,985] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2126821: loss 0.0164
[2019-03-23 10:57:00,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2126821: learning rate 0.0010
[2019-03-23 10:57:01,028] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2126842: loss 0.0319
[2019-03-23 10:57:01,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2126842: learning rate 0.0010
[2019-03-23 10:57:01,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1793161e-14 1.0000000e+00 2.5472201e-20 1.1558299e-20 9.3100772e-24], sum to 1.0000
[2019-03-23 10:57:01,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2723
[2019-03-23 10:57:01,245] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.33333333333333, 92.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 207853.1027149246, 207853.1027149246, 70840.830095588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 189600.0000, 
sim time next is 190200.0000, 
raw observation next is [13.16666666666667, 93.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 205630.3953837501, 205630.3953837501, 70292.18333851923], 
processed observation next is [0.0, 0.17391304347826086, 0.23484848484848497, 0.93, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.07615940569768521, 0.07615940569768521, 0.17144434960614446], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.68294036], dtype=float32), 0.5391599]. 
=============================================
[2019-03-23 10:57:01,442] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2127059: loss 0.0019
[2019-03-23 10:57:01,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2127061: learning rate 0.0010
[2019-03-23 10:57:03,922] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8057316e-14 1.0000000e+00 2.8563324e-21 1.6576848e-20 4.8360704e-24], sum to 1.0000
[2019-03-23 10:57:03,928] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9619
[2019-03-23 10:57:03,941] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3035881641048436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 53.75729996279058, 329702.2295816226, 329702.2295816229, 66371.84992910421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 360600.0000, 
sim time next is 361200.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.407040732724772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 61.18001451380767, 442091.996132585, 442091.9961325846, 78200.9542706201], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.25880091590596493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 1.7763568394002506e-16, 0.0, 0.40225397956387, 0.16373777634540185, 0.1637377763454017, 0.1907340348063905], 
reward next is 0.8093, 
noisyNet noise sample is [array([-0.16640595], dtype=float32), -2.2539408]. 
=============================================
[2019-03-23 10:57:04,447] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2128662: loss 0.0297
[2019-03-23 10:57:04,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2128663: learning rate 0.0010
[2019-03-23 10:57:04,642] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128771: loss 0.0163
[2019-03-23 10:57:04,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128771: learning rate 0.0010
[2019-03-23 10:57:05,034] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2128979: loss 0.0050
[2019-03-23 10:57:05,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2128979: learning rate 0.0010
[2019-03-23 10:57:05,627] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2129292: loss 0.0002
[2019-03-23 10:57:05,628] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2129292: learning rate 0.0010
[2019-03-23 10:57:06,247] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2129641: loss 0.0001
[2019-03-23 10:57:06,248] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2129641: learning rate 0.0010
[2019-03-23 10:57:06,401] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2129726: loss 0.0001
[2019-03-23 10:57:06,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2129726: learning rate 0.0010
[2019-03-23 10:57:06,513] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129797: loss 0.0005
[2019-03-23 10:57:06,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129797: learning rate 0.0010
[2019-03-23 10:57:06,680] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129896: loss 0.0054
[2019-03-23 10:57:06,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129896: learning rate 0.0010
[2019-03-23 10:57:06,743] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2129934: loss 0.0070
[2019-03-23 10:57:06,744] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2129935: learning rate 0.0010
[2019-03-23 10:57:07,193] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2130190: loss 0.0084
[2019-03-23 10:57:07,197] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2130190: learning rate 0.0010
[2019-03-23 10:57:07,783] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2130487: loss 0.0008
[2019-03-23 10:57:07,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2130487: learning rate 0.0010
[2019-03-23 10:57:11,042] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2132121: loss 0.0056
[2019-03-23 10:57:11,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2132121: learning rate 0.0010
[2019-03-23 10:57:11,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7031000e-14 1.0000000e+00 1.3065362e-23 1.4026241e-22 9.2705979e-24], sum to 1.0000
[2019-03-23 10:57:11,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4693
[2019-03-23 10:57:11,881] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.0, 1.0, 2.0, 0.2274738013157256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246982.9505116151, 246982.9505116151, 78511.3242521997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 527400.0000, 
sim time next is 528000.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2209652090978904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 239914.4100366567, 239914.4100366565, 77413.86972801511], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.026206511372363003, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08885718890246545, 0.08885718890246537, 0.18881431640979296], 
reward next is 0.8112, 
noisyNet noise sample is [array([0.48886904], dtype=float32), 1.2203106]. 
=============================================
[2019-03-23 10:57:11,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[78.95023]
 [78.95023]
 [78.95023]
 [78.95023]
 [78.95023]], R is [[78.9719162 ]
 [78.9907074 ]
 [78.99655151]
 [78.99493408]
 [79.01885223]].
[2019-03-23 10:57:13,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6028858e-12 1.0000000e+00 4.4009524e-19 5.2387979e-18 5.3725252e-21], sum to 1.0000
[2019-03-23 10:57:13,826] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3074
[2019-03-23 10:57:13,829] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 100.0, 1.0, 2.0, 0.5451571859432048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592122.2873352406, 592122.2873352406, 110797.7611152322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 452400.0000, 
sim time next is 453000.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.5547394222735842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 602536.481281224, 602536.481281224, 111883.2748287914], 
processed observation next is [1.0, 0.21739130434782608, 0.22727272727272727, 1.0, 1.0, 1.0, 0.4434242778419802, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.22316165973378668, 0.22316165973378668, 0.2728860361677839], 
reward next is 0.7271, 
noisyNet noise sample is [array([0.86905384], dtype=float32), 0.50695753]. 
=============================================
[2019-03-23 10:57:13,855] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.93025]
 [72.93025]
 [72.93025]
 [72.93025]
 [72.93025]], R is [[72.92806244]
 [72.92854309]
 [72.92923737]
 [72.93078613]
 [72.93249512]].
[2019-03-23 10:57:14,094] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2133651: loss 0.0415
[2019-03-23 10:57:14,095] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2133651: learning rate 0.0010
[2019-03-23 10:57:16,443] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2134803: loss 0.0023
[2019-03-23 10:57:16,444] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2134803: loss 0.0008
[2019-03-23 10:57:16,445] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2134803: learning rate 0.0010
[2019-03-23 10:57:16,445] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2134803: learning rate 0.0010
[2019-03-23 10:57:16,996] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2135078: loss 0.0000
[2019-03-23 10:57:16,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2135079: learning rate 0.0010
[2019-03-23 10:57:18,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7068072e-14 1.0000000e+00 1.8589690e-22 1.1783659e-20 1.5833350e-23], sum to 1.0000
[2019-03-23 10:57:18,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1723
[2019-03-23 10:57:18,261] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 64.0, 1.0, 2.0, 0.6469027211586531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 722002.6165191957, 722002.6165191957, 147948.5094632748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 577800.0000, 
sim time next is 578400.0000, 
raw observation next is [22.0, 64.0, 1.0, 2.0, 0.6306931571031126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 703871.0771425016, 703871.0771425016, 146047.3982303523], 
processed observation next is [1.0, 0.6956521739130435, 0.6363636363636364, 0.64, 1.0, 1.0, 0.5383664463788906, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.26069299153425984, 0.26069299153425984, 0.3562131664154934], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.1029314], dtype=float32), 0.8648628]. 
=============================================
[2019-03-23 10:57:20,050] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2136617: loss 0.0649
[2019-03-23 10:57:20,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2136617: learning rate 0.0010
[2019-03-23 10:57:20,247] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2136714: loss 0.0698
[2019-03-23 10:57:20,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2136714: learning rate 0.0010
[2019-03-23 10:57:20,402] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6362831e-12 1.0000000e+00 1.1914571e-18 7.2346143e-17 3.3845889e-19], sum to 1.0000
[2019-03-23 10:57:20,410] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5559
[2019-03-23 10:57:20,416] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 88.0, 1.0, 2.0, 0.2573261025882052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 279404.8259869761, 279404.8259869761, 90078.32843174775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 614400.0000, 
sim time next is 615000.0000, 
raw observation next is [16.0, 88.0, 1.0, 2.0, 0.2569655577532808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 279013.2339095657, 279013.2339095654, 90017.54396814435], 
processed observation next is [1.0, 0.08695652173913043, 0.36363636363636365, 0.88, 1.0, 1.0, 0.07120694719160096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10333823478132063, 0.10333823478132051, 0.21955498528815695], 
reward next is 0.7804, 
noisyNet noise sample is [array([1.3043563], dtype=float32), -0.44057462]. 
=============================================
[2019-03-23 10:57:20,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.852974]
 [70.852974]
 [70.852974]
 [70.852974]
 [70.852974]], R is [[70.92489624]
 [70.99594116]
 [71.06549835]
 [71.13152313]
 [71.19304657]].
[2019-03-23 10:57:20,757] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2136969: loss 0.0796
[2019-03-23 10:57:20,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2136971: learning rate 0.0010
[2019-03-23 10:57:21,302] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2137247: loss 0.0461
[2019-03-23 10:57:21,308] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2137247: learning rate 0.0010
[2019-03-23 10:57:22,066] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2137628: loss 0.0452
[2019-03-23 10:57:22,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2137629: learning rate 0.0010
[2019-03-23 10:57:22,263] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2137730: loss 0.0552
[2019-03-23 10:57:22,265] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2137730: learning rate 0.0010
[2019-03-23 10:57:22,408] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137801: loss 0.0620
[2019-03-23 10:57:22,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137801: learning rate 0.0010
[2019-03-23 10:57:22,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137907: loss 0.0411
[2019-03-23 10:57:22,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137910: learning rate 0.0010
[2019-03-23 10:57:22,641] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2137918: loss 0.0308
[2019-03-23 10:57:22,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2137919: learning rate 0.0010
[2019-03-23 10:57:23,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7399219e-12 1.0000000e+00 1.4897418e-20 5.0268337e-18 1.2488542e-20], sum to 1.0000
[2019-03-23 10:57:23,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4587
[2019-03-23 10:57:23,125] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 56.5, 1.0, 2.0, 0.7756056923280478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 872814.4078998428, 872814.4078998425, 167300.1339616278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 654600.0000, 
sim time next is 655200.0000, 
raw observation next is [24.0, 57.0, 1.0, 2.0, 0.796444198646806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 897092.1816251711, 897092.1816251714, 170623.8742592807], 
processed observation next is [1.0, 0.6086956521739131, 0.7272727272727273, 0.57, 1.0, 1.0, 0.7455552483085076, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3322563635648782, 0.3322563635648783, 0.4161557908762944], 
reward next is 0.5838, 
noisyNet noise sample is [array([1.7520944], dtype=float32), 0.8706481]. 
=============================================
[2019-03-23 10:57:23,144] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2138169: loss 0.0798
[2019-03-23 10:57:23,145] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2138169: learning rate 0.0010
[2019-03-23 10:57:23,906] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2138554: loss 0.0926
[2019-03-23 10:57:23,907] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2138554: learning rate 0.0010
[2019-03-23 10:57:27,120] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2140160: loss 0.0072
[2019-03-23 10:57:27,123] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2140160: learning rate 0.0010
[2019-03-23 10:57:27,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4666766e-12 1.0000000e+00 1.4651595e-18 1.6162940e-17 8.2000014e-21], sum to 1.0000
[2019-03-23 10:57:27,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4978
[2019-03-23 10:57:27,216] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 78.0, 1.0, 2.0, 0.3550403497463058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395549.8511050192, 395549.8511050192, 118749.6663459797], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [19.66666666666667, 79.66666666666666, 1.0, 2.0, 0.3520197536181653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 391578.163493584, 391578.1634935843, 118250.3730866027], 
processed observation next is [1.0, 1.0, 0.5303030303030305, 0.7966666666666665, 1.0, 1.0, 0.19002469202270658, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14502894944206815, 0.14502894944206826, 0.28841554411366516], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.41871718], dtype=float32), -0.010154456]. 
=============================================
[2019-03-23 10:57:27,230] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.1639]
 [70.1639]
 [70.1639]
 [70.1639]
 [70.1639]], R is [[70.17385101]
 [70.18247986]
 [70.18988037]
 [70.1962204 ]
 [70.20204163]].
[2019-03-23 10:57:30,170] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2141662: loss 0.0010
[2019-03-23 10:57:30,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2141662: learning rate 0.0010
[2019-03-23 10:57:30,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5996213e-12 1.0000000e+00 1.2653178e-18 4.3046704e-17 5.3858453e-20], sum to 1.0000
[2019-03-23 10:57:30,222] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-23 10:57:30,229] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 60.0, 1.0, 2.0, 0.465702578612425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531362.204993338, 531362.204993338, 136678.2583837326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 762000.0000, 
sim time next is 762600.0000, 
raw observation next is [26.16666666666667, 60.5, 1.0, 2.0, 0.463974700169518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 529359.0094150781, 529359.0094150781, 136349.816010744], 
processed observation next is [1.0, 0.8260869565217391, 0.825757575757576, 0.605, 1.0, 1.0, 0.3299683752118974, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19605889237595486, 0.19605889237595486, 0.33256052685547316], 
reward next is 0.6674, 
noisyNet noise sample is [array([-2.0553396], dtype=float32), 1.2044616]. 
=============================================
[2019-03-23 10:57:32,392] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2142774: loss 0.0007
[2019-03-23 10:57:32,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2142776: learning rate 0.0010
[2019-03-23 10:57:32,431] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2142790: loss 0.0008
[2019-03-23 10:57:32,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2142790: learning rate 0.0010
[2019-03-23 10:57:33,164] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2143160: loss 0.0011
[2019-03-23 10:57:33,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2143160: learning rate 0.0010
[2019-03-23 10:57:35,240] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0322578e-10 1.0000000e+00 9.3636339e-19 7.7248875e-18 7.6240596e-19], sum to 1.0000
[2019-03-23 10:57:35,247] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3909
[2019-03-23 10:57:35,252] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 71.33333333333333, 1.0, 2.0, 0.4768553939817313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 544097.8921199921, 544097.8921199921, 137922.4963118969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 853800.0000, 
sim time next is 854400.0000, 
raw observation next is [23.66666666666667, 73.66666666666667, 1.0, 2.0, 0.4696187769970284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535646.8934447466, 535646.8934447466, 136517.6289770765], 
processed observation next is [0.0, 0.9130434782608695, 0.7121212121212124, 0.7366666666666667, 1.0, 1.0, 0.3370234712462855, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19838773831286913, 0.19838773831286913, 0.3329698267733573], 
reward next is 0.6670, 
noisyNet noise sample is [array([0.4523408], dtype=float32), 0.23511085]. 
=============================================
[2019-03-23 10:57:35,909] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2144557: loss 0.0029
[2019-03-23 10:57:35,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2144557: learning rate 0.0010
[2019-03-23 10:57:36,268] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2144741: loss 0.0090
[2019-03-23 10:57:36,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2144742: learning rate 0.0010
[2019-03-23 10:57:36,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2145033: loss 0.0115
[2019-03-23 10:57:36,857] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2145033: learning rate 0.0010
[2019-03-23 10:57:37,254] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2145235: loss 0.0002
[2019-03-23 10:57:37,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2145235: learning rate 0.0010
[2019-03-23 10:57:37,926] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8720299e-12 1.0000000e+00 4.2209230e-19 4.1084810e-19 9.1973396e-22], sum to 1.0000
[2019-03-23 10:57:37,934] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4240
[2019-03-23 10:57:37,939] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.5, 100.0, 1.0, 2.0, 0.4953611908813154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 538006.4516882706, 538006.4516882702, 113552.9743452042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1002600.0000, 
sim time next is 1003200.0000, 
raw observation next is [14.33333333333333, 100.0, 1.0, 2.0, 0.4760886100639199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 517063.5767941547, 517063.5767941547, 110261.2890183551], 
processed observation next is [1.0, 0.6086956521739131, 0.28787878787878773, 1.0, 1.0, 1.0, 0.3451107625798998, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1915050284422795, 0.1915050284422795, 0.2689299732155003], 
reward next is 0.7311, 
noisyNet noise sample is [array([1.3945236], dtype=float32), -1.1363691]. 
=============================================
[2019-03-23 10:57:38,012] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2145618: loss 0.0093
[2019-03-23 10:57:38,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2145618: learning rate 0.0010
[2019-03-23 10:57:38,197] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2145709: loss 0.0113
[2019-03-23 10:57:38,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2145710: learning rate 0.0010
[2019-03-23 10:57:38,283] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145754: loss 0.0029
[2019-03-23 10:57:38,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145754: learning rate 0.0010
[2019-03-23 10:57:38,574] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145897: loss 0.0020
[2019-03-23 10:57:38,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145897: learning rate 0.0010
[2019-03-23 10:57:38,648] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2145934: loss 0.0080
[2019-03-23 10:57:38,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2145934: learning rate 0.0010
[2019-03-23 10:57:39,148] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2146192: loss 0.0003
[2019-03-23 10:57:39,149] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2146192: learning rate 0.0010
[2019-03-23 10:57:39,817] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2146529: loss 0.0023
[2019-03-23 10:57:39,819] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2146530: learning rate 0.0010
[2019-03-23 10:57:40,554] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5181949e-12 1.0000000e+00 2.3447480e-20 2.6656697e-19 1.2226446e-21], sum to 1.0000
[2019-03-23 10:57:40,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1988
[2019-03-23 10:57:40,575] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2034760282791062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220921.106046603, 220921.106046603, 73205.59540898693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053000.0000, 
sim time next is 1053600.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215955.5714983086, 215955.5714983089, 72406.91107287286], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07998354499937356, 0.07998354499937367, 0.17660222212895818], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8144809], dtype=float32), 1.1705115]. 
=============================================
[2019-03-23 10:57:41,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6528754e-13 1.0000000e+00 4.2519655e-20 5.1689822e-18 3.4588529e-21], sum to 1.0000
[2019-03-23 10:57:41,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9744
[2019-03-23 10:57:41,392] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 100.0, 1.0, 2.0, 0.4132675399931738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 468489.21223634, 468489.21223634, 127712.4302620824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 940800.0000, 
sim time next is 941400.0000, 
raw observation next is [19.0, 100.0, 1.0, 2.0, 0.4127124483938614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 467859.1255904069, 467859.1255904066, 127659.2700235411], 
processed observation next is [0.0, 0.9130434782608695, 0.5, 1.0, 1.0, 1.0, 0.26589056049232673, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.17328115762607663, 0.17328115762607652, 0.311364073228149], 
reward next is 0.6886, 
noisyNet noise sample is [array([-0.8600208], dtype=float32), 0.19078349]. 
=============================================
[2019-03-23 10:57:43,061] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2148149: loss 0.0261
[2019-03-23 10:57:43,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2148150: learning rate 0.0010
[2019-03-23 10:57:44,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8177955e-12 1.0000000e+00 1.6253565e-19 1.1789201e-18 7.6168140e-21], sum to 1.0000
[2019-03-23 10:57:44,848] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1037
[2019-03-23 10:57:44,851] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 100.0, 1.0, 2.0, 0.4723400015681615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538975.9569223528, 538975.9569223528, 137722.8447298801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1480800.0000, 
sim time next is 1481400.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.4668148540565634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 532622.800517931, 532622.8005179312, 136752.9857209871], 
processed observation next is [0.0, 0.13043478260869565, 0.5681818181818182, 1.0, 1.0, 1.0, 0.33351856757070425, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19726770389553, 0.19726770389553008, 0.3335438676121637], 
reward next is 0.6665, 
noisyNet noise sample is [array([1.2747074], dtype=float32), -0.25907755]. 
=============================================
[2019-03-23 10:57:45,308] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2134308e-12 1.0000000e+00 3.4068170e-19 4.3885654e-18 1.8457854e-20], sum to 1.0000
[2019-03-23 10:57:45,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-23 10:57:45,322] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 100.0, 1.0, 2.0, 0.4572317330331683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521709.5799041325, 521709.5799041325, 135869.2780323732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [20.83333333333333, 100.0, 1.0, 2.0, 0.4633529876063499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528715.7522405231, 528715.7522405231, 136890.8430658874], 
processed observation next is [0.0, 0.21739130434782608, 0.5833333333333331, 1.0, 1.0, 1.0, 0.32919123450793736, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19582064897797152, 0.19582064897797152, 0.33388010503874976], 
reward next is 0.6661, 
noisyNet noise sample is [array([0.20514785], dtype=float32), 0.62383693]. 
=============================================
[2019-03-23 10:57:46,460] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2149861: loss 0.0109
[2019-03-23 10:57:46,462] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2149861: learning rate 0.0010
[2019-03-23 10:57:46,735] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 10:57:46,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 10:57:46,736] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:46,737] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 10:57:46,738] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 10:57:46,738] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:46,738] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 10:57:46,739] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 10:57:46,739] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:46,743] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:46,743] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 10:57:46,761] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 10:57:46,789] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 10:57:46,816] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 10:57:46,841] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 10:57:46,865] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 10:58:45,973] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5287529]
[2019-03-23 10:58:45,973] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.93333333333333, 85.0, 1.0, 2.0, 0.5197510977828292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 591217.5053022378, 591217.5053022378, 150112.4943353425]
[2019-03-23 10:58:45,974] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 10:58:45,976] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.6561457e-12 1.0000000e+00 3.1447045e-18 1.4120279e-17 9.6603096e-20], sampled 0.8029099508128531
[2019-03-23 10:58:48,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5287529]
[2019-03-23 10:58:48,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.11666666666667, 81.00000000000001, 1.0, 2.0, 0.4035661771842352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 456702.1909737177, 456702.1909737177, 130612.9275459376]
[2019-03-23 10:58:48,847] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:58:48,850] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6561457e-12 1.0000000e+00 3.1447045e-18 1.4120279e-17 9.6603096e-20], sampled 0.44550475120735733
[2019-03-23 10:59:07,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5287529]
[2019-03-23 10:59:07,400] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [15.73333333333333, 83.0, 1.0, 2.0, 0.2427794130378999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 263592.1182805537, 263592.1182805533, 86911.27097727366]
[2019-03-23 10:59:07,401] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 10:59:07,405] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [7.6561457e-12 1.0000000e+00 3.1447045e-18 1.4120279e-17 9.6603096e-20], sampled 0.6407808702934404
[2019-03-23 10:59:08,700] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5287529]
[2019-03-23 10:59:08,701] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 76.0, 1.0, 2.0, 0.496572057436323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 566380.787563185, 566380.787563185, 141557.8723359765]
[2019-03-23 10:59:08,702] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:59:08,705] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.6561457e-12 1.0000000e+00 3.1447045e-18 1.4120279e-17 9.6603096e-20], sampled 0.9764673388503547
[2019-03-23 10:59:25,112] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5287529]
[2019-03-23 10:59:25,114] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.9, 67.5, 1.0, 2.0, 0.2740278693768362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 297545.1611916759, 297545.1611916756, 95641.89562283199]
[2019-03-23 10:59:25,114] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 10:59:25,118] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.6561457e-12 1.0000000e+00 3.1447045e-18 1.4120279e-17 9.6603096e-20], sampled 0.9998417378912264
[2019-03-23 10:59:25,163] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 10:59:25,450] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 10:59:25,722] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 10:59:25,727] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 10:59:25,730] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 10:59:26,750] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2150000, evaluation results [2150000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 10:59:28,171] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2150754: loss 0.0013
[2019-03-23 10:59:28,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2150754: learning rate 0.0010
[2019-03-23 10:59:28,256] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2150794: loss 0.0089
[2019-03-23 10:59:28,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2150795: learning rate 0.0010
[2019-03-23 10:59:28,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5722115e-13 1.0000000e+00 5.3373494e-21 7.0415600e-19 3.0005217e-21], sum to 1.0000
[2019-03-23 10:59:28,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2570
[2019-03-23 10:59:28,440] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 67.66666666666667, 1.0, 2.0, 0.3755026936136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422450.3885370153, 422450.3885370153, 122314.6886738986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1100400.0000, 
sim time next is 1101000.0000, 
raw observation next is [22.16666666666667, 68.33333333333333, 1.0, 2.0, 0.3755877171403832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422277.5947080706, 422277.5947080706, 122184.6532125511], 
processed observation next is [1.0, 0.7391304347826086, 0.6439393939393941, 0.6833333333333332, 1.0, 1.0, 0.21948464642547896, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15639910915113728, 0.15639910915113728, 0.2980113492989051], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.82467216], dtype=float32), -0.541125]. 
=============================================
[2019-03-23 10:59:28,452] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.14154]
 [67.14154]
 [67.14154]
 [67.14154]
 [67.14154]], R is [[67.17211151]
 [67.20205688]
 [67.2312088 ]
 [67.25655365]
 [67.25689697]].
[2019-03-23 10:59:28,843] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2151103: loss 0.0512
[2019-03-23 10:59:28,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2151104: learning rate 0.0010
[2019-03-23 10:59:31,152] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1082505e-11 1.0000000e+00 1.7506998e-17 1.0270458e-17 7.6318289e-19], sum to 1.0000
[2019-03-23 10:59:31,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8869
[2019-03-23 10:59:31,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1383852.777434316 W.
[2019-03-23 10:59:31,168] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 59.33333333333334, 1.0, 2.0, 0.6118037996283768, 1.0, 2.0, 0.6118037996283768, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1383852.777434316, 1383852.777434316, 263406.7249573304], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1268400.0000, 
sim time next is 1269000.0000, 
raw observation next is [27.5, 60.0, 1.0, 2.0, 0.416436093049764, 1.0, 2.0, 0.416436093049764, 1.0, 1.0, 0.842278030831582, 6.9112, 6.9112, 77.3421103, 1410090.775473949, 1410090.775473949, 313154.3021300765], 
processed observation next is [1.0, 0.6956521739130435, 0.8863636363636364, 0.6, 1.0, 1.0, 0.27054511631220496, 1.0, 1.0, 0.27054511631220496, 1.0, 0.5, 0.7746829011879743, 0.0, 0.0, 0.5085185399722538, 0.5222558427681293, 0.5222558427681293, 0.7637909808050647], 
reward next is 0.2362, 
noisyNet noise sample is [array([-0.5664736], dtype=float32), -1.8328028]. 
=============================================
[2019-03-23 10:59:31,187] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.781204]
 [63.781204]
 [63.781204]
 [63.781204]
 [63.781204]], R is [[63.37960434]
 [63.10335159]
 [62.86352539]
 [62.56389999]
 [62.09027481]].
[2019-03-23 10:59:31,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.332073e-12 1.000000e+00 4.390556e-19 3.791791e-18 4.529458e-20], sum to 1.0000
[2019-03-23 10:59:31,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9006
[2019-03-23 10:59:31,317] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 95.0, 1.0, 2.0, 0.3713106984529642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 413707.7332058976, 413707.7332058976, 120082.7280947531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1145400.0000, 
sim time next is 1146000.0000, 
raw observation next is [18.0, 96.0, 1.0, 2.0, 0.3527698955115632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 393637.8619383592, 393637.8619383589, 118837.7467651146], 
processed observation next is [1.0, 0.2608695652173913, 0.45454545454545453, 0.96, 1.0, 1.0, 0.19096236938945396, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1457918007179108, 0.1457918007179107, 0.2898481628417429], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.3447236], dtype=float32), 0.46813747]. 
=============================================
[2019-03-23 10:59:31,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.998505]
 [61.998505]
 [61.998505]
 [61.998505]
 [61.998505]], R is [[62.08867264]
 [62.17490005]
 [62.26654816]
 [62.35714722]
 [62.4467659 ]].
[2019-03-23 10:59:31,476] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2152495: loss 0.0136
[2019-03-23 10:59:31,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2152497: learning rate 0.0010
[2019-03-23 10:59:31,993] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2152774: loss 0.0019
[2019-03-23 10:59:31,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2152774: learning rate 0.0010
[2019-03-23 10:59:32,392] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2152987: loss 0.0030
[2019-03-23 10:59:32,396] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2152987: learning rate 0.0010
[2019-03-23 10:59:32,710] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2153151: loss 0.0001
[2019-03-23 10:59:32,712] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2153152: learning rate 0.0010
[2019-03-23 10:59:33,307] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4388051e-12 1.0000000e+00 3.4517239e-20 6.4930793e-19 5.3664623e-21], sum to 1.0000
[2019-03-23 10:59:33,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0726
[2019-03-23 10:59:33,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1109169.776388132 W.
[2019-03-23 10:59:33,337] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 71.5, 1.0, 2.0, 0.9725975696217105, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846325500108, 1109169.776388132, 1109169.776388132, 214931.5990639906], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1247400.0000, 
sim time next is 1248000.0000, 
raw observation next is [25.33333333333333, 69.33333333333333, 1.0, 2.0, 0.448258926768148, 1.0, 1.0, 0.448258926768148, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344237396, 1019819.192785211, 1019819.192785211, 218987.213963673], 
processed observation next is [1.0, 0.43478260869565216, 0.7878787878787876, 0.6933333333333332, 1.0, 1.0, 0.31032365846018495, 1.0, 0.5, 0.31032365846018495, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129129806, 0.37771081214267077, 0.37771081214267077, 0.5341151560089585], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9511107], dtype=float32), -0.33361727]. 
=============================================
[2019-03-23 10:59:33,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.868034]
 [65.868034]
 [65.868034]
 [65.868034]
 [65.868034]], R is [[65.20935822]
 [64.55726624]
 [63.91169357]
 [63.27257538]
 [62.95244598]].
[2019-03-23 10:59:33,405] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2153518: loss 0.0003
[2019-03-23 10:59:33,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2153520: learning rate 0.0010
[2019-03-23 10:59:33,652] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153648: loss 0.0006
[2019-03-23 10:59:33,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153649: learning rate 0.0010
[2019-03-23 10:59:33,835] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2153748: loss 0.0047
[2019-03-23 10:59:33,836] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2153748: learning rate 0.0010
[2019-03-23 10:59:34,011] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2153835: loss 0.0003
[2019-03-23 10:59:34,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2153835: learning rate 0.0010
[2019-03-23 10:59:34,146] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153907: loss 0.0015
[2019-03-23 10:59:34,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153907: learning rate 0.0010
[2019-03-23 10:59:34,713] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2154210: loss 0.0003
[2019-03-23 10:59:34,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2154211: learning rate 0.0010
[2019-03-23 10:59:35,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.95328778e-12 1.00000000e+00 3.04742747e-19 1.15428505e-17
 1.30552179e-20], sum to 1.0000
[2019-03-23 10:59:35,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1304
[2019-03-23 10:59:35,165] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 87.0, 1.0, 2.0, 0.5194452769362142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 591486.143956261, 591486.143956261, 145382.6475370476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1209600.0000, 
sim time next is 1210200.0000, 
raw observation next is [23.5, 86.33333333333333, 1.0, 2.0, 0.5203304083931412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 592463.3440699412, 592463.3440699412, 145514.7879695651], 
processed observation next is [1.0, 0.0, 0.7045454545454546, 0.8633333333333333, 1.0, 1.0, 0.4004130104914264, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2194308681740523, 0.2194308681740523, 0.35491411699893927], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.6182938], dtype=float32), -1.1061538]. 
=============================================
[2019-03-23 10:59:35,226] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2154493: loss 0.0001
[2019-03-23 10:59:35,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2154495: learning rate 0.0010
[2019-03-23 10:59:35,471] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.383425e-12 1.000000e+00 1.711286e-18 4.180482e-17 5.116809e-21], sum to 1.0000
[2019-03-23 10:59:35,478] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9245
[2019-03-23 10:59:35,481] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 95.0, 1.0, 2.0, 0.5127104111331309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 578599.7868904495, 578599.7868904497, 136267.7135274133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1217400.0000, 
sim time next is 1218000.0000, 
raw observation next is [19.0, 96.0, 1.0, 2.0, 0.4507122123304471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 509083.0455774519, 509083.0455774522, 130223.6629093913], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.96, 1.0, 1.0, 0.31339026541305887, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.188549276139797, 0.18854927613979713, 0.3176186900229056], 
reward next is 0.6824, 
noisyNet noise sample is [array([0.93010354], dtype=float32), 0.6136226]. 
=============================================
[2019-03-23 10:59:35,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.41447]
 [64.41447]
 [64.41447]
 [64.41447]
 [64.41447]], R is [[64.45271301]
 [64.47582245]
 [64.52350616]
 [64.5618515 ]
 [64.59106445]].
[2019-03-23 10:59:36,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1619427e-10 1.0000000e+00 1.3217547e-17 5.8854476e-17 9.5375393e-19], sum to 1.0000
[2019-03-23 10:59:36,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-23 10:59:36,065] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 94.0, 1.0, 2.0, 0.3587390537966454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399252.0367817049, 399252.0367817046, 118869.3279509286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1294800.0000, 
sim time next is 1295400.0000, 
raw observation next is [18.0, 94.0, 1.0, 2.0, 0.3579662768057399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 398388.1157221047, 398388.115722105, 118805.7560717479], 
processed observation next is [1.0, 1.0, 0.45454545454545453, 0.94, 1.0, 1.0, 0.19745784600717484, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14755115397114987, 0.14755115397115, 0.28977013676036073], 
reward next is 0.7102, 
noisyNet noise sample is [array([1.3294597], dtype=float32), -0.07381591]. 
=============================================
[2019-03-23 10:59:38,529] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2156217: loss 0.0411
[2019-03-23 10:59:38,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2156218: learning rate 0.0010
[2019-03-23 10:59:41,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5139501e-11 1.0000000e+00 1.7271908e-17 1.9145618e-18 7.7098661e-20], sum to 1.0000
[2019-03-23 10:59:41,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4267
[2019-03-23 10:59:41,251] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465800.0000, 
sim time next is 1466400.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 2.0, 0.4753648205968214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542429.5109104976, 542429.5109104976, 138060.4446414285], 
processed observation next is [0.0, 1.0, 0.575757575757576, 1.0, 1.0, 1.0, 0.3442060257460267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20089981885573988, 0.20089981885573988, 0.3367327918083622], 
reward next is 0.6633, 
noisyNet noise sample is [array([1.6874924], dtype=float32), -2.155022]. 
=============================================
[2019-03-23 10:59:41,383] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2157646: loss 0.4457
[2019-03-23 10:59:41,388] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2157646: learning rate 0.0010
[2019-03-23 10:59:41,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3698213e-10 1.0000000e+00 1.4528719e-16 1.0268231e-16 2.2094457e-19], sum to 1.0000
[2019-03-23 10:59:41,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1398
[2019-03-23 10:59:41,690] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4811271548928894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548937.831359497, 548937.831359497, 139323.8481247724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1476000.0000, 
sim time next is 1476600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4811603865119269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 548975.6894618856, 548975.6894618856, 139327.8939521715], 
processed observation next is [0.0, 0.08695652173913043, 0.5909090909090909, 1.0, 1.0, 1.0, 0.35145048313990856, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.203324329430328, 0.203324329430328, 0.33982413159066216], 
reward next is 0.6602, 
noisyNet noise sample is [array([-0.9075841], dtype=float32), 0.6990781]. 
=============================================
[2019-03-23 10:59:43,557] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2158724: loss 0.0527
[2019-03-23 10:59:43,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2158724: learning rate 0.0010
[2019-03-23 10:59:43,653] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2158769: loss 0.0415
[2019-03-23 10:59:43,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2158769: learning rate 0.0010
[2019-03-23 10:59:43,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0950734e-13 1.0000000e+00 1.7998135e-18 4.7475423e-18 1.2168994e-19], sum to 1.0000
[2019-03-23 10:59:43,738] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4575
[2019-03-23 10:59:43,743] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4879790531842348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 556758.9177535077, 556758.917753508, 140106.1409645511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1444800.0000, 
sim time next is 1445400.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4893590616318537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 558334.0511352582, 558334.0511352585, 140264.8589687533], 
processed observation next is [0.0, 0.7391304347826086, 0.5909090909090909, 1.0, 1.0, 1.0, 0.3616988270398171, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20679038930935487, 0.206790389309355, 0.3421094121189105], 
reward next is 0.6579, 
noisyNet noise sample is [array([2.2986422], dtype=float32), -0.14248821]. 
=============================================
[2019-03-23 10:59:44,431] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2159161: loss 0.0266
[2019-03-23 10:59:44,433] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2159162: learning rate 0.0010
[2019-03-23 10:59:45,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3612553e-12 1.0000000e+00 2.3478125e-17 1.9608852e-17 6.6995213e-20], sum to 1.0000
[2019-03-23 10:59:45,246] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1754
[2019-03-23 10:59:45,250] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4459115402703866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 508224.5579430277, 508224.5579430277, 133334.8105631761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458000.0000, 
sim time next is 1458600.0000, 
raw observation next is [20.16666666666667, 100.0, 1.0, 2.0, 0.4484802221499329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511315.6321275934, 511315.6321275937, 133853.1173190414], 
processed observation next is [0.0, 0.9130434782608695, 0.5530303030303032, 1.0, 1.0, 1.0, 0.31060027768741605, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1893761600472568, 0.1893761600472569, 0.3264710178513205], 
reward next is 0.6735, 
noisyNet noise sample is [array([0.31291446], dtype=float32), 0.8873273]. 
=============================================
[2019-03-23 10:59:47,200] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2160568: loss 0.0510
[2019-03-23 10:59:47,203] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2160568: learning rate 0.0010
[2019-03-23 10:59:47,608] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160777: loss 0.0207
[2019-03-23 10:59:47,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160777: learning rate 0.0010
[2019-03-23 10:59:48,077] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2161015: loss 0.0306
[2019-03-23 10:59:48,078] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2161015: learning rate 0.0010
[2019-03-23 10:59:48,458] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2161207: loss 0.0286
[2019-03-23 10:59:48,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2161208: learning rate 0.0010
[2019-03-23 10:59:49,079] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2161519: loss 0.0136
[2019-03-23 10:59:49,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2161519: learning rate 0.0010
[2019-03-23 10:59:49,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0219089e-12 1.0000000e+00 2.3925293e-18 3.9035836e-18 2.9978573e-20], sum to 1.0000
[2019-03-23 10:59:49,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6636
[2019-03-23 10:59:49,447] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 67.66666666666667, 1.0, 2.0, 0.4675686357798211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.3284634435341, 533508.6985618941, 533508.6985618944, 137570.8045314401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1618800.0000, 
sim time next is 1619400.0000, 
raw observation next is [25.16666666666667, 68.33333333333333, 1.0, 2.0, 0.4691117552495362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.328463443541, 535283.0437390631, 535283.0437390631, 137637.6057967343], 
processed observation next is [1.0, 0.7391304347826086, 0.7803030303030305, 0.6833333333333332, 1.0, 1.0, 0.3363896940619202, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206538, 0.19825297916261594, 0.19825297916261594, 0.3357014775530105], 
reward next is 0.6643, 
noisyNet noise sample is [array([-1.0141668], dtype=float32), -1.7888175]. 
=============================================
[2019-03-23 10:59:49,454] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161710: loss 0.0061
[2019-03-23 10:59:49,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161711: learning rate 0.0010
[2019-03-23 10:59:49,608] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2161788: loss 0.0030
[2019-03-23 10:59:49,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2161788: learning rate 0.0010
[2019-03-23 10:59:49,726] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2161847: loss 0.0110
[2019-03-23 10:59:49,728] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2161847: learning rate 0.0010
[2019-03-23 10:59:50,073] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2162025: loss 0.0215
[2019-03-23 10:59:50,077] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2162025: learning rate 0.0010
[2019-03-23 10:59:50,512] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2162246: loss 0.0417
[2019-03-23 10:59:50,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2162247: learning rate 0.0010
[2019-03-23 10:59:51,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0952772e-14 1.0000000e+00 1.8516811e-20 1.6420405e-18 4.9067098e-21], sum to 1.0000
[2019-03-23 10:59:51,011] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8272
[2019-03-23 10:59:51,019] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 78.83333333333333, 1.0, 2.0, 0.3859280345789154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434749.4948977792, 434749.4948977792, 123517.6759024467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1635000.0000, 
sim time next is 1635600.0000, 
raw observation next is [20.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3824803475799071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 430619.7361191568, 430619.7361191568, 123084.7603103914], 
processed observation next is [1.0, 0.9565217391304348, 0.575757575757576, 0.7966666666666667, 1.0, 1.0, 0.22810043447488387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15948879115524325, 0.15948879115524325, 0.3002067324643693], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.9263761], dtype=float32), -0.08562133]. 
=============================================
[2019-03-23 10:59:51,094] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2162538: loss 0.0476
[2019-03-23 10:59:51,096] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2162538: learning rate 0.0010
[2019-03-23 10:59:51,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3750692e-11 1.0000000e+00 2.2854246e-18 1.1955507e-17 9.3445385e-20], sum to 1.0000
[2019-03-23 10:59:51,829] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8925
[2019-03-23 10:59:51,836] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.3091062181711624, 1.0, 2.0, 0.3091062181711624, 1.0, 1.0, 0.6257749490297202, 6.911199999999999, 6.9112, 77.3421103, 1049461.589072443, 1049461.589072444, 265316.6788858857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1591200.0000, 
sim time next is 1591800.0000, 
raw observation next is [23.16666666666667, 86.5, 1.0, 2.0, 0.8690511367384318, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 989500.4393530269, 989500.4393530271, 197534.1295492308], 
processed observation next is [1.0, 0.43478260869565216, 0.6893939393939396, 0.865, 1.0, 1.0, 0.8363139209230397, 0.0, 0.5, -0.25, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.36648164420482476, 0.3664816442048249, 0.4817905598761727], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.86884236], dtype=float32), -2.3751385]. 
=============================================
[2019-03-23 10:59:53,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0109261e-12 1.0000000e+00 1.3193562e-18 9.5265266e-18 2.3362304e-20], sum to 1.0000
[2019-03-23 10:59:53,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3542
[2019-03-23 10:59:53,425] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 94.0, 1.0, 2.0, 0.4557019371336526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519982.0636194624, 519982.0636194621, 135969.1981997801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1582200.0000, 
sim time next is 1582800.0000, 
raw observation next is [21.66666666666667, 94.0, 1.0, 2.0, 0.4723292178321546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 538936.4318514955, 538936.4318514955, 138145.368823396], 
processed observation next is [1.0, 0.30434782608695654, 0.6212121212121214, 0.94, 1.0, 1.0, 0.3404115222901932, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19960608587092427, 0.19960608587092427, 0.33693992395950245], 
reward next is 0.6631, 
noisyNet noise sample is [array([-0.23892486], dtype=float32), 0.23798528]. 
=============================================
[2019-03-23 10:59:53,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5182499e-12 1.0000000e+00 4.9589297e-20 6.5708927e-20 1.1335644e-21], sum to 1.0000
[2019-03-23 10:59:53,944] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4067
[2019-03-23 10:59:53,949] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1169477.257256694 W.
[2019-03-23 10:59:53,956] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.83333333333333, 62.5, 1.0, 2.0, 0.3440994898213313, 1.0, 1.0, 0.3440994898213313, 1.0, 2.0, 0.6967723728358987, 6.911199999999999, 6.9112, 77.3421103, 1169477.257256694, 1169477.257256695, 278647.206435621], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1613400.0000, 
sim time next is 1614000.0000, 
raw observation next is [26.66666666666667, 63.0, 1.0, 2.0, 0.4905071642115827, 1.0, 2.0, 0.4905071642115827, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1112707.414299424, 1112707.414299424, 230359.2348655571], 
processed observation next is [1.0, 0.6956521739130435, 0.8484848484848487, 0.63, 1.0, 1.0, 0.36313395526447834, 1.0, 1.0, 0.36313395526447834, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4121138571479348, 0.4121138571479348, 0.5618517923550174], 
reward next is 0.4381, 
noisyNet noise sample is [array([-0.6182967], dtype=float32), -0.1925624]. 
=============================================
[2019-03-23 10:59:53,973] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.06373]
 [67.06373]
 [67.06373]
 [67.06373]
 [67.06373]], R is [[66.83123779]
 [66.16292572]
 [65.501297  ]
 [64.84628296]
 [64.19782257]].
[2019-03-23 10:59:54,268] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2164129: loss 0.2698
[2019-03-23 10:59:54,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2164131: learning rate 0.0010
[2019-03-23 10:59:57,252] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2165626: loss 0.0004
[2019-03-23 10:59:57,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2165626: learning rate 0.0010
[2019-03-23 10:59:58,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6974291e-13 1.0000000e+00 3.2339967e-20 1.5282031e-20 4.1990571e-23], sum to 1.0000
[2019-03-23 10:59:58,123] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4689
[2019-03-23 10:59:58,138] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 91.0, 1.0, 2.0, 0.3701042578991744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412784.308259616, 412784.3082596157, 120163.5125357272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1654200.0000, 
sim time next is 1654800.0000, 
raw observation next is [18.66666666666667, 90.0, 1.0, 2.0, 0.365053865292118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 407422.2900025758, 407422.2900025758, 119867.2944202927], 
processed observation next is [1.0, 0.13043478260869565, 0.4848484848484851, 0.9, 1.0, 1.0, 0.20631733161514745, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15089714444539845, 0.15089714444539845, 0.2923592546836407], 
reward next is 0.7076, 
noisyNet noise sample is [array([-1.0846282], dtype=float32), 0.7482107]. 
=============================================
[2019-03-23 10:59:59,381] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2166703: loss 0.2285
[2019-03-23 10:59:59,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2166704: learning rate 0.0010
[2019-03-23 10:59:59,641] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2166834: loss 0.1915
[2019-03-23 10:59:59,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2166834: learning rate 0.0010
[2019-03-23 11:00:00,334] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2167185: loss 0.1781
[2019-03-23 11:00:00,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2167185: learning rate 0.0010
[2019-03-23 11:00:02,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5986655e-12 1.0000000e+00 5.7961612e-20 2.6197810e-19 2.8415181e-22], sum to 1.0000
[2019-03-23 11:00:02,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9366
[2019-03-23 11:00:02,366] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.833333333333334, 72.66666666666667, 1.0, 2.0, 0.2742238030846514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 297757.9752160235, 297757.9752160238, 71634.97155680308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1735800.0000, 
sim time next is 1736400.0000, 
raw observation next is [8.666666666666668, 74.33333333333334, 1.0, 2.0, 0.3277515445984704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 355900.7914549832, 355900.7914549832, 75680.95399954649], 
processed observation next is [1.0, 0.08695652173913043, 0.030303030303030356, 0.7433333333333334, 1.0, 1.0, 0.15968943074808797, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13181510794629006, 0.13181510794629006, 0.1845876926818207], 
reward next is 0.8154, 
noisyNet noise sample is [array([0.99648166], dtype=float32), 0.52812475]. 
=============================================
[2019-03-23 11:00:02,973] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2168511: loss 0.0283
[2019-03-23 11:00:02,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2168512: learning rate 0.0010
[2019-03-23 11:00:03,500] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168778: loss 0.0186
[2019-03-23 11:00:03,503] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168779: learning rate 0.0010
[2019-03-23 11:00:03,906] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2168983: loss 0.0227
[2019-03-23 11:00:03,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2168983: learning rate 0.0010
[2019-03-23 11:00:04,478] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2169275: loss 0.0114
[2019-03-23 11:00:04,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2169275: learning rate 0.0010
[2019-03-23 11:00:05,162] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2169625: loss 0.0051
[2019-03-23 11:00:05,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2169626: learning rate 0.0010
[2019-03-23 11:00:05,270] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169680: loss 0.0248
[2019-03-23 11:00:05,274] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169680: learning rate 0.0010
[2019-03-23 11:00:05,378] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2169733: loss 0.0257
[2019-03-23 11:00:05,380] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2169733: learning rate 0.0010
[2019-03-23 11:00:05,694] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2169888: loss 0.1043
[2019-03-23 11:00:05,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2169889: learning rate 0.0010
[2019-03-23 11:00:06,094] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2170094: loss 0.0934
[2019-03-23 11:00:06,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2170095: learning rate 0.0010
[2019-03-23 11:00:06,309] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2170199: loss 0.0825
[2019-03-23 11:00:06,311] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2170200: learning rate 0.0010
[2019-03-23 11:00:06,746] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5865716e-14 1.0000000e+00 1.3407255e-19 2.0343733e-19 6.9763117e-22], sum to 1.0000
[2019-03-23 11:00:06,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7309
[2019-03-23 11:00:06,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1166950.248678746 W.
[2019-03-23 11:00:06,767] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 61.0, 1.0, 2.0, 0.3414596104944508, 1.0, 2.0, 0.3414596104944508, 1.0, 1.0, 0.6914160273738805, 6.9112, 6.9112, 77.3421103, 1166950.248678746, 1166950.248678746, 273567.5997163976], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1951200.0000, 
sim time next is 1951800.0000, 
raw observation next is [25.83333333333334, 61.0, 1.0, 2.0, 0.5619231104678671, 1.0, 2.0, 0.5619231104678671, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 1281157.132397213, 1281157.132397213, 244792.7072415478], 
processed observation next is [1.0, 0.6086956521739131, 0.8106060606060609, 0.61, 1.0, 1.0, 0.4524038880848339, 1.0, 1.0, 0.4524038880848339, 0.0, 0.5, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4745026416285974, 0.4745026416285974, 0.5970553835159702], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22008905], dtype=float32), -0.02333653]. 
=============================================
[2019-03-23 11:00:06,945] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2170515: loss 0.1273
[2019-03-23 11:00:06,946] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2170515: learning rate 0.0010
[2019-03-23 11:00:09,109] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4825913e-13 1.0000000e+00 2.0543982e-21 1.0014214e-20 1.4784741e-22], sum to 1.0000
[2019-03-23 11:00:09,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5447
[2019-03-23 11:00:09,123] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 64.0, 1.0, 2.0, 0.2522807516438096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 273925.0383677495, 273925.0383677498, 82762.65940675892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1994400.0000, 
sim time next is 1995000.0000, 
raw observation next is [18.0, 64.66666666666667, 1.0, 2.0, 0.2511294644623122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272674.6267190891, 272674.6267190894, 83078.8441110169], 
processed observation next is [0.0, 0.08695652173913043, 0.45454545454545453, 0.6466666666666667, 1.0, 1.0, 0.06391183057789025, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10099060248855152, 0.10099060248855163, 0.2026313271000412], 
reward next is 0.7974, 
noisyNet noise sample is [array([-0.2849593], dtype=float32), 1.040008]. 
=============================================
[2019-03-23 11:00:09,147] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.01384]
 [74.01384]
 [74.01384]
 [74.01384]
 [74.01384]], R is [[74.07107544]
 [74.12850952]
 [74.18388367]
 [74.23710632]
 [74.28816986]].
[2019-03-23 11:00:10,187] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2172151: loss 0.0172
[2019-03-23 11:00:10,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2172152: learning rate 0.0010
[2019-03-23 11:00:13,003] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2173567: loss 0.0841
[2019-03-23 11:00:13,004] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2173568: learning rate 0.0010
[2019-03-23 11:00:13,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6265762e-11 1.0000000e+00 1.9860052e-18 1.3129110e-16 9.0409516e-20], sum to 1.0000
[2019-03-23 11:00:13,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1982
[2019-03-23 11:00:13,142] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 65.33333333333333, 1.0, 2.0, 0.7574874754844879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 864622.979350629, 864622.979350629, 175015.4406590147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1946400.0000, 
sim time next is 1947000.0000, 
raw observation next is [25.66666666666667, 63.16666666666666, 1.0, 2.0, 0.7347787799261786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 838653.5260206725, 838653.5260206725, 171405.7990394971], 
processed observation next is [1.0, 0.5217391304347826, 0.8030303030303032, 0.6316666666666666, 1.0, 1.0, 0.6684734749077231, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3106124170446935, 0.3106124170446935, 0.4180629244865783], 
reward next is 0.5819, 
noisyNet noise sample is [array([-0.5685514], dtype=float32), 0.51270014]. 
=============================================
[2019-03-23 11:00:13,160] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.43619]
 [72.43619]
 [72.43619]
 [72.43619]
 [72.43619]], R is [[72.29376984]
 [72.14396667]
 [71.96377563]
 [71.60463715]
 [70.88858795]].
[2019-03-23 11:00:15,102] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2174632: loss 0.0206
[2019-03-23 11:00:15,106] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2174632: learning rate 0.0010
[2019-03-23 11:00:15,515] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2174842: loss 0.0041
[2019-03-23 11:00:15,520] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2174842: learning rate 0.0010
[2019-03-23 11:00:15,824] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 11:00:15,825] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:00:15,826] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:00:15,829] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:00:15,829] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:00:15,830] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:00:15,831] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:00:15,831] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:00:15,832] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:00:15,834] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:00:15,835] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:00:15,859] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 11:00:15,882] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 11:00:15,910] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 11:00:15,911] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 11:00:15,934] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 11:00:32,594] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47659543]
[2019-03-23 11:00:32,596] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.56640327666667, 54.01400889666667, 1.0, 2.0, 0.4774919208539395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 543404.0472508069, 543404.0472508066, 140097.9115827647]
[2019-03-23 11:00:32,597] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:00:32,600] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7651758e-13 1.0000000e+00 3.1572502e-20 1.4245676e-19 5.3278671e-22], sampled 0.23014159958397906
[2019-03-23 11:00:57,773] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47659543]
[2019-03-23 11:00:57,774] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [25.72784608333333, 67.17045468666666, 1.0, 2.0, 0.6622230625105321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 755493.8428930764, 755493.8428930764, 166871.6685811477]
[2019-03-23 11:00:57,774] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:00:57,777] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7651758e-13 1.0000000e+00 3.1572502e-20 1.4245676e-19 5.3278671e-22], sampled 0.5905351363912192
[2019-03-23 11:01:04,551] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47659543]
[2019-03-23 11:01:04,553] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [24.9766213, 92.59572474, 1.0, 2.0, 0.6594515874613938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 740987.8261640556, 740987.8261640553, 171764.4809861259]
[2019-03-23 11:01:04,555] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:01:04,558] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7651758e-13 1.0000000e+00 3.1572502e-20 1.4245676e-19 5.3278671e-22], sampled 0.8518008950436542
[2019-03-23 11:01:08,396] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47659543]
[2019-03-23 11:01:08,400] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.19629067, 66.7494764, 1.0, 2.0, 0.3170678637041295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 345404.5930182761, 345404.5930182757, 117048.962182262]
[2019-03-23 11:01:08,401] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:01:08,405] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.7651758e-13 1.0000000e+00 3.1572502e-20 1.4245676e-19 5.3278671e-22], sampled 0.9075629294340036
[2019-03-23 11:01:43,334] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47659543]
[2019-03-23 11:01:43,335] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [24.63333333333333, 52.0, 1.0, 2.0, 0.3581958933878071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401043.0066019224, 401043.0066019221, 124207.9310128876]
[2019-03-23 11:01:43,336] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:01:43,339] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.7651758e-13 1.0000000e+00 3.1572502e-20 1.4245676e-19 5.3278671e-22], sampled 0.9626218321755824
[2019-03-23 11:01:50,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.47659543]
[2019-03-23 11:01:50,166] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.889126125, 96.794043725, 1.0, 2.0, 0.3702533466815032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 413671.5323008607, 413671.5323008607, 124811.7790923044]
[2019-03-23 11:01:50,167] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:01:50,172] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.7651758e-13 1.0000000e+00 3.1572502e-20 1.4245676e-19 5.3278671e-22], sampled 0.6472439839744116
[2019-03-23 11:01:54,033] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:01:54,129] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:01:54,156] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:01:54,394] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:01:54,484] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:01:55,499] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2175000, evaluation results [2175000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:01:55,820] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2175167: loss 0.0015
[2019-03-23 11:01:55,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2175167: learning rate 0.0010
[2019-03-23 11:01:58,677] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2176678: loss 0.0645
[2019-03-23 11:01:58,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2176678: learning rate 0.0010
[2019-03-23 11:01:58,982] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176839: loss 0.0334
[2019-03-23 11:01:58,985] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176839: learning rate 0.0010
[2019-03-23 11:01:59,085] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2176897: loss 0.0177
[2019-03-23 11:01:59,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2176897: learning rate 0.0010
[2019-03-23 11:01:59,863] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2177310: loss 0.0227
[2019-03-23 11:01:59,864] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2177310: learning rate 0.0010
[2019-03-23 11:02:00,528] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2177661: loss 0.0005
[2019-03-23 11:02:00,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2177663: learning rate 0.0010
[2019-03-23 11:02:00,619] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177715: loss 0.0001
[2019-03-23 11:02:00,622] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177715: learning rate 0.0010
[2019-03-23 11:02:00,637] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2177720: loss 0.0004
[2019-03-23 11:02:00,639] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2177720: learning rate 0.0010
[2019-03-23 11:02:01,069] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2177951: loss 0.0046
[2019-03-23 11:02:01,072] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2177951: learning rate 0.0010
[2019-03-23 11:02:01,156] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2177989: loss 0.0004
[2019-03-23 11:02:01,157] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2177989: learning rate 0.0010
[2019-03-23 11:02:01,685] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2178277: loss 0.0105
[2019-03-23 11:02:01,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2178277: learning rate 0.0010
[2019-03-23 11:02:02,025] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2178450: loss 0.0153
[2019-03-23 11:02:02,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2178450: learning rate 0.0010
[2019-03-23 11:02:05,129] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2180171: loss 0.0421
[2019-03-23 11:02:05,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2180171: learning rate 0.0010
[2019-03-23 11:02:07,851] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2181542: loss 0.0630
[2019-03-23 11:02:07,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2181544: learning rate 0.0010
[2019-03-23 11:02:09,914] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2182584: loss 0.0072
[2019-03-23 11:02:09,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2182584: learning rate 0.0010
[2019-03-23 11:02:10,182] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2182722: loss 0.0054
[2019-03-23 11:02:10,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2182723: learning rate 0.0010
[2019-03-23 11:02:11,315] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2183289: loss 0.0027
[2019-03-23 11:02:11,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2183289: learning rate 0.0010
[2019-03-23 11:02:14,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2184679: loss 0.0496
[2019-03-23 11:02:14,075] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2184679: learning rate 0.0010
[2019-03-23 11:02:14,180] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184733: loss 0.0357
[2019-03-23 11:02:14,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184733: learning rate 0.0010
[2019-03-23 11:02:14,601] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2184943: loss 0.0021
[2019-03-23 11:02:14,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2184943: learning rate 0.0010
[2019-03-23 11:02:15,138] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2185212: loss 0.0099
[2019-03-23 11:02:15,139] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2185212: learning rate 0.0010
[2019-03-23 11:02:16,089] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2185688: loss 0.0001
[2019-03-23 11:02:16,090] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2185688: learning rate 0.0010
[2019-03-23 11:02:16,188] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2185741: loss 0.0000
[2019-03-23 11:02:16,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2185741: learning rate 0.0010
[2019-03-23 11:02:16,273] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185779: loss 0.0001
[2019-03-23 11:02:16,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185781: learning rate 0.0010
[2019-03-23 11:02:16,531] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2185915: loss 0.0037
[2019-03-23 11:02:16,536] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2185915: learning rate 0.0010
[2019-03-23 11:02:16,635] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2185970: loss 0.0016
[2019-03-23 11:02:16,638] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2185970: learning rate 0.0010
[2019-03-23 11:02:17,294] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2186298: loss 0.0033
[2019-03-23 11:02:17,298] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2186300: learning rate 0.0010
[2019-03-23 11:02:17,690] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2186501: loss 0.0055
[2019-03-23 11:02:17,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2186502: learning rate 0.0010
[2019-03-23 11:02:20,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3033526e-12 1.0000000e+00 3.6519031e-18 5.2922245e-19 2.3017034e-21], sum to 1.0000
[2019-03-23 11:02:20,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6176
[2019-03-23 11:02:20,252] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.9, 97.0, 1.0, 2.0, 0.2030739216174529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220484.4257012011, 220484.4257012014, 72879.46908171753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2520000.0000, 
sim time next is 2520600.0000, 
raw observation next is [12.91666666666667, 97.5, 1.0, 2.0, 0.2711958564833274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294469.171716733, 294469.1717167327, 79554.21858117274], 
processed observation next is [1.0, 0.17391304347826086, 0.22348484848484862, 0.975, 1.0, 1.0, 0.08899482060415922, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1090626561913826, 0.10906265619138247, 0.19403467946627498], 
reward next is 0.8060, 
noisyNet noise sample is [array([2.839922], dtype=float32), 0.16717276]. 
=============================================
[2019-03-23 11:02:21,051] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2188191: loss 0.1252
[2019-03-23 11:02:21,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2188192: learning rate 0.0010
[2019-03-23 11:02:24,562] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2189972: loss 0.0026
[2019-03-23 11:02:24,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2189972: learning rate 0.0010
[2019-03-23 11:02:25,793] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2190581: loss 0.0190
[2019-03-23 11:02:25,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2190581: learning rate 0.0010
[2019-03-23 11:02:25,888] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2190633: loss 0.0178
[2019-03-23 11:02:25,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2190633: learning rate 0.0010
[2019-03-23 11:02:27,061] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2191227: loss 0.0096
[2019-03-23 11:02:27,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2191230: learning rate 0.0010
[2019-03-23 11:02:29,854] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2192630: loss 0.0083
[2019-03-23 11:02:29,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2192630: learning rate 0.0010
[2019-03-23 11:02:29,944] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192677: loss 0.0118
[2019-03-23 11:02:29,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192678: learning rate 0.0010
[2019-03-23 11:02:30,399] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2192899: loss 0.0000
[2019-03-23 11:02:30,404] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2192899: learning rate 0.0010
[2019-03-23 11:02:30,993] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2193204: loss 0.0049
[2019-03-23 11:02:30,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2193205: learning rate 0.0010
[2019-03-23 11:02:31,750] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2193587: loss 0.0027
[2019-03-23 11:02:31,753] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2193587: learning rate 0.0010
[2019-03-23 11:02:32,042] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2193733: loss 0.0005
[2019-03-23 11:02:32,045] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2193734: learning rate 0.0010
[2019-03-23 11:02:32,082] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2193750: loss 0.0007
[2019-03-23 11:02:32,085] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2193750: learning rate 0.0010
[2019-03-23 11:02:32,143] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193779: loss 0.0003
[2019-03-23 11:02:32,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193780: learning rate 0.0010
[2019-03-23 11:02:32,420] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2193918: loss 0.0016
[2019-03-23 11:02:32,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2193920: learning rate 0.0010
[2019-03-23 11:02:33,134] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2194268: loss 0.0045
[2019-03-23 11:02:33,135] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2194268: learning rate 0.0010
[2019-03-23 11:02:33,477] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2194439: loss 0.0001
[2019-03-23 11:02:33,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2194440: learning rate 0.0010
[2019-03-23 11:02:37,622] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2196521: loss 0.0114
[2019-03-23 11:02:37,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2196521: learning rate 0.0010
[2019-03-23 11:02:39,857] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4676472e-12 1.0000000e+00 1.1905211e-18 1.5283679e-18 3.2853006e-20], sum to 1.0000
[2019-03-23 11:02:39,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-23 11:02:39,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.448621279052476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 511132.3459370628, 511132.345937063, 133371.8451292893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2858400.0000, 
sim time next is 2859000.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.777255510165886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 83.30957069189823, 886064.1261484453, 886064.1261484456, 177550.8510867303], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.83, 1.0, 1.0, 0.7215693877073576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5477541418204536, 0.32817189857349827, 0.3281718985734984, 0.43305085630909834], 
reward next is 0.5669, 
noisyNet noise sample is [array([0.41268423], dtype=float32), 1.0683358]. 
=============================================
[2019-03-23 11:02:39,893] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.50993]
 [65.50993]
 [65.50993]
 [65.50993]
 [65.50993]], R is [[65.42178345]
 [65.44226837]
 [65.46304321]
 [65.48394775]
 [65.5046463 ]].
[2019-03-23 11:02:40,514] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2197965: loss 0.1794
[2019-03-23 11:02:40,516] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2197965: learning rate 0.0010
[2019-03-23 11:02:42,029] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2198725: loss 0.0460
[2019-03-23 11:02:42,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2198725: learning rate 0.0010
[2019-03-23 11:02:42,283] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2198858: loss 0.0476
[2019-03-23 11:02:42,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2198859: learning rate 0.0010
[2019-03-23 11:02:43,165] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2199298: loss 0.0227
[2019-03-23 11:02:43,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2199299: learning rate 0.0010
[2019-03-23 11:02:44,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8700395e-11 1.0000000e+00 5.5638339e-19 4.0653760e-18 4.8832220e-20], sum to 1.0000
[2019-03-23 11:02:44,451] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2682
[2019-03-23 11:02:44,456] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 85.0, 1.0, 2.0, 0.6772291068679657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 771163.4835082027, 771163.4835082025, 166562.6766363011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2965200.0000, 
sim time next is 2965800.0000, 
raw observation next is [23.83333333333333, 84.0, 1.0, 2.0, 0.6677288971226779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 760257.4359913166, 760257.4359913169, 165244.3629847116], 
processed observation next is [1.0, 0.30434782608695654, 0.7196969696969695, 0.84, 1.0, 1.0, 0.5846611214033474, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.28157682814493207, 0.2815768281449322, 0.4030350316700283], 
reward next is 0.5970, 
noisyNet noise sample is [array([0.30206272], dtype=float32), 0.049136516]. 
=============================================
[2019-03-23 11:02:44,573] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 11:02:44,574] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:02:44,574] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:44,575] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:02:44,576] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:02:44,576] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:02:44,575] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:02:44,578] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:44,579] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:44,579] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:44,577] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:02:44,600] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 11:02:44,628] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 11:02:44,629] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 11:02:44,630] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 11:02:44,711] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 11:02:50,309] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:02:50,310] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.85, 77.0, 1.0, 2.0, 0.6305567840615773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 690565.957566623, 690565.9575666226, 145663.6984486395]
[2019-03-23 11:02:50,311] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:02:50,314] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.8172252868544532
[2019-03-23 11:02:50,590] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:02:50,592] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [12.0, 76.0, 1.0, 2.0, 0.407040732724772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 61.18001451380767, 442091.996132585, 442091.9961325846, 78200.9542706201]
[2019-03-23 11:02:50,593] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:02:50,597] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.08177331945542066
[2019-03-23 11:03:07,569] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:03:07,570] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.0, 82.16666666666667, 1.0, 2.0, 0.4071086582970768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 461113.958542987, 461113.958542987, 126866.8738477158]
[2019-03-23 11:03:07,572] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:03:07,576] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.27162442053909897
[2019-03-23 11:03:21,790] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:03:21,792] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.76941522833334, 99.49063172499999, 1.0, 2.0, 0.3151343238513132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 347056.030352433, 347056.030352433, 118295.9725545403]
[2019-03-23 11:03:21,792] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:03:21,795] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.06253790044600205
[2019-03-23 11:03:49,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:03:49,085] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.23333333333333, 80.0, 1.0, 2.0, 0.3812245298967183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 427354.2263996874, 427354.2263996878, 126380.0126778542]
[2019-03-23 11:03:49,088] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:03:49,090] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.6892193574138779
[2019-03-23 11:03:50,877] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:03:50,879] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.1, 88.33333333333334, 1.0, 2.0, 0.3485825486869438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 384906.3470228852, 384906.3470228852, 121152.6147842237]
[2019-03-23 11:03:50,881] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:03:50,882] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.07668376168111501
[2019-03-23 11:03:54,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.5734057]
[2019-03-23 11:03:54,673] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.62609567666667, 38.06038538666667, 1.0, 2.0, 0.3615267744088425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 397870.8446940642, 397870.8446940639, 121657.2354813]
[2019-03-23 11:03:54,674] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:03:54,677] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.5621188e-11 1.0000000e+00 8.2851924e-18 3.5462239e-17 2.9215404e-19], sampled 0.7534374901405189
[2019-03-23 11:04:22,985] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:04:23,102] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:04:23,105] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:04:23,168] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:04:23,431] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:04:24,446] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2200000, evaluation results [2200000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:04:25,777] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2200703: loss 0.1139
[2019-03-23 11:04:25,778] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2200703: learning rate 0.0010
[2019-03-23 11:04:25,893] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200764: loss 0.1174
[2019-03-23 11:04:25,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200764: learning rate 0.0010
[2019-03-23 11:04:26,087] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2200864: loss 0.2115
[2019-03-23 11:04:26,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2200865: learning rate 0.0010
[2019-03-23 11:04:26,691] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2201179: loss 0.1318
[2019-03-23 11:04:26,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2201179: learning rate 0.0010
[2019-03-23 11:04:27,562] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2201636: loss 0.0629
[2019-03-23 11:04:27,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2201638: learning rate 0.0010
[2019-03-23 11:04:27,816] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2201768: loss 0.0056
[2019-03-23 11:04:27,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2201768: learning rate 0.0010
[2019-03-23 11:04:27,858] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2201791: loss 0.0040
[2019-03-23 11:04:27,861] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2201791: loss 0.0047
[2019-03-23 11:04:27,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2201791: learning rate 0.0010
[2019-03-23 11:04:27,863] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2201792: learning rate 0.0010
[2019-03-23 11:04:27,868] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2201795: loss 0.0007
[2019-03-23 11:04:27,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2201796: learning rate 0.0010
[2019-03-23 11:04:28,685] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2202222: loss 0.0001
[2019-03-23 11:04:28,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2202222: learning rate 0.0010
[2019-03-23 11:04:29,158] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2202473: loss 0.0003
[2019-03-23 11:04:29,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2202474: learning rate 0.0010
[2019-03-23 11:04:31,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9449562e-11 1.0000000e+00 1.2538880e-16 1.7438156e-16 1.6021611e-19], sum to 1.0000
[2019-03-23 11:04:31,259] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2286
[2019-03-23 11:04:31,263] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 88.83333333333334, 1.0, 2.0, 0.5166601127037479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 588883.5380972439, 588883.5380972441, 144515.444498262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3111000.0000, 
sim time next is 3111600.0000, 
raw observation next is [22.66666666666667, 88.66666666666667, 1.0, 2.0, 0.5107317337529086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 582413.0656062365, 582413.0656062365, 143431.4115721563], 
processed observation next is [1.0, 0.0, 0.6666666666666669, 0.8866666666666667, 1.0, 1.0, 0.3884146671911357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21570854281712462, 0.21570854281712462, 0.34983271115160075], 
reward next is 0.6502, 
noisyNet noise sample is [array([1.3238018], dtype=float32), 0.92381024]. 
=============================================
[2019-03-23 11:04:32,762] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2204402: loss 0.1578
[2019-03-23 11:04:32,765] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2204402: learning rate 0.0010
[2019-03-23 11:04:35,780] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2205973: loss 0.0011
[2019-03-23 11:04:35,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2205973: learning rate 0.0010
[2019-03-23 11:04:36,920] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2206537: loss 0.0705
[2019-03-23 11:04:36,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2206537: learning rate 0.0010
[2019-03-23 11:04:37,275] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2206720: loss 0.0735
[2019-03-23 11:04:37,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2206720: learning rate 0.0010
[2019-03-23 11:04:38,188] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2207181: loss 0.0549
[2019-03-23 11:04:38,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2207182: learning rate 0.0010
[2019-03-23 11:04:41,211] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208702: loss 0.0246
[2019-03-23 11:04:41,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208703: learning rate 0.0010
[2019-03-23 11:04:41,329] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2208760: loss 0.0091
[2019-03-23 11:04:41,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2208760: learning rate 0.0010
[2019-03-23 11:04:41,564] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2208876: loss 0.0362
[2019-03-23 11:04:41,568] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2208877: learning rate 0.0010
[2019-03-23 11:04:42,208] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2209199: loss 0.0205
[2019-03-23 11:04:42,212] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2209201: learning rate 0.0010
[2019-03-23 11:04:42,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1108020e-14 1.0000000e+00 8.1411213e-22 1.8970827e-20 2.6887358e-22], sum to 1.0000
[2019-03-23 11:04:42,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7560
[2019-03-23 11:04:42,442] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.0, 82.0, 1.0, 2.0, 0.2455857330357324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 266653.6315709251, 266653.6315709254, 83550.41565261896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3297000.0000, 
sim time next is 3297600.0000, 
raw observation next is [16.0, 82.0, 1.0, 2.0, 0.2461721677748622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 267290.5493621042, 267290.5493621039, 83612.76070513342], 
processed observation next is [0.0, 0.17391304347826086, 0.36363636363636365, 0.82, 1.0, 1.0, 0.057715209718577735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09899649976374231, 0.0989964997637422, 0.20393356269544738], 
reward next is 0.7961, 
noisyNet noise sample is [array([-0.73166263], dtype=float32), 0.28942648]. 
=============================================
[2019-03-23 11:04:43,052] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209626: loss 0.0410
[2019-03-23 11:04:43,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209626: learning rate 0.0010
[2019-03-23 11:04:43,175] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2209687: loss 0.0304
[2019-03-23 11:04:43,177] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2209687: learning rate 0.0010
[2019-03-23 11:04:43,285] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2209739: loss 0.0370
[2019-03-23 11:04:43,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2209739: learning rate 0.0010
[2019-03-23 11:04:43,318] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2209756: loss 0.0373
[2019-03-23 11:04:43,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2209757: learning rate 0.0010
[2019-03-23 11:04:43,383] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2209789: loss 0.0280
[2019-03-23 11:04:43,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2209790: learning rate 0.0010
[2019-03-23 11:04:44,165] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2210181: loss 0.0661
[2019-03-23 11:04:44,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2210181: learning rate 0.0010
[2019-03-23 11:04:44,699] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2210448: loss 0.0567
[2019-03-23 11:04:44,701] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2210448: learning rate 0.0010
[2019-03-23 11:04:45,010] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.9083526e-14 1.0000000e+00 1.9736766e-21 1.5306186e-20 3.6340678e-21], sum to 1.0000
[2019-03-23 11:04:45,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5211
[2019-03-23 11:04:45,022] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 62.0, 1.0, 2.0, 0.3388404739947677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 372731.1374586791, 372731.1374586794, 115556.7777214553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [21.33333333333334, 62.66666666666667, 1.0, 2.0, 0.3373535401749044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 370687.0220467824, 370687.0220467827, 115295.0456212512], 
processed observation next is [1.0, 0.7391304347826086, 0.6060606060606063, 0.6266666666666667, 1.0, 1.0, 0.17169192521863044, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13729148964695645, 0.13729148964695656, 0.2812074283445151], 
reward next is 0.7188, 
noisyNet noise sample is [array([-0.326008], dtype=float32), -1.4067357]. 
=============================================
[2019-03-23 11:04:49,039] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2212632: loss 0.0222
[2019-03-23 11:04:49,042] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2212632: learning rate 0.0010
[2019-03-23 11:04:49,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2288628e-11 1.0000000e+00 2.4059857e-16 1.9979068e-16 3.9043561e-19], sum to 1.0000
[2019-03-23 11:04:49,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-23 11:04:49,081] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5038814632932073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 574621.4603490036, 574621.4603490036, 142583.8513035755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3456000.0000, 
sim time next is 3456600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5025649793216812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 573140.0239018808, 573140.0239018812, 142396.2467002342], 
processed observation next is [1.0, 0.0, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.3782062241521015, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21227408292662253, 0.21227408292662267, 0.347307918781059], 
reward next is 0.6527, 
noisyNet noise sample is [array([0.03196124], dtype=float32), -0.7334016]. 
=============================================
[2019-03-23 11:04:50,579] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9264304e-12 1.0000000e+00 6.0272437e-18 4.1726729e-18 4.7795921e-20], sum to 1.0000
[2019-03-23 11:04:50,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7896
[2019-03-23 11:04:50,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1200880.370065485 W.
[2019-03-23 11:04:50,606] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.9961884645359882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.110314576998496, 6.9112, 77.32806835967199, 1200880.370065485, 1136212.358454988, 219370.5767182373], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5271150060831382, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9611956836938044, 6.933849482949455, 6.9112, 77.32828823012531, 1148670.18805616, 1141314.115923889, 262707.543262011], 
processed observation next is [1.0, 0.391304347826087, 0.6515151515151518, 0.9233333333333335, 1.0, 1.0, 0.4088937576039227, 0.0, 1.0, -0.25, 1.0, 0.5, 0.9445652624197207, 0.0022649482949455013, 0.0, 0.508427660905665, 0.425433402983763, 0.4227089318236626, 0.6407501055171001], 
reward next is 0.2460, 
noisyNet noise sample is [array([-0.43857032], dtype=float32), -1.5265499]. 
=============================================
[2019-03-23 11:04:51,676] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2213955: loss 0.2927
[2019-03-23 11:04:51,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2213956: learning rate 0.0010
[2019-03-23 11:04:52,980] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2214603: loss 0.0693
[2019-03-23 11:04:52,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2214603: learning rate 0.0010
[2019-03-23 11:04:53,612] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2214918: loss 0.0672
[2019-03-23 11:04:53,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2214918: learning rate 0.0010
[2019-03-23 11:04:54,284] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2215258: loss 0.0158
[2019-03-23 11:04:54,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2215258: learning rate 0.0010
[2019-03-23 11:04:57,319] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216774: loss 0.0481
[2019-03-23 11:04:57,323] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216775: learning rate 0.0010
[2019-03-23 11:04:57,514] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2216870: loss 0.0851
[2019-03-23 11:04:57,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2216871: learning rate 0.0010
[2019-03-23 11:04:57,580] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2216908: loss 0.0827
[2019-03-23 11:04:57,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2216908: learning rate 0.0010
[2019-03-23 11:04:58,156] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2217197: loss 0.0628
[2019-03-23 11:04:58,159] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2217198: learning rate 0.0010
[2019-03-23 11:04:58,885] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217564: loss 0.0253
[2019-03-23 11:04:58,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217564: learning rate 0.0010
[2019-03-23 11:04:59,202] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2217725: loss 0.0051
[2019-03-23 11:04:59,205] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2217726: learning rate 0.0010
[2019-03-23 11:04:59,217] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2217733: loss 0.0048
[2019-03-23 11:04:59,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2217733: learning rate 0.0010
[2019-03-23 11:04:59,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2217782: loss 0.0001
[2019-03-23 11:04:59,312] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2217782: learning rate 0.0010
[2019-03-23 11:04:59,347] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2217799: loss 0.0000
[2019-03-23 11:04:59,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2217799: learning rate 0.0010
[2019-03-23 11:04:59,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4840268e-13 1.0000000e+00 6.0977965e-20 9.7499820e-19 8.4754751e-22], sum to 1.0000
[2019-03-23 11:04:59,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2219
[2019-03-23 11:04:59,472] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.4904825884409207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559657.7154331133, 559657.7154331133, 140215.1722066577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [23.0, 83.0, 1.0, 2.0, 0.491958692099859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561359.2457679696, 561359.2457679696, 140281.0212448875], 
processed observation next is [1.0, 0.8695652173913043, 0.6818181818181818, 0.83, 1.0, 1.0, 0.3649483651248237, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20791083176591468, 0.20791083176591468, 0.34214883230460363], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.325], dtype=float32), 0.3195843]. 
=============================================
[2019-03-23 11:05:00,207] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2218230: loss 0.0005
[2019-03-23 11:05:00,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2218230: learning rate 0.0010
[2019-03-23 11:05:00,885] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2218564: loss 0.0048
[2019-03-23 11:05:00,886] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2218564: learning rate 0.0010
[2019-03-23 11:05:04,699] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2220464: loss 0.1419
[2019-03-23 11:05:04,701] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2220464: learning rate 0.0010
[2019-03-23 11:05:07,057] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2221658: loss 0.0234
[2019-03-23 11:05:07,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2221658: learning rate 0.0010
[2019-03-23 11:05:08,669] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2222472: loss 0.0123
[2019-03-23 11:05:08,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2222474: learning rate 0.0010
[2019-03-23 11:05:08,809] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2045825e-10 1.0000000e+00 4.5436878e-18 1.7151428e-17 4.0423016e-19], sum to 1.0000
[2019-03-23 11:05:08,815] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6991
[2019-03-23 11:05:08,817] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3443582258916563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379023.5013814045, 379023.5013814045, 116052.0181713404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3789000.0000, 
sim time next is 3789600.0000, 
raw observation next is [18.0, 88.0, 1.0, 2.0, 0.3421249238091587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 376559.293360077, 376559.293360077, 115882.0099887087], 
processed observation next is [1.0, 0.8695652173913043, 0.45454545454545453, 0.88, 1.0, 1.0, 0.17765615476144836, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13946640494817666, 0.13946640494817666, 0.28263904875294804], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.6455405], dtype=float32), 1.6045173]. 
=============================================
[2019-03-23 11:05:09,367] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2222822: loss 0.0304
[2019-03-23 11:05:09,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2222823: learning rate 0.0010
[2019-03-23 11:05:09,963] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2223125: loss 0.0654
[2019-03-23 11:05:09,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2223126: learning rate 0.0010
[2019-03-23 11:05:10,374] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3218723e-13 1.0000000e+00 1.9279868e-20 2.8387164e-19 1.3213883e-22], sum to 1.0000
[2019-03-23 11:05:10,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8672
[2019-03-23 11:05:10,386] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 44.83333333333334, 1.0, 2.0, 0.3510346717339876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 392022.1720591531, 392022.1720591531, 118840.7449466965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3942600.0000, 
sim time next is 3943200.0000, 
raw observation next is [25.66666666666667, 44.66666666666667, 1.0, 2.0, 0.3460391939948022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 385580.2463318989, 385580.2463318992, 118059.2147356516], 
processed observation next is [0.0, 0.6521739130434783, 0.8030303030303032, 0.4466666666666667, 1.0, 1.0, 0.18254899249350273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14280749864144404, 0.14280749864144415, 0.2879493042332966], 
reward next is 0.7121, 
noisyNet noise sample is [array([-0.87518936], dtype=float32), -0.6370594]. 
=============================================
[2019-03-23 11:05:11,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9720774e-12 1.0000000e+00 3.5060691e-19 3.9858624e-18 3.9687423e-21], sum to 1.0000
[2019-03-23 11:05:11,182] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3843
[2019-03-23 11:05:11,192] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 59.0, 1.0, 2.0, 0.3464611877367289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 386163.333558778, 386163.333558778, 118142.2836998301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3857400.0000, 
sim time next is 3858000.0000, 
raw observation next is [23.0, 59.66666666666667, 1.0, 2.0, 0.3480728739630552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388504.1827492064, 388504.1827492064, 118509.7518556542], 
processed observation next is [0.0, 0.6521739130434783, 0.6818181818181818, 0.5966666666666667, 1.0, 1.0, 0.18509109245381897, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1438904380552616, 0.1438904380552616, 0.28904817525769316], 
reward next is 0.7110, 
noisyNet noise sample is [array([-0.25831333], dtype=float32), 0.47266072]. 
=============================================
[2019-03-23 11:05:11,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.874146]
 [68.874146]
 [68.874146]
 [68.874146]
 [68.874146]], R is [[68.8963623 ]
 [68.91924286]
 [68.94293976]
 [68.96764374]
 [68.99294281]].
[2019-03-23 11:05:11,316] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2195611e-12 1.0000000e+00 5.5612639e-20 3.8495305e-20 1.4959882e-21], sum to 1.0000
[2019-03-23 11:05:11,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2478
[2019-03-23 11:05:11,328] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 73.0, 1.0, 2.0, 0.3230282817147332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 355871.9209462374, 355871.9209462377, 114598.9586793705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3837600.0000, 
sim time next is 3838200.0000, 
raw observation next is [19.83333333333334, 73.0, 1.0, 2.0, 0.3216106333222846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 353689.4112866067, 353689.411286607, 114258.4435694094], 
processed observation next is [0.0, 0.43478260869565216, 0.5378787878787882, 0.73, 1.0, 1.0, 0.15201329165285576, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13099607825429876, 0.13099607825429888, 0.2786791306570961], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.69547075], dtype=float32), -0.9735405]. 
=============================================
[2019-03-23 11:05:11,815] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8163347e-13 1.0000000e+00 1.1650564e-18 7.2421999e-19 2.4792698e-20], sum to 1.0000
[2019-03-23 11:05:11,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5136
[2019-03-23 11:05:11,823] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 100.0, 1.0, 2.0, 0.3411544369863719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 377563.3064602307, 377563.3064602307, 116606.0070143053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4049400.0000, 
sim time next is 4050000.0000, 
raw observation next is [17.0, 100.0, 1.0, 2.0, 0.3425573014851521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 379120.2932389239, 379120.2932389242, 116715.0016146676], 
processed observation next is [1.0, 0.9130434782608695, 0.4090909090909091, 1.0, 1.0, 1.0, 0.17819662685644014, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14041492342182366, 0.14041492342182377, 0.28467073564553075], 
reward next is 0.7153, 
noisyNet noise sample is [array([-0.48200008], dtype=float32), 1.5617393]. 
=============================================
[2019-03-23 11:05:11,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1755288e-12 1.0000000e+00 6.7339897e-18 6.2287982e-19 8.1045307e-21], sum to 1.0000
[2019-03-23 11:05:11,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2954
[2019-03-23 11:05:11,855] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 44.0, 1.0, 2.0, 0.3289693334187769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 362804.6521093491, 362804.6521093491, 115182.6566630262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3945600.0000, 
sim time next is 3946200.0000, 
raw observation next is [25.0, 44.50000000000001, 1.0, 2.0, 0.3274951280033008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 361288.362633804, 361288.362633804, 115116.7959578276], 
processed observation next is [0.0, 0.6956521739130435, 0.7727272727272727, 0.44500000000000006, 1.0, 1.0, 0.15936891000412595, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13381050467918665, 0.13381050467918665, 0.28077267306787224], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.7531709], dtype=float32), 0.0044267206]. 
=============================================
[2019-03-23 11:05:11,860] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.13725]
 [69.13725]
 [69.13725]
 [69.13725]
 [69.13725]], R is [[69.16120911]
 [69.18518829]
 [69.20907593]
 [69.2326355 ]
 [69.25583649]].
[2019-03-23 11:05:13,160] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224726: loss 0.0319
[2019-03-23 11:05:13,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224727: learning rate 0.0010
[2019-03-23 11:05:13,387] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2224835: loss 0.0031
[2019-03-23 11:05:13,389] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2224836: learning rate 0.0010
[2019-03-23 11:05:13,503] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2224895: loss 0.0112
[2019-03-23 11:05:13,505] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2224897: learning rate 0.0010
[2019-03-23 11:05:13,705] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 11:05:13,707] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:05:13,707] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:05:13,707] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:05:13,707] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:05:13,708] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:05:13,710] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:05:13,708] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:05:13,710] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:05:13,711] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:05:13,714] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:05:13,732] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 11:05:13,755] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 11:05:13,780] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 11:05:13,813] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 11:05:13,813] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 11:05:36,311] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.67002416]
[2019-03-23 11:05:36,313] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.0, 45.0, 1.0, 2.0, 0.5866351107130354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 650214.4354378611, 650214.4354378607, 143706.7808850561]
[2019-03-23 11:05:36,314] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:05:36,316] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0905315e-13 1.0000000e+00 5.6249296e-20 2.2586854e-19 1.2994099e-21], sampled 0.09220873747249092
[2019-03-23 11:05:52,156] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.67002416]
[2019-03-23 11:05:52,157] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.90163101, 98.64948903000001, 1.0, 2.0, 0.4302532692533643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 489747.0402199085, 489747.0402199085, 135329.0129579034]
[2019-03-23 11:05:52,158] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:05:52,162] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.0905315e-13 1.0000000e+00 5.6249296e-20 2.2586854e-19 1.2994099e-21], sampled 0.2394685319703641
[2019-03-23 11:06:03,973] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.67002416]
[2019-03-23 11:06:03,974] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.78361972333333, 100.0, 1.0, 2.0, 0.4181073492823849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 473674.2418518657, 473674.2418518653, 132304.7133885465]
[2019-03-23 11:06:03,975] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:06:03,978] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [7.0905315e-13 1.0000000e+00 5.6249296e-20 2.2586854e-19 1.2994099e-21], sampled 0.9098505691315434
[2019-03-23 11:06:05,857] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.67002416]
[2019-03-23 11:06:05,858] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.03333333333333, 85.33333333333333, 1.0, 2.0, 0.3551138715233869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 395154.9239089296, 395154.9239089296, 122872.4421650819]
[2019-03-23 11:06:05,858] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:06:05,861] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [7.0905315e-13 1.0000000e+00 5.6249296e-20 2.2586854e-19 1.2994099e-21], sampled 0.785470583745731
[2019-03-23 11:06:22,525] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.67002416]
[2019-03-23 11:06:22,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.425823553951088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 485133.3766844978, 485133.3766844981, 131022.1868437692]
[2019-03-23 11:06:22,528] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:06:22,530] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [7.0905315e-13 1.0000000e+00 5.6249296e-20 2.2586854e-19 1.2994099e-21], sampled 0.7710344983472157
[2019-03-23 11:06:51,799] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:06:51,810] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:06:52,160] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:06:52,203] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:06:52,229] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:06:53,244] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2225000, evaluation results [2225000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:06:53,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2714610e-11 1.0000000e+00 1.4690771e-18 2.9116383e-19 2.7205039e-21], sum to 1.0000
[2019-03-23 11:06:53,464] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1212
[2019-03-23 11:06:53,468] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 57.0, 1.0, 2.0, 0.3140621051372298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 343413.4003974305, 343413.4003974305, 112983.1704336908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3869400.0000, 
sim time next is 3870000.0000, 
raw observation next is [22.0, 57.0, 1.0, 2.0, 0.3136099622800332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 342919.8289870513, 342919.8289870513, 112951.8282844786], 
processed observation next is [0.0, 0.8260869565217391, 0.6363636363636364, 0.57, 1.0, 1.0, 0.14201245285004147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12700734406927827, 0.12700734406927827, 0.2754922641084844], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.32389054], dtype=float32), 1.0998389]. 
=============================================
[2019-03-23 11:06:53,499] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.965385]
 [72.965385]
 [72.965385]
 [72.965385]
 [72.965385]], R is [[72.96024323]
 [72.95507812]
 [72.94993591]
 [72.9447937 ]
 [72.93942261]].
[2019-03-23 11:06:53,593] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2225192: loss 0.0104
[2019-03-23 11:06:53,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2225192: learning rate 0.0010
[2019-03-23 11:06:53,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6992245e-12 1.0000000e+00 9.5980538e-19 1.6074941e-18 4.1914914e-21], sum to 1.0000
[2019-03-23 11:06:53,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1602
[2019-03-23 11:06:53,692] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2664834248552358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 289350.80943638, 289350.80943638, 94479.1860622763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3913200.0000, 
sim time next is 3913800.0000, 
raw observation next is [17.5, 80.50000000000001, 1.0, 2.0, 0.2710923548194047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 294356.753801555, 294356.7538015553, 99476.44763157699], 
processed observation next is [0.0, 0.30434782608695654, 0.4318181818181818, 0.8050000000000002, 1.0, 1.0, 0.08886544352425585, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10902101992650186, 0.10902101992650197, 0.24262548202823656], 
reward next is 0.7574, 
noisyNet noise sample is [array([-0.21271574], dtype=float32), 0.35593426]. 
=============================================
[2019-03-23 11:06:54,217] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2225539: loss 0.0248
[2019-03-23 11:06:54,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2225539: learning rate 0.0010
[2019-03-23 11:06:55,385] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2225803: loss 0.0280
[2019-03-23 11:06:55,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2225803: learning rate 0.0010
[2019-03-23 11:06:55,422] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2225808: loss 0.0310
[2019-03-23 11:06:55,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2225808: learning rate 0.0010
[2019-03-23 11:06:55,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2225815: loss 0.0317
[2019-03-23 11:06:55,451] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2225815: learning rate 0.0010
[2019-03-23 11:06:55,646] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2225892: loss 0.0486
[2019-03-23 11:06:55,647] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2225892: learning rate 0.0010
[2019-03-23 11:06:56,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2226375: loss 0.0344
[2019-03-23 11:06:56,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2226375: learning rate 0.0010
[2019-03-23 11:06:56,935] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2226618: loss 0.0185
[2019-03-23 11:06:56,941] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2226619: learning rate 0.0010
[2019-03-23 11:07:00,394] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2228465: loss 0.0005
[2019-03-23 11:07:00,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2228466: learning rate 0.0010
[2019-03-23 11:07:02,579] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2229650: loss 0.0017
[2019-03-23 11:07:02,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2229650: learning rate 0.0010
[2019-03-23 11:07:04,024] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2230466: loss 0.0058
[2019-03-23 11:07:04,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2230466: learning rate 0.0010
[2019-03-23 11:07:04,795] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2230853: loss 0.0073
[2019-03-23 11:07:04,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2230853: learning rate 0.0010
[2019-03-23 11:07:05,492] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2231201: loss 0.0006
[2019-03-23 11:07:05,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2231201: learning rate 0.0010
[2019-03-23 11:07:05,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5176068e-11 1.0000000e+00 3.1258791e-18 9.8461234e-17 5.2536448e-19], sum to 1.0000
[2019-03-23 11:07:05,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-23 11:07:05,803] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.8725210744686109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 992494.4751568334, 992494.4751568334, 188027.1981311093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4121400.0000, 
sim time next is 4122000.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.8698653081387789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 989463.6266954651, 989463.6266954651, 187593.9173650323], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.78, 1.0, 1.0, 0.8373316351734735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3664680098872093, 0.3664680098872093, 0.45754613991471293], 
reward next is 0.5425, 
noisyNet noise sample is [array([1.4558365], dtype=float32), -0.16910453]. 
=============================================
[2019-03-23 11:07:05,822] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.647385]
 [69.647385]
 [69.647385]
 [69.647385]
 [69.647385]], R is [[69.49337769]
 [69.33984375]
 [69.18531799]
 [69.03598785]
 [68.89640045]].
[2019-03-23 11:07:08,283] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232606: loss 0.0000
[2019-03-23 11:07:08,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232609: learning rate 0.0010
[2019-03-23 11:07:08,701] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2232820: loss 0.0024
[2019-03-23 11:07:08,702] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2232820: learning rate 0.0010
[2019-03-23 11:07:09,097] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2233021: loss 0.0103
[2019-03-23 11:07:09,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2233021: learning rate 0.0010
[2019-03-23 11:07:09,203] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2233076: loss 0.0133
[2019-03-23 11:07:09,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2233076: learning rate 0.0010
[2019-03-23 11:07:09,813] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2233383: loss 0.0051
[2019-03-23 11:07:09,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2233383: learning rate 0.0010
[2019-03-23 11:07:10,499] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2233732: loss 0.0028
[2019-03-23 11:07:10,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2233732: learning rate 0.0010
[2019-03-23 11:07:10,519] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2233740: loss 0.0006
[2019-03-23 11:07:10,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2233740: learning rate 0.0010
[2019-03-23 11:07:10,543] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2233753: loss 0.0000
[2019-03-23 11:07:10,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2233754: learning rate 0.0010
[2019-03-23 11:07:10,755] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2233863: loss 0.0004
[2019-03-23 11:07:10,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2233863: learning rate 0.0010
[2019-03-23 11:07:11,647] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2234310: loss 0.0001
[2019-03-23 11:07:11,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2234311: learning rate 0.0010
[2019-03-23 11:07:12,328] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2234654: loss 0.0000
[2019-03-23 11:07:12,331] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2234656: learning rate 0.0010
[2019-03-23 11:07:16,102] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2236534: loss 0.0006
[2019-03-23 11:07:16,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2236534: learning rate 0.0010
[2019-03-23 11:07:16,403] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3134978e-13 1.0000000e+00 1.0852716e-20 5.6492962e-19 4.3818818e-22], sum to 1.0000
[2019-03-23 11:07:16,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0415
[2019-03-23 11:07:16,415] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 100.0, 1.0, 2.0, 0.4331420094977048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 493252.2572937438, 493252.2572937438, 131496.9970689773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4517400.0000, 
sim time next is 4518000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4389476294837914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500178.801262375, 500178.801262375, 132468.909252541], 
processed observation next is [0.0, 0.30434782608695654, 0.5454545454545454, 1.0, 1.0, 1.0, 0.2986845368547392, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1852514078749537, 0.1852514078749537, 0.32309490061595364], 
reward next is 0.6769, 
noisyNet noise sample is [array([-0.16680542], dtype=float32), -1.6504966]. 
=============================================
[2019-03-23 11:07:16,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.496414]
 [68.496414]
 [68.496414]
 [68.496414]
 [68.496414]], R is [[68.48834991]
 [68.48274231]
 [68.47945404]
 [68.47833252]
 [68.47919464]].
[2019-03-23 11:07:18,246] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2237619: loss -60.1271
[2019-03-23 11:07:18,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2237619: learning rate 0.0010
[2019-03-23 11:07:19,849] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2238430: loss 0.0120
[2019-03-23 11:07:19,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2238431: learning rate 0.0010
[2019-03-23 11:07:20,681] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2238844: loss 0.0010
[2019-03-23 11:07:20,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2238845: learning rate 0.0010
[2019-03-23 11:07:21,388] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2239196: loss 0.0003
[2019-03-23 11:07:21,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2239196: learning rate 0.0010
[2019-03-23 11:07:24,198] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240618: loss 0.0036
[2019-03-23 11:07:24,201] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240619: learning rate 0.0010
[2019-03-23 11:07:24,771] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2240910: loss 0.0017
[2019-03-23 11:07:24,775] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2240911: learning rate 0.0010
[2019-03-23 11:07:24,937] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2240997: loss 0.0003
[2019-03-23 11:07:24,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2240997: learning rate 0.0010
[2019-03-23 11:07:25,235] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2241132: loss 0.0017
[2019-03-23 11:07:25,238] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2241133: learning rate 0.0010
[2019-03-23 11:07:25,803] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2241424: loss 0.0007
[2019-03-23 11:07:25,810] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2241425: learning rate 0.0010
[2019-03-23 11:07:26,467] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2241754: loss 0.0069
[2019-03-23 11:07:26,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2241754: learning rate 0.0010
[2019-03-23 11:07:26,480] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2241758: loss 0.0070
[2019-03-23 11:07:26,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2241758: learning rate 0.0010
[2019-03-23 11:07:26,520] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2241776: loss 0.0045
[2019-03-23 11:07:26,523] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2241776: learning rate 0.0010
[2019-03-23 11:07:26,679] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2241860: loss 0.0002
[2019-03-23 11:07:26,681] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2241860: learning rate 0.0010
[2019-03-23 11:07:27,330] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8959520e-11 1.0000000e+00 4.6362390e-18 2.9309073e-18 2.2187533e-19], sum to 1.0000
[2019-03-23 11:07:27,338] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0582
[2019-03-23 11:07:27,345] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 96.0, 1.0, 2.0, 0.4225839350093858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 479813.9189849602, 479813.9189849599, 129152.0604172869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4504800.0000, 
sim time next is 4505400.0000, 
raw observation next is [19.5, 97.0, 1.0, 2.0, 0.4204855361847976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 477269.9954947439, 477269.9954947442, 128826.6506510593], 
processed observation next is [0.0, 0.13043478260869565, 0.5227272727272727, 0.97, 1.0, 1.0, 0.275606920230997, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1767666649980533, 0.1767666649980534, 0.31421134305136417], 
reward next is 0.6858, 
noisyNet noise sample is [array([0.18762879], dtype=float32), -2.038931]. 
=============================================
[2019-03-23 11:07:27,705] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2242376: loss 0.0002
[2019-03-23 11:07:27,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2242377: learning rate 0.0010
[2019-03-23 11:07:28,408] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2242725: loss 0.0029
[2019-03-23 11:07:28,410] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2242727: learning rate 0.0010
[2019-03-23 11:07:31,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5198043e-14 1.0000000e+00 9.3464543e-22 1.0458557e-20 1.3730047e-22], sum to 1.0000
[2019-03-23 11:07:31,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5299
[2019-03-23 11:07:31,946] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 51.0, 1.0, 2.0, 0.3170894254169361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 344761.5396814408, 344761.5396814408, 112505.0360155211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4645200.0000, 
sim time next is 4645800.0000, 
raw observation next is [22.5, 51.5, 1.0, 2.0, 0.3132202687437114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 340115.9652048797, 340115.9652048797, 112087.8381820049], 
processed observation next is [1.0, 0.782608695652174, 0.6590909090909091, 0.515, 1.0, 1.0, 0.14152533592963923, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12596887600180728, 0.12596887600180728, 0.2733849711756217], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.08907467], dtype=float32), -1.4319783]. 
=============================================
[2019-03-23 11:07:32,033] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2244558: loss -72.1435
[2019-03-23 11:07:32,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2244559: learning rate 0.0010
[2019-03-23 11:07:34,029] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2245560: loss 0.0286
[2019-03-23 11:07:34,031] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2245560: learning rate 0.0010
[2019-03-23 11:07:35,798] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2246460: loss -49.4881
[2019-03-23 11:07:35,801] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2246461: learning rate 0.0010
[2019-03-23 11:07:36,671] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2246888: loss -61.5064
[2019-03-23 11:07:36,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2246889: learning rate 0.0010
[2019-03-23 11:07:37,467] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2247290: loss -39.2809
[2019-03-23 11:07:37,470] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2247290: learning rate 0.0010
[2019-03-23 11:07:40,133] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248631: loss -35.5277
[2019-03-23 11:07:40,136] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248631: learning rate 0.0010
[2019-03-23 11:07:40,818] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2248977: loss -52.5354
[2019-03-23 11:07:40,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2248977: learning rate 0.0010
[2019-03-23 11:07:40,823] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2248977: loss -48.7328
[2019-03-23 11:07:40,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2248977: learning rate 0.0010
[2019-03-23 11:07:41,080] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2249107: loss -33.8249
[2019-03-23 11:07:41,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2249107: learning rate 0.0010
[2019-03-23 11:07:41,654] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2249395: loss -33.0364
[2019-03-23 11:07:41,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2249395: learning rate 0.0010
[2019-03-23 11:07:42,274] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2249707: loss -27.6163
[2019-03-23 11:07:42,278] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2249707: learning rate 0.0010
[2019-03-23 11:07:42,440] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2249788: loss -37.5313
[2019-03-23 11:07:42,445] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2249790: learning rate 0.0010
[2019-03-23 11:07:42,512] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2249820: loss -53.8910
[2019-03-23 11:07:42,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2249820: learning rate 0.0010
[2019-03-23 11:07:42,710] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2249921: loss -65.7940
[2019-03-23 11:07:42,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2249921: learning rate 0.0010
[2019-03-23 11:07:42,871] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 11:07:42,872] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2372347e-12 1.0000000e+00 9.7084095e-20 7.4617275e-18 9.9590890e-21], sum to 1.0000
[2019-03-23 11:07:42,872] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:07:42,873] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:07:42,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:07:42,875] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:42,875] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:07:42,875] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:42,876] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:07:42,876] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:42,878] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:42,882] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1456
[2019-03-23 11:07:42,882] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:07:42,887] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.696145695574248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 794429.1991245543, 794429.1991245543, 167179.0051708645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4798800.0000, 
sim time next is 4799400.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.7399669595639449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 844390.7968992114, 844390.7968992116, 173929.9143098838], 
processed observation next is [1.0, 0.5652173913043478, 0.5984848484848487, 0.9900000000000001, 1.0, 1.0, 0.6749586994549311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3127373321848931, 0.3127373321848932, 0.4242193031948386], 
reward next is 0.5758, 
noisyNet noise sample is [array([-0.7108221], dtype=float32), -0.23464452]. 
=============================================
[2019-03-23 11:07:42,903] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 11:07:42,934] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 11:07:42,956] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 11:07:42,958] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 11:07:43,004] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 11:07:54,782] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:07:54,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [27.05, 42.0, 1.0, 2.0, 0.3610564227202052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 405291.4124207843, 405291.4124207843, 124945.8999732511]
[2019-03-23 11:07:54,783] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:07:54,787] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.14393487797048665
[2019-03-23 11:08:15,270] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:08:15,272] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [13.66666666666667, 78.83333333333334, 1.0, 2.0, 0.2266486949265369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 246086.8527503014, 246086.8527503014, 72733.94145985864]
[2019-03-23 11:08:15,273] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:08:15,277] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.15028970850093015
[2019-03-23 11:08:19,998] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:08:19,999] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.78987834333333, 85.01587993999999, 1.0, 2.0, 0.4121976341561075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 467376.5186549926, 467376.5186549926, 132016.3249505963]
[2019-03-23 11:08:20,000] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:08:20,004] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.4192651866435827
[2019-03-23 11:08:54,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:08:54,964] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [23.66666666666667, 75.33333333333333, 1.0, 2.0, 0.4714904823778032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 537925.9790988469, 537925.9790988469, 137122.028533281]
[2019-03-23 11:08:54,965] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:08:54,968] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.9629723790091406
[2019-03-23 11:08:59,307] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:08:59,310] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.75231383, 37.84954062, 1.0, 2.0, 0.4079563661153552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 452185.6693356754, 452185.6693356754, 126562.6138892719]
[2019-03-23 11:08:59,311] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:08:59,316] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.4270451235515097
[2019-03-23 11:09:00,024] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:09:00,028] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.52211133, 84.93183615, 1.0, 2.0, 0.2993504790763679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 325029.44949671, 325029.4494967103, 115454.7396857806]
[2019-03-23 11:09:00,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:09:00,032] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.9258416467916305
[2019-03-23 11:09:02,515] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:09:02,518] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.9, 87.83333333333334, 1.0, 2.0, 0.3575884924607984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 398915.6430446142, 398915.6430446142, 123502.4993532546]
[2019-03-23 11:09:02,518] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:09:02,521] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.2936317041160602
[2019-03-23 11:09:04,024] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7795979]
[2019-03-23 11:09:04,025] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [24.63333333333333, 45.0, 1.0, 2.0, 0.3238789426086094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 356119.8586776874, 356119.8586776874, 118714.7733875079]
[2019-03-23 11:09:04,027] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:09:04,029] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.9617851e-12 1.0000000e+00 5.4019800e-19 2.1632930e-18 1.8520060e-20], sampled 0.2195544344383109
[2019-03-23 11:09:21,258] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:09:21,336] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:09:21,451] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:09:21,553] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:09:21,767] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:09:22,780] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2250000, evaluation results [2250000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:09:22,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6334956e-12 1.0000000e+00 4.3055689e-19 9.5772791e-19 3.3989100e-20], sum to 1.0000
[2019-03-23 11:09:22,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4782
[2019-03-23 11:09:22,981] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 94.0, 1.0, 2.0, 0.4593675982390223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521933.7160916565, 521933.7160916565, 133087.8842687617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4849200.0000, 
sim time next is 4849800.0000, 
raw observation next is [20.0, 94.00000000000001, 1.0, 2.0, 0.4420198375802595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 502198.1252941769, 502198.1252941769, 131310.0929672412], 
processed observation next is [1.0, 0.13043478260869565, 0.5454545454545454, 0.9400000000000002, 1.0, 1.0, 0.3025247969753243, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18599930566450998, 0.18599930566450998, 0.32026851943229556], 
reward next is 0.6797, 
noisyNet noise sample is [array([-0.35123682], dtype=float32), 0.1998149]. 
=============================================
[2019-03-23 11:09:23,464] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2250353: loss -39.0286
[2019-03-23 11:09:23,470] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2250354: learning rate 0.0010
[2019-03-23 11:09:24,185] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2250735: loss -33.9956
[2019-03-23 11:09:24,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2250735: learning rate 0.0010
[2019-03-23 11:09:26,035] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0079523e-12 1.0000000e+00 5.4570734e-19 8.6186468e-20 1.9949021e-20], sum to 1.0000
[2019-03-23 11:09:26,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5573
[2019-03-23 11:09:26,045] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 100.0, 1.0, 2.0, 0.3761778726220805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 422318.968476457, 422318.968476457, 121925.8712279834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4929000.0000, 
sim time next is 4929600.0000, 
raw observation next is [18.0, 100.0, 1.0, 2.0, 0.3746872933688968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 420634.8369124052, 420634.8369124052, 121793.4445544095], 
processed observation next is [1.0, 0.043478260869565216, 0.45454545454545453, 1.0, 1.0, 1.0, 0.21835911671112096, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15579068033792787, 0.15579068033792787, 0.29705718184002317], 
reward next is 0.7029, 
noisyNet noise sample is [array([2.8136837], dtype=float32), 0.0723836]. 
=============================================
[2019-03-23 11:09:27,577] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2252527: loss 0.0000
[2019-03-23 11:09:27,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2252527: learning rate 0.0010
[2019-03-23 11:09:29,829] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2253715: loss -145.0478
[2019-03-23 11:09:29,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2253717: learning rate 0.0010
[2019-03-23 11:09:31,172] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2254441: loss 0.0004
[2019-03-23 11:09:31,173] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2254441: learning rate 0.0010
[2019-03-23 11:09:31,780] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2254806: loss 0.0118
[2019-03-23 11:09:31,784] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2254807: learning rate 0.0010
[2019-03-23 11:09:32,593] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2255246: loss 0.0198
[2019-03-23 11:09:32,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2255246: learning rate 0.0010
[2019-03-23 11:09:34,959] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256439: loss 0.0017
[2019-03-23 11:09:34,960] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256440: learning rate 0.0010
[2019-03-23 11:09:35,948] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2256939: loss 0.0043
[2019-03-23 11:09:35,956] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2256944: learning rate 0.0010
[2019-03-23 11:09:36,143] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2257036: loss 0.0002
[2019-03-23 11:09:36,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2257036: learning rate 0.0010
[2019-03-23 11:09:36,176] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2257052: loss 0.0014
[2019-03-23 11:09:36,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2257052: learning rate 0.0010
[2019-03-23 11:09:36,662] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2257290: loss 0.0012
[2019-03-23 11:09:36,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2257291: learning rate 0.0010
[2019-03-23 11:09:37,595] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2257757: loss 0.0242
[2019-03-23 11:09:37,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2257758: learning rate 0.0010
[2019-03-23 11:09:37,637] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2257776: loss 0.0136
[2019-03-23 11:09:37,639] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2257776: learning rate 0.0010
[2019-03-23 11:09:37,647] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2257780: loss 0.0101
[2019-03-23 11:09:37,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2257780: learning rate 0.0010
[2019-03-23 11:09:37,788] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2257856: loss 0.0045
[2019-03-23 11:09:37,791] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2257856: learning rate 0.0010
[2019-03-23 11:09:38,959] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2258443: loss 0.0121
[2019-03-23 11:09:38,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2258443: learning rate 0.0010
[2019-03-23 11:09:39,451] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2258689: loss 0.0112
[2019-03-23 11:09:39,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2258689: learning rate 0.0010
[2019-03-23 11:09:41,269] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0367675e-12 1.0000000e+00 1.3835115e-19 1.0668995e-18 1.6510205e-20], sum to 1.0000
[2019-03-23 11:09:41,278] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7789
[2019-03-23 11:09:41,282] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 83.33333333333334, 1.0, 2.0, 0.4748597400632896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 541854.0985607877, 541854.0985607874, 138048.0076412174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5178000.0000, 
sim time next is 5178600.0000, 
raw observation next is [22.7, 83.5, 1.0, 2.0, 0.4716636932523403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 538196.125392908, 538196.1253929083, 137534.0615975614], 
processed observation next is [0.0, 0.9565217391304348, 0.6681818181818181, 0.835, 1.0, 1.0, 0.33957961656542535, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19933189829366962, 0.19933189829366976, 0.33544893072575954], 
reward next is 0.6646, 
noisyNet noise sample is [array([0.67607325], dtype=float32), -0.10652909]. 
=============================================
[2019-03-23 11:09:43,286] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2260614: loss -129.9180
[2019-03-23 11:09:43,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2260615: learning rate 0.0010
[2019-03-23 11:09:45,964] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2261919: loss 5.5368
[2019-03-23 11:09:45,966] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2261919: learning rate 0.0010
[2019-03-23 11:09:47,288] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2262582: loss -106.5468
[2019-03-23 11:09:47,290] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2262582: learning rate 0.0010
[2019-03-23 11:09:47,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3578023e-11 1.0000000e+00 3.4582797e-17 4.0881905e-18 7.5086374e-19], sum to 1.0000
[2019-03-23 11:09:47,699] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-23 11:09:47,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1554577.78425613 W.
[2019-03-23 11:09:47,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.4607568202740152, 1.0, 2.0, 0.4607568202740152, 1.0, 2.0, 0.932285874012373, 6.9112, 6.9112, 77.3421103, 1554577.78425613, 1554577.78425613, 338502.6426335744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5328000.0000, 
sim time next is 5328600.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.8787703393919101, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9807447159188322, 6.9112, 6.9112, 77.32846344354104, 1542946.384055107, 1542946.384055107, 325163.5397062154], 
processed observation next is [1.0, 0.6956521739130435, 1.0, 0.51, 1.0, 1.0, 0.8484629242398875, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9724924513126175, 0.0, 0.0, 0.5084288129206541, 0.5714616237241137, 0.5714616237241137, 0.7930818041615009], 
reward next is 0.2069, 
noisyNet noise sample is [array([0.28972498], dtype=float32), 0.719425]. 
=============================================
[2019-03-23 11:09:47,876] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2262871: loss -109.1329
[2019-03-23 11:09:47,879] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2262871: learning rate 0.0010
[2019-03-23 11:09:48,741] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2263310: loss -102.5607
[2019-03-23 11:09:48,745] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2263310: learning rate 0.0010
[2019-03-23 11:09:49,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8191045e-12 1.0000000e+00 6.3907589e-18 7.2823420e-19 3.5714270e-21], sum to 1.0000
[2019-03-23 11:09:50,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1810
[2019-03-23 11:09:50,010] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666666, 87.0, 1.0, 2.0, 0.4305370603296604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 486810.1205946115, 486810.1205946115, 128574.8485070652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5373600.0000, 
sim time next is 5374200.0000, 
raw observation next is [20.08333333333334, 87.0, 1.0, 2.0, 0.4382968790474243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 495256.7029126749, 495256.7029126749, 129130.8612045913], 
processed observation next is [1.0, 0.17391304347826086, 0.5492424242424245, 0.87, 1.0, 1.0, 0.29787109880928037, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1834284084861759, 0.1834284084861759, 0.3149533200111983], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.09165565], dtype=float32), 1.2256488]. 
=============================================
[2019-03-23 11:09:51,175] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264540: loss -94.9547
[2019-03-23 11:09:51,178] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264540: learning rate 0.0010
[2019-03-23 11:09:52,076] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264996: loss -85.0868
[2019-03-23 11:09:52,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264996: learning rate 0.0010
[2019-03-23 11:09:52,130] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2265024: loss -108.7983
[2019-03-23 11:09:52,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2265025: learning rate 0.0010
[2019-03-23 11:09:52,167] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2265041: loss -81.3766
[2019-03-23 11:09:52,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2265042: learning rate 0.0010
[2019-03-23 11:09:52,673] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2265296: loss -116.6546
[2019-03-23 11:09:52,674] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2265296: learning rate 0.0010
[2019-03-23 11:09:53,607] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2265766: loss -144.0702
[2019-03-23 11:09:53,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2265766: learning rate 0.0010
[2019-03-23 11:09:53,665] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2265793: loss -143.1504
[2019-03-23 11:09:53,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2265797: learning rate 0.0010
[2019-03-23 11:09:53,712] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2265817: loss -155.2280
[2019-03-23 11:09:53,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2265817: learning rate 0.0010
[2019-03-23 11:09:53,863] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2265895: loss -164.7823
[2019-03-23 11:09:53,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2265896: learning rate 0.0010
[2019-03-23 11:09:54,810] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2266367: loss -122.2122
[2019-03-23 11:09:54,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2266367: learning rate 0.0010
[2019-03-23 11:09:55,439] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2266684: loss -110.0106
[2019-03-23 11:09:55,442] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2266684: learning rate 0.0010
[2019-03-23 11:09:59,191] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2268540: loss 5.7855
[2019-03-23 11:09:59,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2268540: learning rate 0.0010
[2019-03-23 11:10:00,458] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5281007e-13 1.0000000e+00 3.8121061e-20 4.8953293e-19 1.5205455e-19], sum to 1.0000
[2019-03-23 11:10:00,467] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7543
[2019-03-23 11:10:00,471] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 68.5, 1.0, 2.0, 0.8388287278480935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 947816.8364731552, 947816.8364731552, 178351.1331904713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5995800.0000, 
sim time next is 5996400.0000, 
raw observation next is [22.73333333333333, 67.66666666666667, 1.0, 2.0, 0.7369576463149748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 833464.0691261815, 833464.0691261813, 164249.5502691031], 
processed observation next is [1.0, 0.391304347826087, 0.6696969696969696, 0.6766666666666667, 1.0, 1.0, 0.6711970578937184, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.30869039597265985, 0.30869039597265974, 0.4006086591929344], 
reward next is 0.5994, 
noisyNet noise sample is [array([-1.4188123], dtype=float32), -1.2871668]. 
=============================================
[2019-03-23 11:10:01,306] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2269594: loss -83.8984
[2019-03-23 11:10:01,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2269594: learning rate 0.0010
[2019-03-23 11:10:03,072] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2270497: loss 6.2416
[2019-03-23 11:10:03,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2270497: learning rate 0.0010
[2019-03-23 11:10:03,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2270779: loss 5.7531
[2019-03-23 11:10:03,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2270781: learning rate 0.0010
[2019-03-23 11:10:04,506] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2271223: loss 6.3268
[2019-03-23 11:10:04,507] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2271223: learning rate 0.0010
[2019-03-23 11:10:07,073] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272515: loss 7.8832
[2019-03-23 11:10:07,074] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272515: learning rate 0.0010
[2019-03-23 11:10:07,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7666606e-14 1.0000000e+00 2.4723432e-23 1.9517831e-22 1.1034971e-22], sum to 1.0000
[2019-03-23 11:10:07,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9528
[2019-03-23 11:10:07,272] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 84.0, 1.0, 2.0, 0.233994936669653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 254065.2162612338, 254065.2162612341, 80779.21940087696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5668200.0000, 
sim time next is 5668800.0000, 
raw observation next is [15.5, 83.0, 1.0, 2.0, 0.2300987668679725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 249833.7765943584, 249833.7765943587, 79808.73876209544], 
processed observation next is [0.0, 0.6086956521739131, 0.3409090909090909, 0.83, 1.0, 1.0, 0.03762345858496562, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0925310283682809, 0.092531028368281, 0.19465546039535472], 
reward next is 0.8053, 
noisyNet noise sample is [array([-0.6309344], dtype=float32), 0.05282213]. 
=============================================
[2019-03-23 11:10:07,878] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272918: loss 7.2777
[2019-03-23 11:10:07,881] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272918: learning rate 0.0010
[2019-03-23 11:10:08,141] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2273053: loss 7.4323
[2019-03-23 11:10:08,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2273054: learning rate 0.0010
[2019-03-23 11:10:08,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7541314e-14 1.0000000e+00 3.1009438e-22 1.1972644e-21 2.4761375e-23], sum to 1.0000
[2019-03-23 11:10:08,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1533
[2019-03-23 11:10:08,210] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.6, 62.0, 1.0, 2.0, 0.2115781006698395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 229719.8892953692, 229719.889295369, 73124.65390377633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5781600.0000, 
sim time next is 5782200.0000, 
raw observation next is [16.51666666666667, 62.33333333333334, 1.0, 2.0, 0.2099642904384584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 227967.2921083194, 227967.2921083191, 72880.91350508589], 
processed observation next is [0.0, 0.9565217391304348, 0.38712121212121225, 0.6233333333333334, 1.0, 1.0, 0.012455363048072994, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08443233041048867, 0.08443233041048855, 0.1777583256221607], 
reward next is 0.8222, 
noisyNet noise sample is [array([-0.51695335], dtype=float32), 1.679498]. 
=============================================
[2019-03-23 11:10:08,217] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2273084: loss 7.1884
[2019-03-23 11:10:08,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2273084: learning rate 0.0010
[2019-03-23 11:10:08,662] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2273309: loss 7.5220
[2019-03-23 11:10:08,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2273312: learning rate 0.0010
[2019-03-23 11:10:09,583] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2273776: loss 6.5001
[2019-03-23 11:10:09,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2273776: learning rate 0.0010
[2019-03-23 11:10:09,653] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2273804: loss 6.8198
[2019-03-23 11:10:09,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2273808: learning rate 0.0010
[2019-03-23 11:10:09,868] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2273912: loss 6.1057
[2019-03-23 11:10:09,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2273913: learning rate 0.0010
[2019-03-23 11:10:09,992] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2273971: loss 6.4077
[2019-03-23 11:10:09,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2273972: learning rate 0.0010
[2019-03-23 11:10:10,610] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2274289: loss 5.8374
[2019-03-23 11:10:10,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2274289: learning rate 0.0010
[2019-03-23 11:10:11,462] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2274722: loss 6.0415
[2019-03-23 11:10:11,470] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2274723: learning rate 0.0010
[2019-03-23 11:10:12,020] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:10:12,023] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:10:12,024] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:10:12,024] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:10:12,024] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:10:12,024] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:10:12,026] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:10:12,025] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:10:12,026] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:10:12,028] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:10:12,030] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:10:12,053] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 11:10:12,080] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 11:10:12,107] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 11:10:12,130] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 11:10:12,130] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 11:10:30,501] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:10:30,503] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.6, 90.0, 1.0, 2.0, 0.4393434533420686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 499437.5652861971, 499437.5652861971, 135623.0386607487]
[2019-03-23 11:10:30,505] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:10:30,508] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.7889764122103777
[2019-03-23 11:10:33,102] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:10:33,103] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [27.56666666666667, 61.0, 1.0, 2.0, 0.5258198873155149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 598727.7933178571, 598727.7933178567, 150429.0286040059]
[2019-03-23 11:10:33,107] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:10:33,109] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.023168230217272878
[2019-03-23 11:10:48,137] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:10:48,140] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.46666666666667, 82.33333333333334, 1.0, 2.0, 0.5105282070308081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 582228.8756881742, 582228.8756881737, 147525.024543513]
[2019-03-23 11:10:48,141] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:10:48,146] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.6320929826391483
[2019-03-23 11:11:25,819] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:11:25,820] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.2, 69.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 214281.2746398477, 214281.2746398475, 69099.13272316182]
[2019-03-23 11:11:25,821] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:11:25,824] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.39685370922013097
[2019-03-23 11:11:25,935] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:11:25,936] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [14.59399539, 94.62725021, 1.0, 2.0, 0.2784928769334201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 302376.937377822, 302376.937377822, 91907.86039482529]
[2019-03-23 11:11:25,938] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:11:25,940] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.7668825880113402
[2019-03-23 11:11:36,966] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:11:36,966] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.3, 93.0, 1.0, 2.0, 0.7297019005222249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 816382.5211920845, 816382.5211920845, 158914.1115607515]
[2019-03-23 11:11:36,967] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:11:36,969] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.47224460433906923
[2019-03-23 11:11:42,495] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:11:42,495] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.33333333333334, 56.33333333333333, 1.0, 2.0, 0.5396854956893776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 586175.6291152744, 586175.6291152746, 121460.1477109308]
[2019-03-23 11:11:42,496] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:11:42,499] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.7867443362105121
[2019-03-23 11:11:50,353] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.7564569]
[2019-03-23 11:11:50,354] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [23.07556135666667, 53.64266004, 1.0, 2.0, 0.3533739892699977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 390799.4519310395, 390799.4519310391, 121752.431256486]
[2019-03-23 11:11:50,355] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:11:50,356] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2797485e-13 1.0000000e+00 4.0053223e-20 1.6593116e-19 1.0696405e-21], sampled 0.16990902212353798
[2019-03-23 11:11:50,548] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:11:50,635] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:11:50,723] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:11:50,801] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:11:50,970] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:11:51,987] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2275000, evaluation results [2275000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:11:52,446] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6158374e-13 1.0000000e+00 1.3772663e-19 8.8853108e-21 1.0684939e-22], sum to 1.0000
[2019-03-23 11:11:52,452] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4697
[2019-03-23 11:11:52,458] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.31666666666667, 78.5, 1.0, 2.0, 0.3646919903591213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 408266.8630078759, 408266.8630078762, 120399.7112607209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5965800.0000, 
sim time next is 5966400.0000, 
raw observation next is [20.13333333333333, 79.0, 1.0, 2.0, 0.3632975924611245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406147.4681061209, 406147.4681061209, 120028.3957328234], 
processed observation next is [1.0, 0.043478260869565216, 0.5515151515151513, 0.79, 1.0, 1.0, 0.20412199057640557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15042498818745217, 0.15042498818745217, 0.2927521847142034], 
reward next is 0.7072, 
noisyNet noise sample is [array([-1.093628], dtype=float32), -1.0669041]. 
=============================================
[2019-03-23 11:11:53,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1079404e-13 1.0000000e+00 1.9814627e-20 7.1804899e-21 1.0643480e-23], sum to 1.0000
[2019-03-23 11:11:53,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2601
[2019-03-23 11:11:53,025] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 48.33333333333334, 1.0, 2.0, 0.2212816422626518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 240258.0642548333, 240258.064254833, 73312.92893220345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5743200.0000, 
sim time next is 5743800.0000, 
raw observation next is [18.55, 47.5, 1.0, 2.0, 0.2242050096520991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 243432.9247950199, 243432.9247950202, 73853.99411658155], 
processed observation next is [0.0, 0.4782608695652174, 0.47954545454545455, 0.475, 1.0, 1.0, 0.03025626206512387, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09016034251667404, 0.09016034251667415, 0.18013169296727208], 
reward next is 0.8199, 
noisyNet noise sample is [array([1.9485964], dtype=float32), 0.5660645]. 
=============================================
[2019-03-23 11:11:54,619] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2276500: loss -74.3190
[2019-03-23 11:11:54,625] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2276500: learning rate 0.0010
[2019-03-23 11:11:56,552] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2277519: loss 0.0327
[2019-03-23 11:11:56,554] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2277519: learning rate 0.0010
[2019-03-23 11:11:56,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1914317e-12 1.0000000e+00 7.8736086e-19 7.4679034e-19 5.5383753e-21], sum to 1.0000
[2019-03-23 11:11:56,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6647
[2019-03-23 11:11:56,634] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 79.0, 1.0, 2.0, 0.4923261754567925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 561623.9073485922, 561623.9073485922, 140881.3025249678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6312600.0000, 
sim time next is 6313200.0000, 
raw observation next is [23.66666666666667, 80.0, 1.0, 2.0, 0.4906914620549104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 559788.5427820031, 559788.5427820031, 140618.1298160452], 
processed observation next is [0.0, 0.043478260869565216, 0.7121212121212124, 0.8, 1.0, 1.0, 0.36336432756863796, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20732908991926038, 0.20732908991926038, 0.3429710483318176], 
reward next is 0.6570, 
noisyNet noise sample is [array([-0.39883685], dtype=float32), -0.75854015]. 
=============================================
[2019-03-23 11:11:57,635] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2518140e-12 1.0000000e+00 1.1210131e-19 3.3497669e-19 7.0694094e-21], sum to 1.0000
[2019-03-23 11:11:57,646] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9223
[2019-03-23 11:11:57,650] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.28333333333333, 88.0, 1.0, 2.0, 0.2834803553319216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 307812.1152165395, 307812.1152165392, 95970.07545702365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890200.0000, 
sim time next is 5890800.0000, 
raw observation next is [16.46666666666667, 86.0, 1.0, 2.0, 0.2722627157717675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 295627.938148035, 295627.938148035, 94429.1354195259], 
processed observation next is [1.0, 0.17391304347826086, 0.38484848484848494, 0.86, 1.0, 1.0, 0.0903283947147094, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10949182894371667, 0.10949182894371667, 0.23031496443786806], 
reward next is 0.7697, 
noisyNet noise sample is [array([-1.1716474], dtype=float32), 1.1920575]. 
=============================================
[2019-03-23 11:11:58,473] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2278533: loss -73.0144
[2019-03-23 11:11:58,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2278535: learning rate 0.0010
[2019-03-23 11:11:59,000] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2278809: loss -117.2748
[2019-03-23 11:11:59,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2278809: learning rate 0.0010
[2019-03-23 11:11:59,814] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2279258: loss -43.7164
[2019-03-23 11:11:59,819] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2279259: learning rate 0.0010
[2019-03-23 11:12:02,098] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280469: loss -47.1605
[2019-03-23 11:12:02,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280472: learning rate 0.0010
[2019-03-23 11:12:02,974] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1588124e-12 1.0000000e+00 6.9490681e-20 2.9272743e-19 1.0017767e-20], sum to 1.0000
[2019-03-23 11:12:02,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-23 11:12:02,985] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 46.0, 1.0, 2.0, 0.8269499646176546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 911855.9393490432, 911855.9393490432, 166827.6815792164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6100800.0000, 
sim time next is 6101400.0000, 
raw observation next is [24.3, 45.5, 1.0, 2.0, 0.8261247477434641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 910918.9990284728, 910918.9990284732, 166707.86492014], 
processed observation next is [1.0, 0.6086956521739131, 0.740909090909091, 0.455, 1.0, 1.0, 0.7826559346793301, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3373774070475825, 0.3373774070475827, 0.4066045485857073], 
reward next is 0.5934, 
noisyNet noise sample is [array([0.43133125], dtype=float32), 0.9062464]. 
=============================================
[2019-03-23 11:12:03,028] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280932: loss -79.4242
[2019-03-23 11:12:03,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280933: learning rate 0.0010
[2019-03-23 11:12:03,113] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2280978: loss -84.6298
[2019-03-23 11:12:03,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2280981: learning rate 0.0010
[2019-03-23 11:12:03,239] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2281041: loss -68.1337
[2019-03-23 11:12:03,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2281042: learning rate 0.0010
[2019-03-23 11:12:03,976] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2281412: loss -115.4918
[2019-03-23 11:12:03,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2281413: learning rate 0.0010
[2019-03-23 11:12:04,697] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2281780: loss -114.7820
[2019-03-23 11:12:04,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2281780: learning rate 0.0010
[2019-03-23 11:12:04,776] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2281814: loss -59.2046
[2019-03-23 11:12:04,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2281814: learning rate 0.0010
[2019-03-23 11:12:05,046] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2281952: loss -67.2943
[2019-03-23 11:12:05,047] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2281953: learning rate 0.0010
[2019-03-23 11:12:05,173] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2282016: loss -71.5338
[2019-03-23 11:12:05,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2282016: learning rate 0.0010
[2019-03-23 11:12:05,458] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2282157: loss -69.9732
[2019-03-23 11:12:05,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2282158: learning rate 0.0010
[2019-03-23 11:12:06,501] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2282683: loss -108.8117
[2019-03-23 11:12:06,502] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2282683: learning rate 0.0010
[2019-03-23 11:12:09,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2284397: loss 0.0599
[2019-03-23 11:12:09,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2284397: learning rate 0.0010
[2019-03-23 11:12:11,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1237237e-13 1.0000000e+00 1.8238004e-21 1.4043876e-19 2.2823719e-21], sum to 1.0000
[2019-03-23 11:12:11,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0436
[2019-03-23 11:12:11,722] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333334, 86.16666666666667, 1.0, 2.0, 0.4416071676288303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 503503.9788515508, 503503.9788515508, 133183.7529785786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6257400.0000, 
sim time next is 6258000.0000, 
raw observation next is [22.16666666666667, 85.33333333333334, 1.0, 2.0, 0.4481529432344039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 511157.6768363994, 511157.6768363994, 134236.4907388747], 
processed observation next is [0.0, 0.43478260869565216, 0.6439393939393941, 0.8533333333333334, 1.0, 1.0, 0.31019117904300486, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18931765808755535, 0.18931765808755535, 0.32740607497286517], 
reward next is 0.6726, 
noisyNet noise sample is [array([-1.0271237], dtype=float32), -1.6032352]. 
=============================================
[2019-03-23 11:12:11,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.55109]
 [70.55109]
 [70.55109]
 [70.55109]
 [70.55109]], R is [[70.51816559]
 [70.48815155]
 [70.46078491]
 [70.43548584]
 [70.41213989]].
[2019-03-23 11:12:11,978] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2285423: loss 0.0211
[2019-03-23 11:12:11,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2285423: learning rate 0.0010
[2019-03-23 11:12:14,080] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2286479: loss 0.0006
[2019-03-23 11:12:14,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2286480: learning rate 0.0010
[2019-03-23 11:12:14,585] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2286736: loss 0.0001
[2019-03-23 11:12:14,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2286736: learning rate 0.0010
[2019-03-23 11:12:15,544] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2287214: loss 0.0103
[2019-03-23 11:12:15,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2287215: learning rate 0.0010
[2019-03-23 11:12:18,313] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288456: loss 0.0008
[2019-03-23 11:12:18,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288457: learning rate 0.0010
[2019-03-23 11:12:19,311] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2288953: loss 0.0000
[2019-03-23 11:12:19,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2288953: learning rate 0.0010
[2019-03-23 11:12:19,340] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288963: loss 0.0002
[2019-03-23 11:12:19,342] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288965: learning rate 0.0010
[2019-03-23 11:12:19,477] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2289032: loss 0.0000
[2019-03-23 11:12:19,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2289033: learning rate 0.0010
[2019-03-23 11:12:20,255] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2289424: loss 0.0012
[2019-03-23 11:12:20,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2289424: learning rate 0.0010
[2019-03-23 11:12:20,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2289785: loss 0.0006
[2019-03-23 11:12:20,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2289785: learning rate 0.0010
[2019-03-23 11:12:21,024] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2289811: loss 0.0005
[2019-03-23 11:12:21,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2289811: learning rate 0.0010
[2019-03-23 11:12:21,449] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2290025: loss 0.0032
[2019-03-23 11:12:21,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2290025: learning rate 0.0010
[2019-03-23 11:12:21,520] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2290059: loss 0.0000
[2019-03-23 11:12:21,523] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2290060: learning rate 0.0010
[2019-03-23 11:12:21,889] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2290249: loss 0.0042
[2019-03-23 11:12:21,890] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2290249: learning rate 0.0010
[2019-03-23 11:12:22,993] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2290805: loss 0.0001
[2019-03-23 11:12:22,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2290806: learning rate 0.0010
[2019-03-23 11:12:26,253] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2292452: loss 0.0011
[2019-03-23 11:12:26,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2292452: learning rate 0.0010
[2019-03-23 11:12:27,019] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5353330e-11 1.0000000e+00 2.4751142e-18 5.6031767e-18 5.5653170e-20], sum to 1.0000
[2019-03-23 11:12:27,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7671
[2019-03-23 11:12:27,034] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 73.66666666666667, 1.0, 2.0, 0.469753693686724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 520269.142999238, 520269.142999238, 127572.631693107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6455400.0000, 
sim time next is 6456000.0000, 
raw observation next is [20.0, 72.33333333333334, 1.0, 2.0, 0.3568955481932563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393536.5653918713, 393536.5653918713, 117268.8249083241], 
processed observation next is [1.0, 0.7391304347826086, 0.5454545454545454, 0.7233333333333334, 1.0, 1.0, 0.19611943524157036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14575428347847086, 0.14575428347847086, 0.2860215241666441], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.18598862], dtype=float32), -0.105053306]. 
=============================================
[2019-03-23 11:12:27,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.90191]
 [65.90191]
 [65.90191]
 [65.90191]
 [65.90191]], R is [[65.95687103]
 [65.98615265]
 [65.94682312]
 [65.91403198]
 [65.88733673]].
[2019-03-23 11:12:27,972] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6989304e-11 1.0000000e+00 6.8001513e-18 1.7394289e-18 1.1524662e-20], sum to 1.0000
[2019-03-23 11:12:27,979] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0305
[2019-03-23 11:12:27,986] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.5, 75.0, 1.0, 2.0, 0.2184371739126332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 237168.9102187116, 237168.9102187113, 75161.89417478954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475200.0000, 
sim time next is 6475800.0000, 
raw observation next is [15.5, 75.0, 1.0, 2.0, 0.2181935964794137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 236904.3807797221, 236904.3807797218, 75138.81610920814], 
processed observation next is [1.0, 0.9565217391304348, 0.3409090909090909, 0.75, 1.0, 1.0, 0.022741995599267102, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08774236325174892, 0.08774236325174882, 0.18326540514441012], 
reward next is 0.8167, 
noisyNet noise sample is [array([-0.66064346], dtype=float32), 0.12066587]. 
=============================================
[2019-03-23 11:12:28,171] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2293413: loss 0.0002
[2019-03-23 11:12:28,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2293413: learning rate 0.0010
[2019-03-23 11:12:30,022] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2294348: loss 0.0330
[2019-03-23 11:12:30,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2294349: learning rate 0.0010
[2019-03-23 11:12:30,755] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2294715: loss 0.0471
[2019-03-23 11:12:30,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2294716: learning rate 0.0010
[2019-03-23 11:12:31,691] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2295191: loss 0.0223
[2019-03-23 11:12:31,693] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2295191: learning rate 0.0010
[2019-03-23 11:12:34,415] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296570: loss 0.0630
[2019-03-23 11:12:34,418] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296570: learning rate 0.0010
[2019-03-23 11:12:35,076] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2296907: loss 0.0443
[2019-03-23 11:12:35,078] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2296907: learning rate 0.0010
[2019-03-23 11:12:35,202] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2296974: loss 0.0307
[2019-03-23 11:12:35,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2296974: learning rate 0.0010
[2019-03-23 11:12:35,351] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2297049: loss 0.0168
[2019-03-23 11:12:35,352] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2297049: learning rate 0.0010
[2019-03-23 11:12:36,038] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2297396: loss 0.0081
[2019-03-23 11:12:36,041] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2297397: learning rate 0.0010
[2019-03-23 11:12:36,822] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2297799: loss 0.0175
[2019-03-23 11:12:36,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2297799: learning rate 0.0010
[2019-03-23 11:12:36,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9259433e-13 1.0000000e+00 2.3210051e-20 1.4270431e-18 1.7810704e-20], sum to 1.0000
[2019-03-23 11:12:36,968] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1286
[2019-03-23 11:12:36,972] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 91.5, 1.0, 2.0, 0.3636615371322095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 406283.6740383395, 406283.6740383395, 119936.9213501702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6661800.0000, 
sim time next is 6662400.0000, 
raw observation next is [18.46666666666667, 92.0, 1.0, 2.0, 0.3562027733191913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 397768.6979857694, 397768.6979857694, 119246.8040919691], 
processed observation next is [1.0, 0.08695652173913043, 0.4757575757575758, 0.92, 1.0, 1.0, 0.19525346664898913, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14732173999472942, 0.14732173999472942, 0.29084586363894904], 
reward next is 0.7092, 
noisyNet noise sample is [array([1.0291183], dtype=float32), 0.41151717]. 
=============================================
[2019-03-23 11:12:36,999] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2297887: loss 0.0393
[2019-03-23 11:12:37,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2297887: learning rate 0.0010
[2019-03-23 11:12:37,243] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2298005: loss 0.0142
[2019-03-23 11:12:37,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2298005: learning rate 0.0010
[2019-03-23 11:12:37,323] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2298048: loss 0.0105
[2019-03-23 11:12:37,325] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2298048: learning rate 0.0010
[2019-03-23 11:12:37,650] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2298218: loss 0.0349
[2019-03-23 11:12:37,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2298218: learning rate 0.0010
[2019-03-23 11:12:37,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0038709e-14 1.0000000e+00 1.2671472e-20 2.4952097e-20 1.6670113e-22], sum to 1.0000
[2019-03-23 11:12:37,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0277
[2019-03-23 11:12:37,835] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.3, 93.0, 1.0, 2.0, 0.3519063272706183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 392668.9668405027, 392668.966840503, 118765.8097713347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6663600.0000, 
sim time next is 6664200.0000, 
raw observation next is [18.3, 93.0, 1.0, 2.0, 0.379462604620267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 423437.2769897092, 423437.2769897092, 121031.8543239128], 
processed observation next is [1.0, 0.13043478260869565, 0.4681818181818182, 0.93, 1.0, 1.0, 0.22432825577533372, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1568286211072997, 0.1568286211072997, 0.29519964469247023], 
reward next is 0.7048, 
noisyNet noise sample is [array([1.1723572], dtype=float32), -1.133665]. 
=============================================
[2019-03-23 11:12:38,794] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2298791: loss 0.0423
[2019-03-23 11:12:38,795] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2298791: learning rate 0.0010
[2019-03-23 11:12:40,658] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5593957e-13 1.0000000e+00 9.2551042e-20 1.6383926e-18 2.4668358e-20], sum to 1.0000
[2019-03-23 11:12:40,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6322
[2019-03-23 11:12:40,677] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 98.0, 1.0, 2.0, 0.3600850194431279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 401437.5443897116, 401437.5443897119, 119270.4633039159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6729600.0000, 
sim time next is 6730200.0000, 
raw observation next is [17.7, 98.5, 1.0, 2.0, 0.3605811069330362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 402295.0730565768, 402295.0730565765, 119442.8916730439], 
processed observation next is [1.0, 0.9130434782608695, 0.44090909090909086, 0.985, 1.0, 1.0, 0.20072638366629522, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14899817520613953, 0.14899817520613945, 0.2913241260318144], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.08406984], dtype=float32), 0.80581075]. 
=============================================
[2019-03-23 11:12:41,198] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 11:12:41,199] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:12:41,200] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:12:41,200] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:12:41,200] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:12:41,202] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:12:41,204] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:12:41,204] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:12:41,205] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:12:41,205] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:12:41,206] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:12:41,227] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 11:12:41,253] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 11:12:41,253] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 11:12:41,298] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 11:12:41,329] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 11:12:45,761] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:12:45,762] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.13037677666667, 91.76514054666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 211926.2130589352, 211926.2130589348, 75678.95117002862]
[2019-03-23 11:12:45,765] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:12:45,768] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.7804549258527154
[2019-03-23 11:12:55,275] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:12:55,277] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 64.0, 1.0, 2.0, 0.3612458450824609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 403158.4103321992, 403158.4103321989, 123870.3824867616]
[2019-03-23 11:12:55,279] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:12:55,280] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.7222570032622253
[2019-03-23 11:12:57,234] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:12:57,236] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.628988295, 68.362617195, 1.0, 2.0, 0.4552062851033556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 517159.9535395881, 517159.9535395881, 136975.3101448933]
[2019-03-23 11:12:57,237] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:12:57,242] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.3065614894771216
[2019-03-23 11:13:15,369] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:13:15,370] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [19.04498068, 88.68859494, 1.0, 2.0, 0.3741746587461459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 417149.987547643, 417149.9875476426, 124748.2559752424]
[2019-03-23 11:13:15,371] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:13:15,373] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.5698314242953937
[2019-03-23 11:13:26,688] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:13:26,689] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [13.78761619333333, 81.10597033666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 212712.7747784366, 212712.7747784362, 74745.5124398268]
[2019-03-23 11:13:26,691] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:13:26,693] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.9744833750442665
[2019-03-23 11:13:43,485] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:13:43,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.52405299333333, 96.14460691, 1.0, 2.0, 0.3382521747805424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 369604.2107858337, 369604.2107858334, 118934.0689116343]
[2019-03-23 11:13:43,486] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:13:43,491] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.746611623356447
[2019-03-23 11:13:54,102] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:13:54,103] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.69039414, 81.83939137, 1.0, 2.0, 0.5644311099559555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 632592.0034894424, 632592.0034894424, 144150.1776016961]
[2019-03-23 11:13:54,105] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:13:54,107] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.7043272427921116
[2019-03-23 11:13:59,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:13:59,202] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.9, 69.5, 1.0, 2.0, 0.4141591857708279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 449733.3568400909, 449733.3568400909, 118199.2828058637]
[2019-03-23 11:13:59,203] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:13:59,207] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.32493730189742764
[2019-03-23 11:14:00,208] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:14:00,210] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.86666666666667, 86.5, 1.0, 2.0, 0.3822149486756772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 430270.3363656305, 430270.3363656305, 127361.0203725348]
[2019-03-23 11:14:00,212] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:14:00,215] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.8893897063567474
[2019-03-23 11:14:14,648] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:14:14,650] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [14.06666666666667, 84.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 216865.3850338614, 216865.3850338614, 76647.10641408928]
[2019-03-23 11:14:14,652] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:14:14,655] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.6475284378467476
[2019-03-23 11:14:15,272] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:14:15,273] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [17.2, 64.0, 1.0, 2.0, 0.2383454691599631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 258777.0302105795, 258777.0302105792, 82730.46325100253]
[2019-03-23 11:14:15,275] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:14:15,278] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.6390615834356533
[2019-03-23 11:14:17,847] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:14:17,849] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [17.28333333333333, 65.5, 1.0, 2.0, 0.2351648835652675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 255323.0635326784, 255323.0635326784, 83337.77311743237]
[2019-03-23 11:14:17,850] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:14:17,855] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.07510846415255445
[2019-03-23 11:14:18,055] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.767385]
[2019-03-23 11:14:18,056] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.524527425, 79.14019711166667, 1.0, 2.0, 0.2658932672097465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 288693.4764322446, 288693.4764322442, 101097.2927947235]
[2019-03-23 11:14:18,058] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:14:18,062] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [2.1843499e-12 1.0000000e+00 3.2038530e-19 1.2699503e-18 1.0708617e-20], sampled 0.6656354771252327
[2019-03-23 11:14:20,049] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:14:20,072] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:14:20,086] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:14:20,130] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:14:20,291] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:14:21,305] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2300000, evaluation results [2300000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:14:22,139] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2300441: loss 0.0046
[2019-03-23 11:14:22,142] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2300441: learning rate 0.0010
[2019-03-23 11:14:23,989] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2301431: loss 0.0006
[2019-03-23 11:14:23,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2301432: learning rate 0.0010
[2019-03-23 11:14:25,742] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2302370: loss 0.0024
[2019-03-23 11:14:25,743] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2302370: learning rate 0.0010
[2019-03-23 11:14:26,466] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2302754: loss 0.0022
[2019-03-23 11:14:26,467] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2302755: learning rate 0.0010
[2019-03-23 11:14:27,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2303176: loss 0.0001
[2019-03-23 11:14:27,268] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2303177: learning rate 0.0010
[2019-03-23 11:14:28,800] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6882858e-12 1.0000000e+00 5.1408765e-20 2.5785073e-18 1.3667093e-20], sum to 1.0000
[2019-03-23 11:14:28,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4735
[2019-03-23 11:14:28,809] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 50.0, 1.0, 2.0, 0.4711663176354356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537622.0446264541, 537622.0446264545, 137926.5386280399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6879600.0000, 
sim time next is 6880200.0000, 
raw observation next is [28.71666666666667, 49.66666666666667, 1.0, 2.0, 0.4706604612713234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 537057.7487299328, 537057.7487299332, 137716.7907356203], 
processed observation next is [0.0, 0.6521739130434783, 0.9416666666666668, 0.4966666666666667, 1.0, 1.0, 0.3383255765891542, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19891027730738253, 0.19891027730738264, 0.33589461155029343], 
reward next is 0.6641, 
noisyNet noise sample is [array([-0.5683363], dtype=float32), -0.9652704]. 
=============================================
[2019-03-23 11:14:29,764] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304563: loss 0.0002
[2019-03-23 11:14:29,769] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304564: learning rate 0.0010
[2019-03-23 11:14:30,394] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2304885: loss 0.0019
[2019-03-23 11:14:30,397] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2304886: learning rate 0.0010
[2019-03-23 11:14:30,562] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2304971: loss 0.0021
[2019-03-23 11:14:30,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2304971: learning rate 0.0010
[2019-03-23 11:14:30,676] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2305027: loss 0.0029
[2019-03-23 11:14:30,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2305028: learning rate 0.0010
[2019-03-23 11:14:31,392] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2305393: loss 0.0024
[2019-03-23 11:14:31,395] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2305394: learning rate 0.0010
[2019-03-23 11:14:32,265] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2305827: loss 0.0013
[2019-03-23 11:14:32,269] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2305828: learning rate 0.0010
[2019-03-23 11:14:32,397] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2305894: loss 0.0019
[2019-03-23 11:14:32,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2305894: learning rate 0.0010
[2019-03-23 11:14:32,515] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305960: loss 0.0026
[2019-03-23 11:14:32,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305960: learning rate 0.0010
[2019-03-23 11:14:32,730] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2306063: loss 0.0118
[2019-03-23 11:14:32,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2306063: learning rate 0.0010
[2019-03-23 11:14:32,970] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2306188: loss 0.0065
[2019-03-23 11:14:32,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2306190: learning rate 0.0010
[2019-03-23 11:14:33,032] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3453860e-12 1.0000000e+00 3.7203645e-19 1.1678647e-17 2.0999501e-21], sum to 1.0000
[2019-03-23 11:14:33,040] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0844
[2019-03-23 11:14:33,046] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 90.0, 1.0, 2.0, 0.3699931272565283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 413853.6026374467, 413853.602637447, 120681.7923219092], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6926400.0000, 
sim time next is 6927000.0000, 
raw observation next is [18.8, 89.5, 1.0, 2.0, 0.3682712919122944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 411556.2000045355, 411556.2000045355, 120371.1722023528], 
processed observation next is [0.0, 0.17391304347826086, 0.49090909090909096, 0.895, 1.0, 1.0, 0.210339114890368, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.15242822222390204, 0.15242822222390204, 0.29358822488378733], 
reward next is 0.7064, 
noisyNet noise sample is [array([-0.36321238], dtype=float32), 1.13323]. 
=============================================
[2019-03-23 11:14:33,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.01128]
 [67.01128]
 [67.01128]
 [67.01128]
 [67.01128]], R is [[67.04756927]
 [67.08274841]
 [67.11672211]
 [67.1493454 ]
 [67.18038177]].
[2019-03-23 11:14:34,250] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2306826: loss 0.0088
[2019-03-23 11:14:34,253] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2306827: learning rate 0.0010
[2019-03-23 11:14:36,150] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8120497e-13 1.0000000e+00 2.8650092e-20 1.6806580e-20 2.8015440e-22], sum to 1.0000
[2019-03-23 11:14:36,154] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8215
[2019-03-23 11:14:36,159] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 97.0, 1.0, 2.0, 0.3478251009894788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387215.7418640935, 387215.7418640938, 118048.3827694509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7102800.0000, 
sim time next is 7103400.0000, 
raw observation next is [17.7, 97.0, 1.0, 2.0, 0.3934509836904135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 438123.059599972, 438123.0595999717, 121826.5730418882], 
processed observation next is [1.0, 0.21739130434782608, 0.44090909090909086, 0.97, 1.0, 1.0, 0.24181372961301684, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16226779985184148, 0.16226779985184137, 0.29713798302899563], 
reward next is 0.7029, 
noisyNet noise sample is [array([-0.44982907], dtype=float32), -0.7303137]. 
=============================================
[2019-03-23 11:14:37,430] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2308422: loss 0.0022
[2019-03-23 11:14:37,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2308422: learning rate 0.0010
[2019-03-23 11:14:39,601] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2309530: loss 0.0006
[2019-03-23 11:14:39,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2309531: learning rate 0.0010
[2019-03-23 11:14:40,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5627745e-11 1.0000000e+00 3.0568714e-18 9.5232568e-18 9.9921956e-21], sum to 1.0000
[2019-03-23 11:14:40,435] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7107
[2019-03-23 11:14:40,438] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 91.5, 1.0, 2.0, 0.3437428327402404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 380949.6613173622, 380949.6613173622, 117012.2219896434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7083000.0000, 
sim time next is 7083600.0000, 
raw observation next is [17.9, 92.0, 1.0, 2.0, 0.3426203828282322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379445.9403904856, 379445.9403904856, 116821.5294552188], 
processed observation next is [1.0, 1.0, 0.44999999999999996, 0.92, 1.0, 1.0, 0.17827547853529024, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1405355334779576, 0.1405355334779576, 0.28493055964687514], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.7156822], dtype=float32), -0.4764416]. 
=============================================
[2019-03-23 11:14:41,558] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2310486: loss 0.0081
[2019-03-23 11:14:41,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2310488: learning rate 0.0010
[2019-03-23 11:14:41,918] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2310666: loss 0.0001
[2019-03-23 11:14:41,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2310666: learning rate 0.0010
[2019-03-23 11:14:42,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2311185: loss 0.0028
[2019-03-23 11:14:42,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2311185: learning rate 0.0010
[2019-03-23 11:14:45,741] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312587: loss 0.0194
[2019-03-23 11:14:45,744] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312588: learning rate 0.0010
[2019-03-23 11:14:46,347] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2312895: loss 0.0487
[2019-03-23 11:14:46,349] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2312896: learning rate 0.0010
[2019-03-23 11:14:46,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2312946: loss 0.0326
[2019-03-23 11:14:46,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2312946: learning rate 0.0010
[2019-03-23 11:14:46,571] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2313006: loss 0.0195
[2019-03-23 11:14:46,574] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2313006: learning rate 0.0010
[2019-03-23 11:14:47,201] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2313324: loss 0.0003
[2019-03-23 11:14:47,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2313325: learning rate 0.0010
[2019-03-23 11:14:47,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3007382e-11 1.0000000e+00 1.3525734e-16 4.2400811e-18 1.4242905e-19], sum to 1.0000
[2019-03-23 11:14:47,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4482
[2019-03-23 11:14:47,942] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 48.66666666666666, 1.0, 2.0, 0.340232693097869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 375988.1070192427, 375988.1070192429, 116317.0095252058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7324800.0000, 
sim time next is 7325400.0000, 
raw observation next is [24.0, 49.33333333333334, 1.0, 2.0, 0.3390103240211816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374289.2935324284, 374289.2935324284, 116089.1476518194], 
processed observation next is [1.0, 0.782608695652174, 0.7272727272727273, 0.4933333333333334, 1.0, 1.0, 0.17376290502647695, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.13862566427126977, 0.13862566427126977, 0.28314426256541314], 
reward next is 0.7169, 
noisyNet noise sample is [array([2.8676577], dtype=float32), -0.41196504]. 
=============================================
[2019-03-23 11:14:48,180] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2313817: loss 0.0036
[2019-03-23 11:14:48,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2313818: learning rate 0.0010
[2019-03-23 11:14:48,230] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1507104e-12 1.0000000e+00 5.9843361e-17 1.0746480e-18 2.1328986e-20], sum to 1.0000
[2019-03-23 11:14:48,238] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2602
[2019-03-23 11:14:48,242] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 48.33333333333334, 1.0, 2.0, 0.5852585850634393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 635706.8937844489, 635706.8937844489, 130730.0221816274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7212000.0000, 
sim time next is 7212600.0000, 
raw observation next is [22.2, 48.0, 1.0, 2.0, 0.5819549576968303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 632116.1656211315, 632116.1656211313, 129673.8444389058], 
processed observation next is [1.0, 0.4782608695652174, 0.6454545454545454, 0.48, 1.0, 1.0, 0.4774436971210378, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.23411709837819686, 0.23411709837819678, 0.31627766936318485], 
reward next is 0.6837, 
noisyNet noise sample is [array([-0.72958165], dtype=float32), -0.56609535]. 
=============================================
[2019-03-23 11:14:48,291] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2313872: loss 0.0017
[2019-03-23 11:14:48,294] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2313873: learning rate 0.0010
[2019-03-23 11:14:48,414] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313935: loss 0.0116
[2019-03-23 11:14:48,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313936: learning rate 0.0010
[2019-03-23 11:14:48,545] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2314001: loss 0.0097
[2019-03-23 11:14:48,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2314001: learning rate 0.0010
[2019-03-23 11:14:48,874] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2314164: loss 0.0173
[2019-03-23 11:14:48,877] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2314165: learning rate 0.0010
[2019-03-23 11:14:49,901] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3020971e-13 1.0000000e+00 5.0135407e-19 2.1021713e-20 3.3542628e-22], sum to 1.0000
[2019-03-23 11:14:49,910] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6068
[2019-03-23 11:14:49,916] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.9, 82.83333333333333, 1.0, 2.0, 0.2032330390763043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 220657.224251111, 220657.2242511113, 71905.61605999315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7275000.0000, 
sim time next is 7275600.0000, 
raw observation next is [13.8, 84.0, 1.0, 2.0, 0.2012130206503769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 218463.5270151731, 218463.5270151733, 71769.75174645339], 
processed observation next is [1.0, 0.21739130434782608, 0.26363636363636367, 0.84, 1.0, 1.0, 0.0015162758129711254, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08091241741302707, 0.08091241741302715, 0.17504817499134973], 
reward next is 0.8250, 
noisyNet noise sample is [array([1.5168431], dtype=float32), -0.42660055]. 
=============================================
[2019-03-23 11:14:50,210] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2314839: loss 0.0112
[2019-03-23 11:14:50,211] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2314840: learning rate 0.0010
[2019-03-23 11:14:53,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2316484: loss 0.0078
[2019-03-23 11:14:53,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2316484: learning rate 0.0010
[2019-03-23 11:14:53,751] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2142449e-11 1.0000000e+00 7.0020508e-19 1.7440408e-17 2.6491750e-20], sum to 1.0000
[2019-03-23 11:14:53,761] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0277
[2019-03-23 11:14:53,767] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 43.66666666666667, 1.0, 2.0, 0.8837085433072674, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354103, 989514.0206007666, 989514.0206007669, 180639.2696883507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7316400.0000, 
sim time next is 7317000.0000, 
raw observation next is [25.8, 44.5, 1.0, 2.0, 0.8491836666039703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 950599.2205290803, 950599.2205290806, 175460.5093718329], 
processed observation next is [1.0, 0.6956521739130435, 0.8090909090909091, 0.445, 1.0, 1.0, 0.8114795832549628, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.3520737853811408, 0.352073785381141, 0.42795246188251923], 
reward next is 0.5720, 
noisyNet noise sample is [array([1.1800581], dtype=float32), -1.325879]. 
=============================================
[2019-03-23 11:14:53,780] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.9336]
 [68.9336]
 [68.9336]
 [68.9336]
 [68.9336]], R is [[68.81630707]
 [68.12814331]
 [67.44686127]
 [66.77239227]
 [66.10466766]].
[2019-03-23 11:14:53,995] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4936602e-12 1.0000000e+00 1.0372785e-18 6.0679157e-18 1.3301599e-19], sum to 1.0000
[2019-03-23 11:14:54,005] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3285
[2019-03-23 11:14:54,011] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 87.0, 1.0, 2.0, 0.3547531767705037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 387599.1478664508, 387599.1478664511, 115822.271239689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7355400.0000, 
sim time next is 7356000.0000, 
raw observation next is [17.7, 87.0, 1.0, 2.0, 0.3474410204705829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 379624.4318080782, 379624.4318080782, 115285.1861668952], 
processed observation next is [1.0, 0.13043478260869565, 0.44090909090909086, 0.87, 1.0, 1.0, 0.1843012755882286, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14060164141039933, 0.14060164141039933, 0.28118338089486633], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.3765874], dtype=float32), -1.1874549]. 
=============================================
[2019-03-23 11:14:54,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.30589]
 [69.30589]
 [69.30589]
 [69.30589]
 [69.30589]], R is [[69.33164215]
 [69.35583496]
 [69.38365173]
 [69.41028595]
 [69.43553925]].
[2019-03-23 11:14:54,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7346896e-12 1.0000000e+00 1.1269392e-18 1.3098831e-18 3.8057982e-21], sum to 1.0000
[2019-03-23 11:14:54,139] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6534
[2019-03-23 11:14:54,142] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 46.66666666666667, 1.0, 2.0, 0.3433677911584362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 380405.4636100465, 380405.4636100463, 116931.63784239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7323000.0000, 
sim time next is 7323600.0000, 
raw observation next is [24.6, 47.33333333333334, 1.0, 2.0, 0.3447955287929138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 381687.7229541142, 381687.7229541145, 116922.255750389], 
processed observation next is [1.0, 0.782608695652174, 0.7545454545454546, 0.47333333333333344, 1.0, 1.0, 0.18099441099114225, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1413658233163386, 0.1413658233163387, 0.28517623353753413], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.4167825], dtype=float32), -0.008132664]. 
=============================================
[2019-03-23 11:14:55,828] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2317655: loss 0.0280
[2019-03-23 11:14:55,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2317655: learning rate 0.0010
[2019-03-23 11:14:57,479] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2318485: loss 0.0005
[2019-03-23 11:14:57,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2318485: learning rate 0.0010
[2019-03-23 11:14:57,889] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2318691: loss 0.0003
[2019-03-23 11:14:57,891] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2318692: learning rate 0.0010
[2019-03-23 11:14:58,917] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2319208: loss 0.0013
[2019-03-23 11:14:58,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2319208: learning rate 0.0010
[2019-03-23 11:14:59,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2576246e-12 1.0000000e+00 2.3763840e-18 1.2753398e-17 4.6110127e-20], sum to 1.0000
[2019-03-23 11:14:59,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6929
[2019-03-23 11:14:59,990] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 77.0, 1.0, 2.0, 0.3657627517358572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408206.2858175653, 408206.2858175653, 119922.4418146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7890000.0000, 
sim time next is 7890600.0000, 
raw observation next is [20.41666666666667, 77.5, 1.0, 2.0, 0.3531047920411009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 394766.3798215234, 394766.3798215237, 119203.4902033909], 
processed observation next is [1.0, 0.30434782608695654, 0.5643939393939396, 0.775, 1.0, 1.0, 0.1913809900513761, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14620977030426793, 0.14620977030426802, 0.2907402200082705], 
reward next is 0.7093, 
noisyNet noise sample is [array([-0.3923493], dtype=float32), -0.128095]. 
=============================================
[2019-03-23 11:15:01,652] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320563: loss 0.0000
[2019-03-23 11:15:01,653] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320564: learning rate 0.0010
[2019-03-23 11:15:02,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7975206e-12 1.0000000e+00 2.9704020e-19 1.6924277e-17 9.1017164e-20], sum to 1.0000
[2019-03-23 11:15:02,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6442
[2019-03-23 11:15:02,181] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 73.5, 1.0, 2.0, 0.4585324887890091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 523121.8066535628, 523121.806653563, 135669.554081049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7467000.0000, 
sim time next is 7467600.0000, 
raw observation next is [24.2, 73.0, 1.0, 2.0, 0.4632740257380979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 528593.2618712883, 528593.2618712883, 136433.3471986708], 
processed observation next is [0.0, 0.43478260869565216, 0.7363636363636363, 0.73, 1.0, 1.0, 0.32909253217262235, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19577528217455123, 0.19577528217455123, 0.33276426146017263], 
reward next is 0.6672, 
noisyNet noise sample is [array([0.7616494], dtype=float32), 0.23577006]. 
=============================================
[2019-03-23 11:15:02,307] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2320898: loss 0.0003
[2019-03-23 11:15:02,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2320900: learning rate 0.0010
[2019-03-23 11:15:02,400] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2320944: loss 0.0001
[2019-03-23 11:15:02,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2320945: learning rate 0.0010
[2019-03-23 11:15:02,567] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2321030: loss 0.0003
[2019-03-23 11:15:02,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2321032: learning rate 0.0010
[2019-03-23 11:15:03,146] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2321324: loss 0.0029
[2019-03-23 11:15:03,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2321324: learning rate 0.0010
[2019-03-23 11:15:03,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8379829e-11 1.0000000e+00 3.7575659e-17 9.1496658e-17 7.2472576e-19], sum to 1.0000
[2019-03-23 11:15:03,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6378
[2019-03-23 11:15:03,586] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.16666666666667, 97.66666666666667, 1.0, 2.0, 0.4443566506186492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 506280.4649664879, 506280.4649664879, 132941.4676837768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536000.0000, 
sim time next is 7536600.0000, 
raw observation next is [20.25, 96.5, 1.0, 2.0, 0.4426082311131476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 504193.3871429862, 504193.3871429859, 132643.6049782748], 
processed observation next is [0.0, 0.21739130434782608, 0.5568181818181818, 0.965, 1.0, 1.0, 0.30326028889143447, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.18673829153443933, 0.18673829153443922, 0.3235209877518897], 
reward next is 0.6765, 
noisyNet noise sample is [array([-0.8161549], dtype=float32), 1.507007]. 
=============================================
[2019-03-23 11:15:04,040] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2321770: loss 0.0079
[2019-03-23 11:15:04,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2321771: learning rate 0.0010
[2019-03-23 11:15:04,059] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:15:04,060] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:15:04,119] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 11:15:04,180] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2321819: loss 0.0014
[2019-03-23 11:15:04,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2321819: learning rate 0.0010
[2019-03-23 11:15:04,386] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2321928: loss 0.0024
[2019-03-23 11:15:04,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2321928: learning rate 0.0010
[2019-03-23 11:15:04,390] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321928: loss 0.0068
[2019-03-23 11:15:04,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321930: learning rate 0.0010
[2019-03-23 11:15:04,643] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2322065: loss 0.0024
[2019-03-23 11:15:04,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2322066: learning rate 0.0010
[2019-03-23 11:15:05,933] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2322774: loss 0.0011
[2019-03-23 11:15:05,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2322775: learning rate 0.0010
[2019-03-23 11:15:06,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.3064008e-13 1.0000000e+00 5.3598393e-19 8.1504596e-18 1.9765642e-19], sum to 1.0000
[2019-03-23 11:15:06,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0041
[2019-03-23 11:15:06,647] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1334381.441635409 W.
[2019-03-23 11:15:06,654] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.8, 53.0, 1.0, 2.0, 0.6909728673167095, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9761058445423137, 6.911199999999999, 6.9112, 77.32846344354104, 1334381.441635409, 1334381.441635409, 289616.6281159315], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7660800.0000, 
sim time next is 7661400.0000, 
raw observation next is [28.61666666666667, 53.83333333333334, 1.0, 2.0, 0.7005604664170703, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9753740181303965, 6.911200000000001, 6.9112, 77.32846344354104, 1345815.364003311, 1345815.364003311, 290332.1787180726], 
processed observation next is [1.0, 0.6956521739130435, 0.9371212121212124, 0.5383333333333334, 1.0, 1.0, 0.6257005830213377, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9648200259005664, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.49845013481604106, 0.49845013481604106, 0.7081272651660308], 
reward next is 0.2919, 
noisyNet noise sample is [array([0.11035138], dtype=float32), -0.88538855]. 
=============================================
[2019-03-23 11:15:09,210] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2324423: loss 0.0075
[2019-03-23 11:15:09,212] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2324423: learning rate 0.0010
[2019-03-23 11:15:09,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9514571e-13 1.0000000e+00 9.2796336e-21 6.3313270e-20 9.0095438e-22], sum to 1.0000
[2019-03-23 11:15:09,328] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4671
[2019-03-23 11:15:09,337] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 65.5, 1.0, 2.0, 0.6759779037764949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 752195.0432417636, 752195.0432417636, 150514.082280321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7813800.0000, 
sim time next is 7814400.0000, 
raw observation next is [21.43333333333334, 61.33333333333333, 1.0, 2.0, 0.6703002770913212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 740024.9899580008, 740024.9899580008, 147684.7460765385], 
processed observation next is [1.0, 0.43478260869565216, 0.6106060606060609, 0.6133333333333333, 1.0, 1.0, 0.5878753463641515, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2740833296140744, 0.2740833296140744, 0.36020669774765485], 
reward next is 0.6398, 
noisyNet noise sample is [array([1.1602902], dtype=float32), -1.267869]. 
=============================================
[2019-03-23 11:15:10,347] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 11:15:10,348] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:15:10,350] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:15:10,350] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:15:10,351] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:15:10,352] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:15:10,353] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:15:10,353] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:15:10,354] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:15:10,354] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:15:10,355] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:15:10,378] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 11:15:10,405] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 11:15:10,405] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 11:15:10,455] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 11:15:10,455] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 11:15:40,133] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77855575]
[2019-03-23 11:15:40,134] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [13.66666666666667, 60.66666666666667, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 95.55338769695034, 209745.722174451, 209745.7221744503, 71336.72197475111]
[2019-03-23 11:15:40,134] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:15:40,137] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1191074e-12 1.0000000e+00 1.4656738e-18 5.5935665e-18 5.7597051e-20], sampled 0.46082012872306566
[2019-03-23 11:15:41,100] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.77855575]
[2019-03-23 11:15:41,104] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [16.2, 60.0, 1.0, 2.0, 0.2263966305507238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 245801.2550682689, 245801.2550682689, 77873.77511034974]
[2019-03-23 11:15:41,107] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:15:41,111] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [6.1191074e-12 1.0000000e+00 1.4656738e-18 5.5935665e-18 5.7597051e-20], sampled 0.9355190991796504
[2019-03-23 11:16:48,188] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:16:48,407] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:16:48,446] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:16:48,476] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:16:48,531] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:16:49,546] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2325000, evaluation results [2325000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:16:49,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.79146531e-11 1.00000000e+00 1.09097718e-16 1.27346325e-17
 1.82067499e-18], sum to 1.0000
[2019-03-23 11:16:49,814] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0941
[2019-03-23 11:16:49,820] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 66.33333333333334, 1.0, 2.0, 0.4825231763069097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550566.6557370136, 550566.6557370136, 139332.1025411706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7669200.0000, 
sim time next is 7669800.0000, 
raw observation next is [25.2, 69.5, 1.0, 2.0, 0.4829087234054736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 550975.3320877956, 550975.3320877956, 139512.2069052123], 
processed observation next is [1.0, 0.782608695652174, 0.7818181818181817, 0.695, 1.0, 1.0, 0.35363590425684194, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20406493781029467, 0.20406493781029467, 0.3402736753785666], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.97042775], dtype=float32), -0.30215922]. 
=============================================
[2019-03-23 11:16:52,036] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2326337: loss 0.0179
[2019-03-23 11:16:52,039] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2326337: learning rate 0.0010
[2019-03-23 11:16:52,484] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2326573: loss 0.0224
[2019-03-23 11:16:52,487] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2326575: learning rate 0.0010
[2019-03-23 11:16:53,412] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2327066: loss 0.0215
[2019-03-23 11:16:53,413] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2327066: learning rate 0.0010
[2019-03-23 11:16:56,193] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328546: loss 0.1603
[2019-03-23 11:16:56,195] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328548: learning rate 0.0010
[2019-03-23 11:16:56,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:16:56,315] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:56,339] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 11:16:56,731] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2328806: loss 0.2185
[2019-03-23 11:16:56,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2328806: learning rate 0.0010
[2019-03-23 11:16:56,814] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2328848: loss 0.2275
[2019-03-23 11:16:56,815] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2328848: learning rate 0.0010
[2019-03-23 11:16:56,938] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328914: loss 0.1807
[2019-03-23 11:16:56,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328914: learning rate 0.0010
[2019-03-23 11:16:57,396] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2329192: loss 0.1429
[2019-03-23 11:16:57,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2329192: learning rate 0.0010
[2019-03-23 11:16:58,271] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2329657: loss 0.0187
[2019-03-23 11:16:58,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2329659: learning rate 0.0010
[2019-03-23 11:16:58,389] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2329715: loss 0.0626
[2019-03-23 11:16:58,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2329716: learning rate 0.0010
[2019-03-23 11:16:58,495] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2329764: loss 0.0707
[2019-03-23 11:16:58,497] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2329765: learning rate 0.0010
[2019-03-23 11:16:58,627] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2329832: loss 0.0105
[2019-03-23 11:16:58,628] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2329832: learning rate 0.0010
[2019-03-23 11:16:59,026] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2330038: loss 0.0694
[2019-03-23 11:16:59,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2330039: learning rate 0.0010
[2019-03-23 11:16:59,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:16:59,785] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:16:59,807] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 11:17:00,191] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2330611: loss 0.1200
[2019-03-23 11:17:00,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2330612: learning rate 0.0010
[2019-03-23 11:17:00,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:00,323] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:00,375] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 11:17:00,763] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7602829e-13 1.0000000e+00 2.4438614e-19 4.2257240e-19 1.0876838e-20], sum to 1.0000
[2019-03-23 11:17:00,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2654
[2019-03-23 11:17:00,772] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 65.0, 1.0, 2.0, 0.2877691164956646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 312470.4865266649, 312470.4865266652, 98884.84875860292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7862400.0000, 
sim time next is 7863000.0000, 
raw observation next is [19.3, 65.5, 1.0, 2.0, 0.2844885489632176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308907.1920701596, 308907.1920701599, 98197.78574834878], 
processed observation next is [1.0, 0.0, 0.5136363636363637, 0.655, 1.0, 1.0, 0.10561068620402202, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11441007113709614, 0.11441007113709625, 0.23950679450816775], 
reward next is 0.7605, 
noisyNet noise sample is [array([0.6051471], dtype=float32), 0.5860523]. 
=============================================
[2019-03-23 11:17:00,787] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.028755]
 [72.028755]
 [72.028755]
 [72.028755]
 [72.028755]], R is [[72.06896973]
 [72.10710144]
 [72.13824463]
 [72.16164398]
 [72.17633057]].
[2019-03-23 11:17:00,993] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:00,994] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:01,050] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 11:17:02,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4910809e-11 1.0000000e+00 5.3442413e-19 6.9721193e-19 1.1872099e-19], sum to 1.0000
[2019-03-23 11:17:02,350] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9670
[2019-03-23 11:17:02,355] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 96.0, 1.0, 2.0, 0.3554738781628841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 395055.3200971914, 395055.3200971914, 118372.8525196534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 19200.0000, 
sim time next is 19800.0000, 
raw observation next is [17.5, 97.0, 1.0, 2.0, 0.3524546764306783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 391341.5638586317, 391341.5638586314, 117986.1980983796], 
processed observation next is [1.0, 0.21739130434782608, 0.4318181818181818, 0.97, 1.0, 1.0, 0.19056834553834784, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14494131994764137, 0.14494131994764126, 0.28777121487409657], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.06324112], dtype=float32), 0.43661964]. 
=============================================
[2019-03-23 11:17:03,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:03,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:03,416] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 11:17:04,071] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:04,073] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:04,134] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 11:17:04,135] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:04,137] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:04,204] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 11:17:04,446] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:04,446] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:04,460] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 11:17:04,687] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:04,687] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:04,717] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 11:17:05,379] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:05,380] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:05,390] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:05,392] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:05,407] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 11:17:05,443] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 11:17:05,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:05,519] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:05,551] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 11:17:05,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:05,579] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:05,605] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 11:17:05,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:05,813] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:05,822] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 11:17:06,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 11:17:06,341] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:06,359] EPLUS_ENV_Part3-NA-Pit-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 11:17:17,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6038316e-14 1.0000000e+00 9.0650083e-23 3.4123414e-21 1.6141518e-22], sum to 1.0000
[2019-03-23 11:17:17,383] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7189
[2019-03-23 11:17:17,391] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.0, 76.0, 1.0, 2.0, 0.3035881641048436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 53.75729996279058, 329702.2295816226, 329702.2295816229, 66371.84992910421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 360600.0000, 
sim time next is 361200.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.407040732724772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 61.18001451380767, 442091.996132585, 442091.9961325846, 78200.9542706201], 
processed observation next is [1.0, 0.17391304347826086, 0.18181818181818182, 0.76, 1.0, 1.0, 0.25880091590596493, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 1.7763568394002506e-16, 0.0, 0.40225397956387, 0.16373777634540185, 0.1637377763454017, 0.1907340348063905], 
reward next is 0.8093, 
noisyNet noise sample is [array([-0.32851908], dtype=float32), -0.004744646]. 
=============================================
[2019-03-23 11:17:18,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4766382e-14 1.0000000e+00 1.0150479e-20 8.1007284e-21 7.7717762e-23], sum to 1.0000
[2019-03-23 11:17:18,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2818
[2019-03-23 11:17:18,908] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 64.0, 1.0, 2.0, 0.2865682159448344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 311166.0865496969, 311166.0865496966, 106200.0003820253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 216000.0000, 
sim time next is 216600.0000, 
raw observation next is [20.33333333333334, 61.66666666666667, 1.0, 2.0, 0.2838534592587966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 308217.3718774215, 308217.3718774217, 105428.114932431], 
processed observation next is [0.0, 0.5217391304347826, 0.5606060606060609, 0.6166666666666667, 1.0, 1.0, 0.10481682407349577, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11415458217682278, 0.11415458217682285, 0.2571417437376366], 
reward next is 0.7429, 
noisyNet noise sample is [array([1.6842949], dtype=float32), -1.7969694]. 
=============================================
[2019-03-23 11:17:26,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2530534e-15 1.0000000e+00 1.2867471e-22 6.2988955e-22 1.1389417e-24], sum to 1.0000
[2019-03-23 11:17:26,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8306
[2019-03-23 11:17:26,832] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 60.0, 1.0, 2.0, 0.3023002732548105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 328254.2860647654, 328254.2860647654, 84037.21170550282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 383400.0000, 
sim time next is 384000.0000, 
raw observation next is [17.66666666666667, 57.33333333333333, 1.0, 2.0, 0.3055357800814002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 331768.7760196091, 331768.7760196091, 83746.82127696372], 
processed observation next is [1.0, 0.43478260869565216, 0.4393939393939396, 0.5733333333333333, 1.0, 1.0, 0.13191972510175023, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12287732445170708, 0.12287732445170708, 0.2042605396999115], 
reward next is 0.7957, 
noisyNet noise sample is [array([0.6788362], dtype=float32), 1.4771]. 
=============================================
[2019-03-23 11:17:26,844] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[80.87742]
 [80.87742]
 [80.87742]
 [80.87742]
 [80.87742]], R is [[80.86438751]
 [80.85077667]
 [80.83716583]
 [80.82139587]
 [80.8035202 ]].
[2019-03-23 11:17:34,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0210324e-11 1.0000000e+00 1.4415862e-18 2.8638227e-17 1.4797565e-20], sum to 1.0000
[2019-03-23 11:17:34,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5289
[2019-03-23 11:17:34,322] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 50.5, 1.0, 2.0, 0.6092943210146696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 686886.4247968072, 686886.4247968072, 146710.6883349566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 660600.0000, 
sim time next is 661200.0000, 
raw observation next is [25.66666666666666, 50.66666666666667, 1.0, 2.0, 0.671348517040163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 758176.7518523609, 758176.7518523607, 154967.6898890604], 
processed observation next is [1.0, 0.6521739130434783, 0.8030303030303028, 0.5066666666666667, 1.0, 1.0, 0.5891856463002036, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.2808062043897633, 0.2808062043897632, 0.3779699753391717], 
reward next is 0.6220, 
noisyNet noise sample is [array([-0.7465625], dtype=float32), 0.7807608]. 
=============================================
[2019-03-23 11:17:37,201] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3813781e-13 1.0000000e+00 7.5870681e-19 1.9600243e-18 2.3518686e-21], sum to 1.0000
[2019-03-23 11:17:37,208] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6074
[2019-03-23 11:17:37,212] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 69.0, 1.0, 2.0, 0.8367092919089806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 952833.2077909847, 952833.2077909844, 183408.7702277178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 726000.0000, 
sim time next is 726600.0000, 
raw observation next is [23.83333333333333, 69.0, 1.0, 2.0, 0.8886380717731194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 1012745.094828522, 1012745.094828522, 192596.110274364], 
processed observation next is [1.0, 0.391304347826087, 0.7196969696969695, 0.69, 1.0, 1.0, 0.8607975897163991, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.3750907758624155, 0.3750907758624155, 0.46974661042527804], 
reward next is 0.5303, 
noisyNet noise sample is [array([-1.9596046], dtype=float32), -0.91454005]. 
=============================================
[2019-03-23 11:17:38,518] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 11:17:38,520] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:17:38,520] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:38,521] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:17:38,522] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:38,523] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:17:38,524] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:17:38,527] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:17:38,528] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:38,527] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:38,530] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:17:38,548] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 11:17:38,576] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 11:17:38,578] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 11:17:38,604] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 11:17:38,604] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 11:17:40,039] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:17:40,040] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.25, 48.16666666666667, 1.0, 2.0, 0.2499377912440449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 95.55338769695034, 271365.9159234291, 271365.9159234295, 80660.69300526904]
[2019-03-23 11:17:40,041] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:17:40,043] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.11962473786617411
[2019-03-23 11:17:41,165] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:17:41,166] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.05, 32.33333333333334, 1.0, 2.0, 0.314183435373356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 341139.3817805775, 341139.3817805771, 88445.52873827504]
[2019-03-23 11:17:41,167] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:17:41,173] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.742576611828308
[2019-03-23 11:18:04,932] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:04,934] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.378050865, 70.89527688999999, 1.0, 2.0, 0.2709257056146688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 294158.7809214947, 294158.7809214944, 99196.60522825008]
[2019-03-23 11:18:04,936] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:18:04,938] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.6031133673259509
[2019-03-23 11:18:05,559] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:05,560] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.05, 86.66666666666666, 1.0, 2.0, 0.8876125794158296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 1011965.217049014, 1011965.217049014, 203742.6906568064]
[2019-03-23 11:18:05,562] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:18:05,566] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.3306127264133797
[2019-03-23 11:18:08,176] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:08,177] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.8, 38.0, 1.0, 2.0, 0.3059940777836272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 332244.9452590868, 332244.9452590864, 94148.19689483402]
[2019-03-23 11:18:08,178] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:18:08,182] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.13195510982527925
[2019-03-23 11:18:09,526] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:09,527] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [20.0, 83.0, 1.0, 2.0, 0.3831842627687571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 430324.9633657968, 430324.963365797, 122595.8501004071]
[2019-03-23 11:18:09,528] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:18:09,531] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.22978383082188625
[2019-03-23 11:18:18,830] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:18,831] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.76666666666667, 54.66666666666667, 1.0, 2.0, 0.3296341681201856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362762.2409483832, 362762.2409483828, 119252.3461324434]
[2019-03-23 11:18:18,832] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:18:18,834] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.4094754813106788
[2019-03-23 11:18:22,550] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:22,552] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [18.45223401, 90.05688964166667, 1.0, 2.0, 0.3739661813919489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 417125.1895151825, 417125.1895151825, 124816.4754222225]
[2019-03-23 11:18:22,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:18:22,556] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.22359962590887905
[2019-03-23 11:18:43,798] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:43,799] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [16.03375768166667, 97.253959515, 1.0, 2.0, 0.2937716373228572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 318970.4344587633, 318970.4344587633, 114750.6411860272]
[2019-03-23 11:18:43,801] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:18:43,803] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.8649021322823727
[2019-03-23 11:18:50,593] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:18:50,593] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.63942838, 76.932604605, 1.0, 2.0, 0.5626262872264971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9121497991101425, 7.014192982155965, 6.9112, 95.55303135286393, 1180484.5719958, 1139151.147052889, 271837.3104464109]
[2019-03-23 11:18:50,595] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:18:50,597] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.6841774507953392
[2019-03-23 11:18:50,598] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1180484.5719958 W.
[2019-03-23 11:19:03,649] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:19:03,649] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [17.53513650333333, 85.35901204333334, 1.0, 2.0, 0.298673006581354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 324293.6633971095, 324293.6633971095, 115410.1337690839]
[2019-03-23 11:19:03,650] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:19:03,653] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.5255046294571212
[2019-03-23 11:19:04,195] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:19:04,196] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.2, 87.0, 1.0, 2.0, 0.3648567659573872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 408174.8896390647, 408174.8896390644, 120286.2512656717]
[2019-03-23 11:19:04,198] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:19:04,200] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.38937003174518414
[2019-03-23 11:19:05,026] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8183753]
[2019-03-23 11:19:05,026] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [18.36666666666667, 84.0, 1.0, 2.0, 0.3382423877568907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 371644.2581368729, 371644.2581368729, 119670.044857903]
[2019-03-23 11:19:05,027] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:19:05,030] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.3829123e-12 1.0000000e+00 1.5387627e-19 6.1641499e-19 4.8444418e-21], sampled 0.17878581422808526
[2019-03-23 11:19:16,310] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:19:16,442] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:19:16,515] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:19:16,524] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:19:16,562] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:19:17,576] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2350000, evaluation results [2350000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:19:18,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0198908e-14 1.0000000e+00 4.8120232e-22 6.4992437e-21 6.4328609e-23], sum to 1.0000
[2019-03-23 11:19:18,388] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5262
[2019-03-23 11:19:18,392] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.16666666666667, 99.00000000000001, 1.0, 2.0, 0.2773531766848067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 301156.9669972636, 301156.9669972639, 86504.9565970247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 623400.0000, 
sim time next is 624000.0000, 
raw observation next is [14.33333333333333, 98.0, 1.0, 2.0, 0.2512744861683142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 272832.1344458008, 272832.1344458005, 84630.01395931492], 
processed observation next is [1.0, 0.21739130434782608, 0.28787878787878773, 0.98, 1.0, 1.0, 0.06409310771039275, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10104893868362992, 0.10104893868362981, 0.20641466819345103], 
reward next is 0.7936, 
noisyNet noise sample is [array([0.56547004], dtype=float32), -1.5119625]. 
=============================================
[2019-03-23 11:19:18,408] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.458275]
 [70.458275]
 [70.458275]
 [70.458275]
 [70.458275]], R is [[70.54727936]
 [70.6308136 ]
 [70.72442627]
 [70.81562805]
 [70.90447998]].
[2019-03-23 11:19:22,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1670017e-13 1.0000000e+00 1.8813871e-19 8.4943177e-21 3.1590918e-21], sum to 1.0000
[2019-03-23 11:19:22,638] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9181
[2019-03-23 11:19:22,644] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.16666666666667, 99.0, 1.0, 2.0, 0.2789813954717266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 302925.4780108476, 302925.4780108473, 96180.25258200047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705000.0000, 
sim time next is 705600.0000, 
raw observation next is [15.0, 100.0, 1.0, 2.0, 0.2791171322559056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 303072.9105749211, 303072.9105749211, 95311.11836341786], 
processed observation next is [1.0, 0.17391304347826086, 0.3181818181818182, 1.0, 1.0, 1.0, 0.09889641531988201, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.11224922613885967, 0.11224922613885967, 0.23246614234979965], 
reward next is 0.7675, 
noisyNet noise sample is [array([-1.9555011], dtype=float32), -0.31678143]. 
=============================================
[2019-03-23 11:19:24,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.119783e-12 1.000000e+00 1.980422e-18 9.095301e-19 6.316563e-20], sum to 1.0000
[2019-03-23 11:19:24,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6717
[2019-03-23 11:19:24,769] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 69.66666666666667, 1.0, 2.0, 0.4403600509140969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 501553.8227665648, 501553.8227665645, 132320.3367716757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 774600.0000, 
sim time next is 775200.0000, 
raw observation next is [23.66666666666666, 70.33333333333334, 1.0, 2.0, 0.4379455997707062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 498692.1694187069, 498692.1694187069, 131947.5877280294], 
processed observation next is [1.0, 1.0, 0.7121212121212118, 0.7033333333333335, 1.0, 1.0, 0.2974319997133827, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18470080348840998, 0.18470080348840998, 0.32182338470251076], 
reward next is 0.6782, 
noisyNet noise sample is [array([-0.7173647], dtype=float32), 0.108964704]. 
=============================================
[2019-03-23 11:19:26,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8925646e-13 1.0000000e+00 1.4432919e-18 5.5767959e-19 6.2429219e-21], sum to 1.0000
[2019-03-23 11:19:26,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0172
[2019-03-23 11:19:26,327] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 57.5, 1.0, 2.0, 0.4575018600910513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522021.979742149, 522021.979742149, 136420.3135594749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 755400.0000, 
sim time next is 756000.0000, 
raw observation next is [27.0, 58.0, 1.0, 2.0, 0.4624708067945638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 527705.9912611725, 527705.9912611725, 136844.9344795661], 
processed observation next is [1.0, 0.782608695652174, 0.8636363636363636, 0.58, 1.0, 1.0, 0.32808850849320476, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19544666343006387, 0.19544666343006387, 0.3337681328769905], 
reward next is 0.6662, 
noisyNet noise sample is [array([-0.83512866], dtype=float32), 0.45866486]. 
=============================================
[2019-03-23 11:19:26,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.62227]
 [67.62227]
 [67.62227]
 [67.62227]
 [67.62227]], R is [[67.61227417]
 [67.60341644]
 [67.59508514]
 [67.5869751 ]
 [66.91110229]].
[2019-03-23 11:19:32,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2322502e-13 1.0000000e+00 6.1223897e-19 8.1563069e-18 6.8174947e-20], sum to 1.0000
[2019-03-23 11:19:32,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7300
[2019-03-23 11:19:32,977] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 81.33333333333333, 1.0, 2.0, 0.4649890654104986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 530564.7398986603, 530564.7398986603, 136705.7478255277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 902400.0000, 
sim time next is 903000.0000, 
raw observation next is [23.0, 82.16666666666667, 1.0, 2.0, 0.4690106335009486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 535175.7489576885, 535175.7489576885, 137384.4563203999], 
processed observation next is [0.0, 0.43478260869565216, 0.6818181818181818, 0.8216666666666668, 1.0, 1.0, 0.33626329187618575, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19821324035469942, 0.19821324035469942, 0.33508403980585344], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.69871473], dtype=float32), 1.2753916]. 
=============================================
[2019-03-23 11:19:32,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.56489]
 [66.56489]
 [66.56489]
 [66.56489]
 [66.56489]], R is [[66.56415558]
 [66.56508636]
 [66.56755829]
 [66.57154083]
 [66.57699585]].
[2019-03-23 11:19:33,624] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5389361e-12 1.0000000e+00 5.4242013e-18 8.2707300e-18 6.9885983e-20], sum to 1.0000
[2019-03-23 11:19:33,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-23 11:19:33,640] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.4670462236261512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 532894.9632400925, 532894.9632400925, 136819.3034674335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 914400.0000, 
sim time next is 915000.0000, 
raw observation next is [23.66666666666667, 74.66666666666667, 1.0, 2.0, 0.4650945562539326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 530583.9271236982, 530583.9271236985, 136287.3420843703], 
processed observation next is [0.0, 0.6086956521739131, 0.7121212121212124, 0.7466666666666667, 1.0, 1.0, 0.3313681953174157, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1965125656013697, 0.19651256560136982, 0.3324081514252934], 
reward next is 0.6676, 
noisyNet noise sample is [array([0.18864976], dtype=float32), 1.9890547]. 
=============================================
[2019-03-23 11:19:33,656] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.8638]
 [66.8638]
 [66.8638]
 [66.8638]
 [66.8638]], R is [[66.86275482]
 [66.86042786]
 [66.85897064]
 [66.85838318]
 [66.85858917]].
[2019-03-23 11:19:36,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6110376e-13 1.0000000e+00 3.1519689e-19 4.0839641e-19 9.3732020e-21], sum to 1.0000
[2019-03-23 11:19:36,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2306
[2019-03-23 11:19:36,733] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 100.0, 1.0, 2.0, 0.4794435265477133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 547069.5909525498, 547069.5909525498, 138869.5038178576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1465800.0000, 
sim time next is 1466400.0000, 
raw observation next is [20.66666666666667, 100.0, 1.0, 2.0, 0.4753648205968214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 542429.5109104976, 542429.5109104976, 138060.4446414285], 
processed observation next is [0.0, 1.0, 0.575757575757576, 1.0, 1.0, 1.0, 0.3442060257460267, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.20089981885573988, 0.20089981885573988, 0.3367327918083622], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.6240812], dtype=float32), 0.035795987]. 
=============================================
[2019-03-23 11:19:42,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8785598e-12 1.0000000e+00 1.3358602e-19 7.7111390e-18 6.0668909e-20], sum to 1.0000
[2019-03-23 11:19:42,024] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6957
[2019-03-23 11:19:42,032] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 97.0, 1.0, 2.0, 0.2034760282791062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 220921.106046603, 220921.106046603, 73205.59540898693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053000.0000, 
sim time next is 1053600.0000, 
raw observation next is [13.0, 96.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 215955.5714983086, 215955.5714983089, 72406.91107287286], 
processed observation next is [1.0, 0.17391304347826086, 0.22727272727272727, 0.96, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.07998354499937356, 0.07998354499937367, 0.17660222212895818], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0745345], dtype=float32), -1.5537417]. 
=============================================
[2019-03-23 11:19:42,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2894273e-12 1.0000000e+00 3.6343090e-18 5.5123953e-18 4.9043011e-19], sum to 1.0000
[2019-03-23 11:19:42,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7222
[2019-03-23 11:19:42,704] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 88.0, 1.0, 2.0, 0.3187681011604869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 350472.040807142, 350472.040807142, 114019.5130803875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1130400.0000, 
sim time next is 1131000.0000, 
raw observation next is [18.0, 88.00000000000001, 1.0, 2.0, 0.3542486664005419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 389891.347963838, 389891.3479638383, 116795.3823514859], 
processed observation next is [1.0, 0.08695652173913043, 0.45454545454545453, 0.8800000000000001, 1.0, 1.0, 0.1928108330006774, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14440420294956963, 0.14440420294956974, 0.2848667862231363], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.0066532], dtype=float32), -0.20544937]. 
=============================================
[2019-03-23 11:19:42,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.71379]
 [68.71379]
 [68.71379]
 [68.71379]
 [68.71379]], R is [[68.74179077]
 [68.77627563]
 [68.8120575 ]
 [68.84916687]
 [68.88763428]].
[2019-03-23 11:19:47,075] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0401555e-13 1.0000000e+00 3.1129309e-19 4.0115478e-19 6.8550178e-21], sum to 1.0000
[2019-03-23 11:19:47,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5552
[2019-03-23 11:19:47,086] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 85.0, 1.0, 2.0, 0.5213344767476671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593562.970648845, 593562.970648845, 145671.2022132844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1211400.0000, 
sim time next is 1212000.0000, 
raw observation next is [23.8, 84.33333333333333, 1.0, 2.0, 0.521410059642821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 593629.944739459, 593629.944739459, 145694.9031308524], 
processed observation next is [1.0, 0.0, 0.7181818181818183, 0.8433333333333333, 1.0, 1.0, 0.40176257455352626, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21986294249609592, 0.21986294249609592, 0.35535342227037175], 
reward next is 0.6446, 
noisyNet noise sample is [array([1.1141295], dtype=float32), 0.07996829]. 
=============================================
[2019-03-23 11:19:47,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.119125]
 [64.119125]
 [64.119125]
 [64.119125]
 [64.119125]], R is [[64.12258148]
 [64.12606049]
 [64.12963867]
 [64.13343048]
 [64.13750458]].
[2019-03-23 11:19:47,225] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6233607e-12 1.0000000e+00 2.2751776e-18 4.2712993e-18 5.4180537e-20], sum to 1.0000
[2019-03-23 11:19:47,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1976
[2019-03-23 11:19:47,246] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 92.0, 1.0, 2.0, 0.3535316385900113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 393972.6570555549, 393972.6570555549, 118674.0132137135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1660800.0000, 
sim time next is 1661400.0000, 
raw observation next is [18.5, 91.0, 1.0, 2.0, 0.355513002656245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 396459.766051753, 396459.7660517532, 118953.6645207205], 
processed observation next is [1.0, 0.21739130434782608, 0.4772727272727273, 0.91, 1.0, 1.0, 0.19439125332030627, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14683695038953815, 0.14683695038953823, 0.29013088907492807], 
reward next is 0.7099, 
noisyNet noise sample is [array([0.48105684], dtype=float32), -1.3003166]. 
=============================================
[2019-03-23 11:19:53,889] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2500024e-11 1.0000000e+00 1.1114761e-17 6.6771045e-17 6.6988090e-19], sum to 1.0000
[2019-03-23 11:19:53,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5162
[2019-03-23 11:19:53,909] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 74.0, 1.0, 2.0, 0.5110697679401544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 582754.2421343029, 582754.2421343025, 143535.5327909396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1278600.0000, 
sim time next is 1279200.0000, 
raw observation next is [23.33333333333334, 78.0, 1.0, 2.0, 0.4887367356031698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 557695.0702418404, 557695.0702418402, 139524.2168988483], 
processed observation next is [1.0, 0.8260869565217391, 0.6969696969696972, 0.78, 1.0, 1.0, 0.36092091950396227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20655372971920016, 0.20655372971920008, 0.3403029680459715], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.08111408], dtype=float32), -0.87324953]. 
=============================================
[2019-03-23 11:19:55,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.4452710e-10 1.0000000e+00 9.7109383e-18 3.8381892e-16 7.8837410e-18], sum to 1.0000
[2019-03-23 11:19:55,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0618
[2019-03-23 11:19:55,176] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 100.0, 1.0, 2.0, 0.4530061066684629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516672.061104004, 516672.061104004, 134696.4704187427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1470000.0000, 
sim time next is 1470600.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.4583667718893049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522927.8309339767, 522927.8309339767, 135635.4847656563], 
processed observation next is [0.0, 0.0, 0.5681818181818182, 1.0, 1.0, 1.0, 0.3229584648616311, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19367697441999138, 0.19367697441999138, 0.330818255525991], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.76434594], dtype=float32), -1.4131851]. 
=============================================
[2019-03-23 11:20:01,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9749594e-10 1.0000000e+00 4.5945324e-17 1.9177938e-17 1.5348298e-18], sum to 1.0000
[2019-03-23 11:20:01,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7534
[2019-03-23 11:20:01,739] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4391799499414791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 500521.9969467454, 500521.9969467454, 132599.903506191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1485600.0000, 
sim time next is 1486200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4393252832915737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 500687.5591286489, 500687.5591286492, 132614.6647174618], 
processed observation next is [0.0, 0.17391304347826086, 0.5454545454545454, 1.0, 1.0, 1.0, 0.2991566041144671, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1854398367143144, 0.18543983671431452, 0.3234504017499068], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.47907856], dtype=float32), -0.024429547]. 
=============================================
[2019-03-23 11:20:06,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5715790e-13 1.0000000e+00 1.1906614e-19 7.9074108e-19 1.9638156e-21], sum to 1.0000
[2019-03-23 11:20:06,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4446
[2019-03-23 11:20:06,218] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5173895005407687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588991.8875350053, 588991.8875350053, 145248.3893840361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524600.0000, 
sim time next is 1525200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.5171125550062422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 588677.044754659, 588677.044754659, 145214.2793242243], 
processed observation next is [0.0, 0.6521739130434783, 0.7272727272727273, 0.83, 1.0, 1.0, 0.3963906937578027, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21802853509431813, 0.21802853509431813, 0.3541811690834739], 
reward next is 0.6458, 
noisyNet noise sample is [array([-0.30511102], dtype=float32), -1.2023784]. 
=============================================
[2019-03-23 11:20:06,481] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8895016e-10 1.0000000e+00 9.6626044e-18 2.3809583e-17 2.1804085e-19], sum to 1.0000
[2019-03-23 11:20:06,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7189
[2019-03-23 11:20:06,501] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 80.33333333333334, 1.0, 2.0, 0.5711805413408741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 644807.2146503745, 644807.2146503745, 154270.4177691068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1532400.0000, 
sim time next is 1533000.0000, 
raw observation next is [25.83333333333334, 79.66666666666667, 1.0, 2.0, 0.5744822504192579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 648139.4928852763, 648139.4928852761, 154814.8689539573], 
processed observation next is [0.0, 0.7391304347826086, 0.8106060606060609, 0.7966666666666667, 1.0, 1.0, 0.46810281302407236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24005166403158382, 0.24005166403158373, 0.3775972413511154], 
reward next is 0.6224, 
noisyNet noise sample is [array([0.5542576], dtype=float32), 2.887132]. 
=============================================
[2019-03-23 11:20:06,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.816925]
 [64.816925]
 [64.816925]
 [64.816925]
 [64.816925]], R is [[64.79116821]
 [64.76699066]
 [64.74432373]
 [64.7232132 ]
 [64.70378876]].
[2019-03-23 11:20:06,907] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 11:20:06,909] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:20:06,911] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:20:06,911] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:20:06,912] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:20:06,913] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:20:06,914] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:20:06,914] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:20:06,916] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:20:06,915] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:20:06,918] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:20:06,939] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 11:20:06,967] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 11:20:06,990] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 11:20:06,991] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 11:20:07,034] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 11:20:09,048] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:09,050] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [19.7, 40.66666666666667, 1.0, 2.0, 0.2792723087100403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 303223.4281366758, 303223.4281366758, 83744.46834174251]
[2019-03-23 11:20:09,052] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:09,054] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.6969370951789929
[2019-03-23 11:20:22,834] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:22,835] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 78.0, 1.0, 2.0, 0.3233538921989923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 354444.8312208211, 354444.8312208214, 113953.6611309192]
[2019-03-23 11:20:22,835] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:22,837] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.0901150600707229
[2019-03-23 11:20:24,416] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:24,416] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.26666666666667, 86.16666666666666, 1.0, 2.0, 0.4458603368275074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 507342.1956893299, 507342.1956893295, 136735.052609661]
[2019-03-23 11:20:24,417] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:24,420] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.8004836953836555
[2019-03-23 11:20:26,006] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:26,007] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.636643995, 81.70778173, 1.0, 2.0, 0.6311359032234538, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9318831160220356, 6.986881690111364, 6.9112, 95.55310204423962, 1257571.048032944, 1227198.242948959, 284537.4824795671]
[2019-03-23 11:20:26,010] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:20:26,013] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.3880390375821514
[2019-03-23 11:20:26,015] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1257571.048032944 W.
[2019-03-23 11:20:32,534] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:32,535] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.98333333333333, 64.16666666666667, 1.0, 2.0, 0.3831361965595426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 431338.1690403861, 431338.1690403861, 127457.1913197468]
[2019-03-23 11:20:32,537] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:20:32,539] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.10143461165658396
[2019-03-23 11:20:33,738] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:33,739] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.3978527959477547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 450981.9792828284, 450981.9792828281, 126244.7086768071]
[2019-03-23 11:20:33,740] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:33,743] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.18223143531224684
[2019-03-23 11:20:34,200] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:34,201] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.2, 85.66666666666667, 1.0, 2.0, 0.5481039043015338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 624839.527803501, 624839.5278035006, 152476.4496824206]
[2019-03-23 11:20:34,203] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:34,205] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.5573123192971446
[2019-03-23 11:20:35,579] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:35,579] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.46093955666667, 51.66378797333334, 1.0, 2.0, 0.2813001381308301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 305425.7289287635, 305425.7289287631, 93138.22195780881]
[2019-03-23 11:20:35,581] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:20:35,585] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.7379910923656056
[2019-03-23 11:20:47,948] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:47,949] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.8, 74.0, 1.0, 2.0, 0.4179362332216051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 474985.9998179217, 474985.9998179214, 133408.0441674413]
[2019-03-23 11:20:47,952] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:20:47,956] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.3041644072564935
[2019-03-23 11:20:59,512] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:20:59,513] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [22.2, 78.16666666666666, 1.0, 2.0, 0.4348599309953879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 494515.2786148962, 494515.2786148962, 135328.8841921991]
[2019-03-23 11:20:59,515] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:20:59,517] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.05267978756363334
[2019-03-23 11:21:07,735] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:21:07,735] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.0, 61.0, 1.0, 2.0, 0.3927955181827669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 444075.3252049162, 444075.3252049159, 125021.3483500547]
[2019-03-23 11:21:07,736] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:21:07,738] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.2516662522573079
[2019-03-23 11:21:20,540] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:21:20,542] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [8.8, 97.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 127187.4389903195, 127187.4389903198, 54894.15875724972]
[2019-03-23 11:21:20,542] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:21:20,545] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.47343841946024845
[2019-03-23 11:21:37,908] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:21:37,909] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.6, 44.0, 1.0, 2.0, 0.411947072087057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 447330.3396643335, 447330.3396643332, 111985.9931639176]
[2019-03-23 11:21:37,910] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:21:37,912] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.12952868605019785
[2019-03-23 11:21:40,551] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:21:40,553] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.46305001, 99.65396902, 1.0, 2.0, 0.4767342177246963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 543687.5981807599, 543687.5981807599, 143581.920831229]
[2019-03-23 11:21:40,554] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:21:40,557] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.6489578992658036
[2019-03-23 11:21:41,619] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8186727]
[2019-03-23 11:21:41,621] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [25.94110604, 76.56391691000002, 1.0, 2.0, 0.8695022998621489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 983971.5603069061, 983971.5603069061, 204697.9164375572]
[2019-03-23 11:21:41,622] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:21:41,624] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.2747026e-12 1.0000000e+00 8.1256206e-19 3.0871406e-18 3.0718893e-20], sampled 0.6691494114331761
[2019-03-23 11:21:44,917] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:21:44,954] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:21:45,168] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:21:45,237] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:21:45,349] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:21:46,365] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2375000, evaluation results [2375000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:21:55,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.04362698e-12 1.00000000e+00 1.07647333e-19 1.82864487e-18
 3.99296359e-21], sum to 1.0000
[2019-03-23 11:21:55,180] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8338
[2019-03-23 11:21:55,185] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 42.0, 1.0, 2.0, 0.4233775248051172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 459788.7952596688, 459788.7952596688, 93519.65853064683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1789200.0000, 
sim time next is 1789800.0000, 
raw observation next is [19.16666666666667, 42.66666666666666, 1.0, 2.0, 0.3193248065549847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 346747.0527106086, 346747.0527106083, 83766.36830863659], 
processed observation next is [1.0, 0.7391304347826086, 0.5075757575757578, 0.4266666666666666, 1.0, 1.0, 0.14915600819373084, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.12842483433726243, 0.12842483433726232, 0.2043082153869185], 
reward next is 0.7957, 
noisyNet noise sample is [array([-0.702193], dtype=float32), 0.26047426]. 
=============================================
[2019-03-23 11:21:55,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8621283e-15 1.0000000e+00 1.2410656e-20 2.8155483e-21 7.0358772e-24], sum to 1.0000
[2019-03-23 11:21:55,255] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1920
[2019-03-23 11:21:55,261] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3281546996286083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 356338.7322330874, 356338.7322330874, 77130.67492289764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1741800.0000, 
sim time next is 1742400.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.327643404959841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 355783.3211844948, 355783.3211844945, 77085.15477209113], 
processed observation next is [1.0, 0.17391304347826086, 0.0, 0.81, 1.0, 1.0, 0.15955425619980124, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13177160043870179, 0.13177160043870165, 0.18801257261485643], 
reward next is 0.8120, 
noisyNet noise sample is [array([-1.0893135], dtype=float32), -0.6315281]. 
=============================================
[2019-03-23 11:21:56,370] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1108812e-12 1.0000000e+00 6.8898103e-20 8.1923187e-19 2.6191390e-21], sum to 1.0000
[2019-03-23 11:21:56,381] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1916
[2019-03-23 11:21:56,386] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [12.16666666666667, 74.5, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 196319.0158241154, 196319.0158241157, 64777.57587908563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1720200.0000, 
sim time next is 1720800.0000, 
raw observation next is [12.0, 76.0, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 194454.7327812601, 194454.7327812598, 64468.3242226178], 
processed observation next is [1.0, 0.9565217391304348, 0.18181818181818182, 0.76, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0720202714004667, 0.0720202714004666, 0.15723981517711658], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41933239], dtype=float32), -0.5666185]. 
=============================================
[2019-03-23 11:21:56,772] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3426006e-14 1.0000000e+00 7.1273290e-21 1.7738696e-20 1.6008017e-23], sum to 1.0000
[2019-03-23 11:21:56,782] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-23 11:21:56,792] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2626183663382162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285152.8535174686, 285152.8535174683, 90387.98133601583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1894200.0000, 
sim time next is 1894800.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2646966779283038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 287410.1655337132, 287410.1655337129, 90611.26177589445], 
processed observation next is [1.0, 0.9565217391304348, 0.5, 0.64, 1.0, 1.0, 0.08087084741037975, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10644820945693081, 0.1064482094569307, 0.2210030775021816], 
reward next is 0.7790, 
noisyNet noise sample is [array([-0.00831826], dtype=float32), 0.516011]. 
=============================================
[2019-03-23 11:21:56,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9704223e-13 1.0000000e+00 2.1118416e-19 3.8831026e-18 1.3323473e-21], sum to 1.0000
[2019-03-23 11:21:56,921] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9680
[2019-03-23 11:21:56,926] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [8.0, 81.0, 1.0, 2.0, 0.3289944173467223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 357250.9052531076, 357250.9052531073, 77202.99928950048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1740600.0000, 
sim time next is 1741200.0000, 
raw observation next is [8.0, 81.0, 1.0, 2.0, 0.3287188149719901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 356951.5222539586, 356951.5222539589, 77179.50475938537], 
processed observation next is [1.0, 0.13043478260869565, 0.0, 0.81, 1.0, 1.0, 0.16089851871498764, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.13220426750146616, 0.13220426750146627, 0.18824269453508627], 
reward next is 0.8118, 
noisyNet noise sample is [array([0.39908388], dtype=float32), 0.08039467]. 
=============================================
[2019-03-23 11:21:58,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.07549095e-14 1.00000000e+00 5.67259138e-21 1.86284588e-21
 1.77551966e-22], sum to 1.0000
[2019-03-23 11:21:58,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3599
[2019-03-23 11:21:58,814] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333334, 41.0, 1.0, 2.0, 0.4898208125427576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 531985.8137416075, 531985.8137416075, 101847.8688554584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1781400.0000, 
sim time next is 1782000.0000, 
raw observation next is [20.0, 40.0, 1.0, 2.0, 0.4838806423513903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 525530.8114034265, 525530.8114034268, 101184.7788317587], 
processed observation next is [1.0, 0.6521739130434783, 0.5454545454545454, 0.4, 1.0, 1.0, 0.3548508029392378, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1946410412605283, 0.19464104126052845, 0.24679214349209438], 
reward next is 0.7532, 
noisyNet noise sample is [array([-0.44675556], dtype=float32), 0.5172095]. 
=============================================
[2019-03-23 11:21:58,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.73441]
 [77.73441]
 [77.73441]
 [77.73441]
 [77.73441]], R is [[77.71028137]
 [77.68476868]
 [77.66092682]
 [77.63970184]
 [77.61836243]].
[2019-03-23 11:21:59,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1717682e-15 1.0000000e+00 1.6838658e-21 7.1372565e-22 4.6011985e-24], sum to 1.0000
[2019-03-23 11:21:59,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7408
[2019-03-23 11:21:59,167] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.1, 41.0, 1.0, 2.0, 0.43548986285746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 472949.2156477051, 472949.2156477051, 94320.78793338496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1787400.0000, 
sim time next is 1788000.0000, 
raw observation next is [19.13333333333333, 41.33333333333334, 1.0, 2.0, 0.4184257361666913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 454408.6302365446, 454408.6302365446, 92781.05536625537], 
processed observation next is [1.0, 0.6956521739130435, 0.5060606060606059, 0.41333333333333344, 1.0, 1.0, 0.2730321702083641, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1682994926802017, 0.1682994926802017, 0.22629525699086675], 
reward next is 0.7737, 
noisyNet noise sample is [array([-0.7088742], dtype=float32), 1.0863343]. 
=============================================
[2019-03-23 11:21:59,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.169624]
 [77.169624]
 [77.169624]
 [77.169624]
 [77.169624]], R is [[77.17163086]
 [77.16986847]
 [77.16822815]
 [77.16304779]
 [77.1631546 ]].
[2019-03-23 11:22:06,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7272357e-13 1.0000000e+00 6.0849694e-20 3.6428990e-19 5.8584441e-21], sum to 1.0000
[2019-03-23 11:22:06,441] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-23 11:22:06,445] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 71.0, 1.0, 2.0, 0.2480047927097266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269280.9406202978, 269280.9406202978, 84764.96806948456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2075400.0000, 
sim time next is 2076000.0000, 
raw observation next is [17.0, 74.66666666666667, 1.0, 2.0, 0.2424932347551682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 263294.9303345646, 263294.9303345646, 83964.44476636783], 
processed observation next is [0.0, 0.0, 0.4090909090909091, 0.7466666666666667, 1.0, 1.0, 0.053116543443960246, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09751664086465354, 0.09751664086465354, 0.20479132869845812], 
reward next is 0.7952, 
noisyNet noise sample is [array([0.26118532], dtype=float32), 1.5626026]. 
=============================================
[2019-03-23 11:22:06,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.43398]
 [69.43398]
 [69.43398]
 [69.43398]
 [69.43398]], R is [[69.5348587 ]
 [69.63276672]
 [69.72812653]
 [69.82143402]
 [69.91347504]].
[2019-03-23 11:22:07,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7131233e-12 1.0000000e+00 1.9668155e-20 7.9038219e-19 5.2533990e-21], sum to 1.0000
[2019-03-23 11:22:07,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4500
[2019-03-23 11:22:07,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1218400.438667703 W.
[2019-03-23 11:22:07,662] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.66666666666666, 76.33333333333334, 1.0, 2.0, 0.5872541265955687, 0.0, 1.0, 0.0, 1.0, 1.0, 0.971082701364473, 6.911199999999999, 6.9112, 77.32846344351863, 1218400.438667703, 1218400.438667704, 270025.4640530472], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [24.0, 74.0, 1.0, 2.0, 0.3622909727937099, 1.0, 1.0, 0.3622909727937099, 1.0, 2.0, 0.7337280773489073, 6.9112, 6.9112, 77.3421103, 1237571.585606906, 1237571.585606906, 282673.1585844308], 
processed observation next is [1.0, 0.5217391304347826, 0.7272727272727273, 0.74, 1.0, 1.0, 0.20286371599213737, 1.0, 0.5, 0.20286371599213737, 1.0, 1.0, 0.6196115390698677, 0.0, 0.0, 0.5085185399722538, 0.4583598465210763, 0.4583598465210763, 0.6894467282547093], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20647492], dtype=float32), 1.503369]. 
=============================================
[2019-03-23 11:22:07,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.671906]
 [70.671906]
 [70.671906]
 [70.671906]
 [70.671906]], R is [[69.96517944]
 [69.26552582]
 [68.57286835]
 [67.88713837]
 [67.62981415]].
[2019-03-23 11:22:08,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1097718e-12 1.0000000e+00 8.0294183e-20 1.9260691e-19 3.1242888e-21], sum to 1.0000
[2019-03-23 11:22:08,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0561
[2019-03-23 11:22:08,979] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.5, 72.5, 1.0, 2.0, 0.2421362708272823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 262907.240363693, 262907.2403636927, 85276.68233046256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2100600.0000, 
sim time next is 2101200.0000, 
raw observation next is [18.0, 71.0, 1.0, 2.0, 0.2510262606431582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272562.5373299517, 272562.5373299519, 88689.63269968626], 
processed observation next is [0.0, 0.30434782608695654, 0.45454545454545453, 0.71, 1.0, 1.0, 0.06378282580394773, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10094908789998211, 0.10094908789998218, 0.21631617731630795], 
reward next is 0.7837, 
noisyNet noise sample is [array([-0.50625783], dtype=float32), -0.76803255]. 
=============================================
[2019-03-23 11:22:10,745] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.60388672e-12 1.00000000e+00 1.79885955e-18 1.21217016e-17
 1.87433020e-20], sum to 1.0000
[2019-03-23 11:22:10,751] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9473
[2019-03-23 11:22:10,755] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 69.33333333333334, 1.0, 2.0, 0.2478679237864025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 269132.2886953321, 269132.2886953321, 84401.78573004504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1999200.0000, 
sim time next is 1999800.0000, 
raw observation next is [17.5, 70.0, 1.0, 2.0, 0.2453434705860926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 266390.5142771441, 266390.5142771438, 83659.14641545272], 
processed observation next is [0.0, 0.13043478260869565, 0.4318181818181818, 0.7, 1.0, 1.0, 0.056679338232615735, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.0986631534359793, 0.09866315343597919, 0.20404669857427493], 
reward next is 0.7960, 
noisyNet noise sample is [array([2.4812698], dtype=float32), 0.61366385]. 
=============================================
[2019-03-23 11:22:15,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5436568e-12 1.0000000e+00 5.6946034e-19 4.4971442e-19 1.6650173e-20], sum to 1.0000
[2019-03-23 11:22:15,245] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9643
[2019-03-23 11:22:15,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 73.0, 1.0, 2.0, 0.4048566990355734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 457572.1735903056, 457572.1735903053, 126041.103417309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2222400.0000, 
sim time next is 2223000.0000, 
raw observation next is [22.0, 73.0, 1.0, 2.0, 0.3891277333430141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 439636.2734513578, 439636.2734513578, 124515.3981943815], 
processed observation next is [1.0, 0.7391304347826086, 0.6363636363636364, 0.73, 1.0, 1.0, 0.2364096666787676, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16282824942642882, 0.16282824942642882, 0.30369609315702806], 
reward next is 0.6963, 
noisyNet noise sample is [array([0.44922492], dtype=float32), -1.0412256]. 
=============================================
[2019-03-23 11:22:15,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.03362]
 [73.03362]
 [73.03362]
 [73.03362]
 [73.03362]], R is [[72.99958801]
 [72.96217346]
 [72.89128113]
 [72.72721863]
 [72.56678772]].
[2019-03-23 11:22:15,921] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8806081e-12 1.0000000e+00 2.6565334e-19 9.8771821e-20 4.1727938e-21], sum to 1.0000
[2019-03-23 11:22:15,929] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2291
[2019-03-23 11:22:15,938] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [14.0, 94.00000000000001, 1.0, 2.0, 0.249011466364053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 270374.2798821514, 270374.2798821514, 80130.79883248331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2254200.0000, 
sim time next is 2254800.0000, 
raw observation next is [14.0, 94.0, 1.0, 2.0, 0.2314744595656304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 251327.8450168316, 251327.8450168319, 78623.11021721656], 
processed observation next is [1.0, 0.08695652173913043, 0.2727272727272727, 0.94, 1.0, 1.0, 0.03934307445703798, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.09308438704327096, 0.09308438704327107, 0.19176368345662576], 
reward next is 0.8082, 
noisyNet noise sample is [array([0.296607], dtype=float32), 2.412617]. 
=============================================
[2019-03-23 11:22:18,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8089341e-14 1.0000000e+00 5.4128454e-21 2.7389572e-20 1.5691516e-22], sum to 1.0000
[2019-03-23 11:22:18,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3945
[2019-03-23 11:22:18,983] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 52.0, 1.0, 2.0, 0.2509047139178829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272430.5257931644, 272430.5257931647, 76958.71761645294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2318400.0000, 
sim time next is 2319000.0000, 
raw observation next is [17.83333333333333, 52.5, 1.0, 2.0, 0.2472116593294835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 268419.5272733378, 268419.5272733378, 76400.10269434279], 
processed observation next is [1.0, 0.8695652173913043, 0.44696969696969674, 0.525, 1.0, 1.0, 0.059014574161854357, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09941463973086587, 0.09941463973086587, 0.18634171388864093], 
reward next is 0.8137, 
noisyNet noise sample is [array([0.35119197], dtype=float32), -0.8338047]. 
=============================================
[2019-03-23 11:22:19,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.26814]
 [72.26814]
 [72.26814]
 [72.26814]
 [72.26814]], R is [[72.3591156 ]
 [72.44782257]
 [72.53424072]
 [72.61882782]
 [72.70213318]].
[2019-03-23 11:22:25,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5601478e-12 1.0000000e+00 1.1112375e-19 1.4059100e-19 2.8721220e-20], sum to 1.0000
[2019-03-23 11:22:25,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9625
[2019-03-23 11:22:25,743] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 52.0, 1.0, 2.0, 0.4078560937789581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 442924.8133421099, 442924.8133421099, 92942.21833493933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2289600.0000, 
sim time next is 2290200.0000, 
raw observation next is [18.33333333333333, 51.5, 1.0, 2.0, 0.5116119819602232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 555666.3490291903, 555666.3490291903, 104560.4697650059], 
processed observation next is [1.0, 0.5217391304347826, 0.4696969696969695, 0.515, 1.0, 1.0, 0.3895149774502789, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2058023514922927, 0.2058023514922927, 0.2550255360122095], 
reward next is 0.7450, 
noisyNet noise sample is [array([-1.0952102], dtype=float32), -1.6846862]. 
=============================================
[2019-03-23 11:22:26,782] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9933291e-11 1.0000000e+00 1.7844163e-20 1.4206122e-18 7.9703634e-21], sum to 1.0000
[2019-03-23 11:22:26,795] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9649
[2019-03-23 11:22:26,800] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 49.0, 1.0, 2.0, 0.3679717652736808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 399593.3088645232, 399593.3088645235, 97387.59446458206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2379000.0000, 
sim time next is 2379600.0000, 
raw observation next is [21.0, 49.0, 1.0, 2.0, 0.3733458298320182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 405431.6251390665, 405431.6251390665, 98884.20044047789], 
processed observation next is [1.0, 0.5652173913043478, 0.5909090909090909, 0.49, 1.0, 1.0, 0.21668228729002273, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1501598611626172, 0.1501598611626172, 0.2411809766840924], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.7915623], dtype=float32), -0.45855707]. 
=============================================
[2019-03-23 11:22:33,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7092781e-13 1.0000000e+00 3.8670749e-20 8.7915227e-19 6.5958995e-22], sum to 1.0000
[2019-03-23 11:22:33,346] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8681
[2019-03-23 11:22:33,349] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 68.0, 1.0, 2.0, 0.2537959706694151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 275570.7208624318, 275570.7208624316, 85952.87651490072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2412000.0000, 
sim time next is 2412600.0000, 
raw observation next is [17.83333333333333, 69.5, 1.0, 2.0, 0.2508974199639176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 272422.6038525974, 272422.6038525976, 85855.97396128076], 
processed observation next is [1.0, 0.9565217391304348, 0.44696969696969674, 0.695, 1.0, 1.0, 0.06362177495489701, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1008972606861472, 0.10089726068614725, 0.20940481453970916], 
reward next is 0.7906, 
noisyNet noise sample is [array([0.08228782], dtype=float32), -0.0771156]. 
=============================================
[2019-03-23 11:22:34,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.1934049e-13 1.0000000e+00 1.7355506e-19 4.2997916e-19 2.2010805e-22], sum to 1.0000
[2019-03-23 11:22:34,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3529
[2019-03-23 11:22:34,466] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.16666666666667, 99.0, 1.0, 2.0, 0.224654524208269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 243921.1122892886, 243921.1122892886, 76455.60819144723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2494200.0000, 
sim time next is 2494800.0000, 
raw observation next is [13.0, 100.0, 1.0, 2.0, 0.2236646763795778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 242846.1058561137, 242846.105856114, 76104.7915082787], 
processed observation next is [1.0, 0.9130434782608695, 0.22727272727272727, 1.0, 1.0, 1.0, 0.029580845474472227, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.089943002168931, 0.08994300216893111, 0.18562144270311876], 
reward next is 0.8144, 
noisyNet noise sample is [array([0.42917037], dtype=float32), 0.7905369]. 
=============================================
[2019-03-23 11:22:35,650] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 11:22:35,651] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:22:35,652] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:22:35,652] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:22:35,653] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:22:35,654] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:22:35,655] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:22:35,656] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:22:35,656] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:22:35,656] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:22:35,659] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:22:35,686] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 11:22:35,709] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 11:22:35,711] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 11:22:35,735] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 11:22:35,790] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 11:23:36,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8025804]
[2019-03-23 11:23:36,375] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.378436435, 88.368039625, 1.0, 2.0, 0.4275332278487885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 486774.361126081, 486774.361126081, 135193.1358337092]
[2019-03-23 11:23:36,376] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:23:36,378] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.6507943e-12 1.0000000e+00 1.8482805e-19 7.2423380e-19 6.0835972e-21], sampled 0.2786558137111408
[2019-03-23 11:23:49,057] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8025804]
[2019-03-23 11:23:49,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.1, 64.66666666666667, 1.0, 2.0, 0.3242095180420674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 356519.4203747514, 356519.420374751, 118752.4459942857]
[2019-03-23 11:23:49,083] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:23:49,088] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.6507943e-12 1.0000000e+00 1.8482805e-19 7.2423380e-19 6.0835972e-21], sampled 0.9883761513048981
[2019-03-23 11:24:13,170] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:24:13,224] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:24:13,536] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8025804]
[2019-03-23 11:24:13,537] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.96640204, 80.89046521166667, 1.0, 2.0, 0.250932915329818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272446.6006863058, 272446.6006863054, 87835.46702663317]
[2019-03-23 11:24:13,538] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:24:13,539] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [1.6507943e-12 1.0000000e+00 1.8482805e-19 7.2423380e-19 6.0835972e-21], sampled 0.705656451330924
[2019-03-23 11:24:13,559] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:24:13,649] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:24:13,752] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:24:14,768] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2400000, evaluation results [2400000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:24:16,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0149964e-11 1.0000000e+00 9.9813103e-19 3.2554628e-18 5.0948776e-21], sum to 1.0000
[2019-03-23 11:24:16,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-23 11:24:16,787] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 67.0, 1.0, 2.0, 0.4761566680734189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 543272.8678377873, 543272.8678377873, 137714.4882332846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [24.66666666666667, 67.66666666666667, 1.0, 2.0, 0.4699016173754309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 535983.7639225541, 535983.7639225544, 136581.0895037154], 
processed observation next is [1.0, 0.8260869565217391, 0.7575757575757578, 0.6766666666666667, 1.0, 1.0, 0.3373770217192886, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1985125051565015, 0.19851250515650165, 0.3331246085456473], 
reward next is 0.6669, 
noisyNet noise sample is [array([0.37619346], dtype=float32), 0.7327092]. 
=============================================
[2019-03-23 11:24:20,193] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7250194e-12 1.0000000e+00 2.9756644e-19 6.5503775e-18 3.5507649e-21], sum to 1.0000
[2019-03-23 11:24:20,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5645
[2019-03-23 11:24:20,203] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.43333333333333, 82.66666666666667, 1.0, 2.0, 0.2831164596114522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 307416.8606169726, 307416.8606169729, 104390.0557016533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2594400.0000, 
sim time next is 2595000.0000, 
raw observation next is [17.36666666666667, 85.33333333333334, 1.0, 2.0, 0.2911847750485214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 316180.5422050726, 316180.5422050729, 110605.3320469066], 
processed observation next is [0.0, 0.0, 0.42575757575757595, 0.8533333333333334, 1.0, 1.0, 0.11398096881065176, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.11710390452039726, 0.11710390452039736, 0.26976910255343073], 
reward next is 0.7302, 
noisyNet noise sample is [array([-0.5078491], dtype=float32), 0.5664492]. 
=============================================
[2019-03-23 11:24:20,236] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.545685]
 [70.545685]
 [70.545685]
 [70.545685]
 [70.545685]], R is [[70.57044983]
 [70.61013794]
 [70.66229248]
 [70.72457886]
 [70.79502106]].
[2019-03-23 11:24:25,447] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7847708e-12 1.0000000e+00 3.1189556e-20 9.4729251e-19 8.4267030e-21], sum to 1.0000
[2019-03-23 11:24:25,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8806
[2019-03-23 11:24:25,459] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 51.16666666666666, 1.0, 2.0, 0.454145361954099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 518189.8476602717, 518189.8476602717, 135564.3495154768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2829000.0000, 
sim time next is 2829600.0000, 
raw observation next is [28.0, 51.0, 1.0, 2.0, 0.4529501991942055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 516752.5424578325, 516752.5424578325, 135079.0598500009], 
processed observation next is [1.0, 0.782608695652174, 0.9090909090909091, 0.51, 1.0, 1.0, 0.3161877489927568, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19138983053993797, 0.19138983053993797, 0.32946112158536806], 
reward next is 0.6705, 
noisyNet noise sample is [array([-1.3876481], dtype=float32), 1.7575418]. 
=============================================
[2019-03-23 11:24:28,060] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7889556e-13 1.0000000e+00 5.0978185e-19 1.8044737e-19 3.6088973e-21], sum to 1.0000
[2019-03-23 11:24:28,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8535
[2019-03-23 11:24:28,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1515644.117121956 W.
[2019-03-23 11:24:28,095] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 74.0, 1.0, 2.0, 0.4492328068957038, 1.0, 1.0, 0.4492328068957038, 1.0, 2.0, 0.9089684223506918, 6.911199999999999, 6.9112, 77.3421103, 1515644.117121956, 1515644.117121956, 332289.3881990683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2889000.0000, 
sim time next is 2889600.0000, 
raw observation next is [26.66666666666667, 74.0, 1.0, 2.0, 0.6883853741954276, 1.0, 2.0, 0.6883853741954276, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1548384.419744039, 1548384.419744039, 288161.324987986], 
processed observation next is [1.0, 0.43478260869565216, 0.8484848484848487, 0.74, 1.0, 1.0, 0.6104817177442844, 1.0, 1.0, 0.6104817177442844, 0.0, 0.5, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.5734757110163107, 0.5734757110163107, 0.7028324999706976], 
reward next is 0.2972, 
noisyNet noise sample is [array([1.4779756], dtype=float32), 1.5206175]. 
=============================================
[2019-03-23 11:24:29,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6733701e-10 1.0000000e+00 3.0185750e-17 3.0167793e-17 5.2350395e-19], sum to 1.0000
[2019-03-23 11:24:29,401] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9227
[2019-03-23 11:24:29,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1136457.586816323 W.
[2019-03-23 11:24:29,414] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5152711352822469, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9508480576608461, 6.940459342905923, 6.9112, 77.32839115177505, 1136457.586816323, 1126954.759581415, 254369.1459536035], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2802000.0000, 
sim time next is 2802600.0000, 
raw observation next is [25.0, 67.0, 1.0, 2.0, 0.3437354140294434, 1.0, 1.0, 0.3437354140294434, 1.0, 2.0, 0.6957920618714553, 6.9112, 6.9112, 77.3421103, 1175486.139924422, 1175486.139924422, 273702.2460596295], 
processed observation next is [1.0, 0.43478260869565216, 0.7727272727272727, 0.67, 1.0, 1.0, 0.17966926753680423, 1.0, 0.5, 0.17966926753680423, 1.0, 1.0, 0.5654172312449361, 0.0, 0.0, 0.5085185399722538, 0.43536523700904517, 0.43536523700904517, 0.6675664538039744], 
reward next is 0.3324, 
noisyNet noise sample is [array([-1.264842], dtype=float32), 0.61627764]. 
=============================================
[2019-03-23 11:24:40,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0806658e-13 1.0000000e+00 1.1539191e-18 9.3283381e-19 2.3339066e-19], sum to 1.0000
[2019-03-23 11:24:40,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3316
[2019-03-23 11:24:41,000] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1596226.121919614 W.
[2019-03-23 11:24:41,005] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4728125446742655, 1.0, 2.0, 0.4728125446742655, 1.0, 2.0, 0.955128999851348, 6.911199999999998, 6.9112, 77.3421103, 1596226.121919614, 1596226.121919614, 343963.5103085786], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2988000.0000, 
sim time next is 2988600.0000, 
raw observation next is [28.0, 57.5, 1.0, 2.0, 0.6869203650182936, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9776709880010755, 6.911199999999999, 6.9112, 77.32846344353013, 1328539.483862448, 1328539.483862448, 290508.5961024841], 
processed observation next is [1.0, 0.6086956521739131, 0.9090909090909091, 0.575, 1.0, 1.0, 0.608650456272867, 0.0, 0.5, -0.25, 1.0, 1.0, 0.9681014114301081, -8.881784197001253e-17, 0.0, 0.5084288129205824, 0.49205166068979556, 0.49205166068979556, 0.7085575514694734], 
reward next is 0.2914, 
noisyNet noise sample is [array([1.6450453], dtype=float32), -1.9031769]. 
=============================================
[2019-03-23 11:24:43,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8690622e-12 1.0000000e+00 2.1058656e-18 3.4733761e-18 5.6182576e-21], sum to 1.0000
[2019-03-23 11:24:43,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8846
[2019-03-23 11:24:43,453] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 74.66666666666667, 1.0, 2.0, 0.4444160432111727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 505932.4886812943, 505932.4886812943, 132468.6810773829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3176400.0000, 
sim time next is 3177000.0000, 
raw observation next is [23.0, 75.5, 1.0, 2.0, 0.446913654430989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 509019.1656226801, 509019.1656226801, 132992.2735435702], 
processed observation next is [1.0, 0.782608695652174, 0.6818181818181818, 0.755, 1.0, 1.0, 0.30864206803873623, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18852561689728892, 0.18852561689728892, 0.3243713988867566], 
reward next is 0.6756, 
noisyNet noise sample is [array([0.6905503], dtype=float32), 0.012570641]. 
=============================================
[2019-03-23 11:24:43,470] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.17677]
 [66.17677]
 [66.17677]
 [66.17677]
 [66.17677]], R is [[66.19063568]
 [66.20563507]
 [66.2228241 ]
 [66.24128723]
 [66.25805664]].
[2019-03-23 11:24:44,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0999289e-11 1.0000000e+00 1.1226865e-19 3.2020832e-18 1.3973758e-20], sum to 1.0000
[2019-03-23 11:24:44,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8858
[2019-03-23 11:24:44,551] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 88.0, 1.0, 2.0, 0.3671620107911553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 408785.9890284555, 408785.9890284555, 119615.8551349524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3025200.0000, 
sim time next is 3025800.0000, 
raw observation next is [18.5, 88.0, 1.0, 2.0, 0.3627492294630079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 402896.0491100359, 402896.0491100362, 118853.1199007454], 
processed observation next is [1.0, 0.0, 0.4772727272727273, 0.88, 1.0, 1.0, 0.20343653682875987, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.14922075892964293, 0.14922075892964304, 0.28988565829450097], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.97025865], dtype=float32), 0.12264557]. 
=============================================
[2019-03-23 11:24:46,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9896532e-12 1.0000000e+00 7.9933381e-17 1.4048713e-17 1.7746023e-18], sum to 1.0000
[2019-03-23 11:24:46,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2881
[2019-03-23 11:24:46,018] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.0, 88.0, 1.0, 2.0, 0.237963822659143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 258375.6672778371, 258375.6672778369, 80920.46678724822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3299400.0000, 
sim time next is 3300000.0000, 
raw observation next is [14.66666666666667, 90.0, 1.0, 2.0, 0.2336873647813346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 253731.1761219783, 253731.1761219783, 79871.44350719529], 
processed observation next is [0.0, 0.17391304347826086, 0.30303030303030315, 0.9, 1.0, 1.0, 0.04210920597666822, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.09397450967480678, 0.09397450967480678, 0.1948083987980373], 
reward next is 0.8052, 
noisyNet noise sample is [array([1.2216101], dtype=float32), -1.560268]. 
=============================================
[2019-03-23 11:24:46,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.01419]
 [65.01419]
 [65.01419]
 [65.01419]
 [65.01419]], R is [[65.16924286]
 [65.3201828 ]
 [65.46715546]
 [65.61042023]
 [65.75038147]].
[2019-03-23 11:24:48,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9154557e-10 1.0000000e+00 9.5664710e-19 1.9570741e-17 8.2784592e-19], sum to 1.0000
[2019-03-23 11:24:48,158] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5002
[2019-03-23 11:24:48,167] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.33333333333334, 1.0, 2.0, 0.5473425055822382, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 619352.6633627025, 619352.6633627022, 150698.5730943253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3604800.0000, 
sim time next is 3605400.0000, 
raw observation next is [25.5, 76.5, 1.0, 2.0, 0.5173835026545166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 587206.0738953493, 587206.0738953493, 146239.9661023604], 
processed observation next is [1.0, 0.7391304347826086, 0.7954545454545454, 0.765, 1.0, 1.0, 0.3967293783181457, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.21748373107235158, 0.21748373107235158, 0.35668284415209855], 
reward next is 0.6433, 
noisyNet noise sample is [array([-0.8086322], dtype=float32), 1.2768652]. 
=============================================
[2019-03-23 11:25:03,054] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3557906e-14 1.0000000e+00 2.1200586e-19 4.5840563e-20 1.1908736e-21], sum to 1.0000
[2019-03-23 11:25:03,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0454
[2019-03-23 11:25:03,069] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5412235222038118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 614174.3126980367, 614174.3126980367, 149269.8493434838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3434400.0000, 
sim time next is 3435000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.551640198806727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 625835.2626028797, 625835.2626028797, 150671.605305326], 
processed observation next is [1.0, 0.782608695652174, 0.8181818181818182, 0.74, 1.0, 1.0, 0.4395502485084087, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.23179083800106653, 0.23179083800106653, 0.3674917202568927], 
reward next is 0.6325, 
noisyNet noise sample is [array([-0.54055244], dtype=float32), -0.70429724]. 
=============================================
[2019-03-23 11:25:03,097] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.23247]
 [64.23247]
 [64.23247]
 [64.23247]
 [64.23247]], R is [[64.22265625]
 [64.21635437]
 [64.21617889]
 [64.22142029]
 [64.23079681]].
[2019-03-23 11:25:04,041] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 11:25:04,044] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:25:04,045] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:25:04,047] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:25:04,049] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:25:04,047] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:25:04,049] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:25:04,050] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:25:04,052] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:25:04,050] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:25:04,054] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:25:04,079] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 11:25:04,103] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 11:25:04,126] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 11:25:04,150] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 11:25:04,151] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 11:25:07,818] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:25:07,819] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [23.76666666666667, 32.66666666666667, 1.0, 2.0, 0.3171047345389566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 344312.2278275037, 344312.2278275033, 94162.41315968482]
[2019-03-23 11:25:07,820] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:25:07,823] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.6977842445268184
[2019-03-23 11:25:33,359] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:25:33,360] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.3, 69.33333333333334, 1.0, 2.0, 0.266893628525211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 289779.8800465361, 289779.8800465357, 95722.40241557054]
[2019-03-23 11:25:33,361] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:25:33,363] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.563255216771813
[2019-03-23 11:25:38,804] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:25:38,807] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [20.0, 78.0, 1.0, 2.0, 0.3498830599480619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 389627.7311826851, 389627.7311826851, 122581.8178796374]
[2019-03-23 11:25:38,808] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:25:38,810] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.5196292619452407
[2019-03-23 11:26:04,492] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:26:04,493] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [23.88333333333334, 79.83333333333334, 1.0, 2.0, 0.5054276781830491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 576394.1083334256, 576394.1083334252, 146950.7005248765]
[2019-03-23 11:26:04,494] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:26:04,496] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.756208945655705
[2019-03-23 11:26:06,179] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:26:06,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.13333333333333, 61.0, 1.0, 2.0, 0.3325540676087068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 362811.5287140078, 362811.5287140074, 118324.6621657432]
[2019-03-23 11:26:06,180] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:26:06,183] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.1621078114130341
[2019-03-23 11:26:10,357] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:26:10,358] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [27.0, 51.0, 1.0, 2.0, 0.4177714993195757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 475310.8212366672, 475310.8212366674, 129507.9764528291]
[2019-03-23 11:26:10,359] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:26:10,361] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.17762265253988607
[2019-03-23 11:26:10,983] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:26:10,984] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [20.81465415, 72.6240476, 1.0, 2.0, 0.3953778527915558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 442636.9009617668, 442636.9009617668, 127333.4482798742]
[2019-03-23 11:26:10,985] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:26:10,987] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.8346669252115029
[2019-03-23 11:26:24,457] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8458745]
[2019-03-23 11:26:24,457] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.00954882666667, 67.67792681333334, 1.0, 2.0, 0.4107896652722112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 464200.5056169833, 464200.5056169829, 130877.0543023187]
[2019-03-23 11:26:24,459] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:26:24,464] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [1.5755392e-11 1.0000000e+00 5.4922030e-18 1.8976790e-17 2.6101152e-19], sampled 0.7407583104487285
[2019-03-23 11:26:41,350] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:26:41,657] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:26:41,799] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:26:41,814] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:26:42,094] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:26:43,109] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2425000, evaluation results [2425000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:26:52,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0506925e-12 1.0000000e+00 3.2925040e-19 8.9305138e-19 9.1772272e-21], sum to 1.0000
[2019-03-23 11:26:52,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8255
[2019-03-23 11:26:52,213] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.6613388258719594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 754259.0304219668, 754259.0304219672, 163057.3799072521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3724800.0000, 
sim time next is 3725400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.639769283801275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 729660.8528222458, 729660.8528222458, 160013.89592749], 
processed observation next is [1.0, 0.08695652173913043, 0.6363636363636364, 0.94, 1.0, 1.0, 0.5497116047515936, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.2702447603045355, 0.2702447603045355, 0.39027779494509757], 
reward next is 0.6097, 
noisyNet noise sample is [array([0.5322211], dtype=float32), 1.1859101]. 
=============================================
[2019-03-23 11:26:57,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.6542774e-12 1.0000000e+00 2.5650180e-18 3.8412799e-16 6.8955456e-19], sum to 1.0000
[2019-03-23 11:26:57,106] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0436
[2019-03-23 11:26:57,113] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.634356982625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 723491.519656792, 723491.519656792, 159256.9758902101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3726000.0000, 
sim time next is 3726600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.5800362274303857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 661512.9430847705, 661512.9430847708, 151997.7682703103], 
processed observation next is [1.0, 0.13043478260869565, 0.6363636363636364, 0.9400000000000002, 1.0, 1.0, 0.47504528428798215, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24500479373510017, 0.2450047937351003, 0.37072626407392756], 
reward next is 0.6293, 
noisyNet noise sample is [array([-1.4971595], dtype=float32), 0.40308073]. 
=============================================
[2019-03-23 11:27:01,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4990697e-14 1.0000000e+00 1.4908447e-20 1.8698891e-19 1.2746314e-22], sum to 1.0000
[2019-03-23 11:27:01,495] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2628
[2019-03-23 11:27:01,498] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 82.0, 1.0, 2.0, 0.2642704288430004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286947.2036940478, 286947.2036940481, 94215.65001566483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3909600.0000, 
sim time next is 3910200.0000, 
raw observation next is [17.0, 82.00000000000001, 1.0, 2.0, 0.2642558217303212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 286931.3384812826, 286931.3384812829, 94219.10772467071], 
processed observation next is [0.0, 0.2608695652173913, 0.4090909090909091, 0.8200000000000002, 1.0, 1.0, 0.08031977716290148, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10627086610417874, 0.10627086610417884, 0.22980270176748954], 
reward next is 0.7702, 
noisyNet noise sample is [array([1.1406543], dtype=float32), -0.34399548]. 
=============================================
[2019-03-23 11:27:09,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3218104e-13 1.0000000e+00 1.6792793e-21 2.5275049e-19 2.9010348e-22], sum to 1.0000
[2019-03-23 11:27:09,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8807
[2019-03-23 11:27:09,670] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3175327869473207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 347386.1100369328, 347386.1100369328, 113290.9632149848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4057200.0000, 
sim time next is 4057800.0000, 
raw observation next is [16.83333333333334, 95.0, 1.0, 2.0, 0.3164837416182975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 345953.1197928255, 345953.1197928255, 113113.9426003601], 
processed observation next is [1.0, 1.0, 0.40151515151515177, 0.95, 1.0, 1.0, 0.14560467702287186, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.12813078510845388, 0.12813078510845388, 0.2758876648789271], 
reward next is 0.7241, 
noisyNet noise sample is [array([-1.1441988], dtype=float32), 1.1209226]. 
=============================================
[2019-03-23 11:27:14,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0404310e-12 1.0000000e+00 1.5728944e-18 2.6544365e-19 3.9692895e-20], sum to 1.0000
[2019-03-23 11:27:14,464] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7240
[2019-03-23 11:27:14,470] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 95.0, 1.0, 2.0, 0.3366214463914776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 368936.3511369004, 368936.3511369004, 114896.8123517901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4039800.0000, 
sim time next is 4040400.0000, 
raw observation next is [17.0, 96.0, 1.0, 2.0, 0.3412567308602013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 374726.9850521348, 374726.9850521348, 115494.0398005692], 
processed observation next is [1.0, 0.782608695652174, 0.4090909090909091, 0.96, 1.0, 1.0, 0.17657091357525162, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1387877722415314, 0.1387877722415314, 0.2816927800013883], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.18837348], dtype=float32), -0.12070346]. 
=============================================
[2019-03-23 11:27:18,191] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9721277e-12 1.0000000e+00 2.6944089e-18 8.0711917e-18 2.9776841e-20], sum to 1.0000
[2019-03-23 11:27:18,199] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8638
[2019-03-23 11:27:18,202] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.0, 94.0, 1.0, 2.0, 0.3233467958571533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 353783.3540624561, 353783.3540624561, 113716.1826719446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4238400.0000, 
sim time next is 4239000.0000, 
raw observation next is [17.0, 94.0, 1.0, 2.0, 0.3222822818910813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 352606.1782801722, 352606.1782801719, 113635.9357746284], 
processed observation next is [1.0, 0.043478260869565216, 0.4090909090909091, 0.94, 1.0, 1.0, 0.15285285236385163, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.1305948808445082, 0.1305948808445081, 0.27716081896250827], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.27101588], dtype=float32), -0.44506192]. 
=============================================
[2019-03-23 11:27:18,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.46238]
 [70.46238]
 [70.46238]
 [70.46238]
 [70.46238]], R is [[70.48060608]
 [70.4984436 ]
 [70.51574707]
 [70.53189087]
 [70.54541779]].
[2019-03-23 11:27:23,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6008004e-12 1.0000000e+00 1.9883780e-18 9.3955496e-19 1.4300552e-20], sum to 1.0000
[2019-03-23 11:27:23,125] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7872
[2019-03-23 11:27:23,131] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333333, 70.83333333333333, 1.0, 2.0, 0.4789125133302536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 546475.4115835188, 546475.4115835188, 138376.9486350991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4395000.0000, 
sim time next is 4395600.0000, 
raw observation next is [24.3, 72.0, 1.0, 2.0, 0.4780350990756967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 545449.9106961541, 545449.9106961543, 138083.9603121591], 
processed observation next is [1.0, 0.9130434782608695, 0.740909090909091, 0.72, 1.0, 1.0, 0.3475438738446208, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.20201848544302003, 0.20201848544302012, 0.33679014710282706], 
reward next is 0.6632, 
noisyNet noise sample is [array([-2.4117217], dtype=float32), 1.2973393]. 
=============================================
[2019-03-23 11:27:25,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4873090e-12 1.0000000e+00 1.2023184e-19 2.0271389e-18 4.3218413e-20], sum to 1.0000
[2019-03-23 11:27:25,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7144
[2019-03-23 11:27:25,178] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 52.5, 1.0, 2.0, 0.5328018510498149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 599941.9877912598, 599941.98779126, 137734.3318902218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4710600.0000, 
sim time next is 4711200.0000, 
raw observation next is [25.33333333333333, 52.0, 1.0, 2.0, 0.5898629605349707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 665564.3282046895, 665564.3282046892, 144750.8028364081], 
processed observation next is [1.0, 0.5217391304347826, 0.7878787878787876, 0.52, 1.0, 1.0, 0.4873287006687133, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.24650530674247761, 0.24650530674247748, 0.35305073862538566], 
reward next is 0.6469, 
noisyNet noise sample is [array([-0.85945785], dtype=float32), 0.3078059]. 
=============================================
[2019-03-23 11:27:28,325] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3903070e-12 1.0000000e+00 6.5431852e-18 3.8757626e-18 6.9844635e-21], sum to 1.0000
[2019-03-23 11:27:28,333] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0305
[2019-03-23 11:27:28,341] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 79.5, 1.0, 2.0, 0.4579328355659927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 522152.4243910886, 522152.4243910886, 134943.2091304336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4404600.0000, 
sim time next is 4405200.0000, 
raw observation next is [22.66666666666667, 80.0, 1.0, 2.0, 0.4572556989520523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 521364.2592235688, 521364.2592235688, 134843.7558349885], 
processed observation next is [1.0, 1.0, 0.6666666666666669, 0.8, 1.0, 1.0, 0.32156962369006536, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.19309787378650695, 0.19309787378650695, 0.32888720935363047], 
reward next is 0.6711, 
noisyNet noise sample is [array([-0.58312935], dtype=float32), 1.2179291]. 
=============================================
[2019-03-23 11:27:32,515] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 11:27:32,515] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:27:32,517] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:27:32,517] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:27:32,518] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:27:32,518] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:27:32,519] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:27:32,518] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:27:32,520] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:27:32,522] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:27:32,523] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:27:32,544] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 11:27:32,569] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 11:27:32,570] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 11:27:32,570] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 11:27:32,637] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 11:28:28,491] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:28,492] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [26.8, 62.33333333333334, 1.0, 2.0, 0.5082195987489737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 579469.9474349255, 579469.9474349251, 147456.8861989981]
[2019-03-23 11:28:28,494] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:28:28,496] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.5897114610088114
[2019-03-23 11:28:28,730] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:28,733] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [17.66666666666667, 100.0, 1.0, 2.0, 0.3683748671773764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 412103.2570936999, 412103.2570936996, 120574.1936335087]
[2019-03-23 11:28:28,734] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:28:28,736] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.18295695964045156
[2019-03-23 11:28:30,009] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:30,010] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [21.58030353, 60.65780608, 1.0, 2.0, 0.3584718888684322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 394564.4813697314, 394564.4813697311, 121444.6124817007]
[2019-03-23 11:28:30,011] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:28:30,014] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.9118612595752327
[2019-03-23 11:28:30,679] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:30,679] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.99252664, 71.76881921500001, 1.0, 2.0, 0.5547967215170396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 625814.7013783478, 625814.7013783478, 145027.3366178601]
[2019-03-23 11:28:30,681] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:28:30,683] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.43337185969961933
[2019-03-23 11:28:30,821] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:30,822] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [27.73506589, 43.25139792, 1.0, 2.0, 0.6404218479084876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 726103.956542186, 726103.9565421856, 157168.7281074472]
[2019-03-23 11:28:30,823] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:28:30,825] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.6607499334700027
[2019-03-23 11:28:36,066] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:36,069] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [19.3, 85.0, 1.0, 2.0, 0.3560604329574479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 397526.0117649061, 397526.0117649061, 123518.214335491]
[2019-03-23 11:28:36,070] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:28:36,073] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.7275453605444425
[2019-03-23 11:28:41,504] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:41,506] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation this: [25.8, 50.0, 1.0, 2.0, 0.3951313126349589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 445792.0975363317, 445792.0975363313, 129027.4042033565]
[2019-03-23 11:28:41,507] A3C_EVAL-Part3-NA-Pit-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 11:28:41,511] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.42083308324027724
[2019-03-23 11:28:53,960] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:53,961] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [24.4, 76.5, 1.0, 2.0, 0.5033025154695575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 573949.9963726809, 573949.9963726809, 142532.6020242819]
[2019-03-23 11:28:53,963] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:28:53,965] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.3628561221395913
[2019-03-23 11:28:58,505] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:28:58,507] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [26.04191194, 61.21633476, 1.0, 2.0, 0.4600355273751979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 524807.9516296381, 524807.9516296377, 140227.8444490957]
[2019-03-23 11:28:58,509] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:28:58,511] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.6942303417683394
[2019-03-23 11:29:08,288] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.836433]
[2019-03-23 11:29:08,288] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [18.23333333333333, 63.0, 1.0, 2.0, 0.2686824054410017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 291722.5167453255, 291722.5167453252, 89359.40505636438]
[2019-03-23 11:29:08,291] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:29:08,294] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [5.2866539e-12 1.0000000e+00 1.1472739e-18 3.8112376e-18 4.8048014e-20], sampled 0.5358499025736746
[2019-03-23 11:29:10,148] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:29:10,280] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:29:10,537] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:29:10,583] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:29:10,673] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:29:11,691] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2450000, evaluation results [2450000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:29:12,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5867670e-11 1.0000000e+00 1.1769474e-18 2.0150037e-18 6.0905431e-20], sum to 1.0000
[2019-03-23 11:29:12,227] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8019
[2019-03-23 11:29:12,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1485967.667900532 W.
[2019-03-23 11:29:12,236] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 48.66666666666666, 1.0, 2.0, 0.8222966124152409, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9733502139981705, 6.9112, 6.9112, 77.32846344354104, 1485967.667900532, 1485967.667900532, 307480.3362064118], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4374600.0000, 
sim time next is 4375200.0000, 
raw observation next is [29.0, 49.33333333333333, 1.0, 2.0, 0.4531310780556971, 1.0, 1.0, 0.4531310780556971, 1.0, 2.0, 0.917760803888492, 6.911199999999999, 6.9112, 77.3421103, 1542417.608580897, 1542417.608580897, 328854.9595099664], 
processed observation next is [1.0, 0.6521739130434783, 0.9545454545454546, 0.4933333333333333, 1.0, 1.0, 0.3164138475696213, 1.0, 0.5, 0.3164138475696213, 1.0, 1.0, 0.8825154341264173, -8.881784197001253e-17, 0.0, 0.5085185399722538, 0.5712657809558878, 0.5712657809558878, 0.802085267097479], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15783684], dtype=float32), -0.028365204]. 
=============================================
[2019-03-23 11:29:21,145] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6320800e-13 1.0000000e+00 1.8516609e-19 1.0869881e-18 5.9586711e-22], sum to 1.0000
[2019-03-23 11:29:21,154] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6519
[2019-03-23 11:29:21,159] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 60.0, 1.0, 2.0, 0.5191831732900903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 563894.2575395795, 563894.2575395795, 121656.3393104291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4617000.0000, 
sim time next is 4617600.0000, 
raw observation next is [20.33333333333334, 58.66666666666666, 1.0, 2.0, 0.5348847806941243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 580958.2498231608, 580958.2498231605, 124566.8499899083], 
processed observation next is [1.0, 0.43478260869565216, 0.5606060606060609, 0.5866666666666666, 1.0, 1.0, 0.4186059758676553, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.21516972215672622, 0.2151697221567261, 0.30382158534123976], 
reward next is 0.6962, 
noisyNet noise sample is [array([-2.1636655], dtype=float32), 1.2425214]. 
=============================================
[2019-03-23 11:29:21,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8942252e-12 1.0000000e+00 3.6209394e-19 5.9460327e-19 1.7573079e-20], sum to 1.0000
[2019-03-23 11:29:21,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0758
[2019-03-23 11:29:21,441] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [16.33333333333333, 86.0, 1.0, 2.0, 0.2708163057670788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 294056.9243628739, 294056.9243628736, 92756.60853143819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4581600.0000, 
sim time next is 4582200.0000, 
raw observation next is [16.16666666666667, 87.0, 1.0, 2.0, 0.2682767277935251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 291298.5818225371, 291298.5818225371, 91908.18900981499], 
processed observation next is [1.0, 0.0, 0.37121212121212144, 0.87, 1.0, 1.0, 0.0853459097419064, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.10788836363797671, 0.10788836363797671, 0.22416631465808534], 
reward next is 0.7758, 
noisyNet noise sample is [array([-1.081298], dtype=float32), 1.6000395]. 
=============================================
[2019-03-23 11:29:26,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8354415e-12 1.0000000e+00 1.6961358e-19 5.5857382e-19 6.0371523e-21], sum to 1.0000
[2019-03-23 11:29:26,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1886
[2019-03-23 11:29:26,670] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 64.0, 1.0, 2.0, 0.2648015234051812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 287524.0413995275, 287524.0413995275, 90723.2262650764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4655400.0000, 
sim time next is 4656000.0000, 
raw observation next is [19.0, 64.0, 1.0, 2.0, 0.2635957275987933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 286214.391458178, 286214.3914581777, 90589.07919787308], 
processed observation next is [1.0, 0.9130434782608695, 0.5, 0.64, 1.0, 1.0, 0.0794946594984916, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10600533016969556, 0.10600533016969545, 0.22094897365334898], 
reward next is 0.7791, 
noisyNet noise sample is [array([-1.3516855], dtype=float32), -0.4883066]. 
=============================================
[2019-03-23 11:29:26,683] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[69.9089]
 [69.9089]
 [69.9089]
 [69.9089]
 [69.9089]], R is [[69.98886108]
 [70.06769562]
 [70.14549255]
 [70.22290802]
 [70.29987335]].
[2019-03-23 11:29:27,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9506887e-11 1.0000000e+00 2.1428982e-19 1.2146930e-17 2.9631800e-20], sum to 1.0000
[2019-03-23 11:29:27,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7664
[2019-03-23 11:29:27,575] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.33333333333333, 75.66666666666666, 1.0, 2.0, 0.2629561672483062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 285519.7477671632, 285519.7477671629, 89714.63813194231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4664400.0000, 
sim time next is 4665000.0000, 
raw observation next is [17.16666666666667, 76.33333333333334, 1.0, 2.0, 0.2605306485793052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 282885.335747974, 282885.335747974, 88737.13216972041], 
processed observation next is [1.0, 1.0, 0.4166666666666669, 0.7633333333333334, 1.0, 1.0, 0.07566331072413147, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1047723465733237, 0.1047723465733237, 0.2164320296822449], 
reward next is 0.7836, 
noisyNet noise sample is [array([-0.09622691], dtype=float32), 0.80035645]. 
=============================================
[2019-03-23 11:29:27,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.3376]
 [68.3376]
 [68.3376]
 [68.3376]
 [68.3376]], R is [[68.43779755]
 [68.5345993 ]
 [68.62795258]
 [68.71785736]
 [68.80432892]].
[2019-03-23 11:29:33,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9542245e-13 1.0000000e+00 1.5981385e-19 1.1834072e-19 4.4241093e-21], sum to 1.0000
[2019-03-23 11:29:33,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6926
[2019-03-23 11:29:33,072] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.33333333333334, 100.0, 1.0, 2.0, 0.3871478218601393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 436066.3390564451, 436066.3390564451, 123595.3383666295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4774800.0000, 
sim time next is 4775400.0000, 
raw observation next is [18.5, 100.0, 1.0, 2.0, 0.3984293073020844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 449525.6763099156, 449525.6763099158, 125004.3339971044], 
processed observation next is [1.0, 0.2608695652173913, 0.4772727272727273, 1.0, 1.0, 1.0, 0.24803663412760552, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.16649099122589467, 0.16649099122589472, 0.3048886195051327], 
reward next is 0.6951, 
noisyNet noise sample is [array([-0.77234715], dtype=float32), 0.7096477]. 
=============================================
[2019-03-23 11:29:45,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9552224e-12 1.0000000e+00 3.6692549e-21 1.2051745e-19 1.1579521e-21], sum to 1.0000
[2019-03-23 11:29:45,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-23 11:29:45,429] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.68333333333333, 71.5, 1.0, 2.0, 0.8633014125370693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 983129.801894765, 983129.8018947652, 196398.2927576071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5490600.0000, 
sim time next is 5491200.0000, 
raw observation next is [25.86666666666667, 71.0, 1.0, 2.0, 0.9921249275226355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 1129410.156990527, 1129410.156990528, 220507.6616806629], 
processed observation next is [1.0, 0.5652173913043478, 0.8121212121212124, 0.71, 1.0, 1.0, 0.9901561594032943, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.4183000581446396, 0.41830005814464005, 0.5378235650747876], 
reward next is 0.4622, 
noisyNet noise sample is [array([-1.0275234], dtype=float32), 1.1899033]. 
=============================================
[2019-03-23 11:29:45,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5816325e-12 1.0000000e+00 2.8880101e-19 3.8388276e-19 2.0571832e-20], sum to 1.0000
[2019-03-23 11:29:45,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9948
[2019-03-23 11:29:45,605] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3810454491204145, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7712378442642568, 6.9112, 6.9112, 77.32845337660108, 868592.0169836043, 868592.0169836043, 217980.1056144846], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5228400.0000, 
sim time next is 5229000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6246239313976977, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 77.32846338122582, 712243.5440908142, 712243.5440908142, 158121.6466499747], 
processed observation next is [1.0, 0.5217391304347826, 0.6363636363636364, 0.94, 1.0, 1.0, 0.530779914247122, 0.0, 1.0, -0.25, 0.0, 0.5, -0.4285714285714286, 0.0, 0.0, 0.5084288125109362, 0.26379390521882007, 0.26379390521882007, 0.3856625528048163], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11532315], dtype=float32), -1.00176]. 
=============================================
[2019-03-23 11:29:45,621] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.42477]
 [69.42477]
 [69.42477]
 [69.42477]
 [69.42477]], R is [[68.73052979]
 [68.51156616]
 [68.20827484]
 [68.03122711]
 [67.86245728]].
[2019-03-23 11:29:48,673] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8238444e-12 1.0000000e+00 7.7125762e-19 2.4383488e-19 9.0748137e-20], sum to 1.0000
[2019-03-23 11:29:48,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5616
[2019-03-23 11:29:48,687] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4535970992497777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 516808.1228682996, 516808.1228682999, 133895.8354195116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199000.0000, 
sim time next is 5199600.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4386581447584045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 499775.048020429, 499775.048020429, 132342.3261533377], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.29832268094800557, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.1851018696371959, 0.1851018696371959, 0.32278616134960414], 
reward next is 0.6772, 
noisyNet noise sample is [array([0.18236017], dtype=float32), 0.46741807]. 
=============================================
[2019-03-23 11:29:55,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4729431e-12 1.0000000e+00 1.1745882e-18 1.8754631e-17 1.5146406e-19], sum to 1.0000
[2019-03-23 11:29:55,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3420
[2019-03-23 11:29:55,173] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 68.0, 1.0, 2.0, 0.4985893363033989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 568357.2681076314, 568357.2681076316, 142271.7990951949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5160000.0000, 
sim time next is 5160600.0000, 
raw observation next is [26.0, 69.5, 1.0, 2.0, 0.5066502083886762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 577098.3270993975, 577098.3270993975, 143681.6758046829], 
processed observation next is [0.0, 0.7391304347826086, 0.8181818181818182, 0.695, 1.0, 1.0, 0.3833127604858453, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.213740121147925, 0.213740121147925, 0.35044311171873876], 
reward next is 0.6496, 
noisyNet noise sample is [array([-0.29708758], dtype=float32), -1.2366725]. 
=============================================
[2019-03-23 11:29:55,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9484520e-13 1.0000000e+00 1.2732968e-19 1.1857984e-18 4.8648313e-21], sum to 1.0000
[2019-03-23 11:29:55,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5888
[2019-03-23 11:29:55,338] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 83.83333333333333, 1.0, 2.0, 0.458946535330046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 523514.5916442605, 523514.5916442605, 135479.6243041419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5181000.0000, 
sim time next is 5181600.0000, 
raw observation next is [22.26666666666667, 83.66666666666667, 1.0, 2.0, 0.4555483154006109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 519554.9521824036, 519554.9521824033, 134926.8970514923], 
processed observation next is [0.0, 1.0, 0.6484848484848486, 0.8366666666666667, 1.0, 1.0, 0.3194353942507636, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.19242776006755688, 0.19242776006755677, 0.3290899928085178], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.707273], dtype=float32), 1.1066589]. 
=============================================
[2019-03-23 11:29:55,695] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5832804e-12 1.0000000e+00 1.0612573e-18 7.2398518e-19 6.2997393e-21], sum to 1.0000
[2019-03-23 11:29:55,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1498
[2019-03-23 11:29:55,713] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 83.0, 1.0, 2.0, 0.4329355927031092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 493245.955639325, 493245.9556393247, 131749.8619988137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5200200.0000, 
sim time next is 5200800.0000, 
raw observation next is [22.0, 83.0, 1.0, 2.0, 0.4313792521388989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 491469.3500802136, 491469.3500802136, 131588.3561296366], 
processed observation next is [1.0, 0.17391304347826086, 0.6363636363636364, 0.83, 1.0, 1.0, 0.2892240651736236, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.18202568521489393, 0.18202568521489393, 0.32094721007228444], 
reward next is 0.6791, 
noisyNet noise sample is [array([-1.8377742], dtype=float32), -0.0018030351]. 
=============================================
[2019-03-23 11:30:00,906] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 11:30:00,907] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:30:00,908] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:30:00,908] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:30:00,909] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:30:00,910] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:30:00,910] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:30:00,911] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:30:00,912] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:30:00,910] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:30:00,913] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:30:00,940] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 11:30:00,940] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 11:30:00,941] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 11:30:00,967] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 11:30:01,030] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 11:30:04,640] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:30:04,642] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [11.10584570333333, 96.22986423333334, 1.0, 2.0, 0.2, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 178050.869375792, 178050.8693757916, 67177.73403983853]
[2019-03-23 11:30:04,642] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:30:04,648] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.9913398292094179
[2019-03-23 11:30:05,887] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:30:05,888] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [15.97408504, 100.0, 1.0, 2.0, 0.2816610636108617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 305817.7087363064, 305817.7087363061, 114291.0243289224]
[2019-03-23 11:30:05,890] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:30:05,894] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.7770392094558045
[2019-03-23 11:30:34,669] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:30:34,670] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [22.85, 58.5, 1.0, 2.0, 0.3614502229175249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 401566.4603097224, 401566.4603097221, 123115.7159403609]
[2019-03-23 11:30:34,671] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:30:34,675] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.37636759024432
[2019-03-23 11:30:41,373] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:30:41,373] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.91578873, 90.51716786666668, 1.0, 2.0, 0.5577164971000751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 631566.1049825089, 631566.1049825086, 156175.9788814615]
[2019-03-23 11:30:41,374] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:30:41,379] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.7474287056514591
[2019-03-23 11:30:41,943] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:30:41,944] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [21.64229065, 80.75501201, 1.0, 2.0, 0.4420352772812598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 502403.4894221968, 502403.4894221968, 135812.3022540743]
[2019-03-23 11:30:41,945] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:30:41,948] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.5759783279442656
[2019-03-23 11:31:13,004] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:31:13,005] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [26.6, 58.0, 1.0, 2.0, 0.6530980125231034, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9699072920703993, 6.9112, 6.9112, 77.32846344354104, 1293877.648536733, 1293877.648536733, 277887.0894623151]
[2019-03-23 11:31:13,006] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:31:13,009] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.13100662477933123
[2019-03-23 11:31:13,010] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1293877.648536733 W.
[2019-03-23 11:31:16,092] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:31:16,093] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [23.57270349333334, 50.21477342999999, 1.0, 2.0, 0.3419938849590103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 376716.1648845942, 376716.1648845942, 120300.9428591225]
[2019-03-23 11:31:16,094] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:31:16,096] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.3733149260216324
[2019-03-23 11:31:16,220] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.84367955]
[2019-03-23 11:31:16,222] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [15.58366459, 86.72296987666667, 1.0, 2.0, 0.2512444275515017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 272784.8970994107, 272784.8970994104, 89543.24734409276]
[2019-03-23 11:31:16,222] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:31:16,226] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [4.6198345e-12 1.0000000e+00 8.2740705e-19 2.7155934e-18 3.4373096e-20], sampled 0.6860155623679037
[2019-03-23 11:31:38,691] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:31:38,922] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:31:39,051] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:31:39,103] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:31:39,108] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:31:40,122] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2475000, evaluation results [2475000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
[2019-03-23 11:31:55,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5601993e-10 1.0000000e+00 3.1419225e-18 8.8196809e-17 1.1580599e-18], sum to 1.0000
[2019-03-23 11:31:55,492] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-23 11:31:55,496] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.9, 87.33333333333333, 1.0, 2.0, 0.2579427562230403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280074.5816400938, 280074.5816400941, 88509.1945888216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5661600.0000, 
sim time next is 5662200.0000, 
raw observation next is [16.0, 86.66666666666667, 1.0, 2.0, 0.25838175085634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 280551.3800684243, 280551.3800684246, 88779.37774459744], 
processed observation next is [0.0, 0.5217391304347826, 0.36363636363636365, 0.8666666666666667, 1.0, 1.0, 0.07297718857042501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10390791854386085, 0.10390791854386097, 0.21653506766974986], 
reward next is 0.7835, 
noisyNet noise sample is [array([-0.4920558], dtype=float32), -0.45245612]. 
=============================================
[2019-03-23 11:31:55,797] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.13973594e-14 1.00000000e+00 6.98726908e-19 1.04302344e-19
 2.62704384e-21], sum to 1.0000
[2019-03-23 11:31:55,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1263
[2019-03-23 11:31:55,811] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 42.66666666666666, 1.0, 2.0, 0.2653305022638416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 288098.5818561614, 288098.5818561614, 84309.71617001873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5755800.0000, 
sim time next is 5756400.0000, 
raw observation next is [21.6, 42.0, 1.0, 2.0, 0.2668272246438625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 289724.222447913, 289724.2224479127, 83918.22962250483], 
processed observation next is [0.0, 0.6521739130434783, 0.6181818181818183, 0.42, 1.0, 1.0, 0.0835340308048281, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.10730526757330112, 0.10730526757330099, 0.20467860883537764], 
reward next is 0.7953, 
noisyNet noise sample is [array([-1.0819511], dtype=float32), 0.475866]. 
=============================================
[2019-03-23 11:31:56,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3639941e-13 1.0000000e+00 4.0367829e-20 1.5893474e-19 1.6382097e-20], sum to 1.0000
[2019-03-23 11:31:56,796] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7490
[2019-03-23 11:31:56,799] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [15.91666666666667, 64.83333333333334, 1.0, 2.0, 0.2136468407108457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 231966.5492877442, 231966.5492877439, 72723.58361922044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5685000.0000, 
sim time next is 5685600.0000, 
raw observation next is [15.73333333333334, 65.66666666666667, 1.0, 2.0, 0.2115244341831916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 229661.6074134439, 229661.6074134442, 72381.75799333258], 
processed observation next is [0.0, 0.8260869565217391, 0.3515151515151518, 0.6566666666666667, 1.0, 1.0, 0.014405542728989501, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, -8.881784197001253e-17, 0.0, 0.5084288129206541, 0.08505985459757182, 0.08505985459757193, 0.1765408731544697], 
reward next is 0.8235, 
noisyNet noise sample is [array([-0.33159038], dtype=float32), -0.11263023]. 
=============================================
[2019-03-23 11:32:04,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3172449e-12 1.0000000e+00 1.4992217e-21 1.9582606e-18 1.7872427e-21], sum to 1.0000
[2019-03-23 11:32:04,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3621
[2019-03-23 11:32:04,654] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [13.0, 81.5, 1.0, 2.0, 0.3629273424178603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 394113.1749814787, 394113.1749814787, 85691.16614391125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5797800.0000, 
sim time next is 5798400.0000, 
raw observation next is [12.9, 81.0, 1.0, 2.0, 0.3578041610633465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 388547.5430676473, 388547.5430676473, 84920.06824422709], 
processed observation next is [1.0, 0.08695652173913043, 0.22272727272727275, 0.81, 1.0, 1.0, 0.19725520132918312, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14390649743246198, 0.14390649743246198, 0.20712211766884656], 
reward next is 0.7929, 
noisyNet noise sample is [array([-0.9449335], dtype=float32), 1.0943977]. 
=============================================
[2019-03-23 11:32:07,794] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6392226e-13 1.0000000e+00 1.4247260e-18 1.0970984e-18 2.6438229e-21], sum to 1.0000
[2019-03-23 11:32:07,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9408
[2019-03-23 11:32:07,808] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 53.0, 1.0, 2.0, 0.4074804170361689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 442516.6490915981, 442516.6490915984, 119047.5257336837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5826600.0000, 
sim time next is 5827200.0000, 
raw observation next is [22.33333333333334, 52.33333333333334, 1.0, 2.0, 0.40020461551422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 434611.7235320793, 434611.7235320793, 118474.5429241134], 
processed observation next is [1.0, 0.43478260869565216, 0.6515151515151518, 0.5233333333333334, 1.0, 1.0, 0.25025576939277494, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.16096730501188122, 0.16096730501188122, 0.28896229981491073], 
reward next is 0.7110, 
noisyNet noise sample is [array([0.00611094], dtype=float32), 0.9723795]. 
=============================================
[2019-03-23 11:32:12,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3617312e-13 1.0000000e+00 4.5109883e-21 7.1882499e-20 2.7769138e-21], sum to 1.0000
[2019-03-23 11:32:12,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8494
[2019-03-23 11:32:12,095] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 67.16666666666666, 1.0, 2.0, 0.7384602677116892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 835708.9482273972, 835708.9482273969, 164776.3665605325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5910600.0000, 
sim time next is 5911200.0000, 
raw observation next is [23.3, 66.0, 1.0, 2.0, 0.7589839674208169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 860116.8772896129, 860116.8772896127, 168354.8030187569], 
processed observation next is [1.0, 0.43478260869565216, 0.6954545454545454, 0.66, 1.0, 1.0, 0.698729959276021, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 8.881784197001253e-17, 0.0, 0.5084288129206541, 0.31856180640356035, 0.31856180640356024, 0.41062147077745587], 
reward next is 0.5894, 
noisyNet noise sample is [array([-0.90436906], dtype=float32), -1.0826813]. 
=============================================
[2019-03-23 11:32:17,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1838568e-13 1.0000000e+00 5.1411705e-20 1.4575995e-19 1.8353660e-20], sum to 1.0000
[2019-03-23 11:32:17,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1187
[2019-03-23 11:32:17,146] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.08333333333334, 78.0, 1.0, 2.0, 0.3614013664797919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 403041.3700029799, 403041.3700029802, 119435.7380630517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033000.0000, 
sim time next is 6033600.0000, 
raw observation next is [20.0, 78.0, 1.0, 2.0, 0.3585110038058198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 399367.7840600715, 399367.7840600715, 119007.5550599397], 
processed observation next is [1.0, 0.8695652173913043, 0.5454545454545454, 0.78, 1.0, 1.0, 0.19813875475727472, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14791399409632278, 0.14791399409632278, 0.29026232941448704], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.46730152], dtype=float32), -0.90731704]. 
=============================================
[2019-03-23 11:32:18,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2513523e-12 1.0000000e+00 1.1274417e-19 1.8881817e-19 1.8169890e-20], sum to 1.0000
[2019-03-23 11:32:18,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5892
[2019-03-23 11:32:18,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1190132.46062279 W.
[2019-03-23 11:32:18,184] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 61.5, 1.0, 2.0, 0.5623715096262883, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9701407594287399, 6.911412845738496, 6.9112, 77.32846280124134, 1190132.46062279, 1190063.332680949, 265755.6056513457], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6012600.0000, 
sim time next is 6013200.0000, 
raw observation next is [25.9, 63.00000000000001, 1.0, 2.0, 0.5532556417518047, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9669046919117363, 6.917050300214485, 6.9112, 77.32844896318925, 1179715.021657805, 1177814.964163274, 264010.0757258318], 
processed observation next is [1.0, 0.6086956521739131, 0.8136363636363636, 0.6300000000000001, 1.0, 1.0, 0.4415695521897559, 0.0, 1.0, -0.25, 1.0, 1.0, 0.9527209884453376, 0.000585030021448496, 0.0, 0.5084287177134336, 0.43693148950289074, 0.4362277645049163, 0.6439270139654434], 
reward next is 0.3268, 
noisyNet noise sample is [array([-1.150066], dtype=float32), -0.319745]. 
=============================================
[2019-03-23 11:32:24,450] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7947844e-13 1.0000000e+00 4.1143310e-19 7.4875572e-19 4.0102891e-21], sum to 1.0000
[2019-03-23 11:32:24,461] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8708
[2019-03-23 11:32:24,467] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 76.0, 1.0, 2.0, 0.3578895467920563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 399723.6650322391, 399723.6650322388, 119415.4670386036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6208200.0000, 
sim time next is 6208800.0000, 
raw observation next is [20.5, 76.0, 1.0, 2.0, 0.358389248163288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 77.32846344354104, 400282.8401446967, 400282.8401446967, 119456.5590217559], 
processed observation next is [1.0, 0.8695652173913043, 0.5681818181818182, 0.76, 1.0, 1.0, 0.19798656020410996, 0.0, 1.0, -0.25, 0.0, 1.0, -0.4285714285714286, 0.0, 0.0, 0.5084288129206541, 0.14825290375729508, 0.14825290375729508, 0.29135746102867294], 
reward next is 0.7086, 
noisyNet noise sample is [array([1.029967], dtype=float32), 0.12982978]. 
=============================================
[2019-03-23 11:32:29,278] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 11:32:29,279] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation job starts!
[2019-03-23 11:32:29,281] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:32:29,282] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation job starts!
[2019-03-23 11:32:29,282] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation job starts!
[2019-03-23 11:32:29,284] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:32:29,285] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:32:29,285] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation job starts!
[2019-03-23 11:32:29,286] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:32:29,287] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation job starts!
[2019-03-23 11:32:29,287] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 11:32:29,309] EPLUS_ENV_Part3-NA-Pit-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 11:32:29,335] EPLUS_ENV_Part3-NA-Pit-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 11:32:29,356] EPLUS_ENV_Part3-NA-Pit-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 11:32:29,361] EPLUS_ENV_Part3-NA-Pit-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 11:32:29,382] EPLUS_ENV_Part3-NA-Pit-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_pit_na/37/Eplus-env-Part3-NA-Pit-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 11:32:32,287] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:32:32,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [14.0, 82.0, 1.0, 2.0, 0.2077025519903881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 225511.0557956987, 225511.055795699, 72409.86519321462]
[2019-03-23 11:32:32,288] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:32:32,292] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.9153565778297904
[2019-03-23 11:32:46,095] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:32:46,096] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [21.05, 85.5, 1.0, 2.0, 0.4358614545962531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 495235.1891783972, 495235.1891783969, 135068.9763427388]
[2019-03-23 11:32:46,096] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:32:46,098] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.023346037127788377
[2019-03-23 11:32:55,868] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:32:55,870] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [19.26462594, 52.81446353, 1.0, 2.0, 0.2788463591684714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 302760.8315674246, 302760.8315674246, 88368.41922791506]
[2019-03-23 11:32:55,872] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:32:55,874] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.15772494822387695
[2019-03-23 11:33:04,237] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:33:04,239] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [18.45571316, 78.601211035, 1.0, 2.0, 0.3398435254647842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 369009.5805306326, 369009.5805306326, 118257.2039590668]
[2019-03-23 11:33:04,240] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:33:04,242] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.766012608472137
[2019-03-23 11:33:13,880] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:33:13,881] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [16.87577430333333, 88.60534068, 1.0, 2.0, 0.3233556010206424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 351101.3994474616, 351101.3994474616, 115233.5283106396]
[2019-03-23 11:33:13,882] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:33:13,884] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.7415096009841665
[2019-03-23 11:33:40,028] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:33:40,030] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation this: [20.69967145, 97.47780804666667, 1.0, 2.0, 0.4383622402219413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 95.55338769695034, 499789.6454013999, 499789.6454013995, 137219.6951559641]
[2019-03-23 11:33:40,031] A3C_EVAL-Part3-NA-Pit-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 11:33:40,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.6308773687808505
[2019-03-23 11:33:42,919] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:33:42,919] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation this: [20.23333333333333, 55.0, 1.0, 2.0, 0.2793939482278162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 303355.5331067639, 303355.5331067639, 95271.39060333674]
[2019-03-23 11:33:42,920] A3C_EVAL-Part3-NA-Pit-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 11:33:42,923] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.9474928485991654
[2019-03-23 11:33:56,975] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:33:56,977] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation this: [26.6429871, 62.86707924, 1.0, 2.0, 0.5041784191548001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 95.55338769695034, 574915.1237749679, 574915.1237749679, 146893.9208515492]
[2019-03-23 11:33:56,978] A3C_EVAL-Part3-NA-Pit-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 11:33:56,981] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.5525035427116051
[2019-03-23 11:34:02,293] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:34:02,293] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [18.8, 90.0, 1.0, 2.0, 0.3777429747719234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 77.32846344354104, 422395.5133996037, 422395.5133996034, 121274.3316233929]
[2019-03-23 11:34:02,294] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:34:02,297] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.36299267619516484
[2019-03-23 11:34:03,423] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05736277], dtype=float32), 0.8151898]
[2019-03-23 11:34:03,424] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation this: [21.76666666666667, 88.66666666666667, 1.0, 2.0, 0.4627581469059572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 77.32846344354104, 527898.2850271725, 527898.2850271729, 135979.9116971487]
[2019-03-23 11:34:03,426] A3C_EVAL-Part3-NA-Pit-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 11:34:03,428] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Softmax [6.7010564e-12 1.0000000e+00 1.4154194e-18 4.5855125e-18 6.2669530e-20], sampled 0.21791860671994223
[2019-03-23 11:34:07,785] A3C_EVAL-Part3-NA-Pit-Test-v2 INFO:Evaluation: average rewards by now are 8857.3719 1663773616.7669 105.0000
[2019-03-23 11:34:08,035] A3C_EVAL-Part3-NA-Pit-Test-v4 INFO:Evaluation: average rewards by now are 8575.1610 1683302985.0195 214.0000
[2019-03-23 11:34:08,049] A3C_EVAL-Part3-NA-Pit-Train-v1 INFO:Evaluation: average rewards by now are 8513.0492 1773161079.4054 173.0000
[2019-03-23 11:34:08,127] A3C_EVAL-Part3-NA-Pit-Test-v1 INFO:Evaluation: average rewards by now are 9061.9246 1656184827.5192 80.0000
[2019-03-23 11:34:08,220] A3C_EVAL-Part3-NA-Pit-Test-v3 INFO:Evaluation: average rewards by now are 8597.7413 1705943103.3420 465.0000
[2019-03-23 11:34:09,234] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2500000, evaluation results [2500000.0, 8513.049178629926, 1773161079.4054089, 173.0, 9061.924586821853, 1656184827.5191894, 80.0, 8857.37187739431, 1663773616.7668803, 105.0, 8597.741251737938, 1705943103.342045, 465.0, 8575.160988881958, 1683302985.0195105, 214.0]
